2019-04-22 23:27:16.317849 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 0 finished
-----------------------------  ---------------
replay_buffer/size               700
trainer/QF1 Loss                  61.4412
trainer/QF2 Loss                  61.426
trainer/Policy Loss               -1.38522
trainer/Q1 Predictions Mean        0.000262214
trainer/Q1 Predictions Std         0.00124226
trainer/Q1 Predictions Max         0.00290472
trainer/Q1 Predictions Min        -0.00222828
trainer/Q2 Predictions Mean       -0.00101215
trainer/Q2 Predictions Std         0.000499299
trainer/Q2 Predictions Max         0.000621923
trainer/Q2 Predictions Min        -0.00201106
trainer/Q Targets Mean            -7.05117
trainer/Q Targets Std              3.4234
trainer/Q Targets Max             -0.949434
trainer/Q Targets Min            -12.4157
trainer/Log Pis Mean              -1.38634
trainer/Log Pis Std                0.302476
trainer/Log Pis Max               -0.606862
trainer/Log Pis Min               -1.82999
trainer/Policy mu Mean             0.000224404
trainer/Policy mu Std              0.0010269
trainer/Policy mu Max              0.00177922
trainer/Policy mu Min             -0.00132554
trainer/Policy log std Mean        0.000242565
trainer/Policy log std Std         0.00044387
trainer/Policy log std Max         0.00115134
trainer/Policy log std Min        -0.000693188
trainer/Alpha                      0.9997
trainer/Alpha Loss                -0
exploration/num steps total      700
exploration/num paths total        7
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -8.05014
exploration/Rewards Std            2.93827
exploration/Rewards Max           -1.62246
exploration/Rewards Min          -12.7535
exploration/Returns Mean        -805.014
exploration/Returns Std          258.667
exploration/Returns Max         -451.675
exploration/Returns Min        -1059.46
exploration/Actions Mean           0.0293228
exploration/Actions Std            0.632279
exploration/Actions Max            0.997383
exploration/Actions Min           -0.99202
exploration/Num Paths              5
exploration/Average Returns     -805.014
evaluation/num steps total      1500
evaluation/num paths total        15
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -7.13491
evaluation/Rewards Std             2.65939
evaluation/Rewards Max            -2.64765
evaluation/Rewards Min           -11.5831
evaluation/Returns Mean         -713.491
evaluation/Returns Std           265.923
evaluation/Returns Max          -270.175
evaluation/Returns Min         -1157.27
evaluation/Actions Mean            0.000202467
evaluation/Actions Std             0.00098262
evaluation/Actions Max             0.00170887
evaluation/Actions Min            -0.00114003
evaluation/Num Paths              15
evaluation/Average Returns      -713.491
time/data storing (s)              0.00297896
time/evaluation sampling (s)       0.287558
time/exploration sampling (s)      0.162407
time/logging (s)                   0.00499909
time/saving (s)                    0.00245303
time/training (s)                  2.00829
time/epoch (s)                     2.46869
time/total (s)                     2.68966
Epoch                              0
-----------------------------  ---------------
2019-04-22 23:27:18.844091 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 1 finished
-----------------------------  -------------
replay_buffer/size             1200
trainer/QF1 Loss                  9.28536
trainer/QF2 Loss                  8.98331
trainer/Policy Loss              12.8369
trainer/Q1 Predictions Mean     -14.1295
trainer/Q1 Predictions Std        4.42814
trainer/Q1 Predictions Max       -6.28364
trainer/Q1 Predictions Min      -24.374
trainer/Q2 Predictions Mean     -14.2167
trainer/Q2 Predictions Std        4.35647
trainer/Q2 Predictions Max       -6.57731
trainer/Q2 Predictions Min      -24.5038
trainer/Q Targets Mean          -14.5473
trainer/Q Targets Std             4.74986
trainer/Q Targets Max            -1.20001
trainer/Q Targets Min           -23.7906
trainer/Log Pis Mean             -1.15696
trainer/Log Pis Std               0.557217
trainer/Log Pis Max               0.0642558
trainer/Log Pis Min              -2.7146
trainer/Policy mu Mean           -0.114769
trainer/Policy mu Std             0.331517
trainer/Policy mu Max             0.461771
trainer/Policy mu Min            -0.726375
trainer/Policy log std Mean      -0.183932
trainer/Policy log std Std        0.0456452
trainer/Policy log std Max       -0.111646
trainer/Policy log std Min       -0.30623
trainer/Alpha                     0.862069
trainer/Alpha Loss               -0.467655
exploration/num steps total    1200
exploration/num paths total      12
exploration/path length Mean    100
exploration/path length Std       0
exploration/path length Max     100
exploration/path length Min     100
exploration/Rewards Mean         -6.20791
exploration/Rewards Std           2.52237
exploration/Rewards Max          -0.608772
exploration/Rewards Min         -11.1505
exploration/Returns Mean       -620.791
exploration/Returns Std         213.229
exploration/Returns Max        -271.892
exploration/Returns Min        -884.028
exploration/Actions Mean         -0.0167864
exploration/Actions Std           0.601852
exploration/Actions Max           0.988303
exploration/Actions Min          -0.993956
exploration/Num Paths             5
exploration/Average Returns    -620.791
evaluation/num steps total     3000
evaluation/num paths total       30
evaluation/path length Mean     100
evaluation/path length Std        0
evaluation/path length Max      100
evaluation/path length Min      100
evaluation/Rewards Mean          -4.69481
evaluation/Rewards Std            1.16228
evaluation/Rewards Max           -0.277832
evaluation/Rewards Min          -10.9552
evaluation/Returns Mean        -469.481
evaluation/Returns Std           97.8494
evaluation/Returns Max         -312.082
evaluation/Returns Min         -604.088
evaluation/Actions Mean          -0.0138249
evaluation/Actions Std            0.0869539
evaluation/Actions Max            0.434042
evaluation/Actions Min           -0.578764
evaluation/Num Paths             15
evaluation/Average Returns     -469.481
time/data storing (s)             0.00267216
time/evaluation sampling (s)      0.338078
time/exploration sampling (s)     0.146106
time/logging (s)                  0.00491788
time/saving (s)                   0.00200889
time/training (s)                 2.02643
time/epoch (s)                    2.52021
time/total (s)                    5.21502
Epoch                             1
-----------------------------  -------------
2019-04-22 23:27:21.464545 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 2 finished
-----------------------------  -------------
replay_buffer/size             1700
trainer/QF1 Loss                  1.52233
trainer/QF2 Loss                  1.54722
trainer/Policy Loss              22.0546
trainer/Q1 Predictions Mean     -23.974
trainer/Q1 Predictions Std        8.1222
trainer/Q1 Predictions Max      -12.5145
trainer/Q1 Predictions Min      -42.6938
trainer/Q2 Predictions Mean     -23.9447
trainer/Q2 Predictions Std        8.07828
trainer/Q2 Predictions Max      -12.7407
trainer/Q2 Predictions Min      -42.9517
trainer/Q Targets Mean          -24.2054
trainer/Q Targets Std             8.23281
trainer/Q Targets Max           -12.8176
trainer/Q Targets Min           -42.9807
trainer/Log Pis Mean             -0.681659
trainer/Log Pis Std               1.082
trainer/Log Pis Max               1.78902
trainer/Log Pis Min              -4.30633
trainer/Policy mu Mean            0.0355488
trainer/Policy mu Std             0.693468
trainer/Policy mu Max             1.22652
trainer/Policy mu Min            -1.43342
trainer/Policy log std Mean      -0.353014
trainer/Policy log std Std        0.0529555
trainer/Policy log std Max       -0.254217
trainer/Policy log std Min       -0.541664
trainer/Alpha                     0.754816
trainer/Alpha Loss               -0.753632
exploration/num steps total    1700
exploration/num paths total      17
exploration/path length Mean    100
exploration/path length Std       0
exploration/path length Max     100
exploration/path length Min     100
exploration/Rewards Mean         -4.75124
exploration/Rewards Std           1.59505
exploration/Rewards Max          -0.278708
exploration/Rewards Min          -8.68878
exploration/Returns Mean       -475.124
exploration/Returns Std         132.921
exploration/Returns Max        -278.407
exploration/Returns Min        -645.889
exploration/Actions Mean         -0.00571218
exploration/Actions Std           0.566795
exploration/Actions Max           0.995351
exploration/Actions Min          -0.980986
exploration/Num Paths             5
exploration/Average Returns    -475.124
evaluation/num steps total     4500
evaluation/num paths total       45
evaluation/path length Mean     100
evaluation/path length Std        0
evaluation/path length Max      100
evaluation/path length Min      100
evaluation/Rewards Mean          -4.61999
evaluation/Rewards Std            1.47849
evaluation/Rewards Max           -0.730586
evaluation/Rewards Min          -10.2035
evaluation/Returns Mean        -461.999
evaluation/Returns Std          137.043
evaluation/Returns Max         -224.346
evaluation/Returns Min         -642.176
evaluation/Actions Mean          -0.0223884
evaluation/Actions Std            0.122341
evaluation/Actions Max            0.633384
evaluation/Actions Min           -0.905593
evaluation/Num Paths             15
evaluation/Average Returns     -461.999
time/data storing (s)             0.00291592
time/evaluation sampling (s)      0.352238
time/exploration sampling (s)     0.1566
time/logging (s)                  0.00501174
time/saving (s)                   0.00209384
time/training (s)                 2.09665
time/epoch (s)                    2.61551
time/total (s)                    7.83483
Epoch                             2
-----------------------------  -------------
2019-04-22 23:27:24.309468 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 3 finished
-----------------------------  --------------
replay_buffer/size             2200
trainer/QF1 Loss                 11.6828
trainer/QF2 Loss                 11.697
trainer/Policy Loss              32.6413
trainer/Q1 Predictions Mean     -34.842
trainer/Q1 Predictions Std       10.3155
trainer/Q1 Predictions Max      -16.4657
trainer/Q1 Predictions Min      -56.4541
trainer/Q2 Predictions Mean     -34.907
trainer/Q2 Predictions Std       10.2976
trainer/Q2 Predictions Max      -16.9338
trainer/Q2 Predictions Min      -57.3536
trainer/Q Targets Mean          -34.9225
trainer/Q Targets Std            10.9896
trainer/Q Targets Max            -3.29338
trainer/Q Targets Min           -58.8848
trainer/Log Pis Mean             -0.397432
trainer/Log Pis Std               1.14756
trainer/Log Pis Max               2.93528
trainer/Log Pis Min              -4.05555
trainer/Policy mu Mean           -0.0494227
trainer/Policy mu Std             0.785457
trainer/Policy mu Max             1.50782
trainer/Policy mu Min            -1.61569
trainer/Policy log std Mean      -0.406281
trainer/Policy log std Std        0.0654508
trainer/Policy log std Max       -0.280608
trainer/Policy log std Min       -0.588091
trainer/Alpha                     0.663743
trainer/Alpha Loss               -0.981996
exploration/num steps total    2200
exploration/num paths total      22
exploration/path length Mean    100
exploration/path length Std       0
exploration/path length Max     100
exploration/path length Min     100
exploration/Rewards Mean         -3.93878
exploration/Rewards Std           1.65239
exploration/Rewards Max          -0.637292
exploration/Rewards Min          -9.23155
exploration/Returns Mean       -393.878
exploration/Returns Std         144.586
exploration/Returns Max        -221.459
exploration/Returns Min        -650.844
exploration/Actions Mean         -0.000771848
exploration/Actions Std           0.538102
exploration/Actions Max           0.992328
exploration/Actions Min          -0.985414
exploration/Num Paths             5
exploration/Average Returns    -393.878
evaluation/num steps total     6000
evaluation/num paths total       60
evaluation/path length Mean     100
evaluation/path length Std        0
evaluation/path length Max      100
evaluation/path length Min      100
evaluation/Rewards Mean          -3.73813
evaluation/Rewards Std            1.54725
evaluation/Rewards Max           -1.67722
evaluation/Rewards Min           -8.14647
evaluation/Returns Mean        -373.813
evaluation/Returns Std          146.002
evaluation/Returns Max         -191.509
evaluation/Returns Min         -571.617
evaluation/Actions Mean           0.0010402
evaluation/Actions Std            0.132426
evaluation/Actions Max            0.884658
evaluation/Actions Min           -0.908752
evaluation/Num Paths             15
evaluation/Average Returns     -373.813
time/data storing (s)             0.00287121
time/evaluation sampling (s)      0.363021
time/exploration sampling (s)     0.182856
time/logging (s)                  0.00525064
time/saving (s)                   0.00219843
time/training (s)                 2.28342
time/epoch (s)                    2.83962
time/total (s)                   10.6792
Epoch                             3
-----------------------------  --------------
2019-04-22 23:27:26.908658 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 4 finished
-----------------------------  -------------
replay_buffer/size             2700
trainer/QF1 Loss                  1.61398
trainer/QF2 Loss                  1.33475
trainer/Policy Loss              37.4152
trainer/Q1 Predictions Mean     -39.9192
trainer/Q1 Predictions Std       16.1786
trainer/Q1 Predictions Max      -19.375
trainer/Q1 Predictions Min      -70.5675
trainer/Q2 Predictions Mean     -39.9333
trainer/Q2 Predictions Std       16.2353
trainer/Q2 Predictions Max      -19.6874
trainer/Q2 Predictions Min      -70.8314
trainer/Q Targets Mean          -40.1444
trainer/Q Targets Std            16.4444
trainer/Q Targets Max           -19.6068
trainer/Q Targets Min           -70.1599
trainer/Log Pis Mean             -0.172683
trainer/Log Pis Std               1.43499
trainer/Log Pis Max               2.76901
trainer/Log Pis Min              -3.8165
trainer/Policy mu Mean           -0.143511
trainer/Policy mu Std             0.872177
trainer/Policy mu Max             1.79094
trainer/Policy mu Min            -1.84015
trainer/Policy log std Mean      -0.546034
trainer/Policy log std Std        0.0819238
trainer/Policy log std Max       -0.341068
trainer/Policy log std Min       -0.681334
trainer/Alpha                     0.582894
trainer/Alpha Loss               -1.17216
exploration/num steps total    2700
exploration/num paths total      27
exploration/path length Mean    100
exploration/path length Std       0
exploration/path length Max     100
exploration/path length Min     100
exploration/Rewards Mean         -1.88035
exploration/Rewards Std           1.02372
exploration/Rewards Max          -0.216857
exploration/Rewards Min         -10.3823
exploration/Returns Mean       -188.035
exploration/Returns Std          56.8697
exploration/Returns Max        -132.78
exploration/Returns Min        -261.09
exploration/Actions Mean         -0.0130304
exploration/Actions Std           0.491343
exploration/Actions Max           0.975101
exploration/Actions Min          -0.984251
exploration/Num Paths             5
exploration/Average Returns    -188.035
evaluation/num steps total     7500
evaluation/num paths total       75
evaluation/path length Mean     100
evaluation/path length Std        0
evaluation/path length Max      100
evaluation/path length Min      100
evaluation/Rewards Mean          -3.29559
evaluation/Rewards Std            1.56931
evaluation/Rewards Max           -1.2302
evaluation/Rewards Min          -10.7478
evaluation/Returns Mean        -329.559
evaluation/Returns Std          146.782
evaluation/Returns Max         -124.128
evaluation/Returns Min         -597.095
evaluation/Actions Mean          -0.00243622
evaluation/Actions Std            0.147574
evaluation/Actions Max            0.953291
evaluation/Actions Min           -0.888169
evaluation/Num Paths             15
evaluation/Average Returns     -329.559
time/data storing (s)             0.00273915
time/evaluation sampling (s)      0.363081
time/exploration sampling (s)     0.148433
time/logging (s)                  0.00477978
time/saving (s)                   0.00181971
time/training (s)                 2.07258
time/epoch (s)                    2.59343
time/total (s)                   13.2771
Epoch                             4
-----------------------------  -------------
2019-04-22 23:27:29.473985 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 5 finished
-----------------------------  -------------
replay_buffer/size             3200
trainer/QF1 Loss                  5.77758
trainer/QF2 Loss                  5.7811
trainer/Policy Loss              42.55
trainer/Q1 Predictions Mean     -44.488
trainer/Q1 Predictions Std       15.81
trainer/Q1 Predictions Max      -21.1486
trainer/Q1 Predictions Min      -86.9829
trainer/Q2 Predictions Mean     -44.5114
trainer/Q2 Predictions Std       15.7927
trainer/Q2 Predictions Max      -21.2173
trainer/Q2 Predictions Min      -87.1807
trainer/Q Targets Mean          -44.7701
trainer/Q Targets Std            16.3873
trainer/Q Targets Max            -2.89766
trainer/Q Targets Min           -88.2934
trainer/Log Pis Mean              0.0649534
trainer/Log Pis Std               1.39411
trainer/Log Pis Max               3.02171
trainer/Log Pis Min              -4.79499
trainer/Policy mu Mean           -0.0248111
trainer/Policy mu Std             0.866095
trainer/Policy mu Max             1.72413
trainer/Policy mu Min            -1.97624
trainer/Policy log std Mean      -0.625195
trainer/Policy log std Std        0.106646
trainer/Policy log std Max       -0.379066
trainer/Policy log std Min       -0.830483
trainer/Alpha                     0.511469
trainer/Alpha Loss               -1.2969
exploration/num steps total    3200
exploration/num paths total      32
exploration/path length Mean    100
exploration/path length Std       0
exploration/path length Max     100
exploration/path length Min     100
exploration/Rewards Mean         -3.32103
exploration/Rewards Std           1.36598
exploration/Rewards Max          -1.35826
exploration/Rewards Min         -11.1499
exploration/Returns Mean       -332.103
exploration/Returns Std         105.742
exploration/Returns Max        -245.208
exploration/Returns Min        -540.307
exploration/Actions Mean         -0.00761219
exploration/Actions Std           0.502196
exploration/Actions Max           0.939374
exploration/Actions Min          -0.996098
exploration/Num Paths             5
exploration/Average Returns    -332.103
evaluation/num steps total     9000
evaluation/num paths total       90
evaluation/path length Mean     100
evaluation/path length Std        0
evaluation/path length Max      100
evaluation/path length Min      100
evaluation/Rewards Mean          -2.85241
evaluation/Rewards Std            1.39471
evaluation/Rewards Max           -0.251666
evaluation/Rewards Min          -11.1004
evaluation/Returns Mean        -285.241
evaluation/Returns Std          126.184
evaluation/Returns Max          -92.3734
evaluation/Returns Min         -577.688
evaluation/Actions Mean          -0.0111109
evaluation/Actions Std            0.148182
evaluation/Actions Max            0.953621
evaluation/Actions Min           -0.94634
evaluation/Num Paths             15
evaluation/Average Returns     -285.241
time/data storing (s)             0.00305895
time/evaluation sampling (s)      0.358307
time/exploration sampling (s)     0.148248
time/logging (s)                  0.00605093
time/saving (s)                   0.00196895
time/training (s)                 2.04333
time/epoch (s)                    2.56096
time/total (s)                   15.8429
Epoch                             5
-----------------------------  -------------
2019-04-22 23:27:32.116015 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 6 finished
-----------------------------  ---------------
replay_buffer/size              3700
trainer/QF1 Loss                  55.2679
trainer/QF2 Loss                  55.306
trainer/Policy Loss               46.6511
trainer/Q1 Predictions Mean      -48.482
trainer/Q1 Predictions Std        21.0374
trainer/Q1 Predictions Max       -22.4122
trainer/Q1 Predictions Min      -101.381
trainer/Q2 Predictions Mean      -48.5374
trainer/Q2 Predictions Std        21.0253
trainer/Q2 Predictions Max       -22.4503
trainer/Q2 Predictions Min      -101.428
trainer/Q Targets Mean           -48.0313
trainer/Q Targets Std             21.8661
trainer/Q Targets Max             -4.69276
trainer/Q Targets Min           -102.293
trainer/Log Pis Mean               0.164667
trainer/Log Pis Std                1.57089
trainer/Log Pis Max                4.5998
trainer/Log Pis Min               -3.78087
trainer/Policy mu Mean            -0.079056
trainer/Policy mu Std              0.881726
trainer/Policy mu Max              2.08727
trainer/Policy mu Min             -1.9967
trainer/Policy log std Mean       -0.696321
trainer/Policy log std Std         0.136979
trainer/Policy log std Max        -0.380308
trainer/Policy log std Min        -0.898837
trainer/Alpha                      0.447966
trainer/Alpha Loss                -1.47336
exploration/num steps total     3700
exploration/num paths total       37
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -3.29301
exploration/Rewards Std            1.97762
exploration/Rewards Max           -0.171209
exploration/Rewards Min           -8.78518
exploration/Returns Mean        -329.301
exploration/Returns Std          173.571
exploration/Returns Max         -126.389
exploration/Returns Min         -541.088
exploration/Actions Mean           0.000335605
exploration/Actions Std            0.468071
exploration/Actions Max            0.99513
exploration/Actions Min           -0.980624
exploration/Num Paths              5
exploration/Average Returns     -329.301
evaluation/num steps total     10500
evaluation/num paths total       105
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -3.65013
evaluation/Rewards Std             1.9066
evaluation/Rewards Max            -0.625321
evaluation/Rewards Min           -10.995
evaluation/Returns Mean         -365.013
evaluation/Returns Std           180.033
evaluation/Returns Max           -71.4248
evaluation/Returns Min          -587.096
evaluation/Actions Mean           -0.00314103
evaluation/Actions Std             0.163892
evaluation/Actions Max             0.967438
evaluation/Actions Min            -0.907005
evaluation/Num Paths              15
evaluation/Average Returns      -365.013
time/data storing (s)              0.00400575
time/evaluation sampling (s)       0.354636
time/exploration sampling (s)      0.163482
time/logging (s)                   0.00503347
time/saving (s)                    0.00195838
time/training (s)                  2.10663
time/epoch (s)                     2.63574
time/total (s)                    18.4831
Epoch                              6
-----------------------------  ---------------
2019-04-22 23:27:34.718222 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 7 finished
-----------------------------  ---------------
replay_buffer/size              4200
trainer/QF1 Loss                  50.4554
trainer/QF2 Loss                  50.7895
trainer/Policy Loss               52.5968
trainer/Q1 Predictions Mean      -54.4756
trainer/Q1 Predictions Std        21.9495
trainer/Q1 Predictions Max       -24.1934
trainer/Q1 Predictions Min       -94.0498
trainer/Q2 Predictions Mean      -54.513
trainer/Q2 Predictions Std        21.9743
trainer/Q2 Predictions Max       -24.2356
trainer/Q2 Predictions Min       -94.6494
trainer/Q Targets Mean           -53.9075
trainer/Q Targets Std             22.766
trainer/Q Targets Max             -6.5496
trainer/Q Targets Min            -94.4978
trainer/Log Pis Mean              -0.0594362
trainer/Log Pis Std                1.45611
trainer/Log Pis Max                4.65448
trainer/Log Pis Min               -4.5178
trainer/Policy mu Mean            -0.00598862
trainer/Policy mu Std              0.850039
trainer/Policy mu Max              2.02066
trainer/Policy mu Min             -2.09643
trainer/Policy log std Mean       -0.71418
trainer/Policy log std Std         0.172516
trainer/Policy log std Max        -0.390542
trainer/Policy log std Min        -0.950192
trainer/Alpha                      0.391524
trainer/Alpha Loss                -1.93061
exploration/num steps total     4200
exploration/num paths total       42
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -4.04723
exploration/Rewards Std            2.2433
exploration/Rewards Max           -0.0778609
exploration/Rewards Min           -7.48177
exploration/Returns Mean        -404.723
exploration/Returns Std          210.907
exploration/Returns Max          -69.6011
exploration/Returns Min         -578.52
exploration/Actions Mean           0.000950128
exploration/Actions Std            0.506612
exploration/Actions Max            0.976577
exploration/Actions Min           -0.970714
exploration/Num Paths              5
exploration/Average Returns     -404.723
evaluation/num steps total     12000
evaluation/num paths total       120
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -3.78698
evaluation/Rewards Std             1.68049
evaluation/Rewards Max            -0.212367
evaluation/Rewards Min            -8.78987
evaluation/Returns Mean         -378.698
evaluation/Returns Std           160.169
evaluation/Returns Max          -218.048
evaluation/Returns Min          -604.649
evaluation/Actions Mean            0.0003994
evaluation/Actions Std             0.153147
evaluation/Actions Max             0.940865
evaluation/Actions Min            -0.945226
evaluation/Num Paths              15
evaluation/Average Returns      -378.698
time/data storing (s)              0.0033107
time/evaluation sampling (s)       0.366896
time/exploration sampling (s)      0.158954
time/logging (s)                   0.00480984
time/saving (s)                    0.00195845
time/training (s)                  2.06072
time/epoch (s)                     2.59665
time/total (s)                    21.0842
Epoch                              7
-----------------------------  ---------------
2019-04-22 23:27:37.163971 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 8 finished
-----------------------------  --------------
replay_buffer/size              4700
trainer/QF1 Loss                   1.75032
trainer/QF2 Loss                   1.65026
trainer/Policy Loss               56.0488
trainer/Q1 Predictions Mean      -57.8043
trainer/Q1 Predictions Std        24.0983
trainer/Q1 Predictions Max       -23.9489
trainer/Q1 Predictions Min      -101.026
trainer/Q2 Predictions Mean      -57.7962
trainer/Q2 Predictions Std        24.0501
trainer/Q2 Predictions Max       -23.9873
trainer/Q2 Predictions Min      -100.775
trainer/Q Targets Mean           -58.4019
trainer/Q Targets Std             24.3482
trainer/Q Targets Max            -23.9353
trainer/Q Targets Min           -100.317
trainer/Log Pis Mean               0.039862
trainer/Log Pis Std                1.59438
trainer/Log Pis Max                5.20276
trainer/Log Pis Min               -2.97266
trainer/Policy mu Mean            -0.16466
trainer/Policy mu Std              0.831914
trainer/Policy mu Max              2.17584
trainer/Policy mu Min             -2.02249
trainer/Policy log std Mean       -0.770784
trainer/Policy log std Std         0.209086
trainer/Policy log std Max        -0.36898
trainer/Policy log std Min        -1.09849
trainer/Alpha                      0.341677
trainer/Alpha Loss                -2.10444
exploration/num steps total     4700
exploration/num paths total       47
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.85579
exploration/Rewards Std            2.17218
exploration/Rewards Max           -0.0531831
exploration/Rewards Min           -9.52652
exploration/Returns Mean        -285.579
exploration/Returns Std          190.963
exploration/Returns Max          -79.6536
exploration/Returns Min         -512.942
exploration/Actions Mean          -0.0409343
exploration/Actions Std            0.471867
exploration/Actions Max            0.966067
exploration/Actions Min           -0.987698
exploration/Num Paths              5
exploration/Average Returns     -285.579
evaluation/num steps total     13500
evaluation/num paths total       135
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.61374
evaluation/Rewards Std             2.07235
evaluation/Rewards Max            -0.39418
evaluation/Rewards Min           -10.1587
evaluation/Returns Mean         -261.374
evaluation/Returns Std           198.095
evaluation/Returns Max           -49.8067
evaluation/Returns Min          -603.885
evaluation/Actions Mean           -0.00473068
evaluation/Actions Std             0.162756
evaluation/Actions Max             0.948431
evaluation/Actions Min            -0.962386
evaluation/Num Paths              15
evaluation/Average Returns      -261.374
time/data storing (s)              0.0030447
time/evaluation sampling (s)       0.329322
time/exploration sampling (s)      0.143086
time/logging (s)                   0.00477
time/saving (s)                    0.00158385
time/training (s)                  1.95902
time/epoch (s)                     2.44083
time/total (s)                    23.5292
Epoch                              8
-----------------------------  --------------
2019-04-22 23:27:39.893696 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 9 finished
-----------------------------  ---------------
replay_buffer/size              5200
trainer/QF1 Loss                  14.163
trainer/QF2 Loss                  14.5671
trainer/Policy Loss               59.0472
trainer/Q1 Predictions Mean      -60.2154
trainer/Q1 Predictions Std        26.1727
trainer/Q1 Predictions Max       -23.8089
trainer/Q1 Predictions Min      -110.592
trainer/Q2 Predictions Mean      -60.2256
trainer/Q2 Predictions Std        26.096
trainer/Q2 Predictions Max       -23.77
trainer/Q2 Predictions Min      -110.186
trainer/Q Targets Mean           -60.8338
trainer/Q Targets Std             26.9714
trainer/Q Targets Max             -4.43804
trainer/Q Targets Min           -112.199
trainer/Log Pis Mean               0.204377
trainer/Log Pis Std                1.433
trainer/Log Pis Max                4.93897
trainer/Log Pis Min               -3.52418
trainer/Policy mu Mean            -0.0583119
trainer/Policy mu Std              0.795466
trainer/Policy mu Max              2.30625
trainer/Policy mu Min             -2.1098
trainer/Policy log std Mean       -0.876401
trainer/Policy log std Std         0.253194
trainer/Policy log std Max        -0.374669
trainer/Policy log std Min        -1.27753
trainer/Alpha                      0.298613
trainer/Alpha Loss                -2.16974
exploration/num steps total     5200
exploration/num paths total       52
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.37383
exploration/Rewards Std            0.787608
exploration/Rewards Max           -0.801008
exploration/Rewards Min           -9.38143
exploration/Returns Mean        -237.383
exploration/Returns Std           34.2728
exploration/Returns Max         -201.38
exploration/Returns Min         -299.283
exploration/Actions Mean           0.00257773
exploration/Actions Std            0.40719
exploration/Actions Max            0.979884
exploration/Actions Min           -0.887639
exploration/Num Paths              5
exploration/Average Returns     -237.383
evaluation/num steps total     15000
evaluation/num paths total       150
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -3.32152
evaluation/Rewards Std             1.32989
evaluation/Rewards Max            -0.235188
evaluation/Rewards Min           -10.2426
evaluation/Returns Mean         -332.152
evaluation/Returns Std           123.462
evaluation/Returns Max          -205.795
evaluation/Returns Min          -572.228
evaluation/Actions Mean            0.000995094
evaluation/Actions Std             0.140644
evaluation/Actions Max             0.963512
evaluation/Actions Min            -0.951063
evaluation/Num Paths              15
evaluation/Average Returns      -332.152
time/data storing (s)              0.00302755
time/evaluation sampling (s)       0.333012
time/exploration sampling (s)      0.144264
time/logging (s)                   0.00480865
time/saving (s)                    0.00162011
time/training (s)                  2.23799
time/epoch (s)                     2.72473
time/total (s)                    26.2581
Epoch                              9
-----------------------------  ---------------
2019-04-22 23:27:42.573750 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 10 finished
-----------------------------  --------------
replay_buffer/size              5700
trainer/QF1 Loss                   1.2097
trainer/QF2 Loss                   1.12642
trainer/Policy Loss               55.1439
trainer/Q1 Predictions Mean      -55.9087
trainer/Q1 Predictions Std        26.07
trainer/Q1 Predictions Max       -24.6414
trainer/Q1 Predictions Min      -103.859
trainer/Q2 Predictions Mean      -55.9502
trainer/Q2 Predictions Std        26.1368
trainer/Q2 Predictions Max       -24.647
trainer/Q2 Predictions Min      -104.188
trainer/Q Targets Mean           -55.9759
trainer/Q Targets Std             26.1879
trainer/Q Targets Max            -24.2168
trainer/Q Targets Min           -104.833
trainer/Log Pis Mean               0.302698
trainer/Log Pis Std                1.3624
trainer/Log Pis Max                4.96611
trainer/Log Pis Min               -3.59988
trainer/Policy mu Mean             0.110507
trainer/Policy mu Std              0.751106
trainer/Policy mu Max              2.35477
trainer/Policy mu Min             -2.41344
trainer/Policy log std Mean       -0.988415
trainer/Policy log std Std         0.221673
trainer/Policy log std Max        -0.537833
trainer/Policy log std Min        -1.29832
trainer/Alpha                      0.261248
trainer/Alpha Loss                -2.27782
exploration/num steps total     5700
exploration/num paths total       57
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.45283
exploration/Rewards Std            1.12016
exploration/Rewards Max           -0.0381537
exploration/Rewards Min           -6.45705
exploration/Returns Mean        -145.283
exploration/Returns Std           91.6967
exploration/Returns Max          -59.899
exploration/Returns Min         -283.254
exploration/Actions Mean          -0.00227841
exploration/Actions Std            0.367309
exploration/Actions Max            0.966675
exploration/Actions Min           -0.982006
exploration/Num Paths              5
exploration/Average Returns     -145.283
evaluation/num steps total     16500
evaluation/num paths total       165
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.35489
evaluation/Rewards Std             1.15124
evaluation/Rewards Max            -0.401401
evaluation/Rewards Min           -11.1649
evaluation/Returns Mean         -235.489
evaluation/Returns Std            90.1006
evaluation/Returns Max           -78.0467
evaluation/Returns Min          -399.739
evaluation/Actions Mean           -0.0107627
evaluation/Actions Std             0.15826
evaluation/Actions Max             0.983794
evaluation/Actions Min            -0.965988
evaluation/Num Paths              15
evaluation/Average Returns      -235.489
time/data storing (s)              0.00299334
time/evaluation sampling (s)       0.355521
time/exploration sampling (s)      0.157968
time/logging (s)                   0.00504263
time/saving (s)                    0.0020186
time/training (s)                  2.15162
time/epoch (s)                     2.67517
time/total (s)                    28.9375
Epoch                             10
-----------------------------  --------------
2019-04-22 23:27:45.707134 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 11 finished
-----------------------------  --------------
replay_buffer/size              6200
trainer/QF1 Loss                   1.92532
trainer/QF2 Loss                   1.72631
trainer/Policy Loss               57.8086
trainer/Q1 Predictions Mean      -58.354
trainer/Q1 Predictions Std        25.9478
trainer/Q1 Predictions Max       -24.2082
trainer/Q1 Predictions Min      -110.324
trainer/Q2 Predictions Mean      -58.4023
trainer/Q2 Predictions Std        25.9944
trainer/Q2 Predictions Max       -24.2765
trainer/Q2 Predictions Min      -110.545
trainer/Q Targets Mean           -59.4171
trainer/Q Targets Std             26.4847
trainer/Q Targets Max            -24.2667
trainer/Q Targets Min           -112.611
trainer/Log Pis Mean               0.345943
trainer/Log Pis Std                1.08051
trainer/Log Pis Max                4.27533
trainer/Log Pis Min               -3.65395
trainer/Policy mu Mean             0.0145232
trainer/Policy mu Std              0.730992
trainer/Policy mu Max              2.37855
trainer/Policy mu Min             -2.10529
trainer/Policy log std Mean       -1.06181
trainer/Policy log std Std         0.239146
trainer/Policy log std Max        -0.459008
trainer/Policy log std Min        -1.40749
trainer/Alpha                      0.22872
trainer/Alpha Loss                -2.43972
exploration/num steps total     6200
exploration/num paths total       62
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.12187
exploration/Rewards Std            1.10329
exploration/Rewards Max           -0.0538208
exploration/Rewards Min          -10.6841
exploration/Returns Mean        -212.187
exploration/Returns Std           78.7555
exploration/Returns Max          -64.5087
exploration/Returns Min         -292.71
exploration/Actions Mean          -0.0173393
exploration/Actions Std            0.340075
exploration/Actions Max            0.981762
exploration/Actions Min           -0.979225
exploration/Num Paths              5
exploration/Average Returns     -212.187
evaluation/num steps total     18000
evaluation/num paths total       180
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.98953
evaluation/Rewards Std             1.6905
evaluation/Rewards Max            -0.383347
evaluation/Rewards Min            -9.89688
evaluation/Returns Mean         -298.953
evaluation/Returns Std           150.833
evaluation/Returns Max           -41.6009
evaluation/Returns Min          -568.848
evaluation/Actions Mean           -0.0157172
evaluation/Actions Std             0.15769
evaluation/Actions Max             0.976786
evaluation/Actions Min            -0.984308
evaluation/Num Paths              15
evaluation/Average Returns      -298.953
time/data storing (s)              0.00304501
time/evaluation sampling (s)       0.346883
time/exploration sampling (s)      0.154119
time/logging (s)                   0.00633543
time/saving (s)                    0.00273473
time/training (s)                  2.61606
time/epoch (s)                     3.12918
time/total (s)                    32.0714
Epoch                             11
-----------------------------  --------------
2019-04-22 23:27:49.394499 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 12 finished
-----------------------------  --------------
replay_buffer/size              6700
trainer/QF1 Loss                   6.86646
trainer/QF2 Loss                   6.8927
trainer/Policy Loss               65.5374
trainer/Q1 Predictions Mean      -66.5354
trainer/Q1 Predictions Std        29.6469
trainer/Q1 Predictions Max       -24.7098
trainer/Q1 Predictions Min      -135.697
trainer/Q2 Predictions Mean      -66.5678
trainer/Q2 Predictions Std        29.6838
trainer/Q2 Predictions Max       -24.8073
trainer/Q2 Predictions Min      -135.309
trainer/Q Targets Mean           -66.5248
trainer/Q Targets Std             30.2416
trainer/Q Targets Max             -2.02754
trainer/Q Targets Min           -135.548
trainer/Log Pis Mean               0.588019
trainer/Log Pis Std                1.75771
trainer/Log Pis Max                5.6281
trainer/Log Pis Min               -4.17912
trainer/Policy mu Mean             0.124734
trainer/Policy mu Std              0.920218
trainer/Policy mu Max              2.55286
trainer/Policy mu Min             -2.48116
trainer/Policy log std Mean       -1.12521
trainer/Policy log std Std         0.286666
trainer/Policy log std Max        -0.475002
trainer/Policy log std Min        -1.61903
trainer/Alpha                      0.200927
trainer/Alpha Loss                -2.26561
exploration/num steps total     6700
exploration/num paths total       67
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.96402
exploration/Rewards Std            1.22762
exploration/Rewards Max           -0.0149481
exploration/Rewards Min           -5.83946
exploration/Returns Mean        -196.402
exploration/Returns Std          114.868
exploration/Returns Max          -48.6979
exploration/Returns Min         -304.915
exploration/Actions Mean          -0.00335959
exploration/Actions Std            0.319346
exploration/Actions Max            0.872381
exploration/Actions Min           -0.981039
exploration/Num Paths              5
exploration/Average Returns     -196.402
evaluation/num steps total     19500
evaluation/num paths total       195
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.82736
evaluation/Rewards Std             2.04222
evaluation/Rewards Max            -0.288545
evaluation/Rewards Min            -9.88605
evaluation/Returns Mean         -282.736
evaluation/Returns Std           190.187
evaluation/Returns Max           -36.6569
evaluation/Returns Min          -584.078
evaluation/Actions Mean            0.00933494
evaluation/Actions Std             0.171405
evaluation/Actions Max             0.985078
evaluation/Actions Min            -0.951118
evaluation/Num Paths              15
evaluation/Average Returns      -282.736
time/data storing (s)              0.00385297
time/evaluation sampling (s)       0.404078
time/exploration sampling (s)      0.172485
time/logging (s)                   0.00541185
time/saving (s)                    0.00219405
time/training (s)                  3.09172
time/epoch (s)                     3.67975
time/total (s)                    35.7566
Epoch                             12
-----------------------------  --------------
2019-04-22 23:27:52.386459 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 13 finished
-----------------------------  --------------
replay_buffer/size              7200
trainer/QF1 Loss                  51.3263
trainer/QF2 Loss                  51.1769
trainer/Policy Loss               62.1052
trainer/Q1 Predictions Mean      -62.7706
trainer/Q1 Predictions Std        31.2255
trainer/Q1 Predictions Max       -24.6614
trainer/Q1 Predictions Min      -126.617
trainer/Q2 Predictions Mean      -62.7937
trainer/Q2 Predictions Std        31.3042
trainer/Q2 Predictions Max       -24.7548
trainer/Q2 Predictions Min      -127.534
trainer/Q Targets Mean           -62.5006
trainer/Q Targets Std             32.2808
trainer/Q Targets Max             -2.28325
trainer/Q Targets Min           -129.06
trainer/Log Pis Mean               0.656258
trainer/Log Pis Std                1.25111
trainer/Log Pis Max                3.82537
trainer/Log Pis Min               -3.5227
trainer/Policy mu Mean             0.00794053
trainer/Policy mu Std              0.785209
trainer/Policy mu Max              2.57515
trainer/Policy mu Min             -2.43454
trainer/Policy log std Mean       -1.21576
trainer/Policy log std Std         0.292268
trainer/Policy log std Max        -0.560115
trainer/Policy log std Min        -1.71919
trainer/Alpha                      0.177048
trainer/Alpha Loss                -2.32613
exploration/num steps total     7200
exploration/num paths total       72
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.69795
exploration/Rewards Std            1.96322
exploration/Rewards Max           -0.11475
exploration/Rewards Min           -9.74403
exploration/Returns Mean        -269.795
exploration/Returns Std          180.712
exploration/Returns Max          -71.8632
exploration/Returns Min         -602.433
exploration/Actions Mean           0.0239662
exploration/Actions Std            0.324003
exploration/Actions Max            0.998612
exploration/Actions Min           -0.854959
exploration/Num Paths              5
exploration/Average Returns     -269.795
evaluation/num steps total     21000
evaluation/num paths total       210
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -3.35902
evaluation/Rewards Std             2.06142
evaluation/Rewards Max            -0.460111
evaluation/Rewards Min           -10.2085
evaluation/Returns Mean         -335.902
evaluation/Returns Std           195.259
evaluation/Returns Max           -54.1527
evaluation/Returns Min          -604.175
evaluation/Actions Mean            0.015871
evaluation/Actions Std             0.164613
evaluation/Actions Max             0.984772
evaluation/Actions Min            -0.980218
evaluation/Num Paths              15
evaluation/Average Returns      -335.902
time/data storing (s)              0.00394057
time/evaluation sampling (s)       0.467253
time/exploration sampling (s)      0.196837
time/logging (s)                   0.00481074
time/saving (s)                    0.00217916
time/training (s)                  2.3105
time/epoch (s)                     2.98552
time/total (s)                    38.747
Epoch                             13
-----------------------------  --------------
2019-04-22 23:27:55.029399 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 14 finished
-----------------------------  --------------
replay_buffer/size              7700
trainer/QF1 Loss                 143.654
trainer/QF2 Loss                 144.307
trainer/Policy Loss               71.6359
trainer/Q1 Predictions Mean      -72.2715
trainer/Q1 Predictions Std        32.9722
trainer/Q1 Predictions Max       -24.8049
trainer/Q1 Predictions Min      -129.591
trainer/Q2 Predictions Mean      -72.3109
trainer/Q2 Predictions Std        32.9919
trainer/Q2 Predictions Max       -24.8877
trainer/Q2 Predictions Min      -129.744
trainer/Q Targets Mean           -71.1679
trainer/Q Targets Std             33.3598
trainer/Q Targets Max             -6.5496
trainer/Q Targets Min           -131.031
trainer/Log Pis Mean               0.603038
trainer/Log Pis Std                1.44902
trainer/Log Pis Max                4.75275
trainer/Log Pis Min               -4.6401
trainer/Policy mu Mean            -0.0903022
trainer/Policy mu Std              0.806165
trainer/Policy mu Max              2.47357
trainer/Policy mu Min             -2.29142
trainer/Policy log std Mean       -1.22156
trainer/Policy log std Std         0.341154
trainer/Policy log std Max        -0.485529
trainer/Policy log std Min        -1.79349
trainer/Alpha                      0.155675
trainer/Alpha Loss                -2.59796
exploration/num steps total     7700
exploration/num paths total       77
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.31894
exploration/Rewards Std            1.35502
exploration/Rewards Max           -0.0386725
exploration/Rewards Min          -10.4999
exploration/Returns Mean        -231.894
exploration/Returns Std          109.893
exploration/Returns Max          -46.3879
exploration/Returns Min         -336.033
exploration/Actions Mean          -0.0250214
exploration/Actions Std            0.350476
exploration/Actions Max            0.945561
exploration/Actions Min           -0.987055
exploration/Num Paths              5
exploration/Average Returns     -231.894
evaluation/num steps total     22500
evaluation/num paths total       225
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.24604
evaluation/Rewards Std             1.21783
evaluation/Rewards Max            -0.115562
evaluation/Rewards Min            -9.69978
evaluation/Returns Mean         -224.604
evaluation/Returns Std           102.896
evaluation/Returns Max           -17.5441
evaluation/Returns Min          -310.643
evaluation/Actions Mean           -0.0022176
evaluation/Actions Std             0.165502
evaluation/Actions Max             0.981473
evaluation/Actions Min            -0.978337
evaluation/Num Paths              15
evaluation/Average Returns      -224.604
time/data storing (s)              0.00305448
time/evaluation sampling (s)       0.365468
time/exploration sampling (s)      0.159613
time/logging (s)                   0.00511905
time/saving (s)                    0.00206782
time/training (s)                  2.101
time/epoch (s)                     2.63632
time/total (s)                    41.3891
Epoch                             14
-----------------------------  --------------
2019-04-22 23:27:57.948818 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 15 finished
-----------------------------  --------------
replay_buffer/size              8200
trainer/QF1 Loss                 169.039
trainer/QF2 Loss                 167.75
trainer/Policy Loss               78.7734
trainer/Q1 Predictions Mean      -79.2954
trainer/Q1 Predictions Std        38.5888
trainer/Q1 Predictions Max       -23.6492
trainer/Q1 Predictions Min      -135.864
trainer/Q2 Predictions Mean      -79.3174
trainer/Q2 Predictions Std        38.6173
trainer/Q2 Predictions Max       -23.8958
trainer/Q2 Predictions Min      -137.186
trainer/Q Targets Mean           -78.7346
trainer/Q Targets Std             39.788
trainer/Q Targets Max             -0.551624
trainer/Q Targets Min           -140.241
trainer/Log Pis Mean               0.848004
trainer/Log Pis Std                1.5402
trainer/Log Pis Max                5.39756
trainer/Log Pis Min               -4.43933
trainer/Policy mu Mean            -0.0962662
trainer/Policy mu Std              0.847695
trainer/Policy mu Max              2.35272
trainer/Policy mu Min             -2.66772
trainer/Policy log std Mean       -1.26717
trainer/Policy log std Std         0.332678
trainer/Policy log std Max        -0.603079
trainer/Policy log std Min        -1.87727
trainer/Alpha                      0.136929
trainer/Alpha Loss                -2.29022
exploration/num steps total     8200
exploration/num paths total       82
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -3.68853
exploration/Rewards Std            1.73375
exploration/Rewards Max           -1.13975
exploration/Rewards Min          -11.0493
exploration/Returns Mean        -368.853
exploration/Returns Std          143.195
exploration/Returns Max         -201.945
exploration/Returns Min         -550.496
exploration/Actions Mean           0.0078353
exploration/Actions Std            0.359053
exploration/Actions Max            0.987746
exploration/Actions Min           -0.979361
exploration/Num Paths              5
exploration/Average Returns     -368.853
evaluation/num steps total     24000
evaluation/num paths total       240
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.341
evaluation/Rewards Std             1.63337
evaluation/Rewards Max            -0.258013
evaluation/Rewards Min           -10.4971
evaluation/Returns Mean         -234.1
evaluation/Returns Std           142.22
evaluation/Returns Max           -43.5414
evaluation/Returns Min          -544.521
evaluation/Actions Mean           -0.00712888
evaluation/Actions Std             0.171345
evaluation/Actions Max             0.977602
evaluation/Actions Min            -0.99026
evaluation/Num Paths              15
evaluation/Average Returns      -234.1
time/data storing (s)              0.00407823
time/evaluation sampling (s)       0.351066
time/exploration sampling (s)      0.202276
time/logging (s)                   0.00485033
time/saving (s)                    0.00195194
time/training (s)                  2.3496
time/epoch (s)                     2.91382
time/total (s)                    44.3072
Epoch                             15
-----------------------------  --------------
2019-04-22 23:28:00.602448 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 16 finished
-----------------------------  --------------
replay_buffer/size              8700
trainer/QF1 Loss                  46.2793
trainer/QF2 Loss                  46.5899
trainer/Policy Loss               79.0303
trainer/Q1 Predictions Mean      -79.6496
trainer/Q1 Predictions Std        37.107
trainer/Q1 Predictions Max       -24.4494
trainer/Q1 Predictions Min      -143.37
trainer/Q2 Predictions Mean      -79.6278
trainer/Q2 Predictions Std        37.0911
trainer/Q2 Predictions Max       -24.6676
trainer/Q2 Predictions Min      -142.791
trainer/Q Targets Mean           -80.241
trainer/Q Targets Std             38.739
trainer/Q Targets Max             -5.14013
trainer/Q Targets Min           -144.777
trainer/Log Pis Mean               1.07201
trainer/Log Pis Std                1.52904
trainer/Log Pis Max                5.32811
trainer/Log Pis Min               -3.25626
trainer/Policy mu Mean             0.0821584
trainer/Policy mu Std              0.84698
trainer/Policy mu Max              2.65879
trainer/Policy mu Min             -2.79613
trainer/Policy log std Mean       -1.34465
trainer/Policy log std Std         0.400616
trainer/Policy log std Max        -0.409297
trainer/Policy log std Min        -2.06998
trainer/Alpha                      0.120687
trainer/Alpha Loss                -1.96206
exploration/num steps total     8700
exploration/num paths total       87
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.8561
exploration/Rewards Std            1.11596
exploration/Rewards Max           -0.477915
exploration/Rewards Min           -9.68489
exploration/Returns Mean        -185.61
exploration/Returns Std           70.2253
exploration/Returns Max         -121.927
exploration/Returns Min         -313.423
exploration/Actions Mean           0.0022905
exploration/Actions Std            0.304395
exploration/Actions Max            0.992838
exploration/Actions Min           -0.991356
exploration/Num Paths              5
exploration/Average Returns     -185.61
evaluation/num steps total     25500
evaluation/num paths total       255
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.41333
evaluation/Rewards Std             1.53881
evaluation/Rewards Max            -0.390419
evaluation/Rewards Min           -10.8713
evaluation/Returns Mean         -241.333
evaluation/Returns Std           131.231
evaluation/Returns Max           -49.7453
evaluation/Returns Min          -524.873
evaluation/Actions Mean            0.012984
evaluation/Actions Std             0.179305
evaluation/Actions Max             0.992794
evaluation/Actions Min            -0.984023
evaluation/Num Paths              15
evaluation/Average Returns      -241.333
time/data storing (s)              0.00292645
time/evaluation sampling (s)       0.357397
time/exploration sampling (s)      0.156208
time/logging (s)                   0.00571135
time/saving (s)                    0.00241576
time/training (s)                  2.12458
time/epoch (s)                     2.64924
time/total (s)                    46.9609
Epoch                             16
-----------------------------  --------------
2019-04-22 23:28:03.271986 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 17 finished
-----------------------------  --------------
replay_buffer/size              9200
trainer/QF1 Loss                  82.2749
trainer/QF2 Loss                  82.3105
trainer/Policy Loss               73.4775
trainer/Q1 Predictions Mean      -73.2321
trainer/Q1 Predictions Std        34.0088
trainer/Q1 Predictions Max       -23.7628
trainer/Q1 Predictions Min      -144.404
trainer/Q2 Predictions Mean      -73.2473
trainer/Q2 Predictions Std        33.9456
trainer/Q2 Predictions Max       -23.8038
trainer/Q2 Predictions Min      -144.736
trainer/Q Targets Mean           -72.5037
trainer/Q Targets Std             35.5347
trainer/Q Targets Max             -2.51215
trainer/Q Targets Min           -146.906
trainer/Log Pis Mean               1.08113
trainer/Log Pis Std                1.21989
trainer/Log Pis Max                5.63114
trainer/Log Pis Min               -2.66354
trainer/Policy mu Mean            -0.00363209
trainer/Policy mu Std              0.803693
trainer/Policy mu Max              2.86746
trainer/Policy mu Min             -2.68924
trainer/Policy log std Mean       -1.48503
trainer/Policy log std Std         0.357253
trainer/Policy log std Max        -0.521914
trainer/Policy log std Min        -2.12725
trainer/Alpha                      0.107221
trainer/Alpha Loss                -2.05151
exploration/num steps total     9200
exploration/num paths total       92
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.33224
exploration/Rewards Std            1.3545
exploration/Rewards Max           -0.0158968
exploration/Rewards Min          -10.6108
exploration/Returns Mean        -133.224
exploration/Returns Std           40.3688
exploration/Returns Max          -72.2812
exploration/Returns Min         -184.338
exploration/Actions Mean           0.0210861
exploration/Actions Std            0.296099
exploration/Actions Max            0.994601
exploration/Actions Min           -0.999059
exploration/Num Paths              5
exploration/Average Returns     -133.224
evaluation/num steps total     27000
evaluation/num paths total       270
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.80246
evaluation/Rewards Std             1.30968
evaluation/Rewards Max            -0.167247
evaluation/Rewards Min           -10.6072
evaluation/Returns Mean         -180.246
evaluation/Returns Std           106.832
evaluation/Returns Max           -29.4137
evaluation/Returns Min          -367.83
evaluation/Actions Mean            0.00140633
evaluation/Actions Std             0.161237
evaluation/Actions Max             0.991728
evaluation/Actions Min            -0.987169
evaluation/Num Paths              15
evaluation/Average Returns      -180.246
time/data storing (s)              0.0029328
time/evaluation sampling (s)       0.360161
time/exploration sampling (s)      0.150793
time/logging (s)                   0.00480861
time/saving (s)                    0.00192853
time/training (s)                  2.14138
time/epoch (s)                     2.662
time/total (s)                    49.6282
Epoch                             17
-----------------------------  --------------
2019-04-22 23:28:05.902748 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 18 finished
-----------------------------  --------------
replay_buffer/size              9700
trainer/QF1 Loss                   0.779726
trainer/QF2 Loss                   0.73368
trainer/Policy Loss               70.3722
trainer/Q1 Predictions Mean      -70.1477
trainer/Q1 Predictions Std        34.8503
trainer/Q1 Predictions Max       -24.3752
trainer/Q1 Predictions Min      -149.584
trainer/Q2 Predictions Mean      -70.0986
trainer/Q2 Predictions Std        34.8589
trainer/Q2 Predictions Max       -24.3747
trainer/Q2 Predictions Min      -149.481
trainer/Q Targets Mean           -70.0597
trainer/Q Targets Std             35.1319
trainer/Q Targets Max            -23.8592
trainer/Q Targets Min           -149.836
trainer/Log Pis Mean               1.0441
trainer/Log Pis Std                1.32561
trainer/Log Pis Max                5.53263
trainer/Log Pis Min               -3.87673
trainer/Policy mu Mean             0.0628457
trainer/Policy mu Std              0.636209
trainer/Policy mu Max              2.26723
trainer/Policy mu Min             -2.49976
trainer/Policy log std Mean       -1.6052
trainer/Policy log std Std         0.373613
trainer/Policy log std Max        -0.426786
trainer/Policy log std Min        -2.1867
trainer/Alpha                      0.0967023
trainer/Alpha Loss                -2.23288
exploration/num steps total     9700
exploration/num paths total       97
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.22791
exploration/Rewards Std            0.846949
exploration/Rewards Max           -0.0881739
exploration/Rewards Min           -7.91284
exploration/Returns Mean        -122.791
exploration/Returns Std           35.2298
exploration/Returns Max          -72.6524
exploration/Returns Min         -159.686
exploration/Actions Mean          -0.0160201
exploration/Actions Std            0.274547
exploration/Actions Max            0.978512
exploration/Actions Min           -0.998092
exploration/Num Paths              5
exploration/Average Returns     -122.791
evaluation/num steps total     28500
evaluation/num paths total       285
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.4587
evaluation/Rewards Std             1.22665
evaluation/Rewards Max            -0.052007
evaluation/Rewards Min           -10.6401
evaluation/Returns Mean         -145.87
evaluation/Returns Std            86.5708
evaluation/Returns Max           -36.3742
evaluation/Returns Min          -289.545
evaluation/Actions Mean           -0.00743949
evaluation/Actions Std             0.172848
evaluation/Actions Max             0.992066
evaluation/Actions Min            -0.99202
evaluation/Num Paths              15
evaluation/Average Returns      -145.87
time/data storing (s)              0.00417065
time/evaluation sampling (s)       0.336818
time/exploration sampling (s)      0.222735
time/logging (s)                   0.00516049
time/saving (s)                    0.00228802
time/training (s)                  2.05461
time/epoch (s)                     2.62579
time/total (s)                    52.2583
Epoch                             18
-----------------------------  --------------
2019-04-22 23:28:08.352523 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 19 finished
-----------------------------  --------------
replay_buffer/size             10200
trainer/QF1 Loss                 112.124
trainer/QF2 Loss                 113.608
trainer/Policy Loss               82.2139
trainer/Q1 Predictions Mean      -81.9226
trainer/Q1 Predictions Std        41.7134
trainer/Q1 Predictions Max       -23.6198
trainer/Q1 Predictions Min      -165.807
trainer/Q2 Predictions Mean      -81.957
trainer/Q2 Predictions Std        41.7464
trainer/Q2 Predictions Max       -23.5514
trainer/Q2 Predictions Min      -165.928
trainer/Q Targets Mean           -81.6277
trainer/Q Targets Std             42.8709
trainer/Q Targets Max            -10.531
trainer/Q Targets Min           -169.776
trainer/Log Pis Mean               1.5652
trainer/Log Pis Std                1.24881
trainer/Log Pis Max                6.07013
trainer/Log Pis Min               -1.38231
trainer/Policy mu Mean            -0.0247102
trainer/Policy mu Std              0.918211
trainer/Policy mu Max              2.57444
trainer/Policy mu Min             -2.84597
trainer/Policy log std Mean       -1.539
trainer/Policy log std Std         0.499697
trainer/Policy log std Max        -0.287661
trainer/Policy log std Min        -2.34964
trainer/Alpha                      0.0883489
trainer/Alpha Loss                -1.05495
exploration/num steps total    10200
exploration/num paths total      102
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.02639
exploration/Rewards Std            0.942102
exploration/Rewards Max           -0.0570407
exploration/Rewards Min           -5.98719
exploration/Returns Mean        -202.639
exploration/Returns Std           84.6863
exploration/Returns Max          -42.4467
exploration/Returns Min         -295.385
exploration/Actions Mean           0.0046216
exploration/Actions Std            0.268675
exploration/Actions Max            0.966405
exploration/Actions Min           -0.984792
exploration/Num Paths              5
exploration/Average Returns     -202.639
evaluation/num steps total     30000
evaluation/num paths total       300
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.6984
evaluation/Rewards Std             1.14855
evaluation/Rewards Max            -0.206035
evaluation/Rewards Min            -9.46924
evaluation/Returns Mean         -169.84
evaluation/Returns Std            93.879
evaluation/Returns Max           -34.4587
evaluation/Returns Min          -313.789
evaluation/Actions Mean           -0.00871291
evaluation/Actions Std             0.158108
evaluation/Actions Max             0.984472
evaluation/Actions Min            -0.99431
evaluation/Num Paths              15
evaluation/Average Returns      -169.84
time/data storing (s)              0.00319837
time/evaluation sampling (s)       0.345495
time/exploration sampling (s)      0.153557
time/logging (s)                   0.00479798
time/saving (s)                    0.00204402
time/training (s)                  1.93519
time/epoch (s)                     2.44428
time/total (s)                    54.7068
Epoch                             19
-----------------------------  --------------
2019-04-22 23:28:10.741289 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 20 finished
-----------------------------  --------------
replay_buffer/size             10700
trainer/QF1 Loss                  46.1096
trainer/QF2 Loss                  46.1145
trainer/Policy Loss               79.1846
trainer/Q1 Predictions Mean      -78.8802
trainer/Q1 Predictions Std        37.4479
trainer/Q1 Predictions Max       -23.0867
trainer/Q1 Predictions Min      -154.299
trainer/Q2 Predictions Mean      -78.9266
trainer/Q2 Predictions Std        37.4772
trainer/Q2 Predictions Max       -22.8928
trainer/Q2 Predictions Min      -154.081
trainer/Q Targets Mean           -78.337
trainer/Q Targets Std             38.7241
trainer/Q Targets Max             -0.284744
trainer/Q Targets Min           -155.906
trainer/Log Pis Mean               1.6834
trainer/Log Pis Std                1.54484
trainer/Log Pis Max                7.83111
trainer/Log Pis Min               -1.7187
trainer/Policy mu Mean             0.00854106
trainer/Policy mu Std              0.916809
trainer/Policy mu Max              2.79984
trainer/Policy mu Min             -2.22105
trainer/Policy log std Mean       -1.67571
trainer/Policy log std Std         0.474126
trainer/Policy log std Max        -0.59312
trainer/Policy log std Min        -2.38864
trainer/Alpha                      0.0821664
trainer/Alpha Loss                -0.79116
exploration/num steps total    10700
exploration/num paths total      107
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.84452
exploration/Rewards Std            1.06436
exploration/Rewards Max           -0.525027
exploration/Rewards Min           -9.9647
exploration/Returns Mean        -184.452
exploration/Returns Std           44.6415
exploration/Returns Max         -117.928
exploration/Returns Min         -246.07
exploration/Actions Mean          -0.00748665
exploration/Actions Std            0.233592
exploration/Actions Max            0.985786
exploration/Actions Min           -0.996723
exploration/Num Paths              5
exploration/Average Returns     -184.452
evaluation/num steps total     31500
evaluation/num paths total       315
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.94712
evaluation/Rewards Std             1.0912
evaluation/Rewards Max            -0.266449
evaluation/Rewards Min            -9.58231
evaluation/Returns Mean         -194.712
evaluation/Returns Std            86.0578
evaluation/Returns Max           -79.2584
evaluation/Returns Min          -334.285
evaluation/Actions Mean           -0.00141515
evaluation/Actions Std             0.158869
evaluation/Actions Max             0.993991
evaluation/Actions Min            -0.99093
evaluation/Num Paths              15
evaluation/Average Returns      -194.712
time/data storing (s)              0.0027987
time/evaluation sampling (s)       0.336549
time/exploration sampling (s)      0.145919
time/logging (s)                   0.00486719
time/saving (s)                    0.00196944
time/training (s)                  1.89153
time/epoch (s)                     2.38363
time/total (s)                    57.0947
Epoch                             20
-----------------------------  --------------
2019-04-22 23:28:13.172903 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 21 finished
-----------------------------  ---------------
replay_buffer/size             11200
trainer/QF1 Loss                   1.83021
trainer/QF2 Loss                   1.67732
trainer/Policy Loss               75.7468
trainer/Q1 Predictions Mean      -75.6235
trainer/Q1 Predictions Std        38.785
trainer/Q1 Predictions Max       -22.9217
trainer/Q1 Predictions Min      -156.186
trainer/Q2 Predictions Mean      -75.7122
trainer/Q2 Predictions Std        38.8114
trainer/Q2 Predictions Max       -22.7469
trainer/Q2 Predictions Min      -156.254
trainer/Q Targets Mean           -76.3072
trainer/Q Targets Std             39.1896
trainer/Q Targets Max            -23.1334
trainer/Q Targets Min           -157.886
trainer/Log Pis Mean               1.94797
trainer/Log Pis Std                1.54893
trainer/Log Pis Max                7.94645
trainer/Log Pis Min               -2.66991
trainer/Policy mu Mean            -0.0317207
trainer/Policy mu Std              1.04051
trainer/Policy mu Max              2.76849
trainer/Policy mu Min             -2.75774
trainer/Policy log std Mean       -1.63349
trainer/Policy log std Std         0.475975
trainer/Policy log std Max        -0.323355
trainer/Policy log std Min        -2.35706
trainer/Alpha                      0.0775133
trainer/Alpha Loss                -0.133042
exploration/num steps total    11200
exploration/num paths total      112
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.21185
exploration/Rewards Std            1.09587
exploration/Rewards Max           -0.761616
exploration/Rewards Min           -9.44324
exploration/Returns Mean        -221.185
exploration/Returns Std           71.0881
exploration/Returns Max         -157.874
exploration/Returns Min         -357.846
exploration/Actions Mean           0.00998177
exploration/Actions Std            0.29567
exploration/Actions Max            0.998519
exploration/Actions Min           -0.978365
exploration/Num Paths              5
exploration/Average Returns     -221.185
evaluation/num steps total     33000
evaluation/num paths total       330
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.856
evaluation/Rewards Std             1.02348
evaluation/Rewards Max            -0.429301
evaluation/Rewards Min           -10.8695
evaluation/Returns Mean         -185.6
evaluation/Returns Std            40.7917
evaluation/Returns Max           -91.3078
evaluation/Returns Min          -259.379
evaluation/Actions Mean           -0.000641993
evaluation/Actions Std             0.174645
evaluation/Actions Max             0.992128
evaluation/Actions Min            -0.992864
evaluation/Num Paths              15
evaluation/Average Returns      -185.6
time/data storing (s)              0.00317928
time/evaluation sampling (s)       0.335604
time/exploration sampling (s)      0.151031
time/logging (s)                   0.00477344
time/saving (s)                    0.00195795
time/training (s)                  1.92966
time/epoch (s)                     2.4262
time/total (s)                    59.5252
Epoch                             21
-----------------------------  ---------------
2019-04-22 23:28:15.682929 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 22 finished
-----------------------------  --------------
replay_buffer/size             11700
trainer/QF1 Loss                 103.856
trainer/QF2 Loss                 105.471
trainer/Policy Loss               84.1604
trainer/Q1 Predictions Mean      -83.1167
trainer/Q1 Predictions Std        36.7297
trainer/Q1 Predictions Max       -22.9264
trainer/Q1 Predictions Min      -160.09
trainer/Q2 Predictions Mean      -83.1163
trainer/Q2 Predictions Std        36.7127
trainer/Q2 Predictions Max       -22.8136
trainer/Q2 Predictions Min      -159.911
trainer/Q Targets Mean           -82.5657
trainer/Q Targets Std             39.1672
trainer/Q Targets Max             -1.64235
trainer/Q Targets Min           -162.185
trainer/Log Pis Mean               2.16643
trainer/Log Pis Std                1.56047
trainer/Log Pis Max                6.42496
trainer/Log Pis Min               -3.06285
trainer/Policy mu Mean             0.00275814
trainer/Policy mu Std              1.02702
trainer/Policy mu Max              2.66976
trainer/Policy mu Min             -2.87709
trainer/Policy log std Mean       -1.68105
trainer/Policy log std Std         0.493598
trainer/Policy log std Max        -0.391141
trainer/Policy log std Min        -2.37369
trainer/Alpha                      0.0743182
trainer/Alpha Loss                 0.432613
exploration/num steps total    11700
exploration/num paths total      117
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.49665
exploration/Rewards Std            1.10279
exploration/Rewards Max           -0.0820713
exploration/Rewards Min           -9.83181
exploration/Returns Mean        -149.665
exploration/Returns Std           58.421
exploration/Returns Max          -84.7173
exploration/Returns Min         -233.063
exploration/Actions Mean          -0.0217622
exploration/Actions Std            0.251889
exploration/Actions Max            0.990251
exploration/Actions Min           -0.997012
exploration/Num Paths              5
exploration/Average Returns     -149.665
evaluation/num steps total     34500
evaluation/num paths total       345
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.88653
evaluation/Rewards Std             1.03742
evaluation/Rewards Max            -0.144817
evaluation/Rewards Min           -10.3999
evaluation/Returns Mean         -188.653
evaluation/Returns Std            87.8601
evaluation/Returns Max           -86.7667
evaluation/Returns Min          -385.573
evaluation/Actions Mean            0.0106255
evaluation/Actions Std             0.155666
evaluation/Actions Max             0.994481
evaluation/Actions Min            -0.991679
evaluation/Num Paths              15
evaluation/Average Returns      -188.653
time/data storing (s)              0.00321249
time/evaluation sampling (s)       0.336016
time/exploration sampling (s)      0.148657
time/logging (s)                   0.00462741
time/saving (s)                    0.00154183
time/training (s)                  2.01082
time/epoch (s)                     2.50487
time/total (s)                    62.034
Epoch                             22
-----------------------------  --------------
2019-04-22 23:28:18.113934 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 23 finished
-----------------------------  --------------
replay_buffer/size             12200
trainer/QF1 Loss                   3.38128
trainer/QF2 Loss                   3.33634
trainer/Policy Loss               83.0698
trainer/Q1 Predictions Mean      -82.3146
trainer/Q1 Predictions Std        37.5329
trainer/Q1 Predictions Max       -23.0242
trainer/Q1 Predictions Min      -166.605
trainer/Q2 Predictions Mean      -82.3686
trainer/Q2 Predictions Std        37.5421
trainer/Q2 Predictions Max       -22.9331
trainer/Q2 Predictions Min      -165.904
trainer/Q Targets Mean           -83.5404
trainer/Q Targets Std             38.2984
trainer/Q Targets Max            -23.2684
trainer/Q Targets Min           -172.563
trainer/Log Pis Mean               2.22951
trainer/Log Pis Std                1.82968
trainer/Log Pis Max                7.21933
trainer/Log Pis Min               -2.97795
trainer/Policy mu Mean            -0.0231627
trainer/Policy mu Std              1.10423
trainer/Policy mu Max              2.95757
trainer/Policy mu Min             -3.13512
trainer/Policy log std Mean       -1.67558
trainer/Policy log std Std         0.521548
trainer/Policy log std Max        -0.102244
trainer/Policy log std Min        -2.43676
trainer/Alpha                      0.0726295
trainer/Alpha Loss                 0.601871
exploration/num steps total    12200
exploration/num paths total      122
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.64977
exploration/Rewards Std            0.481168
exploration/Rewards Max           -0.957722
exploration/Rewards Min           -3.46752
exploration/Returns Mean        -164.977
exploration/Returns Std           43.6845
exploration/Returns Max         -129.625
exploration/Returns Min         -241.701
exploration/Actions Mean          -0.0125331
exploration/Actions Std            0.191656
exploration/Actions Max            0.751184
exploration/Actions Min           -0.96247
exploration/Num Paths              5
exploration/Average Returns     -164.977
evaluation/num steps total     36000
evaluation/num paths total       360
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.08122
evaluation/Rewards Std             1.0334
evaluation/Rewards Max            -0.149109
evaluation/Rewards Min           -10.0563
evaluation/Returns Mean         -208.122
evaluation/Returns Std            74.192
evaluation/Returns Max          -106.401
evaluation/Returns Min          -359.295
evaluation/Actions Mean            0.00732548
evaluation/Actions Std             0.167344
evaluation/Actions Max             0.993249
evaluation/Actions Min            -0.995962
evaluation/Num Paths              15
evaluation/Average Returns      -208.122
time/data storing (s)              0.00311656
time/evaluation sampling (s)       0.332951
time/exploration sampling (s)      0.151145
time/logging (s)                   0.00383041
time/saving (s)                    0.00193746
time/training (s)                  1.93268
time/epoch (s)                     2.42566
time/total (s)                    64.4635
Epoch                             23
-----------------------------  --------------
2019-04-22 23:28:20.544661 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 24 finished
-----------------------------  --------------
replay_buffer/size             12700
trainer/QF1 Loss                   6.76715
trainer/QF2 Loss                   7.2064
trainer/Policy Loss               72.2282
trainer/Q1 Predictions Mean      -71.8518
trainer/Q1 Predictions Std        36.385
trainer/Q1 Predictions Max       -24.0055
trainer/Q1 Predictions Min      -158.168
trainer/Q2 Predictions Mean      -71.8028
trainer/Q2 Predictions Std        36.3728
trainer/Q2 Predictions Max       -23.628
trainer/Q2 Predictions Min      -157.786
trainer/Q Targets Mean           -71.8901
trainer/Q Targets Std             36.945
trainer/Q Targets Max             -0.551624
trainer/Q Targets Min           -159.249
trainer/Log Pis Mean               1.78697
trainer/Log Pis Std                1.40736
trainer/Log Pis Max                5.26555
trainer/Log Pis Min               -2.10912
trainer/Policy mu Mean             0.0610479
trainer/Policy mu Std              0.928704
trainer/Policy mu Max              2.59202
trainer/Policy mu Min             -2.8893
trainer/Policy log std Mean       -1.78739
trainer/Policy log std Std         0.491949
trainer/Policy log std Max        -0.472817
trainer/Policy log std Min        -2.57209
trainer/Alpha                      0.0711501
trainer/Alpha Loss                -0.563039
exploration/num steps total    12700
exploration/num paths total      127
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.91347
exploration/Rewards Std            1.01445
exploration/Rewards Max           -0.52858
exploration/Rewards Min           -6.53098
exploration/Returns Mean        -191.347
exploration/Returns Std           87.4118
exploration/Returns Max         -106.596
exploration/Returns Min         -340.222
exploration/Actions Mean           0.00892563
exploration/Actions Std            0.23883
exploration/Actions Max            0.997065
exploration/Actions Min           -0.98897
exploration/Num Paths              5
exploration/Average Returns     -191.347
evaluation/num steps total     37500
evaluation/num paths total       375
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.8358
evaluation/Rewards Std             1.14022
evaluation/Rewards Max            -0.44873
evaluation/Rewards Min            -9.79165
evaluation/Returns Mean         -183.58
evaluation/Returns Std            95.2646
evaluation/Returns Max           -58.6064
evaluation/Returns Min          -363.61
evaluation/Actions Mean            0.00773299
evaluation/Actions Std             0.157642
evaluation/Actions Max             0.992826
evaluation/Actions Min            -0.989387
evaluation/Num Paths              15
evaluation/Average Returns      -183.58
time/data storing (s)              0.00297172
time/evaluation sampling (s)       0.335857
time/exploration sampling (s)      0.146454
time/logging (s)                   0.004785
time/saving (s)                    0.00192294
time/training (s)                  1.93406
time/epoch (s)                     2.42605
time/total (s)                    66.8942
Epoch                             24
-----------------------------  --------------
2019-04-22 23:28:22.943184 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 25 finished
-----------------------------  ---------------
replay_buffer/size             13200
trainer/QF1 Loss                 109.117
trainer/QF2 Loss                 109.316
trainer/Policy Loss               87.7496
trainer/Q1 Predictions Mean      -86.9091
trainer/Q1 Predictions Std        39.6135
trainer/Q1 Predictions Max       -23.4574
trainer/Q1 Predictions Min      -154.017
trainer/Q2 Predictions Mean      -86.9834
trainer/Q2 Predictions Std        39.6128
trainer/Q2 Predictions Max       -23.2826
trainer/Q2 Predictions Min      -154.593
trainer/Q Targets Mean           -86.6775
trainer/Q Targets Std             40.508
trainer/Q Targets Max            -10.0618
trainer/Q Targets Min           -156.751
trainer/Log Pis Mean               1.93705
trainer/Log Pis Std                2.03361
trainer/Log Pis Max                7.44344
trainer/Log Pis Min               -4.33327
trainer/Policy mu Mean             0.0489915
trainer/Policy mu Std              1.05697
trainer/Policy mu Max              2.80415
trainer/Policy mu Min             -3.02877
trainer/Policy log std Mean       -1.68113
trainer/Policy log std Std         0.530806
trainer/Policy log std Max        -0.377824
trainer/Policy log std Min        -2.61232
trainer/Alpha                      0.0702483
trainer/Alpha Loss                -0.167177
exploration/num steps total    13200
exploration/num paths total      132
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.78275
exploration/Rewards Std            1.14246
exploration/Rewards Max           -0.329575
exploration/Rewards Min          -10.5704
exploration/Returns Mean        -178.275
exploration/Returns Std           49.1759
exploration/Returns Max         -113.733
exploration/Returns Min         -233.417
exploration/Actions Mean          -0.0225025
exploration/Actions Std            0.278349
exploration/Actions Max            0.990652
exploration/Actions Min           -0.999082
exploration/Num Paths              5
exploration/Average Returns     -178.275
evaluation/num steps total     39000
evaluation/num paths total       390
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.8141
evaluation/Rewards Std             1.12409
evaluation/Rewards Max            -0.258751
evaluation/Rewards Min            -9.98148
evaluation/Returns Mean         -181.41
evaluation/Returns Std            93.1469
evaluation/Returns Max           -74.0373
evaluation/Returns Min          -358.177
evaluation/Actions Mean            0.000990237
evaluation/Actions Std             0.152569
evaluation/Actions Max             0.991492
evaluation/Actions Min            -0.992972
evaluation/Num Paths              15
evaluation/Average Returns      -181.41
time/data storing (s)              0.0029192
time/evaluation sampling (s)       0.330315
time/exploration sampling (s)      0.145493
time/logging (s)                   0.00482961
time/saving (s)                    0.00195884
time/training (s)                  1.90748
time/epoch (s)                     2.393
time/total (s)                    69.2917
Epoch                             25
-----------------------------  ---------------
2019-04-22 23:28:25.372932 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 26 finished
-----------------------------  --------------
replay_buffer/size             13700
trainer/QF1 Loss                   1.67799
trainer/QF2 Loss                   1.71986
trainer/Policy Loss               84.4356
trainer/Q1 Predictions Mean      -84.0156
trainer/Q1 Predictions Std        34.4889
trainer/Q1 Predictions Max       -23.2927
trainer/Q1 Predictions Min      -149.366
trainer/Q2 Predictions Mean      -83.999
trainer/Q2 Predictions Std        34.52
trainer/Q2 Predictions Max       -23.2951
trainer/Q2 Predictions Min      -149.399
trainer/Q Targets Mean           -84.9023
trainer/Q Targets Std             34.5889
trainer/Q Targets Max            -23.4455
trainer/Q Targets Min           -150.494
trainer/Log Pis Mean               1.98236
trainer/Log Pis Std                1.76427
trainer/Log Pis Max                7.27361
trainer/Log Pis Min               -2.68476
trainer/Policy mu Mean            -0.0454833
trainer/Policy mu Std              1.00766
trainer/Policy mu Max              2.55463
trainer/Policy mu Min             -2.78214
trainer/Policy log std Mean       -1.68352
trainer/Policy log std Std         0.507712
trainer/Policy log std Max        -0.322005
trainer/Policy log std Min        -2.66968
trainer/Alpha                      0.0690416
trainer/Alpha Loss                -0.0471448
exploration/num steps total    13700
exploration/num paths total      137
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.46819
exploration/Rewards Std            1.48215
exploration/Rewards Max           -0.248491
exploration/Rewards Min          -11.0333
exploration/Returns Mean        -246.819
exploration/Returns Std          118.142
exploration/Returns Max          -86.8344
exploration/Returns Min         -398.849
exploration/Actions Mean           0.0108762
exploration/Actions Std            0.245083
exploration/Actions Max            0.995835
exploration/Actions Min           -0.993665
exploration/Num Paths              5
exploration/Average Returns     -246.819
evaluation/num steps total     40500
evaluation/num paths total       405
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.57536
evaluation/Rewards Std             1.14549
evaluation/Rewards Max            -0.484006
evaluation/Rewards Min           -10.9835
evaluation/Returns Mean         -157.536
evaluation/Returns Std            70.153
evaluation/Returns Max           -90.7348
evaluation/Returns Min          -359.519
evaluation/Actions Mean           -0.0147511
evaluation/Actions Std             0.179262
evaluation/Actions Max             0.994197
evaluation/Actions Min            -0.998988
evaluation/Num Paths              15
evaluation/Average Returns      -157.536
time/data storing (s)              0.00288934
time/evaluation sampling (s)       0.332428
time/exploration sampling (s)      0.147643
time/logging (s)                   0.00486881
time/saving (s)                    0.00196715
time/training (s)                  1.93477
time/epoch (s)                     2.42456
time/total (s)                    71.7204
Epoch                             26
-----------------------------  --------------
2019-04-22 23:28:27.796073 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 27 finished
-----------------------------  --------------
replay_buffer/size             14200
trainer/QF1 Loss                  43.3671
trainer/QF2 Loss                  42.8935
trainer/Policy Loss               82.3967
trainer/Q1 Predictions Mean      -81.7433
trainer/Q1 Predictions Std        35.4025
trainer/Q1 Predictions Max       -23.9893
trainer/Q1 Predictions Min      -147.131
trainer/Q2 Predictions Mean      -81.8049
trainer/Q2 Predictions Std        35.4178
trainer/Q2 Predictions Max       -23.7608
trainer/Q2 Predictions Min      -147.786
trainer/Q Targets Mean           -81.5484
trainer/Q Targets Std             36.2774
trainer/Q Targets Max             -1.49836
trainer/Q Targets Min           -146.983
trainer/Log Pis Mean               2.17211
trainer/Log Pis Std                1.80607
trainer/Log Pis Max                7.72393
trainer/Log Pis Min               -0.902787
trainer/Policy mu Mean             0.0705413
trainer/Policy mu Std              1.08467
trainer/Policy mu Max              2.80749
trainer/Policy mu Min             -2.84289
trainer/Policy log std Mean       -1.71679
trainer/Policy log std Std         0.584057
trainer/Policy log std Max        -0.404572
trainer/Policy log std Min        -2.66297
trainer/Alpha                      0.0682126
trainer/Alpha Loss                 0.46215
exploration/num steps total    14200
exploration/num paths total      142
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.99789
exploration/Rewards Std            1.49297
exploration/Rewards Max           -0.0458687
exploration/Rewards Min           -8.04134
exploration/Returns Mean        -199.789
exploration/Returns Std          133.492
exploration/Returns Max          -31.1345
exploration/Returns Min         -345.93
exploration/Actions Mean          -0.0184738
exploration/Actions Std            0.237385
exploration/Actions Max            0.957506
exploration/Actions Min           -0.990286
exploration/Num Paths              5
exploration/Average Returns     -199.789
evaluation/num steps total     42000
evaluation/num paths total       420
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.47722
evaluation/Rewards Std             1.43013
evaluation/Rewards Max            -0.172744
evaluation/Rewards Min            -9.54741
evaluation/Returns Mean         -147.722
evaluation/Returns Std           116.16
evaluation/Returns Max           -24.2086
evaluation/Returns Min          -357.857
evaluation/Actions Mean           -0.0057827
evaluation/Actions Std             0.169483
evaluation/Actions Max             0.994949
evaluation/Actions Min            -0.99707
evaluation/Num Paths              15
evaluation/Average Returns      -147.722
time/data storing (s)              0.00311727
time/evaluation sampling (s)       0.332687
time/exploration sampling (s)      0.148238
time/logging (s)                   0.00353007
time/saving (s)                    0.00192085
time/training (s)                  1.92647
time/epoch (s)                     2.41597
time/total (s)                    74.1411
Epoch                             27
-----------------------------  --------------
2019-04-22 23:28:30.209782 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 28 finished
-----------------------------  ---------------
replay_buffer/size             14700
trainer/QF1 Loss                   1.22613
trainer/QF2 Loss                   1.27268
trainer/Policy Loss               79.3315
trainer/Q1 Predictions Mean      -78.5935
trainer/Q1 Predictions Std        36.0607
trainer/Q1 Predictions Max       -23.7601
trainer/Q1 Predictions Min      -151.313
trainer/Q2 Predictions Mean      -78.6341
trainer/Q2 Predictions Std        36.1283
trainer/Q2 Predictions Max       -23.6771
trainer/Q2 Predictions Min      -152.011
trainer/Q Targets Mean           -79.2336
trainer/Q Targets Std             36.4782
trainer/Q Targets Max            -23.8246
trainer/Q Targets Min           -152.607
trainer/Log Pis Mean               2.27547
trainer/Log Pis Std                1.886
trainer/Log Pis Max                8.23161
trainer/Log Pis Min               -4.30487
trainer/Policy mu Mean             0.0942806
trainer/Policy mu Std              1.12868
trainer/Policy mu Max              3.19884
trainer/Policy mu Min             -2.7849
trainer/Policy log std Mean       -1.69704
trainer/Policy log std Std         0.51105
trainer/Policy log std Max        -0.456963
trainer/Policy log std Min        -2.62828
trainer/Alpha                      0.0670073
trainer/Alpha Loss                 0.74459
exploration/num steps total    14700
exploration/num paths total      147
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.90985
exploration/Rewards Std            1.02173
exploration/Rewards Max           -0.114651
exploration/Rewards Min          -11.5031
exploration/Returns Mean        -190.985
exploration/Returns Std           50.0476
exploration/Returns Max          -95.3606
exploration/Returns Min         -232.597
exploration/Actions Mean           0.00577695
exploration/Actions Std            0.252479
exploration/Actions Max            0.998316
exploration/Actions Min           -1
exploration/Num Paths              5
exploration/Average Returns     -190.985
evaluation/num steps total     43500
evaluation/num paths total       435
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.71478
evaluation/Rewards Std             1.32585
evaluation/Rewards Max            -0.123873
evaluation/Rewards Min           -11.5787
evaluation/Returns Mean         -171.478
evaluation/Returns Std            92.1924
evaluation/Returns Max           -36.7712
evaluation/Returns Min          -289.426
evaluation/Actions Mean           -0.000453292
evaluation/Actions Std             0.180885
evaluation/Actions Max             0.997789
evaluation/Actions Min            -0.995255
evaluation/Num Paths              15
evaluation/Average Returns      -171.478
time/data storing (s)              0.00300111
time/evaluation sampling (s)       0.332374
time/exploration sampling (s)      0.146107
time/logging (s)                   0.00477291
time/saving (s)                    0.00193358
time/training (s)                  1.92238
time/epoch (s)                     2.41057
time/total (s)                    76.5553
Epoch                             28
-----------------------------  ---------------
2019-04-22 23:28:32.626776 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 29 finished
-----------------------------  --------------
replay_buffer/size             15200
trainer/QF1 Loss                  88.5553
trainer/QF2 Loss                  88.3336
trainer/Policy Loss               79.5278
trainer/Q1 Predictions Mean      -78.5239
trainer/Q1 Predictions Std        36.6476
trainer/Q1 Predictions Max       -23.499
trainer/Q1 Predictions Min      -146.914
trainer/Q2 Predictions Mean      -78.5461
trainer/Q2 Predictions Std        36.6376
trainer/Q2 Predictions Max       -23.5861
trainer/Q2 Predictions Min      -147.029
trainer/Q Targets Mean           -78.0092
trainer/Q Targets Std             37.8836
trainer/Q Targets Max             -0.0886411
trainer/Q Targets Min           -147.287
trainer/Log Pis Mean               2.08085
trainer/Log Pis Std                1.49444
trainer/Log Pis Max                7.12966
trainer/Log Pis Min               -1.20297
trainer/Policy mu Mean            -0.0922144
trainer/Policy mu Std              0.953192
trainer/Policy mu Max              3.30836
trainer/Policy mu Min             -2.82522
trainer/Policy log std Mean       -1.85352
trainer/Policy log std Std         0.518335
trainer/Policy log std Max        -0.516435
trainer/Policy log std Min        -2.63399
trainer/Alpha                      0.0669317
trainer/Alpha Loss                 0.218638
exploration/num steps total    15200
exploration/num paths total      152
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.46721
exploration/Rewards Std            0.86047
exploration/Rewards Max           -1.01745
exploration/Rewards Min           -9.4755
exploration/Returns Mean        -246.721
exploration/Returns Std           56.0892
exploration/Returns Max         -165.896
exploration/Returns Min         -310.501
exploration/Actions Mean           0.00302501
exploration/Actions Std            0.224583
exploration/Actions Max            0.996975
exploration/Actions Min           -0.96275
exploration/Num Paths              5
exploration/Average Returns     -246.721
evaluation/num steps total     45000
evaluation/num paths total       450
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.30106
evaluation/Rewards Std             1.0993
evaluation/Rewards Max            -0.042795
evaluation/Rewards Min            -9.62128
evaluation/Returns Mean         -130.106
evaluation/Returns Std            84.9129
evaluation/Returns Max           -34.9237
evaluation/Returns Min          -331.214
evaluation/Actions Mean            0.00976113
evaluation/Actions Std             0.164319
evaluation/Actions Max             0.996208
evaluation/Actions Min            -0.993425
evaluation/Num Paths              15
evaluation/Average Returns      -130.106
time/data storing (s)              0.00311159
time/evaluation sampling (s)       0.333422
time/exploration sampling (s)      0.148209
time/logging (s)                   0.00478967
time/saving (s)                    0.0019433
time/training (s)                  1.92082
time/epoch (s)                     2.4123
time/total (s)                    78.9712
Epoch                             29
-----------------------------  --------------
2019-04-22 23:28:35.049016 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 30 finished
-----------------------------  --------------
replay_buffer/size             15700
trainer/QF1 Loss                   2.33428
trainer/QF2 Loss                   2.31545
trainer/Policy Loss               80.6945
trainer/Q1 Predictions Mean      -79.5357
trainer/Q1 Predictions Std        35.4618
trainer/Q1 Predictions Max       -22.9538
trainer/Q1 Predictions Min      -143.944
trainer/Q2 Predictions Mean      -79.5765
trainer/Q2 Predictions Std        35.5245
trainer/Q2 Predictions Max       -22.9412
trainer/Q2 Predictions Min      -144.199
trainer/Q Targets Mean           -80.6409
trainer/Q Targets Std             35.8581
trainer/Q Targets Max            -23.4361
trainer/Q Targets Min           -145.51
trainer/Log Pis Mean               2.13361
trainer/Log Pis Std                1.72964
trainer/Log Pis Max                7.71195
trainer/Log Pis Min               -2.08852
trainer/Policy mu Mean            -0.115265
trainer/Policy mu Std              0.952353
trainer/Policy mu Max              2.85853
trainer/Policy mu Min             -2.80466
trainer/Policy log std Mean       -1.78706
trainer/Policy log std Std         0.523598
trainer/Policy log std Max        -0.443541
trainer/Policy log std Min        -2.61627
trainer/Alpha                      0.066589
trainer/Alpha Loss                 0.361993
exploration/num steps total    15700
exploration/num paths total      157
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.58141
exploration/Rewards Std            1.49225
exploration/Rewards Max           -0.0342848
exploration/Rewards Min           -6.99602
exploration/Returns Mean        -158.141
exploration/Returns Std          133.868
exploration/Returns Max          -29.5722
exploration/Returns Min         -330.958
exploration/Actions Mean           0.00926521
exploration/Actions Std            0.215217
exploration/Actions Max            0.995197
exploration/Actions Min           -0.981971
exploration/Num Paths              5
exploration/Average Returns     -158.141
evaluation/num steps total     46500
evaluation/num paths total       465
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.89891
evaluation/Rewards Std             1.31738
evaluation/Rewards Max            -0.242761
evaluation/Rewards Min           -11.5573
evaluation/Returns Mean         -189.891
evaluation/Returns Std            87.7654
evaluation/Returns Max           -71.0866
evaluation/Returns Min          -322.187
evaluation/Actions Mean            0.00522388
evaluation/Actions Std             0.184428
evaluation/Actions Max             0.997018
evaluation/Actions Min            -0.999132
evaluation/Num Paths              15
evaluation/Average Returns      -189.891
time/data storing (s)              0.00305273
time/evaluation sampling (s)       0.338468
time/exploration sampling (s)      0.146392
time/logging (s)                   0.00424396
time/saving (s)                    0.00193787
time/training (s)                  1.9219
time/epoch (s)                     2.416
time/total (s)                    81.3917
Epoch                             30
-----------------------------  --------------
2019-04-22 23:28:37.442292 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 31 finished
-----------------------------  --------------
replay_buffer/size             16200
trainer/QF1 Loss                   0.54009
trainer/QF2 Loss                   0.642088
trainer/Policy Loss               80.6261
trainer/Q1 Predictions Mean      -79.7361
trainer/Q1 Predictions Std        36.3102
trainer/Q1 Predictions Max       -23.776
trainer/Q1 Predictions Min      -141.763
trainer/Q2 Predictions Mean      -79.7016
trainer/Q2 Predictions Std        36.3122
trainer/Q2 Predictions Max       -23.7067
trainer/Q2 Predictions Min      -141.601
trainer/Q Targets Mean           -80.0722
trainer/Q Targets Std             36.4342
trainer/Q Targets Max            -23.5486
trainer/Q Targets Min           -142.798
trainer/Log Pis Mean               1.74604
trainer/Log Pis Std                1.49633
trainer/Log Pis Max                6.26775
trainer/Log Pis Min               -3.89409
trainer/Policy mu Mean             0.098895
trainer/Policy mu Std              0.882453
trainer/Policy mu Max              2.93334
trainer/Policy mu Min             -2.92642
trainer/Policy log std Mean       -1.76321
trainer/Policy log std Std         0.537199
trainer/Policy log std Max        -0.417534
trainer/Policy log std Min        -2.72401
trainer/Alpha                      0.0665241
trainer/Alpha Loss                -0.688244
exploration/num steps total    16200
exploration/num paths total      162
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.5107
exploration/Rewards Std            1.50563
exploration/Rewards Max           -0.0141811
exploration/Rewards Min          -10.4019
exploration/Returns Mean        -151.07
exploration/Returns Std          121.083
exploration/Returns Max          -52.9689
exploration/Returns Min         -367.001
exploration/Actions Mean          -0.00394105
exploration/Actions Std            0.246094
exploration/Actions Max            0.99689
exploration/Actions Min           -0.999748
exploration/Num Paths              5
exploration/Average Returns     -151.07
evaluation/num steps total     48000
evaluation/num paths total       480
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.36453
evaluation/Rewards Std             1.24235
evaluation/Rewards Max            -0.0347104
evaluation/Rewards Min            -9.43217
evaluation/Returns Mean         -136.453
evaluation/Returns Std            87.5014
evaluation/Returns Max           -22.0518
evaluation/Returns Min          -352.566
evaluation/Actions Mean           -0.010628
evaluation/Actions Std             0.175244
evaluation/Actions Max             0.996804
evaluation/Actions Min            -0.99725
evaluation/Num Paths              15
evaluation/Average Returns      -136.453
time/data storing (s)              0.00294127
time/evaluation sampling (s)       0.330111
time/exploration sampling (s)      0.144094
time/logging (s)                   0.00408821
time/saving (s)                    0.00198274
time/training (s)                  1.90426
time/epoch (s)                     2.38748
time/total (s)                    83.7837
Epoch                             31
-----------------------------  --------------
2019-04-22 23:28:39.847792 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 32 finished
-----------------------------  --------------
replay_buffer/size             16700
trainer/QF1 Loss                   1.14564
trainer/QF2 Loss                   1.17655
trainer/Policy Loss               82.5644
trainer/Q1 Predictions Mean      -81.8533
trainer/Q1 Predictions Std        30.9956
trainer/Q1 Predictions Max       -23.256
trainer/Q1 Predictions Min      -138.56
trainer/Q2 Predictions Mean      -81.8829
trainer/Q2 Predictions Std        31.0376
trainer/Q2 Predictions Max       -23.4027
trainer/Q2 Predictions Min      -138.391
trainer/Q Targets Mean           -82.6205
trainer/Q Targets Std             31.2697
trainer/Q Targets Max            -23.2142
trainer/Q Targets Min           -141.14
trainer/Log Pis Mean               1.6459
trainer/Log Pis Std                1.34013
trainer/Log Pis Max                6.2359
trainer/Log Pis Min               -2.49623
trainer/Policy mu Mean             0.0778512
trainer/Policy mu Std              0.765336
trainer/Policy mu Max              2.21792
trainer/Policy mu Min             -2.8697
trainer/Policy log std Mean       -1.84813
trainer/Policy log std Std         0.501813
trainer/Policy log std Max        -0.440631
trainer/Policy log std Min        -2.70728
trainer/Alpha                      0.0664967
trainer/Alpha Loss                -0.959777
exploration/num steps total    16700
exploration/num paths total      167
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.75421
exploration/Rewards Std            1.30558
exploration/Rewards Max           -0.333638
exploration/Rewards Min          -10.5458
exploration/Returns Mean        -175.421
exploration/Returns Std           43.2758
exploration/Returns Max         -109.407
exploration/Returns Min         -217.053
exploration/Actions Mean           0.0222462
exploration/Actions Std            0.30205
exploration/Actions Max            0.999569
exploration/Actions Min           -0.997053
exploration/Num Paths              5
exploration/Average Returns     -175.421
evaluation/num steps total     49500
evaluation/num paths total       495
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.30918
evaluation/Rewards Std             1.21617
evaluation/Rewards Max            -0.164558
evaluation/Rewards Min            -9.23386
evaluation/Returns Mean         -130.918
evaluation/Returns Std            93.1359
evaluation/Returns Max           -32.0322
evaluation/Returns Min          -388.375
evaluation/Actions Mean            0.0114498
evaluation/Actions Std             0.17628
evaluation/Actions Max             0.998072
evaluation/Actions Min            -0.996445
evaluation/Num Paths              15
evaluation/Average Returns      -130.918
time/data storing (s)              0.00295862
time/evaluation sampling (s)       0.332776
time/exploration sampling (s)      0.143051
time/logging (s)                   0.00477489
time/saving (s)                    0.00196643
time/training (s)                  1.91492
time/epoch (s)                     2.40044
time/total (s)                    86.1888
Epoch                             32
-----------------------------  --------------
2019-04-22 23:28:42.297577 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 33 finished
-----------------------------  --------------
replay_buffer/size             17200
trainer/QF1 Loss                 317.671
trainer/QF2 Loss                 317.168
trainer/Policy Loss               79.5516
trainer/Q1 Predictions Mean      -78.6922
trainer/Q1 Predictions Std        31.7892
trainer/Q1 Predictions Max       -22.8203
trainer/Q1 Predictions Min      -140.046
trainer/Q2 Predictions Mean      -78.7224
trainer/Q2 Predictions Std        31.8513
trainer/Q2 Predictions Max       -22.7382
trainer/Q2 Predictions Min      -139.99
trainer/Q Targets Mean           -76.4644
trainer/Q Targets Std             33.9034
trainer/Q Targets Max             -2.72657
trainer/Q Targets Min           -142.993
trainer/Log Pis Mean               1.92363
trainer/Log Pis Std                1.60024
trainer/Log Pis Max                7.14478
trainer/Log Pis Min               -1.93716
trainer/Policy mu Mean             0.0269133
trainer/Policy mu Std              0.92996
trainer/Policy mu Max              2.86101
trainer/Policy mu Min             -2.92366
trainer/Policy log std Mean       -1.80656
trainer/Policy log std Std         0.542949
trainer/Policy log std Max        -0.426637
trainer/Policy log std Min        -2.68033
trainer/Alpha                      0.0654657
trainer/Alpha Loss                -0.208188
exploration/num steps total    17200
exploration/num paths total      172
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.07097
exploration/Rewards Std            1.6377
exploration/Rewards Max           -0.0389842
exploration/Rewards Min          -10.216
exploration/Returns Mean        -207.097
exploration/Returns Std          118.519
exploration/Returns Max          -66.7151
exploration/Returns Min         -396.056
exploration/Actions Mean          -0.0254021
exploration/Actions Std            0.272062
exploration/Actions Max            0.997598
exploration/Actions Min           -0.999873
exploration/Num Paths              5
exploration/Average Returns     -207.097
evaluation/num steps total     51000
evaluation/num paths total       510
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.56805
evaluation/Rewards Std             1.36523
evaluation/Rewards Max            -0.0543275
evaluation/Rewards Min           -10.1871
evaluation/Returns Mean         -156.805
evaluation/Returns Std            91.6267
evaluation/Returns Max           -52.3387
evaluation/Returns Min          -399.554
evaluation/Actions Mean            0.00272752
evaluation/Actions Std             0.178384
evaluation/Actions Max             0.986522
evaluation/Actions Min            -0.9986
evaluation/Num Paths              15
evaluation/Average Returns      -156.805
time/data storing (s)              0.00275003
time/evaluation sampling (s)       0.334743
time/exploration sampling (s)      0.147541
time/logging (s)                   0.00487416
time/saving (s)                    0.0106545
time/training (s)                  1.94356
time/epoch (s)                     2.44412
time/total (s)                    88.6376
Epoch                             33
-----------------------------  --------------
2019-04-22 23:28:44.701939 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 34 finished
-----------------------------  --------------
replay_buffer/size             17700
trainer/QF1 Loss                  42.6015
trainer/QF2 Loss                  41.9804
trainer/Policy Loss               87.8826
trainer/Q1 Predictions Mean      -86.7705
trainer/Q1 Predictions Std        35.9888
trainer/Q1 Predictions Max       -22.0644
trainer/Q1 Predictions Min      -156.592
trainer/Q2 Predictions Mean      -86.8174
trainer/Q2 Predictions Std        36.0043
trainer/Q2 Predictions Max       -22.1986
trainer/Q2 Predictions Min      -159.01
trainer/Q Targets Mean           -87.1648
trainer/Q Targets Std             37.2218
trainer/Q Targets Max             -1.27421
trainer/Q Targets Min           -161.629
trainer/Log Pis Mean               2.10431
trainer/Log Pis Std                1.79261
trainer/Log Pis Max                6.60443
trainer/Log Pis Min               -3.30236
trainer/Policy mu Mean             0.0951405
trainer/Policy mu Std              1.04572
trainer/Policy mu Max              3.03412
trainer/Policy mu Min             -3.40522
trainer/Policy log std Mean       -1.785
trainer/Policy log std Std         0.601896
trainer/Policy log std Max        -0.205089
trainer/Policy log std Min        -2.73982
trainer/Alpha                      0.0641167
trainer/Alpha Loss                 0.286553
exploration/num steps total    17700
exploration/num paths total      177
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.18787
exploration/Rewards Std            1.16563
exploration/Rewards Max           -0.156227
exploration/Rewards Min           -7.86275
exploration/Returns Mean        -218.787
exploration/Returns Std           85.475
exploration/Returns Max         -114.686
exploration/Returns Min         -375.956
exploration/Actions Mean          -0.017959
exploration/Actions Std            0.276362
exploration/Actions Max            0.998304
exploration/Actions Min           -0.995097
exploration/Num Paths              5
exploration/Average Returns     -218.787
evaluation/num steps total     52500
evaluation/num paths total       525
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.66452
evaluation/Rewards Std             1.51851
evaluation/Rewards Max            -0.103606
evaluation/Rewards Min           -10.5658
evaluation/Returns Mean         -166.452
evaluation/Returns Std           126.079
evaluation/Returns Max           -18.4954
evaluation/Returns Min          -427.713
evaluation/Actions Mean           -0.00588578
evaluation/Actions Std             0.181935
evaluation/Actions Max             0.99773
evaluation/Actions Min            -0.995605
evaluation/Num Paths              15
evaluation/Average Returns      -166.452
time/data storing (s)              0.00309975
time/evaluation sampling (s)       0.324966
time/exploration sampling (s)      0.146263
time/logging (s)                   0.00485441
time/saving (s)                    0.0019596
time/training (s)                  1.91747
time/epoch (s)                     2.39861
time/total (s)                    91.0407
Epoch                             34
-----------------------------  --------------
2019-04-22 23:28:47.114199 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 35 finished
-----------------------------  --------------
replay_buffer/size             18200
trainer/QF1 Loss                   0.718961
trainer/QF2 Loss                   0.660479
trainer/Policy Loss               75.528
trainer/Q1 Predictions Mean      -74.4819
trainer/Q1 Predictions Std        33.0259
trainer/Q1 Predictions Max       -23.6405
trainer/Q1 Predictions Min      -136.436
trainer/Q2 Predictions Mean      -74.4746
trainer/Q2 Predictions Std        33.0477
trainer/Q2 Predictions Max       -23.3557
trainer/Q2 Predictions Min      -136.389
trainer/Q Targets Mean           -74.6621
trainer/Q Targets Std             33.2135
trainer/Q Targets Max            -23.0786
trainer/Q Targets Min           -137.754
trainer/Log Pis Mean               2.15568
trainer/Log Pis Std                1.34652
trainer/Log Pis Max                7.08064
trainer/Log Pis Min               -0.836684
trainer/Policy mu Mean             0.0687858
trainer/Policy mu Std              0.830792
trainer/Policy mu Max              2.87726
trainer/Policy mu Min             -2.87918
trainer/Policy log std Mean       -1.88813
trainer/Policy log std Std         0.541491
trainer/Policy log std Max        -0.519165
trainer/Policy log std Min        -2.78842
trainer/Alpha                      0.0638578
trainer/Alpha Loss                 0.428303
exploration/num steps total    18200
exploration/num paths total      182
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.55323
exploration/Rewards Std            0.754729
exploration/Rewards Max           -0.262613
exploration/Rewards Min           -6.00315
exploration/Returns Mean        -155.323
exploration/Returns Std           63.0201
exploration/Returns Max          -71.4308
exploration/Returns Min         -237.824
exploration/Actions Mean           0.0153874
exploration/Actions Std            0.215417
exploration/Actions Max            0.996491
exploration/Actions Min           -0.783165
exploration/Num Paths              5
exploration/Average Returns     -155.323
evaluation/num steps total     54000
evaluation/num paths total       540
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.62038
evaluation/Rewards Std             1.35399
evaluation/Rewards Max            -0.112652
evaluation/Rewards Min           -11.5586
evaluation/Returns Mean         -162.038
evaluation/Returns Std           109.738
evaluation/Returns Max           -13.4617
evaluation/Returns Min          -412.242
evaluation/Actions Mean            0.00204477
evaluation/Actions Std             0.170654
evaluation/Actions Max             0.996112
evaluation/Actions Min            -0.998335
evaluation/Num Paths              15
evaluation/Average Returns      -162.038
time/data storing (s)              0.00305559
time/evaluation sampling (s)       0.332792
time/exploration sampling (s)      0.149817
time/logging (s)                   0.00481581
time/saving (s)                    0.00195668
time/training (s)                  1.9141
time/epoch (s)                     2.40653
time/total (s)                    93.4518
Epoch                             35
-----------------------------  --------------
2019-04-22 23:28:49.512881 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 36 finished
-----------------------------  --------------
replay_buffer/size             18700
trainer/QF1 Loss                 151.827
trainer/QF2 Loss                 152.066
trainer/Policy Loss               84.4478
trainer/Q1 Predictions Mean      -83.6729
trainer/Q1 Predictions Std        32.8606
trainer/Q1 Predictions Max       -23.6892
trainer/Q1 Predictions Min      -134.271
trainer/Q2 Predictions Mean      -83.6355
trainer/Q2 Predictions Std        32.8716
trainer/Q2 Predictions Max       -23.8836
trainer/Q2 Predictions Min      -135
trainer/Q Targets Mean           -82.0192
trainer/Q Targets Std             34.7734
trainer/Q Targets Max             -0.289567
trainer/Q Targets Min           -134.007
trainer/Log Pis Mean               1.61146
trainer/Log Pis Std                1.86202
trainer/Log Pis Max                6.62729
trainer/Log Pis Min               -6.01867
trainer/Policy mu Mean             0.09056
trainer/Policy mu Std              0.719508
trainer/Policy mu Max              2.34936
trainer/Policy mu Min             -2.82945
trainer/Policy log std Mean       -1.92373
trainer/Policy log std Std         0.528199
trainer/Policy log std Max        -0.425225
trainer/Policy log std Min        -2.81133
trainer/Alpha                      0.0637063
trainer/Alpha Loss                -1.06978
exploration/num steps total    18700
exploration/num paths total      187
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.76667
exploration/Rewards Std            1.55607
exploration/Rewards Max           -0.211286
exploration/Rewards Min          -10.5463
exploration/Returns Mean        -176.667
exploration/Returns Std           78.5664
exploration/Returns Max          -99.8366
exploration/Returns Min         -300.294
exploration/Actions Mean          -0.0159639
exploration/Actions Std            0.25668
exploration/Actions Max            0.997783
exploration/Actions Min           -0.995345
exploration/Num Paths              5
exploration/Average Returns     -176.667
evaluation/num steps total     55500
evaluation/num paths total       555
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.17907
evaluation/Rewards Std             1.11512
evaluation/Rewards Max            -0.014972
evaluation/Rewards Min            -7.59013
evaluation/Returns Mean         -117.907
evaluation/Returns Std            90.6158
evaluation/Returns Max           -20.4961
evaluation/Returns Min          -304.49
evaluation/Actions Mean           -0.0036034
evaluation/Actions Std             0.141031
evaluation/Actions Max             0.987494
evaluation/Actions Min            -0.993608
evaluation/Num Paths              15
evaluation/Average Returns      -117.907
time/data storing (s)              0.00342154
time/evaluation sampling (s)       0.329258
time/exploration sampling (s)      0.148685
time/logging (s)                   0.00459364
time/saving (s)                    0.00195969
time/training (s)                  1.90469
time/epoch (s)                     2.39261
time/total (s)                    95.849
Epoch                             36
-----------------------------  --------------
2019-04-22 23:28:51.926904 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 37 finished
-----------------------------  --------------
replay_buffer/size             19200
trainer/QF1 Loss                 101.689
trainer/QF2 Loss                 102.069
trainer/Policy Loss               76.8141
trainer/Q1 Predictions Mean      -75.928
trainer/Q1 Predictions Std        35.9415
trainer/Q1 Predictions Max       -22.9168
trainer/Q1 Predictions Min      -147.852
trainer/Q2 Predictions Mean      -75.9694
trainer/Q2 Predictions Std        36.0282
trainer/Q2 Predictions Max       -22.9758
trainer/Q2 Predictions Min      -148.504
trainer/Q Targets Mean           -75.0119
trainer/Q Targets Std             38.5851
trainer/Q Targets Max             -1.22449
trainer/Q Targets Min           -150.905
trainer/Log Pis Mean               2.05843
trainer/Log Pis Std                1.73115
trainer/Log Pis Max                8.64468
trainer/Log Pis Min               -2.56906
trainer/Policy mu Mean            -0.00770528
trainer/Policy mu Std              0.995221
trainer/Policy mu Max              3.20386
trainer/Policy mu Min             -3.2958
trainer/Policy log std Mean       -1.82796
trainer/Policy log std Std         0.543343
trainer/Policy log std Max        -0.493112
trainer/Policy log std Min        -2.6934
trainer/Alpha                      0.0631185
trainer/Alpha Loss                 0.161416
exploration/num steps total    19200
exploration/num paths total      192
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.47602
exploration/Rewards Std            1.00923
exploration/Rewards Max           -0.0116417
exploration/Rewards Min           -7.61618
exploration/Returns Mean        -147.602
exploration/Returns Std           61.5012
exploration/Returns Max          -40.7361
exploration/Returns Min         -210.178
exploration/Actions Mean          -0.0318528
exploration/Actions Std            0.209978
exploration/Actions Max            0.96798
exploration/Actions Min           -0.998697
exploration/Num Paths              5
exploration/Average Returns     -147.602
evaluation/num steps total     57000
evaluation/num paths total       570
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.6545
evaluation/Rewards Std             1.31064
evaluation/Rewards Max            -0.0298978
evaluation/Rewards Min            -9.9879
evaluation/Returns Mean         -165.45
evaluation/Returns Std            85.5956
evaluation/Returns Max           -25.7184
evaluation/Returns Min          -344.651
evaluation/Actions Mean            0.00731669
evaluation/Actions Std             0.193981
evaluation/Actions Max             0.995735
evaluation/Actions Min            -0.996648
evaluation/Num Paths              15
evaluation/Average Returns      -165.45
time/data storing (s)              0.00322057
time/evaluation sampling (s)       0.332363
time/exploration sampling (s)      0.145889
time/logging (s)                   0.00484984
time/saving (s)                    0.00195812
time/training (s)                  1.9203
time/epoch (s)                     2.40858
time/total (s)                    98.2621
Epoch                             37
-----------------------------  --------------
2019-04-22 23:28:54.343140 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 38 finished
-----------------------------  --------------
replay_buffer/size             19700
trainer/QF1 Loss                 102.115
trainer/QF2 Loss                 102.592
trainer/Policy Loss               78.7845
trainer/Q1 Predictions Mean      -77.6849
trainer/Q1 Predictions Std        35.2703
trainer/Q1 Predictions Max       -23.5218
trainer/Q1 Predictions Min      -135.477
trainer/Q2 Predictions Mean      -77.6571
trainer/Q2 Predictions Std        35.3614
trainer/Q2 Predictions Max       -23.1204
trainer/Q2 Predictions Min      -135.805
trainer/Q Targets Mean           -76.7412
trainer/Q Targets Std             36.6732
trainer/Q Targets Max             -0.207864
trainer/Q Targets Min           -135.584
trainer/Log Pis Mean               2.00844
trainer/Log Pis Std                1.72707
trainer/Log Pis Max                8.55697
trainer/Log Pis Min               -2.01049
trainer/Policy mu Mean             0.0783984
trainer/Policy mu Std              0.922945
trainer/Policy mu Max              3.51552
trainer/Policy mu Min             -2.92914
trainer/Policy log std Mean       -1.8707
trainer/Policy log std Std         0.570644
trainer/Policy log std Max        -0.3698
trainer/Policy log std Min        -2.67372
trainer/Alpha                      0.0648154
trainer/Alpha Loss                 0.0230989
exploration/num steps total    19700
exploration/num paths total      197
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.08381
exploration/Rewards Std            1.94121
exploration/Rewards Max           -0.0130376
exploration/Rewards Min           -5.00414
exploration/Returns Mean        -208.381
exploration/Returns Std          188.124
exploration/Returns Max          -27.6401
exploration/Returns Min         -436.413
exploration/Actions Mean           0.00173927
exploration/Actions Std            0.19852
exploration/Actions Max            0.995491
exploration/Actions Min           -0.993683
exploration/Num Paths              5
exploration/Average Returns     -208.381
evaluation/num steps total     58500
evaluation/num paths total       585
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.55945
evaluation/Rewards Std             1.48863
evaluation/Rewards Max            -0.121832
evaluation/Rewards Min           -10.9878
evaluation/Returns Mean         -155.945
evaluation/Returns Std           107.166
evaluation/Returns Max           -49.4644
evaluation/Returns Min          -448.413
evaluation/Actions Mean            0.0124707
evaluation/Actions Std             0.200099
evaluation/Actions Max             0.998805
evaluation/Actions Min            -0.998677
evaluation/Num Paths              15
evaluation/Average Returns      -155.945
time/data storing (s)              0.00290663
time/evaluation sampling (s)       0.331692
time/exploration sampling (s)      0.14243
time/logging (s)                   0.00478627
time/saving (s)                    0.00195016
time/training (s)                  1.92661
time/epoch (s)                     2.41037
time/total (s)                   100.677
Epoch                             38
-----------------------------  --------------
2019-04-22 23:28:56.757171 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 39 finished
-----------------------------  --------------
replay_buffer/size             20200
trainer/QF1 Loss                  94.9105
trainer/QF2 Loss                  94.8118
trainer/Policy Loss               75.1024
trainer/Q1 Predictions Mean      -74.0073
trainer/Q1 Predictions Std        35.3428
trainer/Q1 Predictions Max       -22.5953
trainer/Q1 Predictions Min      -150.064
trainer/Q2 Predictions Mean      -74.0735
trainer/Q2 Predictions Std        35.4266
trainer/Q2 Predictions Max       -22.4847
trainer/Q2 Predictions Min      -151.634
trainer/Q Targets Mean           -74.0033
trainer/Q Targets Std             36.1852
trainer/Q Targets Max             -2.99793
trainer/Q Targets Min           -155.829
trainer/Log Pis Mean               2.19815
trainer/Log Pis Std                1.84894
trainer/Log Pis Max                8.80043
trainer/Log Pis Min               -1.5443
trainer/Policy mu Mean             0.176433
trainer/Policy mu Std              0.97495
trainer/Policy mu Max              3.50559
trainer/Policy mu Min             -3.03754
trainer/Policy log std Mean       -1.88352
trainer/Policy log std Std         0.601062
trainer/Policy log std Max        -0.196727
trainer/Policy log std Min        -2.72081
trainer/Alpha                      0.0642867
trainer/Alpha Loss                 0.543814
exploration/num steps total    20200
exploration/num paths total      202
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.43285
exploration/Rewards Std            0.967455
exploration/Rewards Max           -0.0737814
exploration/Rewards Min           -9.08573
exploration/Returns Mean        -143.285
exploration/Returns Std           33.3752
exploration/Returns Max         -107.438
exploration/Returns Min         -193.179
exploration/Actions Mean           0.0128328
exploration/Actions Std            0.228719
exploration/Actions Max            0.998004
exploration/Actions Min           -0.906078
exploration/Num Paths              5
exploration/Average Returns     -143.285
evaluation/num steps total     60000
evaluation/num paths total       600
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.07362
evaluation/Rewards Std             1.18229
evaluation/Rewards Max            -0.0430186
evaluation/Rewards Min            -9.80458
evaluation/Returns Mean         -207.362
evaluation/Returns Std            87.0848
evaluation/Returns Max           -35.9843
evaluation/Returns Min          -310.957
evaluation/Actions Mean            0.00806924
evaluation/Actions Std             0.181085
evaluation/Actions Max             0.993022
evaluation/Actions Min            -0.996279
evaluation/Num Paths              15
evaluation/Average Returns      -207.362
time/data storing (s)              0.00287665
time/evaluation sampling (s)       0.329423
time/exploration sampling (s)      0.141768
time/logging (s)                   0.00478367
time/saving (s)                    0.00195205
time/training (s)                  1.92868
time/epoch (s)                     2.40948
time/total (s)                   103.09
Epoch                             39
-----------------------------  --------------
2019-04-22 23:28:59.169249 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 40 finished
-----------------------------  --------------
replay_buffer/size             20700
trainer/QF1 Loss                   2.29128
trainer/QF2 Loss                   2.17919
trainer/Policy Loss               82.6189
trainer/Q1 Predictions Mean      -81.6131
trainer/Q1 Predictions Std        33.7303
trainer/Q1 Predictions Max       -23.4267
trainer/Q1 Predictions Min      -140.062
trainer/Q2 Predictions Mean      -81.5787
trainer/Q2 Predictions Std        33.7233
trainer/Q2 Predictions Max       -23.3829
trainer/Q2 Predictions Min      -140.229
trainer/Q Targets Mean           -82.4205
trainer/Q Targets Std             34.2378
trainer/Q Targets Max            -23.7509
trainer/Q Targets Min           -140.722
trainer/Log Pis Mean               1.94833
trainer/Log Pis Std                1.36117
trainer/Log Pis Max                6.16388
trainer/Log Pis Min               -2.1236
trainer/Policy mu Mean             0.0114308
trainer/Policy mu Std              0.88611
trainer/Policy mu Max              3.10567
trainer/Policy mu Min             -3.25786
trainer/Policy log std Mean       -1.8577
trainer/Policy log std Std         0.51284
trainer/Policy log std Max        -0.379139
trainer/Policy log std Min        -2.66597
trainer/Alpha                      0.0627822
trainer/Alpha Loss                -0.143031
exploration/num steps total    20700
exploration/num paths total      207
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.18535
exploration/Rewards Std            1.18176
exploration/Rewards Max           -0.301494
exploration/Rewards Min           -8.07641
exploration/Returns Mean        -218.535
exploration/Returns Std          102.682
exploration/Returns Max          -63.4924
exploration/Returns Min         -340.325
exploration/Actions Mean           0.0257662
exploration/Actions Std            0.238344
exploration/Actions Max            0.976291
exploration/Actions Min           -0.97906
exploration/Num Paths              5
exploration/Average Returns     -218.535
evaluation/num steps total     61500
evaluation/num paths total       615
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.08371
evaluation/Rewards Std             1.00896
evaluation/Rewards Max            -0.0831218
evaluation/Rewards Min           -10.1847
evaluation/Returns Mean         -108.371
evaluation/Returns Std            56.2156
evaluation/Returns Max           -29.9523
evaluation/Returns Min          -216.493
evaluation/Actions Mean            0.00766783
evaluation/Actions Std             0.164222
evaluation/Actions Max             0.997558
evaluation/Actions Min            -0.998006
evaluation/Num Paths              15
evaluation/Average Returns      -108.371
time/data storing (s)              0.00279492
time/evaluation sampling (s)       0.324883
time/exploration sampling (s)      0.143586
time/logging (s)                   0.00477713
time/saving (s)                    0.00194236
time/training (s)                  1.92851
time/epoch (s)                     2.4065
time/total (s)                   105.501
Epoch                             40
-----------------------------  --------------
2019-04-22 23:29:01.568592 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 41 finished
-----------------------------  --------------
replay_buffer/size             21200
trainer/QF1 Loss                   1.25513
trainer/QF2 Loss                   1.16405
trainer/Policy Loss               79.7578
trainer/Q1 Predictions Mean      -78.9527
trainer/Q1 Predictions Std        35.1066
trainer/Q1 Predictions Max       -24.1808
trainer/Q1 Predictions Min      -146.917
trainer/Q2 Predictions Mean      -79.08
trainer/Q2 Predictions Std        35.1189
trainer/Q2 Predictions Max       -24.1085
trainer/Q2 Predictions Min      -148.122
trainer/Q Targets Mean           -79.5957
trainer/Q Targets Std             35.5934
trainer/Q Targets Max            -23.75
trainer/Q Targets Min           -149.093
trainer/Log Pis Mean               1.91794
trainer/Log Pis Std                2.04779
trainer/Log Pis Max               10.9321
trainer/Log Pis Min               -2.47752
trainer/Policy mu Mean             0.183424
trainer/Policy mu Std              0.927003
trainer/Policy mu Max              3.58776
trainer/Policy mu Min             -2.74678
trainer/Policy log std Mean       -1.88164
trainer/Policy log std Std         0.557173
trainer/Policy log std Max        -0.347068
trainer/Policy log std Min        -2.7012
trainer/Alpha                      0.0596489
trainer/Alpha Loss                -0.231343
exploration/num steps total    21200
exploration/num paths total      212
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.91856
exploration/Rewards Std            1.67481
exploration/Rewards Max           -0.0311998
exploration/Rewards Min           -9.72307
exploration/Returns Mean        -191.856
exploration/Returns Std          151.696
exploration/Returns Max          -31.6262
exploration/Returns Min         -458.59
exploration/Actions Mean          -0.0151655
exploration/Actions Std            0.230799
exploration/Actions Max            0.933908
exploration/Actions Min           -0.995631
exploration/Num Paths              5
exploration/Average Returns     -191.856
evaluation/num steps total     63000
evaluation/num paths total       630
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.06508
evaluation/Rewards Std             0.947156
evaluation/Rewards Max            -0.0819389
evaluation/Rewards Min           -10.0684
evaluation/Returns Mean         -106.508
evaluation/Returns Std            63.1736
evaluation/Returns Max           -25.8889
evaluation/Returns Min          -250.288
evaluation/Actions Mean           -0.00960374
evaluation/Actions Std             0.159686
evaluation/Actions Max             0.996625
evaluation/Actions Min            -0.995997
evaluation/Num Paths              15
evaluation/Average Returns      -106.508
time/data storing (s)              0.00290665
time/evaluation sampling (s)       0.332564
time/exploration sampling (s)      0.142769
time/logging (s)                   0.00480818
time/saving (s)                    0.00199841
time/training (s)                  1.90931
time/epoch (s)                     2.39436
time/total (s)                   107.899
Epoch                             41
-----------------------------  --------------
2019-04-22 23:29:03.984103 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 42 finished
-----------------------------  --------------
replay_buffer/size             21700
trainer/QF1 Loss                 138.272
trainer/QF2 Loss                 137.364
trainer/Policy Loss               76.0201
trainer/Q1 Predictions Mean      -74.8231
trainer/Q1 Predictions Std        34.5311
trainer/Q1 Predictions Max       -23.9562
trainer/Q1 Predictions Min      -131.881
trainer/Q2 Predictions Mean      -74.8346
trainer/Q2 Predictions Std        34.5985
trainer/Q2 Predictions Max       -23.6691
trainer/Q2 Predictions Min      -132.288
trainer/Q Targets Mean           -74.2661
trainer/Q Targets Std             35.3243
trainer/Q Targets Max             -2.28935
trainer/Q Targets Min           -133.366
trainer/Log Pis Mean               2.21884
trainer/Log Pis Std                1.78847
trainer/Log Pis Max                8.15383
trainer/Log Pis Min               -3.61041
trainer/Policy mu Mean            -0.0459192
trainer/Policy mu Std              0.986739
trainer/Policy mu Max              3.11043
trainer/Policy mu Min             -2.95536
trainer/Policy log std Mean       -1.88241
trainer/Policy log std Std         0.577473
trainer/Policy log std Max        -0.245578
trainer/Policy log std Min        -2.8172
trainer/Alpha                      0.059517
trainer/Alpha Loss                 0.617501
exploration/num steps total    21700
exploration/num paths total      217
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.06274
exploration/Rewards Std            0.861215
exploration/Rewards Max           -0.0200895
exploration/Rewards Min           -9.10489
exploration/Returns Mean        -106.274
exploration/Returns Std           41.3997
exploration/Returns Max          -51.3619
exploration/Returns Min         -149.655
exploration/Actions Mean           0.0183001
exploration/Actions Std            0.249919
exploration/Actions Max            0.990822
exploration/Actions Min           -0.997281
exploration/Num Paths              5
exploration/Average Returns     -106.274
evaluation/num steps total     64500
evaluation/num paths total       645
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.36096
evaluation/Rewards Std             1.29133
evaluation/Rewards Max            -0.0847079
evaluation/Rewards Min           -10.6899
evaluation/Returns Mean         -136.096
evaluation/Returns Std            84.8163
evaluation/Returns Max           -13.4646
evaluation/Returns Min          -269.02
evaluation/Actions Mean           -0.007284
evaluation/Actions Std             0.189138
evaluation/Actions Max             0.997563
evaluation/Actions Min            -0.997289
evaluation/Num Paths              15
evaluation/Average Returns      -136.096
time/data storing (s)              0.00306025
time/evaluation sampling (s)       0.33175
time/exploration sampling (s)      0.14165
time/logging (s)                   0.0048591
time/saving (s)                    0.00198309
time/training (s)                  1.92674
time/epoch (s)                     2.41005
time/total (s)                   110.313
Epoch                             42
-----------------------------  --------------
2019-04-22 23:29:06.398799 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 43 finished
-----------------------------  --------------
replay_buffer/size             22200
trainer/QF1 Loss                   2.41
trainer/QF2 Loss                   2.24083
trainer/Policy Loss               85.4174
trainer/Q1 Predictions Mean      -84.2809
trainer/Q1 Predictions Std        35.0245
trainer/Q1 Predictions Max       -23.6521
trainer/Q1 Predictions Min      -132.1
trainer/Q2 Predictions Mean      -84.3012
trainer/Q2 Predictions Std        34.9952
trainer/Q2 Predictions Max       -23.6145
trainer/Q2 Predictions Min      -131.705
trainer/Q Targets Mean           -85.0622
trainer/Q Targets Std             35.2547
trainer/Q Targets Max            -23.7237
trainer/Q Targets Min           -135.305
trainer/Log Pis Mean               2.01468
trainer/Log Pis Std                1.36042
trainer/Log Pis Max                7.12783
trainer/Log Pis Min               -1.08089
trainer/Policy mu Mean            -0.0555064
trainer/Policy mu Std              0.870897
trainer/Policy mu Max              2.68935
trainer/Policy mu Min             -3.14658
trainer/Policy log std Mean       -1.85879
trainer/Policy log std Std         0.537886
trainer/Policy log std Max        -0.3278
trainer/Policy log std Min        -2.91269
trainer/Alpha                      0.0589543
trainer/Alpha Loss                 0.0415487
exploration/num steps total    22200
exploration/num paths total      222
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.10298
exploration/Rewards Std            1.25481
exploration/Rewards Max           -0.0245777
exploration/Rewards Min           -9.39586
exploration/Returns Mean        -110.298
exploration/Returns Std           37.2168
exploration/Returns Max          -64.8458
exploration/Returns Min         -168.257
exploration/Actions Mean           0.0226573
exploration/Actions Std            0.268356
exploration/Actions Max            0.996783
exploration/Actions Min           -0.999893
exploration/Num Paths              5
exploration/Average Returns     -110.298
evaluation/num steps total     66000
evaluation/num paths total       660
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.3257
evaluation/Rewards Std             1.25276
evaluation/Rewards Max            -0.0394962
evaluation/Rewards Min           -11.4013
evaluation/Returns Mean         -132.57
evaluation/Returns Std            91.1918
evaluation/Returns Max           -20.9364
evaluation/Returns Min          -314.247
evaluation/Actions Mean           -0.0109124
evaluation/Actions Std             0.188706
evaluation/Actions Max             0.997148
evaluation/Actions Min            -0.99848
evaluation/Num Paths              15
evaluation/Average Returns      -132.57
time/data storing (s)              0.00305036
time/evaluation sampling (s)       0.327035
time/exploration sampling (s)      0.14334
time/logging (s)                   0.00482687
time/saving (s)                    0.00196307
time/training (s)                  1.92884
time/epoch (s)                     2.40905
time/total (s)                   112.727
Epoch                             43
-----------------------------  --------------
2019-04-22 23:29:08.806174 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 44 finished
-----------------------------  --------------
replay_buffer/size             22700
trainer/QF1 Loss                  52.2586
trainer/QF2 Loss                  53.2548
trainer/Policy Loss               76.7056
trainer/Q1 Predictions Mean      -75.9218
trainer/Q1 Predictions Std        35.82
trainer/Q1 Predictions Max       -23.7072
trainer/Q1 Predictions Min      -146.192
trainer/Q2 Predictions Mean      -75.9151
trainer/Q2 Predictions Std        35.7637
trainer/Q2 Predictions Max       -23.5617
trainer/Q2 Predictions Min      -145.397
trainer/Q Targets Mean           -76.039
trainer/Q Targets Std             37.5374
trainer/Q Targets Max             -0.0814506
trainer/Q Targets Min           -145.27
trainer/Log Pis Mean               1.83316
trainer/Log Pis Std                1.6605
trainer/Log Pis Max                7.67687
trainer/Log Pis Min               -3.2032
trainer/Policy mu Mean             0.0750033
trainer/Policy mu Std              0.889898
trainer/Policy mu Max              2.69188
trainer/Policy mu Min             -3.12328
trainer/Policy log std Mean       -1.80163
trainer/Policy log std Std         0.531042
trainer/Policy log std Max        -0.379154
trainer/Policy log std Min        -2.65869
trainer/Alpha                      0.0566442
trainer/Alpha Loss                -0.478944
exploration/num steps total    22700
exploration/num paths total      227
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.0596
exploration/Rewards Std            0.87828
exploration/Rewards Max           -0.0773837
exploration/Rewards Min           -7.10414
exploration/Returns Mean        -105.96
exploration/Returns Std           72.9215
exploration/Returns Max          -43.7682
exploration/Returns Min         -216.094
exploration/Actions Mean           0.0135339
exploration/Actions Std            0.231268
exploration/Actions Max            0.986132
exploration/Actions Min           -0.969533
exploration/Num Paths              5
exploration/Average Returns     -105.96
evaluation/num steps total     67500
evaluation/num paths total       675
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.28683
evaluation/Rewards Std             1.12336
evaluation/Rewards Max            -0.150782
evaluation/Rewards Min           -10.7003
evaluation/Returns Mean         -128.683
evaluation/Returns Std            52.5144
evaluation/Returns Max           -59.995
evaluation/Returns Min          -215.714
evaluation/Actions Mean            0.014841
evaluation/Actions Std             0.193784
evaluation/Actions Max             0.998338
evaluation/Actions Min            -0.996547
evaluation/Num Paths              15
evaluation/Average Returns      -128.683
time/data storing (s)              0.00294055
time/evaluation sampling (s)       0.328121
time/exploration sampling (s)      0.141481
time/logging (s)                   0.00481858
time/saving (s)                    0.00197165
time/training (s)                  1.92245
time/epoch (s)                     2.40178
time/total (s)                   115.133
Epoch                             44
-----------------------------  --------------
2019-04-22 23:29:11.210006 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 45 finished
-----------------------------  --------------
replay_buffer/size             23200
trainer/QF1 Loss                   1.66371
trainer/QF2 Loss                   1.4888
trainer/Policy Loss               75.656
trainer/Q1 Predictions Mean      -74.49
trainer/Q1 Predictions Std        36.9716
trainer/Q1 Predictions Max       -24.2182
trainer/Q1 Predictions Min      -159.977
trainer/Q2 Predictions Mean      -74.4981
trainer/Q2 Predictions Std        36.9668
trainer/Q2 Predictions Max       -24.1839
trainer/Q2 Predictions Min      -160.349
trainer/Q Targets Mean           -75.3274
trainer/Q Targets Std             37.4342
trainer/Q Targets Max            -24.1837
trainer/Q Targets Min           -161.913
trainer/Log Pis Mean               2.24456
trainer/Log Pis Std                1.85069
trainer/Log Pis Max                8.16572
trainer/Log Pis Min               -2.82045
trainer/Policy mu Mean             0.0154628
trainer/Policy mu Std              1.06669
trainer/Policy mu Max              2.82788
trainer/Policy mu Min             -3.42429
trainer/Policy log std Mean       -1.85579
trainer/Policy log std Std         0.606594
trainer/Policy log std Max        -0.372581
trainer/Policy log std Min        -2.88376
trainer/Alpha                      0.0557333
trainer/Alpha Loss                 0.706148
exploration/num steps total    23200
exploration/num paths total      232
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.07478
exploration/Rewards Std            1.04433
exploration/Rewards Max           -0.603888
exploration/Rewards Min          -10.196
exploration/Returns Mean        -207.478
exploration/Returns Std           65.5327
exploration/Returns Max          -89.4049
exploration/Returns Min         -274.217
exploration/Actions Mean           0.00158734
exploration/Actions Std            0.234599
exploration/Actions Max            0.997342
exploration/Actions Min           -0.999314
exploration/Num Paths              5
exploration/Average Returns     -207.478
evaluation/num steps total     69000
evaluation/num paths total       690
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.37906
evaluation/Rewards Std             1.33648
evaluation/Rewards Max            -0.109841
evaluation/Rewards Min           -10.0994
evaluation/Returns Mean         -137.906
evaluation/Returns Std            99.8722
evaluation/Returns Max           -25.231
evaluation/Returns Min          -290.199
evaluation/Actions Mean           -0.00487255
evaluation/Actions Std             0.179102
evaluation/Actions Max             0.999363
evaluation/Actions Min            -0.997205
evaluation/Num Paths              15
evaluation/Average Returns      -137.906
time/data storing (s)              0.00297132
time/evaluation sampling (s)       0.3303
time/exploration sampling (s)      0.143099
time/logging (s)                   0.00466724
time/saving (s)                    0.00193288
time/training (s)                  1.91527
time/epoch (s)                     2.39825
time/total (s)                   117.535
Epoch                             45
-----------------------------  --------------
2019-04-22 23:29:13.622966 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 46 finished
-----------------------------  --------------
replay_buffer/size             23700
trainer/QF1 Loss                   1.07781
trainer/QF2 Loss                   1.08206
trainer/Policy Loss               80.5362
trainer/Q1 Predictions Mean      -79.3416
trainer/Q1 Predictions Std        35.9835
trainer/Q1 Predictions Max       -24.7981
trainer/Q1 Predictions Min      -134.977
trainer/Q2 Predictions Mean      -79.3709
trainer/Q2 Predictions Std        36.0238
trainer/Q2 Predictions Max       -24.8016
trainer/Q2 Predictions Min      -138.081
trainer/Q Targets Mean           -79.8402
trainer/Q Targets Std             36.3386
trainer/Q Targets Max            -24.6799
trainer/Q Targets Min           -136.795
trainer/Log Pis Mean               2.20633
trainer/Log Pis Std                1.75418
trainer/Log Pis Max                8.62777
trainer/Log Pis Min               -1.25928
trainer/Policy mu Mean             0.0405821
trainer/Policy mu Std              1.01184
trainer/Policy mu Max              3.0191
trainer/Policy mu Min             -4.47018
trainer/Policy log std Mean       -1.81944
trainer/Policy log std Std         0.555443
trainer/Policy log std Max        -0.444154
trainer/Policy log std Min        -2.72475
trainer/Alpha                      0.0541304
trainer/Alpha Loss                 0.601753
exploration/num steps total    23700
exploration/num paths total      237
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.16177
exploration/Rewards Std            0.900449
exploration/Rewards Max           -0.0259658
exploration/Rewards Min           -8.34763
exploration/Returns Mean        -116.177
exploration/Returns Std           60.1176
exploration/Returns Max          -29.8505
exploration/Returns Min         -199.273
exploration/Actions Mean          -0.006483
exploration/Actions Std            0.221355
exploration/Actions Max            0.999547
exploration/Actions Min           -0.998766
exploration/Num Paths              5
exploration/Average Returns     -116.177
evaluation/num steps total     70500
evaluation/num paths total       705
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.49229
evaluation/Rewards Std             1.11265
evaluation/Rewards Max            -0.122771
evaluation/Rewards Min           -11.5842
evaluation/Returns Mean         -149.229
evaluation/Returns Std            71.0549
evaluation/Returns Max           -30.8597
evaluation/Returns Min          -251.788
evaluation/Actions Mean           -0.0107286
evaluation/Actions Std             0.181629
evaluation/Actions Max             0.995932
evaluation/Actions Min            -0.998674
evaluation/Num Paths              15
evaluation/Average Returns      -149.229
time/data storing (s)              0.00302861
time/evaluation sampling (s)       0.324755
time/exploration sampling (s)      0.143972
time/logging (s)                   0.0047715
time/saving (s)                    0.0119231
time/training (s)                  1.91929
time/epoch (s)                     2.40774
time/total (s)                   119.947
Epoch                             46
-----------------------------  --------------
2019-04-22 23:29:16.030085 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 47 finished
-----------------------------  --------------
replay_buffer/size             24200
trainer/QF1 Loss                 301.181
trainer/QF2 Loss                 300.353
trainer/Policy Loss               79.5107
trainer/Q1 Predictions Mean      -78.5914
trainer/Q1 Predictions Std        35.6878
trainer/Q1 Predictions Max       -24.9152
trainer/Q1 Predictions Min      -149.986
trainer/Q2 Predictions Mean      -78.5918
trainer/Q2 Predictions Std        35.6278
trainer/Q2 Predictions Max       -24.7219
trainer/Q2 Predictions Min      -149.46
trainer/Q Targets Mean           -75.9974
trainer/Q Targets Std             37.6666
trainer/Q Targets Max             -1.27421
trainer/Q Targets Min           -152.075
trainer/Log Pis Mean               1.67493
trainer/Log Pis Std                1.64613
trainer/Log Pis Max                6.67481
trainer/Log Pis Min               -3.00363
trainer/Policy mu Mean            -0.0554393
trainer/Policy mu Std              0.810399
trainer/Policy mu Max              3.06121
trainer/Policy mu Min             -3.02131
trainer/Policy log std Mean       -1.84194
trainer/Policy log std Std         0.486088
trainer/Policy log std Max        -0.179084
trainer/Policy log std Min        -2.77772
trainer/Alpha                      0.0551857
trainer/Alpha Loss                -0.941722
exploration/num steps total    24200
exploration/num paths total      242
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.43405
exploration/Rewards Std            1.09362
exploration/Rewards Max           -0.0108023
exploration/Rewards Min           -8.03794
exploration/Returns Mean        -143.405
exploration/Returns Std           52.2828
exploration/Returns Max          -64.7898
exploration/Returns Min         -187.629
exploration/Actions Mean          -0.0138944
exploration/Actions Std            0.283051
exploration/Actions Max            0.992774
exploration/Actions Min           -0.998001
exploration/Num Paths              5
exploration/Average Returns     -143.405
evaluation/num steps total     72000
evaluation/num paths total       720
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.19378
evaluation/Rewards Std             1.03205
evaluation/Rewards Max            -0.534131
evaluation/Rewards Min           -10.2774
evaluation/Returns Mean         -119.378
evaluation/Returns Std            57.0645
evaluation/Returns Max           -63.1917
evaluation/Returns Min          -274.166
evaluation/Actions Mean            0.0130287
evaluation/Actions Std             0.182143
evaluation/Actions Max             0.99844
evaluation/Actions Min            -0.997394
evaluation/Num Paths              15
evaluation/Average Returns      -119.378
time/data storing (s)              0.00293345
time/evaluation sampling (s)       0.325419
time/exploration sampling (s)      0.143795
time/logging (s)                   0.00478483
time/saving (s)                    0.0019587
time/training (s)                  1.92241
time/epoch (s)                     2.4013
time/total (s)                   122.353
Epoch                             47
-----------------------------  --------------
2019-04-22 23:29:18.432241 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 48 finished
-----------------------------  --------------
replay_buffer/size             24700
trainer/QF1 Loss                   2.00691
trainer/QF2 Loss                   1.92602
trainer/Policy Loss               76.6885
trainer/Q1 Predictions Mean      -75.5966
trainer/Q1 Predictions Std        36.8603
trainer/Q1 Predictions Max       -24.6379
trainer/Q1 Predictions Min      -125.508
trainer/Q2 Predictions Mean      -75.5827
trainer/Q2 Predictions Std        36.874
trainer/Q2 Predictions Max       -24.6184
trainer/Q2 Predictions Min      -125.572
trainer/Q Targets Mean           -76.5724
trainer/Q Targets Std             37.2556
trainer/Q Targets Max            -24.6236
trainer/Q Targets Min           -127.967
trainer/Log Pis Mean               1.77127
trainer/Log Pis Std                1.52626
trainer/Log Pis Max               10.2895
trainer/Log Pis Min               -2.2925
trainer/Policy mu Mean             0.102258
trainer/Policy mu Std              0.781874
trainer/Policy mu Max              3.41594
trainer/Policy mu Min             -2.0487
trainer/Policy log std Mean       -1.80191
trainer/Policy log std Std         0.479572
trainer/Policy log std Max        -0.433088
trainer/Policy log std Min        -2.72457
trainer/Alpha                      0.0536854
trainer/Alpha Loss                -0.668918
exploration/num steps total    24700
exploration/num paths total      247
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.29514
exploration/Rewards Std            0.781896
exploration/Rewards Max           -0.363081
exploration/Rewards Min           -8.19241
exploration/Returns Mean        -129.514
exploration/Returns Std           45.5829
exploration/Returns Max          -70.3811
exploration/Returns Min         -193.993
exploration/Actions Mean          -0.00176889
exploration/Actions Std            0.242298
exploration/Actions Max            0.980187
exploration/Actions Min           -0.999238
exploration/Num Paths              5
exploration/Average Returns     -129.514
evaluation/num steps total     73500
evaluation/num paths total       735
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.967141
evaluation/Rewards Std             0.870641
evaluation/Rewards Max            -0.104373
evaluation/Rewards Min            -9.28189
evaluation/Returns Mean          -96.7141
evaluation/Returns Std            54.8262
evaluation/Returns Max           -45.9234
evaluation/Returns Min          -186.502
evaluation/Actions Mean            0.00442524
evaluation/Actions Std             0.159027
evaluation/Actions Max             0.997337
evaluation/Actions Min            -0.994215
evaluation/Num Paths              15
evaluation/Average Returns       -96.7141
time/data storing (s)              0.00296485
time/evaluation sampling (s)       0.327664
time/exploration sampling (s)      0.144383
time/logging (s)                   0.00481029
time/saving (s)                    0.00156224
time/training (s)                  1.91486
time/epoch (s)                     2.39624
time/total (s)                   124.754
Epoch                             48
-----------------------------  --------------
2019-04-22 23:29:20.824552 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 49 finished
-----------------------------  --------------
replay_buffer/size             25200
trainer/QF1 Loss                 471.538
trainer/QF2 Loss                 472.635
trainer/Policy Loss               84.6222
trainer/Q1 Predictions Mean      -83.4378
trainer/Q1 Predictions Std        36.9348
trainer/Q1 Predictions Max       -25.1674
trainer/Q1 Predictions Min      -148.527
trainer/Q2 Predictions Mean      -83.473
trainer/Q2 Predictions Std        37.0015
trainer/Q2 Predictions Max       -25.224
trainer/Q2 Predictions Min      -147.769
trainer/Q Targets Mean           -79.7394
trainer/Q Targets Std             40.2238
trainer/Q Targets Max             -2.18796
trainer/Q Targets Min           -150.222
trainer/Log Pis Mean               1.99722
trainer/Log Pis Std                1.42769
trainer/Log Pis Max                6.86496
trainer/Log Pis Min               -2.0007
trainer/Policy mu Mean            -0.0963615
trainer/Policy mu Std              0.86611
trainer/Policy mu Max              3.0664
trainer/Policy mu Min             -3.61785
trainer/Policy log std Mean       -1.90314
trainer/Policy log std Std         0.512572
trainer/Policy log std Max        -0.470396
trainer/Policy log std Min        -2.91537
trainer/Alpha                      0.0541104
trainer/Alpha Loss                -0.00809752
exploration/num steps total    25200
exploration/num paths total      252
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.85923
exploration/Rewards Std            1.21356
exploration/Rewards Max           -0.181879
exploration/Rewards Min          -10.8414
exploration/Returns Mean        -185.923
exploration/Returns Std           52.5675
exploration/Returns Max          -88.1154
exploration/Returns Min         -228.425
exploration/Actions Mean          -0.00702764
exploration/Actions Std            0.265652
exploration/Actions Max            0.997166
exploration/Actions Min           -0.998593
exploration/Num Paths              5
exploration/Average Returns     -185.923
evaluation/num steps total     75000
evaluation/num paths total       750
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.49012
evaluation/Rewards Std             0.875008
evaluation/Rewards Max            -0.0774946
evaluation/Rewards Min            -7.90879
evaluation/Returns Mean         -149.012
evaluation/Returns Std            64.3559
evaluation/Returns Max           -24.1869
evaluation/Returns Min          -211.965
evaluation/Actions Mean           -0.0115941
evaluation/Actions Std             0.166742
evaluation/Actions Max             0.994119
evaluation/Actions Min            -0.998669
evaluation/Num Paths              15
evaluation/Average Returns      -149.012
time/data storing (s)              0.00288231
time/evaluation sampling (s)       0.331565
time/exploration sampling (s)      0.141765
time/logging (s)                   0.00482844
time/saving (s)                    0.00195835
time/training (s)                  1.90342
time/epoch (s)                     2.38642
time/total (s)                   127.145
Epoch                             49
-----------------------------  --------------
2019-04-22 23:29:23.225639 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 50 finished
-----------------------------  ---------------
replay_buffer/size             25700
trainer/QF1 Loss                  20.8327
trainer/QF2 Loss                  21.6172
trainer/Policy Loss               79.7675
trainer/Q1 Predictions Mean      -78.6418
trainer/Q1 Predictions Std        37.7734
trainer/Q1 Predictions Max       -25.6708
trainer/Q1 Predictions Min      -137.545
trainer/Q2 Predictions Mean      -78.6029
trainer/Q2 Predictions Std        37.7868
trainer/Q2 Predictions Max       -25.5602
trainer/Q2 Predictions Min      -136.472
trainer/Q Targets Mean           -78.6802
trainer/Q Targets Std             38.8019
trainer/Q Targets Max             -2.55519
trainer/Q Targets Min           -137.301
trainer/Log Pis Mean               1.88519
trainer/Log Pis Std                1.56272
trainer/Log Pis Max                7.85648
trainer/Log Pis Min               -2.68905
trainer/Policy mu Mean             0.134455
trainer/Policy mu Std              0.809073
trainer/Policy mu Max              3.53271
trainer/Policy mu Min             -2.4679
trainer/Policy log std Mean       -1.90646
trainer/Policy log std Std         0.547874
trainer/Policy log std Max        -0.294768
trainer/Policy log std Min        -3.00717
trainer/Alpha                      0.0555001
trainer/Alpha Loss                -0.331952
exploration/num steps total    25700
exploration/num paths total      257
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.48477
exploration/Rewards Std            1.16409
exploration/Rewards Max           -0.0192183
exploration/Rewards Min          -11.2636
exploration/Returns Mean        -148.477
exploration/Returns Std           65.6959
exploration/Returns Max          -55.1155
exploration/Returns Min         -241.43
exploration/Actions Mean          -0.0112962
exploration/Actions Std            0.270626
exploration/Actions Max            0.999691
exploration/Actions Min           -0.998652
exploration/Num Paths              5
exploration/Average Returns     -148.477
evaluation/num steps total     76500
evaluation/num paths total       765
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.30513
evaluation/Rewards Std             0.952585
evaluation/Rewards Max            -0.129111
evaluation/Rewards Min            -8.7659
evaluation/Returns Mean         -130.513
evaluation/Returns Std            58.2035
evaluation/Returns Max           -28.1373
evaluation/Returns Min          -210.38
evaluation/Actions Mean           -0.000727357
evaluation/Actions Std             0.160942
evaluation/Actions Max             0.997294
evaluation/Actions Min            -0.999271
evaluation/Num Paths              15
evaluation/Average Returns      -130.513
time/data storing (s)              0.00303504
time/evaluation sampling (s)       0.331801
time/exploration sampling (s)      0.142734
time/logging (s)                   0.00478948
time/saving (s)                    0.00152823
time/training (s)                  1.91128
time/epoch (s)                     2.39517
time/total (s)                   129.544
Epoch                             50
-----------------------------  ---------------
2019-04-22 23:29:25.641628 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 51 finished
-----------------------------  --------------
replay_buffer/size             26200
trainer/QF1 Loss                  19.0284
trainer/QF2 Loss                  19.5207
trainer/Policy Loss               72.7744
trainer/Q1 Predictions Mean      -71.7551
trainer/Q1 Predictions Std        36.6239
trainer/Q1 Predictions Max       -24.4569
trainer/Q1 Predictions Min      -125.994
trainer/Q2 Predictions Mean      -71.6801
trainer/Q2 Predictions Std        36.6232
trainer/Q2 Predictions Max       -24.481
trainer/Q2 Predictions Min      -125.41
trainer/Q Targets Mean           -72.428
trainer/Q Targets Std             37.8008
trainer/Q Targets Max             -1.22449
trainer/Q Targets Min           -129.432
trainer/Log Pis Mean               1.90336
trainer/Log Pis Std                1.63736
trainer/Log Pis Max                8.94716
trainer/Log Pis Min               -3.72086
trainer/Policy mu Mean            -0.0278504
trainer/Policy mu Std              0.814852
trainer/Policy mu Max              3.07267
trainer/Policy mu Min             -3.12827
trainer/Policy log std Mean       -1.89804
trainer/Policy log std Std         0.464452
trainer/Policy log std Max        -0.357012
trainer/Policy log std Min        -2.93777
trainer/Alpha                      0.0562901
trainer/Alpha Loss                -0.278058
exploration/num steps total    26200
exploration/num paths total      262
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.68877
exploration/Rewards Std            0.596576
exploration/Rewards Max           -0.204094
exploration/Rewards Min           -4.70203
exploration/Returns Mean        -168.877
exploration/Returns Std           50.9841
exploration/Returns Max          -95.3133
exploration/Returns Min         -222.773
exploration/Actions Mean          -0.00214846
exploration/Actions Std            0.210543
exploration/Actions Max            0.992962
exploration/Actions Min           -0.982343
exploration/Num Paths              5
exploration/Average Returns     -168.877
evaluation/num steps total     78000
evaluation/num paths total       780
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.56137
evaluation/Rewards Std             1.22197
evaluation/Rewards Max            -0.0390916
evaluation/Rewards Min           -10.9091
evaluation/Returns Mean         -156.137
evaluation/Returns Std            76.5678
evaluation/Returns Max           -18.3656
evaluation/Returns Min          -248.119
evaluation/Actions Mean            0.00593059
evaluation/Actions Std             0.192402
evaluation/Actions Max             0.999539
evaluation/Actions Min            -0.996881
evaluation/Num Paths              15
evaluation/Average Returns      -156.137
time/data storing (s)              0.00300273
time/evaluation sampling (s)       0.331652
time/exploration sampling (s)      0.142198
time/logging (s)                   0.00484224
time/saving (s)                    0.00194006
time/training (s)                  1.92652
time/epoch (s)                     2.41016
time/total (s)                   131.959
Epoch                             51
-----------------------------  --------------
2019-04-22 23:29:28.048327 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 52 finished
-----------------------------  --------------
replay_buffer/size             26700
trainer/QF1 Loss                 112.566
trainer/QF2 Loss                 112.893
trainer/Policy Loss               74.6555
trainer/Q1 Predictions Mean      -73.5577
trainer/Q1 Predictions Std        36.0539
trainer/Q1 Predictions Max       -24.8035
trainer/Q1 Predictions Min      -126.386
trainer/Q2 Predictions Mean      -73.5121
trainer/Q2 Predictions Std        36.0093
trainer/Q2 Predictions Max       -24.6246
trainer/Q2 Predictions Min      -125.322
trainer/Q Targets Mean           -72.9843
trainer/Q Targets Std             36.6764
trainer/Q Targets Max             -4.23252
trainer/Q Targets Min           -129.035
trainer/Log Pis Mean               2.15761
trainer/Log Pis Std                1.60762
trainer/Log Pis Max                7.12592
trainer/Log Pis Min               -5.0369
trainer/Policy mu Mean            -0.03271
trainer/Policy mu Std              0.921022
trainer/Policy mu Max              3.36955
trainer/Policy mu Min             -3.6494
trainer/Policy log std Mean       -1.90311
trainer/Policy log std Std         0.587718
trainer/Policy log std Max        -0.341339
trainer/Policy log std Min        -3.04991
trainer/Alpha                      0.0580013
trainer/Alpha Loss                 0.448777
exploration/num steps total    26700
exploration/num paths total      267
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.16234
exploration/Rewards Std            1.08467
exploration/Rewards Max           -0.019035
exploration/Rewards Min           -9.47919
exploration/Returns Mean        -116.234
exploration/Returns Std           65.2403
exploration/Returns Max          -30.3889
exploration/Returns Min         -221.726
exploration/Actions Mean           0.00233758
exploration/Actions Std            0.223882
exploration/Actions Max            0.996672
exploration/Actions Min           -0.99932
exploration/Num Paths              5
exploration/Average Returns     -116.234
evaluation/num steps total     79500
evaluation/num paths total       795
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.15122
evaluation/Rewards Std             1.01644
evaluation/Rewards Max            -0.213816
evaluation/Rewards Min           -10.5026
evaluation/Returns Mean         -115.122
evaluation/Returns Std            62.2635
evaluation/Returns Max           -21.5665
evaluation/Returns Min          -229.098
evaluation/Actions Mean           -0.00171728
evaluation/Actions Std             0.17318
evaluation/Actions Max             0.998647
evaluation/Actions Min            -0.998423
evaluation/Num Paths              15
evaluation/Average Returns      -115.122
time/data storing (s)              0.0029398
time/evaluation sampling (s)       0.322447
time/exploration sampling (s)      0.143439
time/logging (s)                   0.00481394
time/saving (s)                    0.00196005
time/training (s)                  1.92509
time/epoch (s)                     2.40069
time/total (s)                   134.364
Epoch                             52
-----------------------------  --------------
2019-04-22 23:29:30.463877 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 53 finished
-----------------------------  --------------
replay_buffer/size             27200
trainer/QF1 Loss                  17.93
trainer/QF2 Loss                  18.3599
trainer/Policy Loss               72.5494
trainer/Q1 Predictions Mean      -71.4096
trainer/Q1 Predictions Std        34.729
trainer/Q1 Predictions Max       -24.3134
trainer/Q1 Predictions Min      -120.389
trainer/Q2 Predictions Mean      -71.4158
trainer/Q2 Predictions Std        34.7169
trainer/Q2 Predictions Max       -24.2587
trainer/Q2 Predictions Min      -120.579
trainer/Q Targets Mean           -71.9923
trainer/Q Targets Std             35.7071
trainer/Q Targets Max             -1.40346
trainer/Q Targets Min           -122.508
trainer/Log Pis Mean               2.08366
trainer/Log Pis Std                1.3144
trainer/Log Pis Max                6.29541
trainer/Log Pis Min               -1.12357
trainer/Policy mu Mean             0.0681372
trainer/Policy mu Std              0.956228
trainer/Policy mu Max              2.93436
trainer/Policy mu Min             -3.17986
trainer/Policy log std Mean       -1.79019
trainer/Policy log std Std         0.580795
trainer/Policy log std Max        -0.387331
trainer/Policy log std Min        -2.92249
trainer/Alpha                      0.0601649
trainer/Alpha Loss                 0.235132
exploration/num steps total    27200
exploration/num paths total      272
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.477752
exploration/Rewards Std            0.536041
exploration/Rewards Max           -0.0241275
exploration/Rewards Min           -5.43458
exploration/Returns Mean         -47.7752
exploration/Returns Std           13.6617
exploration/Returns Max          -33.37
exploration/Returns Min          -73.7124
exploration/Actions Mean          -0.0187667
exploration/Actions Std            0.19393
exploration/Actions Max            0.648679
exploration/Actions Min           -0.994485
exploration/Num Paths              5
exploration/Average Returns      -47.7752
evaluation/num steps total     81000
evaluation/num paths total       810
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.45942
evaluation/Rewards Std             1.14927
evaluation/Rewards Max            -0.232425
evaluation/Rewards Min           -10.7871
evaluation/Returns Mean         -145.942
evaluation/Returns Std            75.2101
evaluation/Returns Max           -29.9065
evaluation/Returns Min          -235.368
evaluation/Actions Mean           -0.0131068
evaluation/Actions Std             0.182662
evaluation/Actions Max             0.996485
evaluation/Actions Min            -0.997827
evaluation/Num Paths              15
evaluation/Average Returns      -145.942
time/data storing (s)              0.00302098
time/evaluation sampling (s)       0.325267
time/exploration sampling (s)      0.14266
time/logging (s)                   0.00481943
time/saving (s)                    0.00192437
time/training (s)                  1.93189
time/epoch (s)                     2.40958
time/total (s)                   136.778
Epoch                             53
-----------------------------  --------------
2019-04-22 23:29:32.848005 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 54 finished
-----------------------------  --------------
replay_buffer/size             27700
trainer/QF1 Loss                   3.00233
trainer/QF2 Loss                   3.25734
trainer/Policy Loss               73.9323
trainer/Q1 Predictions Mean      -72.8982
trainer/Q1 Predictions Std        36.6803
trainer/Q1 Predictions Max       -24.2893
trainer/Q1 Predictions Min      -143.075
trainer/Q2 Predictions Mean      -72.8472
trainer/Q2 Predictions Std        36.5438
trainer/Q2 Predictions Max       -24.3207
trainer/Q2 Predictions Min      -141.968
trainer/Q Targets Mean           -74.1525
trainer/Q Targets Std             37.131
trainer/Q Targets Max            -24.5397
trainer/Q Targets Min           -144.577
trainer/Log Pis Mean               2.00139
trainer/Log Pis Std                1.77681
trainer/Log Pis Max                9.28238
trainer/Log Pis Min               -3.12439
trainer/Policy mu Mean             0.049636
trainer/Policy mu Std              0.935416
trainer/Policy mu Max              3.15292
trainer/Policy mu Min             -3.44913
trainer/Policy log std Mean       -1.80939
trainer/Policy log std Std         0.553862
trainer/Policy log std Max        -0.494109
trainer/Policy log std Min        -2.98333
trainer/Alpha                      0.0602679
trainer/Alpha Loss                 0.00389145
exploration/num steps total    27700
exploration/num paths total      277
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.28944
exploration/Rewards Std            1.05339
exploration/Rewards Max           -0.0694041
exploration/Rewards Min          -10.2613
exploration/Returns Mean        -128.944
exploration/Returns Std           57.8169
exploration/Returns Max          -56.1698
exploration/Returns Min         -211.419
exploration/Actions Mean          -0.0174815
exploration/Actions Std            0.225778
exploration/Actions Max            0.994017
exploration/Actions Min           -0.99904
exploration/Num Paths              5
exploration/Average Returns     -128.944
evaluation/num steps total     82500
evaluation/num paths total       825
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.16651
evaluation/Rewards Std             1.10446
evaluation/Rewards Max            -0.0354586
evaluation/Rewards Min            -9.57991
evaluation/Returns Mean         -116.651
evaluation/Returns Std            67.4859
evaluation/Returns Max           -29.6817
evaluation/Returns Min          -248.551
evaluation/Actions Mean            0.00557258
evaluation/Actions Std             0.171292
evaluation/Actions Max             0.999025
evaluation/Actions Min            -0.996713
evaluation/Num Paths              15
evaluation/Average Returns      -116.651
time/data storing (s)              0.00306514
time/evaluation sampling (s)       0.327804
time/exploration sampling (s)      0.13978
time/logging (s)                   0.00481839
time/saving (s)                    0.00193072
time/training (s)                  1.90042
time/epoch (s)                     2.37782
time/total (s)                   139.161
Epoch                             54
-----------------------------  --------------
2019-04-22 23:29:35.263651 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 55 finished
-----------------------------  ---------------
replay_buffer/size             28200
trainer/QF1 Loss                   0.651971
trainer/QF2 Loss                   0.872575
trainer/Policy Loss               68.2588
trainer/Q1 Predictions Mean      -66.8801
trainer/Q1 Predictions Std        37.2904
trainer/Q1 Predictions Max       -24.6134
trainer/Q1 Predictions Min      -149.331
trainer/Q2 Predictions Mean      -66.8347
trainer/Q2 Predictions Std        37.1836
trainer/Q2 Predictions Max       -24.4118
trainer/Q2 Predictions Min      -148.193
trainer/Q Targets Mean           -67.3942
trainer/Q Targets Std             37.4557
trainer/Q Targets Max            -24.5512
trainer/Q Targets Min           -147.148
trainer/Log Pis Mean               2.10407
trainer/Log Pis Std                1.50703
trainer/Log Pis Max                7.31696
trainer/Log Pis Min               -2.11048
trainer/Policy mu Mean             0.0129555
trainer/Policy mu Std              0.859357
trainer/Policy mu Max              3.20269
trainer/Policy mu Min             -3.61639
trainer/Policy log std Mean       -1.9982
trainer/Policy log std Std         0.609392
trainer/Policy log std Max        -0.4678
trainer/Policy log std Min        -3.10684
trainer/Alpha                      0.0623824
trainer/Alpha Loss                 0.288759
exploration/num steps total    28200
exploration/num paths total      282
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.879141
exploration/Rewards Std            0.825673
exploration/Rewards Max           -0.0430165
exploration/Rewards Min           -7.47168
exploration/Returns Mean         -87.9141
exploration/Returns Std           63.0343
exploration/Returns Max          -32.1387
exploration/Returns Min         -205.987
exploration/Actions Mean          -0.000354148
exploration/Actions Std            0.182225
exploration/Actions Max            0.897208
exploration/Actions Min           -0.994846
exploration/Num Paths              5
exploration/Average Returns      -87.9141
evaluation/num steps total     84000
evaluation/num paths total       840
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.988618
evaluation/Rewards Std             1.00535
evaluation/Rewards Max            -0.0992446
evaluation/Rewards Min            -9.64747
evaluation/Returns Mean          -98.8618
evaluation/Returns Std            60.1951
evaluation/Returns Max           -24.8549
evaluation/Returns Min          -206.304
evaluation/Actions Mean           -0.00746453
evaluation/Actions Std             0.172076
evaluation/Actions Max             0.992347
evaluation/Actions Min            -0.993603
evaluation/Num Paths              15
evaluation/Average Returns       -98.8618
time/data storing (s)              0.00297589
time/evaluation sampling (s)       0.329682
time/exploration sampling (s)      0.144309
time/logging (s)                   0.00476925
time/saving (s)                    0.00192404
time/training (s)                  1.92596
time/epoch (s)                     2.40962
time/total (s)                   141.575
Epoch                             55
-----------------------------  ---------------
2019-04-22 23:29:37.677146 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 56 finished
-----------------------------  ---------------
replay_buffer/size             28700
trainer/QF1 Loss                   7.33069
trainer/QF2 Loss                   7.09017
trainer/Policy Loss               58.994
trainer/Q1 Predictions Mean      -57.6589
trainer/Q1 Predictions Std        33.4406
trainer/Q1 Predictions Max       -24.1504
trainer/Q1 Predictions Min      -120.396
trainer/Q2 Predictions Mean      -57.7021
trainer/Q2 Predictions Std        33.4843
trainer/Q2 Predictions Max       -24.0043
trainer/Q2 Predictions Min      -120.614
trainer/Q Targets Mean           -58.2611
trainer/Q Targets Std             34.2441
trainer/Q Targets Max             -0.651954
trainer/Q Targets Min           -121.471
trainer/Log Pis Mean               1.93347
trainer/Log Pis Std                1.23557
trainer/Log Pis Max                5.39775
trainer/Log Pis Min               -2.15088
trainer/Policy mu Mean             0.12383
trainer/Policy mu Std              0.765447
trainer/Policy mu Max              3.29483
trainer/Policy mu Min             -2.33275
trainer/Policy log std Mean       -1.96296
trainer/Policy log std Std         0.52584
trainer/Policy log std Max        -0.569848
trainer/Policy log std Min        -2.94159
trainer/Alpha                      0.065103
trainer/Alpha Loss                -0.181746
exploration/num steps total    28700
exploration/num paths total      287
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.17255
exploration/Rewards Std            1.17284
exploration/Rewards Max           -0.0251621
exploration/Rewards Min           -9.19328
exploration/Returns Mean        -117.255
exploration/Returns Std           60.8522
exploration/Returns Max          -36.9099
exploration/Returns Min         -185.644
exploration/Actions Mean           0.00471877
exploration/Actions Std            0.234605
exploration/Actions Max            0.999689
exploration/Actions Min           -0.99795
exploration/Num Paths              5
exploration/Average Returns     -117.255
evaluation/num steps total     85500
evaluation/num paths total       855
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.16309
evaluation/Rewards Std             1.10396
evaluation/Rewards Max            -0.043294
evaluation/Rewards Min            -9.17179
evaluation/Returns Mean         -116.309
evaluation/Returns Std            62.0907
evaluation/Returns Max           -39.5084
evaluation/Returns Min          -212.657
evaluation/Actions Mean            0.000540111
evaluation/Actions Std             0.183629
evaluation/Actions Max             0.999208
evaluation/Actions Min            -0.996675
evaluation/Num Paths              15
evaluation/Average Returns      -116.309
time/data storing (s)              0.00302007
time/evaluation sampling (s)       0.330911
time/exploration sampling (s)      0.140386
time/logging (s)                   0.00480517
time/saving (s)                    0.00166949
time/training (s)                  1.92674
time/epoch (s)                     2.40753
time/total (s)                   143.987
Epoch                             56
-----------------------------  ---------------
2019-04-22 23:29:40.092259 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 57 finished
-----------------------------  --------------
replay_buffer/size             29200
trainer/QF1 Loss                   1.01031
trainer/QF2 Loss                   1.09446
trainer/Policy Loss               72.6499
trainer/Q1 Predictions Mean      -71.4356
trainer/Q1 Predictions Std        35.9598
trainer/Q1 Predictions Max       -23.9548
trainer/Q1 Predictions Min      -129.262
trainer/Q2 Predictions Mean      -71.4085
trainer/Q2 Predictions Std        35.9584
trainer/Q2 Predictions Max       -23.8391
trainer/Q2 Predictions Min      -130.758
trainer/Q Targets Mean           -72.0976
trainer/Q Targets Std             36.3627
trainer/Q Targets Max            -24.1822
trainer/Q Targets Min           -131.738
trainer/Log Pis Mean               2.04763
trainer/Log Pis Std                1.28094
trainer/Log Pis Max                6.49215
trainer/Log Pis Min               -2.01686
trainer/Policy mu Mean            -0.00150186
trainer/Policy mu Std              0.879353
trainer/Policy mu Max              3.19342
trainer/Policy mu Min             -3.33498
trainer/Policy log std Mean       -1.83217
trainer/Policy log std Std         0.555307
trainer/Policy log std Max        -0.277101
trainer/Policy log std Min        -2.92611
trainer/Alpha                      0.0656278
trainer/Alpha Loss                 0.129732
exploration/num steps total    29200
exploration/num paths total      292
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.933108
exploration/Rewards Std            1.01674
exploration/Rewards Max           -0.0373535
exploration/Rewards Min           -8.13046
exploration/Returns Mean         -93.3108
exploration/Returns Std           52.0018
exploration/Returns Max          -47.0261
exploration/Returns Min         -192.366
exploration/Actions Mean          -0.00912143
exploration/Actions Std            0.233063
exploration/Actions Max            0.989704
exploration/Actions Min           -0.99742
exploration/Num Paths              5
exploration/Average Returns      -93.3108
evaluation/num steps total     87000
evaluation/num paths total       870
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.40524
evaluation/Rewards Std             0.966539
evaluation/Rewards Max            -0.0502874
evaluation/Rewards Min            -8.38115
evaluation/Returns Mean         -140.524
evaluation/Returns Std            64.6762
evaluation/Returns Max           -23.706
evaluation/Returns Min          -215.193
evaluation/Actions Mean            0.00534093
evaluation/Actions Std             0.178552
evaluation/Actions Max             0.997508
evaluation/Actions Min            -0.993303
evaluation/Num Paths              15
evaluation/Average Returns      -140.524
time/data storing (s)              0.00293123
time/evaluation sampling (s)       0.329892
time/exploration sampling (s)      0.14389
time/logging (s)                   0.00359886
time/saving (s)                    0.00151674
time/training (s)                  1.92605
time/epoch (s)                     2.40788
time/total (s)                   146.4
Epoch                             57
-----------------------------  --------------
2019-04-22 23:29:42.517953 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 58 finished
-----------------------------  --------------
replay_buffer/size             29700
trainer/QF1 Loss                  14.5114
trainer/QF2 Loss                  14.3998
trainer/Policy Loss               80.989
trainer/Q1 Predictions Mean      -80.0131
trainer/Q1 Predictions Std        34.1664
trainer/Q1 Predictions Max       -24.2054
trainer/Q1 Predictions Min      -143.63
trainer/Q2 Predictions Mean      -80.0448
trainer/Q2 Predictions Std        34.1402
trainer/Q2 Predictions Max       -24.1736
trainer/Q2 Predictions Min      -144.529
trainer/Q Targets Mean           -80.1885
trainer/Q Targets Std             34.7896
trainer/Q Targets Max             -0.521035
trainer/Q Targets Min           -144.785
trainer/Log Pis Mean               2.01137
trainer/Log Pis Std                1.34211
trainer/Log Pis Max                6.10528
trainer/Log Pis Min               -1.86056
trainer/Policy mu Mean            -0.0238344
trainer/Policy mu Std              0.875517
trainer/Policy mu Max              2.7014
trainer/Policy mu Min             -3.4636
trainer/Policy log std Mean       -1.86874
trainer/Policy log std Std         0.589934
trainer/Policy log std Max        -0.456403
trainer/Policy log std Min        -2.98292
trainer/Alpha                      0.0654804
trainer/Alpha Loss                 0.0309812
exploration/num steps total    29700
exploration/num paths total      297
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.774206
exploration/Rewards Std            0.946068
exploration/Rewards Max           -0.0305201
exploration/Rewards Min           -9.32178
exploration/Returns Mean         -77.4206
exploration/Returns Std           39.0738
exploration/Returns Max          -36.7411
exploration/Returns Min         -144.705
exploration/Actions Mean           0.00288397
exploration/Actions Std            0.210236
exploration/Actions Max            0.996621
exploration/Actions Min           -0.991386
exploration/Num Paths              5
exploration/Average Returns      -77.4206
evaluation/num steps total     88500
evaluation/num paths total       885
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.38509
evaluation/Rewards Std             1.19054
evaluation/Rewards Max            -0.0254973
evaluation/Rewards Min           -10.2197
evaluation/Returns Mean         -138.509
evaluation/Returns Std            61.6684
evaluation/Returns Max           -21.8976
evaluation/Returns Min          -217.563
evaluation/Actions Mean            0.00279191
evaluation/Actions Std             0.206081
evaluation/Actions Max             0.999136
evaluation/Actions Min            -0.997304
evaluation/Num Paths              15
evaluation/Average Returns      -138.509
time/data storing (s)              0.00300431
time/evaluation sampling (s)       0.324851
time/exploration sampling (s)      0.144271
time/logging (s)                   0.00478234
time/saving (s)                    0.00988986
time/training (s)                  1.93561
time/epoch (s)                     2.42241
time/total (s)                   148.825
Epoch                             58
-----------------------------  --------------
2019-04-22 23:29:44.930963 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 59 finished
-----------------------------  --------------
replay_buffer/size             30200
trainer/QF1 Loss                  38.435
trainer/QF2 Loss                  38.4897
trainer/Policy Loss               72.7679
trainer/Q1 Predictions Mean      -71.4313
trainer/Q1 Predictions Std        35.6355
trainer/Q1 Predictions Max       -23.7508
trainer/Q1 Predictions Min      -123.764
trainer/Q2 Predictions Mean      -71.4034
trainer/Q2 Predictions Std        35.5971
trainer/Q2 Predictions Max       -23.6579
trainer/Q2 Predictions Min      -122.155
trainer/Q Targets Mean           -71.6218
trainer/Q Targets Std             36.7508
trainer/Q Targets Max             -0.951764
trainer/Q Targets Min           -124.081
trainer/Log Pis Mean               1.99912
trainer/Log Pis Std                1.50334
trainer/Log Pis Max                6.61447
trainer/Log Pis Min               -3.31162
trainer/Policy mu Mean             0.0154903
trainer/Policy mu Std              0.845879
trainer/Policy mu Max              2.90919
trainer/Policy mu Min             -2.86313
trainer/Policy log std Mean       -1.91052
trainer/Policy log std Std         0.55441
trainer/Policy log std Max        -0.581088
trainer/Policy log std Min        -2.90082
trainer/Alpha                      0.0650363
trainer/Alpha Loss                -0.00240392
exploration/num steps total    30200
exploration/num paths total      302
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.549664
exploration/Rewards Std            0.977717
exploration/Rewards Max           -0.0139364
exploration/Rewards Min          -10.3242
exploration/Returns Mean         -54.9664
exploration/Returns Std           36.304
exploration/Returns Max          -20.1953
exploration/Returns Min         -108.348
exploration/Actions Mean          -0.0103145
exploration/Actions Std            0.212838
exploration/Actions Max            0.989123
exploration/Actions Min           -0.998945
exploration/Num Paths              5
exploration/Average Returns      -54.9664
evaluation/num steps total     90000
evaluation/num paths total       900
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.01532
evaluation/Rewards Std             0.914701
evaluation/Rewards Max            -0.0476297
evaluation/Rewards Min           -10.2785
evaluation/Returns Mean         -101.532
evaluation/Returns Std            54.4411
evaluation/Returns Max           -12.5743
evaluation/Returns Min          -191.903
evaluation/Actions Mean           -0.00229391
evaluation/Actions Std             0.150936
evaluation/Actions Max             0.999137
evaluation/Actions Min            -0.997558
evaluation/Num Paths              15
evaluation/Average Returns      -101.532
time/data storing (s)              0.00291375
time/evaluation sampling (s)       0.326794
time/exploration sampling (s)      0.141476
time/logging (s)                   0.004764
time/saving (s)                    0.00197123
time/training (s)                  1.92938
time/epoch (s)                     2.4073
time/total (s)                   151.237
Epoch                             59
-----------------------------  --------------
2019-04-22 23:29:47.355482 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 60 finished
-----------------------------  --------------
replay_buffer/size             30700
trainer/QF1 Loss                  16.3467
trainer/QF2 Loss                  16.4871
trainer/Policy Loss               67.6421
trainer/Q1 Predictions Mean      -66.4884
trainer/Q1 Predictions Std        35.4632
trainer/Q1 Predictions Max       -23.7236
trainer/Q1 Predictions Min      -150.209
trainer/Q2 Predictions Mean      -66.4805
trainer/Q2 Predictions Std        35.4746
trainer/Q2 Predictions Max       -23.7289
trainer/Q2 Predictions Min      -149.236
trainer/Q Targets Mean           -66.7246
trainer/Q Targets Std             36.1816
trainer/Q Targets Max             -2.82778
trainer/Q Targets Min           -150.508
trainer/Log Pis Mean               1.85883
trainer/Log Pis Std                1.50239
trainer/Log Pis Max                8.09087
trainer/Log Pis Min               -3.71299
trainer/Policy mu Mean             0.0146957
trainer/Policy mu Std              0.861264
trainer/Policy mu Max              2.56333
trainer/Policy mu Min             -3.52571
trainer/Policy log std Mean       -1.85022
trainer/Policy log std Std         0.570597
trainer/Policy log std Max        -0.355656
trainer/Policy log std Min        -2.78997
trainer/Alpha                      0.0642022
trainer/Alpha Loss                -0.387604
exploration/num steps total    30700
exploration/num paths total      307
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.917816
exploration/Rewards Std            0.915988
exploration/Rewards Max           -0.0181927
exploration/Rewards Min           -8.14801
exploration/Returns Mean         -91.7816
exploration/Returns Std           63.3547
exploration/Returns Max          -20.0831
exploration/Returns Min         -194.328
exploration/Actions Mean          -0.00578423
exploration/Actions Std            0.177394
exploration/Actions Max            0.99288
exploration/Actions Min           -0.999312
exploration/Num Paths              5
exploration/Average Returns      -91.7816
evaluation/num steps total     91500
evaluation/num paths total       915
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.958695
evaluation/Rewards Std             1.10849
evaluation/Rewards Max            -0.129999
evaluation/Rewards Min           -11.0679
evaluation/Returns Mean          -95.8695
evaluation/Returns Std            49.2189
evaluation/Returns Max           -17.2091
evaluation/Returns Min          -194.543
evaluation/Actions Mean            0.0135119
evaluation/Actions Std             0.192776
evaluation/Actions Max             0.998837
evaluation/Actions Min            -0.994256
evaluation/Num Paths              15
evaluation/Average Returns       -95.8695
time/data storing (s)              0.00292708
time/evaluation sampling (s)       0.333376
time/exploration sampling (s)      0.141633
time/logging (s)                   0.00477282
time/saving (s)                    0.00156799
time/training (s)                  1.93421
time/epoch (s)                     2.41848
time/total (s)                   153.66
Epoch                             60
-----------------------------  --------------
2019-04-22 23:29:49.773937 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 61 finished
-----------------------------  ---------------
replay_buffer/size             31200
trainer/QF1 Loss                 147.809
trainer/QF2 Loss                 146.387
trainer/Policy Loss               61.351
trainer/Q1 Predictions Mean      -60.2844
trainer/Q1 Predictions Std        34.3078
trainer/Q1 Predictions Max       -23.7187
trainer/Q1 Predictions Min      -114.01
trainer/Q2 Predictions Mean      -60.2878
trainer/Q2 Predictions Std        34.3057
trainer/Q2 Predictions Max       -23.6645
trainer/Q2 Predictions Min      -114.48
trainer/Q Targets Mean           -58.7286
trainer/Q Targets Std             35.9188
trainer/Q Targets Max             -0.0146559
trainer/Q Targets Min           -114.683
trainer/Log Pis Mean               1.88456
trainer/Log Pis Std                1.19301
trainer/Log Pis Max                5.5087
trainer/Log Pis Min               -1.96848
trainer/Policy mu Mean             0.0030235
trainer/Policy mu Std              0.738454
trainer/Policy mu Max              2.26171
trainer/Policy mu Min             -3.09742
trainer/Policy log std Mean       -1.93793
trainer/Policy log std Std         0.516045
trainer/Policy log std Max        -0.303762
trainer/Policy log std Min        -2.7471
trainer/Alpha                      0.0647281
trainer/Alpha Loss                -0.316044
exploration/num steps total    31200
exploration/num paths total      312
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.40721
exploration/Rewards Std            1.11661
exploration/Rewards Max           -0.026784
exploration/Rewards Min          -10.108
exploration/Returns Mean        -140.721
exploration/Returns Std           66.9422
exploration/Returns Max          -30.381
exploration/Returns Min         -202.63
exploration/Actions Mean           0.0255667
exploration/Actions Std            0.235447
exploration/Actions Max            0.999973
exploration/Actions Min           -0.974299
exploration/Num Paths              5
exploration/Average Returns     -140.721
evaluation/num steps total     93000
evaluation/num paths total       930
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.07177
evaluation/Rewards Std             0.929539
evaluation/Rewards Max            -0.0376597
evaluation/Rewards Min           -10.2579
evaluation/Returns Mean         -107.177
evaluation/Returns Std            53.7297
evaluation/Returns Max           -10.5108
evaluation/Returns Min          -206.512
evaluation/Actions Mean           -6.82449e-06
evaluation/Actions Std             0.17482
evaluation/Actions Max             0.997885
evaluation/Actions Min            -0.998557
evaluation/Num Paths              15
evaluation/Average Returns      -107.177
time/data storing (s)              0.00300759
time/evaluation sampling (s)       0.330652
time/exploration sampling (s)      0.14432
time/logging (s)                   0.00482126
time/saving (s)                    0.00194343
time/training (s)                  1.92772
time/epoch (s)                     2.41247
time/total (s)                   156.077
Epoch                             61
-----------------------------  ---------------
2019-04-22 23:29:52.185286 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 62 finished
-----------------------------  --------------
replay_buffer/size             31700
trainer/QF1 Loss                   6.2187
trainer/QF2 Loss                   6.0955
trainer/Policy Loss               64.4216
trainer/Q1 Predictions Mean      -63.2427
trainer/Q1 Predictions Std        34.0103
trainer/Q1 Predictions Max       -23.0876
trainer/Q1 Predictions Min      -119.009
trainer/Q2 Predictions Mean      -63.2853
trainer/Q2 Predictions Std        34.0247
trainer/Q2 Predictions Max       -23.0369
trainer/Q2 Predictions Min      -118.501
trainer/Q Targets Mean           -63.6389
trainer/Q Targets Std             34.6921
trainer/Q Targets Max             -0.0373535
trainer/Q Targets Min           -120.206
trainer/Log Pis Mean               1.991
trainer/Log Pis Std                1.50749
trainer/Log Pis Max                6.32519
trainer/Log Pis Min               -1.88038
trainer/Policy mu Mean             0.138444
trainer/Policy mu Std              0.851071
trainer/Policy mu Max              2.86005
trainer/Policy mu Min             -2.53915
trainer/Policy log std Mean       -1.9053
trainer/Policy log std Std         0.595834
trainer/Policy log std Max        -0.497979
trainer/Policy log std Min        -2.82884
trainer/Alpha                      0.0641198
trainer/Alpha Loss                -0.024726
exploration/num steps total    31700
exploration/num paths total      317
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.22735
exploration/Rewards Std            1.04307
exploration/Rewards Max           -0.357243
exploration/Rewards Min           -9.58441
exploration/Returns Mean        -122.735
exploration/Returns Std           50.6842
exploration/Returns Max          -57.3765
exploration/Returns Min         -211.453
exploration/Actions Mean          -0.0112437
exploration/Actions Std            0.250483
exploration/Actions Max            0.999081
exploration/Actions Min           -0.999947
exploration/Num Paths              5
exploration/Average Returns     -122.735
evaluation/num steps total     94500
evaluation/num paths total       945
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.95639
evaluation/Rewards Std             0.97677
evaluation/Rewards Max            -0.165603
evaluation/Rewards Min           -10.6469
evaluation/Returns Mean          -95.639
evaluation/Returns Std            58.3326
evaluation/Returns Max           -19.9038
evaluation/Returns Min          -206.921
evaluation/Actions Mean           -0.00830713
evaluation/Actions Std             0.157838
evaluation/Actions Max             0.997086
evaluation/Actions Min            -0.996097
evaluation/Num Paths              15
evaluation/Average Returns       -95.639
time/data storing (s)              0.00310372
time/evaluation sampling (s)       0.332107
time/exploration sampling (s)      0.141718
time/logging (s)                   0.00478553
time/saving (s)                    0.00156777
time/training (s)                  1.92188
time/epoch (s)                     2.40516
time/total (s)                   158.487
Epoch                             62
-----------------------------  --------------
2019-04-22 23:29:54.607890 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 63 finished
-----------------------------  --------------
replay_buffer/size             32200
trainer/QF1 Loss                   2.05321
trainer/QF2 Loss                   2.08545
trainer/Policy Loss               66.6569
trainer/Q1 Predictions Mean      -65.7054
trainer/Q1 Predictions Std        35.1187
trainer/Q1 Predictions Max       -23.187
trainer/Q1 Predictions Min      -115.605
trainer/Q2 Predictions Mean      -65.6934
trainer/Q2 Predictions Std        35.1038
trainer/Q2 Predictions Max       -23.1156
trainer/Q2 Predictions Min      -114.353
trainer/Q Targets Mean           -66.8074
trainer/Q Targets Std             35.7574
trainer/Q Targets Max            -23.2986
trainer/Q Targets Min           -119.589
trainer/Log Pis Mean               1.88023
trainer/Log Pis Std                1.57846
trainer/Log Pis Max                6.4725
trainer/Log Pis Min               -2.36368
trainer/Policy mu Mean             0.140271
trainer/Policy mu Std              0.905296
trainer/Policy mu Max              3.33548
trainer/Policy mu Min             -3.12117
trainer/Policy log std Mean       -1.86615
trainer/Policy log std Std         0.57309
trainer/Policy log std Max        -0.366283
trainer/Policy log std Min        -2.91305
trainer/Alpha                      0.0625014
trainer/Alpha Loss                -0.332061
exploration/num steps total    32200
exploration/num paths total      322
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.887572
exploration/Rewards Std            0.983262
exploration/Rewards Max           -0.0337374
exploration/Rewards Min          -10.4769
exploration/Returns Mean         -88.7572
exploration/Returns Std           53.846
exploration/Returns Max          -41.9346
exploration/Returns Min         -190.879
exploration/Actions Mean          -0.00975903
exploration/Actions Std            0.200299
exploration/Actions Max            0.998263
exploration/Actions Min           -0.981569
exploration/Num Paths              5
exploration/Average Returns      -88.7572
evaluation/num steps total     96000
evaluation/num paths total       960
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.983331
evaluation/Rewards Std             1.02478
evaluation/Rewards Max            -0.212724
evaluation/Rewards Min           -10.1142
evaluation/Returns Mean          -98.3331
evaluation/Returns Std            38.4542
evaluation/Returns Max           -44.7187
evaluation/Returns Min          -196.806
evaluation/Actions Mean            0.0078273
evaluation/Actions Std             0.186702
evaluation/Actions Max             0.998833
evaluation/Actions Min            -0.996498
evaluation/Num Paths              15
evaluation/Average Returns       -98.3331
time/data storing (s)              0.00297131
time/evaluation sampling (s)       0.333623
time/exploration sampling (s)      0.145247
time/logging (s)                   0.00354534
time/saving (s)                    0.0018874
time/training (s)                  1.92805
time/epoch (s)                     2.41532
time/total (s)                   160.907
Epoch                             63
-----------------------------  --------------
2019-04-22 23:29:57.038280 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 64 finished
-----------------------------  --------------
replay_buffer/size             32700
trainer/QF1 Loss                 193.07
trainer/QF2 Loss                 193.543
trainer/Policy Loss               68.5063
trainer/Q1 Predictions Mean      -66.9516
trainer/Q1 Predictions Std        36.3296
trainer/Q1 Predictions Max       -23.1648
trainer/Q1 Predictions Min      -132.017
trainer/Q2 Predictions Mean      -66.9813
trainer/Q2 Predictions Std        36.2784
trainer/Q2 Predictions Max       -23.0426
trainer/Q2 Predictions Min      -131.535
trainer/Q Targets Mean           -65.6541
trainer/Q Targets Std             37.3857
trainer/Q Targets Max             -2.28784
trainer/Q Targets Min           -133.227
trainer/Log Pis Mean               2.25109
trainer/Log Pis Std                1.8545
trainer/Log Pis Max               10.9581
trainer/Log Pis Min               -2.54187
trainer/Policy mu Mean             0.029505
trainer/Policy mu Std              1.03655
trainer/Policy mu Max              3.28571
trainer/Policy mu Min             -3.24643
trainer/Policy log std Mean       -1.79708
trainer/Policy log std Std         0.635135
trainer/Policy log std Max         0.0338325
trainer/Policy log std Min        -2.81293
trainer/Alpha                      0.0647129
trainer/Alpha Loss                 0.68752
exploration/num steps total    32700
exploration/num paths total      327
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.998237
exploration/Rewards Std            1.22941
exploration/Rewards Max           -0.00614008
exploration/Rewards Min           -9.59651
exploration/Returns Mean         -99.8237
exploration/Returns Std           52.4642
exploration/Returns Max          -52.1142
exploration/Returns Min         -200.99
exploration/Actions Mean          -0.00732832
exploration/Actions Std            0.223252
exploration/Actions Max            0.99373
exploration/Actions Min           -0.99977
exploration/Num Paths              5
exploration/Average Returns      -99.8237
evaluation/num steps total     97500
evaluation/num paths total       975
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.26742
evaluation/Rewards Std             0.813975
evaluation/Rewards Max            -0.293838
evaluation/Rewards Min            -9.22478
evaluation/Returns Mean         -126.742
evaluation/Returns Std            43.7075
evaluation/Returns Max           -40.2951
evaluation/Returns Min          -193.903
evaluation/Actions Mean            0.00180367
evaluation/Actions Std             0.155896
evaluation/Actions Max             0.998078
evaluation/Actions Min            -0.998631
evaluation/Num Paths              15
evaluation/Average Returns      -126.742
time/data storing (s)              0.00307071
time/evaluation sampling (s)       0.330008
time/exploration sampling (s)      0.147597
time/logging (s)                   0.00479201
time/saving (s)                    0.00196363
time/training (s)                  1.9385
time/epoch (s)                     2.42593
time/total (s)                   163.337
Epoch                             64
-----------------------------  --------------
2019-04-22 23:29:59.456080 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 65 finished
-----------------------------  --------------
replay_buffer/size             33200
trainer/QF1 Loss                  22.6688
trainer/QF2 Loss                  21.4202
trainer/Policy Loss               67.1188
trainer/Q1 Predictions Mean      -66.2694
trainer/Q1 Predictions Std        35.4524
trainer/Q1 Predictions Max       -22.8389
trainer/Q1 Predictions Min      -140.236
trainer/Q2 Predictions Mean      -66.245
trainer/Q2 Predictions Std        35.4964
trainer/Q2 Predictions Max       -22.6872
trainer/Q2 Predictions Min      -140.171
trainer/Q Targets Mean           -66.5664
trainer/Q Targets Std             36.2664
trainer/Q Targets Max             -8.68878
trainer/Q Targets Min           -141.494
trainer/Log Pis Mean               1.69094
trainer/Log Pis Std                1.74869
trainer/Log Pis Max                7.88155
trainer/Log Pis Min               -2.76765
trainer/Policy mu Mean             0.022853
trainer/Policy mu Std              0.85323
trainer/Policy mu Max              2.82905
trainer/Policy mu Min             -3.2167
trainer/Policy log std Mean       -1.86381
trainer/Policy log std Std         0.527412
trainer/Policy log std Max        -0.342491
trainer/Policy log std Min        -2.76345
trainer/Alpha                      0.0644936
trainer/Alpha Loss                -0.847167
exploration/num steps total    33200
exploration/num paths total      332
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.15179
exploration/Rewards Std            1.21722
exploration/Rewards Max           -0.534431
exploration/Rewards Min          -10.2062
exploration/Returns Mean        -115.179
exploration/Returns Std           18.7655
exploration/Returns Max          -80.7504
exploration/Returns Min         -136.697
exploration/Actions Mean           0.0302045
exploration/Actions Std            0.244302
exploration/Actions Max            0.995886
exploration/Actions Min           -0.997388
exploration/Num Paths              5
exploration/Average Returns     -115.179
evaluation/num steps total     99000
evaluation/num paths total       990
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.01732
evaluation/Rewards Std             0.979813
evaluation/Rewards Max            -0.0910599
evaluation/Rewards Min           -10.3737
evaluation/Returns Mean         -101.732
evaluation/Returns Std            53.3517
evaluation/Returns Max           -16.1835
evaluation/Returns Min          -210.368
evaluation/Actions Mean            0.00181652
evaluation/Actions Std             0.168657
evaluation/Actions Max             0.998163
evaluation/Actions Min            -0.99572
evaluation/Num Paths              15
evaluation/Average Returns      -101.732
time/data storing (s)              0.00285646
time/evaluation sampling (s)       0.331148
time/exploration sampling (s)      0.142378
time/logging (s)                   0.00484008
time/saving (s)                    0.00196402
time/training (s)                  1.9286
time/epoch (s)                     2.41179
time/total (s)                   165.754
Epoch                             65
-----------------------------  --------------
2019-04-22 23:30:01.881902 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 66 finished
-----------------------------  ---------------
replay_buffer/size              33700
trainer/QF1 Loss                   36.6382
trainer/QF2 Loss                   36.1769
trainer/Policy Loss                66.7549
trainer/Q1 Predictions Mean       -65.5663
trainer/Q1 Predictions Std         33.2363
trainer/Q1 Predictions Max        -22.8207
trainer/Q1 Predictions Min       -138.14
trainer/Q2 Predictions Mean       -65.5833
trainer/Q2 Predictions Std         33.2642
trainer/Q2 Predictions Max        -22.5755
trainer/Q2 Predictions Min       -138.034
trainer/Q Targets Mean            -65.6382
trainer/Q Targets Std              34.2326
trainer/Q Targets Max              -1.20941
trainer/Q Targets Min            -139.483
trainer/Log Pis Mean                2.17817
trainer/Log Pis Std                 1.44923
trainer/Log Pis Max                 5.89315
trainer/Log Pis Min                -3.18877
trainer/Policy mu Mean              0.0570337
trainer/Policy mu Std               0.981378
trainer/Policy mu Max               3.33951
trainer/Policy mu Min              -3.313
trainer/Policy log std Mean        -1.84384
trainer/Policy log std Std          0.598497
trainer/Policy log std Max         -0.360889
trainer/Policy log std Min         -2.82103
trainer/Alpha                       0.0643031
trainer/Alpha Loss                  0.488918
exploration/num steps total     33700
exploration/num paths total       337
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.927431
exploration/Rewards Std             0.859679
exploration/Rewards Max            -0.0236295
exploration/Rewards Min            -8.10172
exploration/Returns Mean          -92.7431
exploration/Returns Std            26.9937
exploration/Returns Max           -55.458
exploration/Returns Min          -135.466
exploration/Actions Mean           -0.00487566
exploration/Actions Std             0.227432
exploration/Actions Max             0.99934
exploration/Actions Min            -0.999458
exploration/Num Paths               5
exploration/Average Returns       -92.7431
evaluation/num steps total     100500
evaluation/num paths total       1005
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.08075
evaluation/Rewards Std              1.13803
evaluation/Rewards Max             -0.104267
evaluation/Rewards Min            -10.6994
evaluation/Returns Mean          -108.075
evaluation/Returns Std             40.0835
evaluation/Returns Max            -54.748
evaluation/Returns Min           -198.778
evaluation/Actions Mean            -0.00555622
evaluation/Actions Std              0.200216
evaluation/Actions Max              0.999423
evaluation/Actions Min             -0.996877
evaluation/Num Paths               15
evaluation/Average Returns       -108.075
time/data storing (s)               0.00292294
time/evaluation sampling (s)        0.330934
time/exploration sampling (s)       0.141946
time/logging (s)                    0.00480573
time/saving (s)                     0.00197019
time/training (s)                   1.9372
time/epoch (s)                      2.41978
time/total (s)                    168.178
Epoch                              66
-----------------------------  ---------------
2019-04-22 23:30:04.287954 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 67 finished
-----------------------------  ---------------
replay_buffer/size              34200
trainer/QF1 Loss                    5.4516
trainer/QF2 Loss                    5.46994
trainer/Policy Loss                63.2475
trainer/Q1 Predictions Mean       -61.8645
trainer/Q1 Predictions Std         34.5233
trainer/Q1 Predictions Max        -22.7598
trainer/Q1 Predictions Min       -110.849
trainer/Q2 Predictions Mean       -61.8889
trainer/Q2 Predictions Std         34.5377
trainer/Q2 Predictions Max        -22.6973
trainer/Q2 Predictions Min       -110.782
trainer/Q Targets Mean            -61.9763
trainer/Q Targets Std              34.9691
trainer/Q Targets Max              -0.756273
trainer/Q Targets Min            -111.72
trainer/Log Pis Mean                1.98746
trainer/Log Pis Std                 1.31521
trainer/Log Pis Max                 6.02677
trainer/Log Pis Min                -4.1805
trainer/Policy mu Mean              0.108097
trainer/Policy mu Std               0.711906
trainer/Policy mu Max               2.77397
trainer/Policy mu Min              -3.0915
trainer/Policy log std Mean        -1.97069
trainer/Policy log std Std          0.492555
trainer/Policy log std Max         -0.297502
trainer/Policy log std Min         -2.81236
trainer/Alpha                       0.065072
trainer/Alpha Loss                 -0.0342578
exploration/num steps total     34200
exploration/num paths total       342
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.21417
exploration/Rewards Std             0.980487
exploration/Rewards Max            -0.0284868
exploration/Rewards Min            -8.86616
exploration/Returns Mean         -121.417
exploration/Returns Std            67.6151
exploration/Returns Max           -43.5585
exploration/Returns Min          -199.985
exploration/Actions Mean           -0.00676632
exploration/Actions Std             0.214786
exploration/Actions Max             0.999753
exploration/Actions Min            -0.991008
exploration/Num Paths               5
exploration/Average Returns      -121.417
evaluation/num steps total     102000
evaluation/num paths total       1020
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.904899
evaluation/Rewards Std              1.09676
evaluation/Rewards Max             -0.167847
evaluation/Rewards Min             -9.92593
evaluation/Returns Mean           -90.4899
evaluation/Returns Std             21.7554
evaluation/Returns Max            -45.9535
evaluation/Returns Min           -124.143
evaluation/Actions Mean             0.00888594
evaluation/Actions Std              0.203428
evaluation/Actions Max              0.999528
evaluation/Actions Min             -0.997716
evaluation/Num Paths               15
evaluation/Average Returns        -90.4899
time/data storing (s)               0.00299522
time/evaluation sampling (s)        0.333107
time/exploration sampling (s)       0.142256
time/logging (s)                    0.00476354
time/saving (s)                     0.00185849
time/training (s)                   1.91528
time/epoch (s)                      2.40026
time/total (s)                    170.582
Epoch                              67
-----------------------------  ---------------
2019-04-22 23:30:06.707561 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 68 finished
-----------------------------  ---------------
replay_buffer/size              34700
trainer/QF1 Loss                    0.918102
trainer/QF2 Loss                    0.872719
trainer/Policy Loss                65.8384
trainer/Q1 Predictions Mean       -64.8093
trainer/Q1 Predictions Std         32.2159
trainer/Q1 Predictions Max        -22.4549
trainer/Q1 Predictions Min       -115.165
trainer/Q2 Predictions Mean       -64.846
trainer/Q2 Predictions Std         32.2923
trainer/Q2 Predictions Max        -22.3178
trainer/Q2 Predictions Min       -116.63
trainer/Q Targets Mean            -65.429
trainer/Q Targets Std              32.6213
trainer/Q Targets Max             -22.5046
trainer/Q Targets Min            -114.825
trainer/Log Pis Mean                1.83477
trainer/Log Pis Std                 1.73843
trainer/Log Pis Max                 9.31922
trainer/Log Pis Min                -4.9791
trainer/Policy mu Mean              0.0280287
trainer/Policy mu Std               0.839188
trainer/Policy mu Max               2.68977
trainer/Policy mu Min              -3.1458
trainer/Policy log std Mean        -1.95461
trainer/Policy log std Std          0.548099
trainer/Policy log std Max         -0.322166
trainer/Policy log std Min         -2.83349
trainer/Alpha                       0.0656319
trainer/Alpha Loss                 -0.450035
exploration/num steps total     34700
exploration/num paths total       347
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.17865
exploration/Rewards Std             1.22126
exploration/Rewards Max            -0.0116345
exploration/Rewards Min           -10.2584
exploration/Returns Mean         -117.865
exploration/Returns Std            55.9054
exploration/Returns Max           -33.0883
exploration/Returns Min          -191.221
exploration/Actions Mean            0.0242244
exploration/Actions Std             0.22649
exploration/Actions Max             0.999992
exploration/Actions Min            -0.963446
exploration/Num Paths               5
exploration/Average Returns      -117.865
evaluation/num steps total     103500
evaluation/num paths total       1035
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.04964
evaluation/Rewards Std              1.02493
evaluation/Rewards Max             -0.109474
evaluation/Rewards Min            -11.0069
evaluation/Returns Mean          -104.964
evaluation/Returns Std             52.0699
evaluation/Returns Max            -15.597
evaluation/Returns Min           -212.97
evaluation/Actions Mean            -0.015601
evaluation/Actions Std              0.181903
evaluation/Actions Max              0.998997
evaluation/Actions Min             -0.997399
evaluation/Num Paths               15
evaluation/Average Returns       -104.964
time/data storing (s)               0.00359549
time/evaluation sampling (s)        0.329739
time/exploration sampling (s)       0.144809
time/logging (s)                    0.00483828
time/saving (s)                     0.00195513
time/training (s)                   1.9286
time/epoch (s)                      2.41354
time/total (s)                    173
Epoch                              68
-----------------------------  ---------------
2019-04-22 23:30:09.119257 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 69 finished
-----------------------------  ---------------
replay_buffer/size              35200
trainer/QF1 Loss                    0.711343
trainer/QF2 Loss                    0.769454
trainer/Policy Loss                65.443
trainer/Q1 Predictions Mean       -64.205
trainer/Q1 Predictions Std         31.939
trainer/Q1 Predictions Max        -22.2376
trainer/Q1 Predictions Min       -119.842
trainer/Q2 Predictions Mean       -64.2005
trainer/Q2 Predictions Std         31.9277
trainer/Q2 Predictions Max        -22.2113
trainer/Q2 Predictions Min       -119.12
trainer/Q Targets Mean            -64.8282
trainer/Q Targets Std              32.2687
trainer/Q Targets Max             -22.3186
trainer/Q Targets Min            -120.446
trainer/Log Pis Mean                2.04964
trainer/Log Pis Std                 1.51188
trainer/Log Pis Max                 7.76592
trainer/Log Pis Min                -2.04282
trainer/Policy mu Mean              0.094457
trainer/Policy mu Std               0.869049
trainer/Policy mu Max               3.1854
trainer/Policy mu Min              -3.43033
trainer/Policy log std Mean        -1.86187
trainer/Policy log std Std          0.609366
trainer/Policy log std Max         -0.306768
trainer/Policy log std Min         -2.87988
trainer/Alpha                       0.0648846
trainer/Alpha Loss                  0.135768
exploration/num steps total     35200
exploration/num paths total       352
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.944461
exploration/Rewards Std             1.35202
exploration/Rewards Max            -0.0602993
exploration/Rewards Min           -11.7329
exploration/Returns Mean          -94.4461
exploration/Returns Std            37.5344
exploration/Returns Max           -36.4769
exploration/Returns Min          -129.692
exploration/Actions Mean            0.0166007
exploration/Actions Std             0.254946
exploration/Actions Max             0.999628
exploration/Actions Min            -0.998109
exploration/Num Paths               5
exploration/Average Returns       -94.4461
evaluation/num steps total     105000
evaluation/num paths total       1050
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.02791
evaluation/Rewards Std              1.16097
evaluation/Rewards Max             -0.181554
evaluation/Rewards Min            -10.4534
evaluation/Returns Mean          -102.791
evaluation/Returns Std             54.938
evaluation/Returns Max            -28.8957
evaluation/Returns Min           -213.797
evaluation/Actions Mean            -0.00767491
evaluation/Actions Std              0.195781
evaluation/Actions Max              0.999126
evaluation/Actions Min             -0.998459
evaluation/Num Paths               15
evaluation/Average Returns       -102.791
time/data storing (s)               0.00294036
time/evaluation sampling (s)        0.332608
time/exploration sampling (s)       0.142623
time/logging (s)                    0.00489074
time/saving (s)                     0.00158878
time/training (s)                   1.92093
time/epoch (s)                      2.40558
time/total (s)                    175.411
Epoch                              69
-----------------------------  ---------------
2019-04-22 23:30:11.522611 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 70 finished
-----------------------------  ---------------
replay_buffer/size              35700
trainer/QF1 Loss                    0.5426
trainer/QF2 Loss                    0.54438
trainer/Policy Loss                65.4006
trainer/Q1 Predictions Mean       -64.1708
trainer/Q1 Predictions Std         32.0407
trainer/Q1 Predictions Max        -22.0177
trainer/Q1 Predictions Min       -114.162
trainer/Q2 Predictions Mean       -64.1464
trainer/Q2 Predictions Std         32.0686
trainer/Q2 Predictions Max        -21.9089
trainer/Q2 Predictions Min       -114.013
trainer/Q Targets Mean            -64.5561
trainer/Q Targets Std              32.2563
trainer/Q Targets Max             -22.0435
trainer/Q Targets Min            -113.822
trainer/Log Pis Mean                2.16237
trainer/Log Pis Std                 1.7146
trainer/Log Pis Max                 9.16834
trainer/Log Pis Min                -1.6408
trainer/Policy mu Mean              0.183019
trainer/Policy mu Std               0.950635
trainer/Policy mu Max               3.17621
trainer/Policy mu Min              -2.92984
trainer/Policy log std Mean        -1.8096
trainer/Policy log std Std          0.592781
trainer/Policy log std Max         -0.102096
trainer/Policy log std Min         -2.84229
trainer/Alpha                       0.063049
trainer/Alpha Loss                  0.448782
exploration/num steps total     35700
exploration/num paths total       357
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.48931
exploration/Rewards Std             1.07261
exploration/Rewards Max            -0.55062
exploration/Rewards Min            -9.20617
exploration/Returns Mean         -148.931
exploration/Returns Std            51.6589
exploration/Returns Max          -101.145
exploration/Returns Min          -212.301
exploration/Actions Mean           -0.00450451
exploration/Actions Std             0.235582
exploration/Actions Max             0.998843
exploration/Actions Min            -0.995636
exploration/Num Paths               5
exploration/Average Returns      -148.931
evaluation/num steps total     106500
evaluation/num paths total       1065
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.955105
evaluation/Rewards Std              1.0579
evaluation/Rewards Max             -0.197213
evaluation/Rewards Min            -10.1365
evaluation/Returns Mean           -95.5105
evaluation/Returns Std             54.7899
evaluation/Returns Max            -36.342
evaluation/Returns Min           -216.145
evaluation/Actions Mean            -0.0107161
evaluation/Actions Std              0.176152
evaluation/Actions Max              0.997719
evaluation/Actions Min             -0.998699
evaluation/Num Paths               15
evaluation/Average Returns        -95.5105
time/data storing (s)               0.00292793
time/evaluation sampling (s)        0.329666
time/exploration sampling (s)       0.139628
time/logging (s)                    0.00482142
time/saving (s)                     0.00197015
time/training (s)                   1.91808
time/epoch (s)                      2.39709
time/total (s)                    177.812
Epoch                              70
-----------------------------  ---------------
2019-04-22 23:30:13.982454 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 71 finished
-----------------------------  ---------------
replay_buffer/size              36200
trainer/QF1 Loss                   33.7623
trainer/QF2 Loss                   33.7118
trainer/Policy Loss                68.7861
trainer/Q1 Predictions Mean       -67.746
trainer/Q1 Predictions Std         35.1111
trainer/Q1 Predictions Max        -21.3926
trainer/Q1 Predictions Min       -153.08
trainer/Q2 Predictions Mean       -67.7969
trainer/Q2 Predictions Std         35.1645
trainer/Q2 Predictions Max        -21.3185
trainer/Q2 Predictions Min       -154.151
trainer/Q Targets Mean            -67.5527
trainer/Q Targets Std              35.8142
trainer/Q Targets Max              -1.43781
trainer/Q Targets Min            -154.71
trainer/Log Pis Mean                2.04347
trainer/Log Pis Std                 1.54861
trainer/Log Pis Max                 8.05272
trainer/Log Pis Min                -1.90164
trainer/Policy mu Mean              0.00320071
trainer/Policy mu Std               0.940948
trainer/Policy mu Max               3.20534
trainer/Policy mu Min              -3.27067
trainer/Policy log std Mean        -1.89856
trainer/Policy log std Std          0.547927
trainer/Policy log std Max         -0.301052
trainer/Policy log std Min         -2.87099
trainer/Alpha                       0.0639234
trainer/Alpha Loss                  0.119543
exploration/num steps total     36200
exploration/num paths total       362
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.64511
exploration/Rewards Std             1.18317
exploration/Rewards Max            -0.522482
exploration/Rewards Min           -11.6354
exploration/Returns Mean         -164.511
exploration/Returns Std            63.5953
exploration/Returns Max           -83.3676
exploration/Returns Min          -248.996
exploration/Actions Mean           -0.00440795
exploration/Actions Std             0.226067
exploration/Actions Max             0.999497
exploration/Actions Min            -0.999812
exploration/Num Paths               5
exploration/Average Returns      -164.511
evaluation/num steps total     108000
evaluation/num paths total       1080
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.39047
evaluation/Rewards Std              0.880856
evaluation/Rewards Max             -0.501641
evaluation/Rewards Min             -9.29915
evaluation/Returns Mean          -139.047
evaluation/Returns Std             45.6875
evaluation/Returns Max            -80.7825
evaluation/Returns Min           -229.219
evaluation/Actions Mean            -0.00426725
evaluation/Actions Std              0.179912
evaluation/Actions Max              0.998306
evaluation/Actions Min             -0.998715
evaluation/Num Paths               15
evaluation/Average Returns       -139.047
time/data storing (s)               0.00290842
time/evaluation sampling (s)        0.346287
time/exploration sampling (s)       0.157413
time/logging (s)                    0.00486748
time/saving (s)                     0.0105078
time/training (s)                   1.93289
time/epoch (s)                      2.45488
time/total (s)                    180.271
Epoch                              71
-----------------------------  ---------------
2019-04-22 23:30:16.407677 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 72 finished
-----------------------------  ---------------
replay_buffer/size              36700
trainer/QF1 Loss                   12.006
trainer/QF2 Loss                   12.2603
trainer/Policy Loss                62.1899
trainer/Q1 Predictions Mean       -60.4494
trainer/Q1 Predictions Std         30.5221
trainer/Q1 Predictions Max        -20.6514
trainer/Q1 Predictions Min       -100.322
trainer/Q2 Predictions Mean       -60.4662
trainer/Q2 Predictions Std         30.4905
trainer/Q2 Predictions Max        -20.7155
trainer/Q2 Predictions Min       -100.543
trainer/Q Targets Mean            -61.4026
trainer/Q Targets Std              31.5039
trainer/Q Targets Max              -0.929605
trainer/Q Targets Min            -101.723
trainer/Log Pis Mean                2.38479
trainer/Log Pis Std                 1.22375
trainer/Log Pis Max                 6.65295
trainer/Log Pis Min                -0.0661843
trainer/Policy mu Mean              0.06167
trainer/Policy mu Std               0.804198
trainer/Policy mu Max               3.18332
trainer/Policy mu Min              -2.57858
trainer/Policy log std Mean        -2.01715
trainer/Policy log std Std          0.579397
trainer/Policy log std Max         -0.447468
trainer/Policy log std Min         -2.91596
trainer/Alpha                       0.062388
trainer/Alpha Loss                  1.06756
exploration/num steps total     36700
exploration/num paths total       367
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.35355
exploration/Rewards Std             0.80549
exploration/Rewards Max            -0.357922
exploration/Rewards Min            -7.85333
exploration/Returns Mean         -135.355
exploration/Returns Std            48.4184
exploration/Returns Max           -68.6885
exploration/Returns Min          -194.439
exploration/Actions Mean            0.00310285
exploration/Actions Std             0.217417
exploration/Actions Max             0.99188
exploration/Actions Min            -0.999827
exploration/Num Paths               5
exploration/Average Returns      -135.355
evaluation/num steps total     109500
evaluation/num paths total       1095
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.00863
evaluation/Rewards Std              1.22562
evaluation/Rewards Max             -0.0873733
evaluation/Rewards Min            -10.39
evaluation/Returns Mean          -100.863
evaluation/Returns Std             56.031
evaluation/Returns Max            -15.6324
evaluation/Returns Min           -207.267
evaluation/Actions Mean            -0.00712072
evaluation/Actions Std              0.195488
evaluation/Actions Max              0.998537
evaluation/Actions Min             -0.998311
evaluation/Num Paths               15
evaluation/Average Returns       -100.863
time/data storing (s)               0.00293694
time/evaluation sampling (s)        0.328374
time/exploration sampling (s)       0.142505
time/logging (s)                    0.0046918
time/saving (s)                     0.00196537
time/training (s)                   1.9381
time/epoch (s)                      2.41857
time/total (s)                    182.694
Epoch                              72
-----------------------------  ---------------
2019-04-22 23:30:18.815479 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 73 finished
-----------------------------  ----------------
replay_buffer/size              37200
trainer/QF1 Loss                   97.593
trainer/QF2 Loss                   97.5256
trainer/Policy Loss                58.9618
trainer/Q1 Predictions Mean       -57.7766
trainer/Q1 Predictions Std         32.5248
trainer/Q1 Predictions Max        -21.0508
trainer/Q1 Predictions Min       -115.076
trainer/Q2 Predictions Mean       -57.7165
trainer/Q2 Predictions Std         32.4812
trainer/Q2 Predictions Max        -21.066
trainer/Q2 Predictions Min       -113.157
trainer/Q Targets Mean            -57.0052
trainer/Q Targets Std              32.6453
trainer/Q Targets Max              -2.50603
trainer/Q Targets Min            -115.368
trainer/Log Pis Mean                2.0751
trainer/Log Pis Std                 1.32433
trainer/Log Pis Max                 6.22755
trainer/Log Pis Min                -1.52436
trainer/Policy mu Mean              0.0293286
trainer/Policy mu Std               0.814746
trainer/Policy mu Max               3.26564
trainer/Policy mu Min              -3.04625
trainer/Policy log std Mean        -2.00011
trainer/Policy log std Std          0.544217
trainer/Policy log std Max         -0.264293
trainer/Policy log std Min         -2.88601
trainer/Alpha                       0.0632311
trainer/Alpha Loss                  0.207343
exploration/num steps total     37200
exploration/num paths total       372
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.816364
exploration/Rewards Std             0.91737
exploration/Rewards Max            -0.0156466
exploration/Rewards Min            -8.70574
exploration/Returns Mean          -81.6364
exploration/Returns Std            52.071
exploration/Returns Max           -17.0947
exploration/Returns Min          -172.149
exploration/Actions Mean            0.00138951
exploration/Actions Std             0.202213
exploration/Actions Max             0.99674
exploration/Actions Min            -0.999574
exploration/Num Paths               5
exploration/Average Returns       -81.6364
evaluation/num steps total     111000
evaluation/num paths total       1110
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.11215
evaluation/Rewards Std              0.886006
evaluation/Rewards Max             -0.0455307
evaluation/Rewards Min             -8.16279
evaluation/Returns Mean          -111.215
evaluation/Returns Std             62.1772
evaluation/Returns Max             -8.17045
evaluation/Returns Min           -192.918
evaluation/Actions Mean            -0.000313018
evaluation/Actions Std              0.162413
evaluation/Actions Max              0.997139
evaluation/Actions Min             -0.998293
evaluation/Num Paths               15
evaluation/Average Returns       -111.215
time/data storing (s)               0.00291444
time/evaluation sampling (s)        0.328852
time/exploration sampling (s)       0.141285
time/logging (s)                    0.00484046
time/saving (s)                     0.00195539
time/training (s)                   1.92189
time/epoch (s)                      2.40174
time/total (s)                    185.1
Epoch                              73
-----------------------------  ----------------
2019-04-22 23:30:21.218240 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 74 finished
-----------------------------  ---------------
replay_buffer/size              37700
trainer/QF1 Loss                   70.5484
trainer/QF2 Loss                   69.7525
trainer/Policy Loss                58.1936
trainer/Q1 Predictions Mean       -56.8858
trainer/Q1 Predictions Std         32.5734
trainer/Q1 Predictions Max        -20.0517
trainer/Q1 Predictions Min       -103.784
trainer/Q2 Predictions Mean       -56.8881
trainer/Q2 Predictions Std         32.5903
trainer/Q2 Predictions Max        -19.9706
trainer/Q2 Predictions Min       -104.079
trainer/Q Targets Mean            -56.655
trainer/Q Targets Std              33.1791
trainer/Q Targets Max              -1.40353
trainer/Q Targets Min            -105.077
trainer/Log Pis Mean                1.80487
trainer/Log Pis Std                 1.44462
trainer/Log Pis Max                 6.2343
trainer/Log Pis Min                -5.58228
trainer/Policy mu Mean              0.0406386
trainer/Policy mu Std               0.719246
trainer/Policy mu Max               2.88734
trainer/Policy mu Min              -2.3968
trainer/Policy log std Mean        -1.95943
trainer/Policy log std Std          0.519338
trainer/Policy log std Max         -0.43003
trainer/Policy log std Min         -2.84905
trainer/Alpha                       0.0639745
trainer/Alpha Loss                 -0.536448
exploration/num steps total     37700
exploration/num paths total       377
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.25919
exploration/Rewards Std             0.786193
exploration/Rewards Max            -0.520719
exploration/Rewards Min            -7.81715
exploration/Returns Mean         -125.919
exploration/Returns Std            36.6142
exploration/Returns Max           -83.8395
exploration/Returns Min          -186.694
exploration/Actions Mean            0.0172926
exploration/Actions Std             0.216996
exploration/Actions Max             0.999148
exploration/Actions Min            -0.916601
exploration/Num Paths               5
exploration/Average Returns      -125.919
evaluation/num steps total     112500
evaluation/num paths total       1125
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.939396
evaluation/Rewards Std              1.02977
evaluation/Rewards Max             -0.108078
evaluation/Rewards Min             -9.69627
evaluation/Returns Mean           -93.9396
evaluation/Returns Std             53.2925
evaluation/Returns Max            -27.8212
evaluation/Returns Min           -206.215
evaluation/Actions Mean            -0.0155644
evaluation/Actions Std              0.176495
evaluation/Actions Max              0.994614
evaluation/Actions Min             -0.998307
evaluation/Num Paths               15
evaluation/Average Returns        -93.9396
time/data storing (s)               0.00301548
time/evaluation sampling (s)        0.325667
time/exploration sampling (s)       0.143317
time/logging (s)                    0.00492877
time/saving (s)                     0.00195231
time/training (s)                   1.91795
time/epoch (s)                      2.39683
time/total (s)                    187.501
Epoch                              74
-----------------------------  ---------------
2019-04-22 23:30:23.628290 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 75 finished
-----------------------------  ---------------
replay_buffer/size              38200
trainer/QF1 Loss                    1.22139
trainer/QF2 Loss                    1.21108
trainer/Policy Loss                66.7095
trainer/Q1 Predictions Mean       -65.2734
trainer/Q1 Predictions Std         29.3709
trainer/Q1 Predictions Max        -20.3645
trainer/Q1 Predictions Min       -104.505
trainer/Q2 Predictions Mean       -65.2621
trainer/Q2 Predictions Std         29.38
trainer/Q2 Predictions Max        -20.3706
trainer/Q2 Predictions Min       -104.487
trainer/Q Targets Mean            -66.0559
trainer/Q Targets Std              29.9505
trainer/Q Targets Max             -20.6008
trainer/Q Targets Min            -106.923
trainer/Log Pis Mean                2.20152
trainer/Log Pis Std                 1.3519
trainer/Log Pis Max                 5.55003
trainer/Log Pis Min                -2.60198
trainer/Policy mu Mean             -0.0854209
trainer/Policy mu Std               0.890122
trainer/Policy mu Max               3.33587
trainer/Policy mu Min              -3.06061
trainer/Policy log std Mean        -1.92573
trainer/Policy log std Std          0.578901
trainer/Policy log std Max         -0.287822
trainer/Policy log std Min         -2.86737
trainer/Alpha                       0.0622188
trainer/Alpha Loss                  0.559671
exploration/num steps total     38200
exploration/num paths total       382
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.09276
exploration/Rewards Std             1.10305
exploration/Rewards Max            -0.00456188
exploration/Rewards Min            -8.41045
exploration/Returns Mean         -109.276
exploration/Returns Std            78.8521
exploration/Returns Max           -26.2596
exploration/Returns Min          -226.351
exploration/Actions Mean           -0.0117885
exploration/Actions Std             0.232308
exploration/Actions Max             0.998876
exploration/Actions Min            -0.998934
exploration/Num Paths               5
exploration/Average Returns      -109.276
evaluation/num steps total     114000
evaluation/num paths total       1140
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.0415
evaluation/Rewards Std              1.05871
evaluation/Rewards Max             -0.0776732
evaluation/Rewards Min            -10.3961
evaluation/Returns Mean          -104.15
evaluation/Returns Std             52.1607
evaluation/Returns Max            -15.8582
evaluation/Returns Min           -209.943
evaluation/Actions Mean             0.0243195
evaluation/Actions Std              0.179976
evaluation/Actions Max              0.998747
evaluation/Actions Min             -0.993458
evaluation/Num Paths               15
evaluation/Average Returns       -104.15
time/data storing (s)               0.00300261
time/evaluation sampling (s)        0.32664
time/exploration sampling (s)       0.142167
time/logging (s)                    0.00487851
time/saving (s)                     0.00195856
time/training (s)                   1.92535
time/epoch (s)                      2.404
time/total (s)                    189.91
Epoch                              75
-----------------------------  ---------------
2019-04-22 23:30:26.042921 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 76 finished
-----------------------------  ----------------
replay_buffer/size              38700
trainer/QF1 Loss                   95.7226
trainer/QF2 Loss                   90.7538
trainer/Policy Loss                63.0784
trainer/Q1 Predictions Mean       -61.8868
trainer/Q1 Predictions Std         33.1097
trainer/Q1 Predictions Max        -19.9134
trainer/Q1 Predictions Min       -138.157
trainer/Q2 Predictions Mean       -61.8477
trainer/Q2 Predictions Std         33.1399
trainer/Q2 Predictions Max        -19.9372
trainer/Q2 Predictions Min       -139.096
trainer/Q Targets Mean            -61.3125
trainer/Q Targets Std              33.7691
trainer/Q Targets Max              -7.58523
trainer/Q Targets Min            -143.396
trainer/Log Pis Mean                1.97444
trainer/Log Pis Std                 1.34111
trainer/Log Pis Max                 5.99131
trainer/Log Pis Min                -2.572
trainer/Policy mu Mean             -0.10457
trainer/Policy mu Std               0.893975
trainer/Policy mu Max               2.62034
trainer/Policy mu Min              -3.18142
trainer/Policy log std Mean        -1.84268
trainer/Policy log std Std          0.546899
trainer/Policy log std Max         -0.387603
trainer/Policy log std Min         -2.71186
trainer/Alpha                       0.0647691
trainer/Alpha Loss                 -0.0699588
exploration/num steps total     38700
exploration/num paths total       387
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.01006
exploration/Rewards Std             0.815445
exploration/Rewards Max            -0.011684
exploration/Rewards Min            -7.81474
exploration/Returns Mean         -101.006
exploration/Returns Std            32.4421
exploration/Returns Max           -48.8849
exploration/Returns Min          -135.953
exploration/Actions Mean            0.000127635
exploration/Actions Std             0.232953
exploration/Actions Max             0.995492
exploration/Actions Min            -0.994489
exploration/Num Paths               5
exploration/Average Returns      -101.006
evaluation/num steps total     115500
evaluation/num paths total       1155
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.999439
evaluation/Rewards Std              1.10223
evaluation/Rewards Max             -0.0733342
evaluation/Rewards Min            -10.7639
evaluation/Returns Mean           -99.9439
evaluation/Returns Std             56.8344
evaluation/Returns Max            -33.4512
evaluation/Returns Min           -231.92
evaluation/Actions Mean            -0.0057137
evaluation/Actions Std              0.185695
evaluation/Actions Max              0.995244
evaluation/Actions Min             -0.998525
evaluation/Num Paths               15
evaluation/Average Returns        -99.9439
time/data storing (s)               0.00286737
time/evaluation sampling (s)        0.332978
time/exploration sampling (s)       0.143089
time/logging (s)                    0.00486928
time/saving (s)                     0.00157596
time/training (s)                   1.9234
time/epoch (s)                      2.40878
time/total (s)                    192.323
Epoch                              76
-----------------------------  ----------------
2019-04-22 23:30:28.441884 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 77 finished
-----------------------------  ---------------
replay_buffer/size              39200
trainer/QF1 Loss                    5.07156
trainer/QF2 Loss                    4.88963
trainer/Policy Loss                62.5046
trainer/Q1 Predictions Mean       -61.105
trainer/Q1 Predictions Std         31.2024
trainer/Q1 Predictions Max        -19.9361
trainer/Q1 Predictions Min       -107.333
trainer/Q2 Predictions Mean       -61.1468
trainer/Q2 Predictions Std         31.205
trainer/Q2 Predictions Max        -19.9844
trainer/Q2 Predictions Min       -107.901
trainer/Q Targets Mean            -61.6873
trainer/Q Targets Std              31.7561
trainer/Q Targets Max              -0.212766
trainer/Q Targets Min            -108.619
trainer/Log Pis Mean                2.07335
trainer/Log Pis Std                 1.26304
trainer/Log Pis Max                 5.7843
trainer/Log Pis Min                -2.85791
trainer/Policy mu Mean              0.0791644
trainer/Policy mu Std               0.821989
trainer/Policy mu Max               3.43868
trainer/Policy mu Min              -2.38359
trainer/Policy log std Mean        -1.98765
trainer/Policy log std Std          0.535489
trainer/Policy log std Max         -0.491002
trainer/Policy log std Min         -2.77086
trainer/Alpha                       0.0648248
trainer/Alpha Loss                  0.200704
exploration/num steps total     39200
exploration/num paths total       392
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.908048
exploration/Rewards Std             0.840552
exploration/Rewards Max            -0.0297671
exploration/Rewards Min            -9.67173
exploration/Returns Mean          -90.8048
exploration/Returns Std            35.0379
exploration/Returns Max           -26.0973
exploration/Returns Min          -126.061
exploration/Actions Mean            0.0109952
exploration/Actions Std             0.21722
exploration/Actions Max             0.995118
exploration/Actions Min            -0.999595
exploration/Num Paths               5
exploration/Average Returns       -90.8048
evaluation/num steps total     117000
evaluation/num paths total       1170
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.08256
evaluation/Rewards Std              1.2294
evaluation/Rewards Max             -0.192495
evaluation/Rewards Min             -9.78211
evaluation/Returns Mean          -108.256
evaluation/Returns Std             70.0789
evaluation/Returns Max            -36.9868
evaluation/Returns Min           -221.879
evaluation/Actions Mean            -0.0136594
evaluation/Actions Std              0.186066
evaluation/Actions Max              0.998899
evaluation/Actions Min             -0.997407
evaluation/Num Paths               15
evaluation/Average Returns       -108.256
time/data storing (s)               0.00301013
time/evaluation sampling (s)        0.330797
time/exploration sampling (s)       0.14208
time/logging (s)                    0.00482027
time/saving (s)                     0.00204407
time/training (s)                   1.91013
time/epoch (s)                      2.39289
time/total (s)                    194.72
Epoch                              77
-----------------------------  ---------------
2019-04-22 23:30:30.850826 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 78 finished
-----------------------------  ---------------
replay_buffer/size              39700
trainer/QF1 Loss                   30.914
trainer/QF2 Loss                   30.861
trainer/Policy Loss                60.9616
trainer/Q1 Predictions Mean       -59.7608
trainer/Q1 Predictions Std         32.2427
trainer/Q1 Predictions Max        -19.7614
trainer/Q1 Predictions Min       -137.751
trainer/Q2 Predictions Mean       -59.7933
trainer/Q2 Predictions Std         32.3062
trainer/Q2 Predictions Max        -19.654
trainer/Q2 Predictions Min       -137.686
trainer/Q Targets Mean            -59.8407
trainer/Q Targets Std              33.2657
trainer/Q Targets Max              -1.48411
trainer/Q Targets Min            -139.322
trainer/Log Pis Mean                2.06249
trainer/Log Pis Std                 1.27412
trainer/Log Pis Max                 6.26122
trainer/Log Pis Min                -1.76317
trainer/Policy mu Mean              0.0429179
trainer/Policy mu Std               0.837904
trainer/Policy mu Max               3.30159
trainer/Policy mu Min              -3.17641
trainer/Policy log std Mean        -1.91683
trainer/Policy log std Std          0.544106
trainer/Policy log std Max         -0.430414
trainer/Policy log std Min         -2.75168
trainer/Alpha                       0.0623802
trainer/Alpha Loss                  0.173383
exploration/num steps total     39700
exploration/num paths total       397
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.72211
exploration/Rewards Std             0.804381
exploration/Rewards Max            -0.0816826
exploration/Rewards Min            -8.99204
exploration/Returns Mean          -72.211
exploration/Returns Std            12.2272
exploration/Returns Max           -54.807
exploration/Returns Min           -86.0849
exploration/Actions Mean            0.00506526
exploration/Actions Std             0.201132
exploration/Actions Max             0.995369
exploration/Actions Min            -0.997111
exploration/Num Paths               5
exploration/Average Returns       -72.211
evaluation/num steps total     118500
evaluation/num paths total       1185
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.14896
evaluation/Rewards Std              1.00466
evaluation/Rewards Max             -0.421035
evaluation/Rewards Min             -9.82468
evaluation/Returns Mean          -114.896
evaluation/Returns Std             53.3215
evaluation/Returns Max            -59.8258
evaluation/Returns Min           -221.587
evaluation/Actions Mean             0.0101422
evaluation/Actions Std              0.173567
evaluation/Actions Max              0.998817
evaluation/Actions Min             -0.997674
evaluation/Num Paths               15
evaluation/Average Returns       -114.896
time/data storing (s)               0.00292822
time/evaluation sampling (s)        0.332342
time/exploration sampling (s)       0.141472
time/logging (s)                    0.00480503
time/saving (s)                     0.00196648
time/training (s)                   1.91934
time/epoch (s)                      2.40285
time/total (s)                    197.127
Epoch                              78
-----------------------------  ---------------
2019-04-22 23:30:33.264547 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 79 finished
-----------------------------  ---------------
replay_buffer/size              40200
trainer/QF1 Loss                  149.978
trainer/QF2 Loss                  149.347
trainer/Policy Loss                64.363
trainer/Q1 Predictions Mean       -63.1416
trainer/Q1 Predictions Std         29.0969
trainer/Q1 Predictions Max        -18.2767
trainer/Q1 Predictions Min       -118.121
trainer/Q2 Predictions Mean       -63.1912
trainer/Q2 Predictions Std         29.1326
trainer/Q2 Predictions Max        -18.0131
trainer/Q2 Predictions Min       -118.319
trainer/Q Targets Mean            -62.9818
trainer/Q Targets Std              30.9901
trainer/Q Targets Max              -1.84378
trainer/Q Targets Min            -120.957
trainer/Log Pis Mean                2.20619
trainer/Log Pis Std                 1.82717
trainer/Log Pis Max                 8.11068
trainer/Log Pis Min                -1.83485
trainer/Policy mu Mean              0.151496
trainer/Policy mu Std               0.969127
trainer/Policy mu Max               3.7137
trainer/Policy mu Min              -2.5
trainer/Policy log std Mean        -1.83734
trainer/Policy log std Std          0.632181
trainer/Policy log std Max         -0.449716
trainer/Policy log std Min         -2.73806
trainer/Alpha                       0.0612338
trainer/Alpha Loss                  0.575879
exploration/num steps total     40200
exploration/num paths total       402
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.18423
exploration/Rewards Std             1.49596
exploration/Rewards Max            -0.014891
exploration/Rewards Min            -9.83454
exploration/Returns Mean         -118.423
exploration/Returns Std            47.1739
exploration/Returns Max           -57.3058
exploration/Returns Min          -202.476
exploration/Actions Mean            0.0146674
exploration/Actions Std             0.242604
exploration/Actions Max             0.999699
exploration/Actions Min            -0.999164
exploration/Num Paths               5
exploration/Average Returns      -118.423
evaluation/num steps total     120000
evaluation/num paths total       1200
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.77329
evaluation/Rewards Std              0.90567
evaluation/Rewards Max             -0.0939075
evaluation/Rewards Min             -8.45525
evaluation/Returns Mean           -77.329
evaluation/Returns Std             55.746
evaluation/Returns Max            -10.0605
evaluation/Returns Min           -200.767
evaluation/Actions Mean            -0.0066784
evaluation/Actions Std              0.157484
evaluation/Actions Max              0.997288
evaluation/Actions Min             -0.99675
evaluation/Num Paths               15
evaluation/Average Returns        -77.329
time/data storing (s)               0.0030055
time/evaluation sampling (s)        0.32925
time/exploration sampling (s)       0.142908
time/logging (s)                    0.00482059
time/saving (s)                     0.00195179
time/training (s)                   1.92604
time/epoch (s)                      2.40798
time/total (s)                    199.539
Epoch                              79
-----------------------------  ---------------
2019-04-22 23:30:35.685128 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 80 finished
-----------------------------  ---------------
replay_buffer/size              40700
trainer/QF1 Loss                  101.359
trainer/QF2 Loss                  101.434
trainer/Policy Loss                61.4941
trainer/Q1 Predictions Mean       -60.2679
trainer/Q1 Predictions Std         31.9384
trainer/Q1 Predictions Max        -18.9726
trainer/Q1 Predictions Min       -104.818
trainer/Q2 Predictions Mean       -60.2535
trainer/Q2 Predictions Std         31.9103
trainer/Q2 Predictions Max        -18.961
trainer/Q2 Predictions Min       -105.053
trainer/Q Targets Mean            -60.2173
trainer/Q Targets Std              32.7076
trainer/Q Targets Max              -4.04721
trainer/Q Targets Min            -108.003
trainer/Log Pis Mean                1.85793
trainer/Log Pis Std                 1.47233
trainer/Log Pis Max                 8.40848
trainer/Log Pis Min                -3.2218
trainer/Policy mu Mean              0.0227714
trainer/Policy mu Std               0.875796
trainer/Policy mu Max               2.96884
trainer/Policy mu Min              -2.52697
trainer/Policy log std Mean        -1.85923
trainer/Policy log std Std          0.573265
trainer/Policy log std Max         -0.362031
trainer/Policy log std Min         -2.74486
trainer/Alpha                       0.0646142
trainer/Alpha Loss                 -0.389182
exploration/num steps total     40700
exploration/num paths total       407
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.51367
exploration/Rewards Std             1.0433
exploration/Rewards Max            -0.289402
exploration/Rewards Min            -9.8915
exploration/Returns Mean         -151.367
exploration/Returns Std            57.4246
exploration/Returns Max           -65.9713
exploration/Returns Min          -213.404
exploration/Actions Mean            0.00894157
exploration/Actions Std             0.203012
exploration/Actions Max             0.997501
exploration/Actions Min            -0.999909
exploration/Num Paths               5
exploration/Average Returns      -151.367
evaluation/num steps total     121500
evaluation/num paths total       1215
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.00613
evaluation/Rewards Std              1.04888
evaluation/Rewards Max             -0.0598445
evaluation/Rewards Min            -10.2273
evaluation/Returns Mean          -100.613
evaluation/Returns Std             59.3197
evaluation/Returns Max            -14.5525
evaluation/Returns Min           -209.338
evaluation/Actions Mean             0.00791192
evaluation/Actions Std              0.182535
evaluation/Actions Max              0.997531
evaluation/Actions Min             -0.994662
evaluation/Num Paths               15
evaluation/Average Returns       -100.613
time/data storing (s)               0.00281942
time/evaluation sampling (s)        0.331126
time/exploration sampling (s)       0.141336
time/logging (s)                    0.00434101
time/saving (s)                     0.00195229
time/training (s)                   1.93242
time/epoch (s)                      2.414
time/total (s)                    201.957
Epoch                              80
-----------------------------  ---------------
2019-04-22 23:30:38.090694 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 81 finished
-----------------------------  ---------------
replay_buffer/size              41200
trainer/QF1 Loss                   72.5308
trainer/QF2 Loss                   72.1548
trainer/Policy Loss                58.4968
trainer/Q1 Predictions Mean       -57.6018
trainer/Q1 Predictions Std         31.1108
trainer/Q1 Predictions Max        -18.9203
trainer/Q1 Predictions Min       -133.015
trainer/Q2 Predictions Mean       -57.5969
trainer/Q2 Predictions Std         31.1564
trainer/Q2 Predictions Max        -18.9
trainer/Q2 Predictions Min       -134.829
trainer/Q Targets Mean            -56.9554
trainer/Q Targets Std              31.4741
trainer/Q Targets Max              -1.65325
trainer/Q Targets Min            -134.381
trainer/Log Pis Mean                1.89389
trainer/Log Pis Std                 1.24102
trainer/Log Pis Max                 5.58389
trainer/Log Pis Min                -2.00534
trainer/Policy mu Mean              0.092193
trainer/Policy mu Std               0.768981
trainer/Policy mu Max               2.8687
trainer/Policy mu Min              -3.25405
trainer/Policy log std Mean        -1.91987
trainer/Policy log std Std          0.497308
trainer/Policy log std Max         -0.198862
trainer/Policy log std Min         -2.79728
trainer/Alpha                       0.0680924
trainer/Alpha Loss                 -0.285095
exploration/num steps total     41200
exploration/num paths total       412
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.816256
exploration/Rewards Std             0.816494
exploration/Rewards Max            -0.0378097
exploration/Rewards Min            -8.50341
exploration/Returns Mean          -81.6256
exploration/Returns Std            27.5113
exploration/Returns Max           -30.3687
exploration/Returns Min          -107.499
exploration/Actions Mean            0.0242857
exploration/Actions Std             0.217611
exploration/Actions Max             0.999499
exploration/Actions Min            -0.954414
exploration/Num Paths               5
exploration/Average Returns       -81.6256
evaluation/num steps total     123000
evaluation/num paths total       1230
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.559965
evaluation/Rewards Std              0.702025
evaluation/Rewards Max             -0.0312963
evaluation/Rewards Min             -7.77378
evaluation/Returns Mean           -55.9965
evaluation/Returns Std             21.8842
evaluation/Returns Max            -17.7685
evaluation/Returns Min           -100.325
evaluation/Actions Mean             0.0100503
evaluation/Actions Std              0.154882
evaluation/Actions Max              0.997626
evaluation/Actions Min             -0.994289
evaluation/Num Paths               15
evaluation/Average Returns        -55.9965
time/data storing (s)               0.00297717
time/evaluation sampling (s)        0.329083
time/exploration sampling (s)       0.139882
time/logging (s)                    0.00481542
time/saving (s)                     0.00195117
time/training (s)                   1.92172
time/epoch (s)                      2.40043
time/total (s)                    204.362
Epoch                              81
-----------------------------  ---------------
2019-04-22 23:30:40.513046 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 82 finished
-----------------------------  ---------------
replay_buffer/size              41700
trainer/QF1 Loss                   94.9478
trainer/QF2 Loss                   94.8697
trainer/Policy Loss                55.8687
trainer/Q1 Predictions Mean       -54.696
trainer/Q1 Predictions Std         31.6588
trainer/Q1 Predictions Max        -18.5568
trainer/Q1 Predictions Min       -116.831
trainer/Q2 Predictions Mean       -54.72
trainer/Q2 Predictions Std         31.739
trainer/Q2 Predictions Max        -18.5223
trainer/Q2 Predictions Min       -118.918
trainer/Q Targets Mean            -54.0014
trainer/Q Targets Std              31.8625
trainer/Q Targets Max              -2.32077
trainer/Q Targets Min            -117.932
trainer/Log Pis Mean                1.91046
trainer/Log Pis Std                 1.43237
trainer/Log Pis Max                 8.54686
trainer/Log Pis Min                -2.77465
trainer/Policy mu Mean              0.145739
trainer/Policy mu Std               0.847384
trainer/Policy mu Max               3.17417
trainer/Policy mu Min              -3.26999
trainer/Policy log std Mean        -1.92921
trainer/Policy log std Std          0.556132
trainer/Policy log std Max         -0.162087
trainer/Policy log std Min         -2.80094
trainer/Alpha                       0.0676847
trainer/Alpha Loss                 -0.24112
exploration/num steps total     41700
exploration/num paths total       417
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.661469
exploration/Rewards Std             0.841149
exploration/Rewards Max            -0.0444079
exploration/Rewards Min            -8.99355
exploration/Returns Mean          -66.1469
exploration/Returns Std            20.5579
exploration/Returns Max           -43.0295
exploration/Returns Min           -97.1339
exploration/Actions Mean           -0.00368767
exploration/Actions Std             0.196717
exploration/Actions Max             0.998898
exploration/Actions Min            -0.99883
exploration/Num Paths               5
exploration/Average Returns       -66.1469
evaluation/num steps total     124500
evaluation/num paths total       1245
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.769202
evaluation/Rewards Std              1.08328
evaluation/Rewards Max             -0.07059
evaluation/Rewards Min             -9.88597
evaluation/Returns Mean           -76.9202
evaluation/Returns Std             40.6605
evaluation/Returns Max            -42.6815
evaluation/Returns Min           -216.549
evaluation/Actions Mean            -0.00264817
evaluation/Actions Std              0.190549
evaluation/Actions Max              0.999014
evaluation/Actions Min             -0.995027
evaluation/Num Paths               15
evaluation/Average Returns        -76.9202
time/data storing (s)               0.00285713
time/evaluation sampling (s)        0.333906
time/exploration sampling (s)       0.141534
time/logging (s)                    0.00477503
time/saving (s)                     0.00154699
time/training (s)                   1.93159
time/epoch (s)                      2.41621
time/total (s)                    206.782
Epoch                              82
-----------------------------  ---------------
2019-04-22 23:30:42.965588 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 83 finished
-----------------------------  ---------------
replay_buffer/size              42200
trainer/QF1 Loss                    1.32187
trainer/QF2 Loss                    1.09566
trainer/Policy Loss                55.6572
trainer/Q1 Predictions Mean       -54.3193
trainer/Q1 Predictions Std         30.4215
trainer/Q1 Predictions Max        -17.9892
trainer/Q1 Predictions Min       -154.405
trainer/Q2 Predictions Mean       -54.3351
trainer/Q2 Predictions Std         30.451
trainer/Q2 Predictions Max        -17.6294
trainer/Q2 Predictions Min       -153.803
trainer/Q Targets Mean            -55.0051
trainer/Q Targets Std              30.476
trainer/Q Targets Max             -18.3749
trainer/Q Targets Min            -148.67
trainer/Log Pis Mean                2.32343
trainer/Log Pis Std                 1.40437
trainer/Log Pis Max                 8.96795
trainer/Log Pis Min                -1.51292
trainer/Policy mu Mean             -0.0601224
trainer/Policy mu Std               0.883389
trainer/Policy mu Max               3.58806
trainer/Policy mu Min              -3.08907
trainer/Policy log std Mean        -1.96114
trainer/Policy log std Std          0.563656
trainer/Policy log std Max         -0.379255
trainer/Policy log std Min         -2.98854
trainer/Alpha                       0.0671276
trainer/Alpha Loss                  0.873686
exploration/num steps total     42200
exploration/num paths total       422
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.18281
exploration/Rewards Std             1.34371
exploration/Rewards Max            -0.0761614
exploration/Rewards Min           -10.4516
exploration/Returns Mean         -118.281
exploration/Returns Std            64.3199
exploration/Returns Max           -65.1742
exploration/Returns Min          -242.791
exploration/Actions Mean           -0.0130489
exploration/Actions Std             0.242883
exploration/Actions Max             0.988042
exploration/Actions Min            -0.999724
exploration/Num Paths               5
exploration/Average Returns      -118.281
evaluation/num steps total     126000
evaluation/num paths total       1260
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.931639
evaluation/Rewards Std              1.22674
evaluation/Rewards Max             -0.141794
evaluation/Rewards Min            -11.6977
evaluation/Returns Mean           -93.1639
evaluation/Returns Std             74.3611
evaluation/Returns Max            -15.1104
evaluation/Returns Min           -245.049
evaluation/Actions Mean            -0.00359328
evaluation/Actions Std              0.187812
evaluation/Actions Max              0.998211
evaluation/Actions Min             -0.998961
evaluation/Num Paths               15
evaluation/Average Returns        -93.1639
time/data storing (s)               0.00299172
time/evaluation sampling (s)        0.32479
time/exploration sampling (s)       0.142968
time/logging (s)                    0.00483343
time/saving (s)                     0.0113434
time/training (s)                   1.95959
time/epoch (s)                      2.44652
time/total (s)                    209.233
Epoch                              83
-----------------------------  ---------------
2019-04-22 23:30:45.385264 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 84 finished
-----------------------------  ---------------
replay_buffer/size              42700
trainer/QF1 Loss                    1.61094
trainer/QF2 Loss                    1.47777
trainer/Policy Loss                53.1585
trainer/Q1 Predictions Mean       -51.9667
trainer/Q1 Predictions Std         30.4687
trainer/Q1 Predictions Max        -17.7555
trainer/Q1 Predictions Min       -103.446
trainer/Q2 Predictions Mean       -52.0113
trainer/Q2 Predictions Std         30.4867
trainer/Q2 Predictions Max        -17.6883
trainer/Q2 Predictions Min       -103.665
trainer/Q Targets Mean            -53.0372
trainer/Q Targets Std              30.8083
trainer/Q Targets Max             -17.9194
trainer/Q Targets Min            -104.878
trainer/Log Pis Mean                2.02085
trainer/Log Pis Std                 1.30921
trainer/Log Pis Max                 8.70987
trainer/Log Pis Min                -0.384974
trainer/Policy mu Mean              0.120233
trainer/Policy mu Std               0.888523
trainer/Policy mu Max               3.36201
trainer/Policy mu Min              -3.60412
trainer/Policy log std Mean        -1.89333
trainer/Policy log std Std          0.558128
trainer/Policy log std Max         -0.295393
trainer/Policy log std Min         -2.79404
trainer/Alpha                       0.0667353
trainer/Alpha Loss                  0.0564436
exploration/num steps total     42700
exploration/num paths total       427
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.974498
exploration/Rewards Std             1.31601
exploration/Rewards Max            -0.0330191
exploration/Rewards Min           -10.6679
exploration/Returns Mean          -97.4498
exploration/Returns Std            23.5229
exploration/Returns Max           -66.8483
exploration/Returns Min          -127.061
exploration/Actions Mean           -0.00296994
exploration/Actions Std             0.256147
exploration/Actions Max             0.999971
exploration/Actions Min            -0.999636
exploration/Num Paths               5
exploration/Average Returns       -97.4498
evaluation/num steps total     127500
evaluation/num paths total       1275
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.910523
evaluation/Rewards Std              1.08972
evaluation/Rewards Max             -0.223614
evaluation/Rewards Min            -10.8325
evaluation/Returns Mean           -91.0523
evaluation/Returns Std             44.0353
evaluation/Returns Max            -28.8989
evaluation/Returns Min           -221.821
evaluation/Actions Mean             0.00920106
evaluation/Actions Std              0.192487
evaluation/Actions Max              0.998692
evaluation/Actions Min             -0.998945
evaluation/Num Paths               15
evaluation/Average Returns        -91.0523
time/data storing (s)               0.00294152
time/evaluation sampling (s)        0.331271
time/exploration sampling (s)       0.141096
time/logging (s)                    0.00485471
time/saving (s)                     0.0018029
time/training (s)                   1.93141
time/epoch (s)                      2.41338
time/total (s)                    211.651
Epoch                              84
-----------------------------  ---------------
2019-04-22 23:30:47.860738 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 85 finished
-----------------------------  ---------------
replay_buffer/size              43200
trainer/QF1 Loss                   61.5112
trainer/QF2 Loss                   61.6271
trainer/Policy Loss                60.1186
trainer/Q1 Predictions Mean       -59.0584
trainer/Q1 Predictions Std         28.7407
trainer/Q1 Predictions Max        -17.9289
trainer/Q1 Predictions Min       -104.778
trainer/Q2 Predictions Mean       -59.0576
trainer/Q2 Predictions Std         28.7456
trainer/Q2 Predictions Max        -17.8245
trainer/Q2 Predictions Min       -104.897
trainer/Q Targets Mean            -58.9454
trainer/Q Targets Std              29.7193
trainer/Q Targets Max              -1.79133
trainer/Q Targets Min            -104.53
trainer/Log Pis Mean                1.93582
trainer/Log Pis Std                 1.3463
trainer/Log Pis Max                 6.76979
trainer/Log Pis Min                -1.26421
trainer/Policy mu Mean              0.138522
trainer/Policy mu Std               0.824025
trainer/Policy mu Max               2.94356
trainer/Policy mu Min              -3.81982
trainer/Policy log std Mean        -1.89357
trainer/Policy log std Std          0.529093
trainer/Policy log std Max         -0.340883
trainer/Policy log std Min         -2.75914
trainer/Alpha                       0.0674081
trainer/Alpha Loss                 -0.173091
exploration/num steps total     43200
exploration/num paths total       432
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.39922
exploration/Rewards Std             1.17663
exploration/Rewards Max            -0.0728298
exploration/Rewards Min            -9.59254
exploration/Returns Mean         -139.922
exploration/Returns Std            62.4168
exploration/Returns Max           -70.1344
exploration/Returns Min          -216.446
exploration/Actions Mean            0.0210781
exploration/Actions Std             0.218115
exploration/Actions Max             0.999924
exploration/Actions Min            -0.990469
exploration/Num Paths               5
exploration/Average Returns      -139.922
evaluation/num steps total     129000
evaluation/num paths total       1290
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.02265
evaluation/Rewards Std              1.0026
evaluation/Rewards Max             -0.330133
evaluation/Rewards Min            -10.7278
evaluation/Returns Mean          -102.265
evaluation/Returns Std             58.6467
evaluation/Returns Max            -42.3459
evaluation/Returns Min           -225.404
evaluation/Actions Mean             0.0020613
evaluation/Actions Std              0.170135
evaluation/Actions Max              0.998739
evaluation/Actions Min             -0.996849
evaluation/Num Paths               15
evaluation/Average Returns       -102.265
time/data storing (s)               0.00278119
time/evaluation sampling (s)        0.31862
time/exploration sampling (s)       0.144956
time/logging (s)                    0.0047594
time/saving (s)                     0.00197135
time/training (s)                   1.99591
time/epoch (s)                      2.46899
time/total (s)                    214.125
Epoch                              85
-----------------------------  ---------------
2019-04-22 23:30:50.278257 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 86 finished
-----------------------------  ---------------
replay_buffer/size              43700
trainer/QF1 Loss                   58.8848
trainer/QF2 Loss                   58.8495
trainer/Policy Loss                52.2704
trainer/Q1 Predictions Mean       -50.9987
trainer/Q1 Predictions Std         28.8024
trainer/Q1 Predictions Max        -17.4706
trainer/Q1 Predictions Min       -102.903
trainer/Q2 Predictions Mean       -50.9676
trainer/Q2 Predictions Std         28.7957
trainer/Q2 Predictions Max        -17.5181
trainer/Q2 Predictions Min       -103.213
trainer/Q Targets Mean            -50.8921
trainer/Q Targets Std              29.4226
trainer/Q Targets Max              -1.69748
trainer/Q Targets Min            -103.373
trainer/Log Pis Mean                1.84148
trainer/Log Pis Std                 1.33208
trainer/Log Pis Max                 6.01927
trainer/Log Pis Min                -3.81087
trainer/Policy mu Mean              0.0260416
trainer/Policy mu Std               0.682793
trainer/Policy mu Max               2.51232
trainer/Policy mu Min              -3.27221
trainer/Policy log std Mean        -1.97732
trainer/Policy log std Std          0.432556
trainer/Policy log std Max         -0.414924
trainer/Policy log std Min         -2.61708
trainer/Alpha                       0.0680863
trainer/Alpha Loss                 -0.425949
exploration/num steps total     43700
exploration/num paths total       437
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.85609
exploration/Rewards Std             0.774985
exploration/Rewards Max            -0.0173903
exploration/Rewards Min            -6.4252
exploration/Returns Mean          -85.609
exploration/Returns Std            54.9083
exploration/Returns Max           -27.0102
exploration/Returns Min          -185.748
exploration/Actions Mean           -0.00841476
exploration/Actions Std             0.195051
exploration/Actions Max             0.941984
exploration/Actions Min            -0.99906
exploration/Num Paths               5
exploration/Average Returns       -85.609
evaluation/num steps total     130500
evaluation/num paths total       1305
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.03883
evaluation/Rewards Std              1.10174
evaluation/Rewards Max             -0.143371
evaluation/Rewards Min            -11.8458
evaluation/Returns Mean          -103.883
evaluation/Returns Std             61.4918
evaluation/Returns Max            -20.9937
evaluation/Returns Min           -229.033
evaluation/Actions Mean            -0.00559323
evaluation/Actions Std              0.178262
evaluation/Actions Max              0.998598
evaluation/Actions Min             -0.997465
evaluation/Num Paths               15
evaluation/Average Returns       -103.883
time/data storing (s)               0.00290175
time/evaluation sampling (s)        0.333509
time/exploration sampling (s)       0.141573
time/logging (s)                    0.00476495
time/saving (s)                     0.00194449
time/training (s)                   1.92696
time/epoch (s)                      2.41165
time/total (s)                    216.54
Epoch                              86
-----------------------------  ---------------
2019-04-22 23:30:52.695558 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 87 finished
-----------------------------  ---------------
replay_buffer/size              44200
trainer/QF1 Loss                   23.1843
trainer/QF2 Loss                   23.4385
trainer/Policy Loss                52.9293
trainer/Q1 Predictions Mean       -51.6736
trainer/Q1 Predictions Std         26.8741
trainer/Q1 Predictions Max        -16.8984
trainer/Q1 Predictions Min       -122.628
trainer/Q2 Predictions Mean       -51.5568
trainer/Q2 Predictions Std         26.8116
trainer/Q2 Predictions Max        -16.8193
trainer/Q2 Predictions Min       -121.493
trainer/Q Targets Mean            -51.8443
trainer/Q Targets Std              27.6167
trainer/Q Targets Max              -0.961441
trainer/Q Targets Min            -122.962
trainer/Log Pis Mean                1.87225
trainer/Log Pis Std                 1.44655
trainer/Log Pis Max                 7.28219
trainer/Log Pis Min                -4.53365
trainer/Policy mu Mean             -0.0548474
trainer/Policy mu Std               0.746079
trainer/Policy mu Max               2.44128
trainer/Policy mu Min              -3.31808
trainer/Policy log std Mean        -1.98307
trainer/Policy log std Std          0.507059
trainer/Policy log std Max         -0.462195
trainer/Policy log std Min         -2.76109
trainer/Alpha                       0.0682845
trainer/Alpha Loss                 -0.342873
exploration/num steps total     44200
exploration/num paths total       442
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.957654
exploration/Rewards Std             0.576486
exploration/Rewards Max            -0.395417
exploration/Rewards Min            -5.81033
exploration/Returns Mean          -95.7654
exploration/Returns Std            37.8079
exploration/Returns Max           -72.5284
exploration/Returns Min          -170.808
exploration/Actions Mean            0.0154339
exploration/Actions Std             0.188086
exploration/Actions Max             0.994686
exploration/Actions Min            -0.979011
exploration/Num Paths               5
exploration/Average Returns       -95.7654
evaluation/num steps total     132000
evaluation/num paths total       1320
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.927536
evaluation/Rewards Std              1.18406
evaluation/Rewards Max             -0.0379807
evaluation/Rewards Min            -10.7427
evaluation/Returns Mean           -92.7536
evaluation/Returns Std             50.436
evaluation/Returns Max            -21.3905
evaluation/Returns Min           -194.34
evaluation/Actions Mean            -0.01211
evaluation/Actions Std              0.182112
evaluation/Actions Max              0.999314
evaluation/Actions Min             -0.998934
evaluation/Num Paths               15
evaluation/Average Returns        -92.7536
time/data storing (s)               0.0029666
time/evaluation sampling (s)        0.331478
time/exploration sampling (s)       0.142197
time/logging (s)                    0.0048026
time/saving (s)                     0.00198532
time/training (s)                   1.92752
time/epoch (s)                      2.41095
time/total (s)                    218.956
Epoch                              87
-----------------------------  ---------------
2019-04-22 23:30:55.104817 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 88 finished
-----------------------------  ----------------
replay_buffer/size              44700
trainer/QF1 Loss                   45.3888
trainer/QF2 Loss                   45.0078
trainer/Policy Loss                53.0996
trainer/Q1 Predictions Mean       -51.4287
trainer/Q1 Predictions Std         29.7986
trainer/Q1 Predictions Max        -16.9605
trainer/Q1 Predictions Min       -109.661
trainer/Q2 Predictions Mean       -51.4494
trainer/Q2 Predictions Std         29.7825
trainer/Q2 Predictions Max        -17.0165
trainer/Q2 Predictions Min       -109.216
trainer/Q Targets Mean            -51.0196
trainer/Q Targets Std              30.2108
trainer/Q Targets Max              -2.54664
trainer/Q Targets Min            -110.904
trainer/Log Pis Mean                2.20042
trainer/Log Pis Std                 1.46531
trainer/Log Pis Max                 8.60602
trainer/Log Pis Min                -1.80243
trainer/Policy mu Mean              0.086193
trainer/Policy mu Std               0.901449
trainer/Policy mu Max               3.92606
trainer/Policy mu Min              -3.16384
trainer/Policy log std Mean        -1.92027
trainer/Policy log std Std          0.549675
trainer/Policy log std Max         -0.194966
trainer/Policy log std Min         -2.67315
trainer/Alpha                       0.0678345
trainer/Alpha Loss                  0.539292
exploration/num steps total     44700
exploration/num paths total       447
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.59769
exploration/Rewards Std             0.727304
exploration/Rewards Max            -0.00767778
exploration/Rewards Min            -6.70512
exploration/Returns Mean          -59.769
exploration/Returns Std            29.8382
exploration/Returns Max           -16.5477
exploration/Returns Min          -104.195
exploration/Actions Mean            0.0109184
exploration/Actions Std             0.196598
exploration/Actions Max             0.999881
exploration/Actions Min            -0.979094
exploration/Num Paths               5
exploration/Average Returns       -59.769
evaluation/num steps total     133500
evaluation/num paths total       1335
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.853351
evaluation/Rewards Std              1.09416
evaluation/Rewards Max             -0.0289616
evaluation/Rewards Min            -10.9917
evaluation/Returns Mean           -85.3351
evaluation/Returns Std             37.5964
evaluation/Returns Max            -36.7791
evaluation/Returns Min           -191.7
evaluation/Actions Mean             0.000629831
evaluation/Actions Std              0.180256
evaluation/Actions Max              0.998114
evaluation/Actions Min             -0.998339
evaluation/Num Paths               15
evaluation/Average Returns        -85.3351
time/data storing (s)               0.00296707
time/evaluation sampling (s)        0.3248
time/exploration sampling (s)       0.142237
time/logging (s)                    0.00476681
time/saving (s)                     0.00198097
time/training (s)                   1.92604
time/epoch (s)                      2.40279
time/total (s)                    221.363
Epoch                              88
-----------------------------  ----------------
2019-04-22 23:30:57.507637 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 89 finished
-----------------------------  ----------------
replay_buffer/size              45200
trainer/QF1 Loss                   12.9406
trainer/QF2 Loss                   12.8136
trainer/Policy Loss                52.1333
trainer/Q1 Predictions Mean       -51.0471
trainer/Q1 Predictions Std         27.5768
trainer/Q1 Predictions Max        -17.3751
trainer/Q1 Predictions Min       -108.841
trainer/Q2 Predictions Mean       -51.1021
trainer/Q2 Predictions Std         27.6263
trainer/Q2 Predictions Max        -17.2259
trainer/Q2 Predictions Min       -108.955
trainer/Q Targets Mean            -50.7934
trainer/Q Targets Std              28.597
trainer/Q Targets Max              -0.351242
trainer/Q Targets Min            -110.039
trainer/Log Pis Mean                1.90893
trainer/Log Pis Std                 1.57812
trainer/Log Pis Max                 9.33395
trainer/Log Pis Min                -1.68131
trainer/Policy mu Mean              0.321505
trainer/Policy mu Std               0.918308
trainer/Policy mu Max               3.66409
trainer/Policy mu Min              -3.04298
trainer/Policy log std Mean        -1.82515
trainer/Policy log std Std          0.54911
trainer/Policy log std Max         -0.104616
trainer/Policy log std Min         -2.62348
trainer/Alpha                       0.0689531
trainer/Alpha Loss                 -0.243541
exploration/num steps total     45200
exploration/num paths total       452
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.90485
exploration/Rewards Std             1.04546
exploration/Rewards Max            -0.0198748
exploration/Rewards Min            -9.2105
exploration/Returns Mean          -90.485
exploration/Returns Std            49.4916
exploration/Returns Max           -40.3554
exploration/Returns Min          -180.979
exploration/Actions Mean           -0.000654709
exploration/Actions Std             0.226817
exploration/Actions Max             0.999672
exploration/Actions Min            -0.997138
exploration/Num Paths               5
exploration/Average Returns       -90.485
evaluation/num steps total     135000
evaluation/num paths total       1350
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.18345
evaluation/Rewards Std              1.07916
evaluation/Rewards Max             -0.235566
evaluation/Rewards Min             -9.00075
evaluation/Returns Mean          -118.345
evaluation/Returns Std             50.4306
evaluation/Returns Max            -62.6089
evaluation/Returns Min           -202.326
evaluation/Actions Mean            -0.0128555
evaluation/Actions Std              0.183702
evaluation/Actions Max              0.999324
evaluation/Actions Min             -0.998817
evaluation/Num Paths               15
evaluation/Average Returns       -118.345
time/data storing (s)               0.00290078
time/evaluation sampling (s)        0.328689
time/exploration sampling (s)       0.139469
time/logging (s)                    0.00478822
time/saving (s)                     0.00198503
time/training (s)                   1.91857
time/epoch (s)                      2.3964
time/total (s)                    223.764
Epoch                              89
-----------------------------  ----------------
2019-04-22 23:30:59.914127 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 90 finished
-----------------------------  ---------------
replay_buffer/size              45700
trainer/QF1 Loss                    1.75363
trainer/QF2 Loss                    1.66428
trainer/Policy Loss                59.4375
trainer/Q1 Predictions Mean       -58.3041
trainer/Q1 Predictions Std         29.9839
trainer/Q1 Predictions Max        -16.4309
trainer/Q1 Predictions Min       -129.8
trainer/Q2 Predictions Mean       -58.2967
trainer/Q2 Predictions Std         30.0569
trainer/Q2 Predictions Max        -16.4136
trainer/Q2 Predictions Min       -130.002
trainer/Q Targets Mean            -59.3126
trainer/Q Targets Std              30.6249
trainer/Q Targets Max             -16.6495
trainer/Q Targets Min            -130.659
trainer/Log Pis Mean                1.98779
trainer/Log Pis Std                 1.27028
trainer/Log Pis Max                 6.25453
trainer/Log Pis Min                -1.52454
trainer/Policy mu Mean             -0.00396452
trainer/Policy mu Std               0.954706
trainer/Policy mu Max               3.1584
trainer/Policy mu Min              -3.28821
trainer/Policy log std Mean        -1.81373
trainer/Policy log std Std          0.570044
trainer/Policy log std Max         -0.223183
trainer/Policy log std Min         -2.54062
trainer/Alpha                       0.0691944
trainer/Alpha Loss                 -0.0326175
exploration/num steps total     45700
exploration/num paths total       457
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.780534
exploration/Rewards Std             1.14839
exploration/Rewards Max            -0.0039257
exploration/Rewards Min            -9.25077
exploration/Returns Mean          -78.0534
exploration/Returns Std            67.2481
exploration/Returns Max           -16.6651
exploration/Returns Min          -208.728
exploration/Actions Mean           -0.0151921
exploration/Actions Std             0.219671
exploration/Actions Max             0.988389
exploration/Actions Min            -0.999527
exploration/Num Paths               5
exploration/Average Returns       -78.0534
evaluation/num steps total     136500
evaluation/num paths total       1365
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.734805
evaluation/Rewards Std              1.18666
evaluation/Rewards Max             -0.0168581
evaluation/Rewards Min             -9.96171
evaluation/Returns Mean           -73.4805
evaluation/Returns Std             52.4011
evaluation/Returns Max             -5.9911
evaluation/Returns Min           -182.305
evaluation/Actions Mean            -0.00554698
evaluation/Actions Std              0.188567
evaluation/Actions Max              0.999512
evaluation/Actions Min             -0.998632
evaluation/Num Paths               15
evaluation/Average Returns        -73.4805
time/data storing (s)               0.00278362
time/evaluation sampling (s)        0.32637
time/exploration sampling (s)       0.141768
time/logging (s)                    0.00475627
time/saving (s)                     0.00197241
time/training (s)                   1.92238
time/epoch (s)                      2.40003
time/total (s)                    226.169
Epoch                              90
-----------------------------  ---------------
2019-04-22 23:31:02.339184 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 91 finished
-----------------------------  ----------------
replay_buffer/size              46200
trainer/QF1 Loss                    0.90895
trainer/QF2 Loss                    1.00225
trainer/Policy Loss                51.9314
trainer/Q1 Predictions Mean       -50.748
trainer/Q1 Predictions Std         29.0313
trainer/Q1 Predictions Max        -16.2507
trainer/Q1 Predictions Min       -114.315
trainer/Q2 Predictions Mean       -50.7305
trainer/Q2 Predictions Std         28.9864
trainer/Q2 Predictions Max        -16.2677
trainer/Q2 Predictions Min       -113.041
trainer/Q Targets Mean            -51.5485
trainer/Q Targets Std              29.3603
trainer/Q Targets Max             -16.5224
trainer/Q Targets Min            -115.002
trainer/Log Pis Mean                2.22559
trainer/Log Pis Std                 1.43559
trainer/Log Pis Max                 6.63971
trainer/Log Pis Min                -1.65122
trainer/Policy mu Mean              0.0226964
trainer/Policy mu Std               0.983637
trainer/Policy mu Max               2.9066
trainer/Policy mu Min              -2.56685
trainer/Policy log std Mean        -1.82824
trainer/Policy log std Std          0.587125
trainer/Policy log std Max         -0.491262
trainer/Policy log std Min         -2.66886
trainer/Alpha                       0.0687994
trainer/Alpha Loss                  0.603828
exploration/num steps total     46200
exploration/num paths total       462
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.582566
exploration/Rewards Std             1.09766
exploration/Rewards Max            -0.0112187
exploration/Rewards Min           -10.1675
exploration/Returns Mean          -58.2566
exploration/Returns Std            26.3387
exploration/Returns Max           -24.7957
exploration/Returns Min           -97.9309
exploration/Actions Mean           -0.00784844
exploration/Actions Std             0.217097
exploration/Actions Max             0.998807
exploration/Actions Min            -0.999401
exploration/Num Paths               5
exploration/Average Returns       -58.2566
evaluation/num steps total     138000
evaluation/num paths total       1380
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.12361
evaluation/Rewards Std              1.17841
evaluation/Rewards Max             -0.0359748
evaluation/Rewards Min             -9.28258
evaluation/Returns Mean          -112.361
evaluation/Returns Std             82.1564
evaluation/Returns Max            -13.2483
evaluation/Returns Min           -234.105
evaluation/Actions Mean            -2.15632e-05
evaluation/Actions Std              0.172941
evaluation/Actions Max              0.999123
evaluation/Actions Min             -0.995075
evaluation/Num Paths               15
evaluation/Average Returns       -112.361
time/data storing (s)               0.0030153
time/evaluation sampling (s)        0.330368
time/exploration sampling (s)       0.142146
time/logging (s)                    0.00390766
time/saving (s)                     0.00195691
time/training (s)                   1.93633
time/epoch (s)                      2.41772
time/total (s)                    228.591
Epoch                              91
-----------------------------  ----------------
2019-04-22 23:31:04.772547 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 92 finished
-----------------------------  ----------------
replay_buffer/size              46700
trainer/QF1 Loss                   93.0935
trainer/QF2 Loss                   93.0228
trainer/Policy Loss                56.2669
trainer/Q1 Predictions Mean       -55.2501
trainer/Q1 Predictions Std         28.0692
trainer/Q1 Predictions Max        -16.1677
trainer/Q1 Predictions Min       -103.221
trainer/Q2 Predictions Mean       -55.2202
trainer/Q2 Predictions Std         28.1001
trainer/Q2 Predictions Max        -16.1352
trainer/Q2 Predictions Min       -103.273
trainer/Q Targets Mean            -54.664
trainer/Q Targets Std              28.3012
trainer/Q Targets Max              -1.74336
trainer/Q Targets Min            -104.695
trainer/Log Pis Mean                1.90592
trainer/Log Pis Std                 1.60781
trainer/Log Pis Max                 6.5049
trainer/Log Pis Min                -5.882
trainer/Policy mu Mean              0.112917
trainer/Policy mu Std               0.845808
trainer/Policy mu Max               3.71436
trainer/Policy mu Min              -2.47586
trainer/Policy log std Mean        -1.91486
trainer/Policy log std Std          0.519123
trainer/Policy log std Max         -0.351516
trainer/Policy log std Min         -2.65726
trainer/Alpha                       0.0708069
trainer/Alpha Loss                 -0.249114
exploration/num steps total     46700
exploration/num paths total       467
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.855338
exploration/Rewards Std             1.26141
exploration/Rewards Max            -0.0212481
exploration/Rewards Min           -11.2251
exploration/Returns Mean          -85.5338
exploration/Returns Std            58.4111
exploration/Returns Max           -34.9111
exploration/Returns Min          -195.872
exploration/Actions Mean            0.00284747
exploration/Actions Std             0.226916
exploration/Actions Max             0.998212
exploration/Actions Min            -0.998224
exploration/Num Paths               5
exploration/Average Returns       -85.5338
evaluation/num steps total     139500
evaluation/num paths total       1395
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.693842
evaluation/Rewards Std              0.99204
evaluation/Rewards Max             -0.033381
evaluation/Rewards Min             -8.97328
evaluation/Returns Mean           -69.3842
evaluation/Returns Std             44.1525
evaluation/Returns Max            -12.7208
evaluation/Returns Min           -189.847
evaluation/Actions Mean            -0.000218301
evaluation/Actions Std              0.184587
evaluation/Actions Max              0.998833
evaluation/Actions Min             -0.997207
evaluation/Num Paths               15
evaluation/Average Returns        -69.3842
time/data storing (s)               0.00270686
time/evaluation sampling (s)        0.337478
time/exploration sampling (s)       0.151715
time/logging (s)                    0.00432959
time/saving (s)                     0.00192507
time/training (s)                   1.92912
time/epoch (s)                      2.42727
time/total (s)                    231.023
Epoch                              92
-----------------------------  ----------------
2019-04-22 23:31:07.184542 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 93 finished
-----------------------------  ---------------
replay_buffer/size              47200
trainer/QF1 Loss                  130.652
trainer/QF2 Loss                  130.809
trainer/Policy Loss                47.7111
trainer/Q1 Predictions Mean       -46.1855
trainer/Q1 Predictions Std         28.6958
trainer/Q1 Predictions Max        -16.2759
trainer/Q1 Predictions Min       -102.129
trainer/Q2 Predictions Mean       -46.2198
trainer/Q2 Predictions Std         28.7404
trainer/Q2 Predictions Max        -16.292
trainer/Q2 Predictions Min       -102.361
trainer/Q Targets Mean            -44.2526
trainer/Q Targets Std              29.9349
trainer/Q Targets Max              -0.231896
trainer/Q Targets Min            -104.169
trainer/Log Pis Mean                2.18202
trainer/Log Pis Std                 1.30484
trainer/Log Pis Max                 6.83122
trainer/Log Pis Min                -1.9952
trainer/Policy mu Mean              0.0165926
trainer/Policy mu Std               0.845929
trainer/Policy mu Max               3.3535
trainer/Policy mu Min              -3.30557
trainer/Policy log std Mean        -1.91553
trainer/Policy log std Std          0.513859
trainer/Policy log std Max         -0.296525
trainer/Policy log std Min         -2.56967
trainer/Alpha                       0.069358
trainer/Alpha Loss                  0.485719
exploration/num steps total     47200
exploration/num paths total       472
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.784774
exploration/Rewards Std             0.81869
exploration/Rewards Max            -0.00793628
exploration/Rewards Min            -6.33501
exploration/Returns Mean          -78.4774
exploration/Returns Std            62.8769
exploration/Returns Max           -30.7165
exploration/Returns Min          -198.943
exploration/Actions Mean           -0.0190994
exploration/Actions Std             0.19648
exploration/Actions Max             0.975774
exploration/Actions Min            -0.998406
exploration/Num Paths               5
exploration/Average Returns       -78.4774
evaluation/num steps total     141000
evaluation/num paths total       1410
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.821174
evaluation/Rewards Std              0.930074
evaluation/Rewards Max             -0.121103
evaluation/Rewards Min             -9.22308
evaluation/Returns Mean           -82.1174
evaluation/Returns Std             58.2584
evaluation/Returns Max            -21.1944
evaluation/Returns Min           -196.75
evaluation/Actions Mean             0.00367186
evaluation/Actions Std              0.171654
evaluation/Actions Max              0.998044
evaluation/Actions Min             -0.990117
evaluation/Num Paths               15
evaluation/Average Returns        -82.1174
time/data storing (s)               0.00280527
time/evaluation sampling (s)        0.330352
time/exploration sampling (s)       0.140759
time/logging (s)                    0.00436273
time/saving (s)                     0.0015602
time/training (s)                   1.92551
time/epoch (s)                      2.40534
time/total (s)                    233.433
Epoch                              93
-----------------------------  ---------------
2019-04-22 23:31:09.597930 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 94 finished
-----------------------------  ---------------
replay_buffer/size              47700
trainer/QF1 Loss                   23.3109
trainer/QF2 Loss                   23.4081
trainer/Policy Loss                48.6425
trainer/Q1 Predictions Mean       -47.1013
trainer/Q1 Predictions Std         26.9101
trainer/Q1 Predictions Max        -15.6008
trainer/Q1 Predictions Min        -99.5888
trainer/Q2 Predictions Mean       -47.1223
trainer/Q2 Predictions Std         26.9048
trainer/Q2 Predictions Max        -15.5843
trainer/Q2 Predictions Min        -99.5496
trainer/Q Targets Mean            -47.2599
trainer/Q Targets Std              27.887
trainer/Q Targets Max              -0.295229
trainer/Q Targets Min            -100.334
trainer/Log Pis Mean                2.05923
trainer/Log Pis Std                 1.40326
trainer/Log Pis Max                 7.4539
trainer/Log Pis Min                -4.28218
trainer/Policy mu Mean              0.045599
trainer/Policy mu Std               0.739411
trainer/Policy mu Max               2.77976
trainer/Policy mu Min              -2.98269
trainer/Policy log std Mean        -2.04978
trainer/Policy log std Std          0.484897
trainer/Policy log std Max         -0.344619
trainer/Policy log std Min         -2.76439
trainer/Alpha                       0.0695537
trainer/Alpha Loss                  0.157882
exploration/num steps total     47700
exploration/num paths total       477
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.11336
exploration/Rewards Std             1.06983
exploration/Rewards Max            -0.225524
exploration/Rewards Min            -8.43405
exploration/Returns Mean         -111.336
exploration/Returns Std            58.7187
exploration/Returns Max           -65.7654
exploration/Returns Min          -222.933
exploration/Actions Mean            0.0219784
exploration/Actions Std             0.221129
exploration/Actions Max             0.999826
exploration/Actions Min            -0.99746
exploration/Num Paths               5
exploration/Average Returns      -111.336
evaluation/num steps total     142500
evaluation/num paths total       1425
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.84664
evaluation/Rewards Std              1.18805
evaluation/Rewards Max             -0.0505341
evaluation/Rewards Min            -10.4834
evaluation/Returns Mean           -84.664
evaluation/Returns Std             57.8201
evaluation/Returns Max            -30.8111
evaluation/Returns Min           -220.082
evaluation/Actions Mean             0.00548364
evaluation/Actions Std              0.19614
evaluation/Actions Max              0.999457
evaluation/Actions Min             -0.998616
evaluation/Num Paths               15
evaluation/Average Returns        -84.664
time/data storing (s)               0.00288325
time/evaluation sampling (s)        0.327465
time/exploration sampling (s)       0.142287
time/logging (s)                    0.00351282
time/saving (s)                     0.00195963
time/training (s)                   1.9279
time/epoch (s)                      2.40601
time/total (s)                    235.843
Epoch                              94
-----------------------------  ---------------
2019-04-22 23:31:12.038361 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 95 finished
-----------------------------  ---------------
replay_buffer/size              48200
trainer/QF1 Loss                  126.255
trainer/QF2 Loss                  125.881
trainer/Policy Loss                53.2889
trainer/Q1 Predictions Mean       -52.0349
trainer/Q1 Predictions Std         27.3425
trainer/Q1 Predictions Max        -15.8719
trainer/Q1 Predictions Min       -106.032
trainer/Q2 Predictions Mean       -52.0398
trainer/Q2 Predictions Std         27.3647
trainer/Q2 Predictions Max        -15.832
trainer/Q2 Predictions Min       -106.591
trainer/Q Targets Mean            -50.3564
trainer/Q Targets Std              28.6084
trainer/Q Targets Max              -0.431357
trainer/Q Targets Min            -104.964
trainer/Log Pis Mean                1.99468
trainer/Log Pis Std                 1.17482
trainer/Log Pis Max                 6.57597
trainer/Log Pis Min                -1.75904
trainer/Policy mu Mean              0.0652338
trainer/Policy mu Std               0.842614
trainer/Policy mu Max               2.99671
trainer/Policy mu Min              -2.34061
trainer/Policy log std Mean        -1.91219
trainer/Policy log std Std          0.526884
trainer/Policy log std Max         -0.452356
trainer/Policy log std Min         -2.66751
trainer/Alpha                       0.0689954
trainer/Alpha Loss                 -0.0142154
exploration/num steps total     48200
exploration/num paths total       482
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.68175
exploration/Rewards Std             1.23159
exploration/Rewards Max            -0.0360706
exploration/Rewards Min            -8.33373
exploration/Returns Mean         -168.175
exploration/Returns Std            96.8867
exploration/Returns Max           -44.1353
exploration/Returns Min          -255.972
exploration/Actions Mean           -0.02481
exploration/Actions Std             0.215916
exploration/Actions Max             0.997552
exploration/Actions Min            -0.998505
exploration/Num Paths               5
exploration/Average Returns      -168.175
evaluation/num steps total     144000
evaluation/num paths total       1440
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.949874
evaluation/Rewards Std              1.16873
evaluation/Rewards Max             -0.0584459
evaluation/Rewards Min             -8.78419
evaluation/Returns Mean           -94.9874
evaluation/Returns Std             78.7381
evaluation/Returns Max            -34.2525
evaluation/Returns Min           -256.108
evaluation/Actions Mean            -0.00206072
evaluation/Actions Std              0.182281
evaluation/Actions Max              0.999509
evaluation/Actions Min             -0.996993
evaluation/Num Paths               15
evaluation/Average Returns        -94.9874
time/data storing (s)               0.00281407
time/evaluation sampling (s)        0.332239
time/exploration sampling (s)       0.151989
time/logging (s)                    0.00481868
time/saving (s)                     0.0109979
time/training (s)                   1.93402
time/epoch (s)                      2.43688
time/total (s)                    238.284
Epoch                              95
-----------------------------  ---------------
2019-04-22 23:31:14.455605 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 96 finished
-----------------------------  ---------------
replay_buffer/size              48700
trainer/QF1 Loss                    0.786127
trainer/QF2 Loss                    0.796048
trainer/Policy Loss                52.6929
trainer/Q1 Predictions Mean       -51.6572
trainer/Q1 Predictions Std         27.2541
trainer/Q1 Predictions Max        -15.3599
trainer/Q1 Predictions Min       -140.266
trainer/Q2 Predictions Mean       -51.6495
trainer/Q2 Predictions Std         27.2365
trainer/Q2 Predictions Max        -15.4295
trainer/Q2 Predictions Min       -140.232
trainer/Q Targets Mean            -52.238
trainer/Q Targets Std              27.4271
trainer/Q Targets Max             -15.6008
trainer/Q Targets Min            -142.094
trainer/Log Pis Mean                2.16857
trainer/Log Pis Std                 1.63163
trainer/Log Pis Max                 8.83045
trainer/Log Pis Min                -2.24614
trainer/Policy mu Mean              0.0693028
trainer/Policy mu Std               1.01171
trainer/Policy mu Max               3.392
trainer/Policy mu Min              -3.57331
trainer/Policy log std Mean        -1.82648
trainer/Policy log std Std          0.567996
trainer/Policy log std Max         -0.175279
trainer/Policy log std Min         -2.52772
trainer/Alpha                       0.071361
trainer/Alpha Loss                  0.445047
exploration/num steps total     48700
exploration/num paths total       487
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.502118
exploration/Rewards Std             0.960084
exploration/Rewards Max            -0.0202206
exploration/Rewards Min           -10.0846
exploration/Returns Mean          -50.2118
exploration/Returns Std            27.4455
exploration/Returns Max           -20.8878
exploration/Returns Min           -99.4789
exploration/Actions Mean            0.00857519
exploration/Actions Std             0.204943
exploration/Actions Max             0.99996
exploration/Actions Min            -0.997685
exploration/Num Paths               5
exploration/Average Returns       -50.2118
evaluation/num steps total     145500
evaluation/num paths total       1455
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.19017
evaluation/Rewards Std              1.19051
evaluation/Rewards Max             -0.0174744
evaluation/Rewards Min            -11.2409
evaluation/Returns Mean          -119.017
evaluation/Returns Std             80.9734
evaluation/Returns Max            -30.7932
evaluation/Returns Min           -253.022
evaluation/Actions Mean            -0.00557742
evaluation/Actions Std              0.183308
evaluation/Actions Max              0.998891
evaluation/Actions Min             -0.996881
evaluation/Num Paths               15
evaluation/Average Returns       -119.017
time/data storing (s)               0.00282699
time/evaluation sampling (s)        0.330416
time/exploration sampling (s)       0.139775
time/logging (s)                    0.00477651
time/saving (s)                     0.00192827
time/training (s)                   1.93099
time/epoch (s)                      2.41071
time/total (s)                    240.699
Epoch                              96
-----------------------------  ---------------
2019-04-22 23:31:16.871772 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 97 finished
-----------------------------  ----------------
replay_buffer/size              49200
trainer/QF1 Loss                    0.512966
trainer/QF2 Loss                    0.412514
trainer/Policy Loss                50.5863
trainer/Q1 Predictions Mean       -49.4358
trainer/Q1 Predictions Std         30.8262
trainer/Q1 Predictions Max        -15.2032
trainer/Q1 Predictions Min       -138.759
trainer/Q2 Predictions Mean       -49.4685
trainer/Q2 Predictions Std         30.8283
trainer/Q2 Predictions Max        -15.2185
trainer/Q2 Predictions Min       -137.998
trainer/Q Targets Mean            -49.6553
trainer/Q Targets Std              30.9332
trainer/Q Targets Max             -15.5225
trainer/Q Targets Min            -138.022
trainer/Log Pis Mean                2.12979
trainer/Log Pis Std                 1.36049
trainer/Log Pis Max                 7.80846
trainer/Log Pis Min                -1.57991
trainer/Policy mu Mean             -0.0260464
trainer/Policy mu Std               0.883782
trainer/Policy mu Max               2.49005
trainer/Policy mu Min              -3.09089
trainer/Policy log std Mean        -1.89568
trainer/Policy log std Std          0.537666
trainer/Policy log std Max         -0.323513
trainer/Policy log std Min         -2.64122
trainer/Alpha                       0.0725666
trainer/Alpha Loss                  0.340488
exploration/num steps total     49200
exploration/num paths total       492
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.16473
exploration/Rewards Std             1.07469
exploration/Rewards Max            -0.0150858
exploration/Rewards Min           -10.8258
exploration/Returns Mean         -116.473
exploration/Returns Std            80.6354
exploration/Returns Max           -33.3995
exploration/Returns Min          -231.705
exploration/Actions Mean           -0.0118045
exploration/Actions Std             0.198625
exploration/Actions Max             0.987476
exploration/Actions Min            -0.998622
exploration/Num Paths               5
exploration/Average Returns      -116.473
evaluation/num steps total     147000
evaluation/num paths total       1470
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.621598
evaluation/Rewards Std              0.894539
evaluation/Rewards Max             -0.0116437
evaluation/Rewards Min             -9.06201
evaluation/Returns Mean           -62.1598
evaluation/Returns Std             48.3035
evaluation/Returns Max             -6.28429
evaluation/Returns Min           -216.021
evaluation/Actions Mean             0.000513947
evaluation/Actions Std              0.155109
evaluation/Actions Max              0.998354
evaluation/Actions Min             -0.996973
evaluation/Num Paths               15
evaluation/Average Returns        -62.1598
time/data storing (s)               0.00281376
time/evaluation sampling (s)        0.31815
time/exploration sampling (s)       0.14128
time/logging (s)                    0.00408351
time/saving (s)                     0.00155836
time/training (s)                   1.94104
time/epoch (s)                      2.40892
time/total (s)                    243.112
Epoch                              97
-----------------------------  ----------------
2019-04-22 23:31:19.295738 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 98 finished
-----------------------------  ---------------
replay_buffer/size              49700
trainer/QF1 Loss                   97.3382
trainer/QF2 Loss                   97.0799
trainer/Policy Loss                48.4505
trainer/Q1 Predictions Mean       -47.4008
trainer/Q1 Predictions Std         23.7014
trainer/Q1 Predictions Max        -15.418
trainer/Q1 Predictions Min       -103.61
trainer/Q2 Predictions Mean       -47.3755
trainer/Q2 Predictions Std         23.6794
trainer/Q2 Predictions Max        -15.3915
trainer/Q2 Predictions Min       -103.959
trainer/Q Targets Mean            -46.2994
trainer/Q Targets Std              23.4381
trainer/Q Targets Max              -4.69276
trainer/Q Targets Min            -104.495
trainer/Log Pis Mean                1.97663
trainer/Log Pis Std                 1.57992
trainer/Log Pis Max                 5.2642
trainer/Log Pis Min                -4.16648
trainer/Policy mu Mean              0.0292445
trainer/Policy mu Std               0.921237
trainer/Policy mu Max               2.4427
trainer/Policy mu Min              -2.20405
trainer/Policy log std Mean        -1.83704
trainer/Policy log std Std          0.594752
trainer/Policy log std Max         -0.599113
trainer/Policy log std Min         -2.60728
trainer/Alpha                       0.0732787
trainer/Alpha Loss                 -0.0610883
exploration/num steps total     49700
exploration/num paths total       497
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.802417
exploration/Rewards Std             1.0369
exploration/Rewards Max            -0.0169455
exploration/Rewards Min            -7.99743
exploration/Returns Mean          -80.2417
exploration/Returns Std             7.93264
exploration/Returns Max           -68.9788
exploration/Returns Min           -90.455
exploration/Actions Mean            0.0170848
exploration/Actions Std             0.231734
exploration/Actions Max             0.999475
exploration/Actions Min            -0.999238
exploration/Num Paths               5
exploration/Average Returns       -80.2417
evaluation/num steps total     148500
evaluation/num paths total       1485
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.84952
evaluation/Rewards Std              1.06796
evaluation/Rewards Max             -0.0899427
evaluation/Rewards Min             -9.96175
evaluation/Returns Mean           -84.952
evaluation/Returns Std             68.1933
evaluation/Returns Max            -21.0828
evaluation/Returns Min           -218.445
evaluation/Actions Mean            -0.00163703
evaluation/Actions Std              0.179075
evaluation/Actions Max              0.998835
evaluation/Actions Min             -0.995071
evaluation/Num Paths               15
evaluation/Average Returns        -84.952
time/data storing (s)               0.00290805
time/evaluation sampling (s)        0.331732
time/exploration sampling (s)       0.141168
time/logging (s)                    0.00482504
time/saving (s)                     0.00196337
time/training (s)                   1.93597
time/epoch (s)                      2.41857
time/total (s)                    245.536
Epoch                              98
-----------------------------  ---------------
2019-04-22 23:31:21.703066 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 99 finished
-----------------------------  ---------------
replay_buffer/size              50200
trainer/QF1 Loss                   36.9023
trainer/QF2 Loss                   36.6606
trainer/Policy Loss                49.3317
trainer/Q1 Predictions Mean       -48.3505
trainer/Q1 Predictions Std         30.7551
trainer/Q1 Predictions Max        -14.7317
trainer/Q1 Predictions Min       -139.177
trainer/Q2 Predictions Mean       -48.3167
trainer/Q2 Predictions Std         30.7724
trainer/Q2 Predictions Max        -14.8408
trainer/Q2 Predictions Min       -139.041
trainer/Q Targets Mean            -48.2394
trainer/Q Targets Std              31.7343
trainer/Q Targets Max              -0.651954
trainer/Q Targets Min            -135.357
trainer/Log Pis Mean                1.95329
trainer/Log Pis Std                 1.21213
trainer/Log Pis Max                 7.34902
trainer/Log Pis Min                -1.7387
trainer/Policy mu Mean              0.100253
trainer/Policy mu Std               0.870231
trainer/Policy mu Max               3.01485
trainer/Policy mu Min              -2.80531
trainer/Policy log std Mean        -1.89594
trainer/Policy log std Std          0.541217
trainer/Policy log std Max         -0.348989
trainer/Policy log std Min         -2.463
trainer/Alpha                       0.0736343
trainer/Alpha Loss                 -0.121845
exploration/num steps total     50200
exploration/num paths total       502
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.67325
exploration/Rewards Std             1.24258
exploration/Rewards Max            -0.0078119
exploration/Rewards Min           -10.7527
exploration/Returns Mean          -67.325
exploration/Returns Std            20.0509
exploration/Returns Max           -37.2075
exploration/Returns Min           -99.542
exploration/Actions Mean            0.00975074
exploration/Actions Std             0.233074
exploration/Actions Max             0.999922
exploration/Actions Min            -0.998637
exploration/Num Paths               5
exploration/Average Returns       -67.325
evaluation/num steps total     150000
evaluation/num paths total       1500
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.543593
evaluation/Rewards Std              0.932166
evaluation/Rewards Max             -0.0764731
evaluation/Rewards Min             -9.21737
evaluation/Returns Mean           -54.3593
evaluation/Returns Std             46.3477
evaluation/Returns Max            -15.9206
evaluation/Returns Min           -196.786
evaluation/Actions Mean            -0.004662
evaluation/Actions Std              0.174929
evaluation/Actions Max              0.998528
evaluation/Actions Min             -0.99552
evaluation/Num Paths               15
evaluation/Average Returns        -54.3593
time/data storing (s)               0.00277456
time/evaluation sampling (s)        0.329271
time/exploration sampling (s)       0.140332
time/logging (s)                    0.00482428
time/saving (s)                     0.00197038
time/training (s)                   1.92164
time/epoch (s)                      2.40082
time/total (s)                    247.941
Epoch                              99
-----------------------------  ---------------
2019-04-22 23:31:24.175264 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 100 finished
-----------------------------  ---------------
replay_buffer/size              50700
trainer/QF1 Loss                    1.5049
trainer/QF2 Loss                    1.10555
trainer/Policy Loss                50.1222
trainer/Q1 Predictions Mean       -48.7499
trainer/Q1 Predictions Std         27.1832
trainer/Q1 Predictions Max        -14.7973
trainer/Q1 Predictions Min       -114.42
trainer/Q2 Predictions Mean       -48.7422
trainer/Q2 Predictions Std         27.2039
trainer/Q2 Predictions Max        -14.8139
trainer/Q2 Predictions Min       -113.797
trainer/Q Targets Mean            -49.2524
trainer/Q Targets Std              27.7117
trainer/Q Targets Max             -14.7927
trainer/Q Targets Min            -118.335
trainer/Log Pis Mean                2.24194
trainer/Log Pis Std                 1.42349
trainer/Log Pis Max                 8.00228
trainer/Log Pis Min                -1.8618
trainer/Policy mu Mean              0.125186
trainer/Policy mu Std               1.01865
trainer/Policy mu Max               3.92576
trainer/Policy mu Min              -3.08842
trainer/Policy log std Mean        -1.78847
trainer/Policy log std Std          0.585729
trainer/Policy log std Max         -0.213105
trainer/Policy log std Min         -2.47157
trainer/Alpha                       0.0736913
trainer/Alpha Loss                  0.630954
exploration/num steps total     50700
exploration/num paths total       507
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.3176
exploration/Rewards Std             1.01989
exploration/Rewards Max            -0.0225291
exploration/Rewards Min            -5.14519
exploration/Returns Mean         -131.76
exploration/Returns Std            90.3061
exploration/Returns Max           -29.0069
exploration/Returns Min          -242.556
exploration/Actions Mean           -0.00180766
exploration/Actions Std             0.195646
exploration/Actions Max             0.986874
exploration/Actions Min            -0.999718
exploration/Num Paths               5
exploration/Average Returns      -131.76
evaluation/num steps total     151500
evaluation/num paths total       1515
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.829341
evaluation/Rewards Std              1.13849
evaluation/Rewards Max             -0.0368392
evaluation/Rewards Min            -10.446
evaluation/Returns Mean           -82.9341
evaluation/Returns Std             54.2642
evaluation/Returns Max             -5.225
evaluation/Returns Min           -257.279
evaluation/Actions Mean             0.00189939
evaluation/Actions Std              0.193384
evaluation/Actions Max              0.997985
evaluation/Actions Min             -0.997445
evaluation/Num Paths               15
evaluation/Average Returns        -82.9341
time/data storing (s)               0.00286717
time/evaluation sampling (s)        0.334212
time/exploration sampling (s)       0.140477
time/logging (s)                    0.00453665
time/saving (s)                     0.00192261
time/training (s)                   1.98136
time/epoch (s)                      2.46538
time/total (s)                    250.411
Epoch                             100
-----------------------------  ---------------
2019-04-22 23:31:26.583429 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 101 finished
-----------------------------  ---------------
replay_buffer/size              51200
trainer/QF1 Loss                    0.951033
trainer/QF2 Loss                    0.940029
trainer/Policy Loss                43.7322
trainer/Q1 Predictions Mean       -42.5477
trainer/Q1 Predictions Std         26.2765
trainer/Q1 Predictions Max        -14.2423
trainer/Q1 Predictions Min        -98.5977
trainer/Q2 Predictions Mean       -42.5117
trainer/Q2 Predictions Std         26.2458
trainer/Q2 Predictions Max        -14.4051
trainer/Q2 Predictions Min        -98.6269
trainer/Q Targets Mean            -43.2062
trainer/Q Targets Std              26.6008
trainer/Q Targets Max             -14.606
trainer/Q Targets Min             -99.4785
trainer/Log Pis Mean                1.84921
trainer/Log Pis Std                 1.48534
trainer/Log Pis Max                 6.95629
trainer/Log Pis Min                -2.46947
trainer/Policy mu Mean             -0.0283212
trainer/Policy mu Std               0.769473
trainer/Policy mu Max               2.75405
trainer/Policy mu Min              -2.77406
trainer/Policy log std Mean        -1.95993
trainer/Policy log std Std          0.540143
trainer/Policy log std Max         -0.18607
trainer/Policy log std Min         -2.46984
trainer/Alpha                       0.072109
trainer/Alpha Loss                 -0.396482
exploration/num steps total     51200
exploration/num paths total       512
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.934596
exploration/Rewards Std             0.96806
exploration/Rewards Max            -0.0287702
exploration/Rewards Min            -8.14482
exploration/Returns Mean          -93.4596
exploration/Returns Std            53.6171
exploration/Returns Max           -38.4278
exploration/Returns Min          -195.578
exploration/Actions Mean           -0.0150317
exploration/Actions Std             0.21351
exploration/Actions Max             0.999287
exploration/Actions Min            -0.995289
exploration/Num Paths               5
exploration/Average Returns       -93.4596
evaluation/num steps total     153000
evaluation/num paths total       1530
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.774102
evaluation/Rewards Std              1.14461
evaluation/Rewards Max             -0.0537575
evaluation/Rewards Min            -11.1178
evaluation/Returns Mean           -77.4102
evaluation/Returns Std             53.235
evaluation/Returns Max            -14.033
evaluation/Returns Min           -205.763
evaluation/Actions Mean            -0.00371111
evaluation/Actions Std              0.175148
evaluation/Actions Max              0.999409
evaluation/Actions Min             -0.997878
evaluation/Num Paths               15
evaluation/Average Returns        -77.4102
time/data storing (s)               0.00285517
time/evaluation sampling (s)        0.330188
time/exploration sampling (s)       0.143054
time/logging (s)                    0.00355642
time/saving (s)                     0.0019682
time/training (s)                   1.91904
time/epoch (s)                      2.40067
time/total (s)                    252.816
Epoch                             101
-----------------------------  ---------------
2019-04-22 23:31:29.019167 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 102 finished
-----------------------------  ----------------
replay_buffer/size              51700
trainer/QF1 Loss                    0.759556
trainer/QF2 Loss                    0.74276
trainer/Policy Loss                44.9598
trainer/Q1 Predictions Mean       -43.8603
trainer/Q1 Predictions Std         23.6462
trainer/Q1 Predictions Max        -13.9218
trainer/Q1 Predictions Min       -101.97
trainer/Q2 Predictions Mean       -43.8546
trainer/Q2 Predictions Std         23.6466
trainer/Q2 Predictions Max        -13.9208
trainer/Q2 Predictions Min       -102.028
trainer/Q Targets Mean            -44.5256
trainer/Q Targets Std              24.0096
trainer/Q Targets Max             -14.3944
trainer/Q Targets Min            -102.553
trainer/Log Pis Mean                1.72649
trainer/Log Pis Std                 1.379
trainer/Log Pis Max                 5.7828
trainer/Log Pis Min                -4.18132
trainer/Policy mu Mean              0.0516193
trainer/Policy mu Std               0.753439
trainer/Policy mu Max               2.57779
trainer/Policy mu Min              -3.20489
trainer/Policy log std Mean        -1.9303
trainer/Policy log std Std          0.482251
trainer/Policy log std Max         -0.40335
trainer/Policy log std Min         -2.50393
trainer/Alpha                       0.0720193
trainer/Alpha Loss                 -0.719481
exploration/num steps total     51700
exploration/num paths total       517
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.863793
exploration/Rewards Std             0.723929
exploration/Rewards Max            -0.0593104
exploration/Rewards Min            -6.02792
exploration/Returns Mean          -86.3793
exploration/Returns Std            57.6797
exploration/Returns Max           -46.0015
exploration/Returns Min          -200.69
exploration/Actions Mean            0.00222845
exploration/Actions Std             0.193628
exploration/Actions Max             0.991713
exploration/Actions Min            -0.997041
exploration/Num Paths               5
exploration/Average Returns       -86.3793
evaluation/num steps total     154500
evaluation/num paths total       1545
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.726775
evaluation/Rewards Std              1.07763
evaluation/Rewards Max             -0.031123
evaluation/Rewards Min            -10.6289
evaluation/Returns Mean           -72.6775
evaluation/Returns Std             38.1255
evaluation/Returns Max            -22.9142
evaluation/Returns Min           -193.397
evaluation/Actions Mean             0.000607876
evaluation/Actions Std              0.188038
evaluation/Actions Max              0.99928
evaluation/Actions Min             -0.998518
evaluation/Num Paths               15
evaluation/Average Returns        -72.6775
time/data storing (s)               0.00296493
time/evaluation sampling (s)        0.330649
time/exploration sampling (s)       0.143889
time/logging (s)                    0.00445634
time/saving (s)                     0.00195273
time/training (s)                   1.94706
time/epoch (s)                      2.43097
time/total (s)                    255.251
Epoch                             102
-----------------------------  ----------------
2019-04-22 23:31:31.434791 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 103 finished
-----------------------------  ---------------
replay_buffer/size              52200
trainer/QF1 Loss                   92.2027
trainer/QF2 Loss                   91.7881
trainer/Policy Loss                48.3053
trainer/Q1 Predictions Mean       -47.1282
trainer/Q1 Predictions Std         28.489
trainer/Q1 Predictions Max        -13.6977
trainer/Q1 Predictions Min        -98.6535
trainer/Q2 Predictions Mean       -47.0598
trainer/Q2 Predictions Std         28.5239
trainer/Q2 Predictions Max        -13.737
trainer/Q2 Predictions Min        -98.848
trainer/Q Targets Mean            -46.9141
trainer/Q Targets Std              28.8199
trainer/Q Targets Max              -2.28325
trainer/Q Targets Min            -101.191
trainer/Log Pis Mean                1.79888
trainer/Log Pis Std                 1.33931
trainer/Log Pis Max                 5.21349
trainer/Log Pis Min                -3.89809
trainer/Policy mu Mean             -0.0974731
trainer/Policy mu Std               0.679252
trainer/Policy mu Max               2.16295
trainer/Policy mu Min              -2.8788
trainer/Policy log std Mean        -1.99987
trainer/Policy log std Std          0.465855
trainer/Policy log std Max         -0.302676
trainer/Policy log std Min         -2.51013
trainer/Alpha                       0.0728603
trainer/Alpha Loss                 -0.526774
exploration/num steps total     52200
exploration/num paths total       522
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.00567
exploration/Rewards Std             1.21121
exploration/Rewards Max            -0.0230161
exploration/Rewards Min           -10.1504
exploration/Returns Mean         -100.567
exploration/Returns Std            52.8549
exploration/Returns Max           -61.6125
exploration/Returns Min          -199.833
exploration/Actions Mean           -0.0129769
exploration/Actions Std             0.252744
exploration/Actions Max             0.998233
exploration/Actions Min            -0.999642
exploration/Num Paths               5
exploration/Average Returns      -100.567
evaluation/num steps total     156000
evaluation/num paths total       1560
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.01369
evaluation/Rewards Std              1.16882
evaluation/Rewards Max             -0.0471155
evaluation/Rewards Min            -10.6779
evaluation/Returns Mean          -101.369
evaluation/Returns Std             58.0139
evaluation/Returns Max            -18.3022
evaluation/Returns Min           -197.83
evaluation/Actions Mean             0.00631072
evaluation/Actions Std              0.196749
evaluation/Actions Max              0.999023
evaluation/Actions Min             -0.998771
evaluation/Num Paths               15
evaluation/Average Returns       -101.369
time/data storing (s)               0.00272452
time/evaluation sampling (s)        0.327002
time/exploration sampling (s)       0.140509
time/logging (s)                    0.00513
time/saving (s)                     0.0019538
time/training (s)                   1.93239
time/epoch (s)                      2.40971
time/total (s)                    257.665
Epoch                             103
-----------------------------  ---------------
2019-04-22 23:31:33.841455 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 104 finished
-----------------------------  ---------------
replay_buffer/size              52700
trainer/QF1 Loss                    0.527906
trainer/QF2 Loss                    0.585455
trainer/Policy Loss                46.9117
trainer/Q1 Predictions Mean       -45.4195
trainer/Q1 Predictions Std         27.2815
trainer/Q1 Predictions Max        -13.9589
trainer/Q1 Predictions Min       -147.464
trainer/Q2 Predictions Mean       -45.5351
trainer/Q2 Predictions Std         27.4005
trainer/Q2 Predictions Max        -13.9538
trainer/Q2 Predictions Min       -148.597
trainer/Q Targets Mean            -45.9731
trainer/Q Targets Std              27.445
trainer/Q Targets Max             -13.9496
trainer/Q Targets Min            -147.958
trainer/Log Pis Mean                2.24403
trainer/Log Pis Std                 1.62148
trainer/Log Pis Max                 7.5013
trainer/Log Pis Min                -1.95004
trainer/Policy mu Mean             -0.0551484
trainer/Policy mu Std               1.00995
trainer/Policy mu Max               3.01562
trainer/Policy mu Min              -3.43974
trainer/Policy log std Mean        -1.84529
trainer/Policy log std Std          0.628754
trainer/Policy log std Max         -0.0755264
trainer/Policy log std Min         -2.54398
trainer/Alpha                       0.0737045
trainer/Alpha Loss                  0.636362
exploration/num steps total     52700
exploration/num paths total       527
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.604017
exploration/Rewards Std             0.846368
exploration/Rewards Max            -0.0341226
exploration/Rewards Min            -7.43471
exploration/Returns Mean          -60.4017
exploration/Returns Std            17.4942
exploration/Returns Max           -33.6645
exploration/Returns Min           -84.6327
exploration/Actions Mean           -0.00737571
exploration/Actions Std             0.221861
exploration/Actions Max             0.999094
exploration/Actions Min            -0.999691
exploration/Num Paths               5
exploration/Average Returns       -60.4017
evaluation/num steps total     157500
evaluation/num paths total       1575
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.629194
evaluation/Rewards Std              0.921243
evaluation/Rewards Max             -0.149708
evaluation/Rewards Min            -11.3045
evaluation/Returns Mean           -62.9194
evaluation/Returns Std             21.3002
evaluation/Returns Max            -33.0254
evaluation/Returns Min           -101.811
evaluation/Actions Mean             0.0124446
evaluation/Actions Std              0.172469
evaluation/Actions Max              0.999478
evaluation/Actions Min             -0.994469
evaluation/Num Paths               15
evaluation/Average Returns        -62.9194
time/data storing (s)               0.00293737
time/evaluation sampling (s)        0.327909
time/exploration sampling (s)       0.139884
time/logging (s)                    0.00354135
time/saving (s)                     0.00197571
time/training (s)                   1.92271
time/epoch (s)                      2.39895
time/total (s)                    260.068
Epoch                             104
-----------------------------  ---------------
2019-04-22 23:31:36.267999 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 105 finished
-----------------------------  ---------------
replay_buffer/size              53200
trainer/QF1 Loss                    0.778739
trainer/QF2 Loss                    0.798294
trainer/Policy Loss                51.4509
trainer/Q1 Predictions Mean       -50.1069
trainer/Q1 Predictions Std         26.9629
trainer/Q1 Predictions Max        -13.5203
trainer/Q1 Predictions Min       -106.107
trainer/Q2 Predictions Mean       -50.1131
trainer/Q2 Predictions Std         26.9445
trainer/Q2 Predictions Max        -13.4009
trainer/Q2 Predictions Min       -106.241
trainer/Q Targets Mean            -50.7977
trainer/Q Targets Std              27.2588
trainer/Q Targets Max             -13.757
trainer/Q Targets Min            -105.456
trainer/Log Pis Mean                2.05367
trainer/Log Pis Std                 1.30267
trainer/Log Pis Max                 7.56036
trainer/Log Pis Min                -2.66901
trainer/Policy mu Mean              0.0864454
trainer/Policy mu Std               0.842454
trainer/Policy mu Max               3.07239
trainer/Policy mu Min              -3.44464
trainer/Policy log std Mean        -1.92939
trainer/Policy log std Std          0.553121
trainer/Policy log std Max         -0.166156
trainer/Policy log std Min         -2.68453
trainer/Alpha                       0.0745147
trainer/Alpha Loss                  0.139374
exploration/num steps total     53200
exploration/num paths total       532
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.526327
exploration/Rewards Std             0.863513
exploration/Rewards Max            -0.00391645
exploration/Rewards Min            -9.55397
exploration/Returns Mean          -52.6327
exploration/Returns Std            19.0335
exploration/Returns Max           -20.3373
exploration/Returns Min           -79.0292
exploration/Actions Mean            0.0121949
exploration/Actions Std             0.201239
exploration/Actions Max             0.998802
exploration/Actions Min            -0.97631
exploration/Num Paths               5
exploration/Average Returns       -52.6327
evaluation/num steps total     159000
evaluation/num paths total       1590
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.870578
evaluation/Rewards Std              1.04675
evaluation/Rewards Max             -0.0575818
evaluation/Rewards Min            -11.2994
evaluation/Returns Mean           -87.0578
evaluation/Returns Std             61.2083
evaluation/Returns Max            -17.4241
evaluation/Returns Min           -206.312
evaluation/Actions Mean             0.00702604
evaluation/Actions Std              0.177164
evaluation/Actions Max              0.999315
evaluation/Actions Min             -0.996856
evaluation/Num Paths               15
evaluation/Average Returns        -87.0578
time/data storing (s)               0.00289991
time/evaluation sampling (s)        0.331928
time/exploration sampling (s)       0.141192
time/logging (s)                    0.00483627
time/saving (s)                     0.00195989
time/training (s)                   1.93897
time/epoch (s)                      2.42178
time/total (s)                    262.495
Epoch                             105
-----------------------------  ---------------
2019-04-22 23:31:38.682685 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 106 finished
-----------------------------  ---------------
replay_buffer/size              53700
trainer/QF1 Loss                   44.9344
trainer/QF2 Loss                   45.018
trainer/Policy Loss                50.4927
trainer/Q1 Predictions Mean       -49.2025
trainer/Q1 Predictions Std         29.2039
trainer/Q1 Predictions Max        -13.5339
trainer/Q1 Predictions Min       -104.46
trainer/Q2 Predictions Mean       -49.1931
trainer/Q2 Predictions Std         29.1774
trainer/Q2 Predictions Max        -13.6366
trainer/Q2 Predictions Min       -104.101
trainer/Q Targets Mean            -48.8943
trainer/Q Targets Std              30.3467
trainer/Q Targets Max              -1.00775
trainer/Q Targets Min            -106.952
trainer/Log Pis Mean                2.01568
trainer/Log Pis Std                 1.12325
trainer/Log Pis Max                 6.52887
trainer/Log Pis Min                -2.3474
trainer/Policy mu Mean              0.0388943
trainer/Policy mu Std               0.894233
trainer/Policy mu Max               3.5449
trainer/Policy mu Min              -3.26342
trainer/Policy log std Mean        -1.86368
trainer/Policy log std Std          0.570959
trainer/Policy log std Max         -0.395299
trainer/Policy log std Min         -2.55945
trainer/Alpha                       0.0736051
trainer/Alpha Loss                  0.0409187
exploration/num steps total     53700
exploration/num paths total       537
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.619161
exploration/Rewards Std             0.944022
exploration/Rewards Max            -0.0646168
exploration/Rewards Min            -9.49073
exploration/Returns Mean          -61.9161
exploration/Returns Std            11.6081
exploration/Returns Max           -40.9366
exploration/Returns Min           -75.8491
exploration/Actions Mean            0.0044585
exploration/Actions Std             0.220185
exploration/Actions Max             0.997155
exploration/Actions Min            -0.99557
exploration/Num Paths               5
exploration/Average Returns       -61.9161
evaluation/num steps total     160500
evaluation/num paths total       1605
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.641725
evaluation/Rewards Std              1.0684
evaluation/Rewards Max             -0.0130284
evaluation/Rewards Min            -10.1065
evaluation/Returns Mean           -64.1725
evaluation/Returns Std             47.3529
evaluation/Returns Max            -16.2633
evaluation/Returns Min           -219.209
evaluation/Actions Mean            -0.00779273
evaluation/Actions Std              0.184559
evaluation/Actions Max              0.999305
evaluation/Actions Min             -0.997182
evaluation/Num Paths               15
evaluation/Average Returns        -64.1725
time/data storing (s)               0.00283853
time/evaluation sampling (s)        0.32687
time/exploration sampling (s)       0.141491
time/logging (s)                    0.0047379
time/saving (s)                     0.00198018
time/training (s)                   1.93017
time/epoch (s)                      2.40809
time/total (s)                    264.907
Epoch                             106
-----------------------------  ---------------
2019-04-22 23:31:41.106735 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 107 finished
-----------------------------  ----------------
replay_buffer/size              54200
trainer/QF1 Loss                    0.586031
trainer/QF2 Loss                    0.563701
trainer/Policy Loss                47.7299
trainer/Q1 Predictions Mean       -46.2114
trainer/Q1 Predictions Std         27.7571
trainer/Q1 Predictions Max        -13.2462
trainer/Q1 Predictions Min       -132.347
trainer/Q2 Predictions Mean       -46.1628
trainer/Q2 Predictions Std         27.7322
trainer/Q2 Predictions Max        -13.301
trainer/Q2 Predictions Min       -131.446
trainer/Q Targets Mean            -46.6696
trainer/Q Targets Std              28.1136
trainer/Q Targets Max             -13.4082
trainer/Q Targets Min            -131.003
trainer/Log Pis Mean                2.09423
trainer/Log Pis Std                 1.30477
trainer/Log Pis Max                 9.14328
trainer/Log Pis Min                -2.36048
trainer/Policy mu Mean              0.00504542
trainer/Policy mu Std               0.701979
trainer/Policy mu Max               2.49082
trainer/Policy mu Min              -3.24334
trainer/Policy log std Mean        -2.04297
trainer/Policy log std Std          0.49997
trainer/Policy log std Max         -0.40526
trainer/Policy log std Min         -2.55655
trainer/Alpha                       0.0731457
trainer/Alpha Loss                  0.246442
exploration/num steps total     54200
exploration/num paths total       542
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.765256
exploration/Rewards Std             0.883652
exploration/Rewards Max            -0.0117591
exploration/Rewards Min            -8.10057
exploration/Returns Mean          -76.5256
exploration/Returns Std            58.0502
exploration/Returns Max           -15.5175
exploration/Returns Min          -185.584
exploration/Actions Mean            0.0116049
exploration/Actions Std             0.197016
exploration/Actions Max             0.997972
exploration/Actions Min            -0.976336
exploration/Num Paths               5
exploration/Average Returns       -76.5256
evaluation/num steps total     162000
evaluation/num paths total       1620
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.663933
evaluation/Rewards Std              1.03588
evaluation/Rewards Max             -0.0318049
evaluation/Rewards Min             -9.12167
evaluation/Returns Mean           -66.3933
evaluation/Returns Std             53.9671
evaluation/Returns Max            -12.1113
evaluation/Returns Min           -192.436
evaluation/Actions Mean            -0.000731508
evaluation/Actions Std              0.171008
evaluation/Actions Max              0.999158
evaluation/Actions Min             -0.997365
evaluation/Num Paths               15
evaluation/Average Returns        -66.3933
time/data storing (s)               0.00290154
time/evaluation sampling (s)        0.33504
time/exploration sampling (s)       0.144121
time/logging (s)                    0.00427971
time/saving (s)                     0.0016527
time/training (s)                   1.92917
time/epoch (s)                      2.41716
time/total (s)                    267.329
Epoch                             107
-----------------------------  ----------------
2019-04-22 23:31:43.540568 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 108 finished
-----------------------------  ---------------
replay_buffer/size              54700
trainer/QF1 Loss                    0.677478
trainer/QF2 Loss                    0.605791
trainer/Policy Loss                42.5247
trainer/Q1 Predictions Mean       -41.294
trainer/Q1 Predictions Std         22.669
trainer/Q1 Predictions Max        -13.1932
trainer/Q1 Predictions Min        -99.9911
trainer/Q2 Predictions Mean       -41.2954
trainer/Q2 Predictions Std         22.627
trainer/Q2 Predictions Max        -13.2985
trainer/Q2 Predictions Min       -100.006
trainer/Q Targets Mean            -41.7258
trainer/Q Targets Std              22.7889
trainer/Q Targets Max             -13.1113
trainer/Q Targets Min            -100.989
trainer/Log Pis Mean                2.15334
trainer/Log Pis Std                 1.40205
trainer/Log Pis Max                 7.0606
trainer/Log Pis Min                -2.11423
trainer/Policy mu Mean             -0.0892649
trainer/Policy mu Std               0.908947
trainer/Policy mu Max               3.18209
trainer/Policy mu Min              -3.03034
trainer/Policy log std Mean        -1.90575
trainer/Policy log std Std          0.58218
trainer/Policy log std Max         -0.439454
trainer/Policy log std Min         -2.60548
trainer/Alpha                       0.073278
trainer/Alpha Loss                  0.400768
exploration/num steps total     54700
exploration/num paths total       547
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.443809
exploration/Rewards Std             1.08211
exploration/Rewards Max            -0.00501172
exploration/Rewards Min            -8.65891
exploration/Returns Mean          -44.3809
exploration/Returns Std            24.674
exploration/Returns Max           -16.0444
exploration/Returns Min           -73.0999
exploration/Actions Mean            0.00796771
exploration/Actions Std             0.229244
exploration/Actions Max             0.999361
exploration/Actions Min            -0.999639
exploration/Num Paths               5
exploration/Average Returns       -44.3809
evaluation/num steps total     163500
evaluation/num paths total       1635
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.696888
evaluation/Rewards Std              0.980623
evaluation/Rewards Max             -0.0318186
evaluation/Rewards Min            -10.0981
evaluation/Returns Mean           -69.6888
evaluation/Returns Std             54.2452
evaluation/Returns Max             -3.31138
evaluation/Returns Min           -203.614
evaluation/Actions Mean            -0.00562439
evaluation/Actions Std              0.165347
evaluation/Actions Max              0.998976
evaluation/Actions Min             -0.996811
evaluation/Num Paths               15
evaluation/Average Returns        -69.6888
time/data storing (s)               0.00282841
time/evaluation sampling (s)        0.331229
time/exploration sampling (s)       0.141316
time/logging (s)                    0.00474573
time/saving (s)                     0.0102322
time/training (s)                   1.93776
time/epoch (s)                      2.42811
time/total (s)                    269.761
Epoch                             108
-----------------------------  ---------------
2019-04-22 23:31:45.972986 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 109 finished
-----------------------------  ---------------
replay_buffer/size              55200
trainer/QF1 Loss                  171.376
trainer/QF2 Loss                  170.853
trainer/Policy Loss                49.1701
trainer/Q1 Predictions Mean       -48.0666
trainer/Q1 Predictions Std         28.2499
trainer/Q1 Predictions Max        -13.0398
trainer/Q1 Predictions Min       -129.401
trainer/Q2 Predictions Mean       -48.0653
trainer/Q2 Predictions Std         28.2735
trainer/Q2 Predictions Max        -13.0863
trainer/Q2 Predictions Min       -130.161
trainer/Q Targets Mean            -46.6122
trainer/Q Targets Std              28.65
trainer/Q Targets Max              -2.11024
trainer/Q Targets Min            -132.63
trainer/Log Pis Mean                2.06171
trainer/Log Pis Std                 1.33649
trainer/Log Pis Max                 6.00441
trainer/Log Pis Min                -1.38899
trainer/Policy mu Mean              0.0619338
trainer/Policy mu Std               0.863695
trainer/Policy mu Max               2.92614
trainer/Policy mu Min              -3.11679
trainer/Policy log std Mean        -1.92168
trainer/Policy log std Std          0.558798
trainer/Policy log std Max         -0.375241
trainer/Policy log std Min         -2.69668
trainer/Alpha                       0.0720347
trainer/Alpha Loss                  0.162336
exploration/num steps total     55200
exploration/num paths total       552
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.662679
exploration/Rewards Std             0.792115
exploration/Rewards Max            -0.0105651
exploration/Rewards Min            -5.57457
exploration/Returns Mean          -66.2679
exploration/Returns Std            63.1115
exploration/Returns Max           -25.0607
exploration/Returns Min          -191.565
exploration/Actions Mean            0.0184246
exploration/Actions Std             0.180194
exploration/Actions Max             0.993421
exploration/Actions Min            -0.858497
exploration/Num Paths               5
exploration/Average Returns       -66.2679
evaluation/num steps total     165000
evaluation/num paths total       1650
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.09901
evaluation/Rewards Std              1.12131
evaluation/Rewards Max             -0.148258
evaluation/Rewards Min            -10.3402
evaluation/Returns Mean          -109.901
evaluation/Returns Std             61.3808
evaluation/Returns Max            -28.945
evaluation/Returns Min           -223.955
evaluation/Actions Mean             0.00532628
evaluation/Actions Std              0.200339
evaluation/Actions Max              0.998892
evaluation/Actions Min             -0.997541
evaluation/Num Paths               15
evaluation/Average Returns       -109.901
time/data storing (s)               0.00305165
time/evaluation sampling (s)        0.330858
time/exploration sampling (s)       0.143724
time/logging (s)                    0.00371898
time/saving (s)                     0.00198537
time/training (s)                   1.9423
time/epoch (s)                      2.42563
time/total (s)                    272.19
Epoch                             109
-----------------------------  ---------------
2019-04-22 23:31:48.389917 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 110 finished
-----------------------------  ---------------
replay_buffer/size              55700
trainer/QF1 Loss                    1.26695
trainer/QF2 Loss                    0.921758
trainer/Policy Loss                45.5008
trainer/Q1 Predictions Mean       -43.9543
trainer/Q1 Predictions Std         28.937
trainer/Q1 Predictions Max        -12.7104
trainer/Q1 Predictions Min       -139.958
trainer/Q2 Predictions Mean       -44.0049
trainer/Q2 Predictions Std         29.0377
trainer/Q2 Predictions Max        -12.7649
trainer/Q2 Predictions Min       -141.282
trainer/Q Targets Mean            -44.6139
trainer/Q Targets Std              29.5444
trainer/Q Targets Max             -12.8786
trainer/Q Targets Min            -142.451
trainer/Log Pis Mean                2.20924
trainer/Log Pis Std                 1.74404
trainer/Log Pis Max                 9.12853
trainer/Log Pis Min                -2.11298
trainer/Policy mu Mean              0.0701125
trainer/Policy mu Std               1.00902
trainer/Policy mu Max               3.74105
trainer/Policy mu Min              -3.28036
trainer/Policy log std Mean        -1.90995
trainer/Policy log std Std          0.611708
trainer/Policy log std Max         -0.157333
trainer/Policy log std Min         -2.86307
trainer/Alpha                       0.0711503
trainer/Alpha Loss                  0.553016
exploration/num steps total     55700
exploration/num paths total       557
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.628362
exploration/Rewards Std             1.09485
exploration/Rewards Max            -0.01982
exploration/Rewards Min            -8.68049
exploration/Returns Mean          -62.8362
exploration/Returns Std            13.6286
exploration/Returns Max           -51.5833
exploration/Returns Min           -84.7122
exploration/Actions Mean            0.0140477
exploration/Actions Std             0.23393
exploration/Actions Max             0.99966
exploration/Actions Min            -0.998547
exploration/Num Paths               5
exploration/Average Returns       -62.8362
evaluation/num steps total     166500
evaluation/num paths total       1665
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.903495
evaluation/Rewards Std              1.01004
evaluation/Rewards Max             -0.0383429
evaluation/Rewards Min             -9.88155
evaluation/Returns Mean           -90.3495
evaluation/Returns Std             59.0667
evaluation/Returns Max            -30.1635
evaluation/Returns Min           -206.347
evaluation/Actions Mean             0.0023432
evaluation/Actions Std              0.164207
evaluation/Actions Max              0.998881
evaluation/Actions Min             -0.997455
evaluation/Num Paths               15
evaluation/Average Returns        -90.3495
time/data storing (s)               0.00294415
time/evaluation sampling (s)        0.330059
time/exploration sampling (s)       0.140848
time/logging (s)                    0.00403749
time/saving (s)                     0.00195636
time/training (s)                   1.9314
time/epoch (s)                      2.41125
time/total (s)                    274.606
Epoch                             110
-----------------------------  ---------------
2019-04-22 23:31:50.786408 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 111 finished
-----------------------------  ---------------
replay_buffer/size              56200
trainer/QF1 Loss                   13.7238
trainer/QF2 Loss                   13.7164
trainer/Policy Loss                42.9967
trainer/Q1 Predictions Mean       -41.5849
trainer/Q1 Predictions Std         26.8102
trainer/Q1 Predictions Max        -12.9613
trainer/Q1 Predictions Min        -97.7701
trainer/Q2 Predictions Mean       -41.6213
trainer/Q2 Predictions Std         26.7815
trainer/Q2 Predictions Max        -13.0276
trainer/Q2 Predictions Min        -97.8909
trainer/Q Targets Mean            -41.325
trainer/Q Targets Std              27.2107
trainer/Q Targets Max              -0.456899
trainer/Q Targets Min             -97.9096
trainer/Log Pis Mean                2.21296
trainer/Log Pis Std                 1.41459
trainer/Log Pis Max                10.4809
trainer/Log Pis Min                -1.4562
trainer/Policy mu Mean              0.162789
trainer/Policy mu Std               0.960088
trainer/Policy mu Max               3.42058
trainer/Policy mu Min              -2.59455
trainer/Policy log std Mean        -1.85028
trainer/Policy log std Std          0.591235
trainer/Policy log std Max         -0.32257
trainer/Policy log std Min         -2.65068
trainer/Alpha                       0.0703618
trainer/Alpha Loss                  0.565202
exploration/num steps total     56200
exploration/num paths total       562
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.01053
exploration/Rewards Std             0.892417
exploration/Rewards Max            -0.126657
exploration/Rewards Min            -7.98304
exploration/Returns Mean         -101.053
exploration/Returns Std            58.3608
exploration/Returns Max           -46.6056
exploration/Returns Min          -214.605
exploration/Actions Mean            0.0120213
exploration/Actions Std             0.208955
exploration/Actions Max             0.999291
exploration/Actions Min            -0.991326
exploration/Num Paths               5
exploration/Average Returns      -101.053
evaluation/num steps total     168000
evaluation/num paths total       1680
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.687807
evaluation/Rewards Std              0.954084
evaluation/Rewards Max             -0.0301803
evaluation/Rewards Min             -9.76699
evaluation/Returns Mean           -68.7807
evaluation/Returns Std             55.6122
evaluation/Returns Max            -17.9947
evaluation/Returns Min           -198.225
evaluation/Actions Mean             0.0043841
evaluation/Actions Std              0.165469
evaluation/Actions Max              0.998418
evaluation/Actions Min             -0.996742
evaluation/Num Paths               15
evaluation/Average Returns        -68.7807
time/data storing (s)               0.00281857
time/evaluation sampling (s)        0.327546
time/exploration sampling (s)       0.140664
time/logging (s)                    0.004797
time/saving (s)                     0.00195597
time/training (s)                   1.91282
time/epoch (s)                      2.3906
time/total (s)                    277.001
Epoch                             111
-----------------------------  ---------------
2019-04-22 23:31:53.196691 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 112 finished
-----------------------------  ---------------
replay_buffer/size              56700
trainer/QF1 Loss                    0.515047
trainer/QF2 Loss                    0.499677
trainer/Policy Loss                47.9944
trainer/Q1 Predictions Mean       -46.5701
trainer/Q1 Predictions Std         29.8436
trainer/Q1 Predictions Max        -12.4969
trainer/Q1 Predictions Min       -125.304
trainer/Q2 Predictions Mean       -46.5767
trainer/Q2 Predictions Std         29.8267
trainer/Q2 Predictions Max        -12.6519
trainer/Q2 Predictions Min       -125.638
trainer/Q Targets Mean            -47.0273
trainer/Q Targets Std              30.089
trainer/Q Targets Max             -12.5935
trainer/Q Targets Min            -127.963
trainer/Log Pis Mean                2.08422
trainer/Log Pis Std                 1.57546
trainer/Log Pis Max                10.5299
trainer/Log Pis Min                -2.29932
trainer/Policy mu Mean              0.172352
trainer/Policy mu Std               0.939478
trainer/Policy mu Max               3.71567
trainer/Policy mu Min              -3.03326
trainer/Policy log std Mean        -1.87048
trainer/Policy log std Std          0.567909
trainer/Policy log std Max         -0.34435
trainer/Policy log std Min         -2.56833
trainer/Alpha                       0.0713241
trainer/Alpha Loss                  0.222398
exploration/num steps total     56700
exploration/num paths total       567
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.471337
exploration/Rewards Std             0.584397
exploration/Rewards Max            -0.0156864
exploration/Rewards Min            -6.78447
exploration/Returns Mean          -47.1337
exploration/Returns Std            21.7062
exploration/Returns Max           -18.1958
exploration/Returns Min           -79.6256
exploration/Actions Mean            0.00208005
exploration/Actions Std             0.194809
exploration/Actions Max             0.996793
exploration/Actions Min            -0.998614
exploration/Num Paths               5
exploration/Average Returns       -47.1337
evaluation/num steps total     169500
evaluation/num paths total       1695
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.868499
evaluation/Rewards Std              1.0043
evaluation/Rewards Max             -0.0604671
evaluation/Rewards Min             -9.47813
evaluation/Returns Mean           -86.8499
evaluation/Returns Std             55.8777
evaluation/Returns Max            -14.3936
evaluation/Returns Min           -215.027
evaluation/Actions Mean             0.00487531
evaluation/Actions Std              0.182808
evaluation/Actions Max              0.998816
evaluation/Actions Min             -0.997088
evaluation/Num Paths               15
evaluation/Average Returns        -86.8499
time/data storing (s)               0.00293189
time/evaluation sampling (s)        0.326238
time/exploration sampling (s)       0.141391
time/logging (s)                    0.00482044
time/saving (s)                     0.00157098
time/training (s)                   1.92662
time/epoch (s)                      2.40357
time/total (s)                    279.409
Epoch                             112
-----------------------------  ---------------
2019-04-22 23:31:55.618132 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 113 finished
-----------------------------  ---------------
replay_buffer/size              57200
trainer/QF1 Loss                   85.6516
trainer/QF2 Loss                   85.3972
trainer/Policy Loss                41.4386
trainer/Q1 Predictions Mean       -39.9829
trainer/Q1 Predictions Std         29.2334
trainer/Q1 Predictions Max        -12.4346
trainer/Q1 Predictions Min       -125.057
trainer/Q2 Predictions Mean       -39.9734
trainer/Q2 Predictions Std         29.2176
trainer/Q2 Predictions Max        -12.4718
trainer/Q2 Predictions Min       -124.917
trainer/Q Targets Mean            -39.4787
trainer/Q Targets Std              29.3453
trainer/Q Targets Max              -1.91385
trainer/Q Targets Min            -130.402
trainer/Log Pis Mean                1.92227
trainer/Log Pis Std                 1.41484
trainer/Log Pis Max                 8.46839
trainer/Log Pis Min                -4.3511
trainer/Policy mu Mean              0.0541404
trainer/Policy mu Std               0.775131
trainer/Policy mu Max               3.90778
trainer/Policy mu Min              -2.90101
trainer/Policy log std Mean        -2.01948
trainer/Policy log std Std          0.550873
trainer/Policy log std Max         -0.160812
trainer/Policy log std Min         -2.68408
trainer/Alpha                       0.0714925
trainer/Alpha Loss                 -0.205065
exploration/num steps total     57200
exploration/num paths total       572
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.507162
exploration/Rewards Std             0.784509
exploration/Rewards Max            -0.0771013
exploration/Rewards Min            -7.64896
exploration/Returns Mean          -50.7162
exploration/Returns Std            16.1293
exploration/Returns Max           -34.4733
exploration/Returns Min           -76.5945
exploration/Actions Mean            0.00668642
exploration/Actions Std             0.207668
exploration/Actions Max             0.994479
exploration/Actions Min            -0.992484
exploration/Num Paths               5
exploration/Average Returns       -50.7162
evaluation/num steps total     171000
evaluation/num paths total       1710
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.589079
evaluation/Rewards Std              0.93805
evaluation/Rewards Max             -0.0292745
evaluation/Rewards Min             -8.91317
evaluation/Returns Mean           -58.9079
evaluation/Returns Std             45.4392
evaluation/Returns Max             -9.98403
evaluation/Returns Min           -203.131
evaluation/Actions Mean            -0.00665768
evaluation/Actions Std              0.181854
evaluation/Actions Max              0.998961
evaluation/Actions Min             -0.997602
evaluation/Num Paths               15
evaluation/Average Returns        -58.9079
time/data storing (s)               0.00296655
time/evaluation sampling (s)        0.3261
time/exploration sampling (s)       0.144091
time/logging (s)                    0.00478502
time/saving (s)                     0.00195172
time/training (s)                   1.93479
time/epoch (s)                      2.41468
time/total (s)                    281.828
Epoch                             113
-----------------------------  ---------------
2019-04-22 23:31:58.039764 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 114 finished
-----------------------------  ---------------
replay_buffer/size              57700
trainer/QF1 Loss                   22.5689
trainer/QF2 Loss                   22.6812
trainer/Policy Loss                43.4732
trainer/Q1 Predictions Mean       -41.9174
trainer/Q1 Predictions Std         26.0214
trainer/Q1 Predictions Max        -12.219
trainer/Q1 Predictions Min       -128.475
trainer/Q2 Predictions Mean       -41.9081
trainer/Q2 Predictions Std         26.0004
trainer/Q2 Predictions Max        -12.2591
trainer/Q2 Predictions Min       -128.328
trainer/Q Targets Mean            -41.5925
trainer/Q Targets Std              26.665
trainer/Q Targets Max              -0.124246
trainer/Q Targets Min            -127.863
trainer/Log Pis Mean                2.11058
trainer/Log Pis Std                 1.24499
trainer/Log Pis Max                 6.56329
trainer/Log Pis Min                -1.16358
trainer/Policy mu Mean              0.0974329
trainer/Policy mu Std               0.838996
trainer/Policy mu Max               2.78284
trainer/Policy mu Min              -3.00975
trainer/Policy log std Mean        -1.94449
trainer/Policy log std Std          0.566016
trainer/Policy log std Max         -0.334072
trainer/Policy log std Min         -2.72969
trainer/Alpha                       0.073458
trainer/Alpha Loss                  0.288733
exploration/num steps total     57700
exploration/num paths total       577
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.12409
exploration/Rewards Std             1.30793
exploration/Rewards Max            -0.0121415
exploration/Rewards Min           -10.4478
exploration/Returns Mean         -112.409
exploration/Returns Std            81.2634
exploration/Returns Max           -28.9882
exploration/Returns Min          -211.971
exploration/Actions Mean           -0.0347907
exploration/Actions Std             0.207825
exploration/Actions Max             0.527701
exploration/Actions Min            -0.999522
exploration/Num Paths               5
exploration/Average Returns      -112.409
evaluation/num steps total     172500
evaluation/num paths total       1725
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.649935
evaluation/Rewards Std              0.913418
evaluation/Rewards Max             -0.113236
evaluation/Rewards Min             -9.31858
evaluation/Returns Mean           -64.9935
evaluation/Returns Std             38.93
evaluation/Returns Max            -24.8002
evaluation/Returns Min           -192.883
evaluation/Actions Mean            -0.00292352
evaluation/Actions Std              0.167907
evaluation/Actions Max              0.99727
evaluation/Actions Min             -0.998362
evaluation/Num Paths               15
evaluation/Average Returns        -64.9935
time/data storing (s)               0.00287541
time/evaluation sampling (s)        0.330077
time/exploration sampling (s)       0.141891
time/logging (s)                    0.00435392
time/saving (s)                     0.00194735
time/training (s)                   1.93363
time/epoch (s)                      2.41477
time/total (s)                    284.247
Epoch                             114
-----------------------------  ---------------
2019-04-22 23:32:00.534757 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 115 finished
-----------------------------  ---------------
replay_buffer/size              58200
trainer/QF1 Loss                   87.1354
trainer/QF2 Loss                   86.8738
trainer/Policy Loss                44.839
trainer/Q1 Predictions Mean       -43.3704
trainer/Q1 Predictions Std         29.1491
trainer/Q1 Predictions Max        -12.3507
trainer/Q1 Predictions Min       -135.21
trainer/Q2 Predictions Mean       -43.3447
trainer/Q2 Predictions Std         29.133
trainer/Q2 Predictions Max        -12.4007
trainer/Q2 Predictions Min       -135.439
trainer/Q Targets Mean            -42.5017
trainer/Q Targets Std              29.1733
trainer/Q Targets Max              -2.0474
trainer/Q Targets Min            -137.065
trainer/Log Pis Mean                2.13089
trainer/Log Pis Std                 1.39968
trainer/Log Pis Max                 6.90796
trainer/Log Pis Min                -3.58789
trainer/Policy mu Mean              0.0995564
trainer/Policy mu Std               0.778277
trainer/Policy mu Max               3.09844
trainer/Policy mu Min              -3.08464
trainer/Policy log std Mean        -1.97763
trainer/Policy log std Std          0.530306
trainer/Policy log std Max         -0.334315
trainer/Policy log std Min         -2.56677
trainer/Alpha                       0.0737336
trainer/Alpha Loss                  0.341265
exploration/num steps total     58200
exploration/num paths total       582
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.660352
exploration/Rewards Std             1.1875
exploration/Rewards Max            -0.0265436
exploration/Rewards Min            -9.7265
exploration/Returns Mean          -66.0352
exploration/Returns Std             4.64489
exploration/Returns Max           -60.7698
exploration/Returns Min           -74.0806
exploration/Actions Mean            0.0350765
exploration/Actions Std             0.237577
exploration/Actions Max             0.999008
exploration/Actions Min            -0.970622
exploration/Num Paths               5
exploration/Average Returns       -66.0352
evaluation/num steps total     174000
evaluation/num paths total       1740
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.794155
evaluation/Rewards Std              1.03977
evaluation/Rewards Max             -0.120587
evaluation/Rewards Min             -9.78519
evaluation/Returns Mean           -79.4155
evaluation/Returns Std             65.9413
evaluation/Returns Max            -19.269
evaluation/Returns Min           -215.396
evaluation/Actions Mean             0.00272507
evaluation/Actions Std              0.173892
evaluation/Actions Max              0.999292
evaluation/Actions Min             -0.993969
evaluation/Num Paths               15
evaluation/Average Returns        -79.4155
time/data storing (s)               0.00314241
time/evaluation sampling (s)        0.326264
time/exploration sampling (s)       0.139868
time/logging (s)                    0.0035973
time/saving (s)                     0.00195143
time/training (s)                   2.01316
time/epoch (s)                      2.48798
time/total (s)                    286.739
Epoch                             115
-----------------------------  ---------------
2019-04-22 23:32:02.974920 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 116 finished
-----------------------------  ---------------
replay_buffer/size              58700
trainer/QF1 Loss                    0.357451
trainer/QF2 Loss                    0.305034
trainer/Policy Loss                42.1996
trainer/Q1 Predictions Mean       -40.5609
trainer/Q1 Predictions Std         26.1371
trainer/Q1 Predictions Max        -12.1737
trainer/Q1 Predictions Min       -101.089
trainer/Q2 Predictions Mean       -40.6146
trainer/Q2 Predictions Std         26.1631
trainer/Q2 Predictions Max        -12.2898
trainer/Q2 Predictions Min       -101.247
trainer/Q Targets Mean            -40.9783
trainer/Q Targets Std              26.2756
trainer/Q Targets Max             -12.1797
trainer/Q Targets Min            -102.679
trainer/Log Pis Mean                2.09291
trainer/Log Pis Std                 1.11397
trainer/Log Pis Max                 5.5606
trainer/Log Pis Min                -1.66051
trainer/Policy mu Mean              0.128501
trainer/Policy mu Std               0.800645
trainer/Policy mu Max               3.65213
trainer/Policy mu Min              -2.61616
trainer/Policy log std Mean        -2.00708
trainer/Policy log std Std          0.557861
trainer/Policy log std Max         -0.184882
trainer/Policy log std Min         -2.75675
trainer/Alpha                       0.0732639
trainer/Alpha Loss                  0.242855
exploration/num steps total     58700
exploration/num paths total       587
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.708518
exploration/Rewards Std             1.05564
exploration/Rewards Max            -0.0900323
exploration/Rewards Min            -9.54429
exploration/Returns Mean          -70.8518
exploration/Returns Std            10.7348
exploration/Returns Max           -53.0056
exploration/Returns Min           -83.8911
exploration/Actions Mean            0.0311415
exploration/Actions Std             0.218044
exploration/Actions Max             0.999944
exploration/Actions Min            -0.969593
exploration/Num Paths               5
exploration/Average Returns       -70.8518
evaluation/num steps total     175500
evaluation/num paths total       1755
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.843141
evaluation/Rewards Std              0.955374
evaluation/Rewards Max             -0.0439535
evaluation/Rewards Min             -8.12543
evaluation/Returns Mean           -84.3141
evaluation/Returns Std             66.4757
evaluation/Returns Max            -13.1859
evaluation/Returns Min           -194.085
evaluation/Actions Mean            -0.00303347
evaluation/Actions Std              0.160362
evaluation/Actions Max              0.995889
evaluation/Actions Min             -0.996679
evaluation/Num Paths               15
evaluation/Average Returns        -84.3141
time/data storing (s)               0.00290517
time/evaluation sampling (s)        0.325963
time/exploration sampling (s)       0.141377
time/logging (s)                    0.00483205
time/saving (s)                     0.0019384
time/training (s)                   1.95884
time/epoch (s)                      2.43585
time/total (s)                    289.179
Epoch                             116
-----------------------------  ---------------
2019-04-22 23:32:05.409963 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 117 finished
-----------------------------  ---------------
replay_buffer/size              59200
trainer/QF1 Loss                   26.5712
trainer/QF2 Loss                   26.6011
trainer/Policy Loss                38.578
trainer/Q1 Predictions Mean       -37.2358
trainer/Q1 Predictions Std         21.7043
trainer/Q1 Predictions Max        -11.8511
trainer/Q1 Predictions Min       -100.007
trainer/Q2 Predictions Mean       -37.2121
trainer/Q2 Predictions Std         21.6977
trainer/Q2 Predictions Max        -11.9384
trainer/Q2 Predictions Min       -100.175
trainer/Q Targets Mean            -37.0329
trainer/Q Targets Std              22.7399
trainer/Q Targets Max              -0.602978
trainer/Q Targets Min            -102.844
trainer/Log Pis Mean                1.96906
trainer/Log Pis Std                 1.37293
trainer/Log Pis Max                 6.47697
trainer/Log Pis Min                -3.33797
trainer/Policy mu Mean              0.0309054
trainer/Policy mu Std               0.798313
trainer/Policy mu Max               3.14673
trainer/Policy mu Min              -2.64602
trainer/Policy log std Mean        -1.93756
trainer/Policy log std Std          0.542044
trainer/Policy log std Max         -0.255998
trainer/Policy log std Min         -2.59872
trainer/Alpha                       0.0724668
trainer/Alpha Loss                 -0.081212
exploration/num steps total     59200
exploration/num paths total       592
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.55578
exploration/Rewards Std             0.987562
exploration/Rewards Max            -0.0286289
exploration/Rewards Min            -8.20863
exploration/Returns Mean          -55.578
exploration/Returns Std             7.33602
exploration/Returns Max           -43.2493
exploration/Returns Min           -64.7999
exploration/Actions Mean            0.0146575
exploration/Actions Std             0.222988
exploration/Actions Max             0.999251
exploration/Actions Min            -0.997826
exploration/Num Paths               5
exploration/Average Returns       -55.578
evaluation/num steps total     177000
evaluation/num paths total       1770
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.788904
evaluation/Rewards Std              1.09623
evaluation/Rewards Max             -0.044088
evaluation/Rewards Min             -9.97399
evaluation/Returns Mean           -78.8904
evaluation/Returns Std             65.2904
evaluation/Returns Max            -10.2881
evaluation/Returns Min           -218.973
evaluation/Actions Mean             0.00188216
evaluation/Actions Std              0.18474
evaluation/Actions Max              0.998181
evaluation/Actions Min             -0.998387
evaluation/Num Paths               15
evaluation/Average Returns        -78.8904
time/data storing (s)               0.00288846
time/evaluation sampling (s)        0.337578
time/exploration sampling (s)       0.139076
time/logging (s)                    0.00499039
time/saving (s)                     0.00194807
time/training (s)                   1.94206
time/epoch (s)                      2.42854
time/total (s)                    291.612
Epoch                             117
-----------------------------  ---------------
2019-04-22 23:32:07.826999 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 118 finished
-----------------------------  ---------------
replay_buffer/size              59700
trainer/QF1 Loss                   15.6789
trainer/QF2 Loss                   15.6188
trainer/Policy Loss                44.9981
trainer/Q1 Predictions Mean       -43.7585
trainer/Q1 Predictions Std         26.4589
trainer/Q1 Predictions Max        -12.0105
trainer/Q1 Predictions Min       -101.992
trainer/Q2 Predictions Mean       -43.7708
trainer/Q2 Predictions Std         26.4707
trainer/Q2 Predictions Max        -11.922
trainer/Q2 Predictions Min       -102.181
trainer/Q Targets Mean            -43.8789
trainer/Q Targets Std              26.9083
trainer/Q Targets Max              -1.79133
trainer/Q Targets Min            -103.508
trainer/Log Pis Mean                1.90872
trainer/Log Pis Std                 1.32472
trainer/Log Pis Max                 6.66293
trainer/Log Pis Min                -2.46726
trainer/Policy mu Mean              0.105385
trainer/Policy mu Std               0.78091
trainer/Policy mu Max               3.84934
trainer/Policy mu Min              -2.69916
trainer/Policy log std Mean        -1.95432
trainer/Policy log std Std          0.501134
trainer/Policy log std Max         -0.246748
trainer/Policy log std Min         -2.55445
trainer/Alpha                       0.071922
trainer/Alpha Loss                 -0.240281
exploration/num steps total     59700
exploration/num paths total       597
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.711184
exploration/Rewards Std             0.981331
exploration/Rewards Max            -0.0211131
exploration/Rewards Min            -8.68943
exploration/Returns Mean          -71.1184
exploration/Returns Std            60.3576
exploration/Returns Max           -24.1606
exploration/Returns Min          -187.822
exploration/Actions Mean           -0.0224921
exploration/Actions Std             0.181995
exploration/Actions Max             0.641079
exploration/Actions Min            -0.997367
exploration/Num Paths               5
exploration/Average Returns       -71.1184
evaluation/num steps total     178500
evaluation/num paths total       1785
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.577809
evaluation/Rewards Std              0.972976
evaluation/Rewards Max             -0.0087589
evaluation/Rewards Min            -10.2042
evaluation/Returns Mean           -57.7809
evaluation/Returns Std             25.75
evaluation/Returns Max            -10.6175
evaluation/Returns Min           -107.339
evaluation/Actions Mean             0.00608177
evaluation/Actions Std              0.18335
evaluation/Actions Max              0.999254
evaluation/Actions Min             -0.99721
evaluation/Num Paths               15
evaluation/Average Returns        -57.7809
time/data storing (s)               0.00291677
time/evaluation sampling (s)        0.326959
time/exploration sampling (s)       0.141522
time/logging (s)                    0.00478553
time/saving (s)                     0.00194424
time/training (s)                   1.9324
time/epoch (s)                      2.41053
time/total (s)                    294.027
Epoch                             118
-----------------------------  ---------------
2019-04-22 23:32:10.269455 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 119 finished
-----------------------------  ---------------
replay_buffer/size              60200
trainer/QF1 Loss                    1.94141
trainer/QF2 Loss                    1.97319
trainer/Policy Loss                44.1357
trainer/Q1 Predictions Mean       -42.8939
trainer/Q1 Predictions Std         28.2328
trainer/Q1 Predictions Max        -11.8886
trainer/Q1 Predictions Min       -137.815
trainer/Q2 Predictions Mean       -42.9553
trainer/Q2 Predictions Std         28.2534
trainer/Q2 Predictions Max        -11.8842
trainer/Q2 Predictions Min       -138.022
trainer/Q Targets Mean            -42.9923
trainer/Q Targets Std              28.5339
trainer/Q Targets Max              -0.220237
trainer/Q Targets Min            -137.504
trainer/Log Pis Mean                2.07987
trainer/Log Pis Std                 1.48408
trainer/Log Pis Max                 9.57672
trainer/Log Pis Min                -1.23257
trainer/Policy mu Mean             -0.0328777
trainer/Policy mu Std               0.912193
trainer/Policy mu Max               3.53965
trainer/Policy mu Min              -3.0787
trainer/Policy log std Mean        -1.90923
trainer/Policy log std Std          0.568998
trainer/Policy log std Max         -0.303588
trainer/Policy log std Min         -2.63519
trainer/Alpha                       0.0711843
trainer/Alpha Loss                  0.211056
exploration/num steps total     60200
exploration/num paths total       602
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.08666
exploration/Rewards Std             1.00602
exploration/Rewards Max            -0.0137875
exploration/Rewards Min            -7.48766
exploration/Returns Mean         -108.666
exploration/Returns Std            71.062
exploration/Returns Max           -22.7535
exploration/Returns Min          -195.573
exploration/Actions Mean           -0.0219536
exploration/Actions Std             0.197731
exploration/Actions Max             0.926358
exploration/Actions Min            -0.997397
exploration/Num Paths               5
exploration/Average Returns      -108.666
evaluation/num steps total     180000
evaluation/num paths total       1800
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.02285
evaluation/Rewards Std              1.24011
evaluation/Rewards Max             -0.0548311
evaluation/Rewards Min             -9.88439
evaluation/Returns Mean          -102.285
evaluation/Returns Std             71.4445
evaluation/Returns Max            -29.0796
evaluation/Returns Min           -212.934
evaluation/Actions Mean            -0.0050682
evaluation/Actions Std              0.203894
evaluation/Actions Max              0.998956
evaluation/Actions Min             -0.998195
evaluation/Num Paths               15
evaluation/Average Returns       -102.285
time/data storing (s)               0.00294466
time/evaluation sampling (s)        0.334363
time/exploration sampling (s)       0.14253
time/logging (s)                    0.00479604
time/saving (s)                     0.00195389
time/training (s)                   1.94938
time/epoch (s)                      2.43596
time/total (s)                    296.467
Epoch                             119
-----------------------------  ---------------
2019-04-22 23:32:12.708987 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 120 finished
-----------------------------  ---------------
replay_buffer/size              60700
trainer/QF1 Loss                   86.8271
trainer/QF2 Loss                   86.9923
trainer/Policy Loss                40.6174
trainer/Q1 Predictions Mean       -39.3492
trainer/Q1 Predictions Std         27.6744
trainer/Q1 Predictions Max        -11.1411
trainer/Q1 Predictions Min       -133.224
trainer/Q2 Predictions Mean       -39.3021
trainer/Q2 Predictions Std         27.658
trainer/Q2 Predictions Max        -11.1197
trainer/Q2 Predictions Min       -132.927
trainer/Q Targets Mean            -38.8243
trainer/Q Targets Std              27.8839
trainer/Q Targets Max              -1.2213
trainer/Q Targets Min            -136.643
trainer/Log Pis Mean                2.18681
trainer/Log Pis Std                 1.23582
trainer/Log Pis Max                 5.92333
trainer/Log Pis Min                -2.12165
trainer/Policy mu Mean             -0.0741896
trainer/Policy mu Std               0.828466
trainer/Policy mu Max               2.92151
trainer/Policy mu Min              -3.10759
trainer/Policy log std Mean        -2.02153
trainer/Policy log std Std          0.543951
trainer/Policy log std Max         -0.503592
trainer/Policy log std Min         -2.76094
trainer/Alpha                       0.0710339
trainer/Alpha Loss                  0.494068
exploration/num steps total     60700
exploration/num paths total       607
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.00042
exploration/Rewards Std             1.13379
exploration/Rewards Max            -0.022769
exploration/Rewards Min           -10.4945
exploration/Returns Mean         -100.042
exploration/Returns Std            84.0875
exploration/Returns Max           -14.1668
exploration/Returns Min          -212.429
exploration/Actions Mean           -0.0289228
exploration/Actions Std             0.210068
exploration/Actions Max             0.978718
exploration/Actions Min            -0.999583
exploration/Num Paths               5
exploration/Average Returns      -100.042
evaluation/num steps total     181500
evaluation/num paths total       1815
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.630438
evaluation/Rewards Std              1.05827
evaluation/Rewards Max             -0.0242651
evaluation/Rewards Min            -10.272
evaluation/Returns Mean           -63.0438
evaluation/Returns Std             59.0785
evaluation/Returns Max             -6.70972
evaluation/Returns Min           -204.852
evaluation/Actions Mean            -0.0154991
evaluation/Actions Std              0.163871
evaluation/Actions Max              0.992273
evaluation/Actions Min             -0.999011
evaluation/Num Paths               15
evaluation/Average Returns        -63.0438
time/data storing (s)               0.00294051
time/evaluation sampling (s)        0.329484
time/exploration sampling (s)       0.140715
time/logging (s)                    0.00480552
time/saving (s)                     0.00976055
time/training (s)                   1.94539
time/epoch (s)                      2.4331
time/total (s)                    298.904
Epoch                             120
-----------------------------  ---------------
2019-04-22 23:32:15.123590 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 121 finished
-----------------------------  ---------------
replay_buffer/size              61200
trainer/QF1 Loss                  178.286
trainer/QF2 Loss                  178.722
trainer/Policy Loss                43.1685
trainer/Q1 Predictions Mean       -41.8787
trainer/Q1 Predictions Std         29.8899
trainer/Q1 Predictions Max        -11.5289
trainer/Q1 Predictions Min       -100.286
trainer/Q2 Predictions Mean       -41.833
trainer/Q2 Predictions Std         29.9235
trainer/Q2 Predictions Max        -11.5612
trainer/Q2 Predictions Min       -100.451
trainer/Q Targets Mean            -40.3245
trainer/Q Targets Std              29.5567
trainer/Q Targets Max              -1.6974
trainer/Q Targets Min            -101.411
trainer/Log Pis Mean                1.93478
trainer/Log Pis Std                 1.16495
trainer/Log Pis Max                 6.69713
trainer/Log Pis Min                -1.37546
trainer/Policy mu Mean              0.0437405
trainer/Policy mu Std               0.747408
trainer/Policy mu Max               2.96755
trainer/Policy mu Min              -2.43008
trainer/Policy log std Mean        -1.93948
trainer/Policy log std Std          0.509538
trainer/Policy log std Max         -0.495166
trainer/Policy log std Min         -2.6184
trainer/Alpha                       0.0706615
trainer/Alpha Loss                 -0.172822
exploration/num steps total     61200
exploration/num paths total       612
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.669891
exploration/Rewards Std             0.795589
exploration/Rewards Max            -0.0194077
exploration/Rewards Min            -8.89103
exploration/Returns Mean          -66.9891
exploration/Returns Std             4.10204
exploration/Returns Max           -60.2912
exploration/Returns Min           -71.1063
exploration/Actions Mean            0.00717423
exploration/Actions Std             0.198023
exploration/Actions Max             0.99931
exploration/Actions Min            -0.998234
exploration/Num Paths               5
exploration/Average Returns       -66.9891
evaluation/num steps total     183000
evaluation/num paths total       1830
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.86119
evaluation/Rewards Std              1.00655
evaluation/Rewards Max             -0.0919758
evaluation/Rewards Min             -9.49406
evaluation/Returns Mean           -86.119
evaluation/Returns Std             65.4395
evaluation/Returns Max            -16.263
evaluation/Returns Min           -209.75
evaluation/Actions Mean             0.00812329
evaluation/Actions Std              0.171381
evaluation/Actions Max              0.998916
evaluation/Actions Min             -0.994096
evaluation/Num Paths               15
evaluation/Average Returns        -86.119
time/data storing (s)               0.00287657
time/evaluation sampling (s)        0.324133
time/exploration sampling (s)       0.140414
time/logging (s)                    0.00473829
time/saving (s)                     0.00192251
time/training (s)                   1.93494
time/epoch (s)                      2.40903
time/total (s)                    301.317
Epoch                             121
-----------------------------  ---------------
2019-04-22 23:32:17.533775 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 122 finished
-----------------------------  ---------------
replay_buffer/size              61700
trainer/QF1 Loss                    1.82946
trainer/QF2 Loss                    1.72645
trainer/Policy Loss                42.5763
trainer/Q1 Predictions Mean       -41.2777
trainer/Q1 Predictions Std         30.4444
trainer/Q1 Predictions Max        -11.6413
trainer/Q1 Predictions Min       -132.049
trainer/Q2 Predictions Mean       -41.341
trainer/Q2 Predictions Std         30.4632
trainer/Q2 Predictions Max        -11.6718
trainer/Q2 Predictions Min       -132.087
trainer/Q Targets Mean            -41.2899
trainer/Q Targets Std              30.6244
trainer/Q Targets Max              -1.2213
trainer/Q Targets Min            -134.388
trainer/Log Pis Mean                1.87766
trainer/Log Pis Std                 1.28964
trainer/Log Pis Max                 7.85936
trainer/Log Pis Min                -1.37421
trainer/Policy mu Mean             -0.0556889
trainer/Policy mu Std               0.832743
trainer/Policy mu Max               2.14766
trainer/Policy mu Min              -3.04356
trainer/Policy log std Mean        -1.91722
trainer/Policy log std Std          0.549759
trainer/Policy log std Max         -0.505783
trainer/Policy log std Min         -2.70499
trainer/Alpha                       0.0705367
trainer/Alpha Loss                 -0.32441
exploration/num steps total     61700
exploration/num paths total       617
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.776485
exploration/Rewards Std             0.998834
exploration/Rewards Max            -0.0205835
exploration/Rewards Min            -7.60938
exploration/Returns Mean          -77.6485
exploration/Returns Std            55.3747
exploration/Returns Max           -39.7078
exploration/Returns Min          -187.585
exploration/Actions Mean            0.0175197
exploration/Actions Std             0.208634
exploration/Actions Max             0.998431
exploration/Actions Min            -0.999356
exploration/Num Paths               5
exploration/Average Returns       -77.6485
evaluation/num steps total     184500
evaluation/num paths total       1845
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.818385
evaluation/Rewards Std              0.955177
evaluation/Rewards Max             -0.0174105
evaluation/Rewards Min             -8.4165
evaluation/Returns Mean           -81.8385
evaluation/Returns Std             68.7802
evaluation/Returns Max            -17.0736
evaluation/Returns Min           -205.263
evaluation/Actions Mean             0.00660987
evaluation/Actions Std              0.161534
evaluation/Actions Max              0.996726
evaluation/Actions Min             -0.992119
evaluation/Num Paths               15
evaluation/Average Returns        -81.8385
time/data storing (s)               0.00288742
time/evaluation sampling (s)        0.33005
time/exploration sampling (s)       0.140459
time/logging (s)                    0.00482983
time/saving (s)                     0.00195639
time/training (s)                   1.92361
time/epoch (s)                      2.40379
time/total (s)                    303.725
Epoch                             122
-----------------------------  ---------------
2019-04-22 23:32:19.926495 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 123 finished
-----------------------------  ---------------
replay_buffer/size              62200
trainer/QF1 Loss                   17.955
trainer/QF2 Loss                   17.8624
trainer/Policy Loss                38.6739
trainer/Q1 Predictions Mean       -37.3979
trainer/Q1 Predictions Std         25.6513
trainer/Q1 Predictions Max        -11.0856
trainer/Q1 Predictions Min       -105.128
trainer/Q2 Predictions Mean       -37.4231
trainer/Q2 Predictions Std         25.6627
trainer/Q2 Predictions Max        -11.1559
trainer/Q2 Predictions Min       -105.578
trainer/Q Targets Mean            -37.3458
trainer/Q Targets Std              26.0271
trainer/Q Targets Max              -3.06664
trainer/Q Targets Min            -104.553
trainer/Log Pis Mean                2.02136
trainer/Log Pis Std                 1.088
trainer/Log Pis Max                 6.51426
trainer/Log Pis Min                -2.23014
trainer/Policy mu Mean              0.0149429
trainer/Policy mu Std               0.789091
trainer/Policy mu Max               2.95939
trainer/Policy mu Min              -2.9956
trainer/Policy log std Mean        -1.95256
trainer/Policy log std Std          0.531729
trainer/Policy log std Max         -0.420056
trainer/Policy log std Min         -2.62426
trainer/Alpha                       0.0696823
trainer/Alpha Loss                  0.0568869
exploration/num steps total     62200
exploration/num paths total       622
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.657096
exploration/Rewards Std             1.04952
exploration/Rewards Max            -0.0124876
exploration/Rewards Min            -8.55457
exploration/Returns Mean          -65.7096
exploration/Returns Std            72.8366
exploration/Returns Max           -18.6894
exploration/Returns Min          -208.666
exploration/Actions Mean           -0.00122778
exploration/Actions Std             0.187097
exploration/Actions Max             0.999789
exploration/Actions Min            -0.992906
exploration/Num Paths               5
exploration/Average Returns       -65.7096
evaluation/num steps total     186000
evaluation/num paths total       1860
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.537292
evaluation/Rewards Std              1.27283
evaluation/Rewards Max             -0.0631964
evaluation/Rewards Min            -11.0889
evaluation/Returns Mean           -53.7292
evaluation/Returns Std             21.3612
evaluation/Returns Max            -23.6798
evaluation/Returns Min            -89.4971
evaluation/Actions Mean             0.0108208
evaluation/Actions Std              0.212246
evaluation/Actions Max              0.999493
evaluation/Actions Min             -0.997801
evaluation/Num Paths               15
evaluation/Average Returns        -53.7292
time/data storing (s)               0.00285159
time/evaluation sampling (s)        0.331965
time/exploration sampling (s)       0.143624
time/logging (s)                    0.0048174
time/saving (s)                     0.00195109
time/training (s)                   1.90064
time/epoch (s)                      2.38584
time/total (s)                    306.115
Epoch                             123
-----------------------------  ---------------
2019-04-22 23:32:22.349472 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 124 finished
-----------------------------  ---------------
replay_buffer/size              62700
trainer/QF1 Loss                    2.0669
trainer/QF2 Loss                    2.03823
trainer/Policy Loss                38.6217
trainer/Q1 Predictions Mean       -37.3255
trainer/Q1 Predictions Std         21.5506
trainer/Q1 Predictions Max        -10.9032
trainer/Q1 Predictions Min        -96.215
trainer/Q2 Predictions Mean       -37.2771
trainer/Q2 Predictions Std         21.5451
trainer/Q2 Predictions Max        -10.8871
trainer/Q2 Predictions Min        -96.2052
trainer/Q Targets Mean            -37.5305
trainer/Q Targets Std              22.0123
trainer/Q Targets Max              -0.199077
trainer/Q Targets Min             -97.3452
trainer/Log Pis Mean                2.10372
trainer/Log Pis Std                 1.45322
trainer/Log Pis Max                 8.001
trainer/Log Pis Min                -2.01165
trainer/Policy mu Mean              0.129541
trainer/Policy mu Std               0.84102
trainer/Policy mu Max               3.22691
trainer/Policy mu Min              -2.94984
trainer/Policy log std Mean        -1.91978
trainer/Policy log std Std          0.555771
trainer/Policy log std Max         -0.37524
trainer/Policy log std Min         -2.654
trainer/Alpha                       0.0701494
trainer/Alpha Loss                  0.275611
exploration/num steps total     62700
exploration/num paths total       627
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.40192
exploration/Rewards Std             1.09832
exploration/Rewards Max            -0.00763458
exploration/Rewards Min            -9.02888
exploration/Returns Mean          -40.192
exploration/Returns Std            11.7717
exploration/Returns Max           -25.0837
exploration/Returns Min           -56.6781
exploration/Actions Mean            0.00401165
exploration/Actions Std             0.242283
exploration/Actions Max             0.999319
exploration/Actions Min            -0.996621
exploration/Num Paths               5
exploration/Average Returns       -40.192
evaluation/num steps total     187500
evaluation/num paths total       1875
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.628064
evaluation/Rewards Std              0.961616
evaluation/Rewards Max             -0.0405607
evaluation/Rewards Min             -9.10552
evaluation/Returns Mean           -62.8064
evaluation/Returns Std             64.4411
evaluation/Returns Max             -8.1072
evaluation/Returns Min           -230.708
evaluation/Actions Mean            -0.00434352
evaluation/Actions Std              0.155993
evaluation/Actions Max              0.99848
evaluation/Actions Min             -0.995512
evaluation/Num Paths               15
evaluation/Average Returns        -62.8064
time/data storing (s)               0.00293611
time/evaluation sampling (s)        0.33099
time/exploration sampling (s)       0.142346
time/logging (s)                    0.00400393
time/saving (s)                     0.00197176
time/training (s)                   1.93301
time/epoch (s)                      2.41526
time/total (s)                    308.535
Epoch                             124
-----------------------------  ---------------
2019-04-22 23:32:24.749027 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 125 finished
-----------------------------  ---------------
replay_buffer/size              63200
trainer/QF1 Loss                   31.2819
trainer/QF2 Loss                   31.5007
trainer/Policy Loss                36.7762
trainer/Q1 Predictions Mean       -35.3259
trainer/Q1 Predictions Std         24.1035
trainer/Q1 Predictions Max        -10.9102
trainer/Q1 Predictions Min       -110.402
trainer/Q2 Predictions Mean       -35.3274
trainer/Q2 Predictions Std         24.111
trainer/Q2 Predictions Max        -10.931
trainer/Q2 Predictions Min       -110.741
trainer/Q Targets Mean            -34.8369
trainer/Q Targets Std              24.7456
trainer/Q Targets Max              -2.23508
trainer/Q Targets Min            -110.576
trainer/Log Pis Mean                2.14476
trainer/Log Pis Std                 1.42852
trainer/Log Pis Max                 7.01712
trainer/Log Pis Min                -2.74302
trainer/Policy mu Mean              0.0280934
trainer/Policy mu Std               0.825146
trainer/Policy mu Max               3.22234
trainer/Policy mu Min              -2.57421
trainer/Policy log std Mean        -2.03335
trainer/Policy log std Std          0.542223
trainer/Policy log std Max         -0.483742
trainer/Policy log std Min         -2.73537
trainer/Alpha                       0.0710314
trainer/Alpha Loss                  0.382848
exploration/num steps total     63200
exploration/num paths total       632
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.724208
exploration/Rewards Std             1.21734
exploration/Rewards Max            -0.0158758
exploration/Rewards Min           -11.5304
exploration/Returns Mean          -72.4208
exploration/Returns Std            80.9995
exploration/Returns Max           -15.6831
exploration/Returns Min          -229.677
exploration/Actions Mean           -0.026623
exploration/Actions Std             0.206944
exploration/Actions Max             0.963496
exploration/Actions Min            -0.998779
exploration/Num Paths               5
exploration/Average Returns       -72.4208
evaluation/num steps total     189000
evaluation/num paths total       1890
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.652787
evaluation/Rewards Std              1.08804
evaluation/Rewards Max             -0.0298251
evaluation/Rewards Min            -11.0421
evaluation/Returns Mean           -65.2787
evaluation/Returns Std             51.9858
evaluation/Returns Max            -15.8206
evaluation/Returns Min           -194.493
evaluation/Actions Mean             0.0085339
evaluation/Actions Std              0.178446
evaluation/Actions Max              0.999496
evaluation/Actions Min             -0.997151
evaluation/Num Paths               15
evaluation/Average Returns        -65.2787
time/data storing (s)               0.00289864
time/evaluation sampling (s)        0.327405
time/exploration sampling (s)       0.142191
time/logging (s)                    0.00484573
time/saving (s)                     0.00195146
time/training (s)                   1.91458
time/epoch (s)                      2.39387
time/total (s)                    310.934
Epoch                             125
-----------------------------  ---------------
2019-04-22 23:32:27.181103 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 126 finished
-----------------------------  ---------------
replay_buffer/size              63700
trainer/QF1 Loss                    0.201498
trainer/QF2 Loss                    0.161427
trainer/Policy Loss                39.939
trainer/Q1 Predictions Mean       -38.6361
trainer/Q1 Predictions Std         26.2786
trainer/Q1 Predictions Max        -10.7752
trainer/Q1 Predictions Min        -94.6889
trainer/Q2 Predictions Mean       -38.6167
trainer/Q2 Predictions Std         26.2919
trainer/Q2 Predictions Max        -10.8711
trainer/Q2 Predictions Min        -94.7233
trainer/Q Targets Mean            -38.7462
trainer/Q Targets Std              26.4059
trainer/Q Targets Max             -10.8733
trainer/Q Targets Min             -94.9408
trainer/Log Pis Mean                2.013
trainer/Log Pis Std                 1.04179
trainer/Log Pis Max                 5.08789
trainer/Log Pis Min                -1.29843
trainer/Policy mu Mean              0.0948595
trainer/Policy mu Std               0.689771
trainer/Policy mu Max               2.56587
trainer/Policy mu Min              -2.46642
trainer/Policy log std Mean        -1.9786
trainer/Policy log std Std          0.492744
trainer/Policy log std Max         -0.459536
trainer/Policy log std Min         -2.70528
trainer/Alpha                       0.0723654
trainer/Alpha Loss                  0.0341356
exploration/num steps total     63700
exploration/num paths total       637
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.431462
exploration/Rewards Std             1.02086
exploration/Rewards Max            -0.00128247
exploration/Rewards Min            -9.3431
exploration/Returns Mean          -43.1462
exploration/Returns Std            18.5238
exploration/Returns Max           -19.2502
exploration/Returns Min           -67.0754
exploration/Actions Mean            0.00405482
exploration/Actions Std             0.200421
exploration/Actions Max             0.998914
exploration/Actions Min            -0.999268
exploration/Num Paths               5
exploration/Average Returns       -43.1462
evaluation/num steps total     190500
evaluation/num paths total       1905
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.00025
evaluation/Rewards Std              1.28599
evaluation/Rewards Max             -0.104614
evaluation/Rewards Min             -9.945
evaluation/Returns Mean          -100.025
evaluation/Returns Std             78.2745
evaluation/Returns Max            -15.2965
evaluation/Returns Min           -221.905
evaluation/Actions Mean             0.00303803
evaluation/Actions Std              0.200279
evaluation/Actions Max              0.998558
evaluation/Actions Min             -0.997834
evaluation/Num Paths               15
evaluation/Average Returns       -100.025
time/data storing (s)               0.00296161
time/evaluation sampling (s)        0.340211
time/exploration sampling (s)       0.142093
time/logging (s)                    0.0035889
time/saving (s)                     0.00158258
time/training (s)                   1.9335
time/epoch (s)                      2.42394
time/total (s)                    313.362
Epoch                             126
-----------------------------  ---------------
2019-04-22 23:32:29.612189 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 127 finished
-----------------------------  ---------------
replay_buffer/size              64200
trainer/QF1 Loss                    0.529966
trainer/QF2 Loss                    0.353837
trainer/Policy Loss                43.6164
trainer/Q1 Predictions Mean       -42.1094
trainer/Q1 Predictions Std         30.0057
trainer/Q1 Predictions Max        -11.1101
trainer/Q1 Predictions Min        -98.3759
trainer/Q2 Predictions Mean       -42.1144
trainer/Q2 Predictions Std         29.996
trainer/Q2 Predictions Max        -11.0252
trainer/Q2 Predictions Min        -98.518
trainer/Q Targets Mean            -42.2694
trainer/Q Targets Std              30.1805
trainer/Q Targets Max             -10.8322
trainer/Q Targets Min             -98.7271
trainer/Log Pis Mean                2.24719
trainer/Log Pis Std                 1.24302
trainer/Log Pis Max                 7.02956
trainer/Log Pis Min                -1.85836
trainer/Policy mu Mean              0.0600405
trainer/Policy mu Std               0.81287
trainer/Policy mu Max               2.55904
trainer/Policy mu Min              -3.38091
trainer/Policy log std Mean        -1.97165
trainer/Policy log std Std          0.517987
trainer/Policy log std Max         -0.077701
trainer/Policy log std Min         -2.67109
trainer/Alpha                       0.0727018
trainer/Alpha Loss                  0.647958
exploration/num steps total     64200
exploration/num paths total       642
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.603719
exploration/Rewards Std             1.09757
exploration/Rewards Max            -0.0141432
exploration/Rewards Min            -8.99202
exploration/Returns Mean          -60.3719
exploration/Returns Std            15.7221
exploration/Returns Max           -38.9417
exploration/Returns Min           -77.4516
exploration/Actions Mean           -0.00488552
exploration/Actions Std             0.238695
exploration/Actions Max             0.99986
exploration/Actions Min            -0.996292
exploration/Num Paths               5
exploration/Average Returns       -60.3719
evaluation/num steps total     192000
evaluation/num paths total       1920
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.530756
evaluation/Rewards Std              0.946185
evaluation/Rewards Max             -0.060332
evaluation/Rewards Min             -8.53655
evaluation/Returns Mean           -53.0756
evaluation/Returns Std             48.2727
evaluation/Returns Max             -8.12218
evaluation/Returns Min           -216.101
evaluation/Actions Mean            -0.00295734
evaluation/Actions Std              0.176052
evaluation/Actions Max              0.999059
evaluation/Actions Min             -0.996583
evaluation/Num Paths               15
evaluation/Average Returns        -53.0756
time/data storing (s)               0.00293053
time/evaluation sampling (s)        0.330595
time/exploration sampling (s)       0.142019
time/logging (s)                    0.00483267
time/saving (s)                     0.00197454
time/training (s)                   1.94337
time/epoch (s)                      2.42572
time/total (s)                    315.792
Epoch                             127
-----------------------------  ---------------
2019-04-22 23:32:32.038785 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 128 finished
-----------------------------  ---------------
replay_buffer/size              64700
trainer/QF1 Loss                   86.5549
trainer/QF2 Loss                   86.4616
trainer/Policy Loss                38.6601
trainer/Q1 Predictions Mean       -37.4186
trainer/Q1 Predictions Std         26.7408
trainer/Q1 Predictions Max        -11.0194
trainer/Q1 Predictions Min       -101.601
trainer/Q2 Predictions Mean       -37.4558
trainer/Q2 Predictions Std         26.7365
trainer/Q2 Predictions Max        -11.0495
trainer/Q2 Predictions Min       -101.428
trainer/Q Targets Mean            -36.755
trainer/Q Targets Std              26.2607
trainer/Q Targets Max              -1.9825
trainer/Q Targets Min            -101.017
trainer/Log Pis Mean                1.93332
trainer/Log Pis Std                 1.38074
trainer/Log Pis Max                 6.72103
trainer/Log Pis Min                -2.32702
trainer/Policy mu Mean              0.0206047
trainer/Policy mu Std               0.763586
trainer/Policy mu Max               2.69763
trainer/Policy mu Min              -2.67014
trainer/Policy log std Mean        -1.97613
trainer/Policy log std Std          0.534256
trainer/Policy log std Max         -0.331782
trainer/Policy log std Min         -2.65071
trainer/Alpha                       0.0730264
trainer/Alpha Loss                 -0.174491
exploration/num steps total     64700
exploration/num paths total       647
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.719247
exploration/Rewards Std             1.33401
exploration/Rewards Max            -0.0127471
exploration/Rewards Min            -9.89041
exploration/Returns Mean          -71.9247
exploration/Returns Std            21.8354
exploration/Returns Max           -36.148
exploration/Returns Min           -98.7907
exploration/Actions Mean            0.0371075
exploration/Actions Std             0.246962
exploration/Actions Max             0.999926
exploration/Actions Min            -0.996851
exploration/Num Paths               5
exploration/Average Returns       -71.9247
evaluation/num steps total     193500
evaluation/num paths total       1935
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.900232
evaluation/Rewards Std              1.11367
evaluation/Rewards Max             -0.0485245
evaluation/Rewards Min            -11.2724
evaluation/Returns Mean           -90.0232
evaluation/Returns Std             80.6162
evaluation/Returns Max             -7.25364
evaluation/Returns Min           -229.049
evaluation/Actions Mean            -0.0116796
evaluation/Actions Std              0.168445
evaluation/Actions Max              0.99296
evaluation/Actions Min             -0.998903
evaluation/Num Paths               15
evaluation/Average Returns        -90.0232
time/data storing (s)               0.00291672
time/evaluation sampling (s)        0.331059
time/exploration sampling (s)       0.141913
time/logging (s)                    0.00426341
time/saving (s)                     0.00205583
time/training (s)                   1.93673
time/epoch (s)                      2.41894
time/total (s)                    318.216
Epoch                             128
-----------------------------  ---------------
2019-04-22 23:32:34.460242 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 129 finished
-----------------------------  ---------------
replay_buffer/size              65200
trainer/QF1 Loss                    1.57685
trainer/QF2 Loss                    1.58802
trainer/Policy Loss                40.4475
trainer/Q1 Predictions Mean       -39.2136
trainer/Q1 Predictions Std         26.7198
trainer/Q1 Predictions Max        -10.5734
trainer/Q1 Predictions Min       -116.145
trainer/Q2 Predictions Mean       -39.2376
trainer/Q2 Predictions Std         26.6792
trainer/Q2 Predictions Max        -10.6037
trainer/Q2 Predictions Min       -115.914
trainer/Q Targets Mean            -39.2051
trainer/Q Targets Std              26.7685
trainer/Q Targets Max              -0.169452
trainer/Q Targets Min            -117.516
trainer/Log Pis Mean                2.11819
trainer/Log Pis Std                 1.33022
trainer/Log Pis Max                 8.18512
trainer/Log Pis Min                -1.30611
trainer/Policy mu Mean              0.0844052
trainer/Policy mu Std               0.833631
trainer/Policy mu Max               3.4421
trainer/Policy mu Min              -2.77556
trainer/Policy log std Mean        -1.97063
trainer/Policy log std Std          0.541972
trainer/Policy log std Max         -0.307956
trainer/Policy log std Min         -2.71386
trainer/Alpha                       0.072785
trainer/Alpha Loss                  0.309687
exploration/num steps total     65200
exploration/num paths total       652
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.472525
exploration/Rewards Std             1.20337
exploration/Rewards Max            -0.015511
exploration/Rewards Min            -9.88882
exploration/Returns Mean          -47.2525
exploration/Returns Std            14.4321
exploration/Returns Max           -30.7294
exploration/Returns Min           -64.832
exploration/Actions Mean            0.00825364
exploration/Actions Std             0.236236
exploration/Actions Max             0.999888
exploration/Actions Min            -0.998527
exploration/Num Paths               5
exploration/Average Returns       -47.2525
evaluation/num steps total     195000
evaluation/num paths total       1950
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.748549
evaluation/Rewards Std              0.880223
evaluation/Rewards Max             -0.0453794
evaluation/Rewards Min             -6.47151
evaluation/Returns Mean           -74.8549
evaluation/Returns Std             74.2895
evaluation/Returns Max            -13.208
evaluation/Returns Min           -201.093
evaluation/Actions Mean             0.00480973
evaluation/Actions Std              0.143317
evaluation/Actions Max              0.9975
evaluation/Actions Min             -0.984414
evaluation/Num Paths               15
evaluation/Average Returns        -74.8549
time/data storing (s)               0.00301775
time/evaluation sampling (s)        0.329524
time/exploration sampling (s)       0.141262
time/logging (s)                    0.00482369
time/saving (s)                     0.0020115
time/training (s)                   1.93436
time/epoch (s)                      2.415
time/total (s)                    320.635
Epoch                             129
-----------------------------  ---------------
2019-04-22 23:32:36.894620 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 130 finished
-----------------------------  ---------------
replay_buffer/size              65700
trainer/QF1 Loss                    1.35722
trainer/QF2 Loss                    1.27039
trainer/Policy Loss                36.9468
trainer/Q1 Predictions Mean       -35.7205
trainer/Q1 Predictions Std         26.2347
trainer/Q1 Predictions Max        -10.5367
trainer/Q1 Predictions Min       -107.791
trainer/Q2 Predictions Mean       -35.7657
trainer/Q2 Predictions Std         26.2543
trainer/Q2 Predictions Max        -10.5322
trainer/Q2 Predictions Min       -108.195
trainer/Q Targets Mean            -35.9338
trainer/Q Targets Std              26.4326
trainer/Q Targets Max              -0.303612
trainer/Q Targets Min            -108.939
trainer/Log Pis Mean                1.96916
trainer/Log Pis Std                 1.2975
trainer/Log Pis Max                 8.46963
trainer/Log Pis Min                -1.78413
trainer/Policy mu Mean              0.0768611
trainer/Policy mu Std               0.767645
trainer/Policy mu Max               3.42496
trainer/Policy mu Min              -3.35099
trainer/Policy log std Mean        -1.99647
trainer/Policy log std Std          0.51804
trainer/Policy log std Max         -0.144132
trainer/Policy log std Min         -2.68078
trainer/Alpha                       0.0730461
trainer/Alpha Loss                 -0.0806933
exploration/num steps total     65700
exploration/num paths total       657
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.436784
exploration/Rewards Std             0.632427
exploration/Rewards Max            -0.00446362
exploration/Rewards Min            -7.48638
exploration/Returns Mean          -43.6784
exploration/Returns Std            13.532
exploration/Returns Max           -22.608
exploration/Returns Min           -62.5228
exploration/Actions Mean           -0.00599581
exploration/Actions Std             0.199982
exploration/Actions Max             0.997812
exploration/Actions Min            -0.998619
exploration/Num Paths               5
exploration/Average Returns       -43.6784
evaluation/num steps total     196500
evaluation/num paths total       1965
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.643192
evaluation/Rewards Std              1.01249
evaluation/Rewards Max             -0.0510167
evaluation/Rewards Min             -9.52629
evaluation/Returns Mean           -64.3192
evaluation/Returns Std             59.4597
evaluation/Returns Max            -20.9708
evaluation/Returns Min           -209.784
evaluation/Actions Mean             0.0121544
evaluation/Actions Std              0.165303
evaluation/Actions Max              0.999452
evaluation/Actions Min             -0.9955
evaluation/Num Paths               15
evaluation/Average Returns        -64.3192
time/data storing (s)               0.00286795
time/evaluation sampling (s)        0.326606
time/exploration sampling (s)       0.140438
time/logging (s)                    0.0044488
time/saving (s)                     0.00156534
time/training (s)                   1.95096
time/epoch (s)                      2.42688
time/total (s)                    323.067
Epoch                             130
-----------------------------  ---------------
2019-04-22 23:32:39.314875 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 131 finished
-----------------------------  ---------------
replay_buffer/size              66200
trainer/QF1 Loss                    9.58816
trainer/QF2 Loss                    9.7319
trainer/Policy Loss                40.0451
trainer/Q1 Predictions Mean       -38.5446
trainer/Q1 Predictions Std         28.3266
trainer/Q1 Predictions Max        -10.3597
trainer/Q1 Predictions Min        -97.9766
trainer/Q2 Predictions Mean       -38.499
trainer/Q2 Predictions Std         28.3204
trainer/Q2 Predictions Max        -10.3578
trainer/Q2 Predictions Min        -98.7087
trainer/Q Targets Mean            -38.549
trainer/Q Targets Std              28.4287
trainer/Q Targets Max              -1.23255
trainer/Q Targets Min             -97.0945
trainer/Log Pis Mean                2.18456
trainer/Log Pis Std                 1.25496
trainer/Log Pis Max                 9.00313
trainer/Log Pis Min                -2.14941
trainer/Policy mu Mean              0.131119
trainer/Policy mu Std               0.818884
trainer/Policy mu Max               3.20155
trainer/Policy mu Min              -2.53508
trainer/Policy log std Mean        -1.94679
trainer/Policy log std Std          0.562746
trainer/Policy log std Max         -0.0198122
trainer/Policy log std Min         -2.58034
trainer/Alpha                       0.0741142
trainer/Alpha Loss                  0.480252
exploration/num steps total     66200
exploration/num paths total       662
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.454717
exploration/Rewards Std             0.854137
exploration/Rewards Max            -0.0173574
exploration/Rewards Min            -7.41093
exploration/Returns Mean          -45.4717
exploration/Returns Std            21.983
exploration/Returns Max           -18.3705
exploration/Returns Min           -80.3226
exploration/Actions Mean            0.0229902
exploration/Actions Std             0.216972
exploration/Actions Max             0.999643
exploration/Actions Min            -0.998203
exploration/Num Paths               5
exploration/Average Returns       -45.4717
evaluation/num steps total     198000
evaluation/num paths total       1980
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.748145
evaluation/Rewards Std              1.05038
evaluation/Rewards Max             -0.0509896
evaluation/Rewards Min            -10.7629
evaluation/Returns Mean           -74.8145
evaluation/Returns Std             68.3422
evaluation/Returns Max             -7.17042
evaluation/Returns Min           -221.392
evaluation/Actions Mean             0.016491
evaluation/Actions Std              0.177294
evaluation/Actions Max              0.999473
evaluation/Actions Min             -0.993238
evaluation/Num Paths               15
evaluation/Average Returns        -74.8145
time/data storing (s)               0.00281593
time/evaluation sampling (s)        0.326949
time/exploration sampling (s)       0.143418
time/logging (s)                    0.00480272
time/saving (s)                     0.00154817
time/training (s)                   1.93416
time/epoch (s)                      2.4137
time/total (s)                    325.485
Epoch                             131
-----------------------------  ---------------
2019-04-22 23:32:41.754851 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 132 finished
-----------------------------  ---------------
replay_buffer/size              66700
trainer/QF1 Loss                    2.80103
trainer/QF2 Loss                    2.57044
trainer/Policy Loss                34.3819
trainer/Q1 Predictions Mean       -33.1014
trainer/Q1 Predictions Std         26.4159
trainer/Q1 Predictions Max         -9.93391
trainer/Q1 Predictions Min       -108.668
trainer/Q2 Predictions Mean       -33.0602
trainer/Q2 Predictions Std         26.4528
trainer/Q2 Predictions Max         -9.84637
trainer/Q2 Predictions Min       -107.707
trainer/Q Targets Mean            -33.6951
trainer/Q Targets Std              27.2924
trainer/Q Targets Max              -0.443297
trainer/Q Targets Min            -108.479
trainer/Log Pis Mean                2.03048
trainer/Log Pis Std                 1.35113
trainer/Log Pis Max                 7.98674
trainer/Log Pis Min                -1.22005
trainer/Policy mu Mean              0.0576623
trainer/Policy mu Std               0.86441
trainer/Policy mu Max               4.24303
trainer/Policy mu Min              -2.53738
trainer/Policy log std Mean        -1.8451
trainer/Policy log std Std          0.56943
trainer/Policy log std Max          0.0254996
trainer/Policy log std Min         -2.64997
trainer/Alpha                       0.0744526
trainer/Alpha Loss                  0.0791803
exploration/num steps total     66700
exploration/num paths total       667
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.753509
exploration/Rewards Std             1.05827
exploration/Rewards Max            -0.0100801
exploration/Rewards Min            -7.73933
exploration/Returns Mean          -75.3509
exploration/Returns Std            62.575
exploration/Returns Max           -34.4354
exploration/Returns Min          -199.757
exploration/Actions Mean           -0.00402371
exploration/Actions Std             0.226281
exploration/Actions Max             0.995581
exploration/Actions Min            -0.998137
exploration/Num Paths               5
exploration/Average Returns       -75.3509
evaluation/num steps total     199500
evaluation/num paths total       1995
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.587154
evaluation/Rewards Std              1.05272
evaluation/Rewards Max             -0.0398892
evaluation/Rewards Min             -9.41519
evaluation/Returns Mean           -58.7154
evaluation/Returns Std             55.9731
evaluation/Returns Max            -16.4678
evaluation/Returns Min           -192.009
evaluation/Actions Mean             0.00456904
evaluation/Actions Std              0.185263
evaluation/Actions Max              0.999137
evaluation/Actions Min             -0.997389
evaluation/Num Paths               15
evaluation/Average Returns        -58.7154
time/data storing (s)               0.00296787
time/evaluation sampling (s)        0.327631
time/exploration sampling (s)       0.141205
time/logging (s)                    0.0048856
time/saving (s)                     0.00198721
time/training (s)                   1.95471
time/epoch (s)                      2.43339
time/total (s)                    327.923
Epoch                             132
-----------------------------  ---------------
2019-04-22 23:32:44.232092 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 133 finished
-----------------------------  ---------------
replay_buffer/size              67200
trainer/QF1 Loss                    0.78447
trainer/QF2 Loss                    0.76477
trainer/Policy Loss                37.1727
trainer/Q1 Predictions Mean       -35.7919
trainer/Q1 Predictions Std         27.5645
trainer/Q1 Predictions Max        -10.0493
trainer/Q1 Predictions Min       -141.973
trainer/Q2 Predictions Mean       -35.815
trainer/Q2 Predictions Std         27.5797
trainer/Q2 Predictions Max        -10.1374
trainer/Q2 Predictions Min       -142.3
trainer/Q Targets Mean            -36.4229
trainer/Q Targets Std              27.9977
trainer/Q Targets Max             -10.5358
trainer/Q Targets Min            -144.437
trainer/Log Pis Mean                2.06878
trainer/Log Pis Std                 1.45597
trainer/Log Pis Max                 6.61416
trainer/Log Pis Min                -2.91447
trainer/Policy mu Mean              0.0856221
trainer/Policy mu Std               0.879247
trainer/Policy mu Max               3.18497
trainer/Policy mu Min              -3.04713
trainer/Policy log std Mean        -1.95555
trainer/Policy log std Std          0.600603
trainer/Policy log std Max         -0.281663
trainer/Policy log std Min         -2.78216
trainer/Alpha                       0.0727325
trainer/Alpha Loss                  0.180263
exploration/num steps total     67200
exploration/num paths total       672
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.446161
exploration/Rewards Std             0.440113
exploration/Rewards Max            -0.0118394
exploration/Rewards Min            -5.14721
exploration/Returns Mean          -44.6161
exploration/Returns Std            13.1052
exploration/Returns Max           -28.8971
exploration/Returns Min           -61.324
exploration/Actions Mean            0.0187427
exploration/Actions Std             0.181044
exploration/Actions Max             0.9945
exploration/Actions Min            -0.972717
exploration/Num Paths               5
exploration/Average Returns       -44.6161
evaluation/num steps total     201000
evaluation/num paths total       2010
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.910641
evaluation/Rewards Std              1.11663
evaluation/Rewards Max             -0.0312619
evaluation/Rewards Min             -9.21738
evaluation/Returns Mean           -91.0641
evaluation/Returns Std             80.2386
evaluation/Returns Max             -9.8833
evaluation/Returns Min           -205.809
evaluation/Actions Mean            -0.0100282
evaluation/Actions Std              0.182873
evaluation/Actions Max              0.997524
evaluation/Actions Min             -0.996967
evaluation/Num Paths               15
evaluation/Average Returns        -91.0641
time/data storing (s)               0.00295579
time/evaluation sampling (s)        0.335373
time/exploration sampling (s)       0.140179
time/logging (s)                    0.00492131
time/saving (s)                     0.00199387
time/training (s)                   1.98485
time/epoch (s)                      2.47027
time/total (s)                    330.397
Epoch                             133
-----------------------------  ---------------
2019-04-22 23:32:46.728968 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 134 finished
-----------------------------  ---------------
replay_buffer/size              67700
trainer/QF1 Loss                    0.229769
trainer/QF2 Loss                    0.203747
trainer/Policy Loss                36.0666
trainer/Q1 Predictions Mean       -34.718
trainer/Q1 Predictions Std         25.7538
trainer/Q1 Predictions Max        -10.2623
trainer/Q1 Predictions Min        -97.5162
trainer/Q2 Predictions Mean       -34.7468
trainer/Q2 Predictions Std         25.7882
trainer/Q2 Predictions Max        -10.2455
trainer/Q2 Predictions Min        -97.7022
trainer/Q Targets Mean            -34.9658
trainer/Q Targets Std              25.9373
trainer/Q Targets Max             -10.4402
trainer/Q Targets Min             -98.9636
trainer/Log Pis Mean                1.92327
trainer/Log Pis Std                 1.62111
trainer/Log Pis Max                 9.41341
trainer/Log Pis Min                -5.02342
trainer/Policy mu Mean              0.130107
trainer/Policy mu Std               0.864046
trainer/Policy mu Max               3.81943
trainer/Policy mu Min              -2.78601
trainer/Policy log std Mean        -1.88139
trainer/Policy log std Std          0.530258
trainer/Policy log std Max         -0.127641
trainer/Policy log std Min         -2.6259
trainer/Alpha                       0.0706288
trainer/Alpha Loss                 -0.203353
exploration/num steps total     67700
exploration/num paths total       677
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.515972
exploration/Rewards Std             0.772825
exploration/Rewards Max            -0.0154115
exploration/Rewards Min            -8.50699
exploration/Returns Mean          -51.5972
exploration/Returns Std             9.60556
exploration/Returns Max           -37.4801
exploration/Returns Min           -63.898
exploration/Actions Mean            0.0020231
exploration/Actions Std             0.206449
exploration/Actions Max             0.994344
exploration/Actions Min            -0.998556
exploration/Num Paths               5
exploration/Average Returns       -51.5972
evaluation/num steps total     202500
evaluation/num paths total       2025
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.717878
evaluation/Rewards Std              1.02073
evaluation/Rewards Max             -0.0348583
evaluation/Rewards Min             -9.67741
evaluation/Returns Mean           -71.7878
evaluation/Returns Std             58.0635
evaluation/Returns Max             -6.18261
evaluation/Returns Min           -210.317
evaluation/Actions Mean             0.00507208
evaluation/Actions Std              0.192284
evaluation/Actions Max              0.997659
evaluation/Actions Min             -0.997036
evaluation/Num Paths               15
evaluation/Average Returns        -71.7878
time/data storing (s)               0.00284091
time/evaluation sampling (s)        0.328579
time/exploration sampling (s)       0.142428
time/logging (s)                    0.00484821
time/saving (s)                     0.00190965
time/training (s)                   2.00899
time/epoch (s)                      2.48959
time/total (s)                    332.891
Epoch                             134
-----------------------------  ---------------
2019-04-22 23:32:49.162633 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 135 finished
-----------------------------  ---------------
replay_buffer/size              68200
trainer/QF1 Loss                    0.382919
trainer/QF2 Loss                    0.330071
trainer/Policy Loss                35.8662
trainer/Q1 Predictions Mean       -34.5512
trainer/Q1 Predictions Std         26.1373
trainer/Q1 Predictions Max        -10.5074
trainer/Q1 Predictions Min        -97.5932
trainer/Q2 Predictions Mean       -34.5133
trainer/Q2 Predictions Std         26.1679
trainer/Q2 Predictions Max        -10.4628
trainer/Q2 Predictions Min        -98.2379
trainer/Q Targets Mean            -34.8267
trainer/Q Targets Std              26.4956
trainer/Q Targets Max             -10.2486
trainer/Q Targets Min             -99.3208
trainer/Log Pis Mean                2.00936
trainer/Log Pis Std                 1.38287
trainer/Log Pis Max                 8.3168
trainer/Log Pis Min                -2.21352
trainer/Policy mu Mean              0.12244
trainer/Policy mu Std               0.894505
trainer/Policy mu Max               3.85938
trainer/Policy mu Min              -2.57174
trainer/Policy log std Mean        -1.87121
trainer/Policy log std Std          0.578785
trainer/Policy log std Max         -0.273178
trainer/Policy log std Min         -2.58955
trainer/Alpha                       0.0702545
trainer/Alpha Loss                  0.0248519
exploration/num steps total     68200
exploration/num paths total       682
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.574284
exploration/Rewards Std             0.828375
exploration/Rewards Max            -0.00558724
exploration/Rewards Min            -5.55415
exploration/Returns Mean          -57.4284
exploration/Returns Std            66.6881
exploration/Returns Max           -17.698
exploration/Returns Min          -190.446
exploration/Actions Mean           -0.00888799
exploration/Actions Std             0.200189
exploration/Actions Max             0.98758
exploration/Actions Min            -0.997703
exploration/Num Paths               5
exploration/Average Returns       -57.4284
evaluation/num steps total     204000
evaluation/num paths total       2040
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.679251
evaluation/Rewards Std              1.10722
evaluation/Rewards Max             -0.0210134
evaluation/Rewards Min            -10.3249
evaluation/Returns Mean           -67.9251
evaluation/Returns Std             66.9699
evaluation/Returns Max            -11.3281
evaluation/Returns Min           -204.79
evaluation/Actions Mean             0.00748561
evaluation/Actions Std              0.184416
evaluation/Actions Max              0.999167
evaluation/Actions Min             -0.998018
evaluation/Num Paths               15
evaluation/Average Returns        -67.9251
time/data storing (s)               0.00286945
time/evaluation sampling (s)        0.328961
time/exploration sampling (s)       0.140539
time/logging (s)                    0.00479327
time/saving (s)                     0.00195118
time/training (s)                   1.94854
time/epoch (s)                      2.42765
time/total (s)                    335.324
Epoch                             135
-----------------------------  ---------------
2019-04-22 23:32:51.583747 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 136 finished
-----------------------------  ---------------
replay_buffer/size              68700
trainer/QF1 Loss                    8.35923
trainer/QF2 Loss                    8.35622
trainer/Policy Loss                36.962
trainer/Q1 Predictions Mean       -35.4869
trainer/Q1 Predictions Std         25.8568
trainer/Q1 Predictions Max        -10.3972
trainer/Q1 Predictions Min       -103.586
trainer/Q2 Predictions Mean       -35.4928
trainer/Q2 Predictions Std         25.8834
trainer/Q2 Predictions Max        -10.4534
trainer/Q2 Predictions Min       -104.273
trainer/Q Targets Mean            -35.5812
trainer/Q Targets Std              26.1961
trainer/Q Targets Max              -0.758137
trainer/Q Targets Min            -102.749
trainer/Log Pis Mean                1.98861
trainer/Log Pis Std                 1.52066
trainer/Log Pis Max                 8.08455
trainer/Log Pis Min                -1.64893
trainer/Policy mu Mean              0.0289018
trainer/Policy mu Std               0.822607
trainer/Policy mu Max               3.43538
trainer/Policy mu Min              -2.8164
trainer/Policy log std Mean        -1.96116
trainer/Policy log std Std          0.542413
trainer/Policy log std Max         -0.237458
trainer/Policy log std Min         -2.68621
trainer/Alpha                       0.0700064
trainer/Alpha Loss                 -0.0302971
exploration/num steps total     68700
exploration/num paths total       687
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.10748
exploration/Rewards Std             1.07663
exploration/Rewards Max            -0.0250159
exploration/Rewards Min            -9.03448
exploration/Returns Mean         -110.748
exploration/Returns Std            69.9545
exploration/Returns Max           -25.1873
exploration/Returns Min          -206.115
exploration/Actions Mean           -0.0124614
exploration/Actions Std             0.227425
exploration/Actions Max             0.999225
exploration/Actions Min            -0.997755
exploration/Num Paths               5
exploration/Average Returns      -110.748
evaluation/num steps total     205500
evaluation/num paths total       2055
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.622441
evaluation/Rewards Std              0.972185
evaluation/Rewards Max             -0.0388773
evaluation/Rewards Min            -10.7423
evaluation/Returns Mean           -62.2441
evaluation/Returns Std             34.9062
evaluation/Returns Max            -21.8953
evaluation/Returns Min           -174.696
evaluation/Actions Mean             0.0125349
evaluation/Actions Std              0.186187
evaluation/Actions Max              0.999266
evaluation/Actions Min             -0.997271
evaluation/Num Paths               15
evaluation/Average Returns        -62.2441
time/data storing (s)               0.00294398
time/evaluation sampling (s)        0.322751
time/exploration sampling (s)       0.143221
time/logging (s)                    0.00484762
time/saving (s)                     0.00195164
time/training (s)                   1.93851
time/epoch (s)                      2.41422
time/total (s)                    337.742
Epoch                             136
-----------------------------  ---------------
2019-04-22 23:32:54.011851 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 137 finished
-----------------------------  ---------------
replay_buffer/size              69200
trainer/QF1 Loss                   33.084
trainer/QF2 Loss                   33.0104
trainer/Policy Loss                37.4
trainer/Q1 Predictions Mean       -36.108
trainer/Q1 Predictions Std         25.5027
trainer/Q1 Predictions Max        -10.0224
trainer/Q1 Predictions Min        -97.8092
trainer/Q2 Predictions Mean       -36.1034
trainer/Q2 Predictions Std         25.4758
trainer/Q2 Predictions Max        -10.1509
trainer/Q2 Predictions Min        -97.9288
trainer/Q Targets Mean            -35.4521
trainer/Q Targets Std              26.4795
trainer/Q Targets Max              -0.828025
trainer/Q Targets Min             -99.4309
trainer/Log Pis Mean                1.98988
trainer/Log Pis Std                 1.32929
trainer/Log Pis Max                 6.02576
trainer/Log Pis Min                -1.38132
trainer/Policy mu Mean              0.100213
trainer/Policy mu Std               0.877874
trainer/Policy mu Max               3.6598
trainer/Policy mu Min              -2.67877
trainer/Policy log std Mean        -1.89801
trainer/Policy log std Std          0.602772
trainer/Policy log std Max         -0.114787
trainer/Policy log std Min         -2.66619
trainer/Alpha                       0.0702132
trainer/Alpha Loss                 -0.0268738
exploration/num steps total     69200
exploration/num paths total       692
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.11315
exploration/Rewards Std             1.15441
exploration/Rewards Max            -0.0403186
exploration/Rewards Min            -8.82663
exploration/Returns Mean         -111.315
exploration/Returns Std            57.5931
exploration/Returns Max           -57.5987
exploration/Returns Min          -182.607
exploration/Actions Mean            0.0220524
exploration/Actions Std             0.225338
exploration/Actions Max             0.999898
exploration/Actions Min            -0.997408
exploration/Num Paths               5
exploration/Average Returns      -111.315
evaluation/num steps total     207000
evaluation/num paths total       2070
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.765292
evaluation/Rewards Std              1.0776
evaluation/Rewards Max             -0.0226589
evaluation/Rewards Min             -9.92876
evaluation/Returns Mean           -76.5292
evaluation/Returns Std             69.5759
evaluation/Returns Max            -15.3032
evaluation/Returns Min           -212.395
evaluation/Actions Mean            -0.00974132
evaluation/Actions Std              0.179687
evaluation/Actions Max              0.995332
evaluation/Actions Min             -0.997317
evaluation/Num Paths               15
evaluation/Average Returns        -76.5292
time/data storing (s)               0.00285856
time/evaluation sampling (s)        0.329643
time/exploration sampling (s)       0.141738
time/logging (s)                    0.00472994
time/saving (s)                     0.00195062
time/training (s)                   1.94004
time/epoch (s)                      2.42096
time/total (s)                    340.168
Epoch                             137
-----------------------------  ---------------
2019-04-22 23:32:56.443136 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 138 finished
-----------------------------  ----------------
replay_buffer/size              69700
trainer/QF1 Loss                    9.26438
trainer/QF2 Loss                    9.31199
trainer/Policy Loss                32.9055
trainer/Q1 Predictions Mean       -31.5297
trainer/Q1 Predictions Std         25.2079
trainer/Q1 Predictions Max        -10.218
trainer/Q1 Predictions Min        -98.6481
trainer/Q2 Predictions Mean       -31.5392
trainer/Q2 Predictions Std         25.2035
trainer/Q2 Predictions Max        -10.2494
trainer/Q2 Predictions Min        -98.7651
trainer/Q Targets Mean            -31.3974
trainer/Q Targets Std              25.6624
trainer/Q Targets Max              -0.464874
trainer/Q Targets Min             -99.7302
trainer/Log Pis Mean                1.79458
trainer/Log Pis Std                 1.16874
trainer/Log Pis Max                 4.25056
trainer/Log Pis Min                -3.20288
trainer/Policy mu Mean              0.00772884
trainer/Policy mu Std               0.765747
trainer/Policy mu Max               3.1336
trainer/Policy mu Min              -2.51894
trainer/Policy log std Mean        -1.94114
trainer/Policy log std Std          0.529858
trainer/Policy log std Max         -0.236973
trainer/Policy log std Min         -2.6746
trainer/Alpha                       0.072071
trainer/Alpha Loss                 -0.54027
exploration/num steps total     69700
exploration/num paths total       697
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.426412
exploration/Rewards Std             0.991772
exploration/Rewards Max            -0.0112438
exploration/Rewards Min            -8.60363
exploration/Returns Mean          -42.6412
exploration/Returns Std             4.86118
exploration/Returns Max           -34.1368
exploration/Returns Min           -47.7629
exploration/Actions Mean           -0.000784376
exploration/Actions Std             0.241721
exploration/Actions Max             0.999138
exploration/Actions Min            -0.998269
exploration/Num Paths               5
exploration/Average Returns       -42.6412
evaluation/num steps total     208500
evaluation/num paths total       2085
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.717519
evaluation/Rewards Std              1.11885
evaluation/Rewards Max             -0.00261702
evaluation/Rewards Min             -9.83173
evaluation/Returns Mean           -71.7519
evaluation/Returns Std             61.548
evaluation/Returns Max             -6.878
evaluation/Returns Min           -205.679
evaluation/Actions Mean             0.00190389
evaluation/Actions Std              0.186992
evaluation/Actions Max              0.99953
evaluation/Actions Min             -0.997901
evaluation/Num Paths               15
evaluation/Average Returns        -71.7519
time/data storing (s)               0.0028708
time/evaluation sampling (s)        0.327323
time/exploration sampling (s)       0.140939
time/logging (s)                    0.00489184
time/saving (s)                     0.00200115
time/training (s)                   1.94637
time/epoch (s)                      2.4244
time/total (s)                    342.597
Epoch                             138
-----------------------------  ----------------
2019-04-22 23:32:58.863703 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 139 finished
-----------------------------  ---------------
replay_buffer/size              70200
trainer/QF1 Loss                    9.00781
trainer/QF2 Loss                    8.86726
trainer/Policy Loss                33.8185
trainer/Q1 Predictions Mean       -32.5333
trainer/Q1 Predictions Std         26.8532
trainer/Q1 Predictions Max         -9.98168
trainer/Q1 Predictions Min        -98.7516
trainer/Q2 Predictions Mean       -32.5614
trainer/Q2 Predictions Std         26.8957
trainer/Q2 Predictions Max         -9.95435
trainer/Q2 Predictions Min        -98.8267
trainer/Q Targets Mean            -32.7327
trainer/Q Targets Std              27.4452
trainer/Q Targets Max              -1.03519
trainer/Q Targets Min            -100.679
trainer/Log Pis Mean                1.80879
trainer/Log Pis Std                 1.23573
trainer/Log Pis Max                 7.50641
trainer/Log Pis Min                -2.98266
trainer/Policy mu Mean              0.040996
trainer/Policy mu Std               0.679812
trainer/Policy mu Max               3.34299
trainer/Policy mu Min              -2.58968
trainer/Policy log std Mean        -1.9858
trainer/Policy log std Std          0.475335
trainer/Policy log std Max         -0.333195
trainer/Policy log std Min         -2.71598
trainer/Alpha                       0.072245
trainer/Alpha Loss                 -0.502425
exploration/num steps total     70200
exploration/num paths total       702
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.794212
exploration/Rewards Std             1.28916
exploration/Rewards Max            -0.0150355
exploration/Rewards Min            -9.64472
exploration/Returns Mean          -79.4212
exploration/Returns Std            71.3496
exploration/Returns Max           -33.8723
exploration/Returns Min          -219.297
exploration/Actions Mean           -0.0160085
exploration/Actions Std             0.22287
exploration/Actions Max             0.993841
exploration/Actions Min            -0.999401
exploration/Num Paths               5
exploration/Average Returns       -79.4212
evaluation/num steps total     210000
evaluation/num paths total       2100
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.494856
evaluation/Rewards Std              0.90721
evaluation/Rewards Max             -0.0271001
evaluation/Rewards Min             -9.81778
evaluation/Returns Mean           -49.4856
evaluation/Returns Std             51.5839
evaluation/Returns Max            -10.5194
evaluation/Returns Min           -224.965
evaluation/Actions Mean             0.00482031
evaluation/Actions Std              0.170761
evaluation/Actions Max              0.999301
evaluation/Actions Min             -0.997243
evaluation/Num Paths               15
evaluation/Average Returns        -49.4856
time/data storing (s)               0.00288803
time/evaluation sampling (s)        0.331252
time/exploration sampling (s)       0.142757
time/logging (s)                    0.00473527
time/saving (s)                     0.00198554
time/training (s)                   1.92975
time/epoch (s)                      2.41337
time/total (s)                    345.015
Epoch                             139
-----------------------------  ---------------
2019-04-22 23:33:01.287982 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 140 finished
-----------------------------  ---------------
replay_buffer/size              70700
trainer/QF1 Loss                   81.981
trainer/QF2 Loss                   81.8583
trainer/Policy Loss                35.52
trainer/Q1 Predictions Mean       -34.4805
trainer/Q1 Predictions Std         27.6028
trainer/Q1 Predictions Max         -9.45773
trainer/Q1 Predictions Min       -103.048
trainer/Q2 Predictions Mean       -34.4473
trainer/Q2 Predictions Std         27.6181
trainer/Q2 Predictions Max         -9.41823
trainer/Q2 Predictions Min       -103.185
trainer/Q Targets Mean            -34.2754
trainer/Q Targets Std              27.777
trainer/Q Targets Max              -2.08721
trainer/Q Targets Min            -105.482
trainer/Log Pis Mean                1.91514
trainer/Log Pis Std                 1.47446
trainer/Log Pis Max                 7.37114
trainer/Log Pis Min                -3.6464
trainer/Policy mu Mean              0.0293478
trainer/Policy mu Std               0.858319
trainer/Policy mu Max               2.76182
trainer/Policy mu Min              -2.83178
trainer/Policy log std Mean        -1.87753
trainer/Policy log std Std          0.569997
trainer/Policy log std Max         -0.408501
trainer/Policy log std Min         -2.76976
trainer/Alpha                       0.0721415
trainer/Alpha Loss                 -0.22311
exploration/num steps total     70700
exploration/num paths total       707
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.819226
exploration/Rewards Std             1.33744
exploration/Rewards Max            -0.0102899
exploration/Rewards Min           -10.9666
exploration/Returns Mean          -81.9226
exploration/Returns Std            53.6242
exploration/Returns Max           -42.5916
exploration/Returns Min          -188.074
exploration/Actions Mean           -0.00684327
exploration/Actions Std             0.243422
exploration/Actions Max             0.980819
exploration/Actions Min            -0.999328
exploration/Num Paths               5
exploration/Average Returns       -81.9226
evaluation/num steps total     211500
evaluation/num paths total       2115
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.420636
evaluation/Rewards Std              0.763847
evaluation/Rewards Max             -0.0364397
evaluation/Rewards Min             -7.12666
evaluation/Returns Mean           -42.0636
evaluation/Returns Std             42.1696
evaluation/Returns Max             -9.51161
evaluation/Returns Min           -192.645
evaluation/Actions Mean             0.00559955
evaluation/Actions Std              0.163472
evaluation/Actions Max              0.997914
evaluation/Actions Min             -0.992779
evaluation/Num Paths               15
evaluation/Average Returns        -42.0636
time/data storing (s)               0.00284863
time/evaluation sampling (s)        0.329025
time/exploration sampling (s)       0.139804
time/logging (s)                    0.00424275
time/saving (s)                     0.00197158
time/training (s)                   1.93888
time/epoch (s)                      2.41677
time/total (s)                    347.436
Epoch                             140
-----------------------------  ---------------
2019-04-22 23:33:03.709269 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 141 finished
-----------------------------  ----------------
replay_buffer/size              71200
trainer/QF1 Loss                  149.454
trainer/QF2 Loss                  149.965
trainer/Policy Loss                34.4942
trainer/Q1 Predictions Mean       -33.1482
trainer/Q1 Predictions Std         27.1273
trainer/Q1 Predictions Max        -10.1132
trainer/Q1 Predictions Min       -125.917
trainer/Q2 Predictions Mean       -33.1741
trainer/Q2 Predictions Std         27.1582
trainer/Q2 Predictions Max        -10.047
trainer/Q2 Predictions Min       -126.058
trainer/Q Targets Mean            -31.7522
trainer/Q Targets Std              25.9945
trainer/Q Targets Max              -0.49218
trainer/Q Targets Min            -100.152
trainer/Log Pis Mean                2.00973
trainer/Log Pis Std                 1.41611
trainer/Log Pis Max                 6.40207
trainer/Log Pis Min                -3.69837
trainer/Policy mu Mean              0.000100291
trainer/Policy mu Std               0.724645
trainer/Policy mu Max               2.43575
trainer/Policy mu Min              -2.91791
trainer/Policy log std Mean        -2.03375
trainer/Policy log std Std          0.506824
trainer/Policy log std Max         -0.445013
trainer/Policy log std Min         -2.78941
trainer/Alpha                       0.0726478
trainer/Alpha Loss                  0.0255184
exploration/num steps total     71200
exploration/num paths total       712
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.527038
exploration/Rewards Std             1.18307
exploration/Rewards Max            -0.0181446
exploration/Rewards Min           -10.4473
exploration/Returns Mean          -52.7038
exploration/Returns Std            26.8485
exploration/Returns Max           -21.4202
exploration/Returns Min           -95.7341
exploration/Actions Mean            0.02001
exploration/Actions Std             0.226463
exploration/Actions Max             0.999959
exploration/Actions Min            -0.99732
exploration/Num Paths               5
exploration/Average Returns       -52.7038
evaluation/num steps total     213000
evaluation/num paths total       2130
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.457631
evaluation/Rewards Std              1.05605
evaluation/Rewards Max             -0.0196018
evaluation/Rewards Min            -10.2344
evaluation/Returns Mean           -45.7631
evaluation/Returns Std             50.7878
evaluation/Returns Max            -10.2643
evaluation/Returns Min           -225.348
evaluation/Actions Mean            -0.00937562
evaluation/Actions Std              0.191402
evaluation/Actions Max              0.999456
evaluation/Actions Min             -0.998247
evaluation/Num Paths               15
evaluation/Average Returns        -45.7631
time/data storing (s)               0.00290816
time/evaluation sampling (s)        0.323987
time/exploration sampling (s)       0.139452
time/logging (s)                    0.00486396
time/saving (s)                     0.00196612
time/training (s)                   1.94202
time/epoch (s)                      2.41519
time/total (s)                    349.856
Epoch                             141
-----------------------------  ----------------
2019-04-22 23:33:06.108087 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 142 finished
-----------------------------  ---------------
replay_buffer/size              71700
trainer/QF1 Loss                   30.032
trainer/QF2 Loss                   30.1446
trainer/Policy Loss                37.5308
trainer/Q1 Predictions Mean       -36.2294
trainer/Q1 Predictions Std         29.5049
trainer/Q1 Predictions Max        -10.2949
trainer/Q1 Predictions Min        -98.104
trainer/Q2 Predictions Mean       -36.2734
trainer/Q2 Predictions Std         29.4964
trainer/Q2 Predictions Max        -10.3586
trainer/Q2 Predictions Min        -98.5048
trainer/Q Targets Mean            -35.2626
trainer/Q Targets Std              30.3835
trainer/Q Targets Max              -0.125783
trainer/Q Targets Min             -98.81
trainer/Log Pis Mean                1.80756
trainer/Log Pis Std                 1.32839
trainer/Log Pis Max                 6.34684
trainer/Log Pis Min                -5.60119
trainer/Policy mu Mean              0.112588
trainer/Policy mu Std               0.648037
trainer/Policy mu Max               2.8124
trainer/Policy mu Min              -2.32941
trainer/Policy log std Mean        -2.02563
trainer/Policy log std Std          0.495501
trainer/Policy log std Max         -0.374395
trainer/Policy log std Min         -2.77677
trainer/Alpha                       0.0722433
trainer/Alpha Loss                 -0.505652
exploration/num steps total     71700
exploration/num paths total       717
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.90387
exploration/Rewards Std             1.23198
exploration/Rewards Max            -0.0315451
exploration/Rewards Min            -9.00731
exploration/Returns Mean          -90.387
exploration/Returns Std            62.6779
exploration/Returns Max           -37.8313
exploration/Returns Min          -209.376
exploration/Actions Mean            0.00473869
exploration/Actions Std             0.241376
exploration/Actions Max             0.998911
exploration/Actions Min            -0.998312
exploration/Num Paths               5
exploration/Average Returns       -90.387
evaluation/num steps total     214500
evaluation/num paths total       2145
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.659615
evaluation/Rewards Std              0.905186
evaluation/Rewards Max             -0.0618137
evaluation/Rewards Min             -8.30102
evaluation/Returns Mean           -65.9615
evaluation/Returns Std             66.6803
evaluation/Returns Max            -13.4694
evaluation/Returns Min           -208.186
evaluation/Actions Mean            -0.00986493
evaluation/Actions Std              0.163149
evaluation/Actions Max              0.997942
evaluation/Actions Min             -0.996991
evaluation/Num Paths               15
evaluation/Average Returns        -65.9615
time/data storing (s)               0.00288797
time/evaluation sampling (s)        0.333524
time/exploration sampling (s)       0.139725
time/logging (s)                    0.00482565
time/saving (s)                     0.00192851
time/training (s)                   1.90876
time/epoch (s)                      2.39165
time/total (s)                    352.252
Epoch                             142
-----------------------------  ---------------
2019-04-22 23:33:08.500818 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 143 finished
-----------------------------  ---------------
replay_buffer/size              72200
trainer/QF1 Loss                    8.66423
trainer/QF2 Loss                    8.52902
trainer/Policy Loss                35.7296
trainer/Q1 Predictions Mean       -34.5275
trainer/Q1 Predictions Std         30.0955
trainer/Q1 Predictions Max         -9.98754
trainer/Q1 Predictions Min       -139.502
trainer/Q2 Predictions Mean       -34.4789
trainer/Q2 Predictions Std         30.0398
trainer/Q2 Predictions Max         -9.95678
trainer/Q2 Predictions Min       -138.054
trainer/Q Targets Mean            -34.3054
trainer/Q Targets Std              30.3742
trainer/Q Targets Max              -0.876611
trainer/Q Targets Min            -140.054
trainer/Log Pis Mean                1.99095
trainer/Log Pis Std                 1.17259
trainer/Log Pis Max                 5.33137
trainer/Log Pis Min                -1.6741
trainer/Policy mu Mean             -0.0106328
trainer/Policy mu Std               0.865734
trainer/Policy mu Max               2.59926
trainer/Policy mu Min              -3.49246
trainer/Policy log std Mean        -1.92617
trainer/Policy log std Std          0.568133
trainer/Policy log std Max         -0.0780977
trainer/Policy log std Min         -2.7091
trainer/Alpha                       0.0712522
trainer/Alpha Loss                 -0.0239022
exploration/num steps total     72200
exploration/num paths total       722
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.208362
exploration/Rewards Std             0.332671
exploration/Rewards Max            -0.0159129
exploration/Rewards Min            -4.63076
exploration/Returns Mean          -20.8362
exploration/Returns Std             6.66714
exploration/Returns Max           -12.9428
exploration/Returns Min           -32.8828
exploration/Actions Mean            0.00161088
exploration/Actions Std             0.16038
exploration/Actions Max             0.993091
exploration/Actions Min            -0.963637
exploration/Num Paths               5
exploration/Average Returns       -20.8362
evaluation/num steps total     216000
evaluation/num paths total       2160
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.923488
evaluation/Rewards Std              0.864387
evaluation/Rewards Max             -0.0318906
evaluation/Rewards Min             -7.3978
evaluation/Returns Mean           -92.3488
evaluation/Returns Std             68.0883
evaluation/Returns Max            -12.0431
evaluation/Returns Min           -192.388
evaluation/Actions Mean             0.00420256
evaluation/Actions Std              0.154263
evaluation/Actions Max              0.996871
evaluation/Actions Min             -0.988426
evaluation/Num Paths               15
evaluation/Average Returns        -92.3488
time/data storing (s)               0.00291168
time/evaluation sampling (s)        0.329431
time/exploration sampling (s)       0.139644
time/logging (s)                    0.00481074
time/saving (s)                     0.00195031
time/training (s)                   1.90816
time/epoch (s)                      2.38691
time/total (s)                    354.642
Epoch                             143
-----------------------------  ---------------
2019-04-22 23:33:10.912560 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 144 finished
-----------------------------  ----------------
replay_buffer/size              72700
trainer/QF1 Loss                  175.896
trainer/QF2 Loss                  175.462
trainer/Policy Loss                32.2951
trainer/Q1 Predictions Mean       -31.175
trainer/Q1 Predictions Std         24.784
trainer/Q1 Predictions Max         -9.86256
trainer/Q1 Predictions Min       -100.512
trainer/Q2 Predictions Mean       -31.1813
trainer/Q2 Predictions Std         24.7811
trainer/Q2 Predictions Max         -9.92986
trainer/Q2 Predictions Min       -100.781
trainer/Q Targets Mean            -29.2063
trainer/Q Targets Std              23.5055
trainer/Q Targets Max              -0.447149
trainer/Q Targets Min            -101.251
trainer/Log Pis Mean                2.02944
trainer/Log Pis Std                 1.2452
trainer/Log Pis Max                 6.8964
trainer/Log Pis Min                -1.6328
trainer/Policy mu Mean              0.118107
trainer/Policy mu Std               0.885942
trainer/Policy mu Max               2.93701
trainer/Policy mu Min              -2.93452
trainer/Policy log std Mean        -1.8875
trainer/Policy log std Std          0.621905
trainer/Policy log std Max         -0.373254
trainer/Policy log std Min         -2.81899
trainer/Alpha                       0.0712562
trainer/Alpha Loss                  0.0777546
exploration/num steps total     72700
exploration/num paths total       727
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.696084
exploration/Rewards Std             0.899748
exploration/Rewards Max            -0.030478
exploration/Rewards Min            -7.35925
exploration/Returns Mean          -69.6084
exploration/Returns Std            58.4471
exploration/Returns Max           -28.176
exploration/Returns Min          -183.305
exploration/Actions Mean            0.0105768
exploration/Actions Std             0.194092
exploration/Actions Max             0.999545
exploration/Actions Min            -0.992745
exploration/Num Paths               5
exploration/Average Returns       -69.6084
evaluation/num steps total     217500
evaluation/num paths total       2175
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.519605
evaluation/Rewards Std              1.15652
evaluation/Rewards Max             -0.0167995
evaluation/Rewards Min             -9.29119
evaluation/Returns Mean           -51.9605
evaluation/Returns Std             40.8073
evaluation/Returns Max             -7.37434
evaluation/Returns Min           -186.513
evaluation/Actions Mean             0.000463151
evaluation/Actions Std              0.207545
evaluation/Actions Max              0.999477
evaluation/Actions Min             -0.998124
evaluation/Num Paths               15
evaluation/Average Returns        -51.9605
time/data storing (s)               0.0029114
time/evaluation sampling (s)        0.333095
time/exploration sampling (s)       0.14084
time/logging (s)                    0.00484684
time/saving (s)                     0.00195952
time/training (s)                   1.92096
time/epoch (s)                      2.40462
time/total (s)                    357.052
Epoch                             144
-----------------------------  ----------------
2019-04-22 23:33:13.335427 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 145 finished
-----------------------------  ---------------
replay_buffer/size              73200
trainer/QF1 Loss                    0.115085
trainer/QF2 Loss                    0.107915
trainer/Policy Loss                32.8284
trainer/Q1 Predictions Mean       -31.3951
trainer/Q1 Predictions Std         24.8857
trainer/Q1 Predictions Max         -9.7542
trainer/Q1 Predictions Min        -94.4681
trainer/Q2 Predictions Mean       -31.4107
trainer/Q2 Predictions Std         24.8608
trainer/Q2 Predictions Max         -9.73368
trainer/Q2 Predictions Min        -94.5114
trainer/Q Targets Mean            -31.4602
trainer/Q Targets Std              24.9755
trainer/Q Targets Max              -9.63077
trainer/Q Targets Min             -95.0558
trainer/Log Pis Mean                2.01865
trainer/Log Pis Std                 1.28647
trainer/Log Pis Max                 5.9279
trainer/Log Pis Min                -2.24042
trainer/Policy mu Mean              0.0650789
trainer/Policy mu Std               0.765283
trainer/Policy mu Max               2.86227
trainer/Policy mu Min              -2.41714
trainer/Policy log std Mean        -1.9675
trainer/Policy log std Std          0.526449
trainer/Policy log std Max         -0.456739
trainer/Policy log std Min         -2.82228
trainer/Alpha                       0.0719375
trainer/Alpha Loss                  0.0491028
exploration/num steps total     73200
exploration/num paths total       732
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.569749
exploration/Rewards Std             1.07007
exploration/Rewards Max            -0.00611496
exploration/Rewards Min            -9.73233
exploration/Returns Mean          -56.9749
exploration/Returns Std            21.816
exploration/Returns Max           -20.1693
exploration/Returns Min           -88.4997
exploration/Actions Mean            0.00597797
exploration/Actions Std             0.221547
exploration/Actions Max             0.999888
exploration/Actions Min            -0.999752
exploration/Num Paths               5
exploration/Average Returns       -56.9749
evaluation/num steps total     219000
evaluation/num paths total       2190
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.465221
evaluation/Rewards Std              0.77565
evaluation/Rewards Max             -0.0180224
evaluation/Rewards Min             -9.54904
evaluation/Returns Mean           -46.5221
evaluation/Returns Std             41.8185
evaluation/Returns Max            -17.0521
evaluation/Returns Min           -190.458
evaluation/Actions Mean             0.00154687
evaluation/Actions Std              0.160748
evaluation/Actions Max              0.99855
evaluation/Actions Min             -0.995671
evaluation/Num Paths               15
evaluation/Average Returns        -46.5221
time/data storing (s)               0.00299218
time/evaluation sampling (s)        0.327999
time/exploration sampling (s)       0.14166
time/logging (s)                    0.00482877
time/saving (s)                     0.00971685
time/training (s)                   1.92856
time/epoch (s)                      2.41575
time/total (s)                    359.472
Epoch                             145
-----------------------------  ---------------
2019-04-22 23:33:15.754477 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 146 finished
-----------------------------  ---------------
replay_buffer/size              73700
trainer/QF1 Loss                   23.6765
trainer/QF2 Loss                   24.5711
trainer/Policy Loss                36.7827
trainer/Q1 Predictions Mean       -35.3697
trainer/Q1 Predictions Std         28.3967
trainer/Q1 Predictions Max         -9.8935
trainer/Q1 Predictions Min       -100.721
trainer/Q2 Predictions Mean       -35.3582
trainer/Q2 Predictions Std         28.3813
trainer/Q2 Predictions Max         -9.87796
trainer/Q2 Predictions Min       -101.141
trainer/Q Targets Mean            -34.8939
trainer/Q Targets Std              28.3685
trainer/Q Targets Max              -9.76271
trainer/Q Targets Min            -101.185
trainer/Log Pis Mean                2.02922
trainer/Log Pis Std                 1.30824
trainer/Log Pis Max                 6.33807
trainer/Log Pis Min                -2.16479
trainer/Policy mu Mean              0.0381529
trainer/Policy mu Std               0.793752
trainer/Policy mu Max               3.07295
trainer/Policy mu Min              -3.66991
trainer/Policy log std Mean        -1.97472
trainer/Policy log std Std          0.525667
trainer/Policy log std Max         -0.261622
trainer/Policy log std Min         -2.77147
trainer/Alpha                       0.0728403
trainer/Alpha Loss                  0.0765316
exploration/num steps total     73700
exploration/num paths total       737
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.662883
exploration/Rewards Std             0.974576
exploration/Rewards Max            -0.00184159
exploration/Rewards Min            -9.63097
exploration/Returns Mean          -66.2883
exploration/Returns Std            76.5345
exploration/Returns Max           -16.2631
exploration/Returns Min          -216.581
exploration/Actions Mean           -0.0167667
exploration/Actions Std             0.195731
exploration/Actions Max             0.977406
exploration/Actions Min            -0.999324
exploration/Num Paths               5
exploration/Average Returns       -66.2883
evaluation/num steps total     220500
evaluation/num paths total       2205
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.488588
evaluation/Rewards Std              1.01608
evaluation/Rewards Max             -0.0335858
evaluation/Rewards Min            -10.5232
evaluation/Returns Mean           -48.8588
evaluation/Returns Std             28.2962
evaluation/Returns Max             -8.97765
evaluation/Returns Min           -104.217
evaluation/Actions Mean             0.011518
evaluation/Actions Std              0.184252
evaluation/Actions Max              0.999028
evaluation/Actions Min             -0.997256
evaluation/Num Paths               15
evaluation/Average Returns        -48.8588
time/data storing (s)               0.0029771
time/evaluation sampling (s)        0.328358
time/exploration sampling (s)       0.140721
time/logging (s)                    0.00479995
time/saving (s)                     0.00195843
time/training (s)                   1.93302
time/epoch (s)                      2.41184
time/total (s)                    361.888
Epoch                             146
-----------------------------  ---------------
2019-04-22 23:33:18.169472 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 147 finished
-----------------------------  ---------------
replay_buffer/size              74200
trainer/QF1 Loss                   12.341
trainer/QF2 Loss                   12.4198
trainer/Policy Loss                33.6357
trainer/Q1 Predictions Mean       -32.2594
trainer/Q1 Predictions Std         26.7344
trainer/Q1 Predictions Max         -9.44824
trainer/Q1 Predictions Min        -94.3948
trainer/Q2 Predictions Mean       -32.2378
trainer/Q2 Predictions Std         26.733
trainer/Q2 Predictions Max         -9.40974
trainer/Q2 Predictions Min        -94.2612
trainer/Q Targets Mean            -32.251
trainer/Q Targets Std              27.4568
trainer/Q Targets Max              -0.115564
trainer/Q Targets Min             -95.41
trainer/Log Pis Mean                1.7305
trainer/Log Pis Std                 1.38153
trainer/Log Pis Max                 5.27642
trainer/Log Pis Min                -2.78476
trainer/Policy mu Mean              0.0900033
trainer/Policy mu Std               0.617101
trainer/Policy mu Max               2.56826
trainer/Policy mu Min              -2.82293
trainer/Policy log std Mean        -2.07807
trainer/Policy log std Std          0.458969
trainer/Policy log std Max         -0.40372
trainer/Policy log std Min         -2.81285
trainer/Alpha                       0.0732521
trainer/Alpha Loss                 -0.704462
exploration/num steps total     74200
exploration/num paths total       742
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.980221
exploration/Rewards Std             1.42014
exploration/Rewards Max            -0.0318395
exploration/Rewards Min           -10.8778
exploration/Returns Mean          -98.0221
exploration/Returns Std            51.8504
exploration/Returns Max           -57.3439
exploration/Returns Min          -198.503
exploration/Actions Mean           -0.0039839
exploration/Actions Std             0.262836
exploration/Actions Max             0.998886
exploration/Actions Min            -0.999628
exploration/Num Paths               5
exploration/Average Returns       -98.0221
evaluation/num steps total     222000
evaluation/num paths total       2220
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.573931
evaluation/Rewards Std              1.0329
evaluation/Rewards Max             -0.0465246
evaluation/Rewards Min            -10.244
evaluation/Returns Mean           -57.3931
evaluation/Returns Std             57.6889
evaluation/Returns Max             -4.79536
evaluation/Returns Min           -198.565
evaluation/Actions Mean             0.0026662
evaluation/Actions Std              0.172575
evaluation/Actions Max              0.999671
evaluation/Actions Min             -0.99529
evaluation/Num Paths               15
evaluation/Average Returns        -57.3931
time/data storing (s)               0.00292306
time/evaluation sampling (s)        0.329155
time/exploration sampling (s)       0.139281
time/logging (s)                    0.00464499
time/saving (s)                     0.00194124
time/training (s)                   1.92967
time/epoch (s)                      2.40761
time/total (s)                    364.3
Epoch                             147
-----------------------------  ---------------
2019-04-22 23:33:20.562955 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 148 finished
-----------------------------  ---------------
replay_buffer/size              74700
trainer/QF1 Loss                    1.64428
trainer/QF2 Loss                    1.64157
trainer/Policy Loss                38.1543
trainer/Q1 Predictions Mean       -36.876
trainer/Q1 Predictions Std         31.4832
trainer/Q1 Predictions Max         -9.36078
trainer/Q1 Predictions Min       -131.059
trainer/Q2 Predictions Mean       -36.8357
trainer/Q2 Predictions Std         31.4341
trainer/Q2 Predictions Max         -9.24594
trainer/Q2 Predictions Min       -131.102
trainer/Q Targets Mean            -37.5952
trainer/Q Targets Std              32.2758
trainer/Q Targets Max              -9.76695
trainer/Q Targets Min            -133.261
trainer/Log Pis Mean                2.23534
trainer/Log Pis Std                 1.40471
trainer/Log Pis Max                 7.25565
trainer/Log Pis Min                -0.294721
trainer/Policy mu Mean             -0.0601675
trainer/Policy mu Std               0.896687
trainer/Policy mu Max               2.63141
trainer/Policy mu Min              -2.9913
trainer/Policy log std Mean        -1.94481
trainer/Policy log std Std          0.565372
trainer/Policy log std Max         -0.364595
trainer/Policy log std Min         -2.74543
trainer/Alpha                       0.0710821
trainer/Alpha Loss                  0.622216
exploration/num steps total     74700
exploration/num paths total       747
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.740365
exploration/Rewards Std             1.22003
exploration/Rewards Max            -0.0106488
exploration/Rewards Min            -9.71588
exploration/Returns Mean          -74.0365
exploration/Returns Std            74.49
exploration/Returns Max           -18.3347
exploration/Returns Min          -215.328
exploration/Actions Mean           -0.0138984
exploration/Actions Std             0.216392
exploration/Actions Max             0.999384
exploration/Actions Min            -0.999159
exploration/Num Paths               5
exploration/Average Returns       -74.0365
evaluation/num steps total     223500
evaluation/num paths total       2235
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.706692
evaluation/Rewards Std              1.16814
evaluation/Rewards Max             -0.0131452
evaluation/Rewards Min            -11.0527
evaluation/Returns Mean           -70.6692
evaluation/Returns Std             76.5847
evaluation/Returns Max             -5.43495
evaluation/Returns Min           -230.892
evaluation/Actions Mean            -0.00540553
evaluation/Actions Std              0.184393
evaluation/Actions Max              0.999174
evaluation/Actions Min             -0.998277
evaluation/Num Paths               15
evaluation/Average Returns        -70.6692
time/data storing (s)               0.00286522
time/evaluation sampling (s)        0.329448
time/exploration sampling (s)       0.139302
time/logging (s)                    0.00476252
time/saving (s)                     0.00191501
time/training (s)                   1.90836
time/epoch (s)                      2.38665
time/total (s)                    366.691
Epoch                             148
-----------------------------  ---------------
2019-04-22 23:33:22.971908 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 149 finished
-----------------------------  ---------------
replay_buffer/size              75200
trainer/QF1 Loss                   13.2108
trainer/QF2 Loss                   13.2731
trainer/Policy Loss                31.7241
trainer/Q1 Predictions Mean       -30.5628
trainer/Q1 Predictions Std         24.9493
trainer/Q1 Predictions Max         -9.58804
trainer/Q1 Predictions Min        -95.5782
trainer/Q2 Predictions Mean       -30.5168
trainer/Q2 Predictions Std         24.9355
trainer/Q2 Predictions Max         -9.52992
trainer/Q2 Predictions Min        -95.3412
trainer/Q Targets Mean            -30.0496
trainer/Q Targets Std              25.4361
trainer/Q Targets Max              -0.563578
trainer/Q Targets Min             -95.5259
trainer/Log Pis Mean                1.90723
trainer/Log Pis Std                 1.17025
trainer/Log Pis Max                 4.77762
trainer/Log Pis Min                -1.71956
trainer/Policy mu Mean              0.07517
trainer/Policy mu Std               0.708174
trainer/Policy mu Max               2.85431
trainer/Policy mu Min              -3.40713
trainer/Policy log std Mean        -1.98337
trainer/Policy log std Std          0.497131
trainer/Policy log std Max         -0.453397
trainer/Policy log std Min         -2.76992
trainer/Alpha                       0.0723153
trainer/Alpha Loss                 -0.243662
exploration/num steps total     75200
exploration/num paths total       752
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.78189
exploration/Rewards Std             0.979356
exploration/Rewards Max            -0.0244637
exploration/Rewards Min            -7.83734
exploration/Returns Mean          -78.189
exploration/Returns Std            58.9743
exploration/Returns Max           -37.9783
exploration/Returns Min          -195.552
exploration/Actions Mean            0.0189375
exploration/Actions Std             0.207747
exploration/Actions Max             0.998365
exploration/Actions Min            -0.974609
exploration/Num Paths               5
exploration/Average Returns       -78.189
evaluation/num steps total     225000
evaluation/num paths total       2250
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.563009
evaluation/Rewards Std              0.982796
evaluation/Rewards Max             -0.0585699
evaluation/Rewards Min             -9.52079
evaluation/Returns Mean           -56.3009
evaluation/Returns Std             45.0724
evaluation/Returns Max             -7.00226
evaluation/Returns Min           -202.948
evaluation/Actions Mean             0.0182077
evaluation/Actions Std              0.168456
evaluation/Actions Max              0.99881
evaluation/Actions Min             -0.989981
evaluation/Num Paths               15
evaluation/Average Returns        -56.3009
time/data storing (s)               0.00272943
time/evaluation sampling (s)        0.328775
time/exploration sampling (s)       0.14205
time/logging (s)                    0.00480299
time/saving (s)                     0.00195477
time/training (s)                   1.92153
time/epoch (s)                      2.40184
time/total (s)                    369.098
Epoch                             149
-----------------------------  ---------------
2019-04-22 23:33:25.370691 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 150 finished
-----------------------------  ---------------
replay_buffer/size              75700
trainer/QF1 Loss                    2.62951
trainer/QF2 Loss                    2.66528
trainer/Policy Loss                33.628
trainer/Q1 Predictions Mean       -31.9641
trainer/Q1 Predictions Std         26.4439
trainer/Q1 Predictions Max         -9.20142
trainer/Q1 Predictions Min        -94.3121
trainer/Q2 Predictions Mean       -31.9769
trainer/Q2 Predictions Std         26.4454
trainer/Q2 Predictions Max         -9.19134
trainer/Q2 Predictions Min        -94.487
trainer/Q Targets Mean            -32.2226
trainer/Q Targets Std              27.1201
trainer/Q Targets Max              -0.0840329
trainer/Q Targets Min             -96.0131
trainer/Log Pis Mean                2.08845
trainer/Log Pis Std                 1.10325
trainer/Log Pis Max                 7.18268
trainer/Log Pis Min                -1.22855
trainer/Policy mu Mean              0.0238237
trainer/Policy mu Std               0.772638
trainer/Policy mu Max               3.34282
trainer/Policy mu Min              -3.17749
trainer/Policy log std Mean        -1.99412
trainer/Policy log std Std          0.535654
trainer/Policy log std Max         -0.433271
trainer/Policy log std Min         -2.66578
trainer/Alpha                       0.0729183
trainer/Alpha Loss                  0.231593
exploration/num steps total     75700
exploration/num paths total       757
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.786223
exploration/Rewards Std             0.991737
exploration/Rewards Max            -0.0103759
exploration/Rewards Min            -8.0181
exploration/Returns Mean          -78.6223
exploration/Returns Std            62.3917
exploration/Returns Max           -31.2782
exploration/Returns Min          -200.206
exploration/Actions Mean            0.00920557
exploration/Actions Std             0.238197
exploration/Actions Max             0.998598
exploration/Actions Min            -0.993675
exploration/Num Paths               5
exploration/Average Returns       -78.6223
evaluation/num steps total     226500
evaluation/num paths total       2265
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.531868
evaluation/Rewards Std              1.1069
evaluation/Rewards Max             -0.012258
evaluation/Rewards Min            -10.3287
evaluation/Returns Mean           -53.1868
evaluation/Returns Std             46.8291
evaluation/Returns Max             -7.91726
evaluation/Returns Min           -197.384
evaluation/Actions Mean             0.0134746
evaluation/Actions Std              0.18961
evaluation/Actions Max              0.999505
evaluation/Actions Min             -0.998538
evaluation/Num Paths               15
evaluation/Average Returns        -53.1868
time/data storing (s)               0.0028962
time/evaluation sampling (s)        0.32548
time/exploration sampling (s)       0.139346
time/logging (s)                    0.00478719
time/saving (s)                     0.00188286
time/training (s)                   1.91736
time/epoch (s)                      2.39175
time/total (s)                    371.494
Epoch                             150
-----------------------------  ---------------
2019-04-22 23:33:27.788630 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 151 finished
-----------------------------  ---------------
replay_buffer/size              76200
trainer/QF1 Loss                    0.19935
trainer/QF2 Loss                    0.156616
trainer/Policy Loss                32.3348
trainer/Q1 Predictions Mean       -30.9861
trainer/Q1 Predictions Std         25.4916
trainer/Q1 Predictions Max         -9.52309
trainer/Q1 Predictions Min        -96.9602
trainer/Q2 Predictions Mean       -30.9871
trainer/Q2 Predictions Std         25.4749
trainer/Q2 Predictions Max         -9.58548
trainer/Q2 Predictions Min        -97.0081
trainer/Q Targets Mean            -31.1119
trainer/Q Targets Std              25.526
trainer/Q Targets Max              -9.49405
trainer/Q Targets Min             -97.6807
trainer/Log Pis Mean                2.14215
trainer/Log Pis Std                 1.28105
trainer/Log Pis Max                 5.8021
trainer/Log Pis Min                -1.54645
trainer/Policy mu Mean             -0.0195784
trainer/Policy mu Std               0.934862
trainer/Policy mu Max               2.95056
trainer/Policy mu Min              -2.87568
trainer/Policy log std Mean        -1.87542
trainer/Policy log std Std          0.597437
trainer/Policy log std Max         -0.455007
trainer/Policy log std Min         -2.72576
trainer/Alpha                       0.0725693
trainer/Alpha Loss                  0.372889
exploration/num steps total     76200
exploration/num paths total       762
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.14415
exploration/Rewards Std             1.2975
exploration/Rewards Max            -0.00915122
exploration/Rewards Min            -9.64665
exploration/Returns Mean         -114.415
exploration/Returns Std            85.3526
exploration/Returns Max           -22.9572
exploration/Returns Min          -220.699
exploration/Actions Mean            0.00150357
exploration/Actions Std             0.244882
exploration/Actions Max             0.999706
exploration/Actions Min            -0.999416
exploration/Num Paths               5
exploration/Average Returns      -114.415
evaluation/num steps total     228000
evaluation/num paths total       2280
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.643322
evaluation/Rewards Std              1.13321
evaluation/Rewards Max             -0.0144831
evaluation/Rewards Min            -11.3847
evaluation/Returns Mean           -64.3322
evaluation/Returns Std             57.1507
evaluation/Returns Max             -6.39532
evaluation/Returns Min           -199.285
evaluation/Actions Mean            -0.00584559
evaluation/Actions Std              0.188283
evaluation/Actions Max              0.999502
evaluation/Actions Min             -0.998559
evaluation/Num Paths               15
evaluation/Average Returns        -64.3322
time/data storing (s)               0.00523612
time/evaluation sampling (s)        0.328797
time/exploration sampling (s)       0.140241
time/logging (s)                    0.00484343
time/saving (s)                     0.00193632
time/training (s)                   1.93
time/epoch (s)                      2.41106
time/total (s)                    373.909
Epoch                             151
-----------------------------  ---------------
2019-04-22 23:33:30.225986 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 152 finished
-----------------------------  ---------------
replay_buffer/size              76700
trainer/QF1 Loss                    5.85642
trainer/QF2 Loss                    5.82118
trainer/Policy Loss                33.7247
trainer/Q1 Predictions Mean       -32.2012
trainer/Q1 Predictions Std         28.4078
trainer/Q1 Predictions Max         -9.20998
trainer/Q1 Predictions Min       -103.311
trainer/Q2 Predictions Mean       -32.1542
trainer/Q2 Predictions Std         28.4171
trainer/Q2 Predictions Max         -9.1729
trainer/Q2 Predictions Min       -103.616
trainer/Q Targets Mean            -32.1988
trainer/Q Targets Std              28.7922
trainer/Q Targets Max              -1.14226
trainer/Q Targets Min            -103.856
trainer/Log Pis Mean                2.14069
trainer/Log Pis Std                 1.31428
trainer/Log Pis Max                 6.50526
trainer/Log Pis Min                -2.68564
trainer/Policy mu Mean             -0.00290379
trainer/Policy mu Std               0.75136
trainer/Policy mu Max               2.62893
trainer/Policy mu Min              -2.71072
trainer/Policy log std Mean        -2.03695
trainer/Policy log std Std          0.484543
trainer/Policy log std Max         -0.606
trainer/Policy log std Min         -2.71137
trainer/Alpha                       0.0739753
trainer/Alpha Loss                  0.366356
exploration/num steps total     76700
exploration/num paths total       767
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.516618
exploration/Rewards Std             0.997673
exploration/Rewards Max            -0.00413452
exploration/Rewards Min            -9.19284
exploration/Returns Mean          -51.6618
exploration/Returns Std            22.5081
exploration/Returns Max           -29.0963
exploration/Returns Min           -82.1425
exploration/Actions Mean           -0.00437947
exploration/Actions Std             0.224802
exploration/Actions Max             0.998207
exploration/Actions Min            -0.999013
exploration/Num Paths               5
exploration/Average Returns       -51.6618
evaluation/num steps total     229500
evaluation/num paths total       2295
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.802785
evaluation/Rewards Std              1.15771
evaluation/Rewards Max             -0.044109
evaluation/Rewards Min             -9.47974
evaluation/Returns Mean           -80.2785
evaluation/Returns Std             76.0723
evaluation/Returns Max            -10.5633
evaluation/Returns Min           -211.139
evaluation/Actions Mean             0.0105427
evaluation/Actions Std              0.185747
evaluation/Actions Max              0.999456
evaluation/Actions Min             -0.99336
evaluation/Num Paths               15
evaluation/Average Returns        -80.2785
time/data storing (s)               0.0028705
time/evaluation sampling (s)        0.3308
time/exploration sampling (s)       0.147027
time/logging (s)                    0.00478413
time/saving (s)                     0.00196689
time/training (s)                   1.94283
time/epoch (s)                      2.43028
time/total (s)                    376.344
Epoch                             152
-----------------------------  ---------------
2019-04-22 23:33:32.622332 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 153 finished
-----------------------------  ---------------
replay_buffer/size              77200
trainer/QF1 Loss                   10.3495
trainer/QF2 Loss                   10.3778
trainer/Policy Loss                33.9384
trainer/Q1 Predictions Mean       -32.8875
trainer/Q1 Predictions Std         25.3339
trainer/Q1 Predictions Max         -9.27569
trainer/Q1 Predictions Min        -97.8752
trainer/Q2 Predictions Mean       -32.912
trainer/Q2 Predictions Std         25.3498
trainer/Q2 Predictions Max         -9.40367
trainer/Q2 Predictions Min        -98.4281
trainer/Q Targets Mean            -32.8244
trainer/Q Targets Std              25.8884
trainer/Q Targets Max              -0.351711
trainer/Q Targets Min             -98.9132
trainer/Log Pis Mean                1.99371
trainer/Log Pis Std                 1.28183
trainer/Log Pis Max                 6.61721
trainer/Log Pis Min                -0.934601
trainer/Policy mu Mean              0.0957422
trainer/Policy mu Std               0.883651
trainer/Policy mu Max               3.3144
trainer/Policy mu Min              -2.50101
trainer/Policy log std Mean        -1.87343
trainer/Policy log std Std          0.555147
trainer/Policy log std Max         -0.301735
trainer/Policy log std Min         -2.66895
trainer/Alpha                       0.074364
trainer/Alpha Loss                 -0.0163392
exploration/num steps total     77200
exploration/num paths total       772
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.444778
exploration/Rewards Std             0.464621
exploration/Rewards Max            -0.00995883
exploration/Rewards Min            -5.45652
exploration/Returns Mean          -44.4778
exploration/Returns Std            14.2318
exploration/Returns Max           -29.9983
exploration/Returns Min           -65.4845
exploration/Actions Mean            0.0116683
exploration/Actions Std             0.197935
exploration/Actions Max             0.996994
exploration/Actions Min            -0.978888
exploration/Num Paths               5
exploration/Average Returns       -44.4778
evaluation/num steps total     231000
evaluation/num paths total       2310
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.510172
evaluation/Rewards Std              1.10441
evaluation/Rewards Max             -0.00648741
evaluation/Rewards Min            -10.1875
evaluation/Returns Mean           -51.0172
evaluation/Returns Std             44.287
evaluation/Returns Max             -9.12894
evaluation/Returns Min           -199.85
evaluation/Actions Mean             0.00309209
evaluation/Actions Std              0.177954
evaluation/Actions Max              0.99938
evaluation/Actions Min             -0.999045
evaluation/Num Paths               15
evaluation/Average Returns        -51.0172
time/data storing (s)               0.00275485
time/evaluation sampling (s)        0.328081
time/exploration sampling (s)       0.138698
time/logging (s)                    0.00477118
time/saving (s)                     0.00156034
time/training (s)                   1.9135
time/epoch (s)                      2.38936
time/total (s)                    378.737
Epoch                             153
-----------------------------  ---------------
2019-04-22 23:33:35.027964 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 154 finished
-----------------------------  ---------------
replay_buffer/size              77700
trainer/QF1 Loss                    5.10543
trainer/QF2 Loss                    5.08491
trainer/Policy Loss                35.1321
trainer/Q1 Predictions Mean       -33.5365
trainer/Q1 Predictions Std         30.5632
trainer/Q1 Predictions Max         -9.31666
trainer/Q1 Predictions Min       -129.42
trainer/Q2 Predictions Mean       -33.5242
trainer/Q2 Predictions Std         30.5204
trainer/Q2 Predictions Max         -9.3271
trainer/Q2 Predictions Min       -128.126
trainer/Q Targets Mean            -33.5603
trainer/Q Targets Std              30.9902
trainer/Q Targets Max              -0.476873
trainer/Q Targets Min            -132.502
trainer/Log Pis Mean                2.23578
trainer/Log Pis Std                 1.09306
trainer/Log Pis Max                 6.11568
trainer/Log Pis Min                -0.179436
trainer/Policy mu Mean              0.0385097
trainer/Policy mu Std               0.862339
trainer/Policy mu Max               2.62
trainer/Policy mu Min              -2.91366
trainer/Policy log std Mean        -1.8993
trainer/Policy log std Std          0.582369
trainer/Policy log std Max         -0.421244
trainer/Policy log std Min         -2.70548
trainer/Alpha                       0.0730791
trainer/Alpha Loss                  0.616865
exploration/num steps total     77700
exploration/num paths total       777
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.796201
exploration/Rewards Std             1.12758
exploration/Rewards Max            -0.0154139
exploration/Rewards Min            -8.56351
exploration/Returns Mean          -79.6201
exploration/Returns Std            66.83
exploration/Returns Max           -34.0977
exploration/Returns Min          -211.842
exploration/Actions Mean            0.012117
exploration/Actions Std             0.218134
exploration/Actions Max             0.999687
exploration/Actions Min            -0.996685
exploration/Num Paths               5
exploration/Average Returns       -79.6201
evaluation/num steps total     232500
evaluation/num paths total       2325
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.671099
evaluation/Rewards Std              0.981147
evaluation/Rewards Max             -0.0113278
evaluation/Rewards Min             -9.10339
evaluation/Returns Mean           -67.1099
evaluation/Returns Std             65.286
evaluation/Returns Max             -6.95386
evaluation/Returns Min           -200.056
evaluation/Actions Mean             0.00531282
evaluation/Actions Std              0.165164
evaluation/Actions Max              0.999193
evaluation/Actions Min             -0.995732
evaluation/Num Paths               15
evaluation/Average Returns        -67.1099
time/data storing (s)               0.0028977
time/evaluation sampling (s)        0.322271
time/exploration sampling (s)       0.14202
time/logging (s)                    0.00357361
time/saving (s)                     0.00195185
time/training (s)                   1.92469
time/epoch (s)                      2.39741
time/total (s)                    381.139
Epoch                             154
-----------------------------  ---------------
2019-04-22 23:33:37.448469 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 155 finished
-----------------------------  ---------------
replay_buffer/size              78200
trainer/QF1 Loss                    0.251594
trainer/QF2 Loss                    0.251631
trainer/Policy Loss                36.6121
trainer/Q1 Predictions Mean       -35.515
trainer/Q1 Predictions Std         28.517
trainer/Q1 Predictions Max         -9.17786
trainer/Q1 Predictions Min       -133.114
trainer/Q2 Predictions Mean       -35.5161
trainer/Q2 Predictions Std         28.5603
trainer/Q2 Predictions Max         -9.18395
trainer/Q2 Predictions Min       -133.867
trainer/Q Targets Mean            -35.7742
trainer/Q Targets Std              28.7683
trainer/Q Targets Max              -9.23871
trainer/Q Targets Min            -134.436
trainer/Log Pis Mean                2.01347
trainer/Log Pis Std                 1.30561
trainer/Log Pis Max                 7.55945
trainer/Log Pis Min                -2.50995
trainer/Policy mu Mean              0.0503425
trainer/Policy mu Std               0.818768
trainer/Policy mu Max               2.84713
trainer/Policy mu Min              -3.18877
trainer/Policy log std Mean        -1.91512
trainer/Policy log std Std          0.528395
trainer/Policy log std Max         -0.444711
trainer/Policy log std Min         -2.6221
trainer/Alpha                       0.0732173
trainer/Alpha Loss                  0.0352125
exploration/num steps total     78200
exploration/num paths total       782
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.70289
exploration/Rewards Std             0.862636
exploration/Rewards Max            -0.00678896
exploration/Rewards Min            -6.77556
exploration/Returns Mean          -70.289
exploration/Returns Std            65.1322
exploration/Returns Max           -19.397
exploration/Returns Min          -195.76
exploration/Actions Mean            0.016751
exploration/Actions Std             0.191878
exploration/Actions Max             0.999206
exploration/Actions Min            -0.942063
exploration/Num Paths               5
exploration/Average Returns       -70.289
evaluation/num steps total     234000
evaluation/num paths total       2340
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.584794
evaluation/Rewards Std              0.92597
evaluation/Rewards Max             -0.0481453
evaluation/Rewards Min             -8.25501
evaluation/Returns Mean           -58.4794
evaluation/Returns Std             40.0521
evaluation/Returns Max            -20.631
evaluation/Returns Min           -199.512
evaluation/Actions Mean             0.00101163
evaluation/Actions Std              0.185495
evaluation/Actions Max              0.998477
evaluation/Actions Min             -0.999387
evaluation/Num Paths               15
evaluation/Average Returns        -58.4794
time/data storing (s)               0.00280045
time/evaluation sampling (s)        0.329014
time/exploration sampling (s)       0.139781
time/logging (s)                    0.00479096
time/saving (s)                     0.00194345
time/training (s)                   1.93674
time/epoch (s)                      2.41507
time/total (s)                    383.558
Epoch                             155
-----------------------------  ---------------
2019-04-22 23:33:39.846444 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 156 finished
-----------------------------  ---------------
replay_buffer/size              78700
trainer/QF1 Loss                   76.8259
trainer/QF2 Loss                   76.7964
trainer/Policy Loss                31.2631
trainer/Q1 Predictions Mean       -29.6409
trainer/Q1 Predictions Std         23.9341
trainer/Q1 Predictions Max         -8.96454
trainer/Q1 Predictions Min       -100.611
trainer/Q2 Predictions Mean       -29.6438
trainer/Q2 Predictions Std         23.9336
trainer/Q2 Predictions Max         -8.90282
trainer/Q2 Predictions Min       -100.835
trainer/Q Targets Mean            -29.1559
trainer/Q Targets Std              23.7947
trainer/Q Targets Max              -2.09434
trainer/Q Targets Min            -103.161
trainer/Log Pis Mean                2.09051
trainer/Log Pis Std                 1.26547
trainer/Log Pis Max                 6.7011
trainer/Log Pis Min                -2.9313
trainer/Policy mu Mean              0.0577833
trainer/Policy mu Std               0.875662
trainer/Policy mu Max               3.36356
trainer/Policy mu Min              -3.08768
trainer/Policy log std Mean        -1.93954
trainer/Policy log std Std          0.607012
trainer/Policy log std Max         -0.214233
trainer/Policy log std Min         -2.66855
trainer/Alpha                       0.072359
trainer/Alpha Loss                  0.237699
exploration/num steps total     78700
exploration/num paths total       787
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.830304
exploration/Rewards Std             1.3525
exploration/Rewards Max            -0.00839956
exploration/Rewards Min            -9.63914
exploration/Returns Mean          -83.0304
exploration/Returns Std            59.2889
exploration/Returns Max           -25.76
exploration/Returns Min          -196.772
exploration/Actions Mean            0.00971917
exploration/Actions Std             0.234385
exploration/Actions Max             0.999164
exploration/Actions Min            -0.999151
exploration/Num Paths               5
exploration/Average Returns       -83.0304
evaluation/num steps total     235500
evaluation/num paths total       2355
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.351438
evaluation/Rewards Std              0.871874
evaluation/Rewards Max             -0.0206488
evaluation/Rewards Min             -9.97401
evaluation/Returns Mean           -35.1438
evaluation/Returns Std             22.1626
evaluation/Returns Max             -5.70664
evaluation/Returns Min            -88.1547
evaluation/Actions Mean             0.00630466
evaluation/Actions Std              0.182003
evaluation/Actions Max              0.999322
evaluation/Actions Min             -0.98712
evaluation/Num Paths               15
evaluation/Average Returns        -35.1438
time/data storing (s)               0.00281132
time/evaluation sampling (s)        0.330677
time/exploration sampling (s)       0.140091
time/logging (s)                    0.00480896
time/saving (s)                     0.00156949
time/training (s)                   1.91096
time/epoch (s)                      2.39092
time/total (s)                    385.953
Epoch                             156
-----------------------------  ---------------
2019-04-22 23:33:42.294891 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 157 finished
-----------------------------  ---------------
replay_buffer/size              79200
trainer/QF1 Loss                    3.07852
trainer/QF2 Loss                    3.08155
trainer/Policy Loss                33.4914
trainer/Q1 Predictions Mean       -32.0485
trainer/Q1 Predictions Std         25.242
trainer/Q1 Predictions Max         -8.8952
trainer/Q1 Predictions Min        -94.1217
trainer/Q2 Predictions Mean       -32.0392
trainer/Q2 Predictions Std         25.2737
trainer/Q2 Predictions Max         -8.8524
trainer/Q2 Predictions Min        -94.1275
trainer/Q Targets Mean            -32.5317
trainer/Q Targets Std              25.8792
trainer/Q Targets Max              -1.72288
trainer/Q Targets Min             -96.6458
trainer/Log Pis Mean                2.19113
trainer/Log Pis Std                 1.68108
trainer/Log Pis Max                10.0883
trainer/Log Pis Min                -1.83715
trainer/Policy mu Mean              0.123276
trainer/Policy mu Std               0.901062
trainer/Policy mu Max               3.60792
trainer/Policy mu Min              -3.03762
trainer/Policy log std Mean        -1.97196
trainer/Policy log std Std          0.58238
trainer/Policy log std Max         -0.145689
trainer/Policy log std Min         -2.64525
trainer/Alpha                       0.07272
trainer/Alpha Loss                  0.500991
exploration/num steps total     79200
exploration/num paths total       792
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.599899
exploration/Rewards Std             1.17733
exploration/Rewards Max            -0.0141637
exploration/Rewards Min            -8.83519
exploration/Returns Mean          -59.9899
exploration/Returns Std             8.44426
exploration/Returns Max           -54.1105
exploration/Returns Min           -76.5292
exploration/Actions Mean            0.038478
exploration/Actions Std             0.241087
exploration/Actions Max             0.999872
exploration/Actions Min            -0.991574
exploration/Num Paths               5
exploration/Average Returns       -59.9899
evaluation/num steps total     237000
evaluation/num paths total       2370
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.742892
evaluation/Rewards Std              1.12177
evaluation/Rewards Max             -0.0397545
evaluation/Rewards Min             -9.00727
evaluation/Returns Mean           -74.2892
evaluation/Returns Std             74.2801
evaluation/Returns Max             -8.02805
evaluation/Returns Min           -219.029
evaluation/Actions Mean             0.00450954
evaluation/Actions Std              0.190244
evaluation/Actions Max              0.999238
evaluation/Actions Min             -0.99764
evaluation/Num Paths               15
evaluation/Average Returns        -74.2892
time/data storing (s)               0.00287374
time/evaluation sampling (s)        0.333522
time/exploration sampling (s)       0.140215
time/logging (s)                    0.0048035
time/saving (s)                     0.0112145
time/training (s)                   1.94875
time/epoch (s)                      2.44138
time/total (s)                    388.399
Epoch                             157
-----------------------------  ---------------
2019-04-22 23:33:44.701385 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 158 finished
-----------------------------  ----------------
replay_buffer/size              79700
trainer/QF1 Loss                    0.291931
trainer/QF2 Loss                    0.177173
trainer/Policy Loss                35.8638
trainer/Q1 Predictions Mean       -34.4094
trainer/Q1 Predictions Std         28.8524
trainer/Q1 Predictions Max         -9.2909
trainer/Q1 Predictions Min        -91.9373
trainer/Q2 Predictions Mean       -34.4441
trainer/Q2 Predictions Std         28.8766
trainer/Q2 Predictions Max         -9.32546
trainer/Q2 Predictions Min        -91.88
trainer/Q Targets Mean            -34.5261
trainer/Q Targets Std              29.1238
trainer/Q Targets Max              -9.11859
trainer/Q Targets Min             -92.2742
trainer/Log Pis Mean                1.98652
trainer/Log Pis Std                 1.02174
trainer/Log Pis Max                 5.95336
trainer/Log Pis Min                -0.91148
trainer/Policy mu Mean              0.0182375
trainer/Policy mu Std               0.680063
trainer/Policy mu Max               3.38977
trainer/Policy mu Min              -2.30536
trainer/Policy log std Mean        -2.00649
trainer/Policy log std Std          0.480335
trainer/Policy log std Max         -0.042794
trainer/Policy log std Min         -2.69917
trainer/Alpha                       0.0729892
trainer/Alpha Loss                 -0.0352789
exploration/num steps total     79700
exploration/num paths total       797
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.41717
exploration/Rewards Std             0.984934
exploration/Rewards Max            -0.00533272
exploration/Rewards Min            -8.60683
exploration/Returns Mean          -41.717
exploration/Returns Std            19.2603
exploration/Returns Max           -17.7228
exploration/Returns Min           -69.7185
exploration/Actions Mean            0.0268288
exploration/Actions Std             0.196899
exploration/Actions Max             0.999899
exploration/Actions Min            -0.760098
exploration/Num Paths               5
exploration/Average Returns       -41.717
evaluation/num steps total     238500
evaluation/num paths total       2385
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.444339
evaluation/Rewards Std              0.82892
evaluation/Rewards Max             -0.00658271
evaluation/Rewards Min             -8.09598
evaluation/Returns Mean           -44.4339
evaluation/Returns Std             45.4955
evaluation/Returns Max             -3.46683
evaluation/Returns Min           -192.856
evaluation/Actions Mean             0.000238586
evaluation/Actions Std              0.16678
evaluation/Actions Max              0.999301
evaluation/Actions Min             -0.997437
evaluation/Num Paths               15
evaluation/Average Returns        -44.4339
time/data storing (s)               0.00294988
time/evaluation sampling (s)        0.324302
time/exploration sampling (s)       0.139389
time/logging (s)                    0.00478194
time/saving (s)                     0.0019522
time/training (s)                   1.92704
time/epoch (s)                      2.40041
time/total (s)                    390.803
Epoch                             158
-----------------------------  ----------------
2019-04-22 23:33:47.112743 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 159 finished
-----------------------------  ---------------
replay_buffer/size              80200
trainer/QF1 Loss                    0.510142
trainer/QF2 Loss                    0.60461
trainer/Policy Loss                25.1637
trainer/Q1 Predictions Mean       -23.642
trainer/Q1 Predictions Std         18.7882
trainer/Q1 Predictions Max         -8.93757
trainer/Q1 Predictions Min        -89.0112
trainer/Q2 Predictions Mean       -23.6387
trainer/Q2 Predictions Std         18.8112
trainer/Q2 Predictions Max         -8.85937
trainer/Q2 Predictions Min        -88.9974
trainer/Q Targets Mean            -24.0202
trainer/Q Targets Std              19.1738
trainer/Q Targets Max              -9.16767
trainer/Q Targets Min             -91.7635
trainer/Log Pis Mean                2.12465
trainer/Log Pis Std                 1.24263
trainer/Log Pis Max                 8.64868
trainer/Log Pis Min                -0.903433
trainer/Policy mu Mean              0.0719066
trainer/Policy mu Std               0.766178
trainer/Policy mu Max               3.19546
trainer/Policy mu Min              -3.78931
trainer/Policy log std Mean        -2.03114
trainer/Policy log std Std          0.495432
trainer/Policy log std Max         -0.148881
trainer/Policy log std Min         -2.73214
trainer/Alpha                       0.0739726
trainer/Alpha Loss                  0.324614
exploration/num steps total     80200
exploration/num paths total       802
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.581729
exploration/Rewards Std             1.18826
exploration/Rewards Max            -0.0256361
exploration/Rewards Min           -10.1342
exploration/Returns Mean          -58.1729
exploration/Returns Std            22.2617
exploration/Returns Max           -38.3575
exploration/Returns Min           -91.1245
exploration/Actions Mean            0.0173493
exploration/Actions Std             0.233696
exploration/Actions Max             0.999901
exploration/Actions Min            -0.997478
exploration/Num Paths               5
exploration/Average Returns       -58.1729
evaluation/num steps total     240000
evaluation/num paths total       2400
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.960437
evaluation/Rewards Std              1.2415
evaluation/Rewards Max             -0.0703533
evaluation/Rewards Min            -10.3978
evaluation/Returns Mean           -96.0437
evaluation/Returns Std             77.3757
evaluation/Returns Max             -8.18317
evaluation/Returns Min           -216.276
evaluation/Actions Mean            -0.0122702
evaluation/Actions Std              0.195898
evaluation/Actions Max              0.998867
evaluation/Actions Min             -0.997828
evaluation/Num Paths               15
evaluation/Average Returns        -96.0437
time/data storing (s)               0.00287375
time/evaluation sampling (s)        0.333383
time/exploration sampling (s)       0.140213
time/logging (s)                    0.00481142
time/saving (s)                     0.0019657
time/training (s)                   1.92125
time/epoch (s)                      2.40449
time/total (s)                    393.212
Epoch                             159
-----------------------------  ---------------
2019-04-22 23:33:49.545637 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 160 finished
-----------------------------  ---------------
replay_buffer/size              80700
trainer/QF1 Loss                    8.46671
trainer/QF2 Loss                    8.45745
trainer/Policy Loss                31.6275
trainer/Q1 Predictions Mean       -30.0816
trainer/Q1 Predictions Std         25.8703
trainer/Q1 Predictions Max         -9.54357
trainer/Q1 Predictions Min        -94.316
trainer/Q2 Predictions Mean       -30.1357
trainer/Q2 Predictions Std         25.8622
trainer/Q2 Predictions Max         -9.58321
trainer/Q2 Predictions Min        -94.5772
trainer/Q Targets Mean            -29.9464
trainer/Q Targets Std              26.2425
trainer/Q Targets Max              -3.06664
trainer/Q Targets Min             -94.7653
trainer/Log Pis Mean                2.10405
trainer/Log Pis Std                 1.37913
trainer/Log Pis Max                 7.33199
trainer/Log Pis Min                -2.34923
trainer/Policy mu Mean             -0.0588035
trainer/Policy mu Std               0.843819
trainer/Policy mu Max               2.75508
trainer/Policy mu Min              -3.33667
trainer/Policy log std Mean        -1.93227
trainer/Policy log std Std          0.569091
trainer/Policy log std Max         -0.235557
trainer/Policy log std Min         -2.66997
trainer/Alpha                       0.0719351
trainer/Alpha Loss                  0.273872
exploration/num steps total     80700
exploration/num paths total       807
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.31768
exploration/Rewards Std             0.907012
exploration/Rewards Max            -0.0295848
exploration/Rewards Min            -5.71193
exploration/Returns Mean         -131.768
exploration/Returns Std            81.0119
exploration/Returns Max           -27.7243
exploration/Returns Min          -203.483
exploration/Actions Mean           -0.00261906
exploration/Actions Std             0.20854
exploration/Actions Max             0.983365
exploration/Actions Min            -0.985779
exploration/Num Paths               5
exploration/Average Returns      -131.768
evaluation/num steps total     241500
evaluation/num paths total       2415
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.538382
evaluation/Rewards Std              1.15139
evaluation/Rewards Max             -0.0329258
evaluation/Rewards Min             -9.18649
evaluation/Returns Mean           -53.8382
evaluation/Returns Std             41.4246
evaluation/Returns Max             -3.70387
evaluation/Returns Min           -192.997
evaluation/Actions Mean             0.0196268
evaluation/Actions Std              0.203431
evaluation/Actions Max              0.998659
evaluation/Actions Min             -0.997989
evaluation/Num Paths               15
evaluation/Average Returns        -53.8382
time/data storing (s)               0.00298171
time/evaluation sampling (s)        0.327436
time/exploration sampling (s)       0.14149
time/logging (s)                    0.00466123
time/saving (s)                     0.00196735
time/training (s)                   1.94679
time/epoch (s)                      2.42532
time/total (s)                    395.642
Epoch                             160
-----------------------------  ---------------
2019-04-22 23:33:51.947414 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 161 finished
-----------------------------  ---------------
replay_buffer/size              81200
trainer/QF1 Loss                    8.94547
trainer/QF2 Loss                    9.03187
trainer/Policy Loss                31.7403
trainer/Q1 Predictions Mean       -30.4291
trainer/Q1 Predictions Std         25.5474
trainer/Q1 Predictions Max         -9.40327
trainer/Q1 Predictions Min        -91.3842
trainer/Q2 Predictions Mean       -30.4192
trainer/Q2 Predictions Std         25.5469
trainer/Q2 Predictions Max         -9.40527
trainer/Q2 Predictions Min        -91.3324
trainer/Q Targets Mean            -30.1067
trainer/Q Targets Std              25.9358
trainer/Q Targets Max              -0.134748
trainer/Q Targets Min             -91.8292
trainer/Log Pis Mean                1.92367
trainer/Log Pis Std                 1.45543
trainer/Log Pis Max                 5.3935
trainer/Log Pis Min                -3.65834
trainer/Policy mu Mean              0.0400472
trainer/Policy mu Std               0.723944
trainer/Policy mu Max               2.6144
trainer/Policy mu Min              -2.82291
trainer/Policy log std Mean        -1.99568
trainer/Policy log std Std          0.512882
trainer/Policy log std Max         -0.370864
trainer/Policy log std Min         -2.7103
trainer/Alpha                       0.0714453
trainer/Alpha Loss                 -0.201432
exploration/num steps total     81200
exploration/num paths total       812
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.283017
exploration/Rewards Std             0.892174
exploration/Rewards Max            -0.00341472
exploration/Rewards Min           -10.2342
exploration/Returns Mean          -28.3017
exploration/Returns Std            17.6456
exploration/Returns Max           -12.6305
exploration/Returns Min           -62.8294
exploration/Actions Mean            0.00558122
exploration/Actions Std             0.204292
exploration/Actions Max             0.999812
exploration/Actions Min            -0.991712
exploration/Num Paths               5
exploration/Average Returns       -28.3017
evaluation/num steps total     243000
evaluation/num paths total       2430
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.854415
evaluation/Rewards Std              1.29912
evaluation/Rewards Max             -0.0137857
evaluation/Rewards Min            -11.9988
evaluation/Returns Mean           -85.4415
evaluation/Returns Std             77.3638
evaluation/Returns Max             -9.26044
evaluation/Returns Min           -220.433
evaluation/Actions Mean            -0.00842487
evaluation/Actions Std              0.203992
evaluation/Actions Max              0.998327
evaluation/Actions Min             -0.999065
evaluation/Num Paths               15
evaluation/Average Returns        -85.4415
time/data storing (s)               0.00331344
time/evaluation sampling (s)        0.326072
time/exploration sampling (s)       0.140121
time/logging (s)                    0.00483714
time/saving (s)                     0.0015832
time/training (s)                   1.91863
time/epoch (s)                      2.39455
time/total (s)                    398.041
Epoch                             161
-----------------------------  ---------------
2019-04-22 23:33:54.368809 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 162 finished
-----------------------------  ---------------
replay_buffer/size              81700
trainer/QF1 Loss                    0.296036
trainer/QF2 Loss                    0.281715
trainer/Policy Loss                32.3659
trainer/Q1 Predictions Mean       -31.0242
trainer/Q1 Predictions Std         25.9245
trainer/Q1 Predictions Max         -9.12064
trainer/Q1 Predictions Min        -93.8575
trainer/Q2 Predictions Mean       -31.0431
trainer/Q2 Predictions Std         25.9347
trainer/Q2 Predictions Max         -9.08872
trainer/Q2 Predictions Min        -94.2897
trainer/Q Targets Mean            -31.2746
trainer/Q Targets Std              26.2328
trainer/Q Targets Max              -9.09702
trainer/Q Targets Min             -94.3486
trainer/Log Pis Mean                2.11013
trainer/Log Pis Std                 1.60298
trainer/Log Pis Max                 6.78503
trainer/Log Pis Min                -1.56857
trainer/Policy mu Mean              0.0737406
trainer/Policy mu Std               0.923314
trainer/Policy mu Max               4.04427
trainer/Policy mu Min              -2.63568
trainer/Policy log std Mean        -1.87132
trainer/Policy log std Std          0.582945
trainer/Policy log std Max         -0.126722
trainer/Policy log std Min         -2.70625
trainer/Alpha                       0.0720658
trainer/Alpha Loss                  0.289647
exploration/num steps total     81700
exploration/num paths total       817
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.914308
exploration/Rewards Std             0.951886
exploration/Rewards Max            -0.0185805
exploration/Rewards Min            -5.58742
exploration/Returns Mean          -91.4308
exploration/Returns Std            82.4177
exploration/Returns Max           -17.897
exploration/Returns Min          -197.166
exploration/Actions Mean           -0.00776229
exploration/Actions Std             0.184082
exploration/Actions Max             0.979817
exploration/Actions Min            -0.993027
exploration/Num Paths               5
exploration/Average Returns       -91.4308
evaluation/num steps total     244500
evaluation/num paths total       2445
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.632722
evaluation/Rewards Std              1.16503
evaluation/Rewards Max             -0.0730143
evaluation/Rewards Min             -9.55458
evaluation/Returns Mean           -63.2722
evaluation/Returns Std             54.2805
evaluation/Returns Max            -15.3469
evaluation/Returns Min           -201.996
evaluation/Actions Mean             0.0152689
evaluation/Actions Std              0.197934
evaluation/Actions Max              0.999337
evaluation/Actions Min             -0.997542
evaluation/Num Paths               15
evaluation/Average Returns        -63.2722
time/data storing (s)               0.00290501
time/evaluation sampling (s)        0.322952
time/exploration sampling (s)       0.139776
time/logging (s)                    0.00479471
time/saving (s)                     0.00197272
time/training (s)                   1.94156
time/epoch (s)                      2.41396
time/total (s)                    400.46
Epoch                             162
-----------------------------  ---------------
2019-04-22 23:33:56.797883 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 163 finished
-----------------------------  ---------------
replay_buffer/size              82200
trainer/QF1 Loss                    0.386345
trainer/QF2 Loss                    0.404031
trainer/Policy Loss                36.9003
trainer/Q1 Predictions Mean       -35.434
trainer/Q1 Predictions Std         30.615
trainer/Q1 Predictions Max         -9.03342
trainer/Q1 Predictions Min       -109.157
trainer/Q2 Predictions Mean       -35.4242
trainer/Q2 Predictions Std         30.5868
trainer/Q2 Predictions Max         -9.05693
trainer/Q2 Predictions Min       -108.486
trainer/Q Targets Mean            -35.7796
trainer/Q Targets Std              31.024
trainer/Q Targets Max              -9.0282
trainer/Q Targets Min            -109.359
trainer/Log Pis Mean                1.98678
trainer/Log Pis Std                 1.09779
trainer/Log Pis Max                 4.85206
trainer/Log Pis Min                -2.60636
trainer/Policy mu Mean              0.0524347
trainer/Policy mu Std               0.688814
trainer/Policy mu Max               2.92986
trainer/Policy mu Min              -2.67677
trainer/Policy log std Mean        -2.00433
trainer/Policy log std Std          0.488759
trainer/Policy log std Max         -0.45468
trainer/Policy log std Min         -2.72602
trainer/Alpha                       0.0717411
trainer/Alpha Loss                 -0.0348397
exploration/num steps total     82200
exploration/num paths total       822
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.373676
exploration/Rewards Std             0.959685
exploration/Rewards Max            -0.0121816
exploration/Rewards Min           -11.299
exploration/Returns Mean          -37.3676
exploration/Returns Std            26.7358
exploration/Returns Max           -12.6874
exploration/Returns Min           -87.0475
exploration/Actions Mean            0.00553923
exploration/Actions Std             0.209772
exploration/Actions Max             0.999275
exploration/Actions Min            -0.999395
exploration/Num Paths               5
exploration/Average Returns       -37.3676
evaluation/num steps total     246000
evaluation/num paths total       2460
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.429278
evaluation/Rewards Std              0.921312
evaluation/Rewards Max             -0.012021
evaluation/Rewards Min             -7.4335
evaluation/Returns Mean           -42.9278
evaluation/Returns Std             47.9478
evaluation/Returns Max             -7.88852
evaluation/Returns Min           -214.193
evaluation/Actions Mean             0.00456825
evaluation/Actions Std              0.190694
evaluation/Actions Max              0.999128
evaluation/Actions Min             -0.995644
evaluation/Num Paths               15
evaluation/Average Returns        -42.9278
time/data storing (s)               0.00282113
time/evaluation sampling (s)        0.328643
time/exploration sampling (s)       0.141752
time/logging (s)                    0.0041077
time/saving (s)                     0.00176126
time/training (s)                   1.94192
time/epoch (s)                      2.421
time/total (s)                    402.885
Epoch                             163
-----------------------------  ---------------
2019-04-22 23:33:59.215736 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 164 finished
-----------------------------  ---------------
replay_buffer/size              82700
trainer/QF1 Loss                   17.9737
trainer/QF2 Loss                   17.8055
trainer/Policy Loss                25.1427
trainer/Q1 Predictions Mean       -23.7209
trainer/Q1 Predictions Std         18.4233
trainer/Q1 Predictions Max         -8.92524
trainer/Q1 Predictions Min        -90.4639
trainer/Q2 Predictions Mean       -23.7446
trainer/Q2 Predictions Std         18.423
trainer/Q2 Predictions Max         -8.90328
trainer/Q2 Predictions Min        -90.415
trainer/Q Targets Mean            -23.1989
trainer/Q Targets Std              19.1175
trainer/Q Targets Max              -0.0610981
trainer/Q Targets Min             -92.7165
trainer/Log Pis Mean                1.90636
trainer/Log Pis Std                 1.46139
trainer/Log Pis Max                 5.05739
trainer/Log Pis Min                -2.51957
trainer/Policy mu Mean              0.132019
trainer/Policy mu Std               0.774732
trainer/Policy mu Max               3.12024
trainer/Policy mu Min              -2.91026
trainer/Policy log std Mean        -1.9875
trainer/Policy log std Std          0.530344
trainer/Policy log std Max         -0.435594
trainer/Policy log std Min         -2.68294
trainer/Alpha                       0.0703701
trainer/Alpha Loss                 -0.24851
exploration/num steps total     82700
exploration/num paths total       827
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.743645
exploration/Rewards Std             1.14532
exploration/Rewards Max            -0.00554518
exploration/Rewards Min            -8.07959
exploration/Returns Mean          -74.3645
exploration/Returns Std            68.8774
exploration/Returns Max           -21.0952
exploration/Returns Min          -208.115
exploration/Actions Mean           -0.015055
exploration/Actions Std             0.238604
exploration/Actions Max             0.99868
exploration/Actions Min            -0.999088
exploration/Num Paths               5
exploration/Average Returns       -74.3645
evaluation/num steps total     247500
evaluation/num paths total       2475
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.47185
evaluation/Rewards Std              0.909181
evaluation/Rewards Max             -0.029759
evaluation/Rewards Min             -9.03526
evaluation/Returns Mean           -47.185
evaluation/Returns Std             46.7733
evaluation/Returns Max             -7.17031
evaluation/Returns Min           -207.504
evaluation/Actions Mean            -0.00129767
evaluation/Actions Std              0.177245
evaluation/Actions Max              0.998485
evaluation/Actions Min             -0.996867
evaluation/Num Paths               15
evaluation/Average Returns        -47.185
time/data storing (s)               0.00291411
time/evaluation sampling (s)        0.326319
time/exploration sampling (s)       0.139018
time/logging (s)                    0.00485156
time/saving (s)                     0.0019709
time/training (s)                   1.93707
time/epoch (s)                      2.41214
time/total (s)                    405.301
Epoch                             164
-----------------------------  ---------------
2019-04-22 23:34:01.615758 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 165 finished
-----------------------------  ---------------
replay_buffer/size              83200
trainer/QF1 Loss                    0.180182
trainer/QF2 Loss                    0.221996
trainer/Policy Loss                27.0286
trainer/Q1 Predictions Mean       -25.6234
trainer/Q1 Predictions Std         22.5582
trainer/Q1 Predictions Max         -8.93334
trainer/Q1 Predictions Min        -96.7812
trainer/Q2 Predictions Mean       -25.5712
trainer/Q2 Predictions Std         22.5345
trainer/Q2 Predictions Max         -8.91742
trainer/Q2 Predictions Min        -96.6151
trainer/Q Targets Mean            -25.8966
trainer/Q Targets Std              22.7325
trainer/Q Targets Max              -9.05642
trainer/Q Targets Min             -97.9371
trainer/Log Pis Mean                2.15437
trainer/Log Pis Std                 1.4548
trainer/Log Pis Max                11.2206
trainer/Log Pis Min                -1.68776
trainer/Policy mu Mean              0.14237
trainer/Policy mu Std               0.853286
trainer/Policy mu Max               3.80109
trainer/Policy mu Min              -2.56721
trainer/Policy log std Mean        -1.95036
trainer/Policy log std Std          0.544015
trainer/Policy log std Max         -0.358972
trainer/Policy log std Min         -2.63439
trainer/Alpha                       0.068125
trainer/Alpha Loss                  0.414696
exploration/num steps total     83200
exploration/num paths total       832
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.893174
exploration/Rewards Std             1.4264
exploration/Rewards Max            -0.00171655
exploration/Rewards Min           -10.8743
exploration/Returns Mean          -89.3174
exploration/Returns Std            47.7758
exploration/Returns Max           -52.0944
exploration/Returns Min          -183.571
exploration/Actions Mean            0.0178753
exploration/Actions Std             0.267301
exploration/Actions Max             0.999886
exploration/Actions Min            -0.998885
exploration/Num Paths               5
exploration/Average Returns       -89.3174
evaluation/num steps total     249000
evaluation/num paths total       2490
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.574991
evaluation/Rewards Std              1.02374
evaluation/Rewards Max             -0.0631553
evaluation/Rewards Min             -9.58842
evaluation/Returns Mean           -57.4991
evaluation/Returns Std             56.5151
evaluation/Returns Max            -11.761
evaluation/Returns Min           -198.566
evaluation/Actions Mean             0.00280569
evaluation/Actions Std              0.186456
evaluation/Actions Max              0.999712
evaluation/Actions Min             -0.998599
evaluation/Num Paths               15
evaluation/Average Returns        -57.4991
time/data storing (s)               0.00293779
time/evaluation sampling (s)        0.325964
time/exploration sampling (s)       0.140492
time/logging (s)                    0.00437668
time/saving (s)                     0.00196839
time/training (s)                   1.91757
time/epoch (s)                      2.39331
time/total (s)                    407.699
Epoch                             165
-----------------------------  ---------------
2019-04-22 23:34:04.036574 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 166 finished
-----------------------------  ---------------
replay_buffer/size              83700
trainer/QF1 Loss                    4.61828
trainer/QF2 Loss                    4.62065
trainer/Policy Loss                33.0434
trainer/Q1 Predictions Mean       -31.4505
trainer/Q1 Predictions Std         29.1165
trainer/Q1 Predictions Max         -8.83438
trainer/Q1 Predictions Min       -109.165
trainer/Q2 Predictions Mean       -31.4732
trainer/Q2 Predictions Std         29.147
trainer/Q2 Predictions Max         -8.65105
trainer/Q2 Predictions Min       -109.85
trainer/Q Targets Mean            -31.8168
trainer/Q Targets Std              29.8517
trainer/Q Targets Max              -0.888255
trainer/Q Targets Min            -109.669
trainer/Log Pis Mean                2.08247
trainer/Log Pis Std                 1.42548
trainer/Log Pis Max                 7.94236
trainer/Log Pis Min                -1.43295
trainer/Policy mu Mean             -0.0242464
trainer/Policy mu Std               0.86357
trainer/Policy mu Max               2.81758
trainer/Policy mu Min              -3.11114
trainer/Policy log std Mean        -1.93747
trainer/Policy log std Std          0.551547
trainer/Policy log std Max         -0.342895
trainer/Policy log std Min         -2.63812
trainer/Alpha                       0.0671414
trainer/Alpha Loss                  0.222747
exploration/num steps total     83700
exploration/num paths total       837
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.612997
exploration/Rewards Std             1.37042
exploration/Rewards Max            -0.00577042
exploration/Rewards Min           -10.9134
exploration/Returns Mean          -61.2997
exploration/Returns Std            15.1234
exploration/Returns Max           -38.0435
exploration/Returns Min           -79.2314
exploration/Actions Mean            0.01237
exploration/Actions Std             0.261289
exploration/Actions Max             0.999661
exploration/Actions Min            -0.998473
exploration/Num Paths               5
exploration/Average Returns       -61.2997
evaluation/num steps total     250500
evaluation/num paths total       2505
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.578854
evaluation/Rewards Std              0.953458
evaluation/Rewards Max             -0.0188158
evaluation/Rewards Min            -10.0798
evaluation/Returns Mean           -57.8854
evaluation/Returns Std             61.9329
evaluation/Returns Max             -3.39034
evaluation/Returns Min           -181.271
evaluation/Actions Mean            -0.00400029
evaluation/Actions Std              0.160883
evaluation/Actions Max              0.998978
evaluation/Actions Min             -0.996674
evaluation/Num Paths               15
evaluation/Average Returns        -57.8854
time/data storing (s)               0.0028125
time/evaluation sampling (s)        0.332542
time/exploration sampling (s)       0.140951
time/logging (s)                    0.00485429
time/saving (s)                     0.00197722
time/training (s)                   1.93256
time/epoch (s)                      2.4157
time/total (s)                    410.118
Epoch                             166
-----------------------------  ---------------
2019-04-22 23:34:06.440053 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 167 finished
-----------------------------  ---------------
replay_buffer/size              84200
trainer/QF1 Loss                    1.19755
trainer/QF2 Loss                    1.16925
trainer/Policy Loss                33.0941
trainer/Q1 Predictions Mean       -31.8257
trainer/Q1 Predictions Std         29.8729
trainer/Q1 Predictions Max         -9.23026
trainer/Q1 Predictions Min       -109.229
trainer/Q2 Predictions Mean       -31.8051
trainer/Q2 Predictions Std         29.8641
trainer/Q2 Predictions Max         -9.24106
trainer/Q2 Predictions Min       -108.656
trainer/Q Targets Mean            -31.8632
trainer/Q Targets Std              29.9696
trainer/Q Targets Max              -0.0706071
trainer/Q Targets Min            -110.293
trainer/Log Pis Mean                1.84646
trainer/Log Pis Std                 1.6092
trainer/Log Pis Max                 8.12123
trainer/Log Pis Min                -3.09205
trainer/Policy mu Mean             -0.10166
trainer/Policy mu Std               0.803543
trainer/Policy mu Max               2.49478
trainer/Policy mu Min              -2.98649
trainer/Policy log std Mean        -1.91835
trainer/Policy log std Std          0.567338
trainer/Policy log std Max         -0.333629
trainer/Policy log std Min         -2.67244
trainer/Alpha                       0.0690574
trainer/Alpha Loss                 -0.410356
exploration/num steps total     84200
exploration/num paths total       842
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.694495
exploration/Rewards Std             1.08173
exploration/Rewards Max            -0.0103832
exploration/Rewards Min           -10.0217
exploration/Returns Mean          -69.4495
exploration/Returns Std            47.7601
exploration/Returns Max           -21.2254
exploration/Returns Min          -160.509
exploration/Actions Mean            0.0291495
exploration/Actions Std             0.225529
exploration/Actions Max             0.999619
exploration/Actions Min            -0.923315
exploration/Num Paths               5
exploration/Average Returns       -69.4495
evaluation/num steps total     252000
evaluation/num paths total       2520
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.441134
evaluation/Rewards Std              0.888111
evaluation/Rewards Max             -0.0246218
evaluation/Rewards Min            -10.8579
evaluation/Returns Mean           -44.1134
evaluation/Returns Std             17.3742
evaluation/Returns Max             -9.18473
evaluation/Returns Min            -77.7216
evaluation/Actions Mean             0.00689036
evaluation/Actions Std              0.169346
evaluation/Actions Max              0.999033
evaluation/Actions Min             -0.998263
evaluation/Num Paths               15
evaluation/Average Returns        -44.1134
time/data storing (s)               0.00290631
time/evaluation sampling (s)        0.332729
time/exploration sampling (s)       0.139636
time/logging (s)                    0.00480061
time/saving (s)                     0.00156365
time/training (s)                   1.91406
time/epoch (s)                      2.3957
time/total (s)                    412.519
Epoch                             167
-----------------------------  ---------------
2019-04-22 23:34:08.831666 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 168 finished
-----------------------------  ---------------
replay_buffer/size              84700
trainer/QF1 Loss                    0.0922474
trainer/QF2 Loss                    0.133148
trainer/Policy Loss                31.3593
trainer/Q1 Predictions Mean       -29.9991
trainer/Q1 Predictions Std         28.7737
trainer/Q1 Predictions Max         -9.06163
trainer/Q1 Predictions Min        -94.0324
trainer/Q2 Predictions Mean       -29.9744
trainer/Q2 Predictions Std         28.7809
trainer/Q2 Predictions Max         -9.03694
trainer/Q2 Predictions Min        -94.948
trainer/Q Targets Mean            -30.0612
trainer/Q Targets Std              28.9093
trainer/Q Targets Max              -8.9576
trainer/Q Targets Min             -94.3087
trainer/Log Pis Mean                1.71615
trainer/Log Pis Std                 1.15629
trainer/Log Pis Max                 5.5651
trainer/Log Pis Min                -2.79199
trainer/Policy mu Mean             -0.0877869
trainer/Policy mu Std               0.589786
trainer/Policy mu Max               3.12059
trainer/Policy mu Min              -2.9781
trainer/Policy log std Mean        -2.01414
trainer/Policy log std Std          0.441703
trainer/Policy log std Max         -0.448085
trainer/Policy log std Min         -2.53041
trainer/Alpha                       0.0709461
trainer/Alpha Loss                 -0.750983
exploration/num steps total     84700
exploration/num paths total       847
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.10963
exploration/Rewards Std             1.12051
exploration/Rewards Max            -0.0717382
exploration/Rewards Min            -8.38721
exploration/Returns Mean         -110.963
exploration/Returns Std            56.6997
exploration/Returns Max           -57.7546
exploration/Returns Min          -182.046
exploration/Actions Mean            0.0153957
exploration/Actions Std             0.234615
exploration/Actions Max             0.999511
exploration/Actions Min            -0.983234
exploration/Num Paths               5
exploration/Average Returns      -110.963
evaluation/num steps total     253500
evaluation/num paths total       2535
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.73534
evaluation/Rewards Std              1.22433
evaluation/Rewards Max             -0.0174209
evaluation/Rewards Min            -10.0072
evaluation/Returns Mean           -73.534
evaluation/Returns Std             63.8282
evaluation/Returns Max            -12.5784
evaluation/Returns Min           -206.441
evaluation/Actions Mean            -0.0114636
evaluation/Actions Std              0.207005
evaluation/Actions Max              0.997503
evaluation/Actions Min             -0.998144
evaluation/Num Paths               15
evaluation/Average Returns        -73.534
time/data storing (s)               0.00283206
time/evaluation sampling (s)        0.328335
time/exploration sampling (s)       0.140476
time/logging (s)                    0.00480693
time/saving (s)                     0.00194973
time/training (s)                   1.90572
time/epoch (s)                      2.38412
time/total (s)                    414.907
Epoch                             168
-----------------------------  ---------------
2019-04-22 23:34:11.237152 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 169 finished
-----------------------------  ---------------
replay_buffer/size              85200
trainer/QF1 Loss                    0.381341
trainer/QF2 Loss                    0.315449
trainer/Policy Loss                31.5552
trainer/Q1 Predictions Mean       -29.9078
trainer/Q1 Predictions Std         28.1131
trainer/Q1 Predictions Max         -8.70775
trainer/Q1 Predictions Min       -136.276
trainer/Q2 Predictions Mean       -29.863
trainer/Q2 Predictions Std         28.0593
trainer/Q2 Predictions Max         -8.70688
trainer/Q2 Predictions Min       -134.725
trainer/Q Targets Mean            -30.0986
trainer/Q Targets Std              28.3187
trainer/Q Targets Max              -9.00106
trainer/Q Targets Min            -133.481
trainer/Log Pis Mean                2.10333
trainer/Log Pis Std                 1.31237
trainer/Log Pis Max                 9.00114
trainer/Log Pis Min                -1.45085
trainer/Policy mu Mean              0.0724326
trainer/Policy mu Std               0.738575
trainer/Policy mu Max               3.28747
trainer/Policy mu Min              -3.23305
trainer/Policy log std Mean        -1.98771
trainer/Policy log std Std          0.526075
trainer/Policy log std Max         -0.355226
trainer/Policy log std Min         -2.56771
trainer/Alpha                       0.0704267
trainer/Alpha Loss                  0.274164
exploration/num steps total     85200
exploration/num paths total       852
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.456542
exploration/Rewards Std             0.780888
exploration/Rewards Max            -0.0242889
exploration/Rewards Min            -7.0973
exploration/Returns Mean          -45.6542
exploration/Returns Std            12.1693
exploration/Returns Max           -26.804
exploration/Returns Min           -57.9454
exploration/Actions Mean            0.0191529
exploration/Actions Std             0.220463
exploration/Actions Max             0.999408
exploration/Actions Min            -0.984286
exploration/Num Paths               5
exploration/Average Returns       -45.6542
evaluation/num steps total     255000
evaluation/num paths total       2550
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.562399
evaluation/Rewards Std              1.10553
evaluation/Rewards Max             -0.0304658
evaluation/Rewards Min            -10.0785
evaluation/Returns Mean           -56.2399
evaluation/Returns Std             39.3019
evaluation/Returns Max             -5.33705
evaluation/Returns Min           -180.226
evaluation/Actions Mean             0.0101453
evaluation/Actions Std              0.196648
evaluation/Actions Max              0.999288
evaluation/Actions Min             -0.998451
evaluation/Num Paths               15
evaluation/Average Returns        -56.2399
time/data storing (s)               0.00289838
time/evaluation sampling (s)        0.329715
time/exploration sampling (s)       0.139711
time/logging (s)                    0.00478541
time/saving (s)                     0.00197697
time/training (s)                   1.91925
time/epoch (s)                      2.39834
time/total (s)                    417.31
Epoch                             169
-----------------------------  ---------------
2019-04-22 23:34:13.663560 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 170 finished
-----------------------------  ---------------
replay_buffer/size              85700
trainer/QF1 Loss                  166.793
trainer/QF2 Loss                  167.12
trainer/Policy Loss                30.4818
trainer/Q1 Predictions Mean       -28.9999
trainer/Q1 Predictions Std         28.9644
trainer/Q1 Predictions Max         -8.93486
trainer/Q1 Predictions Min       -131.657
trainer/Q2 Predictions Mean       -29.0113
trainer/Q2 Predictions Std         28.9466
trainer/Q2 Predictions Max         -8.93515
trainer/Q2 Predictions Min       -130.576
trainer/Q Targets Mean            -26.9587
trainer/Q Targets Std              27.8486
trainer/Q Targets Max              -1.40353
trainer/Q Targets Min            -131.951
trainer/Log Pis Mean                1.94181
trainer/Log Pis Std                 1.55224
trainer/Log Pis Max                 6.57154
trainer/Log Pis Min                -3.88735
trainer/Policy mu Mean             -0.0207958
trainer/Policy mu Std               0.791867
trainer/Policy mu Max               3.17277
trainer/Policy mu Min              -3.10311
trainer/Policy log std Mean        -1.97931
trainer/Policy log std Std          0.543186
trainer/Policy log std Max         -0.387936
trainer/Policy log std Min         -2.59674
trainer/Alpha                       0.069456
trainer/Alpha Loss                 -0.155176
exploration/num steps total     85700
exploration/num paths total       857
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.721579
exploration/Rewards Std             0.84389
exploration/Rewards Max            -0.0195402
exploration/Rewards Min            -6.82458
exploration/Returns Mean          -72.1579
exploration/Returns Std            61.8126
exploration/Returns Max           -22.8577
exploration/Returns Min          -194.198
exploration/Actions Mean            0.00164297
exploration/Actions Std             0.207764
exploration/Actions Max             0.996652
exploration/Actions Min            -0.999894
exploration/Num Paths               5
exploration/Average Returns       -72.1579
evaluation/num steps total     256500
evaluation/num paths total       2565
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.75609
evaluation/Rewards Std              1.16884
evaluation/Rewards Max             -0.0421911
evaluation/Rewards Min             -8.90571
evaluation/Returns Mean           -75.609
evaluation/Returns Std             68.2947
evaluation/Returns Max            -12.7136
evaluation/Returns Min           -210.601
evaluation/Actions Mean             0.00482587
evaluation/Actions Std              0.194715
evaluation/Actions Max              0.999188
evaluation/Actions Min             -0.998549
evaluation/Num Paths               15
evaluation/Average Returns        -75.609
time/data storing (s)               0.00290695
time/evaluation sampling (s)        0.32409
time/exploration sampling (s)       0.141339
time/logging (s)                    0.00479335
time/saving (s)                     0.00973479
time/training (s)                   1.93664
time/epoch (s)                      2.4195
time/total (s)                    419.733
Epoch                             170
-----------------------------  ---------------
2019-04-22 23:34:16.084193 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 171 finished
-----------------------------  ---------------
replay_buffer/size              86200
trainer/QF1 Loss                    7.22897
trainer/QF2 Loss                    7.17249
trainer/Policy Loss                27.4489
trainer/Q1 Predictions Mean       -26.1061
trainer/Q1 Predictions Std         23.8877
trainer/Q1 Predictions Max         -8.81588
trainer/Q1 Predictions Min        -91.3358
trainer/Q2 Predictions Mean       -26.0863
trainer/Q2 Predictions Std         23.8862
trainer/Q2 Predictions Max         -8.75842
trainer/Q2 Predictions Min        -91.4049
trainer/Q Targets Mean            -26.0471
trainer/Q Targets Std              24.4669
trainer/Q Targets Max              -0.283969
trainer/Q Targets Min             -92.727
trainer/Log Pis Mean                2.05804
trainer/Log Pis Std                 1.17601
trainer/Log Pis Max                 6.38249
trainer/Log Pis Min                -1.46511
trainer/Policy mu Mean              0.0990434
trainer/Policy mu Std               0.683499
trainer/Policy mu Max               2.84796
trainer/Policy mu Min              -2.29965
trainer/Policy log std Mean        -2.00344
trainer/Policy log std Std          0.491756
trainer/Policy log std Max         -0.402952
trainer/Policy log std Min         -2.63543
trainer/Alpha                       0.0682963
trainer/Alpha Loss                  0.155759
exploration/num steps total     86200
exploration/num paths total       862
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.323385
exploration/Rewards Std             0.588019
exploration/Rewards Max            -0.00377254
exploration/Rewards Min            -6.30823
exploration/Returns Mean          -32.3385
exploration/Returns Std            15.2539
exploration/Returns Max           -15.3966
exploration/Returns Min           -58.2486
exploration/Actions Mean            0.00117357
exploration/Actions Std             0.205297
exploration/Actions Max             0.988151
exploration/Actions Min            -0.997714
exploration/Num Paths               5
exploration/Average Returns       -32.3385
evaluation/num steps total     258000
evaluation/num paths total       2580
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.464563
evaluation/Rewards Std              1.15863
evaluation/Rewards Max             -0.00490129
evaluation/Rewards Min            -10.7619
evaluation/Returns Mean           -46.4563
evaluation/Returns Std             52.0551
evaluation/Returns Max             -3.49973
evaluation/Returns Min           -230.374
evaluation/Actions Mean            -0.0174781
evaluation/Actions Std              0.193159
evaluation/Actions Max              0.998435
evaluation/Actions Min             -0.998664
evaluation/Num Paths               15
evaluation/Average Returns        -46.4563
time/data storing (s)               0.00287786
time/evaluation sampling (s)        0.328414
time/exploration sampling (s)       0.141888
time/logging (s)                    0.00480069
time/saving (s)                     0.00196342
time/training (s)                   1.93335
time/epoch (s)                      2.4133
time/total (s)                    422.151
Epoch                             171
-----------------------------  ---------------
2019-04-22 23:34:18.487326 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 172 finished
-----------------------------  ---------------
replay_buffer/size              86700
trainer/QF1 Loss                    1.15281
trainer/QF2 Loss                    1.19975
trainer/Policy Loss                27.6343
trainer/Q1 Predictions Mean       -25.9744
trainer/Q1 Predictions Std         25.9811
trainer/Q1 Predictions Max         -9.02437
trainer/Q1 Predictions Min       -125.52
trainer/Q2 Predictions Mean       -25.9508
trainer/Q2 Predictions Std         25.9608
trainer/Q2 Predictions Max         -8.95237
trainer/Q2 Predictions Min       -125.133
trainer/Q Targets Mean            -26.0699
trainer/Q Targets Std              26.2424
trainer/Q Targets Max              -0.17294
trainer/Q Targets Min            -128.397
trainer/Log Pis Mean                2.20838
trainer/Log Pis Std                 1.45419
trainer/Log Pis Max                 6.98644
trainer/Log Pis Min                -2.79767
trainer/Policy mu Mean              0.0131376
trainer/Policy mu Std               0.831001
trainer/Policy mu Max               3.57805
trainer/Policy mu Min              -2.98188
trainer/Policy log std Mean        -2.02175
trainer/Policy log std Std          0.574375
trainer/Policy log std Max         -0.240145
trainer/Policy log std Min         -2.75966
trainer/Alpha                       0.0674569
trainer/Alpha Loss                  0.561872
exploration/num steps total     86700
exploration/num paths total       867
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.316553
exploration/Rewards Std             0.325093
exploration/Rewards Max            -0.00682152
exploration/Rewards Min            -4.04713
exploration/Returns Mean          -31.6553
exploration/Returns Std            12.3451
exploration/Returns Max           -14.4094
exploration/Returns Min           -44.3928
exploration/Actions Mean           -0.00636822
exploration/Actions Std             0.184493
exploration/Actions Max             0.997537
exploration/Actions Min            -0.998551
exploration/Num Paths               5
exploration/Average Returns       -31.6553
evaluation/num steps total     259500
evaluation/num paths total       2595
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.703641
evaluation/Rewards Std              1.22843
evaluation/Rewards Max             -0.008589
evaluation/Rewards Min             -9.86213
evaluation/Returns Mean           -70.3641
evaluation/Returns Std             65.7468
evaluation/Returns Max            -13.1603
evaluation/Returns Min           -235.553
evaluation/Actions Mean             0.0128105
evaluation/Actions Std              0.209353
evaluation/Actions Max              0.999313
evaluation/Actions Min             -0.997883
evaluation/Num Paths               15
evaluation/Average Returns        -70.3641
time/data storing (s)               0.00277001
time/evaluation sampling (s)        0.322398
time/exploration sampling (s)       0.139736
time/logging (s)                    0.00476949
time/saving (s)                     0.00155306
time/training (s)                   1.92472
time/epoch (s)                      2.39595
time/total (s)                    424.551
Epoch                             172
-----------------------------  ---------------
2019-04-22 23:34:20.902017 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 173 finished
-----------------------------  ---------------
replay_buffer/size              87200
trainer/QF1 Loss                    5.73748
trainer/QF2 Loss                    5.63151
trainer/Policy Loss                32.2531
trainer/Q1 Predictions Mean       -31.0396
trainer/Q1 Predictions Std         27.8912
trainer/Q1 Predictions Max         -8.80827
trainer/Q1 Predictions Min        -98.6924
trainer/Q2 Predictions Mean       -31.0019
trainer/Q2 Predictions Std         27.8401
trainer/Q2 Predictions Max         -8.7819
trainer/Q2 Predictions Min        -98.3455
trainer/Q Targets Mean            -31.0253
trainer/Q Targets Std              28.1113
trainer/Q Targets Max              -0.617229
trainer/Q Targets Min             -98.8238
trainer/Log Pis Mean                2.0666
trainer/Log Pis Std                 1.51476
trainer/Log Pis Max                 8.04602
trainer/Log Pis Min                -2.70983
trainer/Policy mu Mean              0.0514371
trainer/Policy mu Std               0.928565
trainer/Policy mu Max               3.00486
trainer/Policy mu Min              -2.68292
trainer/Policy log std Mean        -1.84285
trainer/Policy log std Std          0.54275
trainer/Policy log std Max         -0.360506
trainer/Policy log std Min         -2.58926
trainer/Alpha                       0.0658666
trainer/Alpha Loss                  0.181161
exploration/num steps total     87200
exploration/num paths total       872
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.357136
exploration/Rewards Std             0.753797
exploration/Rewards Max            -0.0101222
exploration/Rewards Min            -8.52119
exploration/Returns Mean          -35.7136
exploration/Returns Std            11.0507
exploration/Returns Max           -20.0023
exploration/Returns Min           -48.8982
exploration/Actions Mean           -0.00828792
exploration/Actions Std             0.22335
exploration/Actions Max             0.999102
exploration/Actions Min            -0.998805
exploration/Num Paths               5
exploration/Average Returns       -35.7136
evaluation/num steps total     261000
evaluation/num paths total       2610
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.698638
evaluation/Rewards Std              1.20836
evaluation/Rewards Max             -0.0163234
evaluation/Rewards Min            -10.3115
evaluation/Returns Mean           -69.8638
evaluation/Returns Std             79.1535
evaluation/Returns Max            -10.9149
evaluation/Returns Min           -233.696
evaluation/Actions Mean            -0.0177836
evaluation/Actions Std              0.18871
evaluation/Actions Max              0.998987
evaluation/Actions Min             -0.997787
evaluation/Num Paths               15
evaluation/Average Returns        -69.8638
time/data storing (s)               0.00300564
time/evaluation sampling (s)        0.33171
time/exploration sampling (s)       0.139279
time/logging (s)                    0.00482965
time/saving (s)                     0.00177629
time/training (s)                   1.92693
time/epoch (s)                      2.40753
time/total (s)                    426.963
Epoch                             173
-----------------------------  ---------------
2019-04-22 23:34:23.292312 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 174 finished
-----------------------------  ---------------
replay_buffer/size              87700
trainer/QF1 Loss                    6.80778
trainer/QF2 Loss                    6.78641
trainer/Policy Loss                30.3871
trainer/Q1 Predictions Mean       -28.9437
trainer/Q1 Predictions Std         27.2601
trainer/Q1 Predictions Max         -8.66129
trainer/Q1 Predictions Min        -97.4693
trainer/Q2 Predictions Mean       -28.9448
trainer/Q2 Predictions Std         27.2636
trainer/Q2 Predictions Max         -8.59393
trainer/Q2 Predictions Min        -97.6091
trainer/Q Targets Mean            -29.0606
trainer/Q Targets Std              27.8492
trainer/Q Targets Max              -0.169452
trainer/Q Targets Min             -98.6553
trainer/Log Pis Mean                1.83312
trainer/Log Pis Std                 1.19983
trainer/Log Pis Max                 3.91672
trainer/Log Pis Min                -6.10739
trainer/Policy mu Mean              0.0235463
trainer/Policy mu Std               0.625248
trainer/Policy mu Max               3.44295
trainer/Policy mu Min              -2.59407
trainer/Policy log std Mean        -2.00502
trainer/Policy log std Std          0.469023
trainer/Policy log std Max         -0.0656538
trainer/Policy log std Min         -2.67124
trainer/Alpha                       0.0673824
trainer/Alpha Loss                 -0.450127
exploration/num steps total     87700
exploration/num paths total       877
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.489229
exploration/Rewards Std             0.956687
exploration/Rewards Max            -0.0172141
exploration/Rewards Min            -8.13725
exploration/Returns Mean          -48.9229
exploration/Returns Std            18.4298
exploration/Returns Max           -15.7744
exploration/Returns Min           -65.9661
exploration/Actions Mean            0.0315044
exploration/Actions Std             0.231447
exploration/Actions Max             0.999672
exploration/Actions Min            -0.923757
exploration/Num Paths               5
exploration/Average Returns       -48.9229
evaluation/num steps total     262500
evaluation/num paths total       2625
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.414258
evaluation/Rewards Std              0.699487
evaluation/Rewards Max             -0.0302164
evaluation/Rewards Min             -7.70981
evaluation/Returns Mean           -41.4258
evaluation/Returns Std             46.9373
evaluation/Returns Max            -10.4044
evaluation/Returns Min           -206.404
evaluation/Actions Mean             0.0033766
evaluation/Actions Std              0.143399
evaluation/Actions Max              0.998976
evaluation/Actions Min             -0.988793
evaluation/Num Paths               15
evaluation/Average Returns        -41.4258
time/data storing (s)               0.00272718
time/evaluation sampling (s)        0.331536
time/exploration sampling (s)       0.139093
time/logging (s)                    0.00487767
time/saving (s)                     0.0015567
time/training (s)                   1.90301
time/epoch (s)                      2.3828
time/total (s)                    429.35
Epoch                             174
-----------------------------  ---------------
2019-04-22 23:34:25.704955 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 175 finished
-----------------------------  ---------------
replay_buffer/size              88200
trainer/QF1 Loss                    3.76907
trainer/QF2 Loss                    3.72058
trainer/Policy Loss                29.4088
trainer/Q1 Predictions Mean       -27.7557
trainer/Q1 Predictions Std         27.0051
trainer/Q1 Predictions Max         -8.84917
trainer/Q1 Predictions Min        -95.1113
trainer/Q2 Predictions Mean       -27.7865
trainer/Q2 Predictions Std         26.9659
trainer/Q2 Predictions Max         -8.89469
trainer/Q2 Predictions Min        -94.9959
trainer/Q Targets Mean            -27.7473
trainer/Q Targets Std              27.286
trainer/Q Targets Max              -0.143797
trainer/Q Targets Min             -95.8921
trainer/Log Pis Mean                2.06513
trainer/Log Pis Std                 1.58231
trainer/Log Pis Max                 7.25137
trainer/Log Pis Min                -2.46312
trainer/Policy mu Mean              0.139105
trainer/Policy mu Std               0.883236
trainer/Policy mu Max               3.86272
trainer/Policy mu Min              -2.54058
trainer/Policy log std Mean        -1.87873
trainer/Policy log std Std          0.593401
trainer/Policy log std Max         -0.109648
trainer/Policy log std Min         -2.59504
trainer/Alpha                       0.065701
trainer/Alpha Loss                  0.177332
exploration/num steps total     88200
exploration/num paths total       882
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.510524
exploration/Rewards Std             1.35197
exploration/Rewards Max            -0.00993729
exploration/Rewards Min           -10.1737
exploration/Returns Mean          -51.0524
exploration/Returns Std            13.1602
exploration/Returns Max           -33.2088
exploration/Returns Min           -65.7782
exploration/Actions Mean            0.00944973
exploration/Actions Std             0.256017
exploration/Actions Max             0.999965
exploration/Actions Min            -0.997036
exploration/Num Paths               5
exploration/Average Returns       -51.0524
evaluation/num steps total     264000
evaluation/num paths total       2640
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.488904
evaluation/Rewards Std              1.00386
evaluation/Rewards Max             -0.0394129
evaluation/Rewards Min             -9.73609
evaluation/Returns Mean           -48.8904
evaluation/Returns Std             45.6416
evaluation/Returns Max            -13.8567
evaluation/Returns Min           -207.045
evaluation/Actions Mean             0.00854369
evaluation/Actions Std              0.179163
evaluation/Actions Max              0.995861
evaluation/Actions Min             -0.998258
evaluation/Num Paths               15
evaluation/Average Returns        -48.8904
time/data storing (s)               0.00281844
time/evaluation sampling (s)        0.327189
time/exploration sampling (s)       0.141581
time/logging (s)                    0.00478716
time/saving (s)                     0.00158146
time/training (s)                   1.92745
time/epoch (s)                      2.40541
time/total (s)                    431.76
Epoch                             175
-----------------------------  ---------------
2019-04-22 23:34:28.128675 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 176 finished
-----------------------------  ---------------
replay_buffer/size              88700
trainer/QF1 Loss                    3.04502
trainer/QF2 Loss                    2.98582
trainer/Policy Loss                30.4205
trainer/Q1 Predictions Mean       -29.1088
trainer/Q1 Predictions Std         26.9947
trainer/Q1 Predictions Max         -8.95012
trainer/Q1 Predictions Min        -93.9778
trainer/Q2 Predictions Mean       -29.1434
trainer/Q2 Predictions Std         26.9896
trainer/Q2 Predictions Max         -8.97091
trainer/Q2 Predictions Min        -94.2216
trainer/Q Targets Mean            -29.0631
trainer/Q Targets Std              27.5427
trainer/Q Targets Max              -0.0602562
trainer/Q Targets Min             -96.0402
trainer/Log Pis Mean                2.11499
trainer/Log Pis Std                 1.55405
trainer/Log Pis Max                 8.34741
trainer/Log Pis Min                -1.87084
trainer/Policy mu Mean              0.163891
trainer/Policy mu Std               0.972661
trainer/Policy mu Max               3.34238
trainer/Policy mu Min              -2.90178
trainer/Policy log std Mean        -1.87524
trainer/Policy log std Std          0.60995
trainer/Policy log std Max         -0.330557
trainer/Policy log std Min         -2.63175
trainer/Alpha                       0.0664018
trainer/Alpha Loss                  0.311879
exploration/num steps total     88700
exploration/num paths total       887
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.1309
exploration/Rewards Std             1.26344
exploration/Rewards Max            -0.0265539
exploration/Rewards Min            -9.2797
exploration/Returns Mean         -113.09
exploration/Returns Std            78.2185
exploration/Returns Max           -28.0214
exploration/Returns Min          -217.149
exploration/Actions Mean           -0.0176972
exploration/Actions Std             0.240729
exploration/Actions Max             0.99847
exploration/Actions Min            -0.998112
exploration/Num Paths               5
exploration/Average Returns      -113.09
evaluation/num steps total     265500
evaluation/num paths total       2655
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.701459
evaluation/Rewards Std              1.17589
evaluation/Rewards Max             -0.0362034
evaluation/Rewards Min            -11.3008
evaluation/Returns Mean           -70.1459
evaluation/Returns Std             71.5564
evaluation/Returns Max            -12.2107
evaluation/Returns Min           -227.605
evaluation/Actions Mean            -0.0103451
evaluation/Actions Std              0.183874
evaluation/Actions Max              0.998527
evaluation/Actions Min             -0.997782
evaluation/Num Paths               15
evaluation/Average Returns        -70.1459
time/data storing (s)               0.00299872
time/evaluation sampling (s)        0.333469
time/exploration sampling (s)       0.140072
time/logging (s)                    0.00480946
time/saving (s)                     0.00198699
time/training (s)                   1.93288
time/epoch (s)                      2.41621
time/total (s)                    434.181
Epoch                             176
-----------------------------  ---------------
2019-04-22 23:34:30.559363 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 177 finished
-----------------------------  ---------------
replay_buffer/size              89200
trainer/QF1 Loss                    6.4852
trainer/QF2 Loss                    6.53512
trainer/Policy Loss                28.9453
trainer/Q1 Predictions Mean       -27.562
trainer/Q1 Predictions Std         27.9858
trainer/Q1 Predictions Max         -8.78834
trainer/Q1 Predictions Min        -97.6336
trainer/Q2 Predictions Mean       -27.5728
trainer/Q2 Predictions Std         27.9842
trainer/Q2 Predictions Max         -8.83307
trainer/Q2 Predictions Min        -98.2305
trainer/Q Targets Mean            -27.5794
trainer/Q Targets Std              28.4409
trainer/Q Targets Max              -0.156827
trainer/Q Targets Min             -98.232
trainer/Log Pis Mean                1.83835
trainer/Log Pis Std                 1.23851
trainer/Log Pis Max                 5.52835
trainer/Log Pis Min                -1.84384
trainer/Policy mu Mean              0.00375794
trainer/Policy mu Std               0.704532
trainer/Policy mu Max               3.08071
trainer/Policy mu Min              -2.6003
trainer/Policy log std Mean        -1.98685
trainer/Policy log std Std          0.471809
trainer/Policy log std Max         -0.390457
trainer/Policy log std Min         -2.80838
trainer/Alpha                       0.0663891
trainer/Alpha Loss                 -0.438415
exploration/num steps total     89200
exploration/num paths total       892
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.306263
exploration/Rewards Std             0.888996
exploration/Rewards Max            -0.00468863
exploration/Rewards Min           -10.4256
exploration/Returns Mean          -30.6263
exploration/Returns Std            16.8723
exploration/Returns Max           -14.0718
exploration/Returns Min           -60.3295
exploration/Actions Mean           -0.0166696
exploration/Actions Std             0.205307
exploration/Actions Max             0.993674
exploration/Actions Min            -0.998729
exploration/Num Paths               5
exploration/Average Returns       -30.6263
evaluation/num steps total     267000
evaluation/num paths total       2670
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.583567
evaluation/Rewards Std              1.13409
evaluation/Rewards Max             -0.0117763
evaluation/Rewards Min            -10.0296
evaluation/Returns Mean           -58.3567
evaluation/Returns Std             61.755
evaluation/Returns Max             -5.35069
evaluation/Returns Min           -221.753
evaluation/Actions Mean             0.00816796
evaluation/Actions Std              0.204558
evaluation/Actions Max              0.997934
evaluation/Actions Min             -0.997712
evaluation/Num Paths               15
evaluation/Average Returns        -58.3567
time/data storing (s)               0.00299109
time/evaluation sampling (s)        0.329007
time/exploration sampling (s)       0.140913
time/logging (s)                    0.00467456
time/saving (s)                     0.00195269
time/training (s)                   1.94417
time/epoch (s)                      2.42371
time/total (s)                    436.608
Epoch                             177
-----------------------------  ---------------
2019-04-22 23:34:32.948948 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 178 finished
-----------------------------  ---------------
replay_buffer/size              89700
trainer/QF1 Loss                    5.72788
trainer/QF2 Loss                    5.73799
trainer/Policy Loss                30.9237
trainer/Q1 Predictions Mean       -29.1241
trainer/Q1 Predictions Std         27.2569
trainer/Q1 Predictions Max         -8.74799
trainer/Q1 Predictions Min        -93.0806
trainer/Q2 Predictions Mean       -29.0773
trainer/Q2 Predictions Std         27.2747
trainer/Q2 Predictions Max         -8.70427
trainer/Q2 Predictions Min        -93.1028
trainer/Q Targets Mean            -29.2688
trainer/Q Targets Std              27.8379
trainer/Q Targets Max              -0.825801
trainer/Q Targets Min             -93.7163
trainer/Log Pis Mean                2.3087
trainer/Log Pis Std                 1.07252
trainer/Log Pis Max                 7.09092
trainer/Log Pis Min                -1.79496
trainer/Policy mu Mean              0.0297778
trainer/Policy mu Std               0.841809
trainer/Policy mu Max               3.42328
trainer/Policy mu Min              -3.68926
trainer/Policy log std Mean        -1.93357
trainer/Policy log std Std          0.558467
trainer/Policy log std Max          0.0414419
trainer/Policy log std Min         -2.82901
trainer/Alpha                       0.0679093
trainer/Alpha Loss                  0.830339
exploration/num steps total     89700
exploration/num paths total       897
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.351155
exploration/Rewards Std             0.942969
exploration/Rewards Max            -0.01062
exploration/Rewards Min            -8.82745
exploration/Returns Mean          -35.1155
exploration/Returns Std            16.6467
exploration/Returns Max           -14.4677
exploration/Returns Min           -62.0114
exploration/Actions Mean            0.0218551
exploration/Actions Std             0.218053
exploration/Actions Max             0.999353
exploration/Actions Min            -0.997455
exploration/Num Paths               5
exploration/Average Returns       -35.1155
evaluation/num steps total     268500
evaluation/num paths total       2685
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.958688
evaluation/Rewards Std              1.27817
evaluation/Rewards Max             -0.0232051
evaluation/Rewards Min             -9.85824
evaluation/Returns Mean           -95.8688
evaluation/Returns Std             82.1253
evaluation/Returns Max            -10.1576
evaluation/Returns Min           -228.43
evaluation/Actions Mean             0.00374139
evaluation/Actions Std              0.19009
evaluation/Actions Max              0.999503
evaluation/Actions Min             -0.995416
evaluation/Num Paths               15
evaluation/Average Returns        -95.8688
time/data storing (s)               0.0028653
time/evaluation sampling (s)        0.330456
time/exploration sampling (s)       0.141046
time/logging (s)                    0.0048025
time/saving (s)                     0.00198078
time/training (s)                   1.90128
time/epoch (s)                      2.38243
time/total (s)                    438.995
Epoch                             178
-----------------------------  ---------------
2019-04-22 23:34:35.368429 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 179 finished
-----------------------------  ---------------
replay_buffer/size              90200
trainer/QF1 Loss                    5.48849
trainer/QF2 Loss                    5.48052
trainer/Policy Loss                25.4302
trainer/Q1 Predictions Mean       -24.1492
trainer/Q1 Predictions Std         24.6778
trainer/Q1 Predictions Max         -9.06215
trainer/Q1 Predictions Min        -97.2292
trainer/Q2 Predictions Mean       -24.1734
trainer/Q2 Predictions Std         24.6402
trainer/Q2 Predictions Max         -9.15537
trainer/Q2 Predictions Min        -96.3763
trainer/Q Targets Mean            -23.9406
trainer/Q Targets Std              25.0059
trainer/Q Targets Max              -0.683119
trainer/Q Targets Min             -96.0361
trainer/Log Pis Mean                1.64397
trainer/Log Pis Std                 1.30918
trainer/Log Pis Max                 4.31309
trainer/Log Pis Min                -4.27004
trainer/Policy mu Mean              0.0590546
trainer/Policy mu Std               0.659039
trainer/Policy mu Max               2.78133
trainer/Policy mu Min              -2.44753
trainer/Policy log std Mean        -1.93585
trainer/Policy log std Std          0.476207
trainer/Policy log std Max         -0.513585
trainer/Policy log std Min         -2.66616
trainer/Alpha                       0.0686579
trainer/Alpha Loss                 -0.953584
exploration/num steps total     90200
exploration/num paths total       902
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.821434
exploration/Rewards Std             1.20787
exploration/Rewards Max            -0.0214046
exploration/Rewards Min            -9.69431
exploration/Returns Mean          -82.1434
exploration/Returns Std            79.5456
exploration/Returns Max           -34.0247
exploration/Returns Min          -239.115
exploration/Actions Mean           -0.00661703
exploration/Actions Std             0.226473
exploration/Actions Max             0.993203
exploration/Actions Min            -0.999555
exploration/Num Paths               5
exploration/Average Returns       -82.1434
evaluation/num steps total     270000
evaluation/num paths total       2700
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.493268
evaluation/Rewards Std              0.944825
evaluation/Rewards Max             -0.0434218
evaluation/Rewards Min             -9.28928
evaluation/Returns Mean           -49.3268
evaluation/Returns Std             23.5828
evaluation/Returns Max            -17.1957
evaluation/Returns Min            -94.779
evaluation/Actions Mean             0.00712561
evaluation/Actions Std              0.180998
evaluation/Actions Max              0.999665
evaluation/Actions Min             -0.996924
evaluation/Num Paths               15
evaluation/Average Returns        -49.3268
time/data storing (s)               0.00277579
time/evaluation sampling (s)        0.329391
time/exploration sampling (s)       0.141243
time/logging (s)                    0.004791
time/saving (s)                     0.00197484
time/training (s)                   1.93166
time/epoch (s)                      2.41184
time/total (s)                    441.412
Epoch                             179
-----------------------------  ---------------
2019-04-22 23:34:37.776639 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 180 finished
-----------------------------  ---------------
replay_buffer/size              90700
trainer/QF1 Loss                    5.22759
trainer/QF2 Loss                    5.26754
trainer/Policy Loss                27.4677
trainer/Q1 Predictions Mean       -25.9469
trainer/Q1 Predictions Std         24.0389
trainer/Q1 Predictions Max         -8.84867
trainer/Q1 Predictions Min        -92.0529
trainer/Q2 Predictions Mean       -25.967
trainer/Q2 Predictions Std         24.0617
trainer/Q2 Predictions Max         -8.82845
trainer/Q2 Predictions Min        -92.1059
trainer/Q Targets Mean            -25.9276
trainer/Q Targets Std              24.4268
trainer/Q Targets Max              -0.397895
trainer/Q Targets Min             -93.2045
trainer/Log Pis Mean                2.06382
trainer/Log Pis Std                 1.21106
trainer/Log Pis Max                 6.50489
trainer/Log Pis Min                -0.927531
trainer/Policy mu Mean              0.0380264
trainer/Policy mu Std               0.820246
trainer/Policy mu Max               3.34772
trainer/Policy mu Min              -3.17202
trainer/Policy log std Mean        -1.98783
trainer/Policy log std Std          0.552849
trainer/Policy log std Max         -0.349558
trainer/Policy log std Min         -2.82257
trainer/Alpha                       0.0668658
trainer/Alpha Loss                  0.172638
exploration/num steps total     90700
exploration/num paths total       907
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.03089
exploration/Rewards Std             0.9278
exploration/Rewards Max            -0.0423875
exploration/Rewards Min            -6.09225
exploration/Returns Mean         -103.089
exploration/Returns Std            81.8566
exploration/Returns Max           -33.1556
exploration/Returns Min          -208.135
exploration/Actions Mean           -0.00608649
exploration/Actions Std             0.197575
exploration/Actions Max             0.999297
exploration/Actions Min            -0.997069
exploration/Num Paths               5
exploration/Average Returns      -103.089
evaluation/num steps total     271500
evaluation/num paths total       2715
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.461601
evaluation/Rewards Std              1.10958
evaluation/Rewards Max             -0.00293055
evaluation/Rewards Min             -9.21497
evaluation/Returns Mean           -46.1601
evaluation/Returns Std             51.9841
evaluation/Returns Max             -3.70429
evaluation/Returns Min           -226.371
evaluation/Actions Mean            -0.00173914
evaluation/Actions Std              0.18484
evaluation/Actions Max              0.999117
evaluation/Actions Min             -0.997694
evaluation/Num Paths               15
evaluation/Average Returns        -46.1601
time/data storing (s)               0.00281563
time/evaluation sampling (s)        0.332855
time/exploration sampling (s)       0.140331
time/logging (s)                    0.00479495
time/saving (s)                     0.00203665
time/training (s)                   1.91866
time/epoch (s)                      2.40149
time/total (s)                    443.817
Epoch                             180
-----------------------------  ---------------
2019-04-22 23:34:40.215524 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 181 finished
-----------------------------  ---------------
replay_buffer/size              91200
trainer/QF1 Loss                   86.3658
trainer/QF2 Loss                   86.2534
trainer/Policy Loss                32.1071
trainer/Q1 Predictions Mean       -30.8333
trainer/Q1 Predictions Std         29.9624
trainer/Q1 Predictions Max         -8.79375
trainer/Q1 Predictions Min        -99.1511
trainer/Q2 Predictions Mean       -30.8701
trainer/Q2 Predictions Std         29.9616
trainer/Q2 Predictions Max         -8.73555
trainer/Q2 Predictions Min        -99.2296
trainer/Q Targets Mean            -29.9959
trainer/Q Targets Std              29.8803
trainer/Q Targets Max              -0.46739
trainer/Q Targets Min             -98.5004
trainer/Log Pis Mean                1.69242
trainer/Log Pis Std                 1.3194
trainer/Log Pis Max                 7.69197
trainer/Log Pis Min                -2.6054
trainer/Policy mu Mean              0.0968916
trainer/Policy mu Std               0.715037
trainer/Policy mu Max               3.63234
trainer/Policy mu Min              -2.50509
trainer/Policy log std Mean        -1.94438
trainer/Policy log std Std          0.503353
trainer/Policy log std Max         -0.0133066
trainer/Policy log std Min         -2.87645
trainer/Alpha                       0.0660379
trainer/Alpha Loss                 -0.835836
exploration/num steps total     91200
exploration/num paths total       912
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.445655
exploration/Rewards Std             0.91631
exploration/Rewards Max            -0.00459819
exploration/Rewards Min            -7.93825
exploration/Returns Mean          -44.5655
exploration/Returns Std             7.48942
exploration/Returns Max           -37.3196
exploration/Returns Min           -55.4485
exploration/Actions Mean            0.0207202
exploration/Actions Std             0.210288
exploration/Actions Max             0.999265
exploration/Actions Min            -0.993659
exploration/Num Paths               5
exploration/Average Returns       -44.5655
evaluation/num steps total     273000
evaluation/num paths total       2730
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.406814
evaluation/Rewards Std              0.917404
evaluation/Rewards Max             -0.0012007
evaluation/Rewards Min             -8.93444
evaluation/Returns Mean           -40.6814
evaluation/Returns Std             46.0949
evaluation/Returns Max             -4.7449
evaluation/Returns Min           -199.938
evaluation/Actions Mean             0.0026449
evaluation/Actions Std              0.17242
evaluation/Actions Max              0.998132
evaluation/Actions Min             -0.99724
evaluation/Num Paths               15
evaluation/Average Returns        -40.6814
time/data storing (s)               0.00305695
time/evaluation sampling (s)        0.332748
time/exploration sampling (s)       0.140192
time/logging (s)                    0.00477455
time/saving (s)                     0.00157198
time/training (s)                   1.94884
time/epoch (s)                      2.43118
time/total (s)                    446.253
Epoch                             181
-----------------------------  ---------------
2019-04-22 23:34:42.661537 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 182 finished
-----------------------------  ---------------
replay_buffer/size              91700
trainer/QF1 Loss                    5.04077
trainer/QF2 Loss                    4.99414
trainer/Policy Loss                29.1151
trainer/Q1 Predictions Mean       -27.6446
trainer/Q1 Predictions Std         26.6951
trainer/Q1 Predictions Max         -8.78033
trainer/Q1 Predictions Min        -98.0718
trainer/Q2 Predictions Mean       -27.6788
trainer/Q2 Predictions Std         26.7055
trainer/Q2 Predictions Max         -8.86354
trainer/Q2 Predictions Min        -98.1702
trainer/Q Targets Mean            -27.6494
trainer/Q Targets Std              26.9597
trainer/Q Targets Max              -0.336931
trainer/Q Targets Min             -98.7576
trainer/Log Pis Mean                1.98321
trainer/Log Pis Std                 1.38678
trainer/Log Pis Max                 5.9729
trainer/Log Pis Min                -1.75186
trainer/Policy mu Mean              0.110833
trainer/Policy mu Std               0.818717
trainer/Policy mu Max               3.46626
trainer/Policy mu Min              -2.7034
trainer/Policy log std Mean        -1.94403
trainer/Policy log std Std          0.548333
trainer/Policy log std Max         -0.267021
trainer/Policy log std Min         -2.73075
trainer/Alpha                       0.0686881
trainer/Alpha Loss                 -0.0449609
exploration/num steps total     91700
exploration/num paths total       917
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.375354
exploration/Rewards Std             0.716015
exploration/Rewards Max            -0.00632289
exploration/Rewards Min            -6.94568
exploration/Returns Mean          -37.5354
exploration/Returns Std            15.7333
exploration/Returns Max           -18.5699
exploration/Returns Min           -58.7157
exploration/Actions Mean            0.0103733
exploration/Actions Std             0.21263
exploration/Actions Max             0.997926
exploration/Actions Min            -0.993825
exploration/Num Paths               5
exploration/Average Returns       -37.5354
evaluation/num steps total     274500
evaluation/num paths total       2745
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.439594
evaluation/Rewards Std              1.00421
evaluation/Rewards Max             -0.0148612
evaluation/Rewards Min            -10.0326
evaluation/Returns Mean           -43.9594
evaluation/Returns Std             43.9119
evaluation/Returns Max             -8.10828
evaluation/Returns Min           -194.943
evaluation/Actions Mean             0.0114497
evaluation/Actions Std              0.177399
evaluation/Actions Max              0.998791
evaluation/Actions Min             -0.998145
evaluation/Num Paths               15
evaluation/Average Returns        -43.9594
time/data storing (s)               0.00274157
time/evaluation sampling (s)        0.325155
time/exploration sampling (s)       0.139903
time/logging (s)                    0.00477905
time/saving (s)                     0.0110599
time/training (s)                   1.95474
time/epoch (s)                      2.43838
time/total (s)                    448.695
Epoch                             182
-----------------------------  ---------------
2019-04-22 23:34:45.079470 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 183 finished
-----------------------------  ---------------
replay_buffer/size              92200
trainer/QF1 Loss                   95.4622
trainer/QF2 Loss                   95.4537
trainer/Policy Loss                29.9898
trainer/Q1 Predictions Mean       -28.5521
trainer/Q1 Predictions Std         26.2958
trainer/Q1 Predictions Max         -8.64296
trainer/Q1 Predictions Min        -96.7338
trainer/Q2 Predictions Mean       -28.5193
trainer/Q2 Predictions Std         26.3181
trainer/Q2 Predictions Max         -8.59709
trainer/Q2 Predictions Min        -96.7177
trainer/Q Targets Mean            -27.4175
trainer/Q Targets Std              26.064
trainer/Q Targets Max              -0.508452
trainer/Q Targets Min             -95.1202
trainer/Log Pis Mean                1.93869
trainer/Log Pis Std                 1.47962
trainer/Log Pis Max                 8.08302
trainer/Log Pis Min                -1.92728
trainer/Policy mu Mean              0.0826086
trainer/Policy mu Std               0.838835
trainer/Policy mu Max               3.74807
trainer/Policy mu Min              -3.14456
trainer/Policy log std Mean        -1.91891
trainer/Policy log std Std          0.535783
trainer/Policy log std Max         -0.422263
trainer/Policy log std Min         -2.80533
trainer/Alpha                       0.0696361
trainer/Alpha Loss                 -0.16335
exploration/num steps total     92200
exploration/num paths total       922
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.461944
exploration/Rewards Std             1.10401
exploration/Rewards Max            -0.0102938
exploration/Rewards Min           -10.5326
exploration/Returns Mean          -46.1944
exploration/Returns Std            16.2632
exploration/Returns Max           -24.0036
exploration/Returns Min           -67.1286
exploration/Actions Mean            0.0202768
exploration/Actions Std             0.240655
exploration/Actions Max             0.999568
exploration/Actions Min            -0.999931
exploration/Num Paths               5
exploration/Average Returns       -46.1944
evaluation/num steps total     276000
evaluation/num paths total       2760
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.548102
evaluation/Rewards Std              1.06243
evaluation/Rewards Max             -0.0242954
evaluation/Rewards Min             -9.70983
evaluation/Returns Mean           -54.8102
evaluation/Returns Std             62.5859
evaluation/Returns Max             -8.40657
evaluation/Returns Min           -221.26
evaluation/Actions Mean            -0.0024516
evaluation/Actions Std              0.185666
evaluation/Actions Max              0.997211
evaluation/Actions Min             -0.998257
evaluation/Num Paths               15
evaluation/Average Returns        -54.8102
time/data storing (s)               0.00282334
time/evaluation sampling (s)        0.329345
time/exploration sampling (s)       0.138454
time/logging (s)                    0.00483756
time/saving (s)                     0.00195663
time/training (s)                   1.93302
time/epoch (s)                      2.41044
time/total (s)                    451.11
Epoch                             183
-----------------------------  ---------------
2019-04-22 23:34:47.486912 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 184 finished
-----------------------------  ---------------
replay_buffer/size              92700
trainer/QF1 Loss                    6.88299
trainer/QF2 Loss                    6.94339
trainer/Policy Loss                27.5626
trainer/Q1 Predictions Mean       -26.0984
trainer/Q1 Predictions Std         25.4731
trainer/Q1 Predictions Max         -8.8923
trainer/Q1 Predictions Min       -106.86
trainer/Q2 Predictions Mean       -26.1247
trainer/Q2 Predictions Std         25.5006
trainer/Q2 Predictions Max         -8.82839
trainer/Q2 Predictions Min       -107.44
trainer/Q Targets Mean            -25.87
trainer/Q Targets Std              25.6676
trainer/Q Targets Max              -0.929605
trainer/Q Targets Min            -106.887
trainer/Log Pis Mean                1.89374
trainer/Log Pis Std                 1.5942
trainer/Log Pis Max                 8.07768
trainer/Log Pis Min                -5.91996
trainer/Policy mu Mean             -0.0599052
trainer/Policy mu Std               0.713222
trainer/Policy mu Max               2.5477
trainer/Policy mu Min              -3.56249
trainer/Policy log std Mean        -2.05744
trainer/Policy log std Std          0.502818
trainer/Policy log std Max         -0.327899
trainer/Policy log std Min         -2.78013
trainer/Alpha                       0.0692984
trainer/Alpha Loss                 -0.28364
exploration/num steps total     92700
exploration/num paths total       927
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.304217
exploration/Rewards Std             0.811267
exploration/Rewards Max            -0.00184287
exploration/Rewards Min            -7.53296
exploration/Returns Mean          -30.4217
exploration/Returns Std             7.29584
exploration/Returns Max           -18.3586
exploration/Returns Min           -38.8816
exploration/Actions Mean           -0.00920512
exploration/Actions Std             0.228317
exploration/Actions Max             0.99932
exploration/Actions Min            -0.994665
exploration/Num Paths               5
exploration/Average Returns       -30.4217
evaluation/num steps total     277500
evaluation/num paths total       2775
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.789506
evaluation/Rewards Std              1.16994
evaluation/Rewards Max             -0.0349014
evaluation/Rewards Min             -9.74458
evaluation/Returns Mean           -78.9506
evaluation/Returns Std             68.9356
evaluation/Returns Max            -14.1072
evaluation/Returns Min           -211.474
evaluation/Actions Mean            -0.0041291
evaluation/Actions Std              0.191186
evaluation/Actions Max              0.997474
evaluation/Actions Min             -0.998824
evaluation/Num Paths               15
evaluation/Average Returns        -78.9506
time/data storing (s)               0.00300212
time/evaluation sampling (s)        0.329284
time/exploration sampling (s)       0.139558
time/logging (s)                    0.004774
time/saving (s)                     0.00197236
time/training (s)                   1.92118
time/epoch (s)                      2.39977
time/total (s)                    453.515
Epoch                             184
-----------------------------  ---------------
2019-04-22 23:34:49.907534 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 185 finished
-----------------------------  ----------------
replay_buffer/size              93200
trainer/QF1 Loss                   10.4983
trainer/QF2 Loss                   10.5068
trainer/Policy Loss                30.0504
trainer/Q1 Predictions Mean       -28.2146
trainer/Q1 Predictions Std         26.797
trainer/Q1 Predictions Max         -8.57064
trainer/Q1 Predictions Min        -97.9006
trainer/Q2 Predictions Mean       -28.2367
trainer/Q2 Predictions Std         26.7929
trainer/Q2 Predictions Max         -8.57844
trainer/Q2 Predictions Min        -98.0039
trainer/Q Targets Mean            -28.1876
trainer/Q Targets Std              27.4375
trainer/Q Targets Max              -0.489555
trainer/Q Targets Min             -99.9232
trainer/Log Pis Mean                2.3581
trainer/Log Pis Std                 1.33295
trainer/Log Pis Max                 7.69313
trainer/Log Pis Min                -1.30029
trainer/Policy mu Mean              0.111167
trainer/Policy mu Std               0.932662
trainer/Policy mu Max               3.47105
trainer/Policy mu Min              -2.91216
trainer/Policy log std Mean        -1.91802
trainer/Policy log std Std          0.597762
trainer/Policy log std Max         -0.36738
trainer/Policy log std Min         -2.80516
trainer/Alpha                       0.0690698
trainer/Alpha Loss                  0.957122
exploration/num steps total     93200
exploration/num paths total       932
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.75072
exploration/Rewards Std             1.23353
exploration/Rewards Max            -0.0137349
exploration/Rewards Min            -9.78561
exploration/Returns Mean          -75.072
exploration/Returns Std            70.1782
exploration/Returns Max           -20.3907
exploration/Returns Min          -212.259
exploration/Actions Mean           -0.0242109
exploration/Actions Std             0.228837
exploration/Actions Max             0.983319
exploration/Actions Min            -0.999191
exploration/Num Paths               5
exploration/Average Returns       -75.072
evaluation/num steps total     279000
evaluation/num paths total       2790
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.430328
evaluation/Rewards Std              1.20133
evaluation/Rewards Max             -0.0391034
evaluation/Rewards Min             -9.90472
evaluation/Returns Mean           -43.0328
evaluation/Returns Std             20.6326
evaluation/Returns Max             -9.78541
evaluation/Returns Min            -74.7952
evaluation/Actions Mean            -0.000776669
evaluation/Actions Std              0.204325
evaluation/Actions Max              0.999224
evaluation/Actions Min             -0.998632
evaluation/Num Paths               15
evaluation/Average Returns        -43.0328
time/data storing (s)               0.00298329
time/evaluation sampling (s)        0.33084
time/exploration sampling (s)       0.142357
time/logging (s)                    0.00482031
time/saving (s)                     0.00195109
time/training (s)                   1.93001
time/epoch (s)                      2.41296
time/total (s)                    455.932
Epoch                             185
-----------------------------  ----------------
2019-04-22 23:34:52.334527 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 186 finished
-----------------------------  ---------------
replay_buffer/size              93700
trainer/QF1 Loss                   82.1798
trainer/QF2 Loss                   82.2544
trainer/Policy Loss                33.1021
trainer/Q1 Predictions Mean       -31.7843
trainer/Q1 Predictions Std         30.9338
trainer/Q1 Predictions Max         -8.79543
trainer/Q1 Predictions Min       -103.407
trainer/Q2 Predictions Mean       -31.819
trainer/Q2 Predictions Std         30.9985
trainer/Q2 Predictions Max         -8.81986
trainer/Q2 Predictions Min       -104.457
trainer/Q Targets Mean            -31.244
trainer/Q Targets Std              31.024
trainer/Q Targets Max              -1.84108
trainer/Q Targets Min            -104.655
trainer/Log Pis Mean                1.7054
trainer/Log Pis Std                 1.3906
trainer/Log Pis Max                 7.07319
trainer/Log Pis Min                -2.17948
trainer/Policy mu Mean              0.0834553
trainer/Policy mu Std               0.840589
trainer/Policy mu Max               3.78625
trainer/Policy mu Min              -2.75043
trainer/Policy log std Mean        -1.84949
trainer/Policy log std Std          0.538347
trainer/Policy log std Max         -0.247917
trainer/Policy log std Min         -2.73849
trainer/Alpha                       0.0708853
trainer/Alpha Loss                 -0.779709
exploration/num steps total     93700
exploration/num paths total       937
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.691055
exploration/Rewards Std             1.05479
exploration/Rewards Max            -0.00447839
exploration/Rewards Min            -9.62156
exploration/Returns Mean          -69.1055
exploration/Returns Std            65.8155
exploration/Returns Max           -19.8975
exploration/Returns Min          -196.184
exploration/Actions Mean            0.0128234
exploration/Actions Std             0.217609
exploration/Actions Max             0.997266
exploration/Actions Min            -0.997681
exploration/Num Paths               5
exploration/Average Returns       -69.1055
evaluation/num steps total     280500
evaluation/num paths total       2805
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.823706
evaluation/Rewards Std              1.0854
evaluation/Rewards Max             -0.0384438
evaluation/Rewards Min             -9.56769
evaluation/Returns Mean           -82.3706
evaluation/Returns Std             80.6208
evaluation/Returns Max             -8.37787
evaluation/Returns Min           -225.944
evaluation/Actions Mean             0.0027619
evaluation/Actions Std              0.173811
evaluation/Actions Max              0.997983
evaluation/Actions Min             -0.998834
evaluation/Num Paths               15
evaluation/Average Returns        -82.3706
time/data storing (s)               0.00295717
time/evaluation sampling (s)        0.334932
time/exploration sampling (s)       0.139294
time/logging (s)                    0.00449145
time/saving (s)                     0.00198083
time/training (s)                   1.93539
time/epoch (s)                      2.41905
time/total (s)                    458.356
Epoch                             186
-----------------------------  ---------------
2019-04-22 23:34:54.764720 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 187 finished
-----------------------------  ---------------
replay_buffer/size              94200
trainer/QF1 Loss                    5.81326
trainer/QF2 Loss                    5.74973
trainer/Policy Loss                31.8427
trainer/Q1 Predictions Mean       -30.3963
trainer/Q1 Predictions Std         28.9975
trainer/Q1 Predictions Max         -8.97558
trainer/Q1 Predictions Min        -97.5325
trainer/Q2 Predictions Mean       -30.3798
trainer/Q2 Predictions Std         28.9659
trainer/Q2 Predictions Max         -9.05929
trainer/Q2 Predictions Min        -97.6509
trainer/Q Targets Mean            -30.1801
trainer/Q Targets Std              29.5801
trainer/Q Targets Max              -0.840825
trainer/Q Targets Min             -98.2679
trainer/Log Pis Mean                1.88317
trainer/Log Pis Std                 1.12326
trainer/Log Pis Max                 4.64631
trainer/Log Pis Min                -1.70579
trainer/Policy mu Mean             -0.066791
trainer/Policy mu Std               0.658149
trainer/Policy mu Max               2.57216
trainer/Policy mu Min              -2.40617
trainer/Policy log std Mean        -2.03486
trainer/Policy log std Std          0.478637
trainer/Policy log std Max         -0.353471
trainer/Policy log std Min         -2.5956
trainer/Alpha                       0.071602
trainer/Alpha Loss                 -0.308022
exploration/num steps total     94200
exploration/num paths total       942
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.328782
exploration/Rewards Std             0.576398
exploration/Rewards Max            -0.00733618
exploration/Rewards Min            -7.05806
exploration/Returns Mean          -32.8782
exploration/Returns Std            16.7241
exploration/Returns Max           -17.6572
exploration/Returns Min           -62.0138
exploration/Actions Mean            0.00793728
exploration/Actions Std             0.193153
exploration/Actions Max             0.995882
exploration/Actions Min            -0.978582
exploration/Num Paths               5
exploration/Average Returns       -32.8782
evaluation/num steps total     282000
evaluation/num paths total       2820
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.530199
evaluation/Rewards Std              1.18476
evaluation/Rewards Max             -0.0285518
evaluation/Rewards Min            -10.2053
evaluation/Returns Mean           -53.0199
evaluation/Returns Std             36.9174
evaluation/Returns Max            -10.2894
evaluation/Returns Min           -173.291
evaluation/Actions Mean             0.00781687
evaluation/Actions Std              0.203493
evaluation/Actions Max              0.999364
evaluation/Actions Min             -0.998672
evaluation/Num Paths               15
evaluation/Average Returns        -53.0199
time/data storing (s)               0.00275304
time/evaluation sampling (s)        0.325302
time/exploration sampling (s)       0.139976
time/logging (s)                    0.00486736
time/saving (s)                     0.00197005
time/training (s)                   1.94903
time/epoch (s)                      2.4239
time/total (s)                    460.783
Epoch                             187
-----------------------------  ---------------
2019-04-22 23:34:57.203060 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 188 finished
-----------------------------  ---------------
replay_buffer/size              94700
trainer/QF1 Loss                    0.0868345
trainer/QF2 Loss                    0.0926105
trainer/Policy Loss                28.29
trainer/Q1 Predictions Mean       -26.7471
trainer/Q1 Predictions Std         27.4366
trainer/Q1 Predictions Max         -8.63338
trainer/Q1 Predictions Min       -103.31
trainer/Q2 Predictions Mean       -26.7548
trainer/Q2 Predictions Std         27.4404
trainer/Q2 Predictions Max         -8.66847
trainer/Q2 Predictions Min       -103.012
trainer/Q Targets Mean            -26.8327
trainer/Q Targets Std              27.4541
trainer/Q Targets Max              -8.66462
trainer/Q Targets Min            -101.601
trainer/Log Pis Mean                2.10108
trainer/Log Pis Std                 1.1952
trainer/Log Pis Max                 6.72419
trainer/Log Pis Min                -0.841444
trainer/Policy mu Mean              0.0843488
trainer/Policy mu Std               0.804152
trainer/Policy mu Max               3.72243
trainer/Policy mu Min              -2.63739
trainer/Policy log std Mean        -2.02824
trainer/Policy log std Std          0.541177
trainer/Policy log std Max         -0.189975
trainer/Policy log std Min         -2.71304
trainer/Alpha                       0.0730988
trainer/Alpha Loss                  0.264439
exploration/num steps total     94700
exploration/num paths total       947
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.683654
exploration/Rewards Std             0.955331
exploration/Rewards Max            -0.00884391
exploration/Rewards Min            -7.26121
exploration/Returns Mean          -68.3654
exploration/Returns Std            59.2052
exploration/Returns Max           -26.5179
exploration/Returns Min          -186.021
exploration/Actions Mean            0.0233653
exploration/Actions Std             0.214661
exploration/Actions Max             0.998598
exploration/Actions Min            -0.995883
exploration/Num Paths               5
exploration/Average Returns       -68.3654
evaluation/num steps total     283500
evaluation/num paths total       2835
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.408967
evaluation/Rewards Std              1.04433
evaluation/Rewards Max             -0.0170296
evaluation/Rewards Min            -10.3411
evaluation/Returns Mean           -40.8967
evaluation/Returns Std             46.8289
evaluation/Returns Max             -4.54814
evaluation/Returns Min           -201.774
evaluation/Actions Mean            -0.0028122
evaluation/Actions Std              0.194627
evaluation/Actions Max              0.997267
evaluation/Actions Min             -0.997312
evaluation/Num Paths               15
evaluation/Average Returns        -40.8967
time/data storing (s)               0.00290905
time/evaluation sampling (s)        0.332295
time/exploration sampling (s)       0.141885
time/logging (s)                    0.00481632
time/saving (s)                     0.00197143
time/training (s)                   1.94688
time/epoch (s)                      2.43075
time/total (s)                    463.218
Epoch                             188
-----------------------------  ---------------
2019-04-22 23:34:59.622787 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 189 finished
-----------------------------  ---------------
replay_buffer/size              95200
trainer/QF1 Loss                   12.5784
trainer/QF2 Loss                   12.6401
trainer/Policy Loss                24.8559
trainer/Q1 Predictions Mean       -23.4966
trainer/Q1 Predictions Std         23.4035
trainer/Q1 Predictions Max         -8.81125
trainer/Q1 Predictions Min        -94.8998
trainer/Q2 Predictions Mean       -23.4688
trainer/Q2 Predictions Std         23.4278
trainer/Q2 Predictions Max         -8.83487
trainer/Q2 Predictions Min        -94.9543
trainer/Q Targets Mean            -22.9975
trainer/Q Targets Std              23.5872
trainer/Q Targets Max              -1.09547
trainer/Q Targets Min             -95.1768
trainer/Log Pis Mean                1.91973
trainer/Log Pis Std                 1.2496
trainer/Log Pis Max                 5.82446
trainer/Log Pis Min                -1.15793
trainer/Policy mu Mean              0.0340851
trainer/Policy mu Std               0.820232
trainer/Policy mu Max               2.76262
trainer/Policy mu Min              -3.09705
trainer/Policy log std Mean        -1.92434
trainer/Policy log std Std          0.535192
trainer/Policy log std Max         -0.615978
trainer/Policy log std Min         -2.71387
trainer/Alpha                       0.0733679
trainer/Alpha Loss                 -0.209676
exploration/num steps total     95200
exploration/num paths total       952
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.957287
exploration/Rewards Std             0.928986
exploration/Rewards Max            -0.0183719
exploration/Rewards Min            -6.58814
exploration/Returns Mean          -95.7287
exploration/Returns Std            78.1628
exploration/Returns Max           -26.0286
exploration/Returns Min          -192.353
exploration/Actions Mean            0.016619
exploration/Actions Std             0.209544
exploration/Actions Max             0.997152
exploration/Actions Min            -0.995237
exploration/Num Paths               5
exploration/Average Returns       -95.7287
evaluation/num steps total     285000
evaluation/num paths total       2850
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.693876
evaluation/Rewards Std              1.07825
evaluation/Rewards Max             -0.0286504
evaluation/Rewards Min             -9.17217
evaluation/Returns Mean           -69.3876
evaluation/Returns Std             65.896
evaluation/Returns Max             -5.07657
evaluation/Returns Min           -210.012
evaluation/Actions Mean             0.00265148
evaluation/Actions Std              0.170072
evaluation/Actions Max              0.998763
evaluation/Actions Min             -0.999305
evaluation/Num Paths               15
evaluation/Average Returns        -69.3876
time/data storing (s)               0.00277041
time/evaluation sampling (s)        0.324891
time/exploration sampling (s)       0.140519
time/logging (s)                    0.00480426
time/saving (s)                     0.00198308
time/training (s)                   1.93792
time/epoch (s)                      2.41289
time/total (s)                    465.635
Epoch                             189
-----------------------------  ---------------
2019-04-22 23:35:02.055952 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 190 finished
-----------------------------  ---------------
replay_buffer/size              95700
trainer/QF1 Loss                    0.445302
trainer/QF2 Loss                    0.37825
trainer/Policy Loss                31.4609
trainer/Q1 Predictions Mean       -29.9772
trainer/Q1 Predictions Std         30.6313
trainer/Q1 Predictions Max         -8.4435
trainer/Q1 Predictions Min       -104.818
trainer/Q2 Predictions Mean       -29.945
trainer/Q2 Predictions Std         30.6312
trainer/Q2 Predictions Max         -8.4496
trainer/Q2 Predictions Min       -104.969
trainer/Q Targets Mean            -30.3985
trainer/Q Targets Std              30.9172
trainer/Q Targets Max              -8.58394
trainer/Q Targets Min            -106.626
trainer/Log Pis Mean                1.97935
trainer/Log Pis Std                 1.45722
trainer/Log Pis Max                 7.29026
trainer/Log Pis Min                -2.58591
trainer/Policy mu Mean              0.0284997
trainer/Policy mu Std               0.817472
trainer/Policy mu Max               3.49887
trainer/Policy mu Min              -2.57133
trainer/Policy log std Mean        -1.94351
trainer/Policy log std Std          0.503343
trainer/Policy log std Max         -0.327513
trainer/Policy log std Min         -2.58521
trainer/Alpha                       0.0717883
trainer/Alpha Loss                 -0.0543868
exploration/num steps total     95700
exploration/num paths total       957
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.365536
exploration/Rewards Std             0.670608
exploration/Rewards Max            -0.00605111
exploration/Rewards Min            -7.48813
exploration/Returns Mean          -36.5536
exploration/Returns Std            14.8912
exploration/Returns Max           -19.0305
exploration/Returns Min           -55.0189
exploration/Actions Mean           -0.0142163
exploration/Actions Std             0.192007
exploration/Actions Max             0.988299
exploration/Actions Min            -0.999795
exploration/Num Paths               5
exploration/Average Returns       -36.5536
evaluation/num steps total     286500
evaluation/num paths total       2865
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.417426
evaluation/Rewards Std              1.0584
evaluation/Rewards Max             -0.00837919
evaluation/Rewards Min             -9.62906
evaluation/Returns Mean           -41.7426
evaluation/Returns Std             45.8379
evaluation/Returns Max             -9.08108
evaluation/Returns Min           -205.845
evaluation/Actions Mean            -0.00816873
evaluation/Actions Std              0.183359
evaluation/Actions Max              0.997541
evaluation/Actions Min             -0.997782
evaluation/Num Paths               15
evaluation/Average Returns        -41.7426
time/data storing (s)               0.00288378
time/evaluation sampling (s)        0.324675
time/exploration sampling (s)       0.146827
time/logging (s)                    0.00489092
time/saving (s)                     0.00196049
time/training (s)                   1.94456
time/epoch (s)                      2.4258
time/total (s)                    468.065
Epoch                             190
-----------------------------  ---------------
2019-04-22 23:35:04.475834 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 191 finished
-----------------------------  ---------------
replay_buffer/size              96200
trainer/QF1 Loss                   84.1381
trainer/QF2 Loss                   83.617
trainer/Policy Loss                34.4718
trainer/Q1 Predictions Mean       -32.6025
trainer/Q1 Predictions Std         32.2282
trainer/Q1 Predictions Max         -8.60866
trainer/Q1 Predictions Min       -113.418
trainer/Q2 Predictions Mean       -32.5107
trainer/Q2 Predictions Std         32.2026
trainer/Q2 Predictions Max         -8.47693
trainer/Q2 Predictions Min       -112.843
trainer/Q Targets Mean            -32.039
trainer/Q Targets Std              32.257
trainer/Q Targets Max              -2.31068
trainer/Q Targets Min            -115.851
trainer/Log Pis Mean                2.2681
trainer/Log Pis Std                 1.35266
trainer/Log Pis Max                 7.56471
trainer/Log Pis Min                -2.52066
trainer/Policy mu Mean              0.00190009
trainer/Policy mu Std               0.855878
trainer/Policy mu Max               3.25081
trainer/Policy mu Min              -3.4741
trainer/Policy log std Mean        -1.96484
trainer/Policy log std Std          0.568031
trainer/Policy log std Max         -0.335873
trainer/Policy log std Min         -2.76231
trainer/Alpha                       0.0673385
trainer/Alpha Loss                  0.723311
exploration/num steps total     96200
exploration/num paths total       962
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.624367
exploration/Rewards Std             0.824953
exploration/Rewards Max            -0.00662535
exploration/Rewards Min            -6.13153
exploration/Returns Mean          -62.4367
exploration/Returns Std            68.6673
exploration/Returns Max           -17.0036
exploration/Returns Min          -195.91
exploration/Actions Mean            0.00378189
exploration/Actions Std             0.189271
exploration/Actions Max             0.987882
exploration/Actions Min            -0.999834
exploration/Num Paths               5
exploration/Average Returns       -62.4367
evaluation/num steps total     288000
evaluation/num paths total       2880
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.275854
evaluation/Rewards Std              0.796886
evaluation/Rewards Max             -0.0129919
evaluation/Rewards Min             -8.95078
evaluation/Returns Mean           -27.5854
evaluation/Returns Std             13.7983
evaluation/Returns Max            -10.2395
evaluation/Returns Min            -51.2745
evaluation/Actions Mean             0.00722561
evaluation/Actions Std              0.180088
evaluation/Actions Max              0.998897
evaluation/Actions Min             -0.999496
evaluation/Num Paths               15
evaluation/Average Returns        -27.5854
time/data storing (s)               0.00293915
time/evaluation sampling (s)        0.326422
time/exploration sampling (s)       0.13946
time/logging (s)                    0.00480371
time/saving (s)                     0.00182715
time/training (s)                   1.93684
time/epoch (s)                      2.41229
time/total (s)                    470.481
Epoch                             191
-----------------------------  ---------------
2019-04-22 23:35:06.906922 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 192 finished
-----------------------------  ---------------
replay_buffer/size              96700
trainer/QF1 Loss                    2.68847
trainer/QF2 Loss                    2.74032
trainer/Policy Loss                32.5602
trainer/Q1 Predictions Mean       -31.3417
trainer/Q1 Predictions Std         32.5414
trainer/Q1 Predictions Max         -8.6715
trainer/Q1 Predictions Min       -129.291
trainer/Q2 Predictions Mean       -31.3232
trainer/Q2 Predictions Std         32.4811
trainer/Q2 Predictions Max         -8.76081
trainer/Q2 Predictions Min       -128.229
trainer/Q Targets Mean            -31.0836
trainer/Q Targets Std              32.7396
trainer/Q Targets Max              -0.192357
trainer/Q Targets Min            -131.253
trainer/Log Pis Mean                1.62533
trainer/Log Pis Std                 1.47618
trainer/Log Pis Max                 5.99819
trainer/Log Pis Min                -3.95371
trainer/Policy mu Mean             -0.0418578
trainer/Policy mu Std               0.638328
trainer/Policy mu Max               1.76611
trainer/Policy mu Min              -2.7886
trainer/Policy log std Mean        -2.03186
trainer/Policy log std Std          0.47021
trainer/Policy log std Max         -0.504413
trainer/Policy log std Min         -2.81347
trainer/Alpha                       0.066536
trainer/Alpha Loss                 -1.0153
exploration/num steps total     96700
exploration/num paths total       967
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.37681
exploration/Rewards Std             0.839008
exploration/Rewards Max            -0.00953719
exploration/Rewards Min            -7.41165
exploration/Returns Mean          -37.681
exploration/Returns Std             5.93243
exploration/Returns Max           -29.893
exploration/Returns Min           -46.5753
exploration/Actions Mean           -0.0126932
exploration/Actions Std             0.214543
exploration/Actions Max             0.993916
exploration/Actions Min            -0.999991
exploration/Num Paths               5
exploration/Average Returns       -37.681
evaluation/num steps total     289500
evaluation/num paths total       2895
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.845729
evaluation/Rewards Std              1.09994
evaluation/Rewards Max             -0.0101509
evaluation/Rewards Min            -10.4643
evaluation/Returns Mean           -84.5729
evaluation/Returns Std             77.7534
evaluation/Returns Max            -15.4077
evaluation/Returns Min           -211.633
evaluation/Actions Mean            -0.00825453
evaluation/Actions Std              0.179002
evaluation/Actions Max              0.997358
evaluation/Actions Min             -0.998938
evaluation/Num Paths               15
evaluation/Average Returns        -84.5729
time/data storing (s)               0.00359379
time/evaluation sampling (s)        0.326187
time/exploration sampling (s)       0.144073
time/logging (s)                    0.004872
time/saving (s)                     0.00195735
time/training (s)                   1.94293
time/epoch (s)                      2.42361
time/total (s)                    472.909
Epoch                             192
-----------------------------  ---------------
2019-04-22 23:35:09.327065 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 193 finished
-----------------------------  ---------------
replay_buffer/size              97200
trainer/QF1 Loss                    0.140296
trainer/QF2 Loss                    0.210431
trainer/Policy Loss                23.7573
trainer/Q1 Predictions Mean       -22.0502
trainer/Q1 Predictions Std         24.286
trainer/Q1 Predictions Max         -8.32557
trainer/Q1 Predictions Min       -111.506
trainer/Q2 Predictions Mean       -22.0469
trainer/Q2 Predictions Std         24.3331
trainer/Q2 Predictions Max         -8.36128
trainer/Q2 Predictions Min       -112.394
trainer/Q Targets Mean            -22.2576
trainer/Q Targets Std              24.325
trainer/Q Targets Max              -8.54705
trainer/Q Targets Min            -110.621
trainer/Log Pis Mean                2.09363
trainer/Log Pis Std                 1.22619
trainer/Log Pis Max                 5.84822
trainer/Log Pis Min                -3.73077
trainer/Policy mu Mean              0.077695
trainer/Policy mu Std               0.644064
trainer/Policy mu Max               3.68769
trainer/Policy mu Min              -3.08454
trainer/Policy log std Mean        -2.1227
trainer/Policy log std Std          0.469191
trainer/Policy log std Max         -0.64144
trainer/Policy log std Min         -2.78643
trainer/Alpha                       0.0674221
trainer/Alpha Loss                  0.252501
exploration/num steps total     97200
exploration/num paths total       972
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.474015
exploration/Rewards Std             1.07594
exploration/Rewards Max            -0.0113966
exploration/Rewards Min            -8.99627
exploration/Returns Mean          -47.4015
exploration/Returns Std            12.2258
exploration/Returns Max           -32.4316
exploration/Returns Min           -65.5157
exploration/Actions Mean            0.0151739
exploration/Actions Std             0.232769
exploration/Actions Max             0.999759
exploration/Actions Min            -0.999367
exploration/Num Paths               5
exploration/Average Returns       -47.4015
evaluation/num steps total     291000
evaluation/num paths total       2910
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.328819
evaluation/Rewards Std              0.937393
evaluation/Rewards Max             -0.0271662
evaluation/Rewards Min             -9.26042
evaluation/Returns Mean           -32.8819
evaluation/Returns Std             16.874
evaluation/Returns Max            -10.0103
evaluation/Returns Min            -60.0803
evaluation/Actions Mean             0.0102393
evaluation/Actions Std              0.188547
evaluation/Actions Max              0.999218
evaluation/Actions Min             -0.999325
evaluation/Num Paths               15
evaluation/Average Returns        -32.8819
time/data storing (s)               0.00279687
time/evaluation sampling (s)        0.326733
time/exploration sampling (s)       0.139776
time/logging (s)                    0.0035668
time/saving (s)                     0.00197505
time/training (s)                   1.93624
time/epoch (s)                      2.41109
time/total (s)                    475.324
Epoch                             193
-----------------------------  ---------------
2019-04-22 23:35:11.716280 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 194 finished
-----------------------------  ---------------
replay_buffer/size              97700
trainer/QF1 Loss                   88.7612
trainer/QF2 Loss                   88.6744
trainer/Policy Loss                27.3493
trainer/Q1 Predictions Mean       -25.8367
trainer/Q1 Predictions Std         28.8225
trainer/Q1 Predictions Max         -8.31844
trainer/Q1 Predictions Min       -127.711
trainer/Q2 Predictions Mean       -25.8446
trainer/Q2 Predictions Std         28.8112
trainer/Q2 Predictions Max         -8.28467
trainer/Q2 Predictions Min       -126.999
trainer/Q Targets Mean            -25.1737
trainer/Q Targets Std              28.7675
trainer/Q Targets Max              -0.438571
trainer/Q Targets Min            -131.44
trainer/Log Pis Mean                1.88985
trainer/Log Pis Std                 1.36207
trainer/Log Pis Max                 5.43584
trainer/Log Pis Min                -2.49532
trainer/Policy mu Mean              0.0933378
trainer/Policy mu Std               0.781712
trainer/Policy mu Max               3.59255
trainer/Policy mu Min              -3.48185
trainer/Policy log std Mean        -1.98464
trainer/Policy log std Std          0.540354
trainer/Policy log std Max         -0.194473
trainer/Policy log std Min         -2.78873
trainer/Alpha                       0.0675878
trainer/Alpha Loss                 -0.296786
exploration/num steps total     97700
exploration/num paths total       977
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.604975
exploration/Rewards Std             0.909032
exploration/Rewards Max            -0.00408946
exploration/Rewards Min            -6.874
exploration/Returns Mean          -60.4975
exploration/Returns Std            75.7456
exploration/Returns Max           -17.5461
exploration/Returns Min          -211.742
exploration/Actions Mean           -0.00800357
exploration/Actions Std             0.211037
exploration/Actions Max             0.955941
exploration/Actions Min            -0.998036
exploration/Num Paths               5
exploration/Average Returns       -60.4975
evaluation/num steps total     292500
evaluation/num paths total       2925
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.57154
evaluation/Rewards Std              1.13884
evaluation/Rewards Max             -0.00278609
evaluation/Rewards Min            -11.2141
evaluation/Returns Mean           -57.154
evaluation/Returns Std             60.6731
evaluation/Returns Max             -6.09456
evaluation/Returns Min           -204.315
evaluation/Actions Mean            -0.0159947
evaluation/Actions Std              0.184726
evaluation/Actions Max              0.99739
evaluation/Actions Min             -0.99856
evaluation/Num Paths               15
evaluation/Average Returns        -57.154
time/data storing (s)               0.00272106
time/evaluation sampling (s)        0.331805
time/exploration sampling (s)       0.138555
time/logging (s)                    0.00357313
time/saving (s)                     0.00197238
time/training (s)                   1.90476
time/epoch (s)                      2.38338
time/total (s)                    477.711
Epoch                             194
-----------------------------  ---------------
2019-04-22 23:35:14.159747 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 195 finished
-----------------------------  ---------------
replay_buffer/size              98200
trainer/QF1 Loss                    4.2694
trainer/QF2 Loss                    4.21296
trainer/Policy Loss                26.5324
trainer/Q1 Predictions Mean       -25.1458
trainer/Q1 Predictions Std         28.343
trainer/Q1 Predictions Max         -8.56752
trainer/Q1 Predictions Min        -97.2435
trainer/Q2 Predictions Mean       -25.15
trainer/Q2 Predictions Std         28.3794
trainer/Q2 Predictions Max         -8.5561
trainer/Q2 Predictions Min        -97.3868
trainer/Q Targets Mean            -25.0312
trainer/Q Targets Std              28.6746
trainer/Q Targets Max              -0.574509
trainer/Q Targets Min             -97.834
trainer/Log Pis Mean                1.85115
trainer/Log Pis Std                 1.36749
trainer/Log Pis Max                 5.69434
trainer/Log Pis Min                -3.28479
trainer/Policy mu Mean              0.0639889
trainer/Policy mu Std               0.691327
trainer/Policy mu Max               2.74274
trainer/Policy mu Min              -2.29719
trainer/Policy log std Mean        -2.05543
trainer/Policy log std Std          0.550046
trainer/Policy log std Max         -0.58218
trainer/Policy log std Min         -2.92434
trainer/Alpha                       0.0674524
trainer/Alpha Loss                 -0.401353
exploration/num steps total     98200
exploration/num paths total       982
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.720776
exploration/Rewards Std             1.10175
exploration/Rewards Max            -0.00396524
exploration/Rewards Min            -8.72074
exploration/Returns Mean          -72.0776
exploration/Returns Std            61.0738
exploration/Returns Max           -23.5628
exploration/Returns Min          -190.672
exploration/Actions Mean           -0.00912342
exploration/Actions Std             0.246397
exploration/Actions Max             0.999634
exploration/Actions Min            -0.998387
exploration/Num Paths               5
exploration/Average Returns       -72.0776
evaluation/num steps total     294000
evaluation/num paths total       2940
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.510733
evaluation/Rewards Std              0.969064
evaluation/Rewards Max             -0.0106093
evaluation/Rewards Min            -10.8862
evaluation/Returns Mean           -51.0733
evaluation/Returns Std             57.9441
evaluation/Returns Max            -12.1226
evaluation/Returns Min           -198.316
evaluation/Actions Mean             0.00995931
evaluation/Actions Std              0.167317
evaluation/Actions Max              0.998648
evaluation/Actions Min             -0.995639
evaluation/Num Paths               15
evaluation/Average Returns        -51.0733
time/data storing (s)               0.00287378
time/evaluation sampling (s)        0.354293
time/exploration sampling (s)       0.139067
time/logging (s)                    0.0048278
time/saving (s)                     0.0105733
time/training (s)                   1.92561
time/epoch (s)                      2.43724
time/total (s)                    480.153
Epoch                             195
-----------------------------  ---------------
2019-04-22 23:35:16.551259 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 196 finished
-----------------------------  ---------------
replay_buffer/size              98700
trainer/QF1 Loss                    0.196143
trainer/QF2 Loss                    0.211066
trainer/Policy Loss                24.3273
trainer/Q1 Predictions Mean       -22.617
trainer/Q1 Predictions Std         23.5849
trainer/Q1 Predictions Max         -8.28015
trainer/Q1 Predictions Min        -99.0336
trainer/Q2 Predictions Mean       -22.6271
trainer/Q2 Predictions Std         23.5622
trainer/Q2 Predictions Max         -8.34494
trainer/Q2 Predictions Min        -98.9364
trainer/Q Targets Mean            -22.8712
trainer/Q Targets Std              23.7888
trainer/Q Targets Max              -8.62832
trainer/Q Targets Min             -99.8914
trainer/Log Pis Mean                2.13569
trainer/Log Pis Std                 1.18563
trainer/Log Pis Max                 7.50669
trainer/Log Pis Min                -1.11885
trainer/Policy mu Mean              0.0678428
trainer/Policy mu Std               0.82466
trainer/Policy mu Max               3.01606
trainer/Policy mu Min              -3.93437
trainer/Policy log std Mean        -1.97896
trainer/Policy log std Std          0.56893
trainer/Policy log std Max         -0.207951
trainer/Policy log std Min         -2.63878
trainer/Alpha                       0.0685636
trainer/Alpha Loss                  0.363643
exploration/num steps total     98700
exploration/num paths total       987
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.348974
exploration/Rewards Std             0.885781
exploration/Rewards Max            -0.00704471
exploration/Rewards Min            -9.20081
exploration/Returns Mean          -34.8974
exploration/Returns Std            17.4217
exploration/Returns Max           -20.3279
exploration/Returns Min           -68.9649
exploration/Actions Mean           -0.00767512
exploration/Actions Std             0.225204
exploration/Actions Max             0.998651
exploration/Actions Min            -0.999648
exploration/Num Paths               5
exploration/Average Returns       -34.8974
evaluation/num steps total     295500
evaluation/num paths total       2955
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.682102
evaluation/Rewards Std              0.987224
evaluation/Rewards Max             -0.0127723
evaluation/Rewards Min             -8.4845
evaluation/Returns Mean           -68.2102
evaluation/Returns Std             75.6635
evaluation/Returns Max             -4.47337
evaluation/Returns Min           -205.648
evaluation/Actions Mean            -0.00181962
evaluation/Actions Std              0.170385
evaluation/Actions Max              0.997653
evaluation/Actions Min             -0.996993
evaluation/Num Paths               15
evaluation/Average Returns        -68.2102
time/data storing (s)               0.00296561
time/evaluation sampling (s)        0.331589
time/exploration sampling (s)       0.139003
time/logging (s)                    0.00477995
time/saving (s)                     0.0019668
time/training (s)                   1.90398
time/epoch (s)                      2.38428
time/total (s)                    482.541
Epoch                             196
-----------------------------  ---------------
2019-04-22 23:35:18.981757 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 197 finished
-----------------------------  ---------------
replay_buffer/size              99200
trainer/QF1 Loss                    3.79728
trainer/QF2 Loss                    3.80852
trainer/Policy Loss                27.2856
trainer/Q1 Predictions Mean       -25.9086
trainer/Q1 Predictions Std         28.8586
trainer/Q1 Predictions Max         -8.6609
trainer/Q1 Predictions Min       -135.786
trainer/Q2 Predictions Mean       -25.9101
trainer/Q2 Predictions Std         28.8604
trainer/Q2 Predictions Max         -8.71906
trainer/Q2 Predictions Min       -136.311
trainer/Q Targets Mean            -25.8716
trainer/Q Targets Std              29.0288
trainer/Q Targets Max              -0.390835
trainer/Q Targets Min            -137.115
trainer/Log Pis Mean                1.85526
trainer/Log Pis Std                 1.39445
trainer/Log Pis Max                 6.51051
trainer/Log Pis Min                -2.68604
trainer/Policy mu Mean             -0.00535624
trainer/Policy mu Std               0.819905
trainer/Policy mu Max               3.39723
trainer/Policy mu Min              -3.10516
trainer/Policy log std Mean        -1.91552
trainer/Policy log std Std          0.574021
trainer/Policy log std Max         -0.176423
trainer/Policy log std Min         -2.74962
trainer/Alpha                       0.0677394
trainer/Alpha Loss                 -0.389618
exploration/num steps total     99200
exploration/num paths total       992
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.10708
exploration/Rewards Std             1.40245
exploration/Rewards Max            -0.00968181
exploration/Rewards Min           -10.3891
exploration/Returns Mean         -110.708
exploration/Returns Std            82.3507
exploration/Returns Max           -28.4969
exploration/Returns Min          -222.709
exploration/Actions Mean           -0.020277
exploration/Actions Std             0.26485
exploration/Actions Max             0.996399
exploration/Actions Min            -0.999627
exploration/Num Paths               5
exploration/Average Returns      -110.708
evaluation/num steps total     297000
evaluation/num paths total       2970
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.292434
evaluation/Rewards Std              0.86089
evaluation/Rewards Max             -0.0278145
evaluation/Rewards Min             -9.9899
evaluation/Returns Mean           -29.2434
evaluation/Returns Std             15.4791
evaluation/Returns Max             -7.32288
evaluation/Returns Min            -68.3087
evaluation/Actions Mean             0.0101913
evaluation/Actions Std              0.180816
evaluation/Actions Max              0.997602
evaluation/Actions Min             -0.999042
evaluation/Num Paths               15
evaluation/Average Returns        -29.2434
time/data storing (s)               0.00295088
time/evaluation sampling (s)        0.328807
time/exploration sampling (s)       0.143122
time/logging (s)                    0.00479558
time/saving (s)                     0.00194187
time/training (s)                   1.94101
time/epoch (s)                      2.42263
time/total (s)                    484.969
Epoch                             197
-----------------------------  ---------------
2019-04-22 23:35:21.400193 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 198 finished
-----------------------------  ---------------
replay_buffer/size              99700
trainer/QF1 Loss                    0.561319
trainer/QF2 Loss                    0.512118
trainer/Policy Loss                22.9064
trainer/Q1 Predictions Mean       -21.2632
trainer/Q1 Predictions Std         20.7547
trainer/Q1 Predictions Max         -8.50489
trainer/Q1 Predictions Min        -97.7512
trainer/Q2 Predictions Mean       -21.2735
trainer/Q2 Predictions Std         20.7762
trainer/Q2 Predictions Max         -8.55536
trainer/Q2 Predictions Min        -97.7778
trainer/Q Targets Mean            -21.6272
trainer/Q Targets Std              21.3008
trainer/Q Targets Max              -8.41202
trainer/Q Targets Min             -99.2595
trainer/Log Pis Mean                2.31704
trainer/Log Pis Std                 1.48376
trainer/Log Pis Max                 7.55971
trainer/Log Pis Min                -3.19059
trainer/Policy mu Mean              0.0624633
trainer/Policy mu Std               0.968481
trainer/Policy mu Max               2.95351
trainer/Policy mu Min              -3.12201
trainer/Policy log std Mean        -1.90264
trainer/Policy log std Std          0.646177
trainer/Policy log std Max         -0.334491
trainer/Policy log std Min         -2.87625
trainer/Alpha                       0.0659362
trainer/Alpha Loss                  0.862057
exploration/num steps total     99700
exploration/num paths total       997
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.596584
exploration/Rewards Std             0.851354
exploration/Rewards Max            -0.0154565
exploration/Rewards Min            -5.84869
exploration/Returns Mean          -59.6584
exploration/Returns Std            62.795
exploration/Returns Max           -19.5052
exploration/Returns Min          -184.873
exploration/Actions Mean           -0.00614776
exploration/Actions Std             0.222878
exploration/Actions Max             0.99904
exploration/Actions Min            -0.999952
exploration/Num Paths               5
exploration/Average Returns       -59.6584
evaluation/num steps total     298500
evaluation/num paths total       2985
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.364832
evaluation/Rewards Std              1.06578
evaluation/Rewards Max             -0.0087418
evaluation/Rewards Min             -9.52932
evaluation/Returns Mean           -36.4832
evaluation/Returns Std             19.3579
evaluation/Returns Max             -7.12294
evaluation/Returns Min            -62.8548
evaluation/Actions Mean            -0.0141205
evaluation/Actions Std              0.183223
evaluation/Actions Max              0.998727
evaluation/Actions Min             -0.99937
evaluation/Num Paths               15
evaluation/Average Returns        -36.4832
time/data storing (s)               0.00278522
time/evaluation sampling (s)        0.32689
time/exploration sampling (s)       0.140202
time/logging (s)                    0.00482951
time/saving (s)                     0.00198952
time/training (s)                   1.93396
time/epoch (s)                      2.41066
time/total (s)                    487.384
Epoch                             198
-----------------------------  ---------------
2019-04-22 23:35:23.794362 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 199 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.24893
trainer/QF2 Loss                    1.27518
trainer/Policy Loss                27.1964
trainer/Q1 Predictions Mean       -25.8743
trainer/Q1 Predictions Std         29.0015
trainer/Q1 Predictions Max         -8.03553
trainer/Q1 Predictions Min        -96.6251
trainer/Q2 Predictions Mean       -25.8528
trainer/Q2 Predictions Std         28.9599
trainer/Q2 Predictions Max         -7.98438
trainer/Q2 Predictions Min        -96.4026
trainer/Q Targets Mean            -26.466
trainer/Q Targets Std              29.8406
trainer/Q Targets Max              -8.41542
trainer/Q Targets Min             -99.7638
trainer/Log Pis Mean                1.76246
trainer/Log Pis Std                 1.14359
trainer/Log Pis Max                 6.81318
trainer/Log Pis Min                -1.12586
trainer/Policy mu Mean              0.1085
trainer/Policy mu Std               0.660772
trainer/Policy mu Max               3.70768
trainer/Policy mu Min              -2.23312
trainer/Policy log std Mean        -2.06181
trainer/Policy log std Std          0.483892
trainer/Policy log std Max         -0.159834
trainer/Policy log std Min         -2.77492
trainer/Alpha                       0.0670189
trainer/Alpha Loss                 -0.642019
exploration/num steps total    100200
exploration/num paths total      1002
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.702863
exploration/Rewards Std             1.07436
exploration/Rewards Max            -0.0118158
exploration/Rewards Min            -8.771
exploration/Returns Mean          -70.2863
exploration/Returns Std            66.2683
exploration/Returns Max           -35.0245
exploration/Returns Min          -202.764
exploration/Actions Mean           -0.011358
exploration/Actions Std             0.238383
exploration/Actions Max             0.997771
exploration/Actions Min            -0.999227
exploration/Num Paths               5
exploration/Average Returns       -70.2863
evaluation/num steps total     300000
evaluation/num paths total       3000
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.481096
evaluation/Rewards Std              0.998121
evaluation/Rewards Max             -0.0165928
evaluation/Rewards Min             -9.3824
evaluation/Returns Mean           -48.1096
evaluation/Returns Std             54.4722
evaluation/Returns Max             -7.87145
evaluation/Returns Min           -183.88
evaluation/Actions Mean            -0.0112131
evaluation/Actions Std              0.168449
evaluation/Actions Max              0.997808
evaluation/Actions Min             -0.998728
evaluation/Num Paths               15
evaluation/Average Returns        -48.1096
time/data storing (s)               0.00269625
time/evaluation sampling (s)        0.330141
time/exploration sampling (s)       0.138596
time/logging (s)                    0.00481029
time/saving (s)                     0.00195087
time/training (s)                   1.90814
time/epoch (s)                      2.38634
time/total (s)                    489.775
Epoch                             199
-----------------------------  ---------------
2019-04-22 23:35:26.220367 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 200 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.883089
trainer/QF2 Loss                    0.836526
trainer/Policy Loss                31.1797
trainer/Q1 Predictions Mean       -29.8106
trainer/Q1 Predictions Std         31.5678
trainer/Q1 Predictions Max         -8.55895
trainer/Q1 Predictions Min        -97.5716
trainer/Q2 Predictions Mean       -29.8473
trainer/Q2 Predictions Std         31.5719
trainer/Q2 Predictions Max         -8.55731
trainer/Q2 Predictions Min        -97.7787
trainer/Q Targets Mean            -29.8689
trainer/Q Targets Std              31.8496
trainer/Q Targets Max              -0.186779
trainer/Q Targets Min             -98.4262
trainer/Log Pis Mean                1.97388
trainer/Log Pis Std                 1.29565
trainer/Log Pis Max                 6.1382
trainer/Log Pis Min                -1.25514
trainer/Policy mu Mean              0.11873
trainer/Policy mu Std               0.767272
trainer/Policy mu Max               2.70856
trainer/Policy mu Min              -3.00944
trainer/Policy log std Mean        -1.94873
trainer/Policy log std Std          0.555914
trainer/Policy log std Max         -0.427167
trainer/Policy log std Min         -2.77137
trainer/Alpha                       0.0674671
trainer/Alpha Loss                 -0.0704192
exploration/num steps total    100700
exploration/num paths total      1007
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.32462
exploration/Rewards Std             1.00601
exploration/Rewards Max            -0.0231156
exploration/Rewards Min            -7.75682
exploration/Returns Mean         -132.462
exploration/Returns Std            86.469
exploration/Returns Max           -21.9105
exploration/Returns Min          -212.452
exploration/Actions Mean           -0.00762228
exploration/Actions Std             0.212706
exploration/Actions Max             0.99183
exploration/Actions Min            -0.999626
exploration/Num Paths               5
exploration/Average Returns      -132.462
evaluation/num steps total     301500
evaluation/num paths total       3015
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.373004
evaluation/Rewards Std              0.926583
evaluation/Rewards Max             -0.027575
evaluation/Rewards Min             -9.93614
evaluation/Returns Mean           -37.3004
evaluation/Returns Std             47.711
evaluation/Returns Max             -4.73173
evaluation/Returns Min           -204.71
evaluation/Actions Mean            -0.000658468
evaluation/Actions Std              0.169935
evaluation/Actions Max              0.99645
evaluation/Actions Min             -0.997121
evaluation/Num Paths               15
evaluation/Average Returns        -37.3004
time/data storing (s)               0.00260895
time/evaluation sampling (s)        0.330812
time/exploration sampling (s)       0.140541
time/logging (s)                    0.00486217
time/saving (s)                     0.0019398
time/training (s)                   1.93742
time/epoch (s)                      2.41819
time/total (s)                    492.197
Epoch                             200
-----------------------------  ----------------
2019-04-22 23:35:28.638340 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 201 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.22542
trainer/QF2 Loss                    0.221266
trainer/Policy Loss                24.0499
trainer/Q1 Predictions Mean       -22.63
trainer/Q1 Predictions Std         24.1433
trainer/Q1 Predictions Max         -8.63981
trainer/Q1 Predictions Min        -93.9011
trainer/Q2 Predictions Mean       -22.7042
trainer/Q2 Predictions Std         24.1558
trainer/Q2 Predictions Max         -8.63178
trainer/Q2 Predictions Min        -94.0104
trainer/Q Targets Mean            -22.795
trainer/Q Targets Std              24.5336
trainer/Q Targets Max              -8.46374
trainer/Q Targets Min             -95.4801
trainer/Log Pis Mean                1.80378
trainer/Log Pis Std                 1.24269
trainer/Log Pis Max                 5.90569
trainer/Log Pis Min                -2.18252
trainer/Policy mu Mean              0.0558514
trainer/Policy mu Std               0.749348
trainer/Policy mu Max               3.10417
trainer/Policy mu Min              -2.95316
trainer/Policy log std Mean        -1.9733
trainer/Policy log std Std          0.517876
trainer/Policy log std Max         -0.463053
trainer/Policy log std Min         -2.83321
trainer/Alpha                       0.0663444
trainer/Alpha Loss                 -0.532277
exploration/num steps total    101200
exploration/num paths total      1012
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.859546
exploration/Rewards Std             1.46451
exploration/Rewards Max            -0.0174311
exploration/Rewards Min           -11.1601
exploration/Returns Mean          -85.9546
exploration/Returns Std            53.3649
exploration/Returns Max           -32.7761
exploration/Returns Min          -188.099
exploration/Actions Mean           -0.00184339
exploration/Actions Std             0.254601
exploration/Actions Max             0.996904
exploration/Actions Min            -0.998055
exploration/Num Paths               5
exploration/Average Returns       -85.9546
evaluation/num steps total     303000
evaluation/num paths total       3030
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.382185
evaluation/Rewards Std              0.967961
evaluation/Rewards Max             -0.0100451
evaluation/Rewards Min             -9.13354
evaluation/Returns Mean           -38.2185
evaluation/Returns Std             46.5787
evaluation/Returns Max             -6.51557
evaluation/Returns Min           -203.454
evaluation/Actions Mean            -0.00340463
evaluation/Actions Std              0.183435
evaluation/Actions Max              0.998055
evaluation/Actions Min             -0.999544
evaluation/Num Paths               15
evaluation/Average Returns        -38.2185
time/data storing (s)               0.00271781
time/evaluation sampling (s)        0.330845
time/exploration sampling (s)       0.140072
time/logging (s)                    0.00481675
time/saving (s)                     0.00197329
time/training (s)                   1.93026
time/epoch (s)                      2.41069
time/total (s)                    494.613
Epoch                             201
-----------------------------  ---------------
2019-04-22 23:35:31.055877 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 202 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   85.4042
trainer/QF2 Loss                   85.4972
trainer/Policy Loss                28.0696
trainer/Q1 Predictions Mean       -26.5315
trainer/Q1 Predictions Std         29.1344
trainer/Q1 Predictions Max         -8.38922
trainer/Q1 Predictions Min       -105.194
trainer/Q2 Predictions Mean       -26.5646
trainer/Q2 Predictions Std         29.1381
trainer/Q2 Predictions Max         -8.48542
trainer/Q2 Predictions Min       -105.309
trainer/Q Targets Mean            -25.7518
trainer/Q Targets Std              28.6632
trainer/Q Targets Max              -0.186129
trainer/Q Targets Min            -106.502
trainer/Log Pis Mean                1.94452
trainer/Log Pis Std                 1.16439
trainer/Log Pis Max                 4.94185
trainer/Log Pis Min                -3.34195
trainer/Policy mu Mean              0.0794719
trainer/Policy mu Std               0.650823
trainer/Policy mu Max               2.94218
trainer/Policy mu Min              -2.49912
trainer/Policy log std Mean        -2.09554
trainer/Policy log std Std          0.508609
trainer/Policy log std Max         -0.525721
trainer/Policy log std Min         -2.91703
trainer/Alpha                       0.0675674
trainer/Alpha Loss                 -0.149489
exploration/num steps total    101700
exploration/num paths total      1017
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.407699
exploration/Rewards Std             0.991078
exploration/Rewards Max            -0.00224087
exploration/Rewards Min            -8.78789
exploration/Returns Mean          -40.7699
exploration/Returns Std            13.1876
exploration/Returns Max           -19.7529
exploration/Returns Min           -56.1407
exploration/Actions Mean            0.0177181
exploration/Actions Std             0.229522
exploration/Actions Max             0.999161
exploration/Actions Min            -0.995877
exploration/Num Paths               5
exploration/Average Returns       -40.7699
evaluation/num steps total     304500
evaluation/num paths total       3045
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.661003
evaluation/Rewards Std              1.27705
evaluation/Rewards Max             -0.00694097
evaluation/Rewards Min            -10.3357
evaluation/Returns Mean           -66.1003
evaluation/Returns Std             71.2191
evaluation/Returns Max             -7.06229
evaluation/Returns Min           -214.565
evaluation/Actions Mean            -0.00410672
evaluation/Actions Std              0.196615
evaluation/Actions Max              0.999397
evaluation/Actions Min             -0.996949
evaluation/Num Paths               15
evaluation/Average Returns        -66.1003
time/data storing (s)               0.00281981
time/evaluation sampling (s)        0.330099
time/exploration sampling (s)       0.143182
time/logging (s)                    0.00485412
time/saving (s)                     0.00199864
time/training (s)                   1.92673
time/epoch (s)                      2.40969
time/total (s)                    497.027
Epoch                             202
-----------------------------  ---------------
2019-04-22 23:35:33.445741 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 203 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    4.50368
trainer/QF2 Loss                    4.46341
trainer/Policy Loss                27.7043
trainer/Q1 Predictions Mean       -25.9789
trainer/Q1 Predictions Std         29.1266
trainer/Q1 Predictions Max         -8.57802
trainer/Q1 Predictions Min        -95.1221
trainer/Q2 Predictions Mean       -25.9621
trainer/Q2 Predictions Std         29.1157
trainer/Q2 Predictions Max         -8.50931
trainer/Q2 Predictions Min        -94.8833
trainer/Q Targets Mean            -25.9419
trainer/Q Targets Std              29.5771
trainer/Q Targets Max              -0.0413512
trainer/Q Targets Min             -95.8733
trainer/Log Pis Mean                2.0936
trainer/Log Pis Std                 1.33253
trainer/Log Pis Max                 6.79392
trainer/Log Pis Min                -1.35358
trainer/Policy mu Mean              0.0140729
trainer/Policy mu Std               0.715622
trainer/Policy mu Max               3.49881
trainer/Policy mu Min              -2.47996
trainer/Policy log std Mean        -2.07487
trainer/Policy log std Std          0.516535
trainer/Policy log std Max         -0.349558
trainer/Policy log std Min         -2.76546
trainer/Alpha                       0.0692292
trainer/Alpha Loss                  0.249936
exploration/num steps total    102200
exploration/num paths total      1022
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.332722
exploration/Rewards Std             0.931419
exploration/Rewards Max            -0.0060256
exploration/Rewards Min            -8.14048
exploration/Returns Mean          -33.2722
exploration/Returns Std            10.4432
exploration/Returns Max           -14.3264
exploration/Returns Min           -46.3369
exploration/Actions Mean            0.0291075
exploration/Actions Std             0.219114
exploration/Actions Max             0.998438
exploration/Actions Min            -0.998257
exploration/Num Paths               5
exploration/Average Returns       -33.2722
evaluation/num steps total     306000
evaluation/num paths total       3060
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.65778
evaluation/Rewards Std              0.945064
evaluation/Rewards Max             -0.0218889
evaluation/Rewards Min             -7.53847
evaluation/Returns Mean           -65.778
evaluation/Returns Std             78.3805
evaluation/Returns Max            -10.6244
evaluation/Returns Min           -201.443
evaluation/Actions Mean            -0.0102091
evaluation/Actions Std              0.164091
evaluation/Actions Max              0.995354
evaluation/Actions Min             -0.996379
evaluation/Num Paths               15
evaluation/Average Returns        -65.778
time/data storing (s)               0.00273405
time/evaluation sampling (s)        0.324029
time/exploration sampling (s)       0.138282
time/logging (s)                    0.0048033
time/saving (s)                     0.00164632
time/training (s)                   1.91042
time/epoch (s)                      2.38192
time/total (s)                    499.413
Epoch                             203
-----------------------------  ---------------
2019-04-22 23:35:35.865601 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 204 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    7.06593
trainer/QF2 Loss                    7.05553
trainer/Policy Loss                24.538
trainer/Q1 Predictions Mean       -22.8885
trainer/Q1 Predictions Std         24.5974
trainer/Q1 Predictions Max         -8.47731
trainer/Q1 Predictions Min        -94.5616
trainer/Q2 Predictions Mean       -22.9371
trainer/Q2 Predictions Std         24.5928
trainer/Q2 Predictions Max         -8.5832
trainer/Q2 Predictions Min        -94.4266
trainer/Q Targets Mean            -22.6757
trainer/Q Targets Std              24.946
trainer/Q Targets Max              -0.327691
trainer/Q Targets Min             -94.9851
trainer/Log Pis Mean                2.04188
trainer/Log Pis Std                 1.45424
trainer/Log Pis Max                 6.21878
trainer/Log Pis Min                -2.07324
trainer/Policy mu Mean             -0.030709
trainer/Policy mu Std               0.74918
trainer/Policy mu Max               2.64372
trainer/Policy mu Min              -3.03822
trainer/Policy log std Mean        -2.08373
trainer/Policy log std Std          0.563503
trainer/Policy log std Max         -0.490252
trainer/Policy log std Min         -2.72671
trainer/Alpha                       0.0680362
trainer/Alpha Loss                  0.112574
exploration/num steps total    102700
exploration/num paths total      1027
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.698238
exploration/Rewards Std             1.16817
exploration/Rewards Max            -0.00616061
exploration/Rewards Min            -8.414
exploration/Returns Mean          -69.8238
exploration/Returns Std            74.9703
exploration/Returns Max           -21.1948
exploration/Returns Min          -218.726
exploration/Actions Mean           -0.0058376
exploration/Actions Std             0.233095
exploration/Actions Max             0.99847
exploration/Actions Min            -0.995234
exploration/Num Paths               5
exploration/Average Returns       -69.8238
evaluation/num steps total     307500
evaluation/num paths total       3075
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.78869
evaluation/Rewards Std              1.32523
evaluation/Rewards Max             -0.0203827
evaluation/Rewards Min            -10.4264
evaluation/Returns Mean           -78.869
evaluation/Returns Std             83.4829
evaluation/Returns Max             -7.79881
evaluation/Returns Min           -224.482
evaluation/Actions Mean            -0.00929011
evaluation/Actions Std              0.192211
evaluation/Actions Max              0.999604
evaluation/Actions Min             -0.996028
evaluation/Num Paths               15
evaluation/Average Returns        -78.869
time/data storing (s)               0.00275241
time/evaluation sampling (s)        0.325938
time/exploration sampling (s)       0.140112
time/logging (s)                    0.00479448
time/saving (s)                     0.00195646
time/training (s)                   1.93618
time/epoch (s)                      2.41174
time/total (s)                    501.83
Epoch                             204
-----------------------------  ---------------
2019-04-22 23:35:38.271488 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 205 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   83.5468
trainer/QF2 Loss                   83.5842
trainer/Policy Loss                28.4936
trainer/Q1 Predictions Mean       -27.2285
trainer/Q1 Predictions Std         30.3271
trainer/Q1 Predictions Max         -8.29174
trainer/Q1 Predictions Min        -93.8143
trainer/Q2 Predictions Mean       -27.2295
trainer/Q2 Predictions Std         30.3183
trainer/Q2 Predictions Max         -8.32085
trainer/Q2 Predictions Min        -94.1135
trainer/Q Targets Mean            -26.6593
trainer/Q Targets Std              30.2115
trainer/Q Targets Max              -2.20804
trainer/Q Targets Min             -96.0913
trainer/Log Pis Mean                1.76676
trainer/Log Pis Std                 1.32466
trainer/Log Pis Max                 4.78916
trainer/Log Pis Min                -3.22124
trainer/Policy mu Mean              0.0411804
trainer/Policy mu Std               0.764103
trainer/Policy mu Max               2.67949
trainer/Policy mu Min              -2.82197
trainer/Policy log std Mean        -1.96835
trainer/Policy log std Std          0.555244
trainer/Policy log std Max         -0.470197
trainer/Policy log std Min         -2.75399
trainer/Alpha                       0.0665481
trainer/Alpha Loss                 -0.632001
exploration/num steps total    103200
exploration/num paths total      1032
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.940518
exploration/Rewards Std             1.07409
exploration/Rewards Max            -0.00267195
exploration/Rewards Min            -7.33587
exploration/Returns Mean          -94.0518
exploration/Returns Std            88.7063
exploration/Returns Max           -12.8772
exploration/Returns Min          -205.447
exploration/Actions Mean           -0.00495357
exploration/Actions Std             0.207845
exploration/Actions Max             0.999942
exploration/Actions Min            -0.994054
exploration/Num Paths               5
exploration/Average Returns       -94.0518
evaluation/num steps total     309000
evaluation/num paths total       3090
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.604094
evaluation/Rewards Std              1.06413
evaluation/Rewards Max             -0.0107888
evaluation/Rewards Min            -10.8351
evaluation/Returns Mean           -60.4094
evaluation/Returns Std             72.9595
evaluation/Returns Max             -6.77301
evaluation/Returns Min           -221.47
evaluation/Actions Mean            -0.00679602
evaluation/Actions Std              0.179317
evaluation/Actions Max              0.996403
evaluation/Actions Min             -0.998108
evaluation/Num Paths               15
evaluation/Average Returns        -60.4094
time/data storing (s)               0.00273978
time/evaluation sampling (s)        0.323477
time/exploration sampling (s)       0.138761
time/logging (s)                    0.00480219
time/saving (s)                     0.00195813
time/training (s)                   1.92657
time/epoch (s)                      2.39831
time/total (s)                    504.232
Epoch                             205
-----------------------------  ---------------
2019-04-22 23:35:40.696864 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 206 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   83.8526
trainer/QF2 Loss                   83.9207
trainer/Policy Loss                25.3896
trainer/Q1 Predictions Mean       -23.773
trainer/Q1 Predictions Std         25.9327
trainer/Q1 Predictions Max         -8.18377
trainer/Q1 Predictions Min        -93.1243
trainer/Q2 Predictions Mean       -23.7753
trainer/Q2 Predictions Std         25.9464
trainer/Q2 Predictions Max         -8.20578
trainer/Q2 Predictions Min        -93.0428
trainer/Q Targets Mean            -23.0406
trainer/Q Targets Std              25.624
trainer/Q Targets Max              -0.140477
trainer/Q Targets Min             -94.347
trainer/Log Pis Mean                1.9885
trainer/Log Pis Std                 1.26193
trainer/Log Pis Max                 7.19505
trainer/Log Pis Min                -1.87173
trainer/Policy mu Mean             -0.0102653
trainer/Policy mu Std               0.737175
trainer/Policy mu Max               2.79942
trainer/Policy mu Min              -3.00241
trainer/Policy log std Mean        -2.03993
trainer/Policy log std Std          0.491164
trainer/Policy log std Max         -0.68131
trainer/Policy log std Min         -2.89184
trainer/Alpha                       0.0647012
trainer/Alpha Loss                 -0.0314829
exploration/num steps total    103700
exploration/num paths total      1037
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.4741
exploration/Rewards Std             1.37958
exploration/Rewards Max            -0.00661522
exploration/Rewards Min           -11.8607
exploration/Returns Mean          -47.41
exploration/Returns Std            16.2962
exploration/Returns Max           -25.1449
exploration/Returns Min           -68.4446
exploration/Actions Mean            0.0262189
exploration/Actions Std             0.23701
exploration/Actions Max             0.999877
exploration/Actions Min            -0.993075
exploration/Num Paths               5
exploration/Average Returns       -47.41
evaluation/num steps total     310500
evaluation/num paths total       3105
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.30472
evaluation/Rewards Std              0.919635
evaluation/Rewards Max             -0.00897146
evaluation/Rewards Min             -9.134
evaluation/Returns Mean           -30.472
evaluation/Returns Std             16.211
evaluation/Returns Max             -5.58834
evaluation/Returns Min            -63.8045
evaluation/Actions Mean             0.0135158
evaluation/Actions Std              0.1735
evaluation/Actions Max              0.998266
evaluation/Actions Min             -0.998401
evaluation/Num Paths               15
evaluation/Average Returns        -30.472
time/data storing (s)               0.00281576
time/evaluation sampling (s)        0.330543
time/exploration sampling (s)       0.140756
time/logging (s)                    0.00481276
time/saving (s)                     0.00197667
time/training (s)                   1.93685
time/epoch (s)                      2.41775
time/total (s)                    506.654
Epoch                             206
-----------------------------  ---------------
2019-04-22 23:35:43.150873 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 207 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.130775
trainer/QF2 Loss                    0.102441
trainer/Policy Loss                27.1064
trainer/Q1 Predictions Mean       -25.4268
trainer/Q1 Predictions Std         28.2603
trainer/Q1 Predictions Max         -8.43426
trainer/Q1 Predictions Min        -98.7786
trainer/Q2 Predictions Mean       -25.4432
trainer/Q2 Predictions Std         28.2918
trainer/Q2 Predictions Max         -8.43518
trainer/Q2 Predictions Min        -98.9973
trainer/Q Targets Mean            -25.5634
trainer/Q Targets Std              28.4222
trainer/Q Targets Max              -8.43999
trainer/Q Targets Min             -98.7759
trainer/Log Pis Mean                2.14443
trainer/Log Pis Std                 1.10085
trainer/Log Pis Max                 6.54287
trainer/Log Pis Min                -0.337238
trainer/Policy mu Mean             -0.0429181
trainer/Policy mu Std               0.75776
trainer/Policy mu Max               2.60241
trainer/Policy mu Min              -2.51227
trainer/Policy log std Mean        -2.05217
trainer/Policy log std Std          0.572568
trainer/Policy log std Max         -0.584
trainer/Policy log std Min         -2.82257
trainer/Alpha                       0.0671617
trainer/Alpha Loss                  0.390071
exploration/num steps total    104200
exploration/num paths total      1042
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.733945
exploration/Rewards Std             1.36581
exploration/Rewards Max            -0.0075766
exploration/Rewards Min            -9.12
exploration/Returns Mean          -73.3945
exploration/Returns Std            56.516
exploration/Returns Max           -31.7583
exploration/Returns Min          -184.886
exploration/Actions Mean            0.0123715
exploration/Actions Std             0.248859
exploration/Actions Max             0.999726
exploration/Actions Min            -0.999373
exploration/Num Paths               5
exploration/Average Returns       -73.3945
evaluation/num steps total     312000
evaluation/num paths total       3120
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.282128
evaluation/Rewards Std              0.729208
evaluation/Rewards Max             -0.0209047
evaluation/Rewards Min             -8.56109
evaluation/Returns Mean           -28.2128
evaluation/Returns Std             37.5909
evaluation/Returns Max             -2.68016
evaluation/Returns Min           -162.544
evaluation/Actions Mean             0.00897901
evaluation/Actions Std              0.151199
evaluation/Actions Max              0.996052
evaluation/Actions Min             -0.99347
evaluation/Num Paths               15
evaluation/Average Returns        -28.2128
time/data storing (s)               0.00277272
time/evaluation sampling (s)        0.336934
time/exploration sampling (s)       0.142796
time/logging (s)                    0.00484865
time/saving (s)                     0.0104868
time/training (s)                   1.94965
time/epoch (s)                      2.44749
time/total (s)                    509.106
Epoch                             207
-----------------------------  ---------------
2019-04-22 23:35:45.591570 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 208 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                   82.4909
trainer/QF2 Loss                   82.4237
trainer/Policy Loss                27.7036
trainer/Q1 Predictions Mean       -26.3182
trainer/Q1 Predictions Std         28.2721
trainer/Q1 Predictions Max         -8.32786
trainer/Q1 Predictions Min        -93.6247
trainer/Q2 Predictions Mean       -26.3342
trainer/Q2 Predictions Std         28.28
trainer/Q2 Predictions Max         -8.33709
trainer/Q2 Predictions Min        -93.9589
trainer/Q Targets Mean            -25.5171
trainer/Q Targets Std              27.7933
trainer/Q Targets Max              -1.98738
trainer/Q Targets Min             -94.2472
trainer/Log Pis Mean                1.77923
trainer/Log Pis Std                 1.10273
trainer/Log Pis Max                 3.55028
trainer/Log Pis Min                -2.28679
trainer/Policy mu Mean              0.0396891
trainer/Policy mu Std               0.608708
trainer/Policy mu Max               1.96322
trainer/Policy mu Min              -2.40932
trainer/Policy log std Mean        -2.03302
trainer/Policy log std Std          0.493791
trainer/Policy log std Max         -0.451334
trainer/Policy log std Min         -2.76247
trainer/Alpha                       0.0683131
trainer/Alpha Loss                 -0.592449
exploration/num steps total    104700
exploration/num paths total      1047
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.610199
exploration/Rewards Std             1.06345
exploration/Rewards Max            -0.00734993
exploration/Rewards Min           -10.3898
exploration/Returns Mean          -61.0199
exploration/Returns Std            60.5747
exploration/Returns Max           -14.7921
exploration/Returns Min          -176.559
exploration/Actions Mean           -0.000994659
exploration/Actions Std             0.194803
exploration/Actions Max             0.999166
exploration/Actions Min            -0.997426
exploration/Num Paths               5
exploration/Average Returns       -61.0199
evaluation/num steps total     313500
evaluation/num paths total       3135
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.451092
evaluation/Rewards Std              1.03876
evaluation/Rewards Max             -0.0350798
evaluation/Rewards Min            -10.7493
evaluation/Returns Mean           -45.1092
evaluation/Returns Std             58.9807
evaluation/Returns Max             -5.02042
evaluation/Returns Min           -194.447
evaluation/Actions Mean             0.00774974
evaluation/Actions Std              0.176898
evaluation/Actions Max              0.999433
evaluation/Actions Min             -0.998267
evaluation/Num Paths               15
evaluation/Average Returns        -45.1092
time/data storing (s)               0.00276432
time/evaluation sampling (s)        0.328466
time/exploration sampling (s)       0.140237
time/logging (s)                    0.00436696
time/saving (s)                     0.00195756
time/training (s)                   1.95451
time/epoch (s)                      2.4323
time/total (s)                    511.543
Epoch                             208
-----------------------------  ----------------
2019-04-22 23:35:48.134128 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 209 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.247369
trainer/QF2 Loss                    0.272267
trainer/Policy Loss                27.7525
trainer/Q1 Predictions Mean       -26.0937
trainer/Q1 Predictions Std         28.8258
trainer/Q1 Predictions Max         -8.11987
trainer/Q1 Predictions Min        -98.6685
trainer/Q2 Predictions Mean       -26.0654
trainer/Q2 Predictions Std         28.8485
trainer/Q2 Predictions Max         -7.97477
trainer/Q2 Predictions Min        -98.9402
trainer/Q Targets Mean            -26.4133
trainer/Q Targets Std              29.0497
trainer/Q Targets Max              -8.3036
trainer/Q Targets Min            -100.717
trainer/Log Pis Mean                2.15979
trainer/Log Pis Std                 1.30962
trainer/Log Pis Max                 5.86432
trainer/Log Pis Min                -1.40614
trainer/Policy mu Mean              0.0246208
trainer/Policy mu Std               0.787382
trainer/Policy mu Max               2.56112
trainer/Policy mu Min              -2.4937
trainer/Policy log std Mean        -2.08793
trainer/Policy log std Std          0.559553
trainer/Policy log std Max         -0.539036
trainer/Policy log std Min         -2.78149
trainer/Alpha                       0.0683426
trainer/Alpha Loss                  0.428777
exploration/num steps total    105200
exploration/num paths total      1052
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.259611
exploration/Rewards Std             0.624685
exploration/Rewards Max            -0.00285475
exploration/Rewards Min            -6.5968
exploration/Returns Mean          -25.9611
exploration/Returns Std             8.62312
exploration/Returns Max           -14.7777
exploration/Returns Min           -40.1121
exploration/Actions Mean            0.0110357
exploration/Actions Std             0.194146
exploration/Actions Max             0.998271
exploration/Actions Min            -0.997476
exploration/Num Paths               5
exploration/Average Returns       -25.9611
evaluation/num steps total     315000
evaluation/num paths total       3150
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.607144
evaluation/Rewards Std              1.02449
evaluation/Rewards Max             -0.0134602
evaluation/Rewards Min             -8.71868
evaluation/Returns Mean           -60.7144
evaluation/Returns Std             73.2652
evaluation/Returns Max            -11.3176
evaluation/Returns Min           -214.342
evaluation/Actions Mean            -0.00227537
evaluation/Actions Std              0.16838
evaluation/Actions Max              0.997109
evaluation/Actions Min             -0.996593
evaluation/Num Paths               15
evaluation/Average Returns        -60.7144
time/data storing (s)               0.00272655
time/evaluation sampling (s)        0.326072
time/exploration sampling (s)       0.140843
time/logging (s)                    0.0048217
time/saving (s)                     0.00198808
time/training (s)                   2.05882
time/epoch (s)                      2.53527
time/total (s)                    514.083
Epoch                             209
-----------------------------  ---------------
2019-04-22 23:35:50.547657 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 210 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0897011
trainer/QF2 Loss                    0.0857659
trainer/Policy Loss                30.3115
trainer/Q1 Predictions Mean       -28.767
trainer/Q1 Predictions Std         32.2441
trainer/Q1 Predictions Max         -8.44295
trainer/Q1 Predictions Min        -99.7014
trainer/Q2 Predictions Mean       -28.7732
trainer/Q2 Predictions Std         32.2517
trainer/Q2 Predictions Max         -8.38983
trainer/Q2 Predictions Min        -99.8906
trainer/Q Targets Mean            -28.7684
trainer/Q Targets Std              32.2358
trainer/Q Targets Max              -8.35144
trainer/Q Targets Min            -100.467
trainer/Log Pis Mean                1.87868
trainer/Log Pis Std                 1.4714
trainer/Log Pis Max                 4.68118
trainer/Log Pis Min                -4.55073
trainer/Policy mu Mean              0.0230165
trainer/Policy mu Std               0.657194
trainer/Policy mu Max               2.963
trainer/Policy mu Min              -2.49632
trainer/Policy log std Mean        -2.10797
trainer/Policy log std Std          0.502432
trainer/Policy log std Max         -0.494183
trainer/Policy log std Min         -2.74477
trainer/Alpha                       0.0711427
trainer/Alpha Loss                 -0.320651
exploration/num steps total    105700
exploration/num paths total      1057
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.381016
exploration/Rewards Std             1.12453
exploration/Rewards Max            -0.00991977
exploration/Rewards Min            -9.00566
exploration/Returns Mean          -38.1016
exploration/Returns Std            17.0385
exploration/Returns Max           -14.173
exploration/Returns Min           -57.1177
exploration/Actions Mean            0.0157448
exploration/Actions Std             0.225176
exploration/Actions Max             0.999819
exploration/Actions Min            -0.999191
exploration/Num Paths               5
exploration/Average Returns       -38.1016
evaluation/num steps total     316500
evaluation/num paths total       3165
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.381764
evaluation/Rewards Std              1.00831
evaluation/Rewards Max             -0.0190722
evaluation/Rewards Min             -9.48469
evaluation/Returns Mean           -38.1764
evaluation/Returns Std             49.0236
evaluation/Returns Max             -2.18991
evaluation/Returns Min           -208.394
evaluation/Actions Mean             0.00709042
evaluation/Actions Std              0.17991
evaluation/Actions Max              0.9989
evaluation/Actions Min             -0.997129
evaluation/Num Paths               15
evaluation/Average Returns        -38.1764
time/data storing (s)               0.00303778
time/evaluation sampling (s)        0.331582
time/exploration sampling (s)       0.141703
time/logging (s)                    0.00482787
time/saving (s)                     0.00196743
time/training (s)                   1.92248
time/epoch (s)                      2.4056
time/total (s)                    516.493
Epoch                             210
-----------------------------  ---------------
2019-04-22 23:35:52.935763 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 211 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.628729
trainer/QF2 Loss                    0.601874
trainer/Policy Loss                30.5406
trainer/Q1 Predictions Mean       -28.6599
trainer/Q1 Predictions Std         31.7705
trainer/Q1 Predictions Max         -7.94455
trainer/Q1 Predictions Min       -105.083
trainer/Q2 Predictions Mean       -28.6703
trainer/Q2 Predictions Std         31.7679
trainer/Q2 Predictions Max         -7.90741
trainer/Q2 Predictions Min       -105.444
trainer/Q Targets Mean            -29.1173
trainer/Q Targets Std              32.2895
trainer/Q Targets Max              -8.25909
trainer/Q Targets Min            -105.866
trainer/Log Pis Mean                2.12702
trainer/Log Pis Std                 1.0706
trainer/Log Pis Max                 6.20917
trainer/Log Pis Min                -1.19869
trainer/Policy mu Mean              0.0289781
trainer/Policy mu Std               0.668056
trainer/Policy mu Max               2.73943
trainer/Policy mu Min              -2.92197
trainer/Policy log std Mean        -2.12516
trainer/Policy log std Std          0.47996
trainer/Policy log std Max         -0.478849
trainer/Policy log std Min         -2.8505
trainer/Alpha                       0.0710344
trainer/Alpha Loss                  0.335924
exploration/num steps total    106200
exploration/num paths total      1062
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.677454
exploration/Rewards Std             1.09565
exploration/Rewards Max            -0.00537941
exploration/Rewards Min            -9.16505
exploration/Returns Mean          -67.7454
exploration/Returns Std            66.7439
exploration/Returns Max           -22.0339
exploration/Returns Min          -198.719
exploration/Actions Mean           -0.0137234
exploration/Actions Std             0.230263
exploration/Actions Max             0.995467
exploration/Actions Min            -0.999749
exploration/Num Paths               5
exploration/Average Returns       -67.7454
evaluation/num steps total     318000
evaluation/num paths total       3180
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.454262
evaluation/Rewards Std              0.90239
evaluation/Rewards Max             -0.00955565
evaluation/Rewards Min             -8.96992
evaluation/Returns Mean           -45.4262
evaluation/Returns Std             62.633
evaluation/Returns Max             -7.57798
evaluation/Returns Min           -209.679
evaluation/Actions Mean             0.00234641
evaluation/Actions Std              0.172534
evaluation/Actions Max              0.99804
evaluation/Actions Min             -0.992463
evaluation/Num Paths               15
evaluation/Average Returns        -45.4262
time/data storing (s)               0.00274034
time/evaluation sampling (s)        0.327496
time/exploration sampling (s)       0.141987
time/logging (s)                    0.00421056
time/saving (s)                     0.00155034
time/training (s)                   1.9015
time/epoch (s)                      2.37948
time/total (s)                    518.877
Epoch                             211
-----------------------------  ---------------
2019-04-22 23:35:55.372395 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 212 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.072939
trainer/QF2 Loss                    0.0662341
trainer/Policy Loss                25.7498
trainer/Q1 Predictions Mean       -24.101
trainer/Q1 Predictions Std         27.546
trainer/Q1 Predictions Max         -8.14478
trainer/Q1 Predictions Min        -94.4044
trainer/Q2 Predictions Mean       -24.0961
trainer/Q2 Predictions Std         27.5496
trainer/Q2 Predictions Max         -8.11993
trainer/Q2 Predictions Min        -94.5244
trainer/Q Targets Mean            -24.2219
trainer/Q Targets Std              27.6613
trainer/Q Targets Max              -8.29446
trainer/Q Targets Min             -94.8498
trainer/Log Pis Mean                1.92806
trainer/Log Pis Std                 1.15051
trainer/Log Pis Max                 5.49547
trainer/Log Pis Min                -2.6162
trainer/Policy mu Mean              0.0518279
trainer/Policy mu Std               0.622562
trainer/Policy mu Max               2.91506
trainer/Policy mu Min              -2.7951
trainer/Policy log std Mean        -2.12476
trainer/Policy log std Std          0.462394
trainer/Policy log std Max         -0.587432
trainer/Policy log std Min         -2.67632
trainer/Alpha                       0.070099
trainer/Alpha Loss                 -0.191217
exploration/num steps total    106700
exploration/num paths total      1067
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.262974
exploration/Rewards Std             0.746785
exploration/Rewards Max            -0.00195128
exploration/Rewards Min            -7.9651
exploration/Returns Mean          -26.2974
exploration/Returns Std            11.7317
exploration/Returns Max           -14.8546
exploration/Returns Min           -46.8616
exploration/Actions Mean           -0.0105858
exploration/Actions Std             0.21013
exploration/Actions Max             0.988838
exploration/Actions Min            -0.99737
exploration/Num Paths               5
exploration/Average Returns       -26.2974
evaluation/num steps total     319500
evaluation/num paths total       3195
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.436787
evaluation/Rewards Std              1.0209
evaluation/Rewards Max             -0.0333313
evaluation/Rewards Min             -9.81622
evaluation/Returns Mean           -43.6787
evaluation/Returns Std             41.9474
evaluation/Returns Max            -16.4953
evaluation/Returns Min           -191.447
evaluation/Actions Mean             0.0138602
evaluation/Actions Std              0.194641
evaluation/Actions Max              0.998815
evaluation/Actions Min             -0.992335
evaluation/Num Paths               15
evaluation/Average Returns        -43.6787
time/data storing (s)               0.00269324
time/evaluation sampling (s)        0.33363
time/exploration sampling (s)       0.139467
time/logging (s)                    0.00477166
time/saving (s)                     0.00200369
time/training (s)                   1.94674
time/epoch (s)                      2.4293
time/total (s)                    521.31
Epoch                             212
-----------------------------  ---------------
2019-04-22 23:35:57.771794 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 213 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0329561
trainer/QF2 Loss                    0.053291
trainer/Policy Loss                24.9961
trainer/Q1 Predictions Mean       -23.3937
trainer/Q1 Predictions Std         26.1527
trainer/Q1 Predictions Max         -8.40209
trainer/Q1 Predictions Min        -99.7571
trainer/Q2 Predictions Mean       -23.3555
trainer/Q2 Predictions Std         26.1418
trainer/Q2 Predictions Max         -8.33207
trainer/Q2 Predictions Min        -99.5062
trainer/Q Targets Mean            -23.4176
trainer/Q Targets Std              26.2483
trainer/Q Targets Max              -8.21125
trainer/Q Targets Min            -100.43
trainer/Log Pis Mean                2.09639
trainer/Log Pis Std                 1.29351
trainer/Log Pis Max                 6.54236
trainer/Log Pis Min                -1.75436
trainer/Policy mu Mean              0.00157596
trainer/Policy mu Std               0.795826
trainer/Policy mu Max               2.71718
trainer/Policy mu Min              -3.08915
trainer/Policy log std Mean        -2.05621
trainer/Policy log std Std          0.587378
trainer/Policy log std Max         -0.543143
trainer/Policy log std Min         -2.7316
trainer/Alpha                       0.0677423
trainer/Alpha Loss                  0.259498
exploration/num steps total    107200
exploration/num paths total      1072
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.612051
exploration/Rewards Std             1.12328
exploration/Rewards Max            -0.006003
exploration/Rewards Min           -10.214
exploration/Returns Mean          -61.2051
exploration/Returns Std            63.9872
exploration/Returns Max           -14.1623
exploration/Returns Min          -186.112
exploration/Actions Mean            0.0193927
exploration/Actions Std             0.226593
exploration/Actions Max             0.999785
exploration/Actions Min            -0.997439
exploration/Num Paths               5
exploration/Average Returns       -61.2051
evaluation/num steps total     321000
evaluation/num paths total       3210
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.412302
evaluation/Rewards Std              0.913601
evaluation/Rewards Max             -0.00248818
evaluation/Rewards Min             -9.93496
evaluation/Returns Mean           -41.2302
evaluation/Returns Std             55.7459
evaluation/Returns Max             -2.48436
evaluation/Returns Min           -183
evaluation/Actions Mean            -0.00467656
evaluation/Actions Std              0.160473
evaluation/Actions Max              0.995654
evaluation/Actions Min             -0.998187
evaluation/Num Paths               15
evaluation/Average Returns        -41.2302
time/data storing (s)               0.0025633
time/evaluation sampling (s)        0.330734
time/exploration sampling (s)       0.140482
time/logging (s)                    0.0047743
time/saving (s)                     0.00196287
time/training (s)                   1.91088
time/epoch (s)                      2.39139
time/total (s)                    523.706
Epoch                             213
-----------------------------  ---------------
2019-04-22 23:36:00.185972 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 214 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.50005
trainer/QF2 Loss                    1.48754
trainer/Policy Loss                24.5008
trainer/Q1 Predictions Mean       -22.5881
trainer/Q1 Predictions Std         25.9347
trainer/Q1 Predictions Max         -8.29451
trainer/Q1 Predictions Min        -94.8871
trainer/Q2 Predictions Mean       -22.5975
trainer/Q2 Predictions Std         25.9434
trainer/Q2 Predictions Max         -8.36979
trainer/Q2 Predictions Min        -94.9631
trainer/Q Targets Mean            -22.489
trainer/Q Targets Std              26.0336
trainer/Q Targets Max              -0.220622
trainer/Q Targets Min             -94.7466
trainer/Log Pis Mean                2.22317
trainer/Log Pis Std                 1.2589
trainer/Log Pis Max                 5.65195
trainer/Log Pis Min                -2.32524
trainer/Policy mu Mean              0.0510258
trainer/Policy mu Std               0.77574
trainer/Policy mu Max               2.79626
trainer/Policy mu Min              -3.62531
trainer/Policy log std Mean        -2.07818
trainer/Policy log std Std          0.556901
trainer/Policy log std Max         -0.121844
trainer/Policy log std Min         -2.85421
trainer/Alpha                       0.0675822
trainer/Alpha Loss                  0.601333
exploration/num steps total    107700
exploration/num paths total      1077
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.354714
exploration/Rewards Std             1.05353
exploration/Rewards Max            -0.00610345
exploration/Rewards Min           -10.0096
exploration/Returns Mean          -35.4714
exploration/Returns Std            16.1144
exploration/Returns Max           -19.5411
exploration/Returns Min           -64.5132
exploration/Actions Mean            0.00192685
exploration/Actions Std             0.231578
exploration/Actions Max             0.99954
exploration/Actions Min            -0.999014
exploration/Num Paths               5
exploration/Average Returns       -35.4714
evaluation/num steps total     322500
evaluation/num paths total       3225
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.505812
evaluation/Rewards Std              1.07193
evaluation/Rewards Max             -0.0233272
evaluation/Rewards Min             -9.37201
evaluation/Returns Mean           -50.5812
evaluation/Returns Std             59.5528
evaluation/Returns Max             -6.92239
evaluation/Returns Min           -200.364
evaluation/Actions Mean             0.0260503
evaluation/Actions Std              0.197748
evaluation/Actions Max              0.998455
evaluation/Actions Min             -0.993023
evaluation/Num Paths               15
evaluation/Average Returns        -50.5812
time/data storing (s)               0.00345728
time/evaluation sampling (s)        0.330505
time/exploration sampling (s)       0.143978
time/logging (s)                    0.00375912
time/saving (s)                     0.001973
time/training (s)                   1.92127
time/epoch (s)                      2.40494
time/total (s)                    526.116
Epoch                             214
-----------------------------  ---------------
2019-04-22 23:36:02.611073 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 215 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    5.4744
trainer/QF2 Loss                    5.44525
trainer/Policy Loss                26.6164
trainer/Q1 Predictions Mean       -25.0545
trainer/Q1 Predictions Std         29.4845
trainer/Q1 Predictions Max         -8.38358
trainer/Q1 Predictions Min        -99.1856
trainer/Q2 Predictions Mean       -25.0676
trainer/Q2 Predictions Std         29.475
trainer/Q2 Predictions Max         -8.39213
trainer/Q2 Predictions Min        -99.3642
trainer/Q Targets Mean            -24.8121
trainer/Q Targets Std              29.6834
trainer/Q Targets Max              -0.359745
trainer/Q Targets Min             -99.6141
trainer/Log Pis Mean                1.92495
trainer/Log Pis Std                 1.34878
trainer/Log Pis Max                 4.76805
trainer/Log Pis Min                -4.46407
trainer/Policy mu Mean              0.0342729
trainer/Policy mu Std               0.617318
trainer/Policy mu Max               2.1838
trainer/Policy mu Min              -2.51071
trainer/Policy log std Mean        -2.15173
trainer/Policy log std Std          0.488228
trainer/Policy log std Max         -0.552475
trainer/Policy log std Min         -2.75561
trainer/Alpha                       0.0678794
trainer/Alpha Loss                 -0.201902
exploration/num steps total    108200
exploration/num paths total      1082
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.16633
exploration/Rewards Std             1.01197
exploration/Rewards Max            -0.00719878
exploration/Rewards Min            -9.33618
exploration/Returns Mean         -116.633
exploration/Returns Std            77.2075
exploration/Returns Max           -18.7692
exploration/Returns Min          -192.593
exploration/Actions Mean           -0.0270633
exploration/Actions Std             0.225321
exploration/Actions Max             0.716293
exploration/Actions Min            -0.999331
exploration/Num Paths               5
exploration/Average Returns      -116.633
evaluation/num steps total     324000
evaluation/num paths total       3240
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.745576
evaluation/Rewards Std              1.1116
evaluation/Rewards Max             -0.00833913
evaluation/Rewards Min             -9.49545
evaluation/Returns Mean           -74.5576
evaluation/Returns Std             70.3905
evaluation/Returns Max             -6.03572
evaluation/Returns Min           -193.287
evaluation/Actions Mean             0.0048065
evaluation/Actions Std              0.179489
evaluation/Actions Max              0.999085
evaluation/Actions Min             -0.99816
evaluation/Num Paths               15
evaluation/Average Returns        -74.5576
time/data storing (s)               0.00279467
time/evaluation sampling (s)        0.329796
time/exploration sampling (s)       0.139084
time/logging (s)                    0.00478772
time/saving (s)                     0.00197066
time/training (s)                   1.94041
time/epoch (s)                      2.41884
time/total (s)                    528.539
Epoch                             215
-----------------------------  ---------------
2019-04-22 23:36:05.011119 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 216 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    5.22775
trainer/QF2 Loss                    5.18906
trainer/Policy Loss                26.3697
trainer/Q1 Predictions Mean       -24.7515
trainer/Q1 Predictions Std         29.6151
trainer/Q1 Predictions Max         -8.19888
trainer/Q1 Predictions Min       -101.351
trainer/Q2 Predictions Mean       -24.7479
trainer/Q2 Predictions Std         29.5929
trainer/Q2 Predictions Max         -8.21688
trainer/Q2 Predictions Min       -101.253
trainer/Q Targets Mean            -24.6006
trainer/Q Targets Std              29.9214
trainer/Q Targets Max              -0.148661
trainer/Q Targets Min            -100.42
trainer/Log Pis Mean                1.81888
trainer/Log Pis Std                 1.06864
trainer/Log Pis Max                 6.38447
trainer/Log Pis Min                -1.16269
trainer/Policy mu Mean             -0.0282261
trainer/Policy mu Std               0.603737
trainer/Policy mu Max               3.36202
trainer/Policy mu Min              -3.10139
trainer/Policy log std Mean        -2.16911
trainer/Policy log std Std          0.476118
trainer/Policy log std Max         -0.205547
trainer/Policy log std Min         -2.7057
trainer/Alpha                       0.0685528
trainer/Alpha Loss                 -0.485444
exploration/num steps total    108700
exploration/num paths total      1087
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.416561
exploration/Rewards Std             1.24271
exploration/Rewards Max            -0.00493162
exploration/Rewards Min           -10.5348
exploration/Returns Mean          -41.6561
exploration/Returns Std            17.5416
exploration/Returns Max           -22.3285
exploration/Returns Min           -64.1429
exploration/Actions Mean            0.00241085
exploration/Actions Std             0.238932
exploration/Actions Max             0.999526
exploration/Actions Min            -0.998831
exploration/Num Paths               5
exploration/Average Returns       -41.6561
evaluation/num steps total     325500
evaluation/num paths total       3255
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.569232
evaluation/Rewards Std              1.15263
evaluation/Rewards Max             -0.0107101
evaluation/Rewards Min            -11.3728
evaluation/Returns Mean           -56.9232
evaluation/Returns Std             63.9618
evaluation/Returns Max             -4.10756
evaluation/Returns Min           -188.818
evaluation/Actions Mean             0.00881485
evaluation/Actions Std              0.183833
evaluation/Actions Max              0.998374
evaluation/Actions Min             -0.997453
evaluation/Num Paths               15
evaluation/Average Returns        -56.9232
time/data storing (s)               0.00264886
time/evaluation sampling (s)        0.325612
time/exploration sampling (s)       0.142474
time/logging (s)                    0.00526533
time/saving (s)                     0.00160413
time/training (s)                   1.91486
time/epoch (s)                      2.39247
time/total (s)                    530.936
Epoch                             216
-----------------------------  ---------------
2019-04-22 23:36:07.436457 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 217 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    2.6658
trainer/QF2 Loss                    2.66233
trainer/Policy Loss                24.9456
trainer/Q1 Predictions Mean       -23.121
trainer/Q1 Predictions Std         27.5699
trainer/Q1 Predictions Max         -7.8945
trainer/Q1 Predictions Min        -95.4431
trainer/Q2 Predictions Mean       -23.1269
trainer/Q2 Predictions Std         27.5465
trainer/Q2 Predictions Max         -7.87586
trainer/Q2 Predictions Min        -94.8076
trainer/Q Targets Mean            -23.1684
trainer/Q Targets Std              27.9563
trainer/Q Targets Max              -0.140477
trainer/Q Targets Min             -95.329
trainer/Log Pis Mean                2.03529
trainer/Log Pis Std                 1.35072
trainer/Log Pis Max                 6.31583
trainer/Log Pis Min                -3.41839
trainer/Policy mu Mean             -0.0154862
trainer/Policy mu Std               0.614617
trainer/Policy mu Max               3.24783
trainer/Policy mu Min              -2.83843
trainer/Policy log std Mean        -2.196
trainer/Policy log std Std          0.497721
trainer/Policy log std Max         -0.476025
trainer/Policy log std Min         -2.8159
trainer/Alpha                       0.069967
trainer/Alpha Loss                  0.0938655
exploration/num steps total    109200
exploration/num paths total      1092
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.77797
exploration/Rewards Std             0.871792
exploration/Rewards Max            -0.00857278
exploration/Rewards Min            -7.16494
exploration/Returns Mean          -77.797
exploration/Returns Std            67.7338
exploration/Returns Max           -12.0125
exploration/Returns Min          -168.957
exploration/Actions Mean            0.00591518
exploration/Actions Std             0.20475
exploration/Actions Max             0.997356
exploration/Actions Min            -0.996958
exploration/Num Paths               5
exploration/Average Returns       -77.797
evaluation/num steps total     327000
evaluation/num paths total       3270
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.388494
evaluation/Rewards Std              1.02841
evaluation/Rewards Max             -0.00738516
evaluation/Rewards Min            -10.0519
evaluation/Returns Mean           -38.8494
evaluation/Returns Std             38.6859
evaluation/Returns Max             -6.16677
evaluation/Returns Min           -170.328
evaluation/Actions Mean             0.00737553
evaluation/Actions Std              0.18455
evaluation/Actions Max              0.998193
evaluation/Actions Min             -0.998565
evaluation/Num Paths               15
evaluation/Average Returns        -38.8494
time/data storing (s)               0.00267786
time/evaluation sampling (s)        0.326992
time/exploration sampling (s)       0.139704
time/logging (s)                    0.00477547
time/saving (s)                     0.00188794
time/training (s)                   1.9407
time/epoch (s)                      2.41674
time/total (s)                    533.357
Epoch                             217
-----------------------------  ---------------
2019-04-22 23:36:09.838304 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 218 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.906643
trainer/QF2 Loss                    0.916977
trainer/Policy Loss                29.7211
trainer/Q1 Predictions Mean       -28.2207
trainer/Q1 Predictions Std         31.3297
trainer/Q1 Predictions Max         -7.81489
trainer/Q1 Predictions Min       -106.764
trainer/Q2 Predictions Mean       -28.1986
trainer/Q2 Predictions Std         31.365
trainer/Q2 Predictions Max         -7.70158
trainer/Q2 Predictions Min       -107.103
trainer/Q Targets Mean            -28.7533
trainer/Q Targets Std              32.0359
trainer/Q Targets Max              -8.1279
trainer/Q Targets Min            -106.571
trainer/Log Pis Mean                1.75336
trainer/Log Pis Std                 1.38114
trainer/Log Pis Max                 7.30682
trainer/Log Pis Min                -3.35916
trainer/Policy mu Mean             -0.0194412
trainer/Policy mu Std               0.587356
trainer/Policy mu Max               2.80771
trainer/Policy mu Min              -2.72571
trainer/Policy log std Mean        -2.09729
trainer/Policy log std Std          0.495937
trainer/Policy log std Max         -0.489182
trainer/Policy log std Min         -2.75093
trainer/Alpha                       0.0671065
trainer/Alpha Loss                 -0.66626
exploration/num steps total    109700
exploration/num paths total      1097
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.610636
exploration/Rewards Std             1.14108
exploration/Rewards Max            -0.00227505
exploration/Rewards Min            -8.92748
exploration/Returns Mean          -61.0636
exploration/Returns Std            45.6402
exploration/Returns Max           -16.0943
exploration/Returns Min          -148.81
exploration/Actions Mean           -0.0265016
exploration/Actions Std             0.247384
exploration/Actions Max             0.995778
exploration/Actions Min            -0.999322
exploration/Num Paths               5
exploration/Average Returns       -61.0636
evaluation/num steps total     328500
evaluation/num paths total       3285
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.372108
evaluation/Rewards Std              0.827541
evaluation/Rewards Max             -0.011384
evaluation/Rewards Min             -7.39689
evaluation/Returns Mean           -37.2108
evaluation/Returns Std             48.695
evaluation/Returns Max             -2.57418
evaluation/Returns Min           -164.089
evaluation/Actions Mean            -0.00604375
evaluation/Actions Std              0.160691
evaluation/Actions Max              0.999599
evaluation/Actions Min             -0.999244
evaluation/Num Paths               15
evaluation/Average Returns        -37.2108
time/data storing (s)               0.00272341
time/evaluation sampling (s)        0.331813
time/exploration sampling (s)       0.140263
time/logging (s)                    0.0048023
time/saving (s)                     0.00197652
time/training (s)                   1.91208
time/epoch (s)                      2.39366
time/total (s)                    535.756
Epoch                             218
-----------------------------  ---------------
2019-04-22 23:36:12.282224 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 219 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    3.44181
trainer/QF2 Loss                    3.42444
trainer/Policy Loss                27.5316
trainer/Q1 Predictions Mean       -25.878
trainer/Q1 Predictions Std         30.1753
trainer/Q1 Predictions Max         -8.16112
trainer/Q1 Predictions Min        -95.2795
trainer/Q2 Predictions Mean       -25.8452
trainer/Q2 Predictions Std         30.1717
trainer/Q2 Predictions Max         -8.11077
trainer/Q2 Predictions Min        -95.188
trainer/Q Targets Mean            -25.7407
trainer/Q Targets Std              30.4613
trainer/Q Targets Max              -0.227153
trainer/Q Targets Min             -95.3147
trainer/Log Pis Mean                1.92605
trainer/Log Pis Std                 1.48586
trainer/Log Pis Max                 8.25964
trainer/Log Pis Min                -3.91362
trainer/Policy mu Mean              0.0366566
trainer/Policy mu Std               0.628016
trainer/Policy mu Max               3.70566
trainer/Policy mu Min              -3.16212
trainer/Policy log std Mean        -2.14523
trainer/Policy log std Std          0.489065
trainer/Policy log std Max         -0.159243
trainer/Policy log std Min         -2.73807
trainer/Alpha                       0.0676523
trainer/Alpha Loss                 -0.199157
exploration/num steps total    110200
exploration/num paths total      1102
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.591308
exploration/Rewards Std             1.03103
exploration/Rewards Max            -0.00561394
exploration/Rewards Min            -8.68293
exploration/Returns Mean          -59.1308
exploration/Returns Std            55.0082
exploration/Returns Max           -20.0982
exploration/Returns Min          -167.914
exploration/Actions Mean           -0.00249959
exploration/Actions Std             0.244218
exploration/Actions Max             0.998989
exploration/Actions Min            -0.996808
exploration/Num Paths               5
exploration/Average Returns       -59.1308
evaluation/num steps total     330000
evaluation/num paths total       3300
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.399082
evaluation/Rewards Std              1.02896
evaluation/Rewards Max             -0.00236358
evaluation/Rewards Min             -9.0528
evaluation/Returns Mean           -39.9082
evaluation/Returns Std             34.9154
evaluation/Returns Max             -9.49012
evaluation/Returns Min           -163.883
evaluation/Actions Mean            -0.00355791
evaluation/Actions Std              0.189826
evaluation/Actions Max              0.997922
evaluation/Actions Min             -0.999137
evaluation/Num Paths               15
evaluation/Average Returns        -39.9082
time/data storing (s)               0.00277294
time/evaluation sampling (s)        0.332507
time/exploration sampling (s)       0.139485
time/logging (s)                    0.00352418
time/saving (s)                     0.00997244
time/training (s)                   1.94637
time/epoch (s)                      2.43463
time/total (s)                    538.195
Epoch                             219
-----------------------------  ---------------
2019-04-22 23:36:14.683961 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 220 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    3.47945
trainer/QF2 Loss                    3.32923
trainer/Policy Loss                23.0536
trainer/Q1 Predictions Mean       -21.2599
trainer/Q1 Predictions Std         24.7184
trainer/Q1 Predictions Max         -7.98689
trainer/Q1 Predictions Min        -95.5059
trainer/Q2 Predictions Mean       -21.2448
trainer/Q2 Predictions Std         24.6984
trainer/Q2 Predictions Max         -8.00746
trainer/Q2 Predictions Min        -95.1616
trainer/Q Targets Mean            -21.0658
trainer/Q Targets Std              24.7172
trainer/Q Targets Max              -2.30869
trainer/Q Targets Min             -95.0425
trainer/Log Pis Mean                2.1794
trainer/Log Pis Std                 1.09238
trainer/Log Pis Max                 7.7062
trainer/Log Pis Min                -0.850769
trainer/Policy mu Mean              0.104137
trainer/Policy mu Std               0.67539
trainer/Policy mu Max               3.18689
trainer/Policy mu Min              -2.97603
trainer/Policy log std Mean        -2.16235
trainer/Policy log std Std          0.540758
trainer/Policy log std Max         -0.249424
trainer/Policy log std Min         -2.76143
trainer/Alpha                       0.0697724
trainer/Alpha Loss                  0.477684
exploration/num steps total    110700
exploration/num paths total      1107
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.722104
exploration/Rewards Std             1.13019
exploration/Rewards Max            -0.000899836
exploration/Rewards Min            -9.78339
exploration/Returns Mean          -72.2104
exploration/Returns Std            82.8298
exploration/Returns Max           -14.778
exploration/Returns Min          -236.961
exploration/Actions Mean            0.00300115
exploration/Actions Std             0.202545
exploration/Actions Max             0.994418
exploration/Actions Min            -0.998228
exploration/Num Paths               5
exploration/Average Returns       -72.2104
evaluation/num steps total     331500
evaluation/num paths total       3315
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.584792
evaluation/Rewards Std              1.1591
evaluation/Rewards Max             -0.020845
evaluation/Rewards Min            -10.8148
evaluation/Returns Mean           -58.4792
evaluation/Returns Std             65.2929
evaluation/Returns Max             -6.85018
evaluation/Returns Min           -219.92
evaluation/Actions Mean            -0.00157239
evaluation/Actions Std              0.185699
evaluation/Actions Max              0.998892
evaluation/Actions Min             -0.995523
evaluation/Num Paths               15
evaluation/Average Returns        -58.4792
time/data storing (s)               0.00259365
time/evaluation sampling (s)        0.327767
time/exploration sampling (s)       0.143218
time/logging (s)                    0.00450468
time/saving (s)                     0.00193697
time/training (s)                   1.91614
time/epoch (s)                      2.39616
time/total (s)                    540.595
Epoch                             220
-----------------------------  ----------------
2019-04-22 23:36:17.082704 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 221 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    3.32981
trainer/QF2 Loss                    3.2222
trainer/Policy Loss                23.0406
trainer/Q1 Predictions Mean       -21.1562
trainer/Q1 Predictions Std         24.8679
trainer/Q1 Predictions Max         -7.86893
trainer/Q1 Predictions Min        -93.5484
trainer/Q2 Predictions Mean       -21.0994
trainer/Q2 Predictions Std         24.877
trainer/Q2 Predictions Max         -7.81813
trainer/Q2 Predictions Min        -93.5517
trainer/Q Targets Mean            -21.1117
trainer/Q Targets Std              25.194
trainer/Q Targets Max              -3.16249
trainer/Q Targets Min             -94.5433
trainer/Log Pis Mean                2.18435
trainer/Log Pis Std                 1.48012
trainer/Log Pis Max                11.3394
trainer/Log Pis Min                -1.77643
trainer/Policy mu Mean              0.129018
trainer/Policy mu Std               0.696302
trainer/Policy mu Max               3.4499
trainer/Policy mu Min              -2.69487
trainer/Policy log std Mean        -2.13598
trainer/Policy log std Std          0.519726
trainer/Policy log std Max         -0.377839
trainer/Policy log std Min         -2.72989
trainer/Alpha                       0.0701076
trainer/Alpha Loss                  0.48997
exploration/num steps total    111200
exploration/num paths total      1112
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.915868
exploration/Rewards Std             1.09423
exploration/Rewards Max            -0.0113679
exploration/Rewards Min            -8.00109
exploration/Returns Mean          -91.5868
exploration/Returns Std            74.7055
exploration/Returns Max           -24.834
exploration/Returns Min          -191.568
exploration/Actions Mean            0.0199444
exploration/Actions Std             0.230259
exploration/Actions Max             0.999157
exploration/Actions Min            -0.996954
exploration/Num Paths               5
exploration/Average Returns       -91.5868
evaluation/num steps total     333000
evaluation/num paths total       3330
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.406491
evaluation/Rewards Std              0.876539
evaluation/Rewards Max             -0.0100186
evaluation/Rewards Min             -7.7616
evaluation/Returns Mean           -40.6491
evaluation/Returns Std             58.1378
evaluation/Returns Max             -7.40108
evaluation/Returns Min           -187.908
evaluation/Actions Mean             0.0106421
evaluation/Actions Std              0.166758
evaluation/Actions Max              0.998819
evaluation/Actions Min             -0.993164
evaluation/Num Paths               15
evaluation/Average Returns        -40.6491
time/data storing (s)               0.00278593
time/evaluation sampling (s)        0.329516
time/exploration sampling (s)       0.143754
time/logging (s)                    0.00481106
time/saving (s)                     0.0019518
time/training (s)                   1.90838
time/epoch (s)                      2.3912
time/total (s)                    542.991
Epoch                             221
-----------------------------  ---------------
2019-04-22 23:36:19.490516 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 222 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.114658
trainer/QF2 Loss                    0.117471
trainer/Policy Loss                26.9759
trainer/Q1 Predictions Mean       -25.2119
trainer/Q1 Predictions Std         29.3536
trainer/Q1 Predictions Max         -7.93486
trainer/Q1 Predictions Min        -94.9101
trainer/Q2 Predictions Mean       -25.191
trainer/Q2 Predictions Std         29.3286
trainer/Q2 Predictions Max         -7.90064
trainer/Q2 Predictions Min        -94.9721
trainer/Q Targets Mean            -25.2822
trainer/Q Targets Std              29.5182
trainer/Q Targets Max              -7.80035
trainer/Q Targets Min             -95.5982
trainer/Log Pis Mean                2.08435
trainer/Log Pis Std                 1.32264
trainer/Log Pis Max                 6.67728
trainer/Log Pis Min                -1.85789
trainer/Policy mu Mean             -0.00389614
trainer/Policy mu Std               0.735338
trainer/Policy mu Max               2.81892
trainer/Policy mu Min              -3.23662
trainer/Policy log std Mean        -2.10167
trainer/Policy log std Std          0.553549
trainer/Policy log std Max         -0.496711
trainer/Policy log std Min         -2.74199
trainer/Alpha                       0.0688319
trainer/Alpha Loss                  0.225733
exploration/num steps total    111700
exploration/num paths total      1117
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.285529
exploration/Rewards Std             0.651165
exploration/Rewards Max            -0.0103318
exploration/Rewards Min            -7.99052
exploration/Returns Mean          -28.5529
exploration/Returns Std            10.8632
exploration/Returns Max           -15.8817
exploration/Returns Min           -48.6995
exploration/Actions Mean            0.0104865
exploration/Actions Std             0.197202
exploration/Actions Max             0.999539
exploration/Actions Min            -0.996016
exploration/Num Paths               5
exploration/Average Returns       -28.5529
evaluation/num steps total     334500
evaluation/num paths total       3345
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.385841
evaluation/Rewards Std              1.1619
evaluation/Rewards Max             -0.0287228
evaluation/Rewards Min            -10.8162
evaluation/Returns Mean           -38.5841
evaluation/Returns Std             38.043
evaluation/Returns Max             -5.67516
evaluation/Returns Min           -158.146
evaluation/Actions Mean            -0.00323116
evaluation/Actions Std              0.193371
evaluation/Actions Max              0.99937
evaluation/Actions Min             -0.99728
evaluation/Num Paths               15
evaluation/Average Returns        -38.5841
time/data storing (s)               0.00273087
time/evaluation sampling (s)        0.32582
time/exploration sampling (s)       0.13928
time/logging (s)                    0.00480841
time/saving (s)                     0.00196904
time/training (s)                   1.92502
time/epoch (s)                      2.39963
time/total (s)                    545.395
Epoch                             222
-----------------------------  ---------------
2019-04-22 23:36:21.913934 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 223 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   88.6632
trainer/QF2 Loss                   88.6229
trainer/Policy Loss                26.4031
trainer/Q1 Predictions Mean       -24.619
trainer/Q1 Predictions Std         29.6363
trainer/Q1 Predictions Max         -7.70285
trainer/Q1 Predictions Min       -100.736
trainer/Q2 Predictions Mean       -24.6082
trainer/Q2 Predictions Std         29.6356
trainer/Q2 Predictions Max         -7.72935
trainer/Q2 Predictions Min       -100.912
trainer/Q Targets Mean            -23.5673
trainer/Q Targets Std              29.0904
trainer/Q Targets Max              -0.102382
trainer/Q Targets Min             -99.718
trainer/Log Pis Mean                2.08253
trainer/Log Pis Std                 1.21081
trainer/Log Pis Max                 6.97604
trainer/Log Pis Min                -2.65041
trainer/Policy mu Mean              0.0491708
trainer/Policy mu Std               0.61112
trainer/Policy mu Max               2.9405
trainer/Policy mu Min              -2.61151
trainer/Policy log std Mean        -2.14046
trainer/Policy log std Std          0.456283
trainer/Policy log std Max         -0.416898
trainer/Policy log std Min         -2.77817
trainer/Alpha                       0.0699972
trainer/Alpha Loss                  0.219492
exploration/num steps total    112200
exploration/num paths total      1122
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.577003
exploration/Rewards Std             0.878974
exploration/Rewards Max            -0.0119183
exploration/Rewards Min            -7.50024
exploration/Returns Mean          -57.7003
exploration/Returns Std            63.317
exploration/Returns Max           -17.7344
exploration/Returns Min          -183.917
exploration/Actions Mean            0.0144321
exploration/Actions Std             0.204299
exploration/Actions Max             0.997719
exploration/Actions Min            -0.995256
exploration/Num Paths               5
exploration/Average Returns       -57.7003
evaluation/num steps total     336000
evaluation/num paths total       3360
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.593981
evaluation/Rewards Std              1.26872
evaluation/Rewards Max             -0.00847759
evaluation/Rewards Min            -11.3049
evaluation/Returns Mean           -59.3981
evaluation/Returns Std             72.9751
evaluation/Returns Max             -2.23386
evaluation/Returns Min           -214.904
evaluation/Actions Mean            -0.00685376
evaluation/Actions Std              0.199106
evaluation/Actions Max              0.999297
evaluation/Actions Min             -0.999049
evaluation/Num Paths               15
evaluation/Average Returns        -59.3981
time/data storing (s)               0.0025918
time/evaluation sampling (s)        0.321487
time/exploration sampling (s)       0.141601
time/logging (s)                    0.0043292
time/saving (s)                     0.00246499
time/training (s)                   1.94242
time/epoch (s)                      2.41489
time/total (s)                    547.814
Epoch                             223
-----------------------------  ---------------
2019-04-22 23:36:24.311278 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 224 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    3.08065
trainer/QF2 Loss                    3.09665
trainer/Policy Loss                28.0381
trainer/Q1 Predictions Mean       -26.4473
trainer/Q1 Predictions Std         32.0156
trainer/Q1 Predictions Max         -7.67115
trainer/Q1 Predictions Min        -97.0444
trainer/Q2 Predictions Mean       -26.4809
trainer/Q2 Predictions Std         32.0082
trainer/Q2 Predictions Max         -7.69019
trainer/Q2 Predictions Min        -97.4329
trainer/Q Targets Mean            -26.3921
trainer/Q Targets Std              32.4073
trainer/Q Targets Max              -0.212776
trainer/Q Targets Min             -96.7208
trainer/Log Pis Mean                1.8719
trainer/Log Pis Std                 1.07343
trainer/Log Pis Max                 5.30276
trainer/Log Pis Min                -2.63804
trainer/Policy mu Mean             -0.0850024
trainer/Policy mu Std               0.549686
trainer/Policy mu Max               1.70197
trainer/Policy mu Min              -3.27219
trainer/Policy log std Mean        -2.087
trainer/Policy log std Std          0.447276
trainer/Policy log std Max         -0.628182
trainer/Policy log std Min         -2.82376
trainer/Alpha                       0.0705565
trainer/Alpha Loss                 -0.339629
exploration/num steps total    112700
exploration/num paths total      1127
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.330342
exploration/Rewards Std             0.971525
exploration/Rewards Max            -0.0059874
exploration/Rewards Min            -8.64865
exploration/Returns Mean          -33.0342
exploration/Returns Std            12.4747
exploration/Returns Max           -19.3182
exploration/Returns Min           -53.4147
exploration/Actions Mean            0.0101991
exploration/Actions Std             0.229191
exploration/Actions Max             0.998928
exploration/Actions Min            -0.993144
exploration/Num Paths               5
exploration/Average Returns       -33.0342
evaluation/num steps total     337500
evaluation/num paths total       3375
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.470383
evaluation/Rewards Std              1.15573
evaluation/Rewards Max             -0.0168708
evaluation/Rewards Min            -10.8794
evaluation/Returns Mean           -47.0383
evaluation/Returns Std             44.4138
evaluation/Returns Max             -7.06585
evaluation/Returns Min           -155.014
evaluation/Actions Mean            -0.0111055
evaluation/Actions Std              0.194971
evaluation/Actions Max              0.99834
evaluation/Actions Min             -0.997956
evaluation/Num Paths               15
evaluation/Average Returns        -47.0383
time/data storing (s)               0.00265689
time/evaluation sampling (s)        0.331531
time/exploration sampling (s)       0.139321
time/logging (s)                    0.00460603
time/saving (s)                     0.0015953
time/training (s)                   1.91074
time/epoch (s)                      2.39045
time/total (s)                    550.208
Epoch                             224
-----------------------------  ---------------
2019-04-22 23:36:26.722342 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 225 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0662441
trainer/QF2 Loss                    0.109213
trainer/Policy Loss                24.8465
trainer/Q1 Predictions Mean       -23.1543
trainer/Q1 Predictions Std         27.6601
trainer/Q1 Predictions Max         -7.7678
trainer/Q1 Predictions Min       -101.221
trainer/Q2 Predictions Mean       -23.0889
trainer/Q2 Predictions Std         27.6637
trainer/Q2 Predictions Max         -7.84259
trainer/Q2 Predictions Min       -101.268
trainer/Q Targets Mean            -23.2568
trainer/Q Targets Std              27.8013
trainer/Q Targets Max              -7.67944
trainer/Q Targets Min            -100.792
trainer/Log Pis Mean                2.08926
trainer/Log Pis Std                 1.09703
trainer/Log Pis Max                 4.81667
trainer/Log Pis Min                -2.22681
trainer/Policy mu Mean             -0.0370532
trainer/Policy mu Std               0.598114
trainer/Policy mu Max               2.04964
trainer/Policy mu Min              -2.81287
trainer/Policy log std Mean        -2.20716
trainer/Policy log std Std          0.487218
trainer/Policy log std Max         -0.512258
trainer/Policy log std Min         -2.78877
trainer/Alpha                       0.0703625
trainer/Alpha Loss                  0.236918
exploration/num steps total    113200
exploration/num paths total      1132
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.577901
exploration/Rewards Std             1.07031
exploration/Rewards Max            -0.00550489
exploration/Rewards Min            -9.7463
exploration/Returns Mean          -57.7901
exploration/Returns Std            69.4373
exploration/Returns Max           -11.9401
exploration/Returns Min          -195.706
exploration/Actions Mean           -0.0127677
exploration/Actions Std             0.217722
exploration/Actions Max             0.988565
exploration/Actions Min            -0.999708
exploration/Num Paths               5
exploration/Average Returns       -57.7901
evaluation/num steps total     339000
evaluation/num paths total       3390
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.437815
evaluation/Rewards Std              1.30308
evaluation/Rewards Max             -0.00871365
evaluation/Rewards Min            -11.3448
evaluation/Returns Mean           -43.7815
evaluation/Returns Std             47.4769
evaluation/Returns Max             -3.03624
evaluation/Returns Min           -205.066
evaluation/Actions Mean            -0.00183003
evaluation/Actions Std              0.204767
evaluation/Actions Max              0.998352
evaluation/Actions Min             -0.999197
evaluation/Num Paths               15
evaluation/Average Returns        -43.7815
time/data storing (s)               0.00265001
time/evaluation sampling (s)        0.318539
time/exploration sampling (s)       0.13833
time/logging (s)                    0.0047691
time/saving (s)                     0.00201546
time/training (s)                   1.93814
time/epoch (s)                      2.40445
time/total (s)                    552.617
Epoch                             225
-----------------------------  ---------------
2019-04-22 23:36:29.156962 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 226 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.67484
trainer/QF2 Loss                    1.69786
trainer/Policy Loss                24.7906
trainer/Q1 Predictions Mean       -23.2476
trainer/Q1 Predictions Std         27.7966
trainer/Q1 Predictions Max         -7.53962
trainer/Q1 Predictions Min        -97.0914
trainer/Q2 Predictions Mean       -23.2266
trainer/Q2 Predictions Std         27.8022
trainer/Q2 Predictions Max         -7.56852
trainer/Q2 Predictions Min        -97.2243
trainer/Q Targets Mean            -23.4845
trainer/Q Targets Std              28.4908
trainer/Q Targets Max              -0.11264
trainer/Q Targets Min             -97.8606
trainer/Log Pis Mean                1.87527
trainer/Log Pis Std                 1.40361
trainer/Log Pis Max                 8.09246
trainer/Log Pis Min                -2.5644
trainer/Policy mu Mean              0.00956931
trainer/Policy mu Std               0.656951
trainer/Policy mu Max               1.87551
trainer/Policy mu Min              -3.31524
trainer/Policy log std Mean        -2.08571
trainer/Policy log std Std          0.475243
trainer/Policy log std Max         -0.572343
trainer/Policy log std Min         -2.76233
trainer/Alpha                       0.0686706
trainer/Alpha Loss                 -0.334069
exploration/num steps total    113700
exploration/num paths total      1137
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.05749
exploration/Rewards Std             0.994109
exploration/Rewards Max            -0.0193199
exploration/Rewards Min            -9.02926
exploration/Returns Mean         -105.749
exploration/Returns Std            69.9612
exploration/Returns Max           -20.073
exploration/Returns Min          -169.636
exploration/Actions Mean           -0.012218
exploration/Actions Std             0.256247
exploration/Actions Max             0.968205
exploration/Actions Min            -0.998477
exploration/Num Paths               5
exploration/Average Returns      -105.749
evaluation/num steps total     340500
evaluation/num paths total       3405
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.281983
evaluation/Rewards Std              1.00156
evaluation/Rewards Max             -0.00766614
evaluation/Rewards Min             -9.59313
evaluation/Returns Mean           -28.1983
evaluation/Returns Std             14.5338
evaluation/Returns Max             -2.27801
evaluation/Returns Min            -58.2659
evaluation/Actions Mean            -9.73142e-05
evaluation/Actions Std              0.195294
evaluation/Actions Max              0.998813
evaluation/Actions Min             -0.997846
evaluation/Num Paths               15
evaluation/Average Returns        -28.1983
time/data storing (s)               0.00277069
time/evaluation sampling (s)        0.332193
time/exploration sampling (s)       0.138865
time/logging (s)                    0.00476813
time/saving (s)                     0.00156351
time/training (s)                   1.94699
time/epoch (s)                      2.42715
time/total (s)                    555.048
Epoch                             226
-----------------------------  ----------------
2019-04-22 23:36:32.559758 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 227 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.197821
trainer/QF2 Loss                    0.24746
trainer/Policy Loss                28.0232
trainer/Q1 Predictions Mean       -26.0088
trainer/Q1 Predictions Std         31.2452
trainer/Q1 Predictions Max         -7.85089
trainer/Q1 Predictions Min       -118.198
trainer/Q2 Predictions Mean       -25.981
trainer/Q2 Predictions Std         31.154
trainer/Q2 Predictions Max         -7.87066
trainer/Q2 Predictions Min       -117.747
trainer/Q Targets Mean            -26.0038
trainer/Q Targets Std              31.4455
trainer/Q Targets Max              -7.47729
trainer/Q Targets Min            -120.773
trainer/Log Pis Mean                2.27228
trainer/Log Pis Std                 1.57495
trainer/Log Pis Max                11.9815
trainer/Log Pis Min                -1.63386
trainer/Policy mu Mean              0.0240728
trainer/Policy mu Std               0.754845
trainer/Policy mu Max               3.85328
trainer/Policy mu Min              -3.13304
trainer/Policy log std Mean        -2.14041
trainer/Policy log std Std          0.541884
trainer/Policy log std Max         -0.503154
trainer/Policy log std Min         -2.75217
trainer/Alpha                       0.0695881
trainer/Alpha Loss                  0.725704
exploration/num steps total    114200
exploration/num paths total      1142
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.455816
exploration/Rewards Std             1.39765
exploration/Rewards Max            -0.00974861
exploration/Rewards Min            -9.90075
exploration/Returns Mean          -45.5816
exploration/Returns Std            13.8503
exploration/Returns Max           -28.6421
exploration/Returns Min           -63.3111
exploration/Actions Mean           -0.020142
exploration/Actions Std             0.250348
exploration/Actions Max             0.999773
exploration/Actions Min            -0.999441
exploration/Num Paths               5
exploration/Average Returns       -45.5816
evaluation/num steps total     342000
evaluation/num paths total       3420
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.575369
evaluation/Rewards Std              1.16989
evaluation/Rewards Max             -0.00600982
evaluation/Rewards Min             -9.87398
evaluation/Returns Mean           -57.5369
evaluation/Returns Std             65.0292
evaluation/Returns Max             -5.49847
evaluation/Returns Min           -193.816
evaluation/Actions Mean            -0.00264981
evaluation/Actions Std              0.187817
evaluation/Actions Max              0.999432
evaluation/Actions Min             -0.996196
evaluation/Num Paths               15
evaluation/Average Returns        -57.5369
time/data storing (s)               0.00271827
time/evaluation sampling (s)        0.324089
time/exploration sampling (s)       0.140364
time/logging (s)                    0.00513985
time/saving (s)                     0.00221474
time/training (s)                   2.92072
time/epoch (s)                      3.39525
time/total (s)                    558.448
Epoch                             227
-----------------------------  ---------------
2019-04-22 23:36:35.115568 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 228 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.14159
trainer/QF2 Loss                    0.12673
trainer/Policy Loss                27.058
trainer/Q1 Predictions Mean       -25.2939
trainer/Q1 Predictions Std         30.1538
trainer/Q1 Predictions Max         -7.47262
trainer/Q1 Predictions Min        -93.8398
trainer/Q2 Predictions Mean       -25.3179
trainer/Q2 Predictions Std         30.1658
trainer/Q2 Predictions Max         -7.34908
trainer/Q2 Predictions Min        -94.0635
trainer/Q Targets Mean            -25.4594
trainer/Q Targets Std              30.417
trainer/Q Targets Max              -7.51452
trainer/Q Targets Min             -94.6528
trainer/Log Pis Mean                2.04178
trainer/Log Pis Std                 1.20592
trainer/Log Pis Max                 5.92797
trainer/Log Pis Min                -1.35897
trainer/Policy mu Mean             -0.00437605
trainer/Policy mu Std               0.618446
trainer/Policy mu Max               2.80349
trainer/Policy mu Min              -2.83057
trainer/Policy log std Mean        -2.15947
trainer/Policy log std Std          0.474013
trainer/Policy log std Max         -0.403717
trainer/Policy log std Min         -2.85198
trainer/Alpha                       0.0705146
trainer/Alpha Loss                  0.110795
exploration/num steps total    114700
exploration/num paths total      1147
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.876932
exploration/Rewards Std             0.961787
exploration/Rewards Max            -0.00700669
exploration/Rewards Min            -6.81113
exploration/Returns Mean          -87.6932
exploration/Returns Std            70.7635
exploration/Returns Max           -22.6942
exploration/Returns Min          -177.121
exploration/Actions Mean           -0.00581978
exploration/Actions Std             0.21836
exploration/Actions Max             0.998018
exploration/Actions Min            -0.997398
exploration/Num Paths               5
exploration/Average Returns       -87.6932
evaluation/num steps total     343500
evaluation/num paths total       3435
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.570325
evaluation/Rewards Std              1.06382
evaluation/Rewards Max             -0.0332602
evaluation/Rewards Min            -10.5884
evaluation/Returns Mean           -57.0325
evaluation/Returns Std             62.6649
evaluation/Returns Max             -8.83991
evaluation/Returns Min           -189.871
evaluation/Actions Mean            -0.00485864
evaluation/Actions Std              0.17686
evaluation/Actions Max              0.994337
evaluation/Actions Min             -0.997194
evaluation/Num Paths               15
evaluation/Average Returns        -57.0325
time/data storing (s)               0.00300542
time/evaluation sampling (s)        0.359199
time/exploration sampling (s)       0.163735
time/logging (s)                    0.0047869
time/saving (s)                     0.00206226
time/training (s)                   2.01445
time/epoch (s)                      2.54724
time/total (s)                    560.999
Epoch                             228
-----------------------------  ---------------
2019-04-22 23:36:37.619725 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 229 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    3.56148
trainer/QF2 Loss                    3.53683
trainer/Policy Loss                29.2254
trainer/Q1 Predictions Mean       -27.477
trainer/Q1 Predictions Std         32.6819
trainer/Q1 Predictions Max         -7.23649
trainer/Q1 Predictions Min       -104.691
trainer/Q2 Predictions Mean       -27.4674
trainer/Q2 Predictions Std         32.6873
trainer/Q2 Predictions Max         -7.14333
trainer/Q2 Predictions Min       -104.888
trainer/Q Targets Mean            -27.6848
trainer/Q Targets Std              33.2037
trainer/Q Targets Max              -0.65738
trainer/Q Targets Min            -104.765
trainer/Log Pis Mean                2.00106
trainer/Log Pis Std                 1.2229
trainer/Log Pis Max                 4.99526
trainer/Log Pis Min                -3.9025
trainer/Policy mu Mean              0.0163578
trainer/Policy mu Std               0.626936
trainer/Policy mu Max               3.24419
trainer/Policy mu Min              -2.66011
trainer/Policy log std Mean        -2.16035
trainer/Policy log std Std          0.495453
trainer/Policy log std Max         -0.521848
trainer/Policy log std Min         -2.94175
trainer/Alpha                       0.0725191
trainer/Alpha Loss                  0.00277313
exploration/num steps total    115200
exploration/num paths total      1152
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.557818
exploration/Rewards Std             0.894094
exploration/Rewards Max            -0.0160774
exploration/Rewards Min            -7.77221
exploration/Returns Mean          -55.7818
exploration/Returns Std            49.285
exploration/Returns Max           -20.0091
exploration/Returns Min          -151.631
exploration/Actions Mean           -0.0131067
exploration/Actions Std             0.205821
exploration/Actions Max             0.951097
exploration/Actions Min            -0.999593
exploration/Num Paths               5
exploration/Average Returns       -55.7818
evaluation/num steps total     345000
evaluation/num paths total       3450
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.690097
evaluation/Rewards Std              1.16902
evaluation/Rewards Max             -0.0185697
evaluation/Rewards Min             -9.34029
evaluation/Returns Mean           -69.0097
evaluation/Returns Std             63.542
evaluation/Returns Max            -13.8564
evaluation/Returns Min           -186.417
evaluation/Actions Mean             0.0174512
evaluation/Actions Std              0.202451
evaluation/Actions Max              0.997814
evaluation/Actions Min             -0.993522
evaluation/Num Paths               15
evaluation/Average Returns        -69.0097
time/data storing (s)               0.00261408
time/evaluation sampling (s)        0.335262
time/exploration sampling (s)       0.141608
time/logging (s)                    0.00443634
time/saving (s)                     0.00193344
time/training (s)                   2.00993
time/epoch (s)                      2.49578
time/total (s)                    563.499
Epoch                             229
-----------------------------  ---------------
2019-04-22 23:36:40.077358 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 230 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.150196
trainer/QF2 Loss                    0.17497
trainer/Policy Loss                21.0968
trainer/Q1 Predictions Mean       -19.3611
trainer/Q1 Predictions Std         25.0741
trainer/Q1 Predictions Max         -7.0665
trainer/Q1 Predictions Min        -98.1639
trainer/Q2 Predictions Mean       -19.3648
trainer/Q2 Predictions Std         25.0669
trainer/Q2 Predictions Max         -7.02849
trainer/Q2 Predictions Min        -98.4269
trainer/Q Targets Mean            -19.5984
trainer/Q Targets Std              25.2905
trainer/Q Targets Max              -7.31727
trainer/Q Targets Min             -98.7949
trainer/Log Pis Mean                1.88358
trainer/Log Pis Std                 1.17642
trainer/Log Pis Max                 4.80684
trainer/Log Pis Min                -2.17669
trainer/Policy mu Mean              0.0716997
trainer/Policy mu Std               0.563397
trainer/Policy mu Max               2.9518
trainer/Policy mu Min              -2.58925
trainer/Policy log std Mean        -2.22665
trainer/Policy log std Std          0.434142
trainer/Policy log std Max         -0.356762
trainer/Policy log std Min         -2.80173
trainer/Alpha                       0.0733531
trainer/Alpha Loss                 -0.304149
exploration/num steps total    115700
exploration/num paths total      1157
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.492329
exploration/Rewards Std             0.757607
exploration/Rewards Max            -0.00839039
exploration/Rewards Min            -5.24216
exploration/Returns Mean          -49.2329
exploration/Returns Std            63.5988
exploration/Returns Max           -11.4157
exploration/Returns Min          -176.148
exploration/Actions Mean            0.00723497
exploration/Actions Std             0.175333
exploration/Actions Max             0.995282
exploration/Actions Min            -0.996231
exploration/Num Paths               5
exploration/Average Returns       -49.2329
evaluation/num steps total     346500
evaluation/num paths total       3465
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.443073
evaluation/Rewards Std              1.29956
evaluation/Rewards Max             -0.0207959
evaluation/Rewards Min            -10.7716
evaluation/Returns Mean           -44.3073
evaluation/Returns Std             37.0312
evaluation/Returns Max             -9.84116
evaluation/Returns Min           -167.909
evaluation/Actions Mean             0.0143503
evaluation/Actions Std              0.212651
evaluation/Actions Max              0.999157
evaluation/Actions Min             -0.997154
evaluation/Num Paths               15
evaluation/Average Returns        -44.3073
time/data storing (s)               0.0027863
time/evaluation sampling (s)        0.329619
time/exploration sampling (s)       0.144945
time/logging (s)                    0.00474257
time/saving (s)                     0.00205132
time/training (s)                   1.96609
time/epoch (s)                      2.45024
time/total (s)                    565.954
Epoch                             230
-----------------------------  ---------------
2019-04-22 23:36:42.837068 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 231 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0319593
trainer/QF2 Loss                    0.0503893
trainer/Policy Loss                32.7693
trainer/Q1 Predictions Mean       -30.9458
trainer/Q1 Predictions Std         34.7304
trainer/Q1 Predictions Max         -7.30886
trainer/Q1 Predictions Min        -94.2145
trainer/Q2 Predictions Mean       -30.9474
trainer/Q2 Predictions Std         34.7159
trainer/Q2 Predictions Max         -7.25238
trainer/Q2 Predictions Min        -94.2113
trainer/Q Targets Mean            -30.9713
trainer/Q Targets Std              34.7066
trainer/Q Targets Max              -7.23894
trainer/Q Targets Min             -94.3514
trainer/Log Pis Mean                2.00797
trainer/Log Pis Std                 1.21389
trainer/Log Pis Max                 6.12637
trainer/Log Pis Min                -1.28663
trainer/Policy mu Mean              0.012238
trainer/Policy mu Std               0.581775
trainer/Policy mu Max               3.33551
trainer/Policy mu Min              -3.02916
trainer/Policy log std Mean        -2.17427
trainer/Policy log std Std          0.47206
trainer/Policy log std Max         -0.329434
trainer/Policy log std Min         -2.84723
trainer/Alpha                       0.071287
trainer/Alpha Loss                  0.0210451
exploration/num steps total    116200
exploration/num paths total      1162
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.37424
exploration/Rewards Std             1.17077
exploration/Rewards Max            -0.00433843
exploration/Rewards Min            -9.9567
exploration/Returns Mean          -37.424
exploration/Returns Std            17.2186
exploration/Returns Max           -11.77
exploration/Returns Min           -59.7932
exploration/Actions Mean            0.0223112
exploration/Actions Std             0.226389
exploration/Actions Max             0.998954
exploration/Actions Min            -0.999488
exploration/Num Paths               5
exploration/Average Returns       -37.424
evaluation/num steps total     348000
evaluation/num paths total       3480
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.272481
evaluation/Rewards Std              1.01966
evaluation/Rewards Max             -0.0131478
evaluation/Rewards Min            -10.3333
evaluation/Returns Mean           -27.2481
evaluation/Returns Std             15.7883
evaluation/Returns Max             -7.83842
evaluation/Returns Min            -66.1616
evaluation/Actions Mean             0.0159475
evaluation/Actions Std              0.20178
evaluation/Actions Max              0.999014
evaluation/Actions Min             -0.997961
evaluation/Num Paths               15
evaluation/Average Returns        -27.2481
time/data storing (s)               0.00259097
time/evaluation sampling (s)        0.338794
time/exploration sampling (s)       0.143142
time/logging (s)                    0.00480992
time/saving (s)                     0.00197242
time/training (s)                   2.26055
time/epoch (s)                      2.75186
time/total (s)                    568.71
Epoch                             231
-----------------------------  ---------------
2019-04-22 23:36:45.254874 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 232 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                   83.6557
trainer/QF2 Loss                   83.8025
trainer/Policy Loss                30.1969
trainer/Q1 Predictions Mean       -28.3682
trainer/Q1 Predictions Std         32.9787
trainer/Q1 Predictions Max         -7.36945
trainer/Q1 Predictions Min        -93.6553
trainer/Q2 Predictions Mean       -28.3598
trainer/Q2 Predictions Std         32.9953
trainer/Q2 Predictions Max         -7.35168
trainer/Q2 Predictions Min        -93.7888
trainer/Q Targets Mean            -27.5191
trainer/Q Targets Std              32.5035
trainer/Q Targets Max              -1.97839
trainer/Q Targets Min             -93.9652
trainer/Log Pis Mean                2.06603
trainer/Log Pis Std                 1.3341
trainer/Log Pis Max                 6.37045
trainer/Log Pis Min                -1.78006
trainer/Policy mu Mean             -0.0798653
trainer/Policy mu Std               0.591698
trainer/Policy mu Max               2.14854
trainer/Policy mu Min              -3.06674
trainer/Policy log std Mean        -2.1946
trainer/Policy log std Std          0.426137
trainer/Policy log std Max         -0.450501
trainer/Policy log std Min         -2.86763
trainer/Alpha                       0.0717252
trainer/Alpha Loss                  0.173984
exploration/num steps total    116700
exploration/num paths total      1167
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.299265
exploration/Rewards Std             0.892199
exploration/Rewards Max            -0.00486054
exploration/Rewards Min            -8.41182
exploration/Returns Mean          -29.9265
exploration/Returns Std            13.5815
exploration/Returns Max           -11.1765
exploration/Returns Min           -46.0154
exploration/Actions Mean            0.0216234
exploration/Actions Std             0.218326
exploration/Actions Max             0.998238
exploration/Actions Min            -0.988003
exploration/Num Paths               5
exploration/Average Returns       -29.9265
evaluation/num steps total     349500
evaluation/num paths total       3495
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.528769
evaluation/Rewards Std              1.02292
evaluation/Rewards Max             -0.00369815
evaluation/Rewards Min            -10.1998
evaluation/Returns Mean           -52.8769
evaluation/Returns Std             64.5068
evaluation/Returns Max             -6.62639
evaluation/Returns Min           -193.337
evaluation/Actions Mean             9.98187e-05
evaluation/Actions Std              0.178982
evaluation/Actions Max              0.994471
evaluation/Actions Min             -0.997722
evaluation/Num Paths               15
evaluation/Average Returns        -52.8769
time/data storing (s)               0.00270958
time/evaluation sampling (s)        0.337589
time/exploration sampling (s)       0.140185
time/logging (s)                    0.00484185
time/saving (s)                     0.00197485
time/training (s)                   1.9224
time/epoch (s)                      2.4097
time/total (s)                    571.125
Epoch                             232
-----------------------------  ----------------
2019-04-22 23:36:47.682778 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 233 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.920052
trainer/QF2 Loss                    0.909591
trainer/Policy Loss                24.8353
trainer/Q1 Predictions Mean       -22.9742
trainer/Q1 Predictions Std         28.3692
trainer/Q1 Predictions Max         -7.18714
trainer/Q1 Predictions Min        -92.6568
trainer/Q2 Predictions Mean       -22.9434
trainer/Q2 Predictions Std         28.4046
trainer/Q2 Predictions Max         -7.06424
trainer/Q2 Predictions Min        -93.0768
trainer/Q Targets Mean            -23.1275
trainer/Q Targets Std              28.7477
trainer/Q Targets Max              -0.130127
trainer/Q Targets Min             -94.1897
trainer/Log Pis Mean                2.10756
trainer/Log Pis Std                 1.23261
trainer/Log Pis Max                 5.35042
trainer/Log Pis Min                -2.73408
trainer/Policy mu Mean              0.0252054
trainer/Policy mu Std               0.570429
trainer/Policy mu Max               3.10853
trainer/Policy mu Min              -2.91239
trainer/Policy log std Mean        -2.22928
trainer/Policy log std Std          0.438329
trainer/Policy log std Max         -0.409924
trainer/Policy log std Min         -2.74937
trainer/Alpha                       0.0744707
trainer/Alpha Loss                  0.279357
exploration/num steps total    117200
exploration/num paths total      1172
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.503366
exploration/Rewards Std             0.77614
exploration/Rewards Max            -0.00355292
exploration/Rewards Min            -7.47777
exploration/Returns Mean          -50.3366
exploration/Returns Std            59.7279
exploration/Returns Max           -17.7839
exploration/Returns Min          -169.657
exploration/Actions Mean           -0.00651442
exploration/Actions Std             0.196556
exploration/Actions Max             0.988305
exploration/Actions Min            -0.999358
exploration/Num Paths               5
exploration/Average Returns       -50.3366
evaluation/num steps total     351000
evaluation/num paths total       3510
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.284676
evaluation/Rewards Std              0.885264
evaluation/Rewards Max             -0.00424156
evaluation/Rewards Min             -9.95519
evaluation/Returns Mean           -28.4676
evaluation/Returns Std             36.155
evaluation/Returns Max             -4.08639
evaluation/Returns Min           -154.052
evaluation/Actions Mean            -0.00191981
evaluation/Actions Std              0.168373
evaluation/Actions Max              0.998976
evaluation/Actions Min             -0.998221
evaluation/Num Paths               15
evaluation/Average Returns        -28.4676
time/data storing (s)               0.00280419
time/evaluation sampling (s)        0.323747
time/exploration sampling (s)       0.140899
time/logging (s)                    0.00486588
time/saving (s)                     0.00158366
time/training (s)                   1.94571
time/epoch (s)                      2.41961
time/total (s)                    573.549
Epoch                             233
-----------------------------  ---------------
2019-04-22 23:36:50.096718 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 234 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.705623
trainer/QF2 Loss                    0.703574
trainer/Policy Loss                26.2189
trainer/Q1 Predictions Mean       -24.3262
trainer/Q1 Predictions Std         31.3081
trainer/Q1 Predictions Max         -7.09551
trainer/Q1 Predictions Min        -93.7609
trainer/Q2 Predictions Mean       -24.3353
trainer/Q2 Predictions Std         31.3347
trainer/Q2 Predictions Max         -7.08035
trainer/Q2 Predictions Min        -93.6198
trainer/Q Targets Mean            -24.4962
trainer/Q Targets Std              31.6315
trainer/Q Targets Max              -0.0119183
trainer/Q Targets Min             -94.8767
trainer/Log Pis Mean                2.01059
trainer/Log Pis Std                 1.29836
trainer/Log Pis Max                 8.62835
trainer/Log Pis Min                -2.01051
trainer/Policy mu Mean             -0.0197053
trainer/Policy mu Std               0.566313
trainer/Policy mu Max               2.81968
trainer/Policy mu Min              -3.1776
trainer/Policy log std Mean        -2.21687
trainer/Policy log std Std          0.394274
trainer/Policy log std Max         -0.677905
trainer/Policy log std Min         -2.72328
trainer/Alpha                       0.0732186
trainer/Alpha Loss                  0.0276872
exploration/num steps total    117700
exploration/num paths total      1177
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.420281
exploration/Rewards Std             1.11973
exploration/Rewards Max            -0.00432307
exploration/Rewards Min            -9.27566
exploration/Returns Mean          -42.0281
exploration/Returns Std            13.157
exploration/Returns Max           -27.2402
exploration/Returns Min           -61.8443
exploration/Actions Mean           -0.00845667
exploration/Actions Std             0.235328
exploration/Actions Max             0.998753
exploration/Actions Min            -0.998529
exploration/Num Paths               5
exploration/Average Returns       -42.0281
evaluation/num steps total     352500
evaluation/num paths total       3525
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.459517
evaluation/Rewards Std              1.12721
evaluation/Rewards Max             -0.0080025
evaluation/Rewards Min             -9.84203
evaluation/Returns Mean           -45.9517
evaluation/Returns Std             59.0466
evaluation/Returns Max             -6.98119
evaluation/Returns Min           -198.595
evaluation/Actions Mean            -0.00443759
evaluation/Actions Std              0.184802
evaluation/Actions Max              0.997579
evaluation/Actions Min             -0.998014
evaluation/Num Paths               15
evaluation/Average Returns        -45.9517
time/data storing (s)               0.0028543
time/evaluation sampling (s)        0.3217
time/exploration sampling (s)       0.139269
time/logging (s)                    0.00484446
time/saving (s)                     0.00195232
time/training (s)                   1.93511
time/epoch (s)                      2.40573
time/total (s)                    575.959
Epoch                             234
-----------------------------  ---------------
2019-04-22 23:36:52.519978 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 235 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    3.34318
trainer/QF2 Loss                    3.38176
trainer/Policy Loss                26.8696
trainer/Q1 Predictions Mean       -25.107
trainer/Q1 Predictions Std         30.5457
trainer/Q1 Predictions Max         -7.31048
trainer/Q1 Predictions Min        -92.8304
trainer/Q2 Predictions Mean       -25.0829
trainer/Q2 Predictions Std         30.5096
trainer/Q2 Predictions Max         -7.29914
trainer/Q2 Predictions Min        -92.6761
trainer/Q Targets Mean            -25.0366
trainer/Q Targets Std              31.0018
trainer/Q Targets Max              -0.383607
trainer/Q Targets Min             -93.7151
trainer/Log Pis Mean                2.00079
trainer/Log Pis Std                 1.17313
trainer/Log Pis Max                 4.92096
trainer/Log Pis Min                -2.81704
trainer/Policy mu Mean              0.0242489
trainer/Policy mu Std               0.565254
trainer/Policy mu Max               2.65056
trainer/Policy mu Min              -2.72983
trainer/Policy log std Mean        -2.17588
trainer/Policy log std Std          0.45027
trainer/Policy log std Max         -0.625984
trainer/Policy log std Min         -2.73379
trainer/Alpha                       0.0716744
trainer/Alpha Loss                  0.0020787
exploration/num steps total    118200
exploration/num paths total      1182
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.504365
exploration/Rewards Std             0.792614
exploration/Rewards Max            -0.00149384
exploration/Rewards Min            -6.39706
exploration/Returns Mean          -50.4365
exploration/Returns Std            54.3094
exploration/Returns Max           -13.6129
exploration/Returns Min          -158.446
exploration/Actions Mean            0.00602602
exploration/Actions Std             0.195472
exploration/Actions Max             0.988028
exploration/Actions Min            -0.9948
exploration/Num Paths               5
exploration/Average Returns       -50.4365
evaluation/num steps total     354000
evaluation/num paths total       3540
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.577743
evaluation/Rewards Std              1.22256
evaluation/Rewards Max             -0.0115703
evaluation/Rewards Min            -11.4065
evaluation/Returns Mean           -57.7743
evaluation/Returns Std             58.8351
evaluation/Returns Max             -7.29143
evaluation/Returns Min           -177.404
evaluation/Actions Mean            -0.0168877
evaluation/Actions Std              0.202759
evaluation/Actions Max              0.996765
evaluation/Actions Min             -0.998912
evaluation/Num Paths               15
evaluation/Average Returns        -57.7743
time/data storing (s)               0.00281167
time/evaluation sampling (s)        0.325926
time/exploration sampling (s)       0.140012
time/logging (s)                    0.00478671
time/saving (s)                     0.00196435
time/training (s)                   1.93952
time/epoch (s)                      2.41502
time/total (s)                    578.378
Epoch                             235
-----------------------------  ---------------
2019-04-22 23:36:54.945636 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 236 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.04935
trainer/QF2 Loss                    1.02657
trainer/Policy Loss                23.1728
trainer/Q1 Predictions Mean       -21.3598
trainer/Q1 Predictions Std         28.019
trainer/Q1 Predictions Max         -7.40037
trainer/Q1 Predictions Min       -106.536
trainer/Q2 Predictions Mean       -21.3583
trainer/Q2 Predictions Std         28.0084
trainer/Q2 Predictions Max         -7.32692
trainer/Q2 Predictions Min       -106.309
trainer/Q Targets Mean            -21.4907
trainer/Q Targets Std              28.2827
trainer/Q Targets Max              -0.559665
trainer/Q Targets Min            -107.385
trainer/Log Pis Mean                2.04049
trainer/Log Pis Std                 0.919605
trainer/Log Pis Max                 4.32946
trainer/Log Pis Min                -1.07897
trainer/Policy mu Mean             -0.0102924
trainer/Policy mu Std               0.52876
trainer/Policy mu Max               2.86177
trainer/Policy mu Min              -2.55663
trainer/Policy log std Mean        -2.16247
trainer/Policy log std Std          0.37745
trainer/Policy log std Max         -0.651899
trainer/Policy log std Min         -2.74043
trainer/Alpha                       0.069442
trainer/Alpha Loss                  0.107981
exploration/num steps total    118700
exploration/num paths total      1187
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.973991
exploration/Rewards Std             1.3402
exploration/Rewards Max            -0.0116406
exploration/Rewards Min            -9.15083
exploration/Returns Mean          -97.3991
exploration/Returns Std            58.8418
exploration/Returns Max           -39.7688
exploration/Returns Min          -178.526
exploration/Actions Mean           -0.00425869
exploration/Actions Std             0.270768
exploration/Actions Max             0.999191
exploration/Actions Min            -0.996629
exploration/Num Paths               5
exploration/Average Returns       -97.3991
evaluation/num steps total     355500
evaluation/num paths total       3555
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.354948
evaluation/Rewards Std              0.974158
evaluation/Rewards Max             -0.0241206
evaluation/Rewards Min            -11.1006
evaluation/Returns Mean           -35.4948
evaluation/Returns Std             35.7735
evaluation/Returns Max             -6.63687
evaluation/Returns Min           -153.138
evaluation/Actions Mean             0.00562199
evaluation/Actions Std              0.182518
evaluation/Actions Max              0.998492
evaluation/Actions Min             -0.99764
evaluation/Num Paths               15
evaluation/Average Returns        -35.4948
time/data storing (s)               0.00274781
time/evaluation sampling (s)        0.329282
time/exploration sampling (s)       0.14262
time/logging (s)                    0.00478652
time/saving (s)                     0.00197717
time/training (s)                   1.93597
time/epoch (s)                      2.41738
time/total (s)                    580.8
Epoch                             236
-----------------------------  ---------------
2019-04-22 23:36:57.367509 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 237 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    2.09052
trainer/QF2 Loss                    2.10112
trainer/Policy Loss                23.2207
trainer/Q1 Predictions Mean       -21.4652
trainer/Q1 Predictions Std         28.0038
trainer/Q1 Predictions Max         -7.25319
trainer/Q1 Predictions Min        -95.0708
trainer/Q2 Predictions Mean       -21.4498
trainer/Q2 Predictions Std         27.9922
trainer/Q2 Predictions Max         -7.24266
trainer/Q2 Predictions Min        -95.4462
trainer/Q Targets Mean            -21.3901
trainer/Q Targets Std              28.0463
trainer/Q Targets Max              -1.00775
trainer/Q Targets Min             -94.8552
trainer/Log Pis Mean                1.92851
trainer/Log Pis Std                 1.18028
trainer/Log Pis Max                 6.03698
trainer/Log Pis Min                -1.95414
trainer/Policy mu Mean              0.00591893
trainer/Policy mu Std               0.503456
trainer/Policy mu Max               2.91402
trainer/Policy mu Min              -3.00331
trainer/Policy log std Mean        -2.23729
trainer/Policy log std Std          0.376076
trainer/Policy log std Max         -0.572948
trainer/Policy log std Min         -2.72133
trainer/Alpha                       0.0701472
trainer/Alpha Loss                 -0.189974
exploration/num steps total    119200
exploration/num paths total      1192
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.647103
exploration/Rewards Std             1.3496
exploration/Rewards Max            -0.00484538
exploration/Rewards Min           -11.4271
exploration/Returns Mean          -64.7103
exploration/Returns Std            47.7789
exploration/Returns Max           -12.3857
exploration/Returns Min          -154.299
exploration/Actions Mean            0.0106745
exploration/Actions Std             0.253939
exploration/Actions Max             0.999672
exploration/Actions Min            -0.998608
exploration/Num Paths               5
exploration/Average Returns       -64.7103
evaluation/num steps total     357000
evaluation/num paths total       3570
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.390067
evaluation/Rewards Std              0.95821
evaluation/Rewards Max             -0.0110428
evaluation/Rewards Min             -9.68509
evaluation/Returns Mean           -39.0067
evaluation/Returns Std             52.1914
evaluation/Returns Max             -3.87626
evaluation/Returns Min           -178.226
evaluation/Actions Mean             0.000109673
evaluation/Actions Std              0.174551
evaluation/Actions Max              0.998004
evaluation/Actions Min             -0.995743
evaluation/Num Paths               15
evaluation/Average Returns        -39.0067
time/data storing (s)               0.00263414
time/evaluation sampling (s)        0.330397
time/exploration sampling (s)       0.140478
time/logging (s)                    0.00476808
time/saving (s)                     0.00193978
time/training (s)                   1.93332
time/epoch (s)                      2.41354
time/total (s)                    583.218
Epoch                             237
-----------------------------  ----------------
2019-04-22 23:36:59.794155 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 238 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.243748
trainer/QF2 Loss                    0.24309
trainer/Policy Loss                27.1859
trainer/Q1 Predictions Mean       -25.5493
trainer/Q1 Predictions Std         31.2748
trainer/Q1 Predictions Max         -7.1188
trainer/Q1 Predictions Min        -92.1382
trainer/Q2 Predictions Mean       -25.5377
trainer/Q2 Predictions Std         31.293
trainer/Q2 Predictions Max         -7.08231
trainer/Q2 Predictions Min        -92.2771
trainer/Q Targets Mean            -25.8086
trainer/Q Targets Std              31.6353
trainer/Q Targets Max              -7.07088
trainer/Q Targets Min             -93.1796
trainer/Log Pis Mean                1.81509
trainer/Log Pis Std                 1.09198
trainer/Log Pis Max                 4.88017
trainer/Log Pis Min                -2.21581
trainer/Policy mu Mean              0.0116681
trainer/Policy mu Std               0.503767
trainer/Policy mu Max               3.87914
trainer/Policy mu Min              -2.82166
trainer/Policy log std Mean        -2.23488
trainer/Policy log std Std          0.416185
trainer/Policy log std Max         -0.438854
trainer/Policy log std Min         -2.73367
trainer/Alpha                       0.0684718
trainer/Alpha Loss                 -0.495809
exploration/num steps total    119700
exploration/num paths total      1197
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.587083
exploration/Rewards Std             1.03963
exploration/Rewards Max            -0.0051927
exploration/Rewards Min            -9.77946
exploration/Returns Mean          -58.7083
exploration/Returns Std            51.8791
exploration/Returns Max           -20.3335
exploration/Returns Min          -157.071
exploration/Actions Mean            0.0263982
exploration/Actions Std             0.224241
exploration/Actions Max             0.999472
exploration/Actions Min            -0.992376
exploration/Num Paths               5
exploration/Average Returns       -58.7083
evaluation/num steps total     358500
evaluation/num paths total       3585
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.200488
evaluation/Rewards Std              0.720943
evaluation/Rewards Max             -0.00455983
evaluation/Rewards Min             -9.05189
evaluation/Returns Mean           -20.0488
evaluation/Returns Std             15.2801
evaluation/Returns Max             -1.64985
evaluation/Returns Min            -60.6687
evaluation/Actions Mean             0.00612127
evaluation/Actions Std              0.170502
evaluation/Actions Max              0.997148
evaluation/Actions Min             -0.995052
evaluation/Num Paths               15
evaluation/Average Returns        -20.0488
time/data storing (s)               0.00291704
time/evaluation sampling (s)        0.324317
time/exploration sampling (s)       0.14177
time/logging (s)                    0.00490701
time/saving (s)                     0.00195301
time/training (s)                   1.94261
time/epoch (s)                      2.41848
time/total (s)                    585.641
Epoch                             238
-----------------------------  ---------------
2019-04-22 23:37:02.222331 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 239 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.66088
trainer/QF2 Loss                    1.6673
trainer/Policy Loss                23.5166
trainer/Q1 Predictions Mean       -21.6873
trainer/Q1 Predictions Std         27.3128
trainer/Q1 Predictions Max         -7.0691
trainer/Q1 Predictions Min        -91.1963
trainer/Q2 Predictions Mean       -21.7309
trainer/Q2 Predictions Std         27.3025
trainer/Q2 Predictions Max         -6.98458
trainer/Q2 Predictions Min        -91.2807
trainer/Q Targets Mean            -21.8644
trainer/Q Targets Std              27.8067
trainer/Q Targets Max              -0.0762077
trainer/Q Targets Min             -92.9496
trainer/Log Pis Mean                2.00872
trainer/Log Pis Std                 1.62785
trainer/Log Pis Max                 7.48058
trainer/Log Pis Min                -3.60322
trainer/Policy mu Mean             -0.00960979
trainer/Policy mu Std               0.710758
trainer/Policy mu Max               2.78306
trainer/Policy mu Min              -3.39255
trainer/Policy log std Mean        -2.16641
trainer/Policy log std Std          0.509012
trainer/Policy log std Max         -0.387104
trainer/Policy log std Min         -2.7434
trainer/Alpha                       0.0707101
trainer/Alpha Loss                  0.0230892
exploration/num steps total    120200
exploration/num paths total      1202
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.290583
exploration/Rewards Std             0.914339
exploration/Rewards Max            -0.00315729
exploration/Rewards Min            -8.37104
exploration/Returns Mean          -29.0583
exploration/Returns Std            16.722
exploration/Returns Max           -10.9948
exploration/Returns Min           -51.0338
exploration/Actions Mean            0.00734943
exploration/Actions Std             0.195331
exploration/Actions Max             0.999776
exploration/Actions Min            -0.998031
exploration/Num Paths               5
exploration/Average Returns       -29.0583
evaluation/num steps total     360000
evaluation/num paths total       3600
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.394655
evaluation/Rewards Std              1.11743
evaluation/Rewards Max             -0.0136548
evaluation/Rewards Min             -9.25682
evaluation/Returns Mean           -39.4655
evaluation/Returns Std             38.8461
evaluation/Returns Max            -11.8866
evaluation/Returns Min           -179.453
evaluation/Actions Mean             0.00476595
evaluation/Actions Std              0.205917
evaluation/Actions Max              0.998996
evaluation/Actions Min             -0.996967
evaluation/Num Paths               15
evaluation/Average Returns        -39.4655
time/data storing (s)               0.00262819
time/evaluation sampling (s)        0.329626
time/exploration sampling (s)       0.14122
time/logging (s)                    0.00454589
time/saving (s)                     0.00193537
time/training (s)                   1.93957
time/epoch (s)                      2.41953
time/total (s)                    588.065
Epoch                             239
-----------------------------  ---------------
2019-04-22 23:37:04.643651 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 240 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                  161.328
trainer/QF2 Loss                  161.09
trainer/Policy Loss                21.4012
trainer/Q1 Predictions Mean       -19.591
trainer/Q1 Predictions Std         25.4798
trainer/Q1 Predictions Max         -7.07659
trainer/Q1 Predictions Min        -92.4206
trainer/Q2 Predictions Mean       -19.6146
trainer/Q2 Predictions Std         25.4938
trainer/Q2 Predictions Max         -7.10844
trainer/Q2 Predictions Min        -92.4341
trainer/Q Targets Mean            -17.7261
trainer/Q Targets Std              23.5473
trainer/Q Targets Max              -0.199001
trainer/Q Targets Min             -92.5908
trainer/Log Pis Mean                2.05779
trainer/Log Pis Std                 1.1906
trainer/Log Pis Max                 5.29939
trainer/Log Pis Min                -2.73139
trainer/Policy mu Mean              0.0118393
trainer/Policy mu Std               0.495399
trainer/Policy mu Max               2.49739
trainer/Policy mu Min              -3.03445
trainer/Policy log std Mean        -2.27313
trainer/Policy log std Std          0.392871
trainer/Policy log std Max         -0.437661
trainer/Policy log std Min         -2.75809
trainer/Alpha                       0.0730334
trainer/Alpha Loss                  0.151241
exploration/num steps total    120700
exploration/num paths total      1207
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.574385
exploration/Rewards Std             1.05126
exploration/Rewards Max            -0.0106069
exploration/Rewards Min            -9.66821
exploration/Returns Mean          -57.4385
exploration/Returns Std            48.53
exploration/Returns Max           -18.7381
exploration/Returns Min          -150.896
exploration/Actions Mean            0.0161493
exploration/Actions Std             0.218326
exploration/Actions Max             0.999923
exploration/Actions Min            -0.998227
exploration/Num Paths               5
exploration/Average Returns       -57.4385
evaluation/num steps total     361500
evaluation/num paths total       3615
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.306072
evaluation/Rewards Std              1.15974
evaluation/Rewards Max             -0.0294439
evaluation/Rewards Min            -10.5097
evaluation/Returns Mean           -30.6072
evaluation/Returns Std             14.9974
evaluation/Returns Max             -4.83842
evaluation/Returns Min            -56.293
evaluation/Actions Mean             0.0145873
evaluation/Actions Std              0.212726
evaluation/Actions Max              0.999326
evaluation/Actions Min             -0.996483
evaluation/Num Paths               15
evaluation/Average Returns        -30.6072
time/data storing (s)               0.00280742
time/evaluation sampling (s)        0.325198
time/exploration sampling (s)       0.141585
time/logging (s)                    0.00479197
time/saving (s)                     0.00156652
time/training (s)                   1.93742
time/epoch (s)                      2.41337
time/total (s)                    590.483
Epoch                             240
-----------------------------  ---------------
2019-04-22 23:37:07.031948 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 241 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.819769
trainer/QF2 Loss                    0.789346
trainer/Policy Loss                24.6769
trainer/Q1 Predictions Mean       -22.799
trainer/Q1 Predictions Std         29.1573
trainer/Q1 Predictions Max         -6.94742
trainer/Q1 Predictions Min        -90.2813
trainer/Q2 Predictions Mean       -22.8226
trainer/Q2 Predictions Std         29.1733
trainer/Q2 Predictions Max         -6.86304
trainer/Q2 Predictions Min        -90.5658
trainer/Q Targets Mean            -23.3276
trainer/Q Targets Std              29.8696
trainer/Q Targets Max              -7.14429
trainer/Q Targets Min             -91.8814
trainer/Log Pis Mean                2.04494
trainer/Log Pis Std                 0.827408
trainer/Log Pis Max                 4.31424
trainer/Log Pis Min                -0.527099
trainer/Policy mu Mean              0.0195855
trainer/Policy mu Std               0.439449
trainer/Policy mu Max               2.73661
trainer/Policy mu Min              -2.65302
trainer/Policy log std Mean        -2.20339
trainer/Policy log std Std          0.335643
trainer/Policy log std Max         -0.459593
trainer/Policy log std Min         -2.74845
trainer/Alpha                       0.0739863
trainer/Alpha Loss                  0.117016
exploration/num steps total    121200
exploration/num paths total      1212
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.33043
exploration/Rewards Std             1.00255
exploration/Rewards Max            -0.0128889
exploration/Rewards Min            -8.23866
exploration/Returns Mean          -33.043
exploration/Returns Std            16.785
exploration/Returns Max           -12.5001
exploration/Returns Min           -51.3046
exploration/Actions Mean            0.0103867
exploration/Actions Std             0.20615
exploration/Actions Max             0.999627
exploration/Actions Min            -0.998274
exploration/Num Paths               5
exploration/Average Returns       -33.043
evaluation/num steps total     363000
evaluation/num paths total       3630
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.309966
evaluation/Rewards Std              1.05565
evaluation/Rewards Max             -0.0116963
evaluation/Rewards Min            -10.339
evaluation/Returns Mean           -30.9966
evaluation/Returns Std             19.0883
evaluation/Returns Max             -5.81634
evaluation/Returns Min            -63.4268
evaluation/Actions Mean             0.0181892
evaluation/Actions Std              0.193354
evaluation/Actions Max              0.998944
evaluation/Actions Min             -0.996778
evaluation/Num Paths               15
evaluation/Average Returns        -30.9966
time/data storing (s)               0.00265156
time/evaluation sampling (s)        0.327481
time/exploration sampling (s)       0.145886
time/logging (s)                    0.00486665
time/saving (s)                     0.00198658
time/training (s)                   1.89731
time/epoch (s)                      2.38018
time/total (s)                    592.867
Epoch                             241
-----------------------------  ---------------
2019-04-22 23:37:09.444066 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 242 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.412183
trainer/QF2 Loss                    0.345184
trainer/Policy Loss                24.7602
trainer/Q1 Predictions Mean       -23.221
trainer/Q1 Predictions Std         29.4561
trainer/Q1 Predictions Max         -6.89035
trainer/Q1 Predictions Min        -90.4972
trainer/Q2 Predictions Mean       -23.2819
trainer/Q2 Predictions Std         29.4666
trainer/Q2 Predictions Max         -6.77597
trainer/Q2 Predictions Min        -90.6285
trainer/Q Targets Mean            -23.6034
trainer/Q Targets Std              29.9129
trainer/Q Targets Max              -7.02338
trainer/Q Targets Min             -92.3586
trainer/Log Pis Mean                1.75077
trainer/Log Pis Std                 1.13912
trainer/Log Pis Max                 4.66524
trainer/Log Pis Min                -1.48913
trainer/Policy mu Mean              0.0457659
trainer/Policy mu Std               0.535488
trainer/Policy mu Max               3.23338
trainer/Policy mu Min              -2.15762
trainer/Policy log std Mean        -2.15625
trainer/Policy log std Std          0.400547
trainer/Policy log std Max         -0.580352
trainer/Policy log std Min         -2.6873
trainer/Alpha                       0.0726808
trainer/Alpha Loss                 -0.653395
exploration/num steps total    121700
exploration/num paths total      1217
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.528154
exploration/Rewards Std             0.823527
exploration/Rewards Max            -0.00551087
exploration/Rewards Min            -5.90307
exploration/Returns Mean          -52.8154
exploration/Returns Std            56.501
exploration/Returns Max           -18.8498
exploration/Returns Min          -165.639
exploration/Actions Mean           -0.0128702
exploration/Actions Std             0.218776
exploration/Actions Max             0.997587
exploration/Actions Min            -0.998192
exploration/Num Paths               5
exploration/Average Returns       -52.8154
evaluation/num steps total     364500
evaluation/num paths total       3645
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.466616
evaluation/Rewards Std              1.08902
evaluation/Rewards Max             -0.0083937
evaluation/Rewards Min            -10.1265
evaluation/Returns Mean           -46.6616
evaluation/Returns Std             54.2532
evaluation/Returns Max             -9.45222
evaluation/Returns Min           -196.039
evaluation/Actions Mean            -0.0106124
evaluation/Actions Std              0.187953
evaluation/Actions Max              0.998255
evaluation/Actions Min             -0.99909
evaluation/Num Paths               15
evaluation/Average Returns        -46.6616
time/data storing (s)               0.00263062
time/evaluation sampling (s)        0.324732
time/exploration sampling (s)       0.14174
time/logging (s)                    0.00480243
time/saving (s)                     0.00195574
time/training (s)                   1.92806
time/epoch (s)                      2.40392
time/total (s)                    595.276
Epoch                             242
-----------------------------  ---------------
2019-04-22 23:37:11.877701 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 243 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.128874
trainer/QF2 Loss                    0.108457
trainer/Policy Loss                30.0318
trainer/Q1 Predictions Mean       -28.2254
trainer/Q1 Predictions Std         33.3366
trainer/Q1 Predictions Max         -7.10515
trainer/Q1 Predictions Min        -97.4122
trainer/Q2 Predictions Mean       -28.233
trainer/Q2 Predictions Std         33.3207
trainer/Q2 Predictions Max         -7.11021
trainer/Q2 Predictions Min        -96.772
trainer/Q Targets Mean            -28.3026
trainer/Q Targets Std              33.1783
trainer/Q Targets Max              -7.11674
trainer/Q Targets Min             -96.2404
trainer/Log Pis Mean                1.99851
trainer/Log Pis Std                 1.49997
trainer/Log Pis Max                 9.25266
trainer/Log Pis Min                -3.38382
trainer/Policy mu Mean              0.112667
trainer/Policy mu Std               0.615347
trainer/Policy mu Max               3.48846
trainer/Policy mu Min              -2.61109
trainer/Policy log std Mean        -2.14797
trainer/Policy log std Std          0.432925
trainer/Policy log std Max         -0.232185
trainer/Policy log std Min         -2.75704
trainer/Alpha                       0.069202
trainer/Alpha Loss                 -0.00397312
exploration/num steps total    122200
exploration/num paths total      1222
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.723687
exploration/Rewards Std             1.21664
exploration/Rewards Max            -0.010686
exploration/Rewards Min            -8.79175
exploration/Returns Mean          -72.3687
exploration/Returns Std            62.8775
exploration/Returns Max           -28.0602
exploration/Returns Min          -195.979
exploration/Actions Mean           -0.0199311
exploration/Actions Std             0.21999
exploration/Actions Max             0.977196
exploration/Actions Min            -0.998652
exploration/Num Paths               5
exploration/Average Returns       -72.3687
evaluation/num steps total     366000
evaluation/num paths total       3660
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.374574
evaluation/Rewards Std              0.99427
evaluation/Rewards Max             -0.0215377
evaluation/Rewards Min             -9.74158
evaluation/Returns Mean           -37.4574
evaluation/Returns Std             45.4575
evaluation/Returns Max             -7.06648
evaluation/Returns Min           -195.487
evaluation/Actions Mean             0.00975948
evaluation/Actions Std              0.175542
evaluation/Actions Max              0.999113
evaluation/Actions Min             -0.995478
evaluation/Num Paths               15
evaluation/Average Returns        -37.4574
time/data storing (s)               0.00268845
time/evaluation sampling (s)        0.327257
time/exploration sampling (s)       0.140015
time/logging (s)                    0.00480811
time/saving (s)                     0.0051138
time/training (s)                   1.94557
time/epoch (s)                      2.42545
time/total (s)                    597.705
Epoch                             243
-----------------------------  ---------------
2019-04-22 23:37:14.295974 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 244 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    2.53373
trainer/QF2 Loss                    2.4472
trainer/Policy Loss                25.7051
trainer/Q1 Predictions Mean       -23.8223
trainer/Q1 Predictions Std         30.121
trainer/Q1 Predictions Max         -6.96674
trainer/Q1 Predictions Min        -95.0111
trainer/Q2 Predictions Mean       -23.852
trainer/Q2 Predictions Std         30.1668
trainer/Q2 Predictions Max         -6.96553
trainer/Q2 Predictions Min        -95.0621
trainer/Q Targets Mean            -24.0695
trainer/Q Targets Std              30.9145
trainer/Q Targets Max              -0.608144
trainer/Q Targets Min             -95.8821
trainer/Log Pis Mean                2.04186
trainer/Log Pis Std                 1.46512
trainer/Log Pis Max                 6.70097
trainer/Log Pis Min                -5.54792
trainer/Policy mu Mean             -0.16898
trainer/Policy mu Std               0.615738
trainer/Policy mu Max               1.38994
trainer/Policy mu Min              -3.13335
trainer/Policy log std Mean        -2.19533
trainer/Policy log std Std          0.398521
trainer/Policy log std Max         -0.548122
trainer/Policy log std Min         -2.67789
trainer/Alpha                       0.0730963
trainer/Alpha Loss                  0.109501
exploration/num steps total    122700
exploration/num paths total      1227
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.684125
exploration/Rewards Std             1.27148
exploration/Rewards Max            -0.0100865
exploration/Rewards Min           -10.7579
exploration/Returns Mean          -68.4125
exploration/Returns Std            57.9084
exploration/Returns Max           -18.5679
exploration/Returns Min          -180.05
exploration/Actions Mean           -0.0102478
exploration/Actions Std             0.248108
exploration/Actions Max             0.999636
exploration/Actions Min            -0.999162
exploration/Num Paths               5
exploration/Average Returns       -68.4125
evaluation/num steps total     367500
evaluation/num paths total       3675
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.645906
evaluation/Rewards Std              1.03905
evaluation/Rewards Max             -0.00428505
evaluation/Rewards Min            -10.3254
evaluation/Returns Mean           -64.5906
evaluation/Returns Std             66.1302
evaluation/Returns Max            -11.9832
evaluation/Returns Min           -199.473
evaluation/Actions Mean            -0.0113804
evaluation/Actions Std              0.177498
evaluation/Actions Max              0.996652
evaluation/Actions Min             -0.998758
evaluation/Num Paths               15
evaluation/Average Returns        -64.5906
time/data storing (s)               0.00280864
time/evaluation sampling (s)        0.325959
time/exploration sampling (s)       0.13963
time/logging (s)                    0.004843
time/saving (s)                     0.00197977
time/training (s)                   1.93519
time/epoch (s)                      2.41041
time/total (s)                    600.12
Epoch                             244
-----------------------------  ---------------
2019-04-22 23:37:16.710097 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 245 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.01807
trainer/QF2 Loss                    1.01726
trainer/Policy Loss                24.2337
trainer/Q1 Predictions Mean       -22.5261
trainer/Q1 Predictions Std         29.1294
trainer/Q1 Predictions Max         -7.02245
trainer/Q1 Predictions Min        -89.6024
trainer/Q2 Predictions Mean       -22.5176
trainer/Q2 Predictions Std         29.1466
trainer/Q2 Predictions Max         -6.99401
trainer/Q2 Predictions Min        -89.7645
trainer/Q Targets Mean            -22.7775
trainer/Q Targets Std              29.674
trainer/Q Targets Max              -0.178131
trainer/Q Targets Min             -91.1819
trainer/Log Pis Mean                1.85595
trainer/Log Pis Std                 1.29411
trainer/Log Pis Max                 5.30611
trainer/Log Pis Min                -4.92979
trainer/Policy mu Mean             -0.00887726
trainer/Policy mu Std               0.394004
trainer/Policy mu Max               2.33379
trainer/Policy mu Min              -2.87554
trainer/Policy log std Mean        -2.24199
trainer/Policy log std Std          0.318188
trainer/Policy log std Max         -0.431933
trainer/Policy log std Min         -2.67934
trainer/Alpha                       0.0722742
trainer/Alpha Loss                 -0.37846
exploration/num steps total    123200
exploration/num paths total      1232
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.252829
exploration/Rewards Std             0.686434
exploration/Rewards Max            -0.00885296
exploration/Rewards Min            -8.3329
exploration/Returns Mean          -25.2829
exploration/Returns Std             9.49078
exploration/Returns Max           -16.966
exploration/Returns Min           -42.9206
exploration/Actions Mean           -0.00897927
exploration/Actions Std             0.207247
exploration/Actions Max             0.999514
exploration/Actions Min            -0.997687
exploration/Num Paths               5
exploration/Average Returns       -25.2829
evaluation/num steps total     369000
evaluation/num paths total       3690
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.529484
evaluation/Rewards Std              1.06062
evaluation/Rewards Max             -0.0294132
evaluation/Rewards Min            -10.2008
evaluation/Returns Mean           -52.9484
evaluation/Returns Std             50.2828
evaluation/Returns Max             -7.44429
evaluation/Returns Min           -151.563
evaluation/Actions Mean             0.00826757
evaluation/Actions Std              0.188622
evaluation/Actions Max              0.998783
evaluation/Actions Min             -0.996649
evaluation/Num Paths               15
evaluation/Average Returns        -52.9484
time/data storing (s)               0.00270139
time/evaluation sampling (s)        0.328202
time/exploration sampling (s)       0.139104
time/logging (s)                    0.00479687
time/saving (s)                     0.00154673
time/training (s)                   1.92928
time/epoch (s)                      2.40563
time/total (s)                    602.53
Epoch                             245
-----------------------------  ---------------
2019-04-22 23:37:19.134798 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 246 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.0623
trainer/QF2 Loss                    1.06147
trainer/Policy Loss                23.7686
trainer/Q1 Predictions Mean       -21.9631
trainer/Q1 Predictions Std         29.0731
trainer/Q1 Predictions Max         -6.87744
trainer/Q1 Predictions Min       -103.409
trainer/Q2 Predictions Mean       -22.0088
trainer/Q2 Predictions Std         29.1135
trainer/Q2 Predictions Max         -6.80211
trainer/Q2 Predictions Min       -104.191
trainer/Q Targets Mean            -22.226
trainer/Q Targets Std              29.4945
trainer/Q Targets Max              -0.305832
trainer/Q Targets Min            -102.414
trainer/Log Pis Mean                1.9201
trainer/Log Pis Std                 1.15808
trainer/Log Pis Max                 4.99201
trainer/Log Pis Min                -2.4225
trainer/Policy mu Mean             -0.0186583
trainer/Policy mu Std               0.574975
trainer/Policy mu Max               2.45932
trainer/Policy mu Min              -2.78616
trainer/Policy log std Mean        -2.15496
trainer/Policy log std Std          0.485076
trainer/Policy log std Max         -0.319161
trainer/Policy log std Min         -2.78602
trainer/Alpha                       0.0664761
trainer/Alpha Loss                 -0.216594
exploration/num steps total    123700
exploration/num paths total      1237
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.416291
exploration/Rewards Std             1.35491
exploration/Rewards Max            -0.00248241
exploration/Rewards Min           -10.0515
exploration/Returns Mean          -41.6291
exploration/Returns Std            18.1416
exploration/Returns Max           -17.1394
exploration/Returns Min           -62.9428
exploration/Actions Mean           -0.0192254
exploration/Actions Std             0.242077
exploration/Actions Max             0.993975
exploration/Actions Min            -0.999618
exploration/Num Paths               5
exploration/Average Returns       -41.6291
evaluation/num steps total     370500
evaluation/num paths total       3705
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.35248
evaluation/Rewards Std              0.992206
evaluation/Rewards Max             -0.00896965
evaluation/Rewards Min            -10.0771
evaluation/Returns Mean           -35.248
evaluation/Returns Std             43.0336
evaluation/Returns Max             -1.43246
evaluation/Returns Min           -178.529
evaluation/Actions Mean             0.00607264
evaluation/Actions Std              0.17752
evaluation/Actions Max              0.998155
evaluation/Actions Min             -0.997436
evaluation/Num Paths               15
evaluation/Average Returns        -35.248
time/data storing (s)               0.00268528
time/evaluation sampling (s)        0.32149
time/exploration sampling (s)       0.141597
time/logging (s)                    0.0048149
time/saving (s)                     0.00195881
time/training (s)                   1.9442
time/epoch (s)                      2.41674
time/total (s)                    604.951
Epoch                             246
-----------------------------  ---------------
2019-04-22 23:37:21.560411 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 247 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.267018
trainer/QF2 Loss                    0.236135
trainer/Policy Loss                22.7832
trainer/Q1 Predictions Mean       -21.0968
trainer/Q1 Predictions Std         28.1303
trainer/Q1 Predictions Max         -6.96948
trainer/Q1 Predictions Min        -90.3907
trainer/Q2 Predictions Mean       -21.1069
trainer/Q2 Predictions Std         28.1538
trainer/Q2 Predictions Max         -7.00256
trainer/Q2 Predictions Min        -90.5985
trainer/Q Targets Mean            -21.398
trainer/Q Targets Std              28.5021
trainer/Q Targets Max              -7.01429
trainer/Q Targets Min             -91.8228
trainer/Log Pis Mean                1.82005
trainer/Log Pis Std                 1.19772
trainer/Log Pis Max                 5.31597
trainer/Log Pis Min                -1.60378
trainer/Policy mu Mean              0.0680703
trainer/Policy mu Std               0.497426
trainer/Policy mu Max               3.85344
trainer/Policy mu Min              -2.67323
trainer/Policy log std Mean        -2.22056
trainer/Policy log std Std          0.398852
trainer/Policy log std Max         -0.515481
trainer/Policy log std Min         -2.8115
trainer/Alpha                       0.0660965
trainer/Alpha Loss                 -0.488875
exploration/num steps total    124200
exploration/num paths total      1242
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.407045
exploration/Rewards Std             1.31192
exploration/Rewards Max            -0.0123515
exploration/Rewards Min           -10.1583
exploration/Returns Mean          -40.7045
exploration/Returns Std            20.1048
exploration/Returns Max           -13.2539
exploration/Returns Min           -60.4049
exploration/Actions Mean           -0.0253358
exploration/Actions Std             0.234131
exploration/Actions Max             0.998467
exploration/Actions Min            -0.999322
exploration/Num Paths               5
exploration/Average Returns       -40.7045
evaluation/num steps total     372000
evaluation/num paths total       3720
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.486001
evaluation/Rewards Std              1.17889
evaluation/Rewards Max             -0.0146446
evaluation/Rewards Min            -11.1911
evaluation/Returns Mean           -48.6001
evaluation/Returns Std             53.2693
evaluation/Returns Max             -2.755
evaluation/Returns Min           -184.713
evaluation/Actions Mean            -0.00488096
evaluation/Actions Std              0.205215
evaluation/Actions Max              0.999267
evaluation/Actions Min             -0.997676
evaluation/Num Paths               15
evaluation/Average Returns        -48.6001
time/data storing (s)               0.0027309
time/evaluation sampling (s)        0.32667
time/exploration sampling (s)       0.140391
time/logging (s)                    0.00478383
time/saving (s)                     0.00155373
time/training (s)                   1.94095
time/epoch (s)                      2.41708
time/total (s)                    607.372
Epoch                             247
-----------------------------  ---------------
2019-04-22 23:37:23.988324 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 248 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.77705
trainer/QF2 Loss                    1.79142
trainer/Policy Loss                21.87
trainer/Q1 Predictions Mean       -20.1735
trainer/Q1 Predictions Std         27.2626
trainer/Q1 Predictions Max         -6.82444
trainer/Q1 Predictions Min        -92.1517
trainer/Q2 Predictions Mean       -20.2046
trainer/Q2 Predictions Std         27.2539
trainer/Q2 Predictions Max         -6.88959
trainer/Q2 Predictions Min        -91.993
trainer/Q Targets Mean            -20.2109
trainer/Q Targets Std              27.4633
trainer/Q Targets Max              -0.285027
trainer/Q Targets Min             -91.8003
trainer/Log Pis Mean                1.83687
trainer/Log Pis Std                 1.28837
trainer/Log Pis Max                 7.84736
trainer/Log Pis Min                -2.87796
trainer/Policy mu Mean             -0.0276866
trainer/Policy mu Std               0.467003
trainer/Policy mu Max               1.42375
trainer/Policy mu Min              -2.79925
trainer/Policy log std Mean        -2.2053
trainer/Policy log std Std          0.386233
trainer/Policy log std Max         -0.485191
trainer/Policy log std Min         -2.76351
trainer/Alpha                       0.0664587
trainer/Alpha Loss                 -0.442242
exploration/num steps total    124700
exploration/num paths total      1247
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.18364
exploration/Rewards Std             0.94353
exploration/Rewards Max            -0.00177834
exploration/Rewards Min            -6.57893
exploration/Returns Mean         -118.364
exploration/Returns Std            78.9005
exploration/Returns Max           -18.9887
exploration/Returns Min          -190.691
exploration/Actions Mean           -0.0136671
exploration/Actions Std             0.227827
exploration/Actions Max             0.985511
exploration/Actions Min            -0.997762
exploration/Num Paths               5
exploration/Average Returns      -118.364
evaluation/num steps total     373500
evaluation/num paths total       3735
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.376708
evaluation/Rewards Std              1.01733
evaluation/Rewards Max             -0.0157036
evaluation/Rewards Min             -8.44426
evaluation/Returns Mean           -37.6708
evaluation/Returns Std             39.6835
evaluation/Returns Max             -2.75018
evaluation/Returns Min           -175.777
evaluation/Actions Mean             0.00334397
evaluation/Actions Std              0.188181
evaluation/Actions Max              0.998674
evaluation/Actions Min             -0.998623
evaluation/Num Paths               15
evaluation/Average Returns        -37.6708
time/data storing (s)               0.00277872
time/evaluation sampling (s)        0.327545
time/exploration sampling (s)       0.140657
time/logging (s)                    0.00493025
time/saving (s)                     0.00198045
time/training (s)                   1.94219
time/epoch (s)                      2.42008
time/total (s)                    609.797
Epoch                             248
-----------------------------  ---------------
2019-04-22 23:37:26.401748 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 249 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.8431
trainer/QF2 Loss                    1.82946
trainer/Policy Loss                20.4285
trainer/Q1 Predictions Mean       -18.4757
trainer/Q1 Predictions Std         25.4688
trainer/Q1 Predictions Max         -7.10076
trainer/Q1 Predictions Min        -91.2725
trainer/Q2 Predictions Mean       -18.4848
trainer/Q2 Predictions Std         25.4399
trainer/Q2 Predictions Max         -7.09188
trainer/Q2 Predictions Min        -91.3218
trainer/Q Targets Mean            -18.3821
trainer/Q Targets Std              25.4571
trainer/Q Targets Max              -0.227372
trainer/Q Targets Min             -91.6347
trainer/Log Pis Mean                2.06266
trainer/Log Pis Std                 0.97372
trainer/Log Pis Max                 4.93045
trainer/Log Pis Min                -0.862552
trainer/Policy mu Mean             -0.00404966
trainer/Policy mu Std               0.345216
trainer/Policy mu Max               1.75687
trainer/Policy mu Min              -2.93493
trainer/Policy log std Mean        -2.27661
trainer/Policy log std Std          0.33024
trainer/Policy log std Max         -0.620886
trainer/Policy log std Min         -2.72014
trainer/Alpha                       0.0667248
trainer/Alpha Loss                  0.169621
exploration/num steps total    125200
exploration/num paths total      1252
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.627829
exploration/Rewards Std             1.20669
exploration/Rewards Max            -0.0020249
exploration/Rewards Min           -10.1867
exploration/Returns Mean          -62.7829
exploration/Returns Std            52.299
exploration/Returns Max           -14.1453
exploration/Returns Min          -161.711
exploration/Actions Mean           -0.00740263
exploration/Actions Std             0.236844
exploration/Actions Max             0.997071
exploration/Actions Min            -0.999607
exploration/Num Paths               5
exploration/Average Returns       -62.7829
evaluation/num steps total     375000
evaluation/num paths total       3750
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.402766
evaluation/Rewards Std              1.14433
evaluation/Rewards Max             -0.0184968
evaluation/Rewards Min             -9.69335
evaluation/Returns Mean           -40.2766
evaluation/Returns Std             40.2469
evaluation/Returns Max             -2.49136
evaluation/Returns Min           -178.411
evaluation/Actions Mean            -0.012935
evaluation/Actions Std              0.205158
evaluation/Actions Max              0.998448
evaluation/Actions Min             -0.997554
evaluation/Num Paths               15
evaluation/Average Returns        -40.2766
time/data storing (s)               0.00262787
time/evaluation sampling (s)        0.330157
time/exploration sampling (s)       0.142901
time/logging (s)                    0.00479823
time/saving (s)                     0.00178637
time/training (s)                   1.92217
time/epoch (s)                      2.40444
time/total (s)                    612.205
Epoch                             249
-----------------------------  ---------------
2019-04-22 23:37:28.811564 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 250 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    2.76876
trainer/QF2 Loss                    2.66706
trainer/Policy Loss                19.8905
trainer/Q1 Predictions Mean       -18.0017
trainer/Q1 Predictions Std         25.1225
trainer/Q1 Predictions Max         -6.81765
trainer/Q1 Predictions Min       -109.723
trainer/Q2 Predictions Mean       -18.0004
trainer/Q2 Predictions Std         25.1555
trainer/Q2 Predictions Max         -6.84347
trainer/Q2 Predictions Min       -109.292
trainer/Q Targets Mean            -18.041
trainer/Q Targets Std              25.5585
trainer/Q Targets Max              -0.150903
trainer/Q Targets Min            -110.623
trainer/Log Pis Mean                2.0636
trainer/Log Pis Std                 1.50228
trainer/Log Pis Max                10.9818
trainer/Log Pis Min                -2.0982
trainer/Policy mu Mean             -0.045242
trainer/Policy mu Std               0.493602
trainer/Policy mu Max               3.59827
trainer/Policy mu Min              -3.14191
trainer/Policy log std Mean        -2.29502
trainer/Policy log std Std          0.309972
trainer/Policy log std Max         -0.730616
trainer/Policy log std Min         -2.74103
trainer/Alpha                       0.0677496
trainer/Alpha Loss                  0.171208
exploration/num steps total    125700
exploration/num paths total      1257
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.324567
exploration/Rewards Std             0.94628
exploration/Rewards Max            -0.00537407
exploration/Rewards Min            -8.01667
exploration/Returns Mean          -32.4567
exploration/Returns Std             9.90707
exploration/Returns Max           -15.9066
exploration/Returns Min           -43.3364
exploration/Actions Mean            0.0208066
exploration/Actions Std             0.214285
exploration/Actions Max             0.99759
exploration/Actions Min            -0.998938
exploration/Num Paths               5
exploration/Average Returns       -32.4567
evaluation/num steps total     376500
evaluation/num paths total       3765
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.297375
evaluation/Rewards Std              1.07944
evaluation/Rewards Max             -0.0217724
evaluation/Rewards Min             -9.91256
evaluation/Returns Mean           -29.7375
evaluation/Returns Std             13.2369
evaluation/Returns Max             -6.04524
evaluation/Returns Min            -52.5116
evaluation/Actions Mean             0.024677
evaluation/Actions Std              0.195281
evaluation/Actions Max              0.998851
evaluation/Actions Min             -0.996549
evaluation/Num Paths               15
evaluation/Average Returns        -29.7375
time/data storing (s)               0.00266617
time/evaluation sampling (s)        0.328473
time/exploration sampling (s)       0.140563
time/logging (s)                    0.00486535
time/saving (s)                     0.00193346
time/training (s)                   1.92462
time/epoch (s)                      2.40313
time/total (s)                    614.613
Epoch                             250
-----------------------------  ---------------
2019-04-22 23:37:31.227195 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 251 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    2.63008
trainer/QF2 Loss                    2.658
trainer/Policy Loss                21.3757
trainer/Q1 Predictions Mean       -19.6285
trainer/Q1 Predictions Std         26.3084
trainer/Q1 Predictions Max         -6.59371
trainer/Q1 Predictions Min        -87.8697
trainer/Q2 Predictions Mean       -19.6298
trainer/Q2 Predictions Std         26.3134
trainer/Q2 Predictions Max         -6.51877
trainer/Q2 Predictions Min        -87.9447
trainer/Q Targets Mean            -19.9761
trainer/Q Targets Std              27.1628
trainer/Q Targets Max              -0.148661
trainer/Q Targets Min             -90.7586
trainer/Log Pis Mean                1.85631
trainer/Log Pis Std                 1.25474
trainer/Log Pis Max                 5.25502
trainer/Log Pis Min                -3.6338
trainer/Policy mu Mean             -0.0473445
trainer/Policy mu Std               0.443924
trainer/Policy mu Max               1.79213
trainer/Policy mu Min              -3.40277
trainer/Policy log std Mean        -2.28027
trainer/Policy log std Std          0.3338
trainer/Policy log std Max         -0.512764
trainer/Policy log std Min         -2.73989
trainer/Alpha                       0.0730962
trainer/Alpha Loss                 -0.375894
exploration/num steps total    126200
exploration/num paths total      1262
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.99402
exploration/Rewards Std             0.715052
exploration/Rewards Max            -0.0111664
exploration/Rewards Min            -4.1052
exploration/Returns Mean          -99.402
exploration/Returns Std            65.8259
exploration/Returns Max           -14.1478
exploration/Returns Min          -154.6
exploration/Actions Mean            0.00152767
exploration/Actions Std             0.201333
exploration/Actions Max             0.995342
exploration/Actions Min            -0.999049
exploration/Num Paths               5
exploration/Average Returns       -99.402
evaluation/num steps total     378000
evaluation/num paths total       3780
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.571882
evaluation/Rewards Std              1.11328
evaluation/Rewards Max             -0.017122
evaluation/Rewards Min             -9.34023
evaluation/Returns Mean           -57.1882
evaluation/Returns Std             51.5106
evaluation/Returns Max             -8.51392
evaluation/Returns Min           -167.779
evaluation/Actions Mean             0.0102923
evaluation/Actions Std              0.191353
evaluation/Actions Max              0.998901
evaluation/Actions Min             -0.997373
evaluation/Num Paths               15
evaluation/Average Returns        -57.1882
time/data storing (s)               0.00270109
time/evaluation sampling (s)        0.328297
time/exploration sampling (s)       0.139619
time/logging (s)                    0.00446766
time/saving (s)                     0.00156803
time/training (s)                   1.93009
time/epoch (s)                      2.40675
time/total (s)                    617.024
Epoch                             251
-----------------------------  ---------------
2019-04-22 23:37:33.636931 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 252 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.29753
trainer/QF2 Loss                    1.31193
trainer/Policy Loss                25.6947
trainer/Q1 Predictions Mean       -23.8041
trainer/Q1 Predictions Std         30.0696
trainer/Q1 Predictions Max         -6.7748
trainer/Q1 Predictions Min        -91.2871
trainer/Q2 Predictions Mean       -23.7967
trainer/Q2 Predictions Std         30.0417
trainer/Q2 Predictions Max         -6.79927
trainer/Q2 Predictions Min        -91.2393
trainer/Q Targets Mean            -23.9576
trainer/Q Targets Std              30.266
trainer/Q Targets Max              -0.101584
trainer/Q Targets Min             -91.5387
trainer/Log Pis Mean                2.05342
trainer/Log Pis Std                 1.24089
trainer/Log Pis Max                 8.21042
trainer/Log Pis Min                -2.17515
trainer/Policy mu Mean             -0.0334557
trainer/Policy mu Std               0.584558
trainer/Policy mu Max               3.23082
trainer/Policy mu Min              -3.14406
trainer/Policy log std Mean        -2.2023
trainer/Policy log std Std          0.400436
trainer/Policy log std Max         -0.561663
trainer/Policy log std Min         -2.71114
trainer/Alpha                       0.0708932
trainer/Alpha Loss                  0.141382
exploration/num steps total    126700
exploration/num paths total      1267
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.887335
exploration/Rewards Std             1.20759
exploration/Rewards Max            -0.00540973
exploration/Rewards Min           -10.176
exploration/Returns Mean          -88.7335
exploration/Returns Std            59.1618
exploration/Returns Max           -22.7488
exploration/Returns Min          -163.566
exploration/Actions Mean           -0.0105751
exploration/Actions Std             0.246976
exploration/Actions Max             0.999786
exploration/Actions Min            -0.999588
exploration/Num Paths               5
exploration/Average Returns       -88.7335
evaluation/num steps total     379500
evaluation/num paths total       3795
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.464329
evaluation/Rewards Std              0.919893
evaluation/Rewards Max             -0.00058091
evaluation/Rewards Min             -7.27109
evaluation/Returns Mean           -46.4329
evaluation/Returns Std             53.0854
evaluation/Returns Max             -3.83682
evaluation/Returns Min           -164.887
evaluation/Actions Mean             0.00389627
evaluation/Actions Std              0.168425
evaluation/Actions Max              0.997269
evaluation/Actions Min             -0.99594
evaluation/Num Paths               15
evaluation/Average Returns        -46.4329
time/data storing (s)               0.00262082
time/evaluation sampling (s)        0.328934
time/exploration sampling (s)       0.139736
time/logging (s)                    0.0047749
time/saving (s)                     0.00195033
time/training (s)                   1.92348
time/epoch (s)                      2.40149
time/total (s)                    619.43
Epoch                             252
-----------------------------  ---------------
2019-04-22 23:37:36.077454 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 253 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.51751
trainer/QF2 Loss                    1.53061
trainer/Policy Loss                22.1431
trainer/Q1 Predictions Mean       -20.4373
trainer/Q1 Predictions Std         27.1563
trainer/Q1 Predictions Max         -7.00841
trainer/Q1 Predictions Min        -90.505
trainer/Q2 Predictions Mean       -20.4307
trainer/Q2 Predictions Std         27.1623
trainer/Q2 Predictions Max         -7.02066
trainer/Q2 Predictions Min        -90.6713
trainer/Q Targets Mean            -20.3363
trainer/Q Targets Std              27.345
trainer/Q Targets Max              -0.149357
trainer/Q Targets Min             -90.8213
trainer/Log Pis Mean                1.82866
trainer/Log Pis Std                 1.25104
trainer/Log Pis Max                 6.47122
trainer/Log Pis Min                -2.45445
trainer/Policy mu Mean              0.0244257
trainer/Policy mu Std               0.467675
trainer/Policy mu Max               2.56481
trainer/Policy mu Min              -3.0681
trainer/Policy log std Mean        -2.20418
trainer/Policy log std Std          0.395797
trainer/Policy log std Max         -0.545517
trainer/Policy log std Min         -2.78033
trainer/Alpha                       0.0664125
trainer/Alpha Loss                 -0.464604
exploration/num steps total    127200
exploration/num paths total      1272
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.922746
exploration/Rewards Std             1.22585
exploration/Rewards Max            -0.0037783
exploration/Rewards Min            -9.68265
exploration/Returns Mean          -92.2746
exploration/Returns Std            62.8935
exploration/Returns Max           -26.3606
exploration/Returns Min          -178.65
exploration/Actions Mean           -0.00621226
exploration/Actions Std             0.263479
exploration/Actions Max             0.998176
exploration/Actions Min            -0.998674
exploration/Num Paths               5
exploration/Average Returns       -92.2746
evaluation/num steps total     381000
evaluation/num paths total       3810
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.348114
evaluation/Rewards Std              0.994566
evaluation/Rewards Max             -0.00658347
evaluation/Rewards Min            -11.1511
evaluation/Returns Mean           -34.8114
evaluation/Returns Std             37.1604
evaluation/Returns Max             -7.22838
evaluation/Returns Min           -162.393
evaluation/Actions Mean            -1.81281e-05
evaluation/Actions Std              0.186691
evaluation/Actions Max              0.997408
evaluation/Actions Min             -0.998049
evaluation/Num Paths               15
evaluation/Average Returns        -34.8114
time/data storing (s)               0.00291572
time/evaluation sampling (s)        0.328072
time/exploration sampling (s)       0.142449
time/logging (s)                    0.00481059
time/saving (s)                     0.00158418
time/training (s)                   1.95214
time/epoch (s)                      2.43198
time/total (s)                    621.866
Epoch                             253
-----------------------------  ----------------
2019-04-22 23:37:38.506397 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 254 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.61512
trainer/QF2 Loss                    1.59321
trainer/Policy Loss                23.1031
trainer/Q1 Predictions Mean       -21.1516
trainer/Q1 Predictions Std         28.361
trainer/Q1 Predictions Max         -6.80981
trainer/Q1 Predictions Min        -90.5261
trainer/Q2 Predictions Mean       -21.1604
trainer/Q2 Predictions Std         28.3842
trainer/Q2 Predictions Max         -6.7824
trainer/Q2 Predictions Min        -90.5487
trainer/Q Targets Mean            -21.2832
trainer/Q Targets Std              29.012
trainer/Q Targets Max              -0.0610981
trainer/Q Targets Min             -91.5462
trainer/Log Pis Mean                2.04468
trainer/Log Pis Std                 1.27736
trainer/Log Pis Max                 5.0407
trainer/Log Pis Min                -2.93609
trainer/Policy mu Mean              0.0162608
trainer/Policy mu Std               0.459142
trainer/Policy mu Max               2.57022
trainer/Policy mu Min              -2.38443
trainer/Policy log std Mean        -2.28626
trainer/Policy log std Std          0.397153
trainer/Policy log std Max         -0.688931
trainer/Policy log std Min         -2.88247
trainer/Alpha                       0.0647231
trainer/Alpha Loss                  0.122332
exploration/num steps total    127700
exploration/num paths total      1277
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.598901
exploration/Rewards Std             1.07692
exploration/Rewards Max            -0.00464341
exploration/Rewards Min            -9.38436
exploration/Returns Mean          -59.8901
exploration/Returns Std            50.0387
exploration/Returns Max           -13.8632
exploration/Returns Min          -154.874
exploration/Actions Mean           -0.00434775
exploration/Actions Std             0.213168
exploration/Actions Max             0.999683
exploration/Actions Min            -0.997888
exploration/Num Paths               5
exploration/Average Returns       -59.8901
evaluation/num steps total     382500
evaluation/num paths total       3825
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.382826
evaluation/Rewards Std              1.08241
evaluation/Rewards Max             -0.0166209
evaluation/Rewards Min            -11.2101
evaluation/Returns Mean           -38.2826
evaluation/Returns Std             35.5234
evaluation/Returns Max             -6.02255
evaluation/Returns Min           -151.573
evaluation/Actions Mean            -0.00119576
evaluation/Actions Std              0.18133
evaluation/Actions Max              0.998015
evaluation/Actions Min             -0.998504
evaluation/Num Paths               15
evaluation/Average Returns        -38.2826
time/data storing (s)               0.00261394
time/evaluation sampling (s)        0.325847
time/exploration sampling (s)       0.140947
time/logging (s)                    0.00486278
time/saving (s)                     0.00195378
time/training (s)                   1.94428
time/epoch (s)                      2.42051
time/total (s)                    624.291
Epoch                             254
-----------------------------  ---------------
2019-04-22 23:37:40.934385 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 255 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.334748
trainer/QF2 Loss                    0.346383
trainer/Policy Loss                20.0269
trainer/Q1 Predictions Mean       -18.2622
trainer/Q1 Predictions Std         25.0458
trainer/Q1 Predictions Max         -6.70582
trainer/Q1 Predictions Min        -95.8612
trainer/Q2 Predictions Mean       -18.2547
trainer/Q2 Predictions Std         25.0444
trainer/Q2 Predictions Max         -6.67591
trainer/Q2 Predictions Min        -95.9595
trainer/Q Targets Mean            -18.5428
trainer/Q Targets Std              25.4744
trainer/Q Targets Max              -6.82914
trainer/Q Targets Min             -96.8116
trainer/Log Pis Mean                1.90065
trainer/Log Pis Std                 1.25172
trainer/Log Pis Max                 6.30014
trainer/Log Pis Min                -4.41759
trainer/Policy mu Mean             -0.0715877
trainer/Policy mu Std               0.59548
trainer/Policy mu Max               2.62819
trainer/Policy mu Min              -3.6021
trainer/Policy log std Mean        -2.22136
trainer/Policy log std Std          0.454613
trainer/Policy log std Max         -0.267783
trainer/Policy log std Min         -2.84791
trainer/Alpha                       0.0657275
trainer/Alpha Loss                 -0.270449
exploration/num steps total    128200
exploration/num paths total      1282
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.878977
exploration/Rewards Std             1.24249
exploration/Rewards Max            -0.00633015
exploration/Rewards Min            -9.62945
exploration/Returns Mean          -87.8977
exploration/Returns Std            44.4518
exploration/Returns Max           -44.0897
exploration/Returns Min          -144.508
exploration/Actions Mean            0.0171146
exploration/Actions Std             0.25418
exploration/Actions Max             0.999852
exploration/Actions Min            -0.994656
exploration/Num Paths               5
exploration/Average Returns       -87.8977
evaluation/num steps total     384000
evaluation/num paths total       3840
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.333476
evaluation/Rewards Std              1.02259
evaluation/Rewards Max             -0.0246154
evaluation/Rewards Min             -9.72041
evaluation/Returns Mean           -33.3476
evaluation/Returns Std             36.7094
evaluation/Returns Max             -8.88386
evaluation/Returns Min           -162.492
evaluation/Actions Mean             0.00438282
evaluation/Actions Std              0.201332
evaluation/Actions Max              0.9986
evaluation/Actions Min             -0.998954
evaluation/Num Paths               15
evaluation/Average Returns        -33.3476
time/data storing (s)               0.00264847
time/evaluation sampling (s)        0.328093
time/exploration sampling (s)       0.140625
time/logging (s)                    0.00489096
time/saving (s)                     0.00193895
time/training (s)                   1.94122
time/epoch (s)                      2.41941
time/total (s)                    626.715
Epoch                             255
-----------------------------  ---------------
2019-04-22 23:37:43.398805 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 256 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0995578
trainer/QF2 Loss                    0.0885254
trainer/Policy Loss                22.4372
trainer/Q1 Predictions Mean       -20.4255
trainer/Q1 Predictions Std         27.5832
trainer/Q1 Predictions Max         -6.86779
trainer/Q1 Predictions Min        -89.2357
trainer/Q2 Predictions Mean       -20.4332
trainer/Q2 Predictions Std         27.5951
trainer/Q2 Predictions Max         -6.96057
trainer/Q2 Predictions Min        -90.3048
trainer/Q Targets Mean            -20.5244
trainer/Q Targets Std              27.7362
trainer/Q Targets Max              -6.76535
trainer/Q Targets Min             -91.1185
trainer/Log Pis Mean                2.19898
trainer/Log Pis Std                 0.964738
trainer/Log Pis Max                 5.85325
trainer/Log Pis Min                -1.13543
trainer/Policy mu Mean              0.00483075
trainer/Policy mu Std               0.404191
trainer/Policy mu Max               2.46583
trainer/Policy mu Min              -3.26427
trainer/Policy log std Mean        -2.33501
trainer/Policy log std Std          0.315041
trainer/Policy log std Max         -0.624282
trainer/Policy log std Min         -2.82929
trainer/Alpha                       0.0685136
trainer/Alpha Loss                  0.533455
exploration/num steps total    128700
exploration/num paths total      1287
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.16721
exploration/Rewards Std             1.11498
exploration/Rewards Max            -0.0138923
exploration/Rewards Min            -7.9312
exploration/Returns Mean         -116.721
exploration/Returns Std            57.9957
exploration/Returns Max           -45.5289
exploration/Returns Min          -169.325
exploration/Actions Mean            0.020382
exploration/Actions Std             0.253161
exploration/Actions Max             0.999945
exploration/Actions Min            -0.994379
exploration/Num Paths               5
exploration/Average Returns      -116.721
evaluation/num steps total     385500
evaluation/num paths total       3855
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.681332
evaluation/Rewards Std              1.22571
evaluation/Rewards Max             -0.0221017
evaluation/Rewards Min            -10.5032
evaluation/Returns Mean           -68.1332
evaluation/Returns Std             60.9379
evaluation/Returns Max             -7.06007
evaluation/Returns Min           -177.585
evaluation/Actions Mean             0.0170378
evaluation/Actions Std              0.200417
evaluation/Actions Max              0.999031
evaluation/Actions Min             -0.99845
evaluation/Num Paths               15
evaluation/Average Returns        -68.1332
time/data storing (s)               0.00282955
time/evaluation sampling (s)        0.336015
time/exploration sampling (s)       0.140204
time/logging (s)                    0.00520272
time/saving (s)                     0.00180772
time/training (s)                   1.97014
time/epoch (s)                      2.4562
time/total (s)                    629.176
Epoch                             256
-----------------------------  ---------------
2019-04-22 23:37:45.810694 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 257 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.7692
trainer/QF2 Loss                    0.809061
trainer/Policy Loss                27.3986
trainer/Q1 Predictions Mean       -25.6369
trainer/Q1 Predictions Std         31.5567
trainer/Q1 Predictions Max         -6.41694
trainer/Q1 Predictions Min        -95.0204
trainer/Q2 Predictions Mean       -25.6175
trainer/Q2 Predictions Std         31.5297
trainer/Q2 Predictions Max         -6.46781
trainer/Q2 Predictions Min        -94.5249
trainer/Q Targets Mean            -26.166
trainer/Q Targets Std              32.1982
trainer/Q Targets Max              -6.72166
trainer/Q Targets Min             -95.3568
trainer/Log Pis Mean                2.02911
trainer/Log Pis Std                 1.17765
trainer/Log Pis Max                 5.24407
trainer/Log Pis Min                -2.84147
trainer/Policy mu Mean             -0.124638
trainer/Policy mu Std               0.508996
trainer/Policy mu Max               3.19059
trainer/Policy mu Min              -2.95165
trainer/Policy log std Mean        -2.26513
trainer/Policy log std Std          0.356056
trainer/Policy log std Max         -0.433535
trainer/Policy log std Min         -2.80974
trainer/Alpha                       0.0686426
trainer/Alpha Loss                  0.0779778
exploration/num steps total    129200
exploration/num paths total      1292
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.383774
exploration/Rewards Std             1.15855
exploration/Rewards Max            -0.00670807
exploration/Rewards Min           -10.4278
exploration/Returns Mean          -38.3774
exploration/Returns Std            16.3048
exploration/Returns Max           -16.3656
exploration/Returns Min           -63.1862
exploration/Actions Mean           -0.00276903
exploration/Actions Std             0.233567
exploration/Actions Max             0.995667
exploration/Actions Min            -0.998811
exploration/Num Paths               5
exploration/Average Returns       -38.3774
evaluation/num steps total     387000
evaluation/num paths total       3870
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.331183
evaluation/Rewards Std              0.665533
evaluation/Rewards Max             -0.029655
evaluation/Rewards Min             -8.48473
evaluation/Returns Mean           -33.1183
evaluation/Returns Std             35.0404
evaluation/Returns Max             -8.5153
evaluation/Returns Min           -119.879
evaluation/Actions Mean            -0.00559541
evaluation/Actions Std              0.15779
evaluation/Actions Max              0.995532
evaluation/Actions Min             -0.997569
evaluation/Num Paths               15
evaluation/Average Returns        -33.1183
time/data storing (s)               0.0026865
time/evaluation sampling (s)        0.328356
time/exploration sampling (s)       0.139511
time/logging (s)                    0.00486349
time/saving (s)                     0.00196487
time/training (s)                   1.92542
time/epoch (s)                      2.4028
time/total (s)                    631.584
Epoch                             257
-----------------------------  ---------------
2019-04-22 23:37:48.265337 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 258 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   70.7058
trainer/QF2 Loss                   71.0139
trainer/Policy Loss                29.3336
trainer/Q1 Predictions Mean       -27.4603
trainer/Q1 Predictions Std         31.3999
trainer/Q1 Predictions Max         -6.79087
trainer/Q1 Predictions Min        -86.0967
trainer/Q2 Predictions Mean       -27.4619
trainer/Q2 Predictions Std         31.3786
trainer/Q2 Predictions Max         -6.92409
trainer/Q2 Predictions Min        -86.0877
trainer/Q Targets Mean            -26.7299
trainer/Q Targets Std              31.3959
trainer/Q Targets Max              -0.108257
trainer/Q Targets Min             -87.1898
trainer/Log Pis Mean                2.0337
trainer/Log Pis Std                 1.60411
trainer/Log Pis Max                10.4094
trainer/Log Pis Min                -2.41312
trainer/Policy mu Mean              0.0682529
trainer/Policy mu Std               0.695305
trainer/Policy mu Max               3.71022
trainer/Policy mu Min              -3.07901
trainer/Policy log std Mean        -2.12965
trainer/Policy log std Std          0.479889
trainer/Policy log std Max         -0.214034
trainer/Policy log std Min         -2.75636
trainer/Alpha                       0.0703946
trainer/Alpha Loss                  0.0894168
exploration/num steps total    129700
exploration/num paths total      1297
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.614915
exploration/Rewards Std             1.10103
exploration/Rewards Max            -0.00225132
exploration/Rewards Min            -7.68618
exploration/Returns Mean          -61.4915
exploration/Returns Std            39.7148
exploration/Returns Max           -37.3914
exploration/Returns Min          -140.742
exploration/Actions Mean            0.0269918
exploration/Actions Std             0.240771
exploration/Actions Max             0.999733
exploration/Actions Min            -0.995079
exploration/Num Paths               5
exploration/Average Returns       -61.4915
evaluation/num steps total     388500
evaluation/num paths total       3885
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.701723
evaluation/Rewards Std              1.01659
evaluation/Rewards Max             -0.0275848
evaluation/Rewards Min            -10.4876
evaluation/Returns Mean           -70.1723
evaluation/Returns Std             55.6746
evaluation/Returns Max            -13.0083
evaluation/Returns Min           -153.881
evaluation/Actions Mean             0.0100496
evaluation/Actions Std              0.176418
evaluation/Actions Max              0.999444
evaluation/Actions Min             -0.997592
evaluation/Num Paths               15
evaluation/Average Returns        -70.1723
time/data storing (s)               0.00486054
time/evaluation sampling (s)        0.332184
time/exploration sampling (s)       0.143494
time/logging (s)                    0.00476609
time/saving (s)                     0.00195278
time/training (s)                   1.95869
time/epoch (s)                      2.44594
time/total (s)                    634.034
Epoch                             258
-----------------------------  ---------------
2019-04-22 23:37:50.694351 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 259 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.727225
trainer/QF2 Loss                    0.743616
trainer/Policy Loss                22.3371
trainer/Q1 Predictions Mean       -20.4634
trainer/Q1 Predictions Std         26.9956
trainer/Q1 Predictions Max         -6.77951
trainer/Q1 Predictions Min        -85.518
trainer/Q2 Predictions Mean       -20.4795
trainer/Q2 Predictions Std         26.9807
trainer/Q2 Predictions Max         -6.77417
trainer/Q2 Predictions Min        -85.5678
trainer/Q Targets Mean            -20.5524
trainer/Q Targets Std              27.1435
trainer/Q Targets Max              -0.195747
trainer/Q Targets Min             -85.78
trainer/Log Pis Mean                2.00412
trainer/Log Pis Std                 0.975007
trainer/Log Pis Max                 4.2297
trainer/Log Pis Min                -1.71991
trainer/Policy mu Mean             -0.0117873
trainer/Policy mu Std               0.436353
trainer/Policy mu Max               2.6556
trainer/Policy mu Min              -2.47756
trainer/Policy log std Mean        -2.22147
trainer/Policy log std Std          0.417363
trainer/Policy log std Max         -0.511408
trainer/Policy log std Min         -2.79792
trainer/Alpha                       0.0706824
trainer/Alpha Loss                  0.0109037
exploration/num steps total    130200
exploration/num paths total      1302
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.46365
exploration/Rewards Std             1.24627
exploration/Rewards Max            -0.00754456
exploration/Rewards Min            -9.30309
exploration/Returns Mean          -46.365
exploration/Returns Std            10.8778
exploration/Returns Max           -27.7343
exploration/Returns Min           -60.644
exploration/Actions Mean            0.0193358
exploration/Actions Std             0.239409
exploration/Actions Max             0.999571
exploration/Actions Min            -0.998222
exploration/Num Paths               5
exploration/Average Returns       -46.365
evaluation/num steps total     390000
evaluation/num paths total       3900
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.470167
evaluation/Rewards Std              0.994969
evaluation/Rewards Max             -0.0552536
evaluation/Rewards Min             -9.04992
evaluation/Returns Mean           -47.0167
evaluation/Returns Std             41.719
evaluation/Returns Max            -12.4814
evaluation/Returns Min           -153.644
evaluation/Actions Mean            -0.00229133
evaluation/Actions Std              0.191708
evaluation/Actions Max              0.999031
evaluation/Actions Min             -0.99535
evaluation/Num Paths               15
evaluation/Average Returns        -47.0167
time/data storing (s)               0.00289455
time/evaluation sampling (s)        0.334446
time/exploration sampling (s)       0.141326
time/logging (s)                    0.00477842
time/saving (s)                     0.0015725
time/training (s)                   1.93546
time/epoch (s)                      2.42048
time/total (s)                    636.459
Epoch                             259
-----------------------------  ---------------
2019-04-22 23:37:53.115222 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 260 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.723536
trainer/QF2 Loss                    0.728714
trainer/Policy Loss                22.6542
trainer/Q1 Predictions Mean       -20.8079
trainer/Q1 Predictions Std         27.0537
trainer/Q1 Predictions Max         -6.65384
trainer/Q1 Predictions Min        -86.0547
trainer/Q2 Predictions Mean       -20.8073
trainer/Q2 Predictions Std         27.0648
trainer/Q2 Predictions Max         -6.68762
trainer/Q2 Predictions Min        -85.8531
trainer/Q Targets Mean            -20.7583
trainer/Q Targets Std              27.2158
trainer/Q Targets Max              -0.123991
trainer/Q Targets Min             -86.1087
trainer/Log Pis Mean                1.97721
trainer/Log Pis Std                 1.06512
trainer/Log Pis Max                 4.86366
trainer/Log Pis Min                -1.88283
trainer/Policy mu Mean             -0.00990724
trainer/Policy mu Std               0.451964
trainer/Policy mu Max               2.70864
trainer/Policy mu Min              -2.90573
trainer/Policy log std Mean        -2.28061
trainer/Policy log std Std          0.355646
trainer/Policy log std Max         -0.654829
trainer/Policy log std Min         -2.84122
trainer/Alpha                       0.0704174
trainer/Alpha Loss                 -0.0604673
exploration/num steps total    130700
exploration/num paths total      1307
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.220246
exploration/Rewards Std             0.59918
exploration/Rewards Max            -0.00768457
exploration/Rewards Min            -6.57191
exploration/Returns Mean          -22.0246
exploration/Returns Std             6.44362
exploration/Returns Max           -14.2327
exploration/Returns Min           -33.2424
exploration/Actions Mean           -0.00561095
exploration/Actions Std             0.194387
exploration/Actions Max             0.996554
exploration/Actions Min            -0.996503
exploration/Num Paths               5
exploration/Average Returns       -22.0246
evaluation/num steps total     391500
evaluation/num paths total       3915
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.49113
evaluation/Rewards Std              1.21905
evaluation/Rewards Max             -0.0185198
evaluation/Rewards Min            -11.1385
evaluation/Returns Mean           -49.113
evaluation/Returns Std             49.3111
evaluation/Returns Max             -7.48153
evaluation/Returns Min           -177.515
evaluation/Actions Mean            -0.0079013
evaluation/Actions Std              0.203204
evaluation/Actions Max              0.99774
evaluation/Actions Min             -0.998498
evaluation/Num Paths               15
evaluation/Average Returns        -49.113
time/data storing (s)               0.00260842
time/evaluation sampling (s)        0.325077
time/exploration sampling (s)       0.139588
time/logging (s)                    0.00475754
time/saving (s)                     0.00188283
time/training (s)                   1.93947
time/epoch (s)                      2.41338
time/total (s)                    638.876
Epoch                             260
-----------------------------  ---------------
2019-04-22 23:37:55.548723 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 261 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.2995
trainer/QF2 Loss                    1.29316
trainer/Policy Loss                21.5881
trainer/Q1 Predictions Mean       -19.5051
trainer/Q1 Predictions Std         25.3473
trainer/Q1 Predictions Max         -6.63325
trainer/Q1 Predictions Min        -84.8942
trainer/Q2 Predictions Mean       -19.5392
trainer/Q2 Predictions Std         25.3376
trainer/Q2 Predictions Max         -6.62953
trainer/Q2 Predictions Min        -84.9527
trainer/Q Targets Mean            -19.5429
trainer/Q Targets Std              25.7338
trainer/Q Targets Max              -0.0271173
trainer/Q Targets Min             -86.2306
trainer/Log Pis Mean                2.21469
trainer/Log Pis Std                 1.10856
trainer/Log Pis Max                 6.89208
trainer/Log Pis Min                -1.14672
trainer/Policy mu Mean             -0.000263433
trainer/Policy mu Std               0.63093
trainer/Policy mu Max               3.23799
trainer/Policy mu Min              -2.87734
trainer/Policy log std Mean        -2.1893
trainer/Policy log std Std          0.460747
trainer/Policy log std Max         -0.471091
trainer/Policy log std Min         -2.84422
trainer/Alpha                       0.0685141
trainer/Alpha Loss                  0.575565
exploration/num steps total    131200
exploration/num paths total      1312
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.258312
exploration/Rewards Std             0.787878
exploration/Rewards Max            -0.00620768
exploration/Rewards Min            -8.30139
exploration/Returns Mean          -25.8312
exploration/Returns Std            11.5156
exploration/Returns Max           -10.6203
exploration/Returns Min           -43.5434
exploration/Actions Mean            0.00644807
exploration/Actions Std             0.209139
exploration/Actions Max             0.998888
exploration/Actions Min            -0.996305
exploration/Num Paths               5
exploration/Average Returns       -25.8312
evaluation/num steps total     393000
evaluation/num paths total       3930
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.517597
evaluation/Rewards Std              1.23788
evaluation/Rewards Max             -0.0133694
evaluation/Rewards Min            -10.3979
evaluation/Returns Mean           -51.7597
evaluation/Returns Std             49.5821
evaluation/Returns Max             -4.40232
evaluation/Returns Min           -152.003
evaluation/Actions Mean             0.00429411
evaluation/Actions Std              0.199509
evaluation/Actions Max              0.999251
evaluation/Actions Min             -0.997081
evaluation/Num Paths               15
evaluation/Average Returns        -51.7597
time/data storing (s)               0.00272516
time/evaluation sampling (s)        0.32623
time/exploration sampling (s)       0.140569
time/logging (s)                    0.00486086
time/saving (s)                     0.00195173
time/training (s)                   1.94899
time/epoch (s)                      2.42532
time/total (s)                    641.305
Epoch                             261
-----------------------------  ----------------
2019-04-22 23:37:57.970810 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 262 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                   68.9124
trainer/QF2 Loss                   68.9141
trainer/Policy Loss                31.9076
trainer/Q1 Predictions Mean       -30.0704
trainer/Q1 Predictions Std         33.7986
trainer/Q1 Predictions Max         -6.60849
trainer/Q1 Predictions Min        -86.5758
trainer/Q2 Predictions Mean       -30.0998
trainer/Q2 Predictions Std         33.7853
trainer/Q2 Predictions Max         -6.64559
trainer/Q2 Predictions Min        -86.6208
trainer/Q Targets Mean            -29.3891
trainer/Q Targets Std              33.4824
trainer/Q Targets Max              -1.95419
trainer/Q Targets Min             -86.2183
trainer/Log Pis Mean                1.99348
trainer/Log Pis Std                 1.19766
trainer/Log Pis Max                 7.47283
trainer/Log Pis Min                -0.746558
trainer/Policy mu Mean             -0.101473
trainer/Policy mu Std               0.602065
trainer/Policy mu Max               3.589
trainer/Policy mu Min              -2.96195
trainer/Policy log std Mean        -2.16655
trainer/Policy log std Std          0.414689
trainer/Policy log std Max         -0.525494
trainer/Policy log std Min         -2.80344
trainer/Alpha                       0.0696533
trainer/Alpha Loss                 -0.0173576
exploration/num steps total    131700
exploration/num paths total      1317
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.509812
exploration/Rewards Std             1.06857
exploration/Rewards Max            -0.0026539
exploration/Rewards Min            -9.79745
exploration/Returns Mean          -50.9812
exploration/Returns Std            56.8999
exploration/Returns Max           -12.72
exploration/Returns Min          -163.515
exploration/Actions Mean            0.000231795
exploration/Actions Std             0.230981
exploration/Actions Max             0.998417
exploration/Actions Min            -0.999874
exploration/Num Paths               5
exploration/Average Returns       -50.9812
evaluation/num steps total     394500
evaluation/num paths total       3945
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.435101
evaluation/Rewards Std              0.945777
evaluation/Rewards Max             -0.0275686
evaluation/Rewards Min             -9.25596
evaluation/Returns Mean           -43.5101
evaluation/Returns Std             45.9709
evaluation/Returns Max             -4.7263
evaluation/Returns Min           -154.104
evaluation/Actions Mean             0.00675021
evaluation/Actions Std              0.180078
evaluation/Actions Max              0.997757
evaluation/Actions Min             -0.996852
evaluation/Num Paths               15
evaluation/Average Returns        -43.5101
time/data storing (s)               0.00283639
time/evaluation sampling (s)        0.33108
time/exploration sampling (s)       0.140762
time/logging (s)                    0.0047888
time/saving (s)                     0.0019485
time/training (s)                   1.93227
time/epoch (s)                      2.41369
time/total (s)                    643.723
Epoch                             262
-----------------------------  ----------------
2019-04-22 23:38:00.400834 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 263 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   68.2267
trainer/QF2 Loss                   68.3653
trainer/Policy Loss                20.2255
trainer/Q1 Predictions Mean       -18.4465
trainer/Q1 Predictions Std         25.4143
trainer/Q1 Predictions Max         -6.63051
trainer/Q1 Predictions Min        -87.1839
trainer/Q2 Predictions Mean       -18.4506
trainer/Q2 Predictions Std         25.4176
trainer/Q2 Predictions Max         -6.67685
trainer/Q2 Predictions Min        -86.6991
trainer/Q Targets Mean            -17.7094
trainer/Q Targets Std              24.7613
trainer/Q Targets Max              -0.504619
trainer/Q Targets Min             -86.2099
trainer/Log Pis Mean                1.96044
trainer/Log Pis Std                 1.02503
trainer/Log Pis Max                 4.60797
trainer/Log Pis Min                -1.72319
trainer/Policy mu Mean             -0.0124641
trainer/Policy mu Std               0.477395
trainer/Policy mu Max               2.46567
trainer/Policy mu Min              -2.7728
trainer/Policy log std Mean        -2.21318
trainer/Policy log std Std          0.39314
trainer/Policy log std Max         -0.543897
trainer/Policy log std Min         -2.76866
trainer/Alpha                       0.0708182
trainer/Alpha Loss                 -0.104739
exploration/num steps total    132200
exploration/num paths total      1322
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.837948
exploration/Rewards Std             0.937166
exploration/Rewards Max            -0.00729921
exploration/Rewards Min            -8.33582
exploration/Returns Mean          -83.7948
exploration/Returns Std            52.3984
exploration/Returns Max           -13.3757
exploration/Returns Min          -135.984
exploration/Actions Mean           -0.0117713
exploration/Actions Std             0.245556
exploration/Actions Max             0.99888
exploration/Actions Min            -0.999663
exploration/Num Paths               5
exploration/Average Returns       -83.7948
evaluation/num steps total     396000
evaluation/num paths total       3960
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.383054
evaluation/Rewards Std              1.00692
evaluation/Rewards Max             -0.0168903
evaluation/Rewards Min            -11.0972
evaluation/Returns Mean           -38.3054
evaluation/Returns Std             33.3101
evaluation/Returns Max             -3.75917
evaluation/Returns Min           -116.507
evaluation/Actions Mean             0.00237098
evaluation/Actions Std              0.182814
evaluation/Actions Max              0.997858
evaluation/Actions Min             -0.998682
evaluation/Num Paths               15
evaluation/Average Returns        -38.3054
time/data storing (s)               0.00261399
time/evaluation sampling (s)        0.333311
time/exploration sampling (s)       0.141582
time/logging (s)                    0.00481802
time/saving (s)                     0.0015958
time/training (s)                   1.93776
time/epoch (s)                      2.42168
time/total (s)                    646.149
Epoch                             263
-----------------------------  ---------------
2019-04-22 23:38:02.806575 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 264 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0668593
trainer/QF2 Loss                    0.0811799
trainer/Policy Loss                20.9489
trainer/Q1 Predictions Mean       -19.2709
trainer/Q1 Predictions Std         25.9825
trainer/Q1 Predictions Max         -6.64668
trainer/Q1 Predictions Min        -88.4147
trainer/Q2 Predictions Mean       -19.2375
trainer/Q2 Predictions Std         25.9919
trainer/Q2 Predictions Max         -6.61893
trainer/Q2 Predictions Min        -88.4172
trainer/Q Targets Mean            -19.433
trainer/Q Targets Std              26.0463
trainer/Q Targets Max              -6.61949
trainer/Q Targets Min             -87.7137
trainer/Log Pis Mean                1.80553
trainer/Log Pis Std                 1.11688
trainer/Log Pis Max                 4.596
trainer/Log Pis Min                -2.48549
trainer/Policy mu Mean             -0.0417324
trainer/Policy mu Std               0.521461
trainer/Policy mu Max               2.51553
trainer/Policy mu Min              -3.0286
trainer/Policy log std Mean        -2.17166
trainer/Policy log std Std          0.432145
trainer/Policy log std Max         -0.362657
trainer/Policy log std Min         -2.72665
trainer/Alpha                       0.0719763
trainer/Alpha Loss                 -0.511738
exploration/num steps total    132700
exploration/num paths total      1327
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.633869
exploration/Rewards Std             1.27103
exploration/Rewards Max            -0.0116074
exploration/Rewards Min            -9.5609
exploration/Returns Mean          -63.3869
exploration/Returns Std            33.7264
exploration/Returns Max           -33.1706
exploration/Returns Min          -127.294
exploration/Actions Mean            0.019498
exploration/Actions Std             0.246693
exploration/Actions Max             0.99993
exploration/Actions Min            -0.993851
exploration/Num Paths               5
exploration/Average Returns       -63.3869
evaluation/num steps total     397500
evaluation/num paths total       3975
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.354461
evaluation/Rewards Std              1.09624
evaluation/Rewards Max             -0.0366928
evaluation/Rewards Min            -11.1143
evaluation/Returns Mean           -35.4461
evaluation/Returns Std             35.7902
evaluation/Returns Max             -3.88886
evaluation/Returns Min           -156.045
evaluation/Actions Mean            -0.00404325
evaluation/Actions Std              0.190929
evaluation/Actions Max              0.998327
evaluation/Actions Min             -0.999331
evaluation/Num Paths               15
evaluation/Average Returns        -35.4461
time/data storing (s)               0.00280764
time/evaluation sampling (s)        0.332625
time/exploration sampling (s)       0.139638
time/logging (s)                    0.0047768
time/saving (s)                     0.00192924
time/training (s)                   1.91553
time/epoch (s)                      2.39731
time/total (s)                    648.551
Epoch                             264
-----------------------------  ---------------
2019-04-22 23:38:05.224513 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 265 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.481605
trainer/QF2 Loss                    0.497917
trainer/Policy Loss                26.1881
trainer/Q1 Predictions Mean       -24.5926
trainer/Q1 Predictions Std         30.5739
trainer/Q1 Predictions Max         -6.76655
trainer/Q1 Predictions Min        -99.7055
trainer/Q2 Predictions Mean       -24.5892
trainer/Q2 Predictions Std         30.5805
trainer/Q2 Predictions Max         -6.78238
trainer/Q2 Predictions Min        -99.1597
trainer/Q Targets Mean            -24.5542
trainer/Q Targets Std              30.7029
trainer/Q Targets Max              -0.143505
trainer/Q Targets Min             -99.7244
trainer/Log Pis Mean                1.74552
trainer/Log Pis Std                 1.06075
trainer/Log Pis Max                 3.60352
trainer/Log Pis Min                -1.39579
trainer/Policy mu Mean             -0.0818228
trainer/Policy mu Std               0.421526
trainer/Policy mu Max               0.829691
trainer/Policy mu Min              -2.68575
trainer/Policy log std Mean        -2.20332
trainer/Policy log std Std          0.392992
trainer/Policy log std Max         -0.602204
trainer/Policy log std Min         -2.68228
trainer/Alpha                       0.0713689
trainer/Alpha Loss                 -0.671733
exploration/num steps total    133200
exploration/num paths total      1332
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.790713
exploration/Rewards Std             1.12536
exploration/Rewards Max            -0.00890779
exploration/Rewards Min           -10.0495
exploration/Returns Mean          -79.0713
exploration/Returns Std            42.8421
exploration/Returns Max           -27.3894
exploration/Returns Min          -130.394
exploration/Actions Mean           -0.00499559
exploration/Actions Std             0.245086
exploration/Actions Max             0.997972
exploration/Actions Min            -0.99748
exploration/Num Paths               5
exploration/Average Returns       -79.0713
evaluation/num steps total     399000
evaluation/num paths total       3990
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.582708
evaluation/Rewards Std              1.29665
evaluation/Rewards Max             -0.0273749
evaluation/Rewards Min            -10.2076
evaluation/Returns Mean           -58.2708
evaluation/Returns Std             41.1775
evaluation/Returns Max             -7.0115
evaluation/Returns Min           -143.61
evaluation/Actions Mean             0.0125868
evaluation/Actions Std              0.201804
evaluation/Actions Max              0.99957
evaluation/Actions Min             -0.996613
evaluation/Num Paths               15
evaluation/Average Returns        -58.2708
time/data storing (s)               0.00264578
time/evaluation sampling (s)        0.331083
time/exploration sampling (s)       0.141888
time/logging (s)                    0.00481256
time/saving (s)                     0.0019555
time/training (s)                   1.92727
time/epoch (s)                      2.40966
time/total (s)                    650.965
Epoch                             265
-----------------------------  ---------------
2019-04-22 23:38:07.639310 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 266 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.795247
trainer/QF2 Loss                    0.759484
trainer/Policy Loss                27.0325
trainer/Q1 Predictions Mean       -25.1127
trainer/Q1 Predictions Std         30.8186
trainer/Q1 Predictions Max         -6.86728
trainer/Q1 Predictions Min       -106.027
trainer/Q2 Predictions Mean       -25.0749
trainer/Q2 Predictions Std         30.771
trainer/Q2 Predictions Max         -6.89506
trainer/Q2 Predictions Min       -104.189
trainer/Q Targets Mean            -24.8766
trainer/Q Targets Std              30.6691
trainer/Q Targets Max              -0.202339
trainer/Q Targets Min            -105.049
trainer/Log Pis Mean                2.1111
trainer/Log Pis Std                 1.30557
trainer/Log Pis Max                 6.42942
trainer/Log Pis Min                -2.18767
trainer/Policy mu Mean             -0.187037
trainer/Policy mu Std               0.63464
trainer/Policy mu Max               2.46547
trainer/Policy mu Min              -3.82392
trainer/Policy log std Mean        -2.24023
trainer/Policy log std Std          0.445669
trainer/Policy log std Max         -0.393964
trainer/Policy log std Min         -2.85636
trainer/Alpha                       0.0648481
trainer/Alpha Loss                  0.303977
exploration/num steps total    133700
exploration/num paths total      1337
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.589778
exploration/Rewards Std             0.77817
exploration/Rewards Max            -0.00816974
exploration/Rewards Min            -8.36158
exploration/Returns Mean          -58.9778
exploration/Returns Std            34.9782
exploration/Returns Max           -19.4302
exploration/Returns Min          -100.805
exploration/Actions Mean           -0.00367211
exploration/Actions Std             0.20903
exploration/Actions Max             0.992224
exploration/Actions Min            -0.999294
exploration/Num Paths               5
exploration/Average Returns       -58.9778
evaluation/num steps total     400500
evaluation/num paths total       4005
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.408746
evaluation/Rewards Std              0.996142
evaluation/Rewards Max             -0.0476212
evaluation/Rewards Min             -8.53864
evaluation/Returns Mean           -40.8746
evaluation/Returns Std             27.5526
evaluation/Returns Max            -15.8622
evaluation/Returns Min           -106.685
evaluation/Actions Mean            -0.0010805
evaluation/Actions Std              0.205039
evaluation/Actions Max              0.997574
evaluation/Actions Min             -0.997955
evaluation/Num Paths               15
evaluation/Average Returns        -40.8746
time/data storing (s)               0.00287421
time/evaluation sampling (s)        0.326932
time/exploration sampling (s)       0.14057
time/logging (s)                    0.00441052
time/saving (s)                     0.00195646
time/training (s)                   1.92922
time/epoch (s)                      2.40596
time/total (s)                    653.375
Epoch                             266
-----------------------------  ---------------
2019-04-22 23:38:10.055433 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 267 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0953678
trainer/QF2 Loss                    0.114623
trainer/Policy Loss                22.5247
trainer/Q1 Predictions Mean       -20.9202
trainer/Q1 Predictions Std         26.8906
trainer/Q1 Predictions Max         -6.81268
trainer/Q1 Predictions Min        -89.1449
trainer/Q2 Predictions Mean       -20.9194
trainer/Q2 Predictions Std         26.8927
trainer/Q2 Predictions Max         -6.7271
trainer/Q2 Predictions Min        -89.7193
trainer/Q Targets Mean            -21.0418
trainer/Q Targets Std              27.0894
trainer/Q Targets Max              -6.77924
trainer/Q Targets Min             -88.4064
trainer/Log Pis Mean                1.73935
trainer/Log Pis Std                 1.31048
trainer/Log Pis Max                 3.608
trainer/Log Pis Min                -5.24183
trainer/Policy mu Mean             -0.0322444
trainer/Policy mu Std               0.55159
trainer/Policy mu Max               2.74295
trainer/Policy mu Min              -3.16414
trainer/Policy log std Mean        -2.1712
trainer/Policy log std Std          0.454309
trainer/Policy log std Max         -0.342064
trainer/Policy log std Min         -2.74055
trainer/Alpha                       0.066642
trainer/Alpha Loss                 -0.705937
exploration/num steps total    134200
exploration/num paths total      1342
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.548694
exploration/Rewards Std             1.06083
exploration/Rewards Max            -0.012088
exploration/Rewards Min            -8.87023
exploration/Returns Mean          -54.8694
exploration/Returns Std            47.1901
exploration/Returns Max           -18.8719
exploration/Returns Min          -147.833
exploration/Actions Mean            0.00195719
exploration/Actions Std             0.233097
exploration/Actions Max             0.999754
exploration/Actions Min            -0.999586
exploration/Num Paths               5
exploration/Average Returns       -54.8694
evaluation/num steps total     402000
evaluation/num paths total       4020
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.313204
evaluation/Rewards Std              1.15965
evaluation/Rewards Max             -0.0314531
evaluation/Rewards Min            -10.8131
evaluation/Returns Mean           -31.3204
evaluation/Returns Std             21.7901
evaluation/Returns Max             -6.42905
evaluation/Returns Min            -67.9515
evaluation/Actions Mean             0.00422518
evaluation/Actions Std              0.194682
evaluation/Actions Max              0.999296
evaluation/Actions Min             -0.998537
evaluation/Num Paths               15
evaluation/Average Returns        -31.3204
time/data storing (s)               0.00273599
time/evaluation sampling (s)        0.333162
time/exploration sampling (s)       0.144186
time/logging (s)                    0.00477675
time/saving (s)                     0.00195297
time/training (s)                   1.92187
time/epoch (s)                      2.40869
time/total (s)                    655.788
Epoch                             267
-----------------------------  ---------------
2019-04-22 23:38:12.488024 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 268 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.63805
trainer/QF2 Loss                    0.674363
trainer/Policy Loss                21.9909
trainer/Q1 Predictions Mean       -19.9793
trainer/Q1 Predictions Std         26.0754
trainer/Q1 Predictions Max         -6.96695
trainer/Q1 Predictions Min        -82.6083
trainer/Q2 Predictions Mean       -19.9729
trainer/Q2 Predictions Std         26.0926
trainer/Q2 Predictions Max         -7.02604
trainer/Q2 Predictions Min        -82.7912
trainer/Q Targets Mean            -19.8461
trainer/Q Targets Std              26.0018
trainer/Q Targets Max              -0.190803
trainer/Q Targets Min             -82.4156
trainer/Log Pis Mean                2.143
trainer/Log Pis Std                 1.07407
trainer/Log Pis Max                 5.58574
trainer/Log Pis Min                -3.48754
trainer/Policy mu Mean             -0.0150868
trainer/Policy mu Std               0.430428
trainer/Policy mu Max               2.70774
trainer/Policy mu Min              -1.51683
trainer/Policy log std Mean        -2.24562
trainer/Policy log std Std          0.419666
trainer/Policy log std Max         -0.63167
trainer/Policy log std Min         -2.86402
trainer/Alpha                       0.0679568
trainer/Alpha Loss                  0.384498
exploration/num steps total    134700
exploration/num paths total      1347
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.445379
exploration/Rewards Std             1.24226
exploration/Rewards Max            -0.00835028
exploration/Rewards Min            -9.16694
exploration/Returns Mean          -44.5379
exploration/Returns Std             9.72736
exploration/Returns Max           -30.5286
exploration/Returns Min           -55.203
exploration/Actions Mean            0.0168291
exploration/Actions Std             0.250959
exploration/Actions Max             0.997583
exploration/Actions Min            -0.996026
exploration/Num Paths               5
exploration/Average Returns       -44.5379
evaluation/num steps total     403500
evaluation/num paths total       4035
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.298099
evaluation/Rewards Std              0.885494
evaluation/Rewards Max             -0.0121551
evaluation/Rewards Min             -9.11874
evaluation/Returns Mean           -29.8099
evaluation/Returns Std             26.6149
evaluation/Returns Max             -2.41665
evaluation/Returns Min           -115.519
evaluation/Actions Mean             0.00307211
evaluation/Actions Std              0.180666
evaluation/Actions Max              0.997568
evaluation/Actions Min             -0.996619
evaluation/Num Paths               15
evaluation/Average Returns        -29.8099
time/data storing (s)               0.00263279
time/evaluation sampling (s)        0.329085
time/exploration sampling (s)       0.140208
time/logging (s)                    0.00482085
time/saving (s)                     0.00194433
time/training (s)                   1.9455
time/epoch (s)                      2.42419
time/total (s)                    658.216
Epoch                             268
-----------------------------  ---------------
2019-04-22 23:38:14.872789 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 269 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.816612
trainer/QF2 Loss                    0.817116
trainer/Policy Loss                21.1615
trainer/Q1 Predictions Mean       -19.3432
trainer/Q1 Predictions Std         25.7688
trainer/Q1 Predictions Max         -6.6388
trainer/Q1 Predictions Min        -89.511
trainer/Q2 Predictions Mean       -19.3495
trainer/Q2 Predictions Std         25.7886
trainer/Q2 Predictions Max         -6.67478
trainer/Q2 Predictions Min        -89.7483
trainer/Q Targets Mean            -19.5349
trainer/Q Targets Std              26.0978
trainer/Q Targets Max              -0.308857
trainer/Q Targets Min             -88.8055
trainer/Log Pis Mean                2.00241
trainer/Log Pis Std                 1.0134
trainer/Log Pis Max                 4.25328
trainer/Log Pis Min                -1.67153
trainer/Policy mu Mean             -0.069293
trainer/Policy mu Std               0.475618
trainer/Policy mu Max               2.53279
trainer/Policy mu Min              -2.78805
trainer/Policy log std Mean        -2.2385
trainer/Policy log std Std          0.395922
trainer/Policy log std Max         -0.535708
trainer/Policy log std Min         -2.8089
trainer/Alpha                       0.0686095
trainer/Alpha Loss                  0.00644636
exploration/num steps total    135200
exploration/num paths total      1352
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.683988
exploration/Rewards Std             1.56337
exploration/Rewards Max            -0.0020964
exploration/Rewards Min           -10.9869
exploration/Returns Mean          -68.3988
exploration/Returns Std            23.2619
exploration/Returns Max           -34.0904
exploration/Returns Min          -107.095
exploration/Actions Mean           -0.0167773
exploration/Actions Std             0.279107
exploration/Actions Max             0.999139
exploration/Actions Min            -0.99888
exploration/Num Paths               5
exploration/Average Returns       -68.3988
evaluation/num steps total     405000
evaluation/num paths total       4050
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.396916
evaluation/Rewards Std              1.10549
evaluation/Rewards Max             -0.0267169
evaluation/Rewards Min            -10.4228
evaluation/Returns Mean           -39.6916
evaluation/Returns Std             28.5856
evaluation/Returns Max             -8.32371
evaluation/Returns Min           -105.276
evaluation/Actions Mean            -0.00196525
evaluation/Actions Std              0.199458
evaluation/Actions Max              0.998712
evaluation/Actions Min             -0.998443
evaluation/Num Paths               15
evaluation/Average Returns        -39.6916
time/data storing (s)               0.0028119
time/evaluation sampling (s)        0.327988
time/exploration sampling (s)       0.138884
time/logging (s)                    0.00477884
time/saving (s)                     0.00154802
time/training (s)                   1.89993
time/epoch (s)                      2.37594
time/total (s)                    660.596
Epoch                             269
-----------------------------  ---------------
2019-04-22 23:38:17.289382 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 270 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.957443
trainer/QF2 Loss                    0.919006
trainer/Policy Loss                19.0016
trainer/Q1 Predictions Mean       -17.088
trainer/Q1 Predictions Std         22.5076
trainer/Q1 Predictions Max         -6.73168
trainer/Q1 Predictions Min        -78.6324
trainer/Q2 Predictions Mean       -17.1219
trainer/Q2 Predictions Std         22.5344
trainer/Q2 Predictions Max         -6.79452
trainer/Q2 Predictions Min        -78.7114
trainer/Q Targets Mean            -17.2286
trainer/Q Targets Std              23.0117
trainer/Q Targets Max              -0.165489
trainer/Q Targets Min             -80.1537
trainer/Log Pis Mean                2.02342
trainer/Log Pis Std                 1.12763
trainer/Log Pis Max                 7.3886
trainer/Log Pis Min                -1.58612
trainer/Policy mu Mean              0.0050899
trainer/Policy mu Std               0.432937
trainer/Policy mu Max               2.66719
trainer/Policy mu Min              -2.82678
trainer/Policy log std Mean        -2.24238
trainer/Policy log std Std          0.375237
trainer/Policy log std Max         -0.457409
trainer/Policy log std Min         -2.84135
trainer/Alpha                       0.0689351
trainer/Alpha Loss                  0.0626423
exploration/num steps total    135700
exploration/num paths total      1357
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.496402
exploration/Rewards Std             0.871842
exploration/Rewards Max            -0.012251
exploration/Rewards Min            -8.20146
exploration/Returns Mean          -49.6402
exploration/Returns Std            35.1822
exploration/Returns Max           -15.9192
exploration/Returns Min          -115.241
exploration/Actions Mean           -0.0125318
exploration/Actions Std             0.221349
exploration/Actions Max             0.999033
exploration/Actions Min            -0.997303
exploration/Num Paths               5
exploration/Average Returns       -49.6402
evaluation/num steps total     406500
evaluation/num paths total       4065
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.419012
evaluation/Rewards Std              1.01581
evaluation/Rewards Max             -0.0116339
evaluation/Rewards Min            -11.2742
evaluation/Returns Mean           -41.9012
evaluation/Returns Std             33.0148
evaluation/Returns Max             -2.63097
evaluation/Returns Min           -131.38
evaluation/Actions Mean            -0.00231048
evaluation/Actions Std              0.185606
evaluation/Actions Max              0.998059
evaluation/Actions Min             -0.996168
evaluation/Num Paths               15
evaluation/Average Returns        -41.9012
time/data storing (s)               0.00276839
time/evaluation sampling (s)        0.330842
time/exploration sampling (s)       0.141832
time/logging (s)                    0.00484622
time/saving (s)                     0.00159261
time/training (s)                   1.92652
time/epoch (s)                      2.40841
time/total (s)                    663.009
Epoch                             270
-----------------------------  ---------------
2019-04-22 23:38:19.700060 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 271 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.93321
trainer/QF2 Loss                    1.92752
trainer/Policy Loss                19.3103
trainer/Q1 Predictions Mean       -17.3401
trainer/Q1 Predictions Std         23.5552
trainer/Q1 Predictions Max         -6.58915
trainer/Q1 Predictions Min        -86.2509
trainer/Q2 Predictions Mean       -17.3736
trainer/Q2 Predictions Std         23.5381
trainer/Q2 Predictions Max         -6.62093
trainer/Q2 Predictions Min        -86.1673
trainer/Q Targets Mean            -17.3428
trainer/Q Targets Std              23.9076
trainer/Q Targets Max              -0.0670162
trainer/Q Targets Min             -86.4202
trainer/Log Pis Mean                2.18299
trainer/Log Pis Std                 0.944653
trainer/Log Pis Max                 4.9488
trainer/Log Pis Min                -0.937187
trainer/Policy mu Mean             -0.0531466
trainer/Policy mu Std               0.446288
trainer/Policy mu Max               2.48461
trainer/Policy mu Min              -2.64381
trainer/Policy log std Mean        -2.26653
trainer/Policy log std Std          0.338353
trainer/Policy log std Max         -0.698619
trainer/Policy log std Min         -2.77749
trainer/Alpha                       0.0707076
trainer/Alpha Loss                  0.484826
exploration/num steps total    136200
exploration/num paths total      1362
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.590094
exploration/Rewards Std             0.807974
exploration/Rewards Max            -0.0140307
exploration/Rewards Min            -7.54404
exploration/Returns Mean          -59.0094
exploration/Returns Std            38.3851
exploration/Returns Max           -21.8299
exploration/Returns Min          -116.547
exploration/Actions Mean           -0.00969309
exploration/Actions Std             0.211588
exploration/Actions Max             0.994475
exploration/Actions Min            -0.996057
exploration/Num Paths               5
exploration/Average Returns       -59.0094
evaluation/num steps total     408000
evaluation/num paths total       4080
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.341058
evaluation/Rewards Std              1.05437
evaluation/Rewards Max             -0.0112618
evaluation/Rewards Min            -10.2491
evaluation/Returns Mean           -34.1058
evaluation/Returns Std             30.9661
evaluation/Returns Max             -3.43077
evaluation/Returns Min           -129.12
evaluation/Actions Mean            -0.00454043
evaluation/Actions Std              0.182991
evaluation/Actions Max              0.999005
evaluation/Actions Min             -0.996815
evaluation/Num Paths               15
evaluation/Average Returns        -34.1058
time/data storing (s)               0.00265169
time/evaluation sampling (s)        0.328248
time/exploration sampling (s)       0.140844
time/logging (s)                    0.00349937
time/saving (s)                     0.00193294
time/training (s)                   1.92369
time/epoch (s)                      2.40087
time/total (s)                    665.413
Epoch                             271
-----------------------------  ---------------
2019-04-22 23:38:22.090682 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 272 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.07786
trainer/QF2 Loss                    1.06965
trainer/Policy Loss                24.8373
trainer/Q1 Predictions Mean       -22.9738
trainer/Q1 Predictions Std         27.9779
trainer/Q1 Predictions Max         -6.86446
trainer/Q1 Predictions Min        -79.6549
trainer/Q2 Predictions Mean       -22.972
trainer/Q2 Predictions Std         27.9186
trainer/Q2 Predictions Max         -6.93693
trainer/Q2 Predictions Min        -79.1046
trainer/Q Targets Mean            -22.7919
trainer/Q Targets Std              27.9654
trainer/Q Targets Max              -0.129337
trainer/Q Targets Min             -78.6757
trainer/Log Pis Mean                2.15381
trainer/Log Pis Std                 0.941421
trainer/Log Pis Max                 3.68788
trainer/Log Pis Min                -2.3693
trainer/Policy mu Mean             -0.117633
trainer/Policy mu Std               0.407798
trainer/Policy mu Max               0.489033
trainer/Policy mu Min              -2.05264
trainer/Policy log std Mean        -2.23419
trainer/Policy log std Std          0.346449
trainer/Policy log std Max         -0.600448
trainer/Policy log std Min         -2.80619
trainer/Alpha                       0.0729961
trainer/Alpha Loss                  0.402585
exploration/num steps total    136700
exploration/num paths total      1367
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.305373
exploration/Rewards Std             0.870908
exploration/Rewards Max            -0.00568497
exploration/Rewards Min            -9.25586
exploration/Returns Mean          -30.5373
exploration/Returns Std            11.6189
exploration/Returns Max           -14.8095
exploration/Returns Min           -49.6601
exploration/Actions Mean            0.0115294
exploration/Actions Std             0.21397
exploration/Actions Max             0.999728
exploration/Actions Min            -0.995581
exploration/Num Paths               5
exploration/Average Returns       -30.5373
evaluation/num steps total     409500
evaluation/num paths total       4095
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.357633
evaluation/Rewards Std              1.01993
evaluation/Rewards Max             -0.0158173
evaluation/Rewards Min            -10.7093
evaluation/Returns Mean           -35.7633
evaluation/Returns Std             33.6787
evaluation/Returns Max             -7.44071
evaluation/Returns Min           -126.126
evaluation/Actions Mean             0.000985661
evaluation/Actions Std              0.193703
evaluation/Actions Max              0.999758
evaluation/Actions Min             -0.997877
evaluation/Num Paths               15
evaluation/Average Returns        -35.7633
time/data storing (s)               0.00271043
time/evaluation sampling (s)        0.318869
time/exploration sampling (s)       0.140317
time/logging (s)                    0.00480816
time/saving (s)                     0.00158002
time/training (s)                   1.9162
time/epoch (s)                      2.38448
time/total (s)                    667.803
Epoch                             272
-----------------------------  ----------------
2019-04-22 23:38:24.509720 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 273 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0759139
trainer/QF2 Loss                    0.0743404
trainer/Policy Loss                20.4682
trainer/Q1 Predictions Mean       -18.5331
trainer/Q1 Predictions Std         23.6685
trainer/Q1 Predictions Max         -6.60843
trainer/Q1 Predictions Min        -75.46
trainer/Q2 Predictions Mean       -18.5267
trainer/Q2 Predictions Std         23.6575
trainer/Q2 Predictions Max         -6.67888
trainer/Q2 Predictions Min        -75.522
trainer/Q Targets Mean            -18.7181
trainer/Q Targets Std              23.7855
trainer/Q Targets Max              -6.68114
trainer/Q Targets Min             -75.9134
trainer/Log Pis Mean                2.13603
trainer/Log Pis Std                 0.800852
trainer/Log Pis Max                 4.34823
trainer/Log Pis Min                -1.34883
trainer/Policy mu Mean             -0.0801146
trainer/Policy mu Std               0.400958
trainer/Policy mu Max               2.55924
trainer/Policy mu Min              -2.69469
trainer/Policy log std Mean        -2.26294
trainer/Policy log std Std          0.356931
trainer/Policy log std Max         -0.530566
trainer/Policy log std Min         -2.76896
trainer/Alpha                       0.0746541
trainer/Alpha Loss                  0.352977
exploration/num steps total    137200
exploration/num paths total      1372
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.673993
exploration/Rewards Std             1.09032
exploration/Rewards Max            -0.018001
exploration/Rewards Min            -9.97805
exploration/Returns Mean          -67.3993
exploration/Returns Std            57.6627
exploration/Returns Max           -18.6408
exploration/Returns Min          -144.214
exploration/Actions Mean           -0.0177443
exploration/Actions Std             0.219072
exploration/Actions Max             0.991641
exploration/Actions Min            -0.998653
exploration/Num Paths               5
exploration/Average Returns       -67.3993
evaluation/num steps total     411000
evaluation/num paths total       4110
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.258483
evaluation/Rewards Std              0.942435
evaluation/Rewards Max             -0.0414689
evaluation/Rewards Min             -9.80596
evaluation/Returns Mean           -25.8483
evaluation/Returns Std             14.8346
evaluation/Returns Max             -6.09407
evaluation/Returns Min            -48.2417
evaluation/Actions Mean             0.00231968
evaluation/Actions Std              0.189629
evaluation/Actions Max              0.998858
evaluation/Actions Min             -0.996595
evaluation/Num Paths               15
evaluation/Average Returns        -25.8483
time/data storing (s)               0.00275159
time/evaluation sampling (s)        0.327241
time/exploration sampling (s)       0.139783
time/logging (s)                    0.00487801
time/saving (s)                     0.0019519
time/training (s)                   1.93433
time/epoch (s)                      2.41094
time/total (s)                    670.218
Epoch                             273
-----------------------------  ---------------
2019-04-22 23:38:26.951321 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 274 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.803093
trainer/QF2 Loss                    0.803108
trainer/Policy Loss                21.2584
trainer/Q1 Predictions Mean       -19.3592
trainer/Q1 Predictions Std         23.6344
trainer/Q1 Predictions Max         -6.73968
trainer/Q1 Predictions Min        -76.0902
trainer/Q2 Predictions Mean       -19.3857
trainer/Q2 Predictions Std         23.631
trainer/Q2 Predictions Max         -6.79797
trainer/Q2 Predictions Min        -76.4763
trainer/Q Targets Mean            -19.4219
trainer/Q Targets Std              23.9272
trainer/Q Targets Max              -0.0714156
trainer/Q Targets Min             -75.9495
trainer/Log Pis Mean                2.05417
trainer/Log Pis Std                 1.28091
trainer/Log Pis Max                 6.95928
trainer/Log Pis Min                -5.68673
trainer/Policy mu Mean             -0.035493
trainer/Policy mu Std               0.483551
trainer/Policy mu Max               2.20669
trainer/Policy mu Min              -2.75785
trainer/Policy log std Mean        -2.24442
trainer/Policy log std Std          0.372689
trainer/Policy log std Max         -0.616755
trainer/Policy log std Min         -2.87498
trainer/Alpha                       0.0728219
trainer/Alpha Loss                  0.141899
exploration/num steps total    137700
exploration/num paths total      1377
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.601188
exploration/Rewards Std             1.1997
exploration/Rewards Max            -0.00527982
exploration/Rewards Min           -10.2594
exploration/Returns Mean          -60.1188
exploration/Returns Std            56.247
exploration/Returns Max           -18.1784
exploration/Returns Min          -169.61
exploration/Actions Mean           -0.0194494
exploration/Actions Std             0.230185
exploration/Actions Max             0.997507
exploration/Actions Min            -0.999441
exploration/Num Paths               5
exploration/Average Returns       -60.1188
evaluation/num steps total     412500
evaluation/num paths total       4125
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.535546
evaluation/Rewards Std              1.19418
evaluation/Rewards Max             -0.0205919
evaluation/Rewards Min            -11.8524
evaluation/Returns Mean           -53.5546
evaluation/Returns Std             57.8055
evaluation/Returns Max             -5.88507
evaluation/Returns Min           -182.366
evaluation/Actions Mean            -0.005596
evaluation/Actions Std              0.199231
evaluation/Actions Max              0.998473
evaluation/Actions Min             -0.999444
evaluation/Num Paths               15
evaluation/Average Returns        -53.5546
time/data storing (s)               0.00299521
time/evaluation sampling (s)        0.336301
time/exploration sampling (s)       0.13926
time/logging (s)                    0.00398102
time/saving (s)                     0.00196841
time/training (s)                   1.948
time/epoch (s)                      2.43251
time/total (s)                    672.654
Epoch                             274
-----------------------------  ---------------
2019-04-22 23:38:29.360440 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 275 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.159878
trainer/QF2 Loss                    0.188446
trainer/Policy Loss                21.2164
trainer/Q1 Predictions Mean       -19.2913
trainer/Q1 Predictions Std         23.6582
trainer/Q1 Predictions Max         -6.57672
trainer/Q1 Predictions Min        -73.0723
trainer/Q2 Predictions Mean       -19.2608
trainer/Q2 Predictions Std         23.6407
trainer/Q2 Predictions Max         -6.55889
trainer/Q2 Predictions Min        -73.0803
trainer/Q Targets Mean            -19.5105
trainer/Q Targets Std              23.9508
trainer/Q Targets Max              -6.69357
trainer/Q Targets Min             -73.7915
trainer/Log Pis Mean                2.08897
trainer/Log Pis Std                 1.10171
trainer/Log Pis Max                 7.53309
trainer/Log Pis Min                -0.416355
trainer/Policy mu Mean             -0.0207904
trainer/Policy mu Std               0.507724
trainer/Policy mu Max               2.44644
trainer/Policy mu Min              -2.61338
trainer/Policy log std Mean        -2.22773
trainer/Policy log std Std          0.367217
trainer/Policy log std Max         -0.630693
trainer/Policy log std Min         -2.80329
trainer/Alpha                       0.0713244
trainer/Alpha Loss                  0.234946
exploration/num steps total    138200
exploration/num paths total      1382
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.543312
exploration/Rewards Std             1.09267
exploration/Rewards Max            -0.00791773
exploration/Rewards Min            -9.38539
exploration/Returns Mean          -54.3312
exploration/Returns Std            43.4174
exploration/Returns Max           -13.0295
exploration/Returns Min          -137.61
exploration/Actions Mean           -0.00270765
exploration/Actions Std             0.23533
exploration/Actions Max             0.996409
exploration/Actions Min            -0.998954
exploration/Num Paths               5
exploration/Average Returns       -54.3312
evaluation/num steps total     414000
evaluation/num paths total       4140
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.349239
evaluation/Rewards Std              0.851085
evaluation/Rewards Max             -0.0201604
evaluation/Rewards Min             -9.17719
evaluation/Returns Mean           -34.9239
evaluation/Returns Std             31.3246
evaluation/Returns Max             -7.45876
evaluation/Returns Min           -114.712
evaluation/Actions Mean            -0.00329794
evaluation/Actions Std              0.178623
evaluation/Actions Max              0.997729
evaluation/Actions Min             -0.997119
evaluation/Num Paths               15
evaluation/Average Returns        -34.9239
time/data storing (s)               0.00266927
time/evaluation sampling (s)        0.32493
time/exploration sampling (s)       0.139125
time/logging (s)                    0.00478832
time/saving (s)                     0.00155734
time/training (s)                   1.92931
time/epoch (s)                      2.40238
time/total (s)                    675.061
Epoch                             275
-----------------------------  ---------------
2019-04-22 23:38:31.780961 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 276 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.724544
trainer/QF2 Loss                    0.738977
trainer/Policy Loss                19.2484
trainer/Q1 Predictions Mean       -17.5974
trainer/Q1 Predictions Std         21.9736
trainer/Q1 Predictions Max         -6.74018
trainer/Q1 Predictions Min        -75.3752
trainer/Q2 Predictions Mean       -17.6059
trainer/Q2 Predictions Std         21.965
trainer/Q2 Predictions Max         -6.73485
trainer/Q2 Predictions Min        -75.6585
trainer/Q Targets Mean            -17.6856
trainer/Q Targets Std              22.298
trainer/Q Targets Max              -0.173977
trainer/Q Targets Min             -75.7681
trainer/Log Pis Mean                1.807
trainer/Log Pis Std                 1.01929
trainer/Log Pis Max                 4.52095
trainer/Log Pis Min                -2.13385
trainer/Policy mu Mean             -0.0229643
trainer/Policy mu Std               0.375606
trainer/Policy mu Max               1.7861
trainer/Policy mu Min              -2.51283
trainer/Policy log std Mean        -2.25656
trainer/Policy log std Std          0.296747
trainer/Policy log std Max         -0.520944
trainer/Policy log std Min         -2.76549
trainer/Alpha                       0.0703176
trainer/Alpha Loss                 -0.512349
exploration/num steps total    138700
exploration/num paths total      1387
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.353212
exploration/Rewards Std             1.05721
exploration/Rewards Max            -0.00884441
exploration/Rewards Min            -9.73179
exploration/Returns Mean          -35.3212
exploration/Returns Std            19.4686
exploration/Returns Max           -15.0244
exploration/Returns Min           -62.9618
exploration/Actions Mean           -0.00690542
exploration/Actions Std             0.216885
exploration/Actions Max             0.999581
exploration/Actions Min            -0.99922
exploration/Num Paths               5
exploration/Average Returns       -35.3212
evaluation/num steps total     415500
evaluation/num paths total       4155
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.50405
evaluation/Rewards Std              1.12152
evaluation/Rewards Max             -0.000991575
evaluation/Rewards Min             -9.92018
evaluation/Returns Mean           -50.405
evaluation/Returns Std             43.9691
evaluation/Returns Max             -7.76853
evaluation/Returns Min           -142.673
evaluation/Actions Mean            -0.00315983
evaluation/Actions Std              0.195901
evaluation/Actions Max              0.998109
evaluation/Actions Min             -0.997305
evaluation/Num Paths               15
evaluation/Average Returns        -50.405
time/data storing (s)               0.00274492
time/evaluation sampling (s)        0.327037
time/exploration sampling (s)       0.138555
time/logging (s)                    0.0038436
time/saving (s)                     0.00194091
time/training (s)                   1.93671
time/epoch (s)                      2.41083
time/total (s)                    677.476
Epoch                             276
-----------------------------  ----------------
2019-04-22 23:38:34.191493 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 277 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0912069
trainer/QF2 Loss                    0.0748815
trainer/Policy Loss                16.0076
trainer/Q1 Predictions Mean       -14.2787
trainer/Q1 Predictions Std         17.911
trainer/Q1 Predictions Max         -6.86375
trainer/Q1 Predictions Min        -71.9519
trainer/Q2 Predictions Mean       -14.2628
trainer/Q2 Predictions Std         17.9169
trainer/Q2 Predictions Max         -6.89867
trainer/Q2 Predictions Min        -71.6865
trainer/Q Targets Mean            -14.2666
trainer/Q Targets Std              18.1226
trainer/Q Targets Max              -6.76525
trainer/Q Targets Min             -72.3233
trainer/Log Pis Mean                1.8174
trainer/Log Pis Std                 1.04381
trainer/Log Pis Max                 4.79519
trainer/Log Pis Min                -2.53247
trainer/Policy mu Mean             -0.030333
trainer/Policy mu Std               0.373385
trainer/Policy mu Max               1.91399
trainer/Policy mu Min              -2.85275
trainer/Policy log std Mean        -2.20693
trainer/Policy log std Std          0.284082
trainer/Policy log std Max         -0.334352
trainer/Policy log std Min         -2.80499
trainer/Alpha                       0.0678161
trainer/Alpha Loss                 -0.491309
exploration/num steps total    139200
exploration/num paths total      1392
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.51377
exploration/Rewards Std             1.44486
exploration/Rewards Max            -0.00564892
exploration/Rewards Min           -10.1678
exploration/Returns Mean          -51.377
exploration/Returns Std            12.3868
exploration/Returns Max           -39.3906
exploration/Returns Min           -68.1296
exploration/Actions Mean            0.0234524
exploration/Actions Std             0.264855
exploration/Actions Max             0.999541
exploration/Actions Min            -0.998784
exploration/Num Paths               5
exploration/Average Returns       -51.377
evaluation/num steps total     417000
evaluation/num paths total       4170
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.23363
evaluation/Rewards Std              0.853562
evaluation/Rewards Max             -0.0199283
evaluation/Rewards Min             -8.33636
evaluation/Returns Mean           -23.363
evaluation/Returns Std             11.2736
evaluation/Returns Max             -3.8343
evaluation/Returns Min            -41.6451
evaluation/Actions Mean            -0.00115129
evaluation/Actions Std              0.183438
evaluation/Actions Max              0.998675
evaluation/Actions Min             -0.99793
evaluation/Num Paths               15
evaluation/Average Returns        -23.363
time/data storing (s)               0.00259155
time/evaluation sampling (s)        0.323336
time/exploration sampling (s)       0.141069
time/logging (s)                    0.00477649
time/saving (s)                     0.00154939
time/training (s)                   1.92927
time/epoch (s)                      2.4026
time/total (s)                    679.883
Epoch                             277
-----------------------------  ---------------
2019-04-22 23:38:36.603176 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 278 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.37718
trainer/QF2 Loss                    1.42327
trainer/Policy Loss                19.4004
trainer/Q1 Predictions Mean       -17.3783
trainer/Q1 Predictions Std         21.4247
trainer/Q1 Predictions Max         -6.73999
trainer/Q1 Predictions Min        -86.8338
trainer/Q2 Predictions Mean       -17.4253
trainer/Q2 Predictions Std         21.4457
trainer/Q2 Predictions Max         -6.69896
trainer/Q2 Predictions Min        -86.6081
trainer/Q Targets Mean            -17.3375
trainer/Q Targets Std              21.6967
trainer/Q Targets Max              -0.196949
trainer/Q Targets Min             -86.4632
trainer/Log Pis Mean                2.18597
trainer/Log Pis Std                 1.27392
trainer/Log Pis Max                 6.43985
trainer/Log Pis Min                -1.50113
trainer/Policy mu Mean             -0.0922449
trainer/Policy mu Std               0.581433
trainer/Policy mu Max               2.87178
trainer/Policy mu Min              -3.00004
trainer/Policy log std Mean        -2.26633
trainer/Policy log std Std          0.389636
trainer/Policy log std Max         -0.576411
trainer/Policy log std Min         -2.89987
trainer/Alpha                       0.0681703
trainer/Alpha Loss                  0.499501
exploration/num steps total    139700
exploration/num paths total      1397
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.444363
exploration/Rewards Std             0.94958
exploration/Rewards Max            -0.00256223
exploration/Rewards Min            -9.02665
exploration/Returns Mean          -44.4363
exploration/Returns Std            43.1921
exploration/Returns Max           -18.5067
exploration/Returns Min          -130.44
exploration/Actions Mean            0.0148192
exploration/Actions Std             0.21057
exploration/Actions Max             0.998853
exploration/Actions Min            -0.999758
exploration/Num Paths               5
exploration/Average Returns       -44.4363
evaluation/num steps total     418500
evaluation/num paths total       4185
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.187481
evaluation/Rewards Std              0.756589
evaluation/Rewards Max             -0.00804274
evaluation/Rewards Min             -9.27028
evaluation/Returns Mean           -18.7481
evaluation/Returns Std             12.9735
evaluation/Returns Max             -3.03054
evaluation/Returns Min            -50.0861
evaluation/Actions Mean            -0.00430292
evaluation/Actions Std              0.165136
evaluation/Actions Max              0.99618
evaluation/Actions Min             -0.99674
evaluation/Num Paths               15
evaluation/Average Returns        -18.7481
time/data storing (s)               0.00272677
time/evaluation sampling (s)        0.324556
time/exploration sampling (s)       0.140029
time/logging (s)                    0.00479296
time/saving (s)                     0.00196031
time/training (s)                   1.9291
time/epoch (s)                      2.40316
time/total (s)                    682.29
Epoch                             278
-----------------------------  ---------------
2019-04-22 23:38:39.025524 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 279 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.591688
trainer/QF2 Loss                    0.72569
trainer/Policy Loss                23.5401
trainer/Q1 Predictions Mean       -21.3651
trainer/Q1 Predictions Std         26.206
trainer/Q1 Predictions Max         -6.79263
trainer/Q1 Predictions Min       -124.372
trainer/Q2 Predictions Mean       -21.3568
trainer/Q2 Predictions Std         26.1934
trainer/Q2 Predictions Max         -6.86083
trainer/Q2 Predictions Min       -125.414
trainer/Q Targets Mean            -21.3378
trainer/Q Targets Std              26.2604
trainer/Q Targets Max              -0.144
trainer/Q Targets Min            -125.566
trainer/Log Pis Mean                2.34203
trainer/Log Pis Std                 1.57175
trainer/Log Pis Max                10.6812
trainer/Log Pis Min                -0.587887
trainer/Policy mu Mean             -0.0533317
trainer/Policy mu Std               0.765701
trainer/Policy mu Max               3.64914
trainer/Policy mu Min              -4.06874
trainer/Policy log std Mean        -2.18296
trainer/Policy log std Std          0.475292
trainer/Policy log std Max         -0.0321751
trainer/Policy log std Min         -2.90515
trainer/Alpha                       0.0715597
trainer/Alpha Loss                  0.902059
exploration/num steps total    140200
exploration/num paths total      1402
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.26214
exploration/Rewards Std             0.715399
exploration/Rewards Max            -0.00995253
exploration/Rewards Min            -7.8417
exploration/Returns Mean          -26.214
exploration/Returns Std            15.1054
exploration/Returns Max           -15.0715
exploration/Returns Min           -53.8881
exploration/Actions Mean            0.00764311
exploration/Actions Std             0.196831
exploration/Actions Max             0.99743
exploration/Actions Min            -0.989932
exploration/Num Paths               5
exploration/Average Returns       -26.214
evaluation/num steps total     420000
evaluation/num paths total       4200
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.502787
evaluation/Rewards Std              1.19548
evaluation/Rewards Max             -0.0198195
evaluation/Rewards Min            -10.8015
evaluation/Returns Mean           -50.2787
evaluation/Returns Std             33.7767
evaluation/Returns Max             -6.91925
evaluation/Returns Min           -123.431
evaluation/Actions Mean             0.000372911
evaluation/Actions Std              0.201412
evaluation/Actions Max              0.998903
evaluation/Actions Min             -0.99932
evaluation/Num Paths               15
evaluation/Average Returns        -50.2787
time/data storing (s)               0.00275376
time/evaluation sampling (s)        0.327382
time/exploration sampling (s)       0.141674
time/logging (s)                    0.0048402
time/saving (s)                     0.00193952
time/training (s)                   1.93651
time/epoch (s)                      2.4151
time/total (s)                    684.71
Epoch                             279
-----------------------------  ----------------
2019-04-22 23:38:41.439357 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 280 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.965392
trainer/QF2 Loss                    0.922484
trainer/Policy Loss                21.9328
trainer/Q1 Predictions Mean       -19.8185
trainer/Q1 Predictions Std         22.5154
trainer/Q1 Predictions Max         -6.76278
trainer/Q1 Predictions Min        -69.156
trainer/Q2 Predictions Mean       -19.8345
trainer/Q2 Predictions Std         22.5254
trainer/Q2 Predictions Max         -6.72629
trainer/Q2 Predictions Min        -69.2158
trainer/Q Targets Mean            -19.9594
trainer/Q Targets Std              22.9322
trainer/Q Targets Max              -0.840825
trainer/Q Targets Min             -70.3559
trainer/Log Pis Mean                2.22462
trainer/Log Pis Std                 1.1077
trainer/Log Pis Max                 8.60571
trainer/Log Pis Min                -0.516173
trainer/Policy mu Mean             -0.0472494
trainer/Policy mu Std               0.58583
trainer/Policy mu Max               3.20605
trainer/Policy mu Min              -3.45873
trainer/Policy log std Mean        -2.20663
trainer/Policy log std Std          0.379189
trainer/Policy log std Max         -0.372097
trainer/Policy log std Min         -2.79658
trainer/Alpha                       0.0682091
trainer/Alpha Loss                  0.603124
exploration/num steps total    140700
exploration/num paths total      1407
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.470881
exploration/Rewards Std             0.953438
exploration/Rewards Max            -0.0108514
exploration/Rewards Min           -10.0675
exploration/Returns Mean          -47.0881
exploration/Returns Std            33.9496
exploration/Returns Max           -17.3993
exploration/Returns Min          -103.041
exploration/Actions Mean           -0.0114434
exploration/Actions Std             0.219231
exploration/Actions Max             0.982434
exploration/Actions Min            -0.999697
exploration/Num Paths               5
exploration/Average Returns       -47.0881
evaluation/num steps total     421500
evaluation/num paths total       4215
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.459088
evaluation/Rewards Std              1.0756
evaluation/Rewards Max             -0.0307821
evaluation/Rewards Min            -10.0171
evaluation/Returns Mean           -45.9088
evaluation/Returns Std             33.973
evaluation/Returns Max             -6.60806
evaluation/Returns Min           -118.167
evaluation/Actions Mean            -0.0164891
evaluation/Actions Std              0.197206
evaluation/Actions Max              0.996645
evaluation/Actions Min             -0.997378
evaluation/Num Paths               15
evaluation/Average Returns        -45.9088
time/data storing (s)               0.00273765
time/evaluation sampling (s)        0.335814
time/exploration sampling (s)       0.139201
time/logging (s)                    0.00481394
time/saving (s)                     0.00194026
time/training (s)                   1.92142
time/epoch (s)                      2.40592
time/total (s)                    687.119
Epoch                             280
-----------------------------  ---------------
2019-04-22 23:38:43.885048 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 281 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.09405
trainer/QF2 Loss                    0.100494
trainer/Policy Loss                19.1237
trainer/Q1 Predictions Mean       -17.2458
trainer/Q1 Predictions Std         20.5
trainer/Q1 Predictions Max         -6.83006
trainer/Q1 Predictions Min        -69.0952
trainer/Q2 Predictions Mean       -17.2719
trainer/Q2 Predictions Std         20.4686
trainer/Q2 Predictions Max         -6.82461
trainer/Q2 Predictions Min        -69.0968
trainer/Q Targets Mean            -17.4448
trainer/Q Targets Std              20.6201
trainer/Q Targets Max              -6.81313
trainer/Q Targets Min             -69.3619
trainer/Log Pis Mean                2.00013
trainer/Log Pis Std                 1.26367
trainer/Log Pis Max                 8.63546
trainer/Log Pis Min                -1.14323
trainer/Policy mu Mean             -0.0912828
trainer/Policy mu Std               0.576332
trainer/Policy mu Max               2.4543
trainer/Policy mu Min              -3.24682
trainer/Policy log std Mean        -2.20022
trainer/Policy log std Std          0.412046
trainer/Policy log std Max         -0.379191
trainer/Policy log std Min         -2.8491
trainer/Alpha                       0.0667712
trainer/Alpha Loss                  0.00035064
exploration/num steps total    141200
exploration/num paths total      1412
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.33956
exploration/Rewards Std             1.1295
exploration/Rewards Max            -0.00589543
exploration/Rewards Min           -10.5579
exploration/Returns Mean          -33.956
exploration/Returns Std            19.4937
exploration/Returns Max           -13.1402
exploration/Returns Min           -67.6641
exploration/Actions Mean            0.0171588
exploration/Actions Std             0.220785
exploration/Actions Max             0.999585
exploration/Actions Min            -0.997444
exploration/Num Paths               5
exploration/Average Returns       -33.956
evaluation/num steps total     423000
evaluation/num paths total       4230
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.323625
evaluation/Rewards Std              1.20727
evaluation/Rewards Max             -0.0085501
evaluation/Rewards Min             -9.61044
evaluation/Returns Mean           -32.3625
evaluation/Returns Std             14.5655
evaluation/Returns Max             -6.83788
evaluation/Returns Min            -53.6977
evaluation/Actions Mean             0.00749628
evaluation/Actions Std              0.209674
evaluation/Actions Max              0.998807
evaluation/Actions Min             -0.998206
evaluation/Num Paths               15
evaluation/Average Returns        -32.3625
time/data storing (s)               0.00273387
time/evaluation sampling (s)        0.328138
time/exploration sampling (s)       0.168482
time/logging (s)                    0.00394107
time/saving (s)                     0.0106065
time/training (s)                   1.92285
time/epoch (s)                      2.43675
time/total (s)                    689.56
Epoch                             281
-----------------------------  ---------------
2019-04-22 23:38:46.295307 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 282 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.74986
trainer/QF2 Loss                    1.68751
trainer/Policy Loss                24.0627
trainer/Q1 Predictions Mean       -22.0757
trainer/Q1 Predictions Std         24.8616
trainer/Q1 Predictions Max         -6.8516
trainer/Q1 Predictions Min        -91.4314
trainer/Q2 Predictions Mean       -22.1282
trainer/Q2 Predictions Std         24.8682
trainer/Q2 Predictions Max         -6.8024
trainer/Q2 Predictions Min        -92.8316
trainer/Q Targets Mean            -22.1004
trainer/Q Targets Std              25.1274
trainer/Q Targets Max              -0.0583435
trainer/Q Targets Min             -92.6731
trainer/Log Pis Mean                2.17453
trainer/Log Pis Std                 1.16201
trainer/Log Pis Max                 6.73033
trainer/Log Pis Min                -0.922148
trainer/Policy mu Mean             -0.0799312
trainer/Policy mu Std               0.613632
trainer/Policy mu Max               2.7613
trainer/Policy mu Min              -2.74095
trainer/Policy log std Mean        -2.17759
trainer/Policy log std Std          0.449648
trainer/Policy log std Max         -0.594782
trainer/Policy log std Min         -2.94083
trainer/Alpha                       0.0674093
trainer/Alpha Loss                  0.470709
exploration/num steps total    141700
exploration/num paths total      1417
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.563096
exploration/Rewards Std             1.09896
exploration/Rewards Max            -0.00863349
exploration/Rewards Min           -10.3289
exploration/Returns Mean          -56.3096
exploration/Returns Std            33.5815
exploration/Returns Max           -26.8109
exploration/Returns Min          -119.446
exploration/Actions Mean           -0.0104319
exploration/Actions Std             0.24069
exploration/Actions Max             0.995992
exploration/Actions Min            -0.998538
exploration/Num Paths               5
exploration/Average Returns       -56.3096
evaluation/num steps total     424500
evaluation/num paths total       4245
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.345795
evaluation/Rewards Std              0.792333
evaluation/Rewards Max             -0.0251021
evaluation/Rewards Min             -9.22885
evaluation/Returns Mean           -34.5795
evaluation/Returns Std             35.3896
evaluation/Returns Max             -7.4828
evaluation/Returns Min           -125.418
evaluation/Actions Mean            -0.00293008
evaluation/Actions Std              0.172799
evaluation/Actions Max              0.996486
evaluation/Actions Min             -0.997927
evaluation/Num Paths               15
evaluation/Average Returns        -34.5795
time/data storing (s)               0.0030917
time/evaluation sampling (s)        0.330699
time/exploration sampling (s)       0.140352
time/logging (s)                    0.00480895
time/saving (s)                     0.00194437
time/training (s)                   1.92154
time/epoch (s)                      2.40244
time/total (s)                    691.967
Epoch                             282
-----------------------------  ---------------
2019-04-22 23:38:48.705749 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 283 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                   43.8162
trainer/QF2 Loss                   43.4195
trainer/Policy Loss                21.0625
trainer/Q1 Predictions Mean       -19.2934
trainer/Q1 Predictions Std         22.045
trainer/Q1 Predictions Max         -6.78774
trainer/Q1 Predictions Min        -80.3775
trainer/Q2 Predictions Mean       -19.2636
trainer/Q2 Predictions Std         22.0616
trainer/Q2 Predictions Max         -6.88055
trainer/Q2 Predictions Min        -80.1928
trainer/Q Targets Mean            -18.5444
trainer/Q Targets Std              21.818
trainer/Q Targets Max              -0.223006
trainer/Q Targets Min             -78.7569
trainer/Log Pis Mean                1.93219
trainer/Log Pis Std                 1.61638
trainer/Log Pis Max                 8.50012
trainer/Log Pis Min                -2.70073
trainer/Policy mu Mean             -0.121797
trainer/Policy mu Std               0.759166
trainer/Policy mu Max               2.85766
trainer/Policy mu Min              -3.5868
trainer/Policy log std Mean        -2.06674
trainer/Policy log std Std          0.505288
trainer/Policy log std Max         -0.260196
trainer/Policy log std Min         -2.73081
trainer/Alpha                       0.0677873
trainer/Alpha Loss                 -0.182506
exploration/num steps total    142200
exploration/num paths total      1422
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.389434
exploration/Rewards Std             1.09187
exploration/Rewards Max            -0.000418639
exploration/Rewards Min            -9.37732
exploration/Returns Mean          -38.9434
exploration/Returns Std            12.4628
exploration/Returns Max           -24.532
exploration/Returns Min           -61.8939
exploration/Actions Mean           -0.0174062
exploration/Actions Std             0.249632
exploration/Actions Max             0.996064
exploration/Actions Min            -0.999498
exploration/Num Paths               5
exploration/Average Returns       -38.9434
evaluation/num steps total     426000
evaluation/num paths total       4260
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.320498
evaluation/Rewards Std              0.885282
evaluation/Rewards Max             -0.0165577
evaluation/Rewards Min             -9.38182
evaluation/Returns Mean           -32.0498
evaluation/Returns Std             33.7114
evaluation/Returns Max             -5.89702
evaluation/Returns Min           -125.967
evaluation/Actions Mean             0.00911963
evaluation/Actions Std              0.172779
evaluation/Actions Max              0.997545
evaluation/Actions Min             -0.997558
evaluation/Num Paths               15
evaluation/Average Returns        -32.0498
time/data storing (s)               0.00261252
time/evaluation sampling (s)        0.327228
time/exploration sampling (s)       0.139803
time/logging (s)                    0.00485314
time/saving (s)                     0.00156171
time/training (s)                   1.92555
time/epoch (s)                      2.40161
time/total (s)                    694.373
Epoch                             283
-----------------------------  ----------------
2019-04-22 23:38:51.129261 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 284 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   42.4087
trainer/QF2 Loss                   42.6287
trainer/Policy Loss                22.6041
trainer/Q1 Predictions Mean       -20.9666
trainer/Q1 Predictions Std         23.8053
trainer/Q1 Predictions Max         -6.98459
trainer/Q1 Predictions Min        -76.4181
trainer/Q2 Predictions Mean       -20.981
trainer/Q2 Predictions Std         23.8253
trainer/Q2 Predictions Max         -7.0612
trainer/Q2 Predictions Min        -76.835
trainer/Q Targets Mean            -20.1678
trainer/Q Targets Std              23.8218
trainer/Q Targets Max              -0.172909
trainer/Q Targets Min             -76.6738
trainer/Log Pis Mean                1.86018
trainer/Log Pis Std                 1.3669
trainer/Log Pis Max                 8.87701
trainer/Log Pis Min                -1.90848
trainer/Policy mu Mean             -0.161758
trainer/Policy mu Std               0.491592
trainer/Policy mu Max               0.749098
trainer/Policy mu Min              -2.98978
trainer/Policy log std Mean        -2.14452
trainer/Policy log std Std          0.386676
trainer/Policy log std Max         -0.452629
trainer/Policy log std Min         -2.81753
trainer/Alpha                       0.0676636
trainer/Alpha Loss                 -0.376553
exploration/num steps total    142700
exploration/num paths total      1427
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.386143
exploration/Rewards Std             1.06285
exploration/Rewards Max            -0.00500723
exploration/Rewards Min            -8.13461
exploration/Returns Mean          -38.6143
exploration/Returns Std             5.43035
exploration/Returns Max           -28.2124
exploration/Returns Min           -43.4903
exploration/Actions Mean            0.0236672
exploration/Actions Std             0.248055
exploration/Actions Max             0.998268
exploration/Actions Min            -0.999525
exploration/Num Paths               5
exploration/Average Returns       -38.6143
evaluation/num steps total     427500
evaluation/num paths total       4275
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.251873
evaluation/Rewards Std              0.805795
evaluation/Rewards Max             -0.0140358
evaluation/Rewards Min             -9.09453
evaluation/Returns Mean           -25.1873
evaluation/Returns Std             19.5129
evaluation/Returns Max             -5.58026
evaluation/Returns Min            -89.1249
evaluation/Actions Mean             0.00222614
evaluation/Actions Std              0.17886
evaluation/Actions Max              0.99739
evaluation/Actions Min             -0.996216
evaluation/Num Paths               15
evaluation/Average Returns        -25.1873
time/data storing (s)               0.00273548
time/evaluation sampling (s)        0.332837
time/exploration sampling (s)       0.139302
time/logging (s)                    0.004828
time/saving (s)                     0.00157929
time/training (s)                   1.93327
time/epoch (s)                      2.41456
time/total (s)                    696.792
Epoch                             284
-----------------------------  ---------------
2019-04-22 23:38:53.560177 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 285 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.676212
trainer/QF2 Loss                    0.723408
trainer/Policy Loss                23.165
trainer/Q1 Predictions Mean       -21.3855
trainer/Q1 Predictions Std         23.1669
trainer/Q1 Predictions Max         -6.91858
trainer/Q1 Predictions Min        -65.4945
trainer/Q2 Predictions Mean       -21.3713
trainer/Q2 Predictions Std         23.1561
trainer/Q2 Predictions Max         -6.90653
trainer/Q2 Predictions Min        -65.4463
trainer/Q Targets Mean            -21.3619
trainer/Q Targets Std              23.2245
trainer/Q Targets Max              -0.134008
trainer/Q Targets Min             -65.4906
trainer/Log Pis Mean                2.02912
trainer/Log Pis Std                 1.26047
trainer/Log Pis Max                 8.36474
trainer/Log Pis Min                -1.92327
trainer/Policy mu Mean             -0.0350378
trainer/Policy mu Std               0.675874
trainer/Policy mu Max               3.46756
trainer/Policy mu Min              -3.2549
trainer/Policy log std Mean        -2.18233
trainer/Policy log std Std          0.439322
trainer/Policy log std Max         -0.363351
trainer/Policy log std Min         -2.83914
trainer/Alpha                       0.0674159
trainer/Alpha Loss                  0.0785416
exploration/num steps total    143200
exploration/num paths total      1432
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.334891
exploration/Rewards Std             1.11419
exploration/Rewards Max            -0.0107961
exploration/Rewards Min           -11.515
exploration/Returns Mean          -33.4891
exploration/Returns Std            19.9413
exploration/Returns Max           -14.3568
exploration/Returns Min           -63.1939
exploration/Actions Mean            0.0345484
exploration/Actions Std             0.215872
exploration/Actions Max             0.999653
exploration/Actions Min            -0.572271
exploration/Num Paths               5
exploration/Average Returns       -33.4891
evaluation/num steps total     429000
evaluation/num paths total       4290
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.404176
evaluation/Rewards Std              1.08104
evaluation/Rewards Max             -0.0211003
evaluation/Rewards Min            -10.837
evaluation/Returns Mean           -40.4176
evaluation/Returns Std             24.9106
evaluation/Returns Max            -13.0278
evaluation/Returns Min            -99.6841
evaluation/Actions Mean             0.0198323
evaluation/Actions Std              0.202168
evaluation/Actions Max              0.999522
evaluation/Actions Min             -0.99717
evaluation/Num Paths               15
evaluation/Average Returns        -40.4176
time/data storing (s)               0.00288989
time/evaluation sampling (s)        0.327854
time/exploration sampling (s)       0.139867
time/logging (s)                    0.00481635
time/saving (s)                     0.0019599
time/training (s)                   1.94462
time/epoch (s)                      2.42201
time/total (s)                    699.218
Epoch                             285
-----------------------------  ---------------
2019-04-22 23:38:56.010728 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 286 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.177409
trainer/QF2 Loss                    0.178428
trainer/Policy Loss                21.3797
trainer/Q1 Predictions Mean       -19.6579
trainer/Q1 Predictions Std         21.9637
trainer/Q1 Predictions Max         -6.76149
trainer/Q1 Predictions Min        -63.9244
trainer/Q2 Predictions Mean       -19.6298
trainer/Q2 Predictions Std         21.9921
trainer/Q2 Predictions Max         -6.80203
trainer/Q2 Predictions Min        -64.1027
trainer/Q Targets Mean            -19.8546
trainer/Q Targets Std              22.2754
trainer/Q Targets Max              -6.82324
trainer/Q Targets Min             -65.1404
trainer/Log Pis Mean                1.94838
trainer/Log Pis Std                 1.16117
trainer/Log Pis Max                 6.41094
trainer/Log Pis Min                -3.07871
trainer/Policy mu Mean             -0.02695
trainer/Policy mu Std               0.491396
trainer/Policy mu Max               3.15671
trainer/Policy mu Min              -1.54897
trainer/Policy log std Mean        -2.20749
trainer/Policy log std Std          0.355455
trainer/Policy log std Max         -0.55477
trainer/Policy log std Min         -2.72813
trainer/Alpha                       0.0679892
trainer/Alpha Loss                 -0.138771
exploration/num steps total    143700
exploration/num paths total      1437
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.465862
exploration/Rewards Std             0.895916
exploration/Rewards Max            -0.00679841
exploration/Rewards Min            -7.32295
exploration/Returns Mean          -46.5862
exploration/Returns Std            24.3039
exploration/Returns Max           -19.8145
exploration/Returns Min           -92.4585
exploration/Actions Mean           -0.0122249
exploration/Actions Std             0.229375
exploration/Actions Max             0.996342
exploration/Actions Min            -0.997858
exploration/Num Paths               5
exploration/Average Returns       -46.5862
evaluation/num steps total     430500
evaluation/num paths total       4305
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.288381
evaluation/Rewards Std              0.831414
evaluation/Rewards Max             -0.0468757
evaluation/Rewards Min             -9.03176
evaluation/Returns Mean           -28.8381
evaluation/Returns Std             25.6926
evaluation/Returns Max             -6.36739
evaluation/Returns Min           -109.216
evaluation/Actions Mean            -6.03714e-05
evaluation/Actions Std              0.16865
evaluation/Actions Max              0.999223
evaluation/Actions Min             -0.995585
evaluation/Num Paths               15
evaluation/Average Returns        -28.8381
time/data storing (s)               0.00271185
time/evaluation sampling (s)        0.330669
time/exploration sampling (s)       0.141718
time/logging (s)                    0.00353989
time/saving (s)                     0.00194303
time/training (s)                   1.95949
time/epoch (s)                      2.44007
time/total (s)                    701.663
Epoch                             286
-----------------------------  ----------------
2019-04-22 23:38:58.440025 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 287 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    2.04478
trainer/QF2 Loss                    2.05444
trainer/Policy Loss                20.0602
trainer/Q1 Predictions Mean       -18.3881
trainer/Q1 Predictions Std         21.7387
trainer/Q1 Predictions Max         -6.79636
trainer/Q1 Predictions Min        -89.4975
trainer/Q2 Predictions Mean       -18.3432
trainer/Q2 Predictions Std         21.747
trainer/Q2 Predictions Max         -6.78277
trainer/Q2 Predictions Min        -89.5149
trainer/Q Targets Mean            -18.3738
trainer/Q Targets Std              22.0185
trainer/Q Targets Max              -0.318759
trainer/Q Targets Min             -88.7512
trainer/Log Pis Mean                1.90183
trainer/Log Pis Std                 1.00943
trainer/Log Pis Max                 5.16648
trainer/Log Pis Min                -1.54255
trainer/Policy mu Mean             -0.112642
trainer/Policy mu Std               0.47834
trainer/Policy mu Max               2.39393
trainer/Policy mu Min              -2.95767
trainer/Policy log std Mean        -2.23383
trainer/Policy log std Std          0.357818
trainer/Policy log std Max         -0.255137
trainer/Policy log std Min         -2.74199
trainer/Alpha                       0.0663464
trainer/Alpha Loss                 -0.266324
exploration/num steps total    144200
exploration/num paths total      1442
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.414405
exploration/Rewards Std             0.808413
exploration/Rewards Max            -0.00820648
exploration/Rewards Min            -8.04866
exploration/Returns Mean          -41.4405
exploration/Returns Std            32.9221
exploration/Returns Max           -15.3626
exploration/Returns Min          -104.305
exploration/Actions Mean            0.00290688
exploration/Actions Std             0.209867
exploration/Actions Max             0.999943
exploration/Actions Min            -0.999705
exploration/Num Paths               5
exploration/Average Returns       -41.4405
evaluation/num steps total     432000
evaluation/num paths total       4320
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.346066
evaluation/Rewards Std              0.908968
evaluation/Rewards Max             -0.0319858
evaluation/Rewards Min             -9.28484
evaluation/Returns Mean           -34.6066
evaluation/Returns Std             29.9187
evaluation/Returns Max             -7.22595
evaluation/Returns Min           -108.99
evaluation/Actions Mean             0.0125695
evaluation/Actions Std              0.185176
evaluation/Actions Max              0.999714
evaluation/Actions Min             -0.995191
evaluation/Num Paths               15
evaluation/Average Returns        -34.6066
time/data storing (s)               0.00286159
time/evaluation sampling (s)        0.33223
time/exploration sampling (s)       0.144193
time/logging (s)                    0.0048596
time/saving (s)                     0.00192026
time/training (s)                   1.93534
time/epoch (s)                      2.42141
time/total (s)                    704.089
Epoch                             287
-----------------------------  ---------------
2019-04-22 23:39:00.867988 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 288 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0934606
trainer/QF2 Loss                    0.0834988
trainer/Policy Loss                16.6172
trainer/Q1 Predictions Mean       -14.9408
trainer/Q1 Predictions Std         17.6741
trainer/Q1 Predictions Max         -6.83904
trainer/Q1 Predictions Min        -66.4275
trainer/Q2 Predictions Mean       -14.955
trainer/Q2 Predictions Std         17.6887
trainer/Q2 Predictions Max         -6.86479
trainer/Q2 Predictions Min        -66.7495
trainer/Q Targets Mean            -15.0961
trainer/Q Targets Std              17.8557
trainer/Q Targets Max              -6.84266
trainer/Q Targets Min             -66.5546
trainer/Log Pis Mean                1.75641
trainer/Log Pis Std                 1.34179
trainer/Log Pis Max                 6.82827
trainer/Log Pis Min                -4.39101
trainer/Policy mu Mean             -0.0795715
trainer/Policy mu Std               0.40272
trainer/Policy mu Max               3.12312
trainer/Policy mu Min              -2.61236
trainer/Policy log std Mean        -2.28288
trainer/Policy log std Std          0.286736
trainer/Policy log std Max         -0.597529
trainer/Policy log std Min         -2.90035
trainer/Alpha                       0.0661254
trainer/Alpha Loss                 -0.661651
exploration/num steps total    144700
exploration/num paths total      1447
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.2592
exploration/Rewards Std             0.686777
exploration/Rewards Max            -0.00423377
exploration/Rewards Min            -6.74414
exploration/Returns Mean          -25.92
exploration/Returns Std             7.68769
exploration/Returns Max           -16.8564
exploration/Returns Min           -36.4917
exploration/Actions Mean            0.0120345
exploration/Actions Std             0.208148
exploration/Actions Max             0.997368
exploration/Actions Min            -0.999353
exploration/Num Paths               5
exploration/Average Returns       -25.92
evaluation/num steps total     433500
evaluation/num paths total       4335
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.364398
evaluation/Rewards Std              0.966479
evaluation/Rewards Max             -0.023015
evaluation/Rewards Min            -10.0771
evaluation/Returns Mean           -36.4398
evaluation/Returns Std             25.8012
evaluation/Returns Max             -5.14434
evaluation/Returns Min            -91.1821
evaluation/Actions Mean            -0.0198949
evaluation/Actions Std              0.189304
evaluation/Actions Max              0.999539
evaluation/Actions Min             -0.998947
evaluation/Num Paths               15
evaluation/Average Returns        -36.4398
time/data storing (s)               0.0028024
time/evaluation sampling (s)        0.32766
time/exploration sampling (s)       0.138396
time/logging (s)                    0.00351204
time/saving (s)                     0.00196264
time/training (s)                   1.94394
time/epoch (s)                      2.41827
time/total (s)                    706.512
Epoch                             288
-----------------------------  ---------------
2019-04-22 23:39:03.287140 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 289 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.59117
trainer/QF2 Loss                    0.571017
trainer/Policy Loss                19.588
trainer/Q1 Predictions Mean       -17.7808
trainer/Q1 Predictions Std         20.6625
trainer/Q1 Predictions Max         -6.88259
trainer/Q1 Predictions Min        -64.8276
trainer/Q2 Predictions Mean       -17.827
trainer/Q2 Predictions Std         20.6583
trainer/Q2 Predictions Max         -6.87229
trainer/Q2 Predictions Min        -65.0318
trainer/Q Targets Mean            -17.8844
trainer/Q Targets Std              20.9329
trainer/Q Targets Max              -0.201669
trainer/Q Targets Min             -65.8212
trainer/Log Pis Mean                1.9043
trainer/Log Pis Std                 1.02477
trainer/Log Pis Max                 4.40092
trainer/Log Pis Min                -2.12391
trainer/Policy mu Mean             -0.0118343
trainer/Policy mu Std               0.447007
trainer/Policy mu Max               2.6232
trainer/Policy mu Min              -2.89789
trainer/Policy log std Mean        -2.23273
trainer/Policy log std Std          0.328849
trainer/Policy log std Max         -0.4034
trainer/Policy log std Min         -2.77879
trainer/Alpha                       0.0680137
trainer/Alpha Loss                 -0.257236
exploration/num steps total    145200
exploration/num paths total      1452
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.400324
exploration/Rewards Std             1.13489
exploration/Rewards Max            -0.0103222
exploration/Rewards Min            -9.60393
exploration/Returns Mean          -40.0324
exploration/Returns Std            17.3954
exploration/Returns Max           -20.9631
exploration/Returns Min           -61.1449
exploration/Actions Mean           -0.00599987
exploration/Actions Std             0.248731
exploration/Actions Max             0.998315
exploration/Actions Min            -0.998423
exploration/Num Paths               5
exploration/Average Returns       -40.0324
evaluation/num steps total     435000
evaluation/num paths total       4350
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.636891
evaluation/Rewards Std              1.18842
evaluation/Rewards Max             -0.016997
evaluation/Rewards Min            -12.0538
evaluation/Returns Mean           -63.6891
evaluation/Returns Std             51.9338
evaluation/Returns Max             -7.2864
evaluation/Returns Min           -152.125
evaluation/Actions Mean            -0.0141302
evaluation/Actions Std              0.202831
evaluation/Actions Max              0.996314
evaluation/Actions Min             -0.99823
evaluation/Num Paths               15
evaluation/Average Returns        -63.6891
time/data storing (s)               0.00272554
time/evaluation sampling (s)        0.327641
time/exploration sampling (s)       0.141996
time/logging (s)                    0.00352743
time/saving (s)                     0.00199276
time/training (s)                   1.93262
time/epoch (s)                      2.41051
time/total (s)                    708.927
Epoch                             289
-----------------------------  ---------------
2019-04-22 23:39:05.719435 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 290 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.23002
trainer/QF2 Loss                    1.24039
trainer/Policy Loss                17.8415
trainer/Q1 Predictions Mean       -16.0075
trainer/Q1 Predictions Std         18.9233
trainer/Q1 Predictions Max         -6.78319
trainer/Q1 Predictions Min        -93.6199
trainer/Q2 Predictions Mean       -15.9984
trainer/Q2 Predictions Std         18.9421
trainer/Q2 Predictions Max         -6.79293
trainer/Q2 Predictions Min        -93.6641
trainer/Q Targets Mean            -16.0839
trainer/Q Targets Std              19.3063
trainer/Q Targets Max              -0.0503091
trainer/Q Targets Min             -93.3684
trainer/Log Pis Mean                1.95964
trainer/Log Pis Std                 1.52145
trainer/Log Pis Max                 8.21355
trainer/Log Pis Min                -3.33587
trainer/Policy mu Mean             -0.0544316
trainer/Policy mu Std               0.638644
trainer/Policy mu Max               2.95466
trainer/Policy mu Min              -3.09173
trainer/Policy log std Mean        -2.17297
trainer/Policy log std Std          0.441488
trainer/Policy log std Max         -0.219844
trainer/Policy log std Min         -2.90102
trainer/Alpha                       0.069273
trainer/Alpha Loss                 -0.107748
exploration/num steps total    145700
exploration/num paths total      1457
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.272327
exploration/Rewards Std             0.731961
exploration/Rewards Max            -0.00773703
exploration/Rewards Min            -6.54679
exploration/Returns Mean          -27.2327
exploration/Returns Std             5.98398
exploration/Returns Max           -20.2985
exploration/Returns Min           -34.2344
exploration/Actions Mean            0.0210585
exploration/Actions Std             0.224291
exploration/Actions Max             0.998699
exploration/Actions Min            -0.999504
exploration/Num Paths               5
exploration/Average Returns       -27.2327
evaluation/num steps total     436500
evaluation/num paths total       4365
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.325881
evaluation/Rewards Std              0.95383
evaluation/Rewards Max             -0.00935371
evaluation/Rewards Min            -10.1376
evaluation/Returns Mean           -32.5881
evaluation/Returns Std             27.3834
evaluation/Returns Max             -4.77013
evaluation/Returns Min            -91.5833
evaluation/Actions Mean             0.00587461
evaluation/Actions Std              0.17889
evaluation/Actions Max              0.99966
evaluation/Actions Min             -0.99766
evaluation/Num Paths               15
evaluation/Average Returns        -32.5881
time/data storing (s)               0.00261864
time/evaluation sampling (s)        0.326184
time/exploration sampling (s)       0.140461
time/logging (s)                    0.00415361
time/saving (s)                     0.00193605
time/training (s)                   1.94909
time/epoch (s)                      2.42444
time/total (s)                    711.356
Epoch                             290
-----------------------------  ---------------
2019-04-22 23:39:08.155550 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 291 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.80218
trainer/QF2 Loss                    1.8127
trainer/Policy Loss                18.2849
trainer/Q1 Predictions Mean       -16.5198
trainer/Q1 Predictions Std         19.2195
trainer/Q1 Predictions Max         -6.85339
trainer/Q1 Predictions Min        -61.4388
trainer/Q2 Predictions Mean       -16.5082
trainer/Q2 Predictions Std         19.1889
trainer/Q2 Predictions Max         -6.9198
trainer/Q2 Predictions Min        -61.5464
trainer/Q Targets Mean            -16.4459
trainer/Q Targets Std              19.4788
trainer/Q Targets Max              -0.112135
trainer/Q Targets Min             -62.2541
trainer/Log Pis Mean                1.91926
trainer/Log Pis Std                 0.921389
trainer/Log Pis Max                 3.09847
trainer/Log Pis Min                -2.88961
trainer/Policy mu Mean             -0.0346008
trainer/Policy mu Std               0.328804
trainer/Policy mu Max               2.20293
trainer/Policy mu Min              -2.17783
trainer/Policy log std Mean        -2.25171
trainer/Policy log std Std          0.260667
trainer/Policy log std Max         -0.727829
trainer/Policy log std Min         -2.72299
trainer/Alpha                       0.0672813
trainer/Alpha Loss                 -0.217899
exploration/num steps total    146200
exploration/num paths total      1462
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.221675
exploration/Rewards Std             0.650685
exploration/Rewards Max            -0.00207568
exploration/Rewards Min            -7.91687
exploration/Returns Mean          -22.1675
exploration/Returns Std            11.0033
exploration/Returns Max           -14.4673
exploration/Returns Min           -43.9124
exploration/Actions Mean           -0.0031177
exploration/Actions Std             0.191806
exploration/Actions Max             0.997648
exploration/Actions Min            -0.998617
exploration/Num Paths               5
exploration/Average Returns       -22.1675
evaluation/num steps total     438000
evaluation/num paths total       4380
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.370055
evaluation/Rewards Std              0.946064
evaluation/Rewards Max             -0.00935633
evaluation/Rewards Min            -10.3231
evaluation/Returns Mean           -37.0055
evaluation/Returns Std             35.4346
evaluation/Returns Max             -6.33101
evaluation/Returns Min           -135.156
evaluation/Actions Mean            -0.0039438
evaluation/Actions Std              0.190193
evaluation/Actions Max              0.999019
evaluation/Actions Min             -0.997159
evaluation/Num Paths               15
evaluation/Average Returns        -37.0055
time/data storing (s)               0.00288202
time/evaluation sampling (s)        0.332435
time/exploration sampling (s)       0.139423
time/logging (s)                    0.00478647
time/saving (s)                     0.00194437
time/training (s)                   1.94689
time/epoch (s)                      2.42836
time/total (s)                    713.788
Epoch                             291
-----------------------------  ---------------
2019-04-22 23:39:10.575269 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 292 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.993751
trainer/QF2 Loss                    0.967048
trainer/Policy Loss                19.101
trainer/Q1 Predictions Mean       -17.4033
trainer/Q1 Predictions Std         19.7128
trainer/Q1 Predictions Max         -6.96083
trainer/Q1 Predictions Min        -61.2021
trainer/Q2 Predictions Mean       -17.4119
trainer/Q2 Predictions Std         19.7138
trainer/Q2 Predictions Max         -6.97609
trainer/Q2 Predictions Min        -61.1787
trainer/Q Targets Mean            -17.3913
trainer/Q Targets Std              19.9519
trainer/Q Targets Max              -0.277008
trainer/Q Targets Min             -61.9874
trainer/Log Pis Mean                1.9316
trainer/Log Pis Std                 1.17519
trainer/Log Pis Max                 4.83365
trainer/Log Pis Min                -2.42888
trainer/Policy mu Mean             -0.0778416
trainer/Policy mu Std               0.465661
trainer/Policy mu Max               3.2737
trainer/Policy mu Min              -1.55242
trainer/Policy log std Mean        -2.24322
trainer/Policy log std Std          0.328754
trainer/Policy log std Max         -0.333795
trainer/Policy log std Min         -2.89287
trainer/Alpha                       0.0670412
trainer/Alpha Loss                 -0.184846
exploration/num steps total    146700
exploration/num paths total      1467
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.535658
exploration/Rewards Std             1.3607
exploration/Rewards Max            -0.0103163
exploration/Rewards Min           -11.8326
exploration/Returns Mean          -53.5658
exploration/Returns Std            24.8683
exploration/Returns Max           -21.4537
exploration/Returns Min           -83.1789
exploration/Actions Mean            0.0284889
exploration/Actions Std             0.239161
exploration/Actions Max             0.999632
exploration/Actions Min            -0.997169
exploration/Num Paths               5
exploration/Average Returns       -53.5658
evaluation/num steps total     439500
evaluation/num paths total       4395
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.400053
evaluation/Rewards Std              1.1169
evaluation/Rewards Max             -0.0350509
evaluation/Rewards Min            -10.623
evaluation/Returns Mean           -40.0053
evaluation/Returns Std             28.8687
evaluation/Returns Max             -7.33883
evaluation/Returns Min           -120.715
evaluation/Actions Mean             0.0117855
evaluation/Actions Std              0.202396
evaluation/Actions Max              0.999359
evaluation/Actions Min             -0.997494
evaluation/Num Paths               15
evaluation/Average Returns        -40.0053
time/data storing (s)               0.00278976
time/evaluation sampling (s)        0.327698
time/exploration sampling (s)       0.140469
time/logging (s)                    0.00479282
time/saving (s)                     0.00194043
time/training (s)                   1.93307
time/epoch (s)                      2.41076
time/total (s)                    716.203
Epoch                             292
-----------------------------  ---------------
2019-04-22 23:39:12.981206 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 293 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.168911
trainer/QF2 Loss                    0.192922
trainer/Policy Loss                20.8661
trainer/Q1 Predictions Mean       -18.9753
trainer/Q1 Predictions Std         20.8962
trainer/Q1 Predictions Max         -6.90282
trainer/Q1 Predictions Min        -76.011
trainer/Q2 Predictions Mean       -18.9378
trainer/Q2 Predictions Std         20.8927
trainer/Q2 Predictions Max         -6.91363
trainer/Q2 Predictions Min        -75.1524
trainer/Q Targets Mean            -19.1917
trainer/Q Targets Std              21.1457
trainer/Q Targets Max              -6.97705
trainer/Q Targets Min             -75.6507
trainer/Log Pis Mean                2.0326
trainer/Log Pis Std                 1.13715
trainer/Log Pis Max                 5.87732
trainer/Log Pis Min                -0.939564
trainer/Policy mu Mean             -0.056922
trainer/Policy mu Std               0.550283
trainer/Policy mu Max               2.93593
trainer/Policy mu Min              -2.87889
trainer/Policy log std Mean        -2.19127
trainer/Policy log std Std          0.401626
trainer/Policy log std Max         -0.642749
trainer/Policy log std Min         -2.92296
trainer/Alpha                       0.0670507
trainer/Alpha Loss                  0.0881044
exploration/num steps total    147200
exploration/num paths total      1472
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.666448
exploration/Rewards Std             1.54104
exploration/Rewards Max            -0.00708539
exploration/Rewards Min           -11.3014
exploration/Returns Mean          -66.6448
exploration/Returns Std            41.3014
exploration/Returns Max           -29.3329
exploration/Returns Min          -146.155
exploration/Actions Mean            0.00579568
exploration/Actions Std             0.281674
exploration/Actions Max             0.999587
exploration/Actions Min            -0.99997
exploration/Num Paths               5
exploration/Average Returns       -66.6448
evaluation/num steps total     441000
evaluation/num paths total       4410
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.395333
evaluation/Rewards Std              0.899972
evaluation/Rewards Max             -0.0125933
evaluation/Rewards Min             -8.285
evaluation/Returns Mean           -39.5333
evaluation/Returns Std             40.3528
evaluation/Returns Max             -7.8381
evaluation/Returns Min           -131.042
evaluation/Actions Mean             0.00184538
evaluation/Actions Std              0.181093
evaluation/Actions Max              0.997655
evaluation/Actions Min             -0.997066
evaluation/Num Paths               15
evaluation/Average Returns        -39.5333
time/data storing (s)               0.00272315
time/evaluation sampling (s)        0.325767
time/exploration sampling (s)       0.140987
time/logging (s)                    0.00486901
time/saving (s)                     0.00977277
time/training (s)                   1.91295
time/epoch (s)                      2.39707
time/total (s)                    718.605
Epoch                             293
-----------------------------  ---------------
2019-04-22 23:39:15.411026 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 294 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.184581
trainer/QF2 Loss                    0.172194
trainer/Policy Loss                18.39
trainer/Q1 Predictions Mean       -16.295
trainer/Q1 Predictions Std         18.3362
trainer/Q1 Predictions Max         -6.6726
trainer/Q1 Predictions Min        -65.3209
trainer/Q2 Predictions Mean       -16.338
trainer/Q2 Predictions Std         18.3681
trainer/Q2 Predictions Max         -6.63496
trainer/Q2 Predictions Min        -66.3921
trainer/Q Targets Mean            -16.4642
trainer/Q Targets Std              18.5954
trainer/Q Targets Max              -6.90448
trainer/Q Targets Min             -65.8566
trainer/Log Pis Mean                2.21789
trainer/Log Pis Std                 0.993939
trainer/Log Pis Max                 5.91927
trainer/Log Pis Min                -0.574916
trainer/Policy mu Mean             -0.00893566
trainer/Policy mu Std               0.572395
trainer/Policy mu Max               3.04761
trainer/Policy mu Min              -2.77657
trainer/Policy log std Mean        -2.19714
trainer/Policy log std Std          0.38266
trainer/Policy log std Max         -0.460328
trainer/Policy log std Min         -2.89393
trainer/Alpha                       0.0673225
trainer/Alpha Loss                  0.587909
exploration/num steps total    147700
exploration/num paths total      1477
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.586215
exploration/Rewards Std             1.20712
exploration/Rewards Max            -0.0132103
exploration/Rewards Min            -9.33037
exploration/Returns Mean          -58.6215
exploration/Returns Std            27.2225
exploration/Returns Max           -31.5312
exploration/Returns Min          -109.714
exploration/Actions Mean            0.00872494
exploration/Actions Std             0.255752
exploration/Actions Max             0.999923
exploration/Actions Min            -0.999037
exploration/Num Paths               5
exploration/Average Returns       -58.6215
evaluation/num steps total     442500
evaluation/num paths total       4425
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.344588
evaluation/Rewards Std              0.915715
evaluation/Rewards Max             -0.00485276
evaluation/Rewards Min             -8.90447
evaluation/Returns Mean           -34.4588
evaluation/Returns Std             29.9177
evaluation/Returns Max             -5.16796
evaluation/Returns Min           -104.203
evaluation/Actions Mean            -0.0124927
evaluation/Actions Std              0.179107
evaluation/Actions Max              0.995523
evaluation/Actions Min             -0.998263
evaluation/Num Paths               15
evaluation/Average Returns        -34.4588
time/data storing (s)               0.00268605
time/evaluation sampling (s)        0.323192
time/exploration sampling (s)       0.138658
time/logging (s)                    0.00475039
time/saving (s)                     0.00195178
time/training (s)                   1.95016
time/epoch (s)                      2.4214
time/total (s)                    721.03
Epoch                             294
-----------------------------  ---------------
2019-04-22 23:39:17.825359 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 295 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.61194
trainer/QF2 Loss                    1.61763
trainer/Policy Loss                17.4696
trainer/Q1 Predictions Mean       -15.4033
trainer/Q1 Predictions Std         18.3924
trainer/Q1 Predictions Max         -6.83201
trainer/Q1 Predictions Min        -76.821
trainer/Q2 Predictions Mean       -15.4362
trainer/Q2 Predictions Std         18.4129
trainer/Q2 Predictions Max         -6.83342
trainer/Q2 Predictions Min        -77.5608
trainer/Q Targets Mean            -15.3502
trainer/Q Targets Std              18.4205
trainer/Q Targets Max              -0.144307
trainer/Q Targets Min             -76.6462
trainer/Log Pis Mean                2.15298
trainer/Log Pis Std                 1.4526
trainer/Log Pis Max                 9.3355
trainer/Log Pis Min                -2.90975
trainer/Policy mu Mean             -0.147092
trainer/Policy mu Std               0.649004
trainer/Policy mu Max               3.10233
trainer/Policy mu Min              -3.38354
trainer/Policy log std Mean        -2.22046
trainer/Policy log std Std          0.420364
trainer/Policy log std Max         -0.40852
trainer/Policy log std Min         -2.83234
trainer/Alpha                       0.0662971
trainer/Alpha Loss                  0.415119
exploration/num steps total    148200
exploration/num paths total      1482
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.240481
exploration/Rewards Std             0.586713
exploration/Rewards Max            -0.00620221
exploration/Rewards Min            -5.77874
exploration/Returns Mean          -24.0481
exploration/Returns Std             5.0273
exploration/Returns Max           -18.2612
exploration/Returns Min           -31.8336
exploration/Actions Mean           -0.00790386
exploration/Actions Std             0.214599
exploration/Actions Max             0.997802
exploration/Actions Min            -0.997636
exploration/Num Paths               5
exploration/Average Returns       -24.0481
evaluation/num steps total     444000
evaluation/num paths total       4440
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.463213
evaluation/Rewards Std              1.06414
evaluation/Rewards Max             -0.00510906
evaluation/Rewards Min            -10.9085
evaluation/Returns Mean           -46.3213
evaluation/Returns Std             37.7142
evaluation/Returns Max             -1.37776
evaluation/Returns Min           -103.234
evaluation/Actions Mean             0.00403789
evaluation/Actions Std              0.179738
evaluation/Actions Max              0.998089
evaluation/Actions Min             -0.996839
evaluation/Num Paths               15
evaluation/Average Returns        -46.3213
time/data storing (s)               0.00274219
time/evaluation sampling (s)        0.325097
time/exploration sampling (s)       0.140959
time/logging (s)                    0.00379464
time/saving (s)                     0.00194308
time/training (s)                   1.92978
time/epoch (s)                      2.40432
time/total (s)                    723.439
Epoch                             295
-----------------------------  ---------------
2019-04-22 23:39:20.213886 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 296 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.707735
trainer/QF2 Loss                    0.68364
trainer/Policy Loss                18.2614
trainer/Q1 Predictions Mean       -16.3478
trainer/Q1 Predictions Std         19.4448
trainer/Q1 Predictions Max         -6.85423
trainer/Q1 Predictions Min       -110.087
trainer/Q2 Predictions Mean       -16.3016
trainer/Q2 Predictions Std         19.4822
trainer/Q2 Predictions Max         -6.79625
trainer/Q2 Predictions Min       -110.63
trainer/Q Targets Mean            -16.3599
trainer/Q Targets Std              19.6466
trainer/Q Targets Max              -0.472896
trainer/Q Targets Min            -110.678
trainer/Log Pis Mean                2.10891
trainer/Log Pis Std                 1.35919
trainer/Log Pis Max                 9.16994
trainer/Log Pis Min                -1.27444
trainer/Policy mu Mean             -0.0621372
trainer/Policy mu Std               0.686008
trainer/Policy mu Max               2.9887
trainer/Policy mu Min              -3.99958
trainer/Policy log std Mean        -2.20828
trainer/Policy log std Std          0.436231
trainer/Policy log std Max         -0.184168
trainer/Policy log std Min         -2.76183
trainer/Alpha                       0.0663887
trainer/Alpha Loss                  0.295406
exploration/num steps total    148700
exploration/num paths total      1487
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.254403
exploration/Rewards Std             0.716212
exploration/Rewards Max            -0.00697546
exploration/Rewards Min            -6.94029
exploration/Returns Mean          -25.4403
exploration/Returns Std             9.54117
exploration/Returns Max           -14.7678
exploration/Returns Min           -39.1071
exploration/Actions Mean            0.0159121
exploration/Actions Std             0.206457
exploration/Actions Max             0.999544
exploration/Actions Min            -0.993885
exploration/Num Paths               5
exploration/Average Returns       -25.4403
evaluation/num steps total     445500
evaluation/num paths total       4455
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.30132
evaluation/Rewards Std              0.816476
evaluation/Rewards Max             -0.0121573
evaluation/Rewards Min             -8.90948
evaluation/Returns Mean           -30.132
evaluation/Returns Std             32.0155
evaluation/Returns Max             -3.92796
evaluation/Returns Min           -108.49
evaluation/Actions Mean            -0.0075784
evaluation/Actions Std              0.176084
evaluation/Actions Max              0.998981
evaluation/Actions Min             -0.996603
evaluation/Num Paths               15
evaluation/Average Returns        -30.132
time/data storing (s)               0.00285882
time/evaluation sampling (s)        0.330244
time/exploration sampling (s)       0.140979
time/logging (s)                    0.00478958
time/saving (s)                     0.00197666
time/training (s)                   1.90052
time/epoch (s)                      2.38136
time/total (s)                    725.825
Epoch                             296
-----------------------------  ---------------
2019-04-22 23:39:22.629398 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 297 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0742859
trainer/QF2 Loss                    0.0597247
trainer/Policy Loss                14.8835
trainer/Q1 Predictions Mean       -13.2255
trainer/Q1 Predictions Std         14.6647
trainer/Q1 Predictions Max         -7.01431
trainer/Q1 Predictions Min        -57.4736
trainer/Q2 Predictions Mean       -13.2055
trainer/Q2 Predictions Std         14.6767
trainer/Q2 Predictions Max         -6.99202
trainer/Q2 Predictions Min        -57.4702
trainer/Q Targets Mean            -13.3064
trainer/Q Targets Std              14.85
trainer/Q Targets Max              -6.90157
trainer/Q Targets Min             -57.9851
trainer/Log Pis Mean                1.71923
trainer/Log Pis Std                 0.930803
trainer/Log Pis Max                 3.38555
trainer/Log Pis Min                -2.05527
trainer/Policy mu Mean             -0.0705514
trainer/Policy mu Std               0.490729
trainer/Policy mu Max               1.63292
trainer/Policy mu Min              -2.85605
trainer/Policy log std Mean        -2.20294
trainer/Policy log std Std          0.389448
trainer/Policy log std Max         -0.488022
trainer/Policy log std Min         -2.83912
trainer/Alpha                       0.0674661
trainer/Alpha Loss                 -0.756982
exploration/num steps total    149200
exploration/num paths total      1492
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.302547
exploration/Rewards Std             0.902998
exploration/Rewards Max            -0.00568337
exploration/Rewards Min            -8.67367
exploration/Returns Mean          -30.2547
exploration/Returns Std            12.7768
exploration/Returns Max           -16.3778
exploration/Returns Min           -53.2317
exploration/Actions Mean            0.0102779
exploration/Actions Std             0.241847
exploration/Actions Max             0.99788
exploration/Actions Min            -0.999889
exploration/Num Paths               5
exploration/Average Returns       -30.2547
evaluation/num steps total     447000
evaluation/num paths total       4470
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.371325
evaluation/Rewards Std              0.815121
evaluation/Rewards Max             -0.00419893
evaluation/Rewards Min             -8.75863
evaluation/Returns Mean           -37.1325
evaluation/Returns Std             36.9097
evaluation/Returns Max             -8.23508
evaluation/Returns Min           -110.091
evaluation/Actions Mean             0.0113488
evaluation/Actions Std              0.172273
evaluation/Actions Max              0.999114
evaluation/Actions Min             -0.998659
evaluation/Num Paths               15
evaluation/Average Returns        -37.1325
time/data storing (s)               0.00257842
time/evaluation sampling (s)        0.328618
time/exploration sampling (s)       0.139999
time/logging (s)                    0.00349661
time/saving (s)                     0.00159021
time/training (s)                   1.92912
time/epoch (s)                      2.4054
time/total (s)                    728.234
Epoch                             297
-----------------------------  ---------------
2019-04-22 23:39:25.032947 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 298 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.89665
trainer/QF2 Loss                    1.9194
trainer/Policy Loss                14.8308
trainer/Q1 Predictions Mean       -12.6254
trainer/Q1 Predictions Std         13.6029
trainer/Q1 Predictions Max         -6.88732
trainer/Q1 Predictions Min        -57.9375
trainer/Q2 Predictions Mean       -12.6746
trainer/Q2 Predictions Std         13.602
trainer/Q2 Predictions Max         -6.93138
trainer/Q2 Predictions Min        -57.9018
trainer/Q Targets Mean            -12.4607
trainer/Q Targets Std              13.7919
trainer/Q Targets Max              -0.0414678
trainer/Q Targets Min             -57.9845
trainer/Log Pis Mean                2.27899
trainer/Log Pis Std                 1.03463
trainer/Log Pis Max                 7.62406
trainer/Log Pis Min                 0.121142
trainer/Policy mu Mean             -0.0376598
trainer/Policy mu Std               0.561647
trainer/Policy mu Max               2.92055
trainer/Policy mu Min              -3.17601
trainer/Policy log std Mean        -2.24868
trainer/Policy log std Std          0.39559
trainer/Policy log std Max         -0.656697
trainer/Policy log std Min         -2.88722
trainer/Alpha                       0.0668741
trainer/Alpha Loss                  0.754673
exploration/num steps total    149700
exploration/num paths total      1497
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.566854
exploration/Rewards Std             1.26657
exploration/Rewards Max            -0.00254378
exploration/Rewards Min           -10.0946
exploration/Returns Mean          -56.6854
exploration/Returns Std            37.0924
exploration/Returns Max           -11.3421
exploration/Returns Min          -117.517
exploration/Actions Mean           -0.00754957
exploration/Actions Std             0.232011
exploration/Actions Max             0.999789
exploration/Actions Min            -0.999841
exploration/Num Paths               5
exploration/Average Returns       -56.6854
evaluation/num steps total     448500
evaluation/num paths total       4485
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.425078
evaluation/Rewards Std              1.04628
evaluation/Rewards Max             -0.0169791
evaluation/Rewards Min             -9.60041
evaluation/Returns Mean           -42.5078
evaluation/Returns Std             37.4034
evaluation/Returns Max             -8.67241
evaluation/Returns Min           -116.581
evaluation/Actions Mean            -0.01033
evaluation/Actions Std              0.197051
evaluation/Actions Max              0.995456
evaluation/Actions Min             -0.997305
evaluation/Num Paths               15
evaluation/Average Returns        -42.5078
time/data storing (s)               0.00266047
time/evaluation sampling (s)        0.326423
time/exploration sampling (s)       0.141093
time/logging (s)                    0.00475207
time/saving (s)                     0.00155718
time/training (s)                   1.91951
time/epoch (s)                      2.39599
time/total (s)                    730.635
Epoch                             298
-----------------------------  ---------------
2019-04-22 23:39:27.444915 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 299 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0736684
trainer/QF2 Loss                    0.0707666
trainer/Policy Loss                18.0587
trainer/Q1 Predictions Mean       -16.1195
trainer/Q1 Predictions Std         17.5667
trainer/Q1 Predictions Max         -6.90097
trainer/Q1 Predictions Min        -64.119
trainer/Q2 Predictions Mean       -16.1304
trainer/Q2 Predictions Std         17.5965
trainer/Q2 Predictions Max         -6.89496
trainer/Q2 Predictions Min        -63.8829
trainer/Q Targets Mean            -16.2032
trainer/Q Targets Std              17.6149
trainer/Q Targets Max              -6.90991
trainer/Q Targets Min             -63.2377
trainer/Log Pis Mean                2.00784
trainer/Log Pis Std                 1.34924
trainer/Log Pis Max                 8.49574
trainer/Log Pis Min                -1.29683
trainer/Policy mu Mean             -0.0147094
trainer/Policy mu Std               0.666734
trainer/Policy mu Max               3.38786
trainer/Policy mu Min              -2.86408
trainer/Policy log std Mean        -2.20478
trainer/Policy log std Std          0.45181
trainer/Policy log std Max         -0.473682
trainer/Policy log std Min         -2.79786
trainer/Alpha                       0.0680847
trainer/Alpha Loss                  0.0210754
exploration/num steps total    150200
exploration/num paths total      1502
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.476509
exploration/Rewards Std             0.94786
exploration/Rewards Max            -0.0212906
exploration/Rewards Min            -9.06431
exploration/Returns Mean          -47.6509
exploration/Returns Std            32.2569
exploration/Returns Max           -13.3361
exploration/Returns Min          -104.597
exploration/Actions Mean            0.00993857
exploration/Actions Std             0.213345
exploration/Actions Max             0.997577
exploration/Actions Min            -0.999636
exploration/Num Paths               5
exploration/Average Returns       -47.6509
evaluation/num steps total     450000
evaluation/num paths total       4500
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.415453
evaluation/Rewards Std              1.01504
evaluation/Rewards Max             -0.00180208
evaluation/Rewards Min            -10.6343
evaluation/Returns Mean           -41.5453
evaluation/Returns Std             36.8684
evaluation/Returns Max             -2.20304
evaluation/Returns Min           -121.219
evaluation/Actions Mean             0.000399979
evaluation/Actions Std              0.185991
evaluation/Actions Max              0.999259
evaluation/Actions Min             -0.999328
evaluation/Num Paths               15
evaluation/Average Returns        -41.5453
time/data storing (s)               0.002724
time/evaluation sampling (s)        0.331486
time/exploration sampling (s)       0.139897
time/logging (s)                    0.0047684
time/saving (s)                     0.00199726
time/training (s)                   1.92247
time/epoch (s)                      2.40334
time/total (s)                    733.042
Epoch                             299
-----------------------------  ----------------
2019-04-22 23:39:29.938997 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 300 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.86326
trainer/QF2 Loss                    1.99837
trainer/Policy Loss                17.4156
trainer/Q1 Predictions Mean       -15.4266
trainer/Q1 Predictions Std         17.3733
trainer/Q1 Predictions Max         -6.98126
trainer/Q1 Predictions Min        -70.3107
trainer/Q2 Predictions Mean       -15.3763
trainer/Q2 Predictions Std         17.2884
trainer/Q2 Predictions Max         -6.98623
trainer/Q2 Predictions Min        -69.2049
trainer/Q Targets Mean            -15.3105
trainer/Q Targets Std              17.6308
trainer/Q Targets Max              -0.0480581
trainer/Q Targets Min             -69.2077
trainer/Log Pis Mean                2.13896
trainer/Log Pis Std                 1.4841
trainer/Log Pis Max                11.2781
trainer/Log Pis Min                -0.852966
trainer/Policy mu Mean             -0.0199008
trainer/Policy mu Std               0.644297
trainer/Policy mu Max               3.70335
trainer/Policy mu Min              -3.26266
trainer/Policy log std Mean        -2.25278
trainer/Policy log std Std          0.398459
trainer/Policy log std Max         -0.463617
trainer/Policy log std Min         -2.78806
trainer/Alpha                       0.0699123
trainer/Alpha Loss                  0.369719
exploration/num steps total    150700
exploration/num paths total      1507
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.499911
exploration/Rewards Std             1.0617
exploration/Rewards Max            -0.00984253
exploration/Rewards Min            -8.85698
exploration/Returns Mean          -49.9911
exploration/Returns Std            38.7575
exploration/Returns Max           -12.33
exploration/Returns Min          -124.449
exploration/Actions Mean           -0.0124908
exploration/Actions Std             0.239997
exploration/Actions Max             0.999899
exploration/Actions Min            -0.999473
exploration/Num Paths               5
exploration/Average Returns       -49.9911
evaluation/num steps total     451500
evaluation/num paths total       4515
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.307185
evaluation/Rewards Std              1.04046
evaluation/Rewards Max             -0.00778531
evaluation/Rewards Min            -10.0753
evaluation/Returns Mean           -30.7185
evaluation/Returns Std             24.8012
evaluation/Returns Max             -3.2186
evaluation/Returns Min           -106.062
evaluation/Actions Mean             0.0091516
evaluation/Actions Std              0.192314
evaluation/Actions Max              0.998926
evaluation/Actions Min             -0.999255
evaluation/Num Paths               15
evaluation/Average Returns        -30.7185
time/data storing (s)               0.00278259
time/evaluation sampling (s)        0.323856
time/exploration sampling (s)       0.140339
time/logging (s)                    0.00477695
time/saving (s)                     0.00198232
time/training (s)                   2.01249
time/epoch (s)                      2.48622
time/total (s)                    735.531
Epoch                             300
-----------------------------  ---------------
2019-04-22 23:39:32.352075 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 301 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   29.3577
trainer/QF2 Loss                   29.5472
trainer/Policy Loss                17.7108
trainer/Q1 Predictions Mean       -15.8733
trainer/Q1 Predictions Std         17.3476
trainer/Q1 Predictions Max         -6.9537
trainer/Q1 Predictions Min        -56.2342
trainer/Q2 Predictions Mean       -15.8676
trainer/Q2 Predictions Std         17.3578
trainer/Q2 Predictions Max         -6.98546
trainer/Q2 Predictions Min        -56.3037
trainer/Q Targets Mean            -15.355
trainer/Q Targets Std              17.1379
trainer/Q Targets Max              -0.100171
trainer/Q Targets Min             -56.6763
trainer/Log Pis Mean                2.01481
trainer/Log Pis Std                 1.00532
trainer/Log Pis Max                 5.37858
trainer/Log Pis Min                -0.992359
trainer/Policy mu Mean             -0.138628
trainer/Policy mu Std               0.443105
trainer/Policy mu Max               1.12833
trainer/Policy mu Min              -2.87051
trainer/Policy log std Mean        -2.18693
trainer/Policy log std Std          0.362841
trainer/Policy log std Max         -0.636904
trainer/Policy log std Min         -2.82457
trainer/Alpha                       0.0687597
trainer/Alpha Loss                  0.0396423
exploration/num steps total    151200
exploration/num paths total      1512
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.55281
exploration/Rewards Std             1.17386
exploration/Rewards Max            -0.00672939
exploration/Rewards Min            -9.81026
exploration/Returns Mean          -55.281
exploration/Returns Std            31.8799
exploration/Returns Max           -24.1288
exploration/Returns Min          -109.109
exploration/Actions Mean           -0.00533987
exploration/Actions Std             0.248021
exploration/Actions Max             0.999329
exploration/Actions Min            -0.998377
exploration/Num Paths               5
exploration/Average Returns       -55.281
evaluation/num steps total     453000
evaluation/num paths total       4530
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.299088
evaluation/Rewards Std              1.15683
evaluation/Rewards Max             -0.00213459
evaluation/Rewards Min             -9.57115
evaluation/Returns Mean           -29.9088
evaluation/Returns Std             17.5256
evaluation/Returns Max             -2.60556
evaluation/Returns Min            -56.813
evaluation/Actions Mean             0.0069781
evaluation/Actions Std              0.206914
evaluation/Actions Max              0.998782
evaluation/Actions Min             -0.997426
evaluation/Num Paths               15
evaluation/Average Returns        -29.9088
time/data storing (s)               0.00275567
time/evaluation sampling (s)        0.336104
time/exploration sampling (s)       0.141084
time/logging (s)                    0.00479853
time/saving (s)                     0.00178855
time/training (s)                   1.91768
time/epoch (s)                      2.40421
time/total (s)                    737.94
Epoch                             301
-----------------------------  ---------------
2019-04-22 23:39:34.830687 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 302 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   29.19
trainer/QF2 Loss                   29.2611
trainer/Policy Loss                20.8239
trainer/Q1 Predictions Mean       -18.8253
trainer/Q1 Predictions Std         19.7744
trainer/Q1 Predictions Max         -6.9966
trainer/Q1 Predictions Min        -68.5776
trainer/Q2 Predictions Mean       -18.8826
trainer/Q2 Predictions Std         19.7994
trainer/Q2 Predictions Max         -6.993
trainer/Q2 Predictions Min        -67.9968
trainer/Q Targets Mean            -18.4279
trainer/Q Targets Std              19.6258
trainer/Q Targets Max              -1.85494
trainer/Q Targets Min             -67.9046
trainer/Log Pis Mean                2.07024
trainer/Log Pis Std                 1.11788
trainer/Log Pis Max                 7.80286
trainer/Log Pis Min                -1.6821
trainer/Policy mu Mean             -0.0471465
trainer/Policy mu Std               0.550672
trainer/Policy mu Max               2.98827
trainer/Policy mu Min              -3.28281
trainer/Policy log std Mean        -2.2306
trainer/Policy log std Std          0.412349
trainer/Policy log std Max         -0.0721684
trainer/Policy log std Min         -2.84493
trainer/Alpha                       0.0674141
trainer/Alpha Loss                  0.189427
exploration/num steps total    151700
exploration/num paths total      1517
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.454313
exploration/Rewards Std             0.92168
exploration/Rewards Max            -0.00686899
exploration/Rewards Min            -9.22704
exploration/Returns Mean          -45.4313
exploration/Returns Std            32.3429
exploration/Returns Max           -18.4543
exploration/Returns Min          -105.651
exploration/Actions Mean           -0.00367049
exploration/Actions Std             0.228571
exploration/Actions Max             0.998403
exploration/Actions Min            -0.997238
exploration/Num Paths               5
exploration/Average Returns       -45.4313
evaluation/num steps total     454500
evaluation/num paths total       4545
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.434021
evaluation/Rewards Std              1.0698
evaluation/Rewards Max             -0.0148149
evaluation/Rewards Min            -10.0259
evaluation/Returns Mean           -43.4021
evaluation/Returns Std             36.954
evaluation/Returns Max             -3.81646
evaluation/Returns Min           -120.364
evaluation/Actions Mean             0.00855198
evaluation/Actions Std              0.198885
evaluation/Actions Max              0.999511
evaluation/Actions Min             -0.997794
evaluation/Num Paths               15
evaluation/Average Returns        -43.4021
time/data storing (s)               0.00263462
time/evaluation sampling (s)        0.325157
time/exploration sampling (s)       0.154282
time/logging (s)                    0.00501909
time/saving (s)                     0.00198101
time/training (s)                   1.98089
time/epoch (s)                      2.46996
time/total (s)                    740.414
Epoch                             302
-----------------------------  ---------------
2019-04-22 23:39:37.262371 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 303 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.43361
trainer/QF2 Loss                    1.41479
trainer/Policy Loss                19.758
trainer/Q1 Predictions Mean       -17.9579
trainer/Q1 Predictions Std         18.9854
trainer/Q1 Predictions Max         -6.84725
trainer/Q1 Predictions Min        -55.552
trainer/Q2 Predictions Mean       -17.9468
trainer/Q2 Predictions Std         19.0115
trainer/Q2 Predictions Max         -6.74697
trainer/Q2 Predictions Min        -55.597
trainer/Q Targets Mean            -18.0246
trainer/Q Targets Std              19.4534
trainer/Q Targets Max              -0.184319
trainer/Q Targets Min             -56.5687
trainer/Log Pis Mean                1.9985
trainer/Log Pis Std                 1.03526
trainer/Log Pis Max                 4.37806
trainer/Log Pis Min                -2.05844
trainer/Policy mu Mean             -0.08317
trainer/Policy mu Std               0.376081
trainer/Policy mu Max               3.28373
trainer/Policy mu Min              -1.48865
trainer/Policy log std Mean        -2.31184
trainer/Policy log std Std          0.306635
trainer/Policy log std Max         -0.462741
trainer/Policy log std Min         -2.86336
trainer/Alpha                       0.0668371
trainer/Alpha Loss                 -0.00404937
exploration/num steps total    152200
exploration/num paths total      1522
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.323138
exploration/Rewards Std             0.969266
exploration/Rewards Max            -0.00987645
exploration/Rewards Min            -8.77486
exploration/Returns Mean          -32.3138
exploration/Returns Std            13.0625
exploration/Returns Max           -15.156
exploration/Returns Min           -55.0089
exploration/Actions Mean            0.0226198
exploration/Actions Std             0.228789
exploration/Actions Max             0.999725
exploration/Actions Min            -0.99482
exploration/Num Paths               5
exploration/Average Returns       -32.3138
evaluation/num steps total     456000
evaluation/num paths total       4560
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.371485
evaluation/Rewards Std              1.04638
evaluation/Rewards Max             -0.0130399
evaluation/Rewards Min            -11.2484
evaluation/Returns Mean           -37.1485
evaluation/Returns Std             30.8657
evaluation/Returns Max             -8.09065
evaluation/Returns Min           -107.543
evaluation/Actions Mean             0.00166749
evaluation/Actions Std              0.201957
evaluation/Actions Max              0.99955
evaluation/Actions Min             -0.997474
evaluation/Num Paths               15
evaluation/Average Returns        -37.1485
time/data storing (s)               0.00285149
time/evaluation sampling (s)        0.335329
time/exploration sampling (s)       0.138213
time/logging (s)                    0.00478667
time/saving (s)                     0.00198244
time/training (s)                   1.94003
time/epoch (s)                      2.42319
time/total (s)                    742.841
Epoch                             303
-----------------------------  ---------------
2019-04-22 23:39:39.669100 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 304 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.528005
trainer/QF2 Loss                    0.565591
trainer/Policy Loss                18.3725
trainer/Q1 Predictions Mean       -16.555
trainer/Q1 Predictions Std         17.7863
trainer/Q1 Predictions Max         -6.91038
trainer/Q1 Predictions Min        -56.2132
trainer/Q2 Predictions Mean       -16.5394
trainer/Q2 Predictions Std         17.7725
trainer/Q2 Predictions Max         -6.8798
trainer/Q2 Predictions Min        -56.3098
trainer/Q Targets Mean            -16.5173
trainer/Q Targets Std              17.9317
trainer/Q Targets Max              -0.443536
trainer/Q Targets Min             -56.6427
trainer/Log Pis Mean                1.97438
trainer/Log Pis Std                 1.19316
trainer/Log Pis Max                 5.76937
trainer/Log Pis Min                -3.20135
trainer/Policy mu Mean             -0.0582787
trainer/Policy mu Std               0.573359
trainer/Policy mu Max               3.55887
trainer/Policy mu Min              -3.536
trainer/Policy log std Mean        -2.25881
trainer/Policy log std Std          0.396179
trainer/Policy log std Max         -0.370366
trainer/Policy log std Min         -2.73506
trainer/Alpha                       0.0655172
trainer/Alpha Loss                 -0.0698369
exploration/num steps total    152700
exploration/num paths total      1527
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.257997
exploration/Rewards Std             0.739952
exploration/Rewards Max            -0.00540827
exploration/Rewards Min            -6.6452
exploration/Returns Mean          -25.7997
exploration/Returns Std             9.96595
exploration/Returns Max           -12.3681
exploration/Returns Min           -37.0009
exploration/Actions Mean           -0.00794405
exploration/Actions Std             0.207695
exploration/Actions Max             0.999046
exploration/Actions Min            -0.998729
exploration/Num Paths               5
exploration/Average Returns       -25.7997
evaluation/num steps total     457500
evaluation/num paths total       4575
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.438247
evaluation/Rewards Std              0.915649
evaluation/Rewards Max             -0.0106606
evaluation/Rewards Min             -9.52416
evaluation/Returns Mean           -43.8247
evaluation/Returns Std             40.5801
evaluation/Returns Max             -2.8569
evaluation/Returns Min           -115.382
evaluation/Actions Mean             0.00243831
evaluation/Actions Std              0.178912
evaluation/Actions Max              0.997492
evaluation/Actions Min             -0.998743
evaluation/Num Paths               15
evaluation/Average Returns        -43.8247
time/data storing (s)               0.00266823
time/evaluation sampling (s)        0.325417
time/exploration sampling (s)       0.139973
time/logging (s)                    0.00480744
time/saving (s)                     0.00199545
time/training (s)                   1.92291
time/epoch (s)                      2.39778
time/total (s)                    745.243
Epoch                             304
-----------------------------  ---------------
2019-04-22 23:39:42.100788 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 305 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.525185
trainer/QF2 Loss                    0.55904
trainer/Policy Loss                15.9454
trainer/Q1 Predictions Mean       -14.012
trainer/Q1 Predictions Std         16.5356
trainer/Q1 Predictions Max         -6.84512
trainer/Q1 Predictions Min        -73.5984
trainer/Q2 Predictions Mean       -13.9956
trainer/Q2 Predictions Std         16.5665
trainer/Q2 Predictions Max         -6.80349
trainer/Q2 Predictions Min        -73.4535
trainer/Q Targets Mean            -14.0873
trainer/Q Targets Std              16.5601
trainer/Q Targets Max              -0.198539
trainer/Q Targets Min             -73.1754
trainer/Log Pis Mean                2.02086
trainer/Log Pis Std                 1.04429
trainer/Log Pis Max                 5.51883
trainer/Log Pis Min                -1.33196
trainer/Policy mu Mean             -0.0775848
trainer/Policy mu Std               0.494501
trainer/Policy mu Max               1.87516
trainer/Policy mu Min              -3.71582
trainer/Policy log std Mean        -2.2592
trainer/Policy log std Std          0.341405
trainer/Policy log std Max         -0.529763
trainer/Policy log std Min         -2.77874
trainer/Alpha                       0.065149
trainer/Alpha Loss                  0.0569703
exploration/num steps total    153200
exploration/num paths total      1532
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.420304
exploration/Rewards Std             1.27434
exploration/Rewards Max            -0.00986609
exploration/Rewards Min           -10.767
exploration/Returns Mean          -42.0304
exploration/Returns Std            11.4612
exploration/Returns Max           -30.8226
exploration/Returns Min           -59.6329
exploration/Actions Mean            0.0200042
exploration/Actions Std             0.256368
exploration/Actions Max             0.999333
exploration/Actions Min            -0.999223
exploration/Num Paths               5
exploration/Average Returns       -42.0304
evaluation/num steps total     459000
evaluation/num paths total       4590
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.394151
evaluation/Rewards Std              1.13917
evaluation/Rewards Max             -0.0296373
evaluation/Rewards Min             -9.91615
evaluation/Returns Mean           -39.4151
evaluation/Returns Std             36.2506
evaluation/Returns Max             -3.6205
evaluation/Returns Min           -128.357
evaluation/Actions Mean            -0.00630958
evaluation/Actions Std              0.200548
evaluation/Actions Max              0.999084
evaluation/Actions Min             -0.998933
evaluation/Num Paths               15
evaluation/Average Returns        -39.4151
time/data storing (s)               0.00278824
time/evaluation sampling (s)        0.330454
time/exploration sampling (s)       0.141705
time/logging (s)                    0.00485374
time/saving (s)                     0.0102064
time/training (s)                   1.93344
time/epoch (s)                      2.42345
time/total (s)                    747.671
Epoch                             305
-----------------------------  ---------------
2019-04-22 23:39:44.524700 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 306 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0969349
trainer/QF2 Loss                    0.10428
trainer/Policy Loss                19.4086
trainer/Q1 Predictions Mean       -17.5329
trainer/Q1 Predictions Std         18.5081
trainer/Q1 Predictions Max         -6.94801
trainer/Q1 Predictions Min        -55.3853
trainer/Q2 Predictions Mean       -17.5175
trainer/Q2 Predictions Std         18.5133
trainer/Q2 Predictions Max         -6.92183
trainer/Q2 Predictions Min        -55.5515
trainer/Q Targets Mean            -17.6861
trainer/Q Targets Std              18.7531
trainer/Q Targets Max              -6.87487
trainer/Q Targets Min             -55.9639
trainer/Log Pis Mean                2.05101
trainer/Log Pis Std                 1.05202
trainer/Log Pis Max                 5.11339
trainer/Log Pis Min                -2.12794
trainer/Policy mu Mean             -0.0109964
trainer/Policy mu Std               0.458237
trainer/Policy mu Max               2.83946
trainer/Policy mu Min              -1.64637
trainer/Policy log std Mean        -2.26181
trainer/Policy log std Std          0.354602
trainer/Policy log std Max         -0.691921
trainer/Policy log std Min         -2.82024
trainer/Alpha                       0.0670697
trainer/Alpha Loss                  0.137833
exploration/num steps total    153700
exploration/num paths total      1537
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.302619
exploration/Rewards Std             0.864424
exploration/Rewards Max            -0.00644304
exploration/Rewards Min            -7.38399
exploration/Returns Mean          -30.2619
exploration/Returns Std             5.13576
exploration/Returns Max           -25.5696
exploration/Returns Min           -40.0541
exploration/Actions Mean            0.0267925
exploration/Actions Std             0.232698
exploration/Actions Max             0.998057
exploration/Actions Min            -0.998127
exploration/Num Paths               5
exploration/Average Returns       -30.2619
evaluation/num steps total     460500
evaluation/num paths total       4605
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.332604
evaluation/Rewards Std              0.973759
evaluation/Rewards Max             -0.0118311
evaluation/Rewards Min            -10.7623
evaluation/Returns Mean           -33.2604
evaluation/Returns Std             32.7243
evaluation/Returns Max             -2.65876
evaluation/Returns Min           -109.584
evaluation/Actions Mean            -0.00556023
evaluation/Actions Std              0.194065
evaluation/Actions Max              0.996401
evaluation/Actions Min             -0.997701
evaluation/Num Paths               15
evaluation/Average Returns        -33.2604
time/data storing (s)               0.00264684
time/evaluation sampling (s)        0.330218
time/exploration sampling (s)       0.145042
time/logging (s)                    0.00454598
time/saving (s)                     0.00197196
time/training (s)                   1.92997
time/epoch (s)                      2.41439
time/total (s)                    750.09
Epoch                             306
-----------------------------  ---------------
2019-04-22 23:39:46.958684 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 307 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.598298
trainer/QF2 Loss                    0.596325
trainer/Policy Loss                14.9524
trainer/Q1 Predictions Mean       -13.0598
trainer/Q1 Predictions Std         14.7733
trainer/Q1 Predictions Max         -6.70948
trainer/Q1 Predictions Min        -56.1245
trainer/Q2 Predictions Mean       -13.0801
trainer/Q2 Predictions Std         14.7759
trainer/Q2 Predictions Max         -6.6596
trainer/Q2 Predictions Min        -56.4085
trainer/Q Targets Mean            -13.0893
trainer/Q Targets Std              14.7451
trainer/Q Targets Max              -0.186261
trainer/Q Targets Min             -55.5804
trainer/Log Pis Mean                2.04657
trainer/Log Pis Std                 0.896798
trainer/Log Pis Max                 5.25178
trainer/Log Pis Min                -0.630112
trainer/Policy mu Mean             -0.0328582
trainer/Policy mu Std               0.375233
trainer/Policy mu Max               2.78753
trainer/Policy mu Min              -2.78403
trainer/Policy log std Mean        -2.2898
trainer/Policy log std Std          0.289951
trainer/Policy log std Max         -0.557785
trainer/Policy log std Min         -2.77299
trainer/Alpha                       0.0687699
trainer/Alpha Loss                  0.124673
exploration/num steps total    154200
exploration/num paths total      1542
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.420911
exploration/Rewards Std             1.35793
exploration/Rewards Max            -0.00437158
exploration/Rewards Min           -11.5938
exploration/Returns Mean          -42.0911
exploration/Returns Std            20.8668
exploration/Returns Max           -17.8011
exploration/Returns Min           -66.4775
exploration/Actions Mean            0.00476152
exploration/Actions Std             0.253362
exploration/Actions Max             0.999848
exploration/Actions Min            -0.999198
exploration/Num Paths               5
exploration/Average Returns       -42.0911
evaluation/num steps total     462000
evaluation/num paths total       4620
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.338026
evaluation/Rewards Std              0.926178
evaluation/Rewards Max             -0.0144948
evaluation/Rewards Min             -8.77419
evaluation/Returns Mean           -33.8026
evaluation/Returns Std             28.6008
evaluation/Returns Max             -9.78986
evaluation/Returns Min           -107.45
evaluation/Actions Mean             0.00622299
evaluation/Actions Std              0.188928
evaluation/Actions Max              0.998141
evaluation/Actions Min             -0.996845
evaluation/Num Paths               15
evaluation/Average Returns        -33.8026
time/data storing (s)               0.00274274
time/evaluation sampling (s)        0.327599
time/exploration sampling (s)       0.143075
time/logging (s)                    0.0048008
time/saving (s)                     0.00157758
time/training (s)                   1.94527
time/epoch (s)                      2.42507
time/total (s)                    752.52
Epoch                             307
-----------------------------  ---------------
2019-04-22 23:39:49.395182 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 308 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   27.2568
trainer/QF2 Loss                   27.259
trainer/Policy Loss                17.5731
trainer/Q1 Predictions Mean       -15.6279
trainer/Q1 Predictions Std         17.1394
trainer/Q1 Predictions Max         -6.79224
trainer/Q1 Predictions Min        -55.0073
trainer/Q2 Predictions Mean       -15.6536
trainer/Q2 Predictions Std         17.1589
trainer/Q2 Predictions Max         -6.76776
trainer/Q2 Predictions Min        -55.1509
trainer/Q Targets Mean            -15.2666
trainer/Q Targets Std              16.9718
trainer/Q Targets Max              -1.63721
trainer/Q Targets Min             -55.8152
trainer/Log Pis Mean                2.02512
trainer/Log Pis Std                 1.17454
trainer/Log Pis Max                 7.4603
trainer/Log Pis Min                -0.987007
trainer/Policy mu Mean             -0.017419
trainer/Policy mu Std               0.478549
trainer/Policy mu Max               3.44447
trainer/Policy mu Min              -2.22537
trainer/Policy log std Mean        -2.26972
trainer/Policy log std Std          0.347501
trainer/Policy log std Max         -0.702437
trainer/Policy log std Min         -2.87674
trainer/Alpha                       0.0684943
trainer/Alpha Loss                  0.0673415
exploration/num steps total    154700
exploration/num paths total      1547
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.376902
exploration/Rewards Std             1.11981
exploration/Rewards Max            -0.00173659
exploration/Rewards Min            -9.09126
exploration/Returns Mean          -37.6902
exploration/Returns Std            12.8867
exploration/Returns Max           -18.3114
exploration/Returns Min           -55.9106
exploration/Actions Mean           -0.00952596
exploration/Actions Std             0.245295
exploration/Actions Max             0.99826
exploration/Actions Min            -0.999232
exploration/Num Paths               5
exploration/Average Returns       -37.6902
evaluation/num steps total     463500
evaluation/num paths total       4635
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.271883
evaluation/Rewards Std              0.949873
evaluation/Rewards Max             -0.0105151
evaluation/Rewards Min             -9.8849
evaluation/Returns Mean           -27.1883
evaluation/Returns Std             31.1979
evaluation/Returns Max             -4.05255
evaluation/Returns Min           -126.78
evaluation/Actions Mean             0.0129183
evaluation/Actions Std              0.173177
evaluation/Actions Max              0.997946
evaluation/Actions Min             -0.996645
evaluation/Num Paths               15
evaluation/Average Returns        -27.1883
time/data storing (s)               0.0025824
time/evaluation sampling (s)        0.332807
time/exploration sampling (s)       0.140688
time/logging (s)                    0.00482607
time/saving (s)                     0.0015998
time/training (s)                   1.94494
time/epoch (s)                      2.42744
time/total (s)                    754.952
Epoch                             308
-----------------------------  ---------------
2019-04-22 23:39:51.836751 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 309 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.105157
trainer/QF2 Loss                    0.109407
trainer/Policy Loss                15.46
trainer/Q1 Predictions Mean       -13.6163
trainer/Q1 Predictions Std         15.7149
trainer/Q1 Predictions Max         -6.71737
trainer/Q1 Predictions Min        -72.6493
trainer/Q2 Predictions Mean       -13.5752
trainer/Q2 Predictions Std         15.6995
trainer/Q2 Predictions Max         -6.70826
trainer/Q2 Predictions Min        -71.8215
trainer/Q Targets Mean            -13.7791
trainer/Q Targets Std              15.9086
trainer/Q Targets Max              -6.90328
trainer/Q Targets Min             -72.6367
trainer/Log Pis Mean                1.91011
trainer/Log Pis Std                 1.27769
trainer/Log Pis Max                 7.1675
trainer/Log Pis Min                -1.96564
trainer/Policy mu Mean             -0.0473014
trainer/Policy mu Std               0.472254
trainer/Policy mu Max               2.61761
trainer/Policy mu Min              -3.48306
trainer/Policy log std Mean        -2.26443
trainer/Policy log std Std          0.348596
trainer/Policy log std Max         -0.404602
trainer/Policy log std Min         -2.77836
trainer/Alpha                       0.0675812
trainer/Alpha Loss                 -0.242223
exploration/num steps total    155200
exploration/num paths total      1552
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.271626
exploration/Rewards Std             0.717013
exploration/Rewards Max            -0.00660198
exploration/Rewards Min            -6.64283
exploration/Returns Mean          -27.1626
exploration/Returns Std             4.52971
exploration/Returns Max           -19.5576
exploration/Returns Min           -31.3599
exploration/Actions Mean           -0.000751658
exploration/Actions Std             0.224662
exploration/Actions Max             0.99878
exploration/Actions Min            -0.997636
exploration/Num Paths               5
exploration/Average Returns       -27.1626
evaluation/num steps total     465000
evaluation/num paths total       4650
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.393565
evaluation/Rewards Std              1.14391
evaluation/Rewards Max             -0.0131765
evaluation/Rewards Min            -11.9545
evaluation/Returns Mean           -39.3565
evaluation/Returns Std             39.2331
evaluation/Returns Max             -4.87546
evaluation/Returns Min           -147.223
evaluation/Actions Mean            -0.000751092
evaluation/Actions Std              0.199871
evaluation/Actions Max              0.998969
evaluation/Actions Min             -0.999427
evaluation/Num Paths               15
evaluation/Average Returns        -39.3565
time/data storing (s)               0.00283947
time/evaluation sampling (s)        0.329235
time/exploration sampling (s)       0.138797
time/logging (s)                    0.00478422
time/saving (s)                     0.00194698
time/training (s)                   1.95567
time/epoch (s)                      2.43328
time/total (s)                    757.388
Epoch                             309
-----------------------------  ----------------
2019-04-22 23:39:54.258994 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 310 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0206886
trainer/QF2 Loss                    0.0353247
trainer/Policy Loss                13.3762
trainer/Q1 Predictions Mean       -11.6026
trainer/Q1 Predictions Std         12.7472
trainer/Q1 Predictions Max         -6.78017
trainer/Q1 Predictions Min        -55.2151
trainer/Q2 Predictions Mean       -11.5661
trainer/Q2 Predictions Std         12.7298
trainer/Q2 Predictions Max         -6.79175
trainer/Q2 Predictions Min        -55.1286
trainer/Q Targets Mean            -11.5931
trainer/Q Targets Std              12.7038
trainer/Q Targets Max              -6.87315
trainer/Q Targets Min             -55.0641
trainer/Log Pis Mean                1.84049
trainer/Log Pis Std                 1.00508
trainer/Log Pis Max                 4.07742
trainer/Log Pis Min                -1.6686
trainer/Policy mu Mean             -0.049167
trainer/Policy mu Std               0.342755
trainer/Policy mu Max               1.76033
trainer/Policy mu Min              -2.55996
trainer/Policy log std Mean        -2.2858
trainer/Policy log std Std          0.314097
trainer/Policy log std Max         -0.727398
trainer/Policy log std Min         -2.74262
trainer/Alpha                       0.067202
trainer/Alpha Loss                 -0.430692
exploration/num steps total    155700
exploration/num paths total      1557
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.319537
exploration/Rewards Std             0.885972
exploration/Rewards Max            -0.0065816
exploration/Rewards Min            -7.04558
exploration/Returns Mean          -31.9537
exploration/Returns Std            10.4601
exploration/Returns Max           -12.0451
exploration/Returns Min           -39.7275
exploration/Actions Mean           -0.0117659
exploration/Actions Std             0.230705
exploration/Actions Max             0.998237
exploration/Actions Min            -0.999876
exploration/Num Paths               5
exploration/Average Returns       -31.9537
evaluation/num steps total     466500
evaluation/num paths total       4665
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.317358
evaluation/Rewards Std              1.09128
evaluation/Rewards Max             -0.0193158
evaluation/Rewards Min            -11.6437
evaluation/Returns Mean           -31.7358
evaluation/Returns Std             25.9802
evaluation/Returns Max             -4.72289
evaluation/Returns Min           -106.811
evaluation/Actions Mean             0.00106447
evaluation/Actions Std              0.201228
evaluation/Actions Max              0.997282
evaluation/Actions Min             -0.998517
evaluation/Num Paths               15
evaluation/Average Returns        -31.7358
time/data storing (s)               0.00286067
time/evaluation sampling (s)        0.327179
time/exploration sampling (s)       0.139851
time/logging (s)                    0.00479585
time/saving (s)                     0.00189168
time/training (s)                   1.93636
time/epoch (s)                      2.41294
time/total (s)                    759.806
Epoch                             310
-----------------------------  ---------------
2019-04-22 23:39:56.696332 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 311 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.525027
trainer/QF2 Loss                    0.550111
trainer/Policy Loss                15.8974
trainer/Q1 Predictions Mean       -14.0447
trainer/Q1 Predictions Std         16.2209
trainer/Q1 Predictions Max         -6.7045
trainer/Q1 Predictions Min        -73.4454
trainer/Q2 Predictions Mean       -14.0463
trainer/Q2 Predictions Std         16.2414
trainer/Q2 Predictions Max         -6.6913
trainer/Q2 Predictions Min        -73.5212
trainer/Q Targets Mean            -14.119
trainer/Q Targets Std              16.377
trainer/Q Targets Max              -0.140477
trainer/Q Targets Min             -73.2524
trainer/Log Pis Mean                1.97178
trainer/Log Pis Std                 1.07881
trainer/Log Pis Max                 5.48366
trainer/Log Pis Min                -3.07805
trainer/Policy mu Mean             -0.0323695
trainer/Policy mu Std               0.451092
trainer/Policy mu Max               3.1279
trainer/Policy mu Min              -2.96525
trainer/Policy log std Mean        -2.24237
trainer/Policy log std Std          0.334828
trainer/Policy log std Max         -0.459372
trainer/Policy log std Min         -2.70191
trainer/Alpha                       0.0677302
trainer/Alpha Loss                 -0.0759666
exploration/num steps total    156200
exploration/num paths total      1562
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.444749
exploration/Rewards Std             0.983741
exploration/Rewards Max            -0.00539502
exploration/Rewards Min            -9.32032
exploration/Returns Mean          -44.4749
exploration/Returns Std            39.2432
exploration/Returns Max            -9.51668
exploration/Returns Min          -120.98
exploration/Actions Mean            0.0034058
exploration/Actions Std             0.229018
exploration/Actions Max             0.998491
exploration/Actions Min            -0.999169
exploration/Num Paths               5
exploration/Average Returns       -44.4749
evaluation/num steps total     468000
evaluation/num paths total       4680
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.341518
evaluation/Rewards Std              0.988824
evaluation/Rewards Max             -0.0197615
evaluation/Rewards Min             -9.80865
evaluation/Returns Mean           -34.1518
evaluation/Returns Std             27.5111
evaluation/Returns Max             -7.51201
evaluation/Returns Min            -96.5812
evaluation/Actions Mean             0.00684511
evaluation/Actions Std              0.196126
evaluation/Actions Max              0.997298
evaluation/Actions Min             -0.996588
evaluation/Num Paths               15
evaluation/Average Returns        -34.1518
time/data storing (s)               0.00272259
time/evaluation sampling (s)        0.323791
time/exploration sampling (s)       0.142955
time/logging (s)                    0.00480438
time/saving (s)                     0.00196034
time/training (s)                   1.9518
time/epoch (s)                      2.42803
time/total (s)                    762.238
Epoch                             311
-----------------------------  ---------------
2019-04-22 23:39:59.122737 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 312 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   26.6848
trainer/QF2 Loss                   26.6581
trainer/Policy Loss                15.1865
trainer/Q1 Predictions Mean       -13.1621
trainer/Q1 Predictions Std         14.5969
trainer/Q1 Predictions Max         -6.88555
trainer/Q1 Predictions Min        -54.2605
trainer/Q2 Predictions Mean       -13.1423
trainer/Q2 Predictions Std         14.6018
trainer/Q2 Predictions Max         -6.87986
trainer/Q2 Predictions Min        -54.2718
trainer/Q Targets Mean            -12.7619
trainer/Q Targets Std              14.2991
trainer/Q Targets Max              -1.37665
trainer/Q Targets Min             -54.9766
trainer/Log Pis Mean                2.16604
trainer/Log Pis Std                 1.04124
trainer/Log Pis Max                 7.1538
trainer/Log Pis Min                -0.488819
trainer/Policy mu Mean             -0.0587741
trainer/Policy mu Std               0.397757
trainer/Policy mu Max               2.64281
trainer/Policy mu Min              -2.80948
trainer/Policy log std Mean        -2.33185
trainer/Policy log std Std          0.324577
trainer/Policy log std Max         -0.65993
trainer/Policy log std Min         -2.84458
trainer/Alpha                       0.0679728
trainer/Alpha Loss                  0.446448
exploration/num steps total    156700
exploration/num paths total      1567
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.232405
exploration/Rewards Std             0.784206
exploration/Rewards Max            -0.00776288
exploration/Rewards Min            -9.20015
exploration/Returns Mean          -23.2405
exploration/Returns Std            13.5961
exploration/Returns Max           -11.912
exploration/Returns Min           -47.472
exploration/Actions Mean            0.0108101
exploration/Actions Std             0.190804
exploration/Actions Max             0.995761
exploration/Actions Min            -0.980011
exploration/Num Paths               5
exploration/Average Returns       -23.2405
evaluation/num steps total     469500
evaluation/num paths total       4695
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.164421
evaluation/Rewards Std              0.775687
evaluation/Rewards Max             -0.0156996
evaluation/Rewards Min             -9.47972
evaluation/Returns Mean           -16.4421
evaluation/Returns Std             14.121
evaluation/Returns Max             -3.31144
evaluation/Returns Min            -53.2146
evaluation/Actions Mean             0.00105593
evaluation/Actions Std              0.16303
evaluation/Actions Max              0.9995
evaluation/Actions Min             -0.99781
evaluation/Num Paths               15
evaluation/Average Returns        -16.4421
time/data storing (s)               0.00280798
time/evaluation sampling (s)        0.329607
time/exploration sampling (s)       0.140242
time/logging (s)                    0.00478745
time/saving (s)                     0.00157238
time/training (s)                   1.93825
time/epoch (s)                      2.41726
time/total (s)                    764.66
Epoch                             312
-----------------------------  ---------------
2019-04-22 23:40:01.540516 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 313 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.81723
trainer/QF2 Loss                    1.82858
trainer/Policy Loss                17.5745
trainer/Q1 Predictions Mean       -15.7575
trainer/Q1 Predictions Std         17.1203
trainer/Q1 Predictions Max         -6.77273
trainer/Q1 Predictions Min        -54.8596
trainer/Q2 Predictions Mean       -15.7567
trainer/Q2 Predictions Std         17.0926
trainer/Q2 Predictions Max         -6.77994
trainer/Q2 Predictions Min        -54.8603
trainer/Q Targets Mean            -15.508
trainer/Q Targets Std              17.2065
trainer/Q Targets Max              -0.0357689
trainer/Q Targets Min             -54.556
trainer/Log Pis Mean                1.98507
trainer/Log Pis Std                 1.45913
trainer/Log Pis Max                 8.22402
trainer/Log Pis Min                -2.72806
trainer/Policy mu Mean             -0.122296
trainer/Policy mu Std               0.557263
trainer/Policy mu Max               2.87842
trainer/Policy mu Min              -2.91663
trainer/Policy log std Mean        -2.24658
trainer/Policy log std Std          0.421877
trainer/Policy log std Max         -0.380503
trainer/Policy log std Min         -2.82951
trainer/Alpha                       0.0698625
trainer/Alpha Loss                 -0.0397441
exploration/num steps total    157200
exploration/num paths total      1572
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.29889
exploration/Rewards Std             0.944873
exploration/Rewards Max            -0.0118764
exploration/Rewards Min           -10.2231
exploration/Returns Mean          -29.889
exploration/Returns Std            21.2603
exploration/Returns Max           -13.6792
exploration/Returns Min           -71.4911
exploration/Actions Mean           -0.0242589
exploration/Actions Std             0.206703
exploration/Actions Max             0.945556
exploration/Actions Min            -0.999726
exploration/Num Paths               5
exploration/Average Returns       -29.889
evaluation/num steps total     471000
evaluation/num paths total       4710
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.355071
evaluation/Rewards Std              0.972837
evaluation/Rewards Max             -0.0268634
evaluation/Rewards Min             -9.39745
evaluation/Returns Mean           -35.5071
evaluation/Returns Std             32.2951
evaluation/Returns Max             -6.52103
evaluation/Returns Min           -125.555
evaluation/Actions Mean             0.00915195
evaluation/Actions Std              0.193195
evaluation/Actions Max              0.999505
evaluation/Actions Min             -0.99844
evaluation/Num Paths               15
evaluation/Average Returns        -35.5071
time/data storing (s)               0.0026287
time/evaluation sampling (s)        0.321842
time/exploration sampling (s)       0.139894
time/logging (s)                    0.00478991
time/saving (s)                     0.00197362
time/training (s)                   1.93741
time/epoch (s)                      2.40854
time/total (s)                    767.073
Epoch                             313
-----------------------------  ---------------
2019-04-22 23:40:03.953551 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 314 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.30149
trainer/QF2 Loss                    1.35251
trainer/Policy Loss                15.8249
trainer/Q1 Predictions Mean       -13.9083
trainer/Q1 Predictions Std         15.3932
trainer/Q1 Predictions Max         -6.80702
trainer/Q1 Predictions Min        -68.0884
trainer/Q2 Predictions Mean       -13.8847
trainer/Q2 Predictions Std         15.3707
trainer/Q2 Predictions Max         -6.79664
trainer/Q2 Predictions Min        -68.283
trainer/Q Targets Mean            -13.9993
trainer/Q Targets Std              15.7489
trainer/Q Targets Max              -0.220638
trainer/Q Targets Min             -68.7398
trainer/Log Pis Mean                2.06726
trainer/Log Pis Std                 1.0566
trainer/Log Pis Max                 5.89818
trainer/Log Pis Min                -0.391218
trainer/Policy mu Mean             -0.0939994
trainer/Policy mu Std               0.624495
trainer/Policy mu Max               2.21885
trainer/Policy mu Min              -3.18263
trainer/Policy log std Mean        -2.21982
trainer/Policy log std Std          0.429443
trainer/Policy log std Max         -0.261327
trainer/Policy log std Min         -2.7377
trainer/Alpha                       0.0712459
trainer/Alpha Loss                  0.17768
exploration/num steps total    157700
exploration/num paths total      1577
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.546437
exploration/Rewards Std             1.1835
exploration/Rewards Max            -0.000428008
exploration/Rewards Min            -9.52569
exploration/Returns Mean          -54.6437
exploration/Returns Std            40.4709
exploration/Returns Max           -26.4568
exploration/Returns Min          -134.357
exploration/Actions Mean           -0.0038884
exploration/Actions Std             0.245242
exploration/Actions Max             0.997707
exploration/Actions Min            -0.999212
exploration/Num Paths               5
exploration/Average Returns       -54.6437
evaluation/num steps total     472500
evaluation/num paths total       4725
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.26157
evaluation/Rewards Std              0.918425
evaluation/Rewards Max             -0.0081452
evaluation/Rewards Min             -9.42688
evaluation/Returns Mean           -26.157
evaluation/Returns Std             27.018
evaluation/Returns Max             -4.78416
evaluation/Returns Min           -113.015
evaluation/Actions Mean            -0.0129579
evaluation/Actions Std              0.181437
evaluation/Actions Max              0.994519
evaluation/Actions Min             -0.99885
evaluation/Num Paths               15
evaluation/Average Returns        -26.157
time/data storing (s)               0.00261219
time/evaluation sampling (s)        0.332035
time/exploration sampling (s)       0.142087
time/logging (s)                    0.00467301
time/saving (s)                     0.00160826
time/training (s)                   1.92039
time/epoch (s)                      2.4034
time/total (s)                    769.481
Epoch                             314
-----------------------------  ----------------
2019-04-22 23:40:06.364506 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 315 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.663213
trainer/QF2 Loss                    0.63296
trainer/Policy Loss                16.3732
trainer/Q1 Predictions Mean       -14.5089
trainer/Q1 Predictions Std         15.5036
trainer/Q1 Predictions Max         -6.83602
trainer/Q1 Predictions Min        -53.1719
trainer/Q2 Predictions Mean       -14.5048
trainer/Q2 Predictions Std         15.5437
trainer/Q2 Predictions Max         -6.86028
trainer/Q2 Predictions Min        -53.2569
trainer/Q Targets Mean            -14.5624
trainer/Q Targets Std              15.7698
trainer/Q Targets Max              -0.448437
trainer/Q Targets Min             -53.7219
trainer/Log Pis Mean                1.99619
trainer/Log Pis Std                 1.30013
trainer/Log Pis Max                 6.68467
trainer/Log Pis Min                -2.12971
trainer/Policy mu Mean             -0.0163224
trainer/Policy mu Std               0.535355
trainer/Policy mu Max               2.94296
trainer/Policy mu Min              -3.13562
trainer/Policy log std Mean        -2.2239
trainer/Policy log std Std          0.372792
trainer/Policy log std Max         -0.403529
trainer/Policy log std Min         -2.86916
trainer/Alpha                       0.0708775
trainer/Alpha Loss                 -0.0100935
exploration/num steps total    158200
exploration/num paths total      1582
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.485527
exploration/Rewards Std             0.873442
exploration/Rewards Max            -0.010711
exploration/Rewards Min            -7.90311
exploration/Returns Mean          -48.5527
exploration/Returns Std            33.8804
exploration/Returns Max           -19.5817
exploration/Returns Min          -113.338
exploration/Actions Mean           -0.0270182
exploration/Actions Std             0.234326
exploration/Actions Max             0.992736
exploration/Actions Min            -0.998581
exploration/Num Paths               5
exploration/Average Returns       -48.5527
evaluation/num steps total     474000
evaluation/num paths total       4740
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.255403
evaluation/Rewards Std              1.05016
evaluation/Rewards Max             -0.00525532
evaluation/Rewards Min            -10.7526
evaluation/Returns Mean           -25.5403
evaluation/Returns Std             15.0131
evaluation/Returns Max             -4.98015
evaluation/Returns Min            -52.175
evaluation/Actions Mean             0.00942963
evaluation/Actions Std              0.196802
evaluation/Actions Max              0.99924
evaluation/Actions Min             -0.996758
evaluation/Num Paths               15
evaluation/Average Returns        -25.5403
time/data storing (s)               0.00273846
time/evaluation sampling (s)        0.330284
time/exploration sampling (s)       0.139405
time/logging (s)                    0.00457245
time/saving (s)                     0.00196885
time/training (s)                   1.92337
time/epoch (s)                      2.40234
time/total (s)                    771.888
Epoch                             315
-----------------------------  ---------------
2019-04-22 23:40:08.794154 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 316 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0499488
trainer/QF2 Loss                    0.0559855
trainer/Policy Loss                15.7125
trainer/Q1 Predictions Mean       -13.7239
trainer/Q1 Predictions Std         14.954
trainer/Q1 Predictions Max         -6.91527
trainer/Q1 Predictions Min        -53.0919
trainer/Q2 Predictions Mean       -13.7455
trainer/Q2 Predictions Std         14.9259
trainer/Q2 Predictions Max         -6.90255
trainer/Q2 Predictions Min        -53.0486
trainer/Q Targets Mean            -13.862
trainer/Q Targets Std              15.0387
trainer/Q Targets Max              -6.85947
trainer/Q Targets Min             -53.3039
trainer/Log Pis Mean                2.12787
trainer/Log Pis Std                 0.959189
trainer/Log Pis Max                 3.84536
trainer/Log Pis Min                -2.20948
trainer/Policy mu Mean             -0.052834
trainer/Policy mu Std               0.41036
trainer/Policy mu Max               2.57743
trainer/Policy mu Min              -3.12938
trainer/Policy log std Mean        -2.29291
trainer/Policy log std Std          0.307305
trainer/Policy log std Max         -0.495299
trainer/Policy log std Min         -2.73176
trainer/Alpha                       0.0690135
trainer/Alpha Loss                  0.341876
exploration/num steps total    158700
exploration/num paths total      1587
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.548018
exploration/Rewards Std             1.20415
exploration/Rewards Max            -0.00877685
exploration/Rewards Min           -10.0709
exploration/Returns Mean          -54.8018
exploration/Returns Std            32.6379
exploration/Returns Max           -15.9938
exploration/Returns Min          -103.699
exploration/Actions Mean            0.0042451
exploration/Actions Std             0.238956
exploration/Actions Max             0.999216
exploration/Actions Min            -0.997921
exploration/Num Paths               5
exploration/Average Returns       -54.8018
evaluation/num steps total     475500
evaluation/num paths total       4755
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.264727
evaluation/Rewards Std              1.09447
evaluation/Rewards Max             -0.0139701
evaluation/Rewards Min             -9.69851
evaluation/Returns Mean           -26.4727
evaluation/Returns Std             18.059
evaluation/Returns Max             -4.38932
evaluation/Returns Min            -56.5927
evaluation/Actions Mean             0.0160564
evaluation/Actions Std              0.192062
evaluation/Actions Max              0.999359
evaluation/Actions Min             -0.998499
evaluation/Num Paths               15
evaluation/Average Returns        -26.4727
time/data storing (s)               0.00280809
time/evaluation sampling (s)        0.336463
time/exploration sampling (s)       0.139484
time/logging (s)                    0.00476367
time/saving (s)                     0.00196209
time/training (s)                   1.93497
time/epoch (s)                      2.42045
time/total (s)                    774.313
Epoch                             316
-----------------------------  ---------------
2019-04-22 23:40:11.202089 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 317 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.107596
trainer/QF2 Loss                    0.125399
trainer/Policy Loss                15.3668
trainer/Q1 Predictions Mean       -13.6222
trainer/Q1 Predictions Std         14.8712
trainer/Q1 Predictions Max         -6.75435
trainer/Q1 Predictions Min        -53.1035
trainer/Q2 Predictions Mean       -13.599
trainer/Q2 Predictions Std         14.8731
trainer/Q2 Predictions Max         -6.72709
trainer/Q2 Predictions Min        -52.9749
trainer/Q Targets Mean            -13.8137
trainer/Q Targets Std              15.0924
trainer/Q Targets Max              -6.93013
trainer/Q Targets Min             -54.2476
trainer/Log Pis Mean                1.84676
trainer/Log Pis Std                 1.1474
trainer/Log Pis Max                 6.87825
trainer/Log Pis Min                -1.77928
trainer/Policy mu Mean              0.0304821
trainer/Policy mu Std               0.418728
trainer/Policy mu Max               2.82735
trainer/Policy mu Min              -2.02136
trainer/Policy log std Mean        -2.27061
trainer/Policy log std Std          0.339653
trainer/Policy log std Max         -0.477359
trainer/Policy log std Min         -2.86814
trainer/Alpha                       0.0704041
trainer/Alpha Loss                 -0.406607
exploration/num steps total    159200
exploration/num paths total      1592
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.552696
exploration/Rewards Std             0.704863
exploration/Rewards Max            -0.00543328
exploration/Rewards Min            -6.51588
exploration/Returns Mean          -55.2696
exploration/Returns Std            42.6525
exploration/Returns Max           -16.4152
exploration/Returns Min          -110.298
exploration/Actions Mean           -0.00514351
exploration/Actions Std             0.207151
exploration/Actions Max             0.994307
exploration/Actions Min            -0.998051
exploration/Num Paths               5
exploration/Average Returns       -55.2696
evaluation/num steps total     477000
evaluation/num paths total       4770
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.341462
evaluation/Rewards Std              1.16074
evaluation/Rewards Max             -0.00177803
evaluation/Rewards Min            -10.2388
evaluation/Returns Mean           -34.1462
evaluation/Returns Std             31.535
evaluation/Returns Max             -4.4996
evaluation/Returns Min           -133.216
evaluation/Actions Mean             0.011549
evaluation/Actions Std              0.195219
evaluation/Actions Max              0.999416
evaluation/Actions Min             -0.997489
evaluation/Num Paths               15
evaluation/Average Returns        -34.1462
time/data storing (s)               0.00263861
time/evaluation sampling (s)        0.327904
time/exploration sampling (s)       0.143352
time/logging (s)                    0.00481057
time/saving (s)                     0.00185063
time/training (s)                   1.9181
time/epoch (s)                      2.39865
time/total (s)                    776.716
Epoch                             317
-----------------------------  ---------------
2019-04-22 23:40:13.623848 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 318 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.757348
trainer/QF2 Loss                    0.742081
trainer/Policy Loss                14.1863
trainer/Q1 Predictions Mean       -12.2529
trainer/Q1 Predictions Std         13.2299
trainer/Q1 Predictions Max         -6.87592
trainer/Q1 Predictions Min        -52.5353
trainer/Q2 Predictions Mean       -12.2693
trainer/Q2 Predictions Std         13.2372
trainer/Q2 Predictions Max         -6.92166
trainer/Q2 Predictions Min        -52.6418
trainer/Q Targets Mean            -12.2762
trainer/Q Targets Std              13.4546
trainer/Q Targets Max              -0.234183
trainer/Q Targets Min             -53.1124
trainer/Log Pis Mean                1.9824
trainer/Log Pis Std                 1.09171
trainer/Log Pis Max                 4.59753
trainer/Log Pis Min                -2.85759
trainer/Policy mu Mean              0.0252402
trainer/Policy mu Std               0.369304
trainer/Policy mu Max               2.86597
trainer/Policy mu Min              -1.04342
trainer/Policy log std Mean        -2.28159
trainer/Policy log std Std          0.306489
trainer/Policy log std Max         -0.842221
trainer/Policy log std Min         -2.91579
trainer/Alpha                       0.069611
trainer/Alpha Loss                 -0.0468904
exploration/num steps total    159700
exploration/num paths total      1597
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.534413
exploration/Rewards Std             0.640326
exploration/Rewards Max            -0.0108854
exploration/Rewards Min            -5.75368
exploration/Returns Mean          -53.4413
exploration/Returns Std            42.5614
exploration/Returns Max           -15.6352
exploration/Returns Min          -107.853
exploration/Actions Mean            0.000381484
exploration/Actions Std             0.194032
exploration/Actions Max             0.983884
exploration/Actions Min            -0.999434
exploration/Num Paths               5
exploration/Average Returns       -53.4413
evaluation/num steps total     478500
evaluation/num paths total       4785
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.263344
evaluation/Rewards Std              0.915853
evaluation/Rewards Max             -0.00560862
evaluation/Rewards Min             -9.28715
evaluation/Returns Mean           -26.3344
evaluation/Returns Std             27.6003
evaluation/Returns Max             -5.43174
evaluation/Returns Min           -123.182
evaluation/Actions Mean             0.00151532
evaluation/Actions Std              0.19201
evaluation/Actions Max              0.998665
evaluation/Actions Min             -0.998913
evaluation/Num Paths               15
evaluation/Average Returns        -26.3344
time/data storing (s)               0.00276353
time/evaluation sampling (s)        0.327584
time/exploration sampling (s)       0.139101
time/logging (s)                    0.00484006
time/saving (s)                     0.0100744
time/training (s)                   1.92809
time/epoch (s)                      2.41245
time/total (s)                    779.133
Epoch                             318
-----------------------------  ----------------
2019-04-22 23:40:16.055345 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 319 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0241289
trainer/QF2 Loss                    0.0215335
trainer/Policy Loss                15.4114
trainer/Q1 Predictions Mean       -13.373
trainer/Q1 Predictions Std         14.5627
trainer/Q1 Predictions Max         -6.88772
trainer/Q1 Predictions Min        -53.1232
trainer/Q2 Predictions Mean       -13.3729
trainer/Q2 Predictions Std         14.5322
trainer/Q2 Predictions Max         -6.88229
trainer/Q2 Predictions Min        -53.2252
trainer/Q Targets Mean            -13.4202
trainer/Q Targets Std              14.5195
trainer/Q Targets Max              -6.86446
trainer/Q Targets Min             -53.1149
trainer/Log Pis Mean                2.1255
trainer/Log Pis Std                 0.735238
trainer/Log Pis Max                 4.71681
trainer/Log Pis Min                 0.165471
trainer/Policy mu Mean             -0.0191443
trainer/Policy mu Std               0.481437
trainer/Policy mu Max               2.65316
trainer/Policy mu Min              -2.82556
trainer/Policy log std Mean        -2.23702
trainer/Policy log std Std          0.383072
trainer/Policy log std Max         -0.514034
trainer/Policy log std Min         -2.8774
trainer/Alpha                       0.0688927
trainer/Alpha Loss                  0.335712
exploration/num steps total    160200
exploration/num paths total      1602
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.538666
exploration/Rewards Std             1.10816
exploration/Rewards Max            -0.00134993
exploration/Rewards Min           -10.086
exploration/Returns Mean          -53.8666
exploration/Returns Std            35.6091
exploration/Returns Max           -13.5721
exploration/Returns Min          -113.653
exploration/Actions Mean            0.00694416
exploration/Actions Std             0.228884
exploration/Actions Max             0.997418
exploration/Actions Min            -0.999847
exploration/Num Paths               5
exploration/Average Returns       -53.8666
evaluation/num steps total     480000
evaluation/num paths total       4800
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.225531
evaluation/Rewards Std              0.942839
evaluation/Rewards Max             -0.00781814
evaluation/Rewards Min            -10.02
evaluation/Returns Mean           -22.5531
evaluation/Returns Std             13.7243
evaluation/Returns Max             -3.30701
evaluation/Returns Min            -53.8026
evaluation/Actions Mean            -0.0062992
evaluation/Actions Std              0.183441
evaluation/Actions Max              0.995321
evaluation/Actions Min             -0.999005
evaluation/Num Paths               15
evaluation/Average Returns        -22.5531
time/data storing (s)               0.00283332
time/evaluation sampling (s)        0.322988
time/exploration sampling (s)       0.141161
time/logging (s)                    0.00478962
time/saving (s)                     0.00197605
time/training (s)                   1.94828
time/epoch (s)                      2.42202
time/total (s)                    781.559
Epoch                             319
-----------------------------  ---------------
2019-04-22 23:40:18.470847 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 320 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0392298
trainer/QF2 Loss                    0.0372081
trainer/Policy Loss                15.9464
trainer/Q1 Predictions Mean       -14.0373
trainer/Q1 Predictions Std         15.5262
trainer/Q1 Predictions Max         -6.81609
trainer/Q1 Predictions Min        -53.5865
trainer/Q2 Predictions Mean       -14.0467
trainer/Q2 Predictions Std         15.5162
trainer/Q2 Predictions Max         -6.79499
trainer/Q2 Predictions Min        -53.6336
trainer/Q Targets Mean            -14.1415
trainer/Q Targets Std              15.5954
trainer/Q Targets Max              -6.91592
trainer/Q Targets Min             -53.9084
trainer/Log Pis Mean                2.01908
trainer/Log Pis Std                 1.0145
trainer/Log Pis Max                 5.84745
trainer/Log Pis Min                -0.940229
trainer/Policy mu Mean             -0.0446722
trainer/Policy mu Std               0.414037
trainer/Policy mu Max               2.59094
trainer/Policy mu Min              -2.36724
trainer/Policy log std Mean        -2.28537
trainer/Policy log std Std          0.333874
trainer/Policy log std Max         -0.680528
trainer/Policy log std Min         -2.76129
trainer/Alpha                       0.0703774
trainer/Alpha Loss                  0.0506249
exploration/num steps total    160700
exploration/num paths total      1607
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.305823
exploration/Rewards Std             1.02098
exploration/Rewards Max            -0.00566052
exploration/Rewards Min           -10.1131
exploration/Returns Mean          -30.5823
exploration/Returns Std            18.75
exploration/Returns Max           -11.0807
exploration/Returns Min           -64.0148
exploration/Actions Mean            0.0154218
exploration/Actions Std             0.224489
exploration/Actions Max             0.999772
exploration/Actions Min            -0.999539
exploration/Num Paths               5
exploration/Average Returns       -30.5823
evaluation/num steps total     481500
evaluation/num paths total       4815
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.394168
evaluation/Rewards Std              0.969939
evaluation/Rewards Max             -0.00676615
evaluation/Rewards Min             -9.54344
evaluation/Returns Mean           -39.4168
evaluation/Returns Std             36.9894
evaluation/Returns Max             -2.03519
evaluation/Returns Min           -127.029
evaluation/Actions Mean             0.0169481
evaluation/Actions Std              0.186995
evaluation/Actions Max              0.998914
evaluation/Actions Min             -0.997755
evaluation/Num Paths               15
evaluation/Average Returns        -39.4168
time/data storing (s)               0.00262287
time/evaluation sampling (s)        0.329139
time/exploration sampling (s)       0.140467
time/logging (s)                    0.0039303
time/saving (s)                     0.00158381
time/training (s)                   1.92745
time/epoch (s)                      2.4052
time/total (s)                    783.969
Epoch                             320
-----------------------------  ---------------
2019-04-22 23:40:20.904230 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 321 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0215519
trainer/QF2 Loss                    0.0251339
trainer/Policy Loss                16.6308
trainer/Q1 Predictions Mean       -14.8484
trainer/Q1 Predictions Std         16.4397
trainer/Q1 Predictions Max         -6.68458
trainer/Q1 Predictions Min        -53.3114
trainer/Q2 Predictions Mean       -14.8457
trainer/Q2 Predictions Std         16.452
trainer/Q2 Predictions Max         -6.67988
trainer/Q2 Predictions Min        -53.3783
trainer/Q Targets Mean            -14.8556
trainer/Q Targets Std              16.4353
trainer/Q Targets Max              -6.85964
trainer/Q Targets Min             -53.6241
trainer/Log Pis Mean                1.9078
trainer/Log Pis Std                 1.00869
trainer/Log Pis Max                 4.21635
trainer/Log Pis Min                -1.78162
trainer/Policy mu Mean             -0.038497
trainer/Policy mu Std               0.348226
trainer/Policy mu Max               1.55717
trainer/Policy mu Min              -2.54638
trainer/Policy log std Mean        -2.28224
trainer/Policy log std Std          0.302266
trainer/Policy log std Max         -0.493269
trainer/Policy log std Min         -2.80133
trainer/Alpha                       0.0684072
trainer/Alpha Loss                 -0.247319
exploration/num steps total    161200
exploration/num paths total      1612
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.378918
exploration/Rewards Std             0.700553
exploration/Rewards Max            -0.0137529
exploration/Rewards Min            -8.56473
exploration/Returns Mean          -37.8918
exploration/Returns Std            28.354
exploration/Returns Max           -12.8673
exploration/Returns Min           -90.4686
exploration/Actions Mean           -0.0164643
exploration/Actions Std             0.204314
exploration/Actions Max             0.982257
exploration/Actions Min            -0.997469
exploration/Num Paths               5
exploration/Average Returns       -37.8918
evaluation/num steps total     483000
evaluation/num paths total       4830
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.464315
evaluation/Rewards Std              1.15907
evaluation/Rewards Max             -0.00975995
evaluation/Rewards Min            -11.0603
evaluation/Returns Mean           -46.4315
evaluation/Returns Std             38.8947
evaluation/Returns Max             -8.54532
evaluation/Returns Min           -122.433
evaluation/Actions Mean            -0.0190216
evaluation/Actions Std              0.209004
evaluation/Actions Max              0.99805
evaluation/Actions Min             -0.998538
evaluation/Num Paths               15
evaluation/Average Returns        -46.4315
time/data storing (s)               0.00259305
time/evaluation sampling (s)        0.330492
time/exploration sampling (s)       0.14031
time/logging (s)                    0.00482965
time/saving (s)                     0.00188918
time/training (s)                   1.94468
time/epoch (s)                      2.4248
time/total (s)                    786.399
Epoch                             321
-----------------------------  ---------------
2019-04-22 23:40:23.313927 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 322 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.656713
trainer/QF2 Loss                    0.649349
trainer/Policy Loss                16.8817
trainer/Q1 Predictions Mean       -14.9714
trainer/Q1 Predictions Std         16.4848
trainer/Q1 Predictions Max         -6.71796
trainer/Q1 Predictions Min        -67.5312
trainer/Q2 Predictions Mean       -14.9738
trainer/Q2 Predictions Std         16.5208
trainer/Q2 Predictions Max         -6.68981
trainer/Q2 Predictions Min        -67.9887
trainer/Q Targets Mean            -15.0851
trainer/Q Targets Std              16.8521
trainer/Q Targets Max              -0.212776
trainer/Q Targets Min             -67.8047
trainer/Log Pis Mean                1.9849
trainer/Log Pis Std                 1.02633
trainer/Log Pis Max                 5.05976
trainer/Log Pis Min                -1.2764
trainer/Policy mu Mean             -0.0719014
trainer/Policy mu Std               0.482915
trainer/Policy mu Max               1.93151
trainer/Policy mu Min              -3.19532
trainer/Policy log std Mean        -2.23351
trainer/Policy log std Std          0.339285
trainer/Policy log std Max         -0.622476
trainer/Policy log std Min         -2.74328
trainer/Alpha                       0.0686647
trainer/Alpha Loss                 -0.040452
exploration/num steps total    161700
exploration/num paths total      1617
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.456933
exploration/Rewards Std             0.922552
exploration/Rewards Max            -0.00997661
exploration/Rewards Min            -7.06779
exploration/Returns Mean          -45.6933
exploration/Returns Std            30.9514
exploration/Returns Max           -21.6293
exploration/Returns Min          -106.888
exploration/Actions Mean            0.0210502
exploration/Actions Std             0.23776
exploration/Actions Max             0.997368
exploration/Actions Min            -0.99948
exploration/Num Paths               5
exploration/Average Returns       -45.6933
evaluation/num steps total     484500
evaluation/num paths total       4845
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.412991
evaluation/Rewards Std              0.990737
evaluation/Rewards Max             -0.0299444
evaluation/Rewards Min            -10.1314
evaluation/Returns Mean           -41.2991
evaluation/Returns Std             36.3451
evaluation/Returns Max            -11.6282
evaluation/Returns Min           -124.969
evaluation/Actions Mean            -0.00699166
evaluation/Actions Std              0.191267
evaluation/Actions Max              0.998494
evaluation/Actions Min             -0.995522
evaluation/Num Paths               15
evaluation/Average Returns        -41.2991
time/data storing (s)               0.00265787
time/evaluation sampling (s)        0.329506
time/exploration sampling (s)       0.139577
time/logging (s)                    0.00461248
time/saving (s)                     0.00198058
time/training (s)                   1.92264
time/epoch (s)                      2.40097
time/total (s)                    788.803
Epoch                             322
-----------------------------  ---------------
2019-04-22 23:40:25.731727 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 323 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.85256
trainer/QF2 Loss                    1.89878
trainer/Policy Loss                18.1846
trainer/Q1 Predictions Mean       -16.281
trainer/Q1 Predictions Std         17.4705
trainer/Q1 Predictions Max         -6.737
trainer/Q1 Predictions Min        -57.2747
trainer/Q2 Predictions Mean       -16.2401
trainer/Q2 Predictions Std         17.4788
trainer/Q2 Predictions Max         -6.69257
trainer/Q2 Predictions Min        -55.7349
trainer/Q Targets Mean            -16.7081
trainer/Q Targets Std              18.2928
trainer/Q Targets Max              -0.0502279
trainer/Q Targets Min             -59.405
trainer/Log Pis Mean                2.01686
trainer/Log Pis Std                 1.16641
trainer/Log Pis Max                 8.13647
trainer/Log Pis Min                -1.07994
trainer/Policy mu Mean             -0.0270576
trainer/Policy mu Std               0.530041
trainer/Policy mu Max               4.05322
trainer/Policy mu Min              -2.51153
trainer/Policy log std Mean        -2.20998
trainer/Policy log std Std          0.350812
trainer/Policy log std Max         -0.630526
trainer/Policy log std Min         -2.71249
trainer/Alpha                       0.0670706
trainer/Alpha Loss                  0.0455503
exploration/num steps total    162200
exploration/num paths total      1622
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.537052
exploration/Rewards Std             1.53407
exploration/Rewards Max            -0.0181993
exploration/Rewards Min           -11.2236
exploration/Returns Mean          -53.7052
exploration/Returns Std            19.7412
exploration/Returns Max           -17.3031
exploration/Returns Min           -76.2113
exploration/Actions Mean           -0.00746622
exploration/Actions Std             0.266376
exploration/Actions Max             0.999919
exploration/Actions Min            -0.999155
exploration/Num Paths               5
exploration/Average Returns       -53.7052
evaluation/num steps total     486000
evaluation/num paths total       4860
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.441809
evaluation/Rewards Std              1.02052
evaluation/Rewards Max             -0.0069948
evaluation/Rewards Min             -9.32267
evaluation/Returns Mean           -44.1809
evaluation/Returns Std             36.8656
evaluation/Returns Max             -5.67297
evaluation/Returns Min           -120.221
evaluation/Actions Mean            -0.00722875
evaluation/Actions Std              0.20047
evaluation/Actions Max              0.997213
evaluation/Actions Min             -0.998745
evaluation/Num Paths               15
evaluation/Average Returns        -44.1809
time/data storing (s)               0.00260708
time/evaluation sampling (s)        0.326689
time/exploration sampling (s)       0.14309
time/logging (s)                    0.00352595
time/saving (s)                     0.0018181
time/training (s)                   1.92984
time/epoch (s)                      2.40757
time/total (s)                    791.215
Epoch                             323
-----------------------------  ---------------
2019-04-22 23:40:28.166841 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 324 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.24592
trainer/QF2 Loss                    1.22659
trainer/Policy Loss                13.8771
trainer/Q1 Predictions Mean       -12.2214
trainer/Q1 Predictions Std         13.3627
trainer/Q1 Predictions Max         -6.65865
trainer/Q1 Predictions Min        -55.4939
trainer/Q2 Predictions Mean       -12.2308
trainer/Q2 Predictions Std         13.3927
trainer/Q2 Predictions Max         -6.66276
trainer/Q2 Predictions Min        -55.8389
trainer/Q Targets Mean            -12.1525
trainer/Q Targets Std              13.6436
trainer/Q Targets Max              -0.171535
trainer/Q Targets Min             -56.0418
trainer/Log Pis Mean                1.69205
trainer/Log Pis Std                 1.22738
trainer/Log Pis Max                 5.70214
trainer/Log Pis Min                -3.34416
trainer/Policy mu Mean             -0.0100583
trainer/Policy mu Std               0.487964
trainer/Policy mu Max               2.44581
trainer/Policy mu Min              -2.47777
trainer/Policy log std Mean        -2.199
trainer/Policy log std Std          0.374222
trainer/Policy log std Max         -0.443336
trainer/Policy log std Min         -2.64447
trainer/Alpha                       0.0672779
trainer/Alpha Loss                 -0.83112
exploration/num steps total    162700
exploration/num paths total      1627
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.195592
exploration/Rewards Std             0.414402
exploration/Rewards Max            -0.00511979
exploration/Rewards Min            -4.36644
exploration/Returns Mean          -19.5592
exploration/Returns Std             2.24258
exploration/Returns Max           -16.7627
exploration/Returns Min           -23.5219
exploration/Actions Mean           -0.00758796
exploration/Actions Std             0.203683
exploration/Actions Max             0.99894
exploration/Actions Min            -0.986028
exploration/Num Paths               5
exploration/Average Returns       -19.5592
evaluation/num steps total     487500
evaluation/num paths total       4875
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.298832
evaluation/Rewards Std              0.973567
evaluation/Rewards Max             -0.00844912
evaluation/Rewards Min             -8.52995
evaluation/Returns Mean           -29.8832
evaluation/Returns Std             26.672
evaluation/Returns Max             -7.5152
evaluation/Returns Min           -118.75
evaluation/Actions Mean            -0.010739
evaluation/Actions Std              0.188833
evaluation/Actions Max              0.998174
evaluation/Actions Min             -0.99758
evaluation/Num Paths               15
evaluation/Average Returns        -29.8832
time/data storing (s)               0.00282566
time/evaluation sampling (s)        0.331749
time/exploration sampling (s)       0.14174
time/logging (s)                    0.00484201
time/saving (s)                     0.00196394
time/training (s)                   1.94411
time/epoch (s)                      2.42723
time/total (s)                    793.646
Epoch                             324
-----------------------------  ---------------
2019-04-22 23:40:30.572240 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 325 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.30897
trainer/QF2 Loss                    1.30344
trainer/Policy Loss                14.6802
trainer/Q1 Predictions Mean       -12.6416
trainer/Q1 Predictions Std         13.9877
trainer/Q1 Predictions Max         -6.70337
trainer/Q1 Predictions Min        -57.195
trainer/Q2 Predictions Mean       -12.5928
trainer/Q2 Predictions Std         13.8972
trainer/Q2 Predictions Max         -6.65396
trainer/Q2 Predictions Min        -54.8396
trainer/Q Targets Mean            -12.6358
trainer/Q Targets Std              14.2698
trainer/Q Targets Max              -0.154752
trainer/Q Targets Min             -56.1986
trainer/Log Pis Mean                2.18641
trainer/Log Pis Std                 1.09548
trainer/Log Pis Max                 7.61057
trainer/Log Pis Min                -1.3416
trainer/Policy mu Mean             -0.000543485
trainer/Policy mu Std               0.475579
trainer/Policy mu Max               3.06708
trainer/Policy mu Min              -2.95547
trainer/Policy log std Mean        -2.30637
trainer/Policy log std Std          0.312556
trainer/Policy log std Max         -0.749533
trainer/Policy log std Min         -2.79483
trainer/Alpha                       0.0675839
trainer/Alpha Loss                  0.502312
exploration/num steps total    163200
exploration/num paths total      1632
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.472374
exploration/Rewards Std             0.981573
exploration/Rewards Max            -0.00125568
exploration/Rewards Min            -8.92446
exploration/Returns Mean          -47.2374
exploration/Returns Std            37.1989
exploration/Returns Max           -12.7254
exploration/Returns Min          -115.624
exploration/Actions Mean           -0.00121987
exploration/Actions Std             0.220023
exploration/Actions Max             0.997891
exploration/Actions Min            -0.998109
exploration/Num Paths               5
exploration/Average Returns       -47.2374
evaluation/num steps total     489000
evaluation/num paths total       4890
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.458842
evaluation/Rewards Std              1.16246
evaluation/Rewards Max             -0.0210662
evaluation/Rewards Min            -10.1523
evaluation/Returns Mean           -45.8842
evaluation/Returns Std             36.5189
evaluation/Returns Max             -3.86279
evaluation/Returns Min           -128.22
evaluation/Actions Mean             0.00836748
evaluation/Actions Std              0.199535
evaluation/Actions Max              0.999473
evaluation/Actions Min             -0.997927
evaluation/Num Paths               15
evaluation/Average Returns        -45.8842
time/data storing (s)               0.00274054
time/evaluation sampling (s)        0.321335
time/exploration sampling (s)       0.140207
time/logging (s)                    0.00476745
time/saving (s)                     0.00196467
time/training (s)                   1.92536
time/epoch (s)                      2.39637
time/total (s)                    796.048
Epoch                             325
-----------------------------  ----------------
2019-04-22 23:40:32.998357 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 326 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.709291
trainer/QF2 Loss                    0.715546
trainer/Policy Loss                16.1194
trainer/Q1 Predictions Mean       -14.2182
trainer/Q1 Predictions Std         15.4027
trainer/Q1 Predictions Max         -6.7567
trainer/Q1 Predictions Min        -52.2241
trainer/Q2 Predictions Mean       -14.2054
trainer/Q2 Predictions Std         15.4014
trainer/Q2 Predictions Max         -6.81714
trainer/Q2 Predictions Min        -52.3242
trainer/Q Targets Mean            -14.2868
trainer/Q Targets Std              15.6526
trainer/Q Targets Max              -0.140664
trainer/Q Targets Min             -53.038
trainer/Log Pis Mean                1.97634
trainer/Log Pis Std                 1.15445
trainer/Log Pis Max                 6.17194
trainer/Log Pis Min                -3.5645
trainer/Policy mu Mean             -0.0494302
trainer/Policy mu Std               0.544052
trainer/Policy mu Max               3.06011
trainer/Policy mu Min              -3.48695
trainer/Policy log std Mean        -2.22951
trainer/Policy log std Std          0.394228
trainer/Policy log std Max         -0.54605
trainer/Policy log std Min         -2.71803
trainer/Alpha                       0.0702879
trainer/Alpha Loss                 -0.0628301
exploration/num steps total    163700
exploration/num paths total      1637
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.475063
exploration/Rewards Std             1.42801
exploration/Rewards Max            -0.00211185
exploration/Rewards Min            -9.59234
exploration/Returns Mean          -47.5063
exploration/Returns Std            13.3422
exploration/Returns Max           -22.2064
exploration/Returns Min           -60.5446
exploration/Actions Mean           -0.00337342
exploration/Actions Std             0.264404
exploration/Actions Max             0.998878
exploration/Actions Min            -0.998406
exploration/Num Paths               5
exploration/Average Returns       -47.5063
evaluation/num steps total     490500
evaluation/num paths total       4905
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.305275
evaluation/Rewards Std              1.06382
evaluation/Rewards Max             -0.0164828
evaluation/Rewards Min             -9.57135
evaluation/Returns Mean           -30.5275
evaluation/Returns Std             32.1122
evaluation/Returns Max             -4.44174
evaluation/Returns Min           -139.308
evaluation/Actions Mean             0.00563471
evaluation/Actions Std              0.200595
evaluation/Actions Max              0.997567
evaluation/Actions Min             -0.998116
evaluation/Num Paths               15
evaluation/Average Returns        -30.5275
time/data storing (s)               0.00276668
time/evaluation sampling (s)        0.331126
time/exploration sampling (s)       0.139716
time/logging (s)                    0.00486037
time/saving (s)                     0.00155848
time/training (s)                   1.9369
time/epoch (s)                      2.41692
time/total (s)                    798.469
Epoch                             326
-----------------------------  ---------------
2019-04-22 23:40:35.432078 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 327 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.672245
trainer/QF2 Loss                    0.622771
trainer/Policy Loss                16.325
trainer/Q1 Predictions Mean       -14.6405
trainer/Q1 Predictions Std         15.7125
trainer/Q1 Predictions Max         -6.72588
trainer/Q1 Predictions Min        -50.6822
trainer/Q2 Predictions Mean       -14.6367
trainer/Q2 Predictions Std         15.7574
trainer/Q2 Predictions Max         -6.73301
trainer/Q2 Predictions Min        -50.8607
trainer/Q Targets Mean            -15.0282
trainer/Q Targets Std              16.4158
trainer/Q Targets Max              -6.79703
trainer/Q Targets Min             -52.6342
trainer/Log Pis Mean                1.77367
trainer/Log Pis Std                 0.953195
trainer/Log Pis Max                 3.25845
trainer/Log Pis Min                -2.09969
trainer/Policy mu Mean             -0.0550494
trainer/Policy mu Std               0.296866
trainer/Policy mu Max               0.644776
trainer/Policy mu Min              -2.04878
trainer/Policy log std Mean        -2.25342
trainer/Policy log std Std          0.279639
trainer/Policy log std Max         -0.917175
trainer/Policy log std Min         -2.71613
trainer/Alpha                       0.0715588
trainer/Alpha Loss                 -0.596857
exploration/num steps total    164200
exploration/num paths total      1642
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.331553
exploration/Rewards Std             0.970053
exploration/Rewards Max            -0.00446629
exploration/Rewards Min            -9.90343
exploration/Returns Mean          -33.1553
exploration/Returns Std            19.1957
exploration/Returns Max           -16.1076
exploration/Returns Min           -67.4523
exploration/Actions Mean           -0.0204902
exploration/Actions Std             0.224234
exploration/Actions Max             0.996375
exploration/Actions Min            -0.998194
exploration/Num Paths               5
exploration/Average Returns       -33.1553
evaluation/num steps total     492000
evaluation/num paths total       4920
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.406844
evaluation/Rewards Std              0.906669
evaluation/Rewards Max             -0.0228135
evaluation/Rewards Min            -10.0136
evaluation/Returns Mean           -40.6844
evaluation/Returns Std             38.6922
evaluation/Returns Max             -7.61397
evaluation/Returns Min           -122.472
evaluation/Actions Mean            -0.00684655
evaluation/Actions Std              0.179753
evaluation/Actions Max              0.997903
evaluation/Actions Min             -0.998745
evaluation/Num Paths               15
evaluation/Average Returns        -40.6844
time/data storing (s)               0.00272983
time/evaluation sampling (s)        0.32914
time/exploration sampling (s)       0.140583
time/logging (s)                    0.0048311
time/saving (s)                     0.00196204
time/training (s)                   1.94493
time/epoch (s)                      2.42418
time/total (s)                    800.897
Epoch                             327
-----------------------------  ---------------
2019-04-22 23:40:37.851730 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 328 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.752342
trainer/QF2 Loss                    0.749133
trainer/Policy Loss                17.9302
trainer/Q1 Predictions Mean       -15.7599
trainer/Q1 Predictions Std         17.2204
trainer/Q1 Predictions Max         -6.46403
trainer/Q1 Predictions Min        -72.9274
trainer/Q2 Predictions Mean       -15.7466
trainer/Q2 Predictions Std         17.2313
trainer/Q2 Predictions Max         -6.47058
trainer/Q2 Predictions Min        -72.8493
trainer/Q Targets Mean            -15.9106
trainer/Q Targets Std              17.4649
trainer/Q Targets Max              -0.121828
trainer/Q Targets Min             -73.0292
trainer/Log Pis Mean                2.28027
trainer/Log Pis Std                 1.09327
trainer/Log Pis Max                 6.19316
trainer/Log Pis Min                -1.67438
trainer/Policy mu Mean             -0.134612
trainer/Policy mu Std               0.663928
trainer/Policy mu Max               2.85703
trainer/Policy mu Min              -3.35206
trainer/Policy log std Mean        -2.17476
trainer/Policy log std Std          0.470408
trainer/Policy log std Max         -0.305677
trainer/Policy log std Min         -2.76389
trainer/Alpha                       0.0702465
trainer/Alpha Loss                  0.744336
exploration/num steps total    164700
exploration/num paths total      1647
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.235797
exploration/Rewards Std             0.728646
exploration/Rewards Max            -0.00268189
exploration/Rewards Min            -8.20566
exploration/Returns Mean          -23.5797
exploration/Returns Std            13.7281
exploration/Returns Max           -10.1348
exploration/Returns Min           -45.9454
exploration/Actions Mean            0.00901901
exploration/Actions Std             0.183935
exploration/Actions Max             0.997841
exploration/Actions Min            -0.991232
exploration/Num Paths               5
exploration/Average Returns       -23.5797
evaluation/num steps total     493500
evaluation/num paths total       4935
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.509236
evaluation/Rewards Std              1.25966
evaluation/Rewards Max             -0.00409236
evaluation/Rewards Min            -10.794
evaluation/Returns Mean           -50.9236
evaluation/Returns Std             44.3025
evaluation/Returns Max             -5.9559
evaluation/Returns Min           -143.541
evaluation/Actions Mean            -0.011136
evaluation/Actions Std              0.213045
evaluation/Actions Max              0.997242
evaluation/Actions Min             -0.99804
evaluation/Num Paths               15
evaluation/Average Returns        -50.9236
time/data storing (s)               0.00278353
time/evaluation sampling (s)        0.322087
time/exploration sampling (s)       0.144285
time/logging (s)                    0.00355071
time/saving (s)                     0.00155358
time/training (s)                   1.93506
time/epoch (s)                      2.40932
time/total (s)                    803.311
Epoch                             328
-----------------------------  ---------------
2019-04-22 23:40:40.256021 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 329 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.642306
trainer/QF2 Loss                    0.610915
trainer/Policy Loss                16.2218
trainer/Q1 Predictions Mean       -14.5189
trainer/Q1 Predictions Std         15.7538
trainer/Q1 Predictions Max         -6.66696
trainer/Q1 Predictions Min        -51.4186
trainer/Q2 Predictions Mean       -14.5527
trainer/Q2 Predictions Std         15.7831
trainer/Q2 Predictions Max         -6.68538
trainer/Q2 Predictions Min        -51.537
trainer/Q Targets Mean            -14.6942
trainer/Q Targets Std              16.0953
trainer/Q Targets Max              -0.14229
trainer/Q Targets Min             -52.6175
trainer/Log Pis Mean                1.81956
trainer/Log Pis Std                 1.11048
trainer/Log Pis Max                 3.64524
trainer/Log Pis Min                -2.06079
trainer/Policy mu Mean             -0.075935
trainer/Policy mu Std               0.416302
trainer/Policy mu Max               2.44588
trainer/Policy mu Min              -2.87453
trainer/Policy log std Mean        -2.25301
trainer/Policy log std Std          0.322005
trainer/Policy log std Max         -0.766837
trainer/Policy log std Min         -2.7009
trainer/Alpha                       0.070735
trainer/Alpha Loss                 -0.477959
exploration/num steps total    165200
exploration/num paths total      1652
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.539787
exploration/Rewards Std             1.17095
exploration/Rewards Max            -0.00269371
exploration/Rewards Min            -8.41648
exploration/Returns Mean          -53.9787
exploration/Returns Std            40.0235
exploration/Returns Max           -12.4348
exploration/Returns Min          -129.249
exploration/Actions Mean           -0.0138901
exploration/Actions Std             0.22566
exploration/Actions Max             0.998689
exploration/Actions Min            -0.998748
exploration/Num Paths               5
exploration/Average Returns       -53.9787
evaluation/num steps total     495000
evaluation/num paths total       4950
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.257423
evaluation/Rewards Std              0.98101
evaluation/Rewards Max             -0.0246801
evaluation/Rewards Min             -8.68946
evaluation/Returns Mean           -25.7423
evaluation/Returns Std             12.9725
evaluation/Returns Max             -8.96188
evaluation/Returns Min            -46.2906
evaluation/Actions Mean             0.00959193
evaluation/Actions Std              0.195997
evaluation/Actions Max              0.999257
evaluation/Actions Min             -0.99618
evaluation/Num Paths               15
evaluation/Average Returns        -25.7423
time/data storing (s)               0.00271474
time/evaluation sampling (s)        0.323483
time/exploration sampling (s)       0.138874
time/logging (s)                    0.00483392
time/saving (s)                     0.00205724
time/training (s)                   1.92555
time/epoch (s)                      2.39751
time/total (s)                    805.713
Epoch                             329
-----------------------------  ---------------
2019-04-22 23:40:42.695013 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 330 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.670714
trainer/QF2 Loss                    0.698655
trainer/Policy Loss                14.284
trainer/Q1 Predictions Mean       -12.2884
trainer/Q1 Predictions Std         13.8486
trainer/Q1 Predictions Max         -6.70376
trainer/Q1 Predictions Min        -79.5622
trainer/Q2 Predictions Mean       -12.3275
trainer/Q2 Predictions Std         13.8571
trainer/Q2 Predictions Max         -6.79607
trainer/Q2 Predictions Min        -80.1853
trainer/Q Targets Mean            -12.3787
trainer/Q Targets Std              13.9581
trainer/Q Targets Max              -0.0636315
trainer/Q Targets Min             -78.8526
trainer/Log Pis Mean                2.01226
trainer/Log Pis Std                 1.11555
trainer/Log Pis Max                 5.73677
trainer/Log Pis Min                -2.21508
trainer/Policy mu Mean             -0.0393613
trainer/Policy mu Std               0.509954
trainer/Policy mu Max               2.8324
trainer/Policy mu Min              -2.96054
trainer/Policy log std Mean        -2.20187
trainer/Policy log std Std          0.36518
trainer/Policy log std Max         -0.293947
trainer/Policy log std Min         -2.73788
trainer/Alpha                       0.0693916
trainer/Alpha Loss                  0.0327154
exploration/num steps total    165700
exploration/num paths total      1657
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.501933
exploration/Rewards Std             1.02813
exploration/Rewards Max            -0.00315777
exploration/Rewards Min            -8.29172
exploration/Returns Mean          -50.1933
exploration/Returns Std            34.8051
exploration/Returns Max           -15.9659
exploration/Returns Min          -116.669
exploration/Actions Mean            0.0113882
exploration/Actions Std             0.229156
exploration/Actions Max             0.998927
exploration/Actions Min            -0.999873
exploration/Num Paths               5
exploration/Average Returns       -50.1933
evaluation/num steps total     496500
evaluation/num paths total       4965
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.387817
evaluation/Rewards Std              0.926927
evaluation/Rewards Max             -0.00769142
evaluation/Rewards Min            -10.4294
evaluation/Returns Mean           -38.7817
evaluation/Returns Std             36.1025
evaluation/Returns Max             -7.02809
evaluation/Returns Min           -110.947
evaluation/Actions Mean            -0.00974168
evaluation/Actions Std              0.187978
evaluation/Actions Max              0.994804
evaluation/Actions Min             -0.997047
evaluation/Num Paths               15
evaluation/Average Returns        -38.7817
time/data storing (s)               0.00270952
time/evaluation sampling (s)        0.326168
time/exploration sampling (s)       0.140507
time/logging (s)                    0.00480257
time/saving (s)                     0.0100866
time/training (s)                   1.94522
time/epoch (s)                      2.4295
time/total (s)                    808.147
Epoch                             330
-----------------------------  ---------------
2019-04-22 23:40:45.125424 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 331 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.677593
trainer/QF2 Loss                    0.693107
trainer/Policy Loss                16.9943
trainer/Q1 Predictions Mean       -15.0409
trainer/Q1 Predictions Std         15.6837
trainer/Q1 Predictions Max         -6.82142
trainer/Q1 Predictions Min        -51.4642
trainer/Q2 Predictions Mean       -15.0769
trainer/Q2 Predictions Std         15.6879
trainer/Q2 Predictions Max         -6.86945
trainer/Q2 Predictions Min        -51.5456
trainer/Q Targets Mean            -15.2396
trainer/Q Targets Std              16.0561
trainer/Q Targets Max              -0.142754
trainer/Q Targets Min             -52.6255
trainer/Log Pis Mean                2.02544
trainer/Log Pis Std                 1.42157
trainer/Log Pis Max                 9.02881
trainer/Log Pis Min                -2.32951
trainer/Policy mu Mean             -0.0233508
trainer/Policy mu Std               0.600719
trainer/Policy mu Max               2.94032
trainer/Policy mu Min              -3.00963
trainer/Policy log std Mean        -2.22791
trainer/Policy log std Std          0.406011
trainer/Policy log std Max         -0.435956
trainer/Policy log std Min         -2.85756
trainer/Alpha                       0.068638
trainer/Alpha Loss                  0.0681614
exploration/num steps total    166200
exploration/num paths total      1662
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.461919
exploration/Rewards Std             1.03146
exploration/Rewards Max            -0.0149612
exploration/Rewards Min            -9.91117
exploration/Returns Mean          -46.1919
exploration/Returns Std            28.6094
exploration/Returns Max           -12.284
exploration/Returns Min           -93.7517
exploration/Actions Mean           -0.00148486
exploration/Actions Std             0.22744
exploration/Actions Max             0.999143
exploration/Actions Min            -0.998604
exploration/Num Paths               5
exploration/Average Returns       -46.1919
evaluation/num steps total     498000
evaluation/num paths total       4980
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.237647
evaluation/Rewards Std              1.02706
evaluation/Rewards Max             -0.00363986
evaluation/Rewards Min            -10.203
evaluation/Returns Mean           -23.7647
evaluation/Returns Std             16.1145
evaluation/Returns Max             -1.31775
evaluation/Returns Min            -54.6621
evaluation/Actions Mean             0.00246297
evaluation/Actions Std              0.198138
evaluation/Actions Max              0.999252
evaluation/Actions Min             -0.996403
evaluation/Num Paths               15
evaluation/Average Returns        -23.7647
time/data storing (s)               0.00279345
time/evaluation sampling (s)        0.324614
time/exploration sampling (s)       0.140923
time/logging (s)                    0.00479446
time/saving (s)                     0.00195058
time/training (s)                   1.94663
time/epoch (s)                      2.4217
time/total (s)                    810.573
Epoch                             331
-----------------------------  ---------------
2019-04-22 23:40:47.620377 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 332 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.73635
trainer/QF2 Loss                    0.714095
trainer/Policy Loss                16.703
trainer/Q1 Predictions Mean       -14.7125
trainer/Q1 Predictions Std         15.85
trainer/Q1 Predictions Max         -6.57334
trainer/Q1 Predictions Min        -50.6227
trainer/Q2 Predictions Mean       -14.7315
trainer/Q2 Predictions Std         15.8779
trainer/Q2 Predictions Max         -6.56226
trainer/Q2 Predictions Min        -50.6696
trainer/Q Targets Mean            -14.9742
trainer/Q Targets Std              16.3133
trainer/Q Targets Max              -0.298017
trainer/Q Targets Min             -51.923
trainer/Log Pis Mean                2.11668
trainer/Log Pis Std                 1.06845
trainer/Log Pis Max                 5.64857
trainer/Log Pis Min                -2.53747
trainer/Policy mu Mean             -0.0287186
trainer/Policy mu Std               0.396442
trainer/Policy mu Max               2.64378
trainer/Policy mu Min              -1.86943
trainer/Policy log std Mean        -2.29107
trainer/Policy log std Std          0.35073
trainer/Policy log std Max         -0.517106
trainer/Policy log std Min         -2.79159
trainer/Alpha                       0.0706612
trainer/Alpha Loss                  0.309192
exploration/num steps total    166700
exploration/num paths total      1667
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.350866
exploration/Rewards Std             0.995852
exploration/Rewards Max            -0.00681793
exploration/Rewards Min            -7.96926
exploration/Returns Mean          -35.0866
exploration/Returns Std             7.70223
exploration/Returns Max           -23.7717
exploration/Returns Min           -46.0516
exploration/Actions Mean            0.0255904
exploration/Actions Std             0.238538
exploration/Actions Max             0.999451
exploration/Actions Min            -0.995509
exploration/Num Paths               5
exploration/Average Returns       -35.0866
evaluation/num steps total     499500
evaluation/num paths total       4995
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.448627
evaluation/Rewards Std              1.28046
evaluation/Rewards Max             -0.0035946
evaluation/Rewards Min             -9.91277
evaluation/Returns Mean           -44.8627
evaluation/Returns Std             27.1847
evaluation/Returns Max             -2.84015
evaluation/Returns Min           -102.224
evaluation/Actions Mean            -0.00797842
evaluation/Actions Std              0.213895
evaluation/Actions Max              0.9996
evaluation/Actions Min             -0.997232
evaluation/Num Paths               15
evaluation/Average Returns        -44.8627
time/data storing (s)               0.00271759
time/evaluation sampling (s)        0.328173
time/exploration sampling (s)       0.140093
time/logging (s)                    0.00485553
time/saving (s)                     0.00194005
time/training (s)                   2.00778
time/epoch (s)                      2.48555
time/total (s)                    813.063
Epoch                             332
-----------------------------  ---------------
2019-04-22 23:40:50.042460 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 333 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.83117
trainer/QF2 Loss                    0.824227
trainer/Policy Loss                17.9284
trainer/Q1 Predictions Mean       -15.7746
trainer/Q1 Predictions Std         16.3661
trainer/Q1 Predictions Max         -6.52505
trainer/Q1 Predictions Min        -52.4599
trainer/Q2 Predictions Mean       -15.8135
trainer/Q2 Predictions Std         16.3674
trainer/Q2 Predictions Max         -6.5361
trainer/Q2 Predictions Min        -52.0193
trainer/Q Targets Mean            -15.9856
trainer/Q Targets Std              16.7191
trainer/Q Targets Max              -0.0738134
trainer/Q Targets Min             -52.5695
trainer/Log Pis Mean                2.25034
trainer/Log Pis Std                 1.08011
trainer/Log Pis Max                 6.27384
trainer/Log Pis Min                -1.79619
trainer/Policy mu Mean             -0.0966795
trainer/Policy mu Std               0.615379
trainer/Policy mu Max               2.74614
trainer/Policy mu Min              -3.28393
trainer/Policy log std Mean        -2.18485
trainer/Policy log std Std          0.452659
trainer/Policy log std Max         -0.600925
trainer/Policy log std Min         -2.72553
trainer/Alpha                       0.0708507
trainer/Alpha Loss                  0.662725
exploration/num steps total    167200
exploration/num paths total      1672
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.421765
exploration/Rewards Std             0.886197
exploration/Rewards Max            -0.00367226
exploration/Rewards Min            -9.70964
exploration/Returns Mean          -42.1765
exploration/Returns Std            26.1652
exploration/Returns Max           -17.8813
exploration/Returns Min           -85.6388
exploration/Actions Mean            0.00548431
exploration/Actions Std             0.217577
exploration/Actions Max             0.991344
exploration/Actions Min            -0.998845
exploration/Num Paths               5
exploration/Average Returns       -42.1765
evaluation/num steps total     501000
evaluation/num paths total       5010
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.244221
evaluation/Rewards Std              1.00041
evaluation/Rewards Max             -0.0107712
evaluation/Rewards Min            -10.7355
evaluation/Returns Mean           -24.4221
evaluation/Returns Std             14.6606
evaluation/Returns Max             -5.72074
evaluation/Returns Min            -50.2268
evaluation/Actions Mean            -0.00378118
evaluation/Actions Std              0.196856
evaluation/Actions Max              0.997982
evaluation/Actions Min             -0.998622
evaluation/Num Paths               15
evaluation/Average Returns        -24.4221
time/data storing (s)               0.0028061
time/evaluation sampling (s)        0.35327
time/exploration sampling (s)       0.146996
time/logging (s)                    0.00483286
time/saving (s)                     0.00199042
time/training (s)                   1.90308
time/epoch (s)                      2.41297
time/total (s)                    815.48
Epoch                             333
-----------------------------  ---------------
2019-04-22 23:40:52.457395 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 334 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.3286
trainer/QF2 Loss                    0.317464
trainer/Policy Loss                16.0593
trainer/Q1 Predictions Mean       -14.2847
trainer/Q1 Predictions Std         15.4038
trainer/Q1 Predictions Max         -6.7553
trainer/Q1 Predictions Min        -50.807
trainer/Q2 Predictions Mean       -14.2989
trainer/Q2 Predictions Std         15.41
trainer/Q2 Predictions Max         -6.78497
trainer/Q2 Predictions Min        -50.8393
trainer/Q Targets Mean            -14.5551
trainer/Q Targets Std              15.88
trainer/Q Targets Max              -6.62893
trainer/Q Targets Min             -51.9748
trainer/Log Pis Mean                1.91233
trainer/Log Pis Std                 0.950304
trainer/Log Pis Max                 3.35204
trainer/Log Pis Min                -1.6073
trainer/Policy mu Mean             -0.0673986
trainer/Policy mu Std               0.396326
trainer/Policy mu Max               2.50969
trainer/Policy mu Min              -2.10054
trainer/Policy log std Mean        -2.22908
trainer/Policy log std Std          0.324165
trainer/Policy log std Max         -0.6397
trainer/Policy log std Min         -2.66361
trainer/Alpha                       0.0704651
trainer/Alpha Loss                 -0.232536
exploration/num steps total    167700
exploration/num paths total      1677
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.327238
exploration/Rewards Std             0.99238
exploration/Rewards Max            -0.00123569
exploration/Rewards Min            -9.95809
exploration/Returns Mean          -32.7238
exploration/Returns Std            14.64
exploration/Returns Max           -16.3105
exploration/Returns Min           -54.3568
exploration/Actions Mean            0.00421505
exploration/Actions Std             0.229032
exploration/Actions Max             0.998536
exploration/Actions Min            -0.999002
exploration/Num Paths               5
exploration/Average Returns       -32.7238
evaluation/num steps total     502500
evaluation/num paths total       5025
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.298917
evaluation/Rewards Std              1.13637
evaluation/Rewards Max             -0.00884434
evaluation/Rewards Min             -9.92852
evaluation/Returns Mean           -29.8917
evaluation/Returns Std             14.0785
evaluation/Returns Max             -5.95547
evaluation/Returns Min            -51.8283
evaluation/Actions Mean             0.0110962
evaluation/Actions Std              0.202777
evaluation/Actions Max              0.998867
evaluation/Actions Min             -0.998242
evaluation/Num Paths               15
evaluation/Average Returns        -29.8917
time/data storing (s)               0.00274665
time/evaluation sampling (s)        0.333314
time/exploration sampling (s)       0.139736
time/logging (s)                    0.00379833
time/saving (s)                     0.00196195
time/training (s)                   1.92268
time/epoch (s)                      2.40423
time/total (s)                    817.889
Epoch                             334
-----------------------------  ---------------
2019-04-22 23:40:54.865020 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 335 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.452961
trainer/QF2 Loss                    0.486391
trainer/Policy Loss                15.3866
trainer/Q1 Predictions Mean       -13.5565
trainer/Q1 Predictions Std         14.773
trainer/Q1 Predictions Max         -6.59159
trainer/Q1 Predictions Min        -50.9079
trainer/Q2 Predictions Mean       -13.5773
trainer/Q2 Predictions Std         14.7517
trainer/Q2 Predictions Max         -6.64146
trainer/Q2 Predictions Min        -51.1912
trainer/Q Targets Mean            -13.5516
trainer/Q Targets Std              14.8568
trainer/Q Targets Max              -0.198539
trainer/Q Targets Min             -51.0205
trainer/Log Pis Mean                1.88944
trainer/Log Pis Std                 0.981555
trainer/Log Pis Max                 3.19969
trainer/Log Pis Min                -1.75673
trainer/Policy mu Mean             -0.0559618
trainer/Policy mu Std               0.331722
trainer/Policy mu Max               2.17334
trainer/Policy mu Min              -2.75969
trainer/Policy log std Mean        -2.29426
trainer/Policy log std Std          0.274098
trainer/Policy log std Max         -0.52644
trainer/Policy log std Min         -2.66994
trainer/Alpha                       0.0695406
trainer/Alpha Loss                 -0.294716
exploration/num steps total    168200
exploration/num paths total      1682
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.366968
exploration/Rewards Std             1.0828
exploration/Rewards Max            -0.00287644
exploration/Rewards Min            -9.65723
exploration/Returns Mean          -36.6968
exploration/Returns Std            18.5155
exploration/Returns Max           -14.5855
exploration/Returns Min           -67.7314
exploration/Actions Mean            0.020419
exploration/Actions Std             0.22444
exploration/Actions Max             0.999645
exploration/Actions Min            -0.975685
exploration/Num Paths               5
exploration/Average Returns       -36.6968
evaluation/num steps total     504000
evaluation/num paths total       5040
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.444516
evaluation/Rewards Std              0.964779
evaluation/Rewards Max             -0.0321941
evaluation/Rewards Min            -10.0165
evaluation/Returns Mean           -44.4516
evaluation/Returns Std             31.0547
evaluation/Returns Max             -7.7254
evaluation/Returns Min           -104.667
evaluation/Actions Mean             0.0167264
evaluation/Actions Std              0.187322
evaluation/Actions Max              0.997721
evaluation/Actions Min             -0.996982
evaluation/Num Paths               15
evaluation/Average Returns        -44.4516
time/data storing (s)               0.0026101
time/evaluation sampling (s)        0.329804
time/exploration sampling (s)       0.139757
time/logging (s)                    0.00486857
time/saving (s)                     0.00197565
time/training (s)                   1.92105
time/epoch (s)                      2.40006
time/total (s)                    820.293
Epoch                             335
-----------------------------  ---------------
2019-04-22 23:40:57.328327 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 336 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    2.30671
trainer/QF2 Loss                    2.31173
trainer/Policy Loss                16.1268
trainer/Q1 Predictions Mean       -14.2151
trainer/Q1 Predictions Std         14.6835
trainer/Q1 Predictions Max         -6.70429
trainer/Q1 Predictions Min        -50.9024
trainer/Q2 Predictions Mean       -14.1948
trainer/Q2 Predictions Std         14.6595
trainer/Q2 Predictions Max         -6.69661
trainer/Q2 Predictions Min        -50.0451
trainer/Q Targets Mean            -14.1983
trainer/Q Targets Std              15.2921
trainer/Q Targets Max              -0.144642
trainer/Q Targets Min             -51.3856
trainer/Log Pis Mean                1.99272
trainer/Log Pis Std                 1.28472
trainer/Log Pis Max                 6.08031
trainer/Log Pis Min                -1.41204
trainer/Policy mu Mean             -0.012917
trainer/Policy mu Std               0.655906
trainer/Policy mu Max               3.12389
trainer/Policy mu Min              -2.90816
trainer/Policy log std Mean        -2.21656
trainer/Policy log std Std          0.458144
trainer/Policy log std Max         -0.277453
trainer/Policy log std Min         -2.7264
trainer/Alpha                       0.0699429
trainer/Alpha Loss                 -0.0193754
exploration/num steps total    168700
exploration/num paths total      1687
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.316678
exploration/Rewards Std             0.981392
exploration/Rewards Max            -0.00988138
exploration/Rewards Min            -8.70694
exploration/Returns Mean          -31.6678
exploration/Returns Std            13.5266
exploration/Returns Max           -13.7559
exploration/Returns Min           -53.6981
exploration/Actions Mean            0.0249463
exploration/Actions Std             0.218142
exploration/Actions Max             0.998353
exploration/Actions Min            -0.995696
exploration/Num Paths               5
exploration/Average Returns       -31.6678
evaluation/num steps total     505500
evaluation/num paths total       5055
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.38581
evaluation/Rewards Std              0.970675
evaluation/Rewards Max             -0.0116704
evaluation/Rewards Min             -9.48684
evaluation/Returns Mean           -38.581
evaluation/Returns Std             37.7416
evaluation/Returns Max             -5.92938
evaluation/Returns Min           -121.603
evaluation/Actions Mean            -0.00671716
evaluation/Actions Std              0.188187
evaluation/Actions Max              0.99907
evaluation/Actions Min             -0.998041
evaluation/Num Paths               15
evaluation/Average Returns        -38.581
time/data storing (s)               0.00282369
time/evaluation sampling (s)        0.333126
time/exploration sampling (s)       0.141651
time/logging (s)                    0.00428939
time/saving (s)                     0.00195531
time/training (s)                   1.96934
time/epoch (s)                      2.45319
time/total (s)                    822.751
Epoch                             336
-----------------------------  ---------------
2019-04-22 23:40:59.757956 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 337 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.278248
trainer/QF2 Loss                    0.421099
trainer/Policy Loss                17.3756
trainer/Q1 Predictions Mean       -15.209
trainer/Q1 Predictions Std         15.9053
trainer/Q1 Predictions Max         -6.59664
trainer/Q1 Predictions Min        -57.3871
trainer/Q2 Predictions Mean       -15.2024
trainer/Q2 Predictions Std         15.8436
trainer/Q2 Predictions Max         -6.56347
trainer/Q2 Predictions Min        -54.6866
trainer/Q Targets Mean            -15.5239
trainer/Q Targets Std              16.281
trainer/Q Targets Max              -6.63596
trainer/Q Targets Min             -58.814
trainer/Log Pis Mean                2.25063
trainer/Log Pis Std                 1.29805
trainer/Log Pis Max                 7.04564
trainer/Log Pis Min                -1.77049
trainer/Policy mu Mean              0.031547
trainer/Policy mu Std               0.673436
trainer/Policy mu Max               4.08115
trainer/Policy mu Min              -2.86388
trainer/Policy log std Mean        -2.21378
trainer/Policy log std Std          0.435916
trainer/Policy log std Max         -0.362489
trainer/Policy log std Min         -2.63597
trainer/Alpha                       0.0692567
trainer/Alpha Loss                  0.669182
exploration/num steps total    169200
exploration/num paths total      1692
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.409795
exploration/Rewards Std             0.651208
exploration/Rewards Max            -0.00287823
exploration/Rewards Min            -5.66179
exploration/Returns Mean          -40.9795
exploration/Returns Std            31.3565
exploration/Returns Max           -16.8747
exploration/Returns Min          -102.835
exploration/Actions Mean           -0.0067698
exploration/Actions Std             0.205458
exploration/Actions Max             0.998648
exploration/Actions Min            -0.996617
exploration/Num Paths               5
exploration/Average Returns       -40.9795
evaluation/num steps total     507000
evaluation/num paths total       5070
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.191988
evaluation/Rewards Std              0.755642
evaluation/Rewards Max             -0.0184894
evaluation/Rewards Min            -10.0043
evaluation/Returns Mean           -19.1988
evaluation/Returns Std             12.9329
evaluation/Returns Max             -4.42222
evaluation/Returns Min            -51.8391
evaluation/Actions Mean             0.00233816
evaluation/Actions Std              0.167854
evaluation/Actions Max              0.998728
evaluation/Actions Min             -0.995203
evaluation/Num Paths               15
evaluation/Average Returns        -19.1988
time/data storing (s)               0.00280774
time/evaluation sampling (s)        0.335924
time/exploration sampling (s)       0.141618
time/logging (s)                    0.00491745
time/saving (s)                     0.00195215
time/training (s)                   1.93402
time/epoch (s)                      2.42124
time/total (s)                    825.176
Epoch                             337
-----------------------------  ---------------
2019-04-22 23:41:02.188833 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 338 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.640929
trainer/QF2 Loss                    0.649524
trainer/Policy Loss                15.1096
trainer/Q1 Predictions Mean       -13.126
trainer/Q1 Predictions Std         13.7439
trainer/Q1 Predictions Max         -6.71235
trainer/Q1 Predictions Min        -50.4464
trainer/Q2 Predictions Mean       -13.1547
trainer/Q2 Predictions Std         13.7448
trainer/Q2 Predictions Max         -6.74435
trainer/Q2 Predictions Min        -50.4841
trainer/Q Targets Mean            -13.1659
trainer/Q Targets Std              13.8845
trainer/Q Targets Max              -0.126604
trainer/Q Targets Min             -50.9927
trainer/Log Pis Mean                2.02892
trainer/Log Pis Std                 1.10118
trainer/Log Pis Max                 6.35889
trainer/Log Pis Min                -1.21084
trainer/Policy mu Mean              0.0459833
trainer/Policy mu Std               0.532754
trainer/Policy mu Max               3.21656
trainer/Policy mu Min              -2.3977
trainer/Policy log std Mean        -2.22338
trainer/Policy log std Std          0.374895
trainer/Policy log std Max         -0.64551
trainer/Policy log std Min         -2.67979
trainer/Alpha                       0.0700196
trainer/Alpha Loss                  0.0769076
exploration/num steps total    169700
exploration/num paths total      1697
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.222123
exploration/Rewards Std             0.721977
exploration/Rewards Max            -0.00617017
exploration/Rewards Min            -8.8163
exploration/Returns Mean          -22.2123
exploration/Returns Std            14.8245
exploration/Returns Max           -12.5964
exploration/Returns Min           -51.6654
exploration/Actions Mean            0.0145072
exploration/Actions Std             0.189481
exploration/Actions Max             0.99855
exploration/Actions Min            -0.963997
exploration/Num Paths               5
exploration/Average Returns       -22.2123
evaluation/num steps total     508500
evaluation/num paths total       5085
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.340095
evaluation/Rewards Std              1.12238
evaluation/Rewards Max             -0.00418078
evaluation/Rewards Min            -10.0376
evaluation/Returns Mean           -34.0095
evaluation/Returns Std             26.8867
evaluation/Returns Max             -5.52716
evaluation/Returns Min           -125.693
evaluation/Actions Mean             0.00379502
evaluation/Actions Std              0.207954
evaluation/Actions Max              0.996836
evaluation/Actions Min             -0.998879
evaluation/Num Paths               15
evaluation/Average Returns        -34.0095
time/data storing (s)               0.00277426
time/evaluation sampling (s)        0.330352
time/exploration sampling (s)       0.140488
time/logging (s)                    0.00480332
time/saving (s)                     0.00197012
time/training (s)                   1.9416
time/epoch (s)                      2.42199
time/total (s)                    827.602
Epoch                             338
-----------------------------  ---------------
2019-04-22 23:41:04.617501 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 339 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.618531
trainer/QF2 Loss                    0.60928
trainer/Policy Loss                15.5219
trainer/Q1 Predictions Mean       -13.6401
trainer/Q1 Predictions Std         14.5504
trainer/Q1 Predictions Max         -6.54016
trainer/Q1 Predictions Min        -50.3639
trainer/Q2 Predictions Mean       -13.6282
trainer/Q2 Predictions Std         14.5672
trainer/Q2 Predictions Max         -6.50176
trainer/Q2 Predictions Min        -50.2325
trainer/Q Targets Mean            -13.7498
trainer/Q Targets Std              14.8745
trainer/Q Targets Max              -0.192082
trainer/Q Targets Min             -51.1931
trainer/Log Pis Mean                1.95827
trainer/Log Pis Std                 1.03702
trainer/Log Pis Max                 6.02233
trainer/Log Pis Min                -1.80523
trainer/Policy mu Mean              0.0150986
trainer/Policy mu Std               0.513257
trainer/Policy mu Max               3.02796
trainer/Policy mu Min              -2.60019
trainer/Policy log std Mean        -2.20766
trainer/Policy log std Std          0.388092
trainer/Policy log std Max         -0.507433
trainer/Policy log std Min         -2.66134
trainer/Alpha                       0.0701647
trainer/Alpha Loss                 -0.110875
exploration/num steps total    170200
exploration/num paths total      1702
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.651064
exploration/Rewards Std             0.934065
exploration/Rewards Max            -0.00330679
exploration/Rewards Min            -8.11831
exploration/Returns Mean          -65.1064
exploration/Returns Std            41.6201
exploration/Returns Max           -13.1561
exploration/Returns Min          -123.901
exploration/Actions Mean           -0.0130744
exploration/Actions Std             0.212036
exploration/Actions Max             0.939269
exploration/Actions Min            -0.998511
exploration/Num Paths               5
exploration/Average Returns       -65.1064
evaluation/num steps total     510000
evaluation/num paths total       5100
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.337964
evaluation/Rewards Std              0.831231
evaluation/Rewards Max             -0.0168033
evaluation/Rewards Min             -9.7339
evaluation/Returns Mean           -33.7964
evaluation/Returns Std             32.449
evaluation/Returns Max             -6.43697
evaluation/Returns Min           -114.414
evaluation/Actions Mean            -4.1331e-05
evaluation/Actions Std              0.170043
evaluation/Actions Max              0.99941
evaluation/Actions Min             -0.997913
evaluation/Num Paths               15
evaluation/Average Returns        -33.7964
time/data storing (s)               0.00278198
time/evaluation sampling (s)        0.323309
time/exploration sampling (s)       0.138952
time/logging (s)                    0.00482557
time/saving (s)                     0.00195518
time/training (s)                   1.94725
time/epoch (s)                      2.41908
time/total (s)                    830.026
Epoch                             339
-----------------------------  ---------------
2019-04-22 23:41:07.034405 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 340 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.582354
trainer/QF2 Loss                    0.598388
trainer/Policy Loss                16.6935
trainer/Q1 Predictions Mean       -14.5516
trainer/Q1 Predictions Std         15.626
trainer/Q1 Predictions Max         -6.73633
trainer/Q1 Predictions Min        -53.1311
trainer/Q2 Predictions Mean       -14.5282
trainer/Q2 Predictions Std         15.6162
trainer/Q2 Predictions Max         -6.75708
trainer/Q2 Predictions Min        -53.1132
trainer/Q Targets Mean            -14.646
trainer/Q Targets Std              15.9171
trainer/Q Targets Max              -0.0298124
trainer/Q Targets Min             -53.074
trainer/Log Pis Mean                2.26005
trainer/Log Pis Std                 1.12029
trainer/Log Pis Max                 7.6616
trainer/Log Pis Min                -1.33502
trainer/Policy mu Mean             -0.0171209
trainer/Policy mu Std               0.536573
trainer/Policy mu Max               3.67359
trainer/Policy mu Min              -2.40841
trainer/Policy log std Mean        -2.26604
trainer/Policy log std Std          0.35257
trainer/Policy log std Max         -0.469502
trainer/Policy log std Min         -2.7113
trainer/Alpha                       0.0702753
trainer/Alpha Loss                  0.690565
exploration/num steps total    170700
exploration/num paths total      1707
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.31078
exploration/Rewards Std             1.07723
exploration/Rewards Max            -0.00779554
exploration/Rewards Min           -12.0761
exploration/Returns Mean          -31.078
exploration/Returns Std            22.2681
exploration/Returns Max           -12.1081
exploration/Returns Min           -74.3039
exploration/Actions Mean            0.00126261
exploration/Actions Std             0.230445
exploration/Actions Max             0.995294
exploration/Actions Min            -0.999574
exploration/Num Paths               5
exploration/Average Returns       -31.078
evaluation/num steps total     511500
evaluation/num paths total       5115
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.26543
evaluation/Rewards Std              1.09663
evaluation/Rewards Max             -0.0146823
evaluation/Rewards Min            -10.3669
evaluation/Returns Mean           -26.543
evaluation/Returns Std             16.3028
evaluation/Returns Max             -4.87689
evaluation/Returns Min            -59.4965
evaluation/Actions Mean            -0.00905618
evaluation/Actions Std              0.204324
evaluation/Actions Max              0.99746
evaluation/Actions Min             -0.997723
evaluation/Num Paths               15
evaluation/Average Returns        -26.543
time/data storing (s)               0.0027619
time/evaluation sampling (s)        0.332795
time/exploration sampling (s)       0.144188
time/logging (s)                    0.00475251
time/saving (s)                     0.00196818
time/training (s)                   1.92157
time/epoch (s)                      2.40804
time/total (s)                    832.437
Epoch                             340
-----------------------------  ---------------
2019-04-22 23:41:09.449900 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 341 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0419018
trainer/QF2 Loss                    0.0419453
trainer/Policy Loss                15.4371
trainer/Q1 Predictions Mean       -13.4761
trainer/Q1 Predictions Std         14.3059
trainer/Q1 Predictions Max         -6.50653
trainer/Q1 Predictions Min        -50.5996
trainer/Q2 Predictions Mean       -13.4775
trainer/Q2 Predictions Std         14.3097
trainer/Q2 Predictions Max         -6.54804
trainer/Q2 Predictions Min        -50.519
trainer/Q Targets Mean            -13.5731
trainer/Q Targets Std              14.3599
trainer/Q Targets Max              -6.48502
trainer/Q Targets Min             -50.9474
trainer/Log Pis Mean                2.0523
trainer/Log Pis Std                 1.31919
trainer/Log Pis Max                 7.6726
trainer/Log Pis Min                -1.15681
trainer/Policy mu Mean             -0.0822051
trainer/Policy mu Std               0.599084
trainer/Policy mu Max               3.08548
trainer/Policy mu Min              -2.59401
trainer/Policy log std Mean        -2.17295
trainer/Policy log std Std          0.438811
trainer/Policy log std Max         -0.49831
trainer/Policy log std Min         -2.66983
trainer/Alpha                       0.0685642
trainer/Alpha Loss                  0.140163
exploration/num steps total    171200
exploration/num paths total      1712
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.697493
exploration/Rewards Std             1.24352
exploration/Rewards Max            -0.00887035
exploration/Rewards Min           -10.2495
exploration/Returns Mean          -69.7493
exploration/Returns Std            26.7801
exploration/Returns Max           -39.3918
exploration/Returns Min          -109.273
exploration/Actions Mean           -0.00192263
exploration/Actions Std             0.249066
exploration/Actions Max             0.999868
exploration/Actions Min            -0.999531
exploration/Num Paths               5
exploration/Average Returns       -69.7493
evaluation/num steps total     513000
evaluation/num paths total       5130
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.373394
evaluation/Rewards Std              1.06575
evaluation/Rewards Max             -0.00359652
evaluation/Rewards Min             -9.53933
evaluation/Returns Mean           -37.3394
evaluation/Returns Std             28.981
evaluation/Returns Max             -4.45101
evaluation/Returns Min           -107.782
evaluation/Actions Mean            -0.0158762
evaluation/Actions Std              0.195602
evaluation/Actions Max              0.998328
evaluation/Actions Min             -0.999249
evaluation/Num Paths               15
evaluation/Average Returns        -37.3394
time/data storing (s)               0.00271119
time/evaluation sampling (s)        0.313635
time/exploration sampling (s)       0.141311
time/logging (s)                    0.0047767
time/saving (s)                     0.00200976
time/training (s)                   1.94329
time/epoch (s)                      2.40773
time/total (s)                    834.849
Epoch                             341
-----------------------------  ---------------
2019-04-22 23:41:11.884036 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 342 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.145786
trainer/QF2 Loss                    0.135415
trainer/Policy Loss                14.1488
trainer/Q1 Predictions Mean       -12.3712
trainer/Q1 Predictions Std         13.5954
trainer/Q1 Predictions Max         -6.48833
trainer/Q1 Predictions Min        -49.6189
trainer/Q2 Predictions Mean       -12.396
trainer/Q2 Predictions Std         13.5864
trainer/Q2 Predictions Max         -6.5237
trainer/Q2 Predictions Min        -49.7453
trainer/Q Targets Mean            -12.609
trainer/Q Targets Std              13.8646
trainer/Q Targets Max              -6.50891
trainer/Q Targets Min             -50.8245
trainer/Log Pis Mean                1.87669
trainer/Log Pis Std                 1.07078
trainer/Log Pis Max                 3.3702
trainer/Log Pis Min                -3.83238
trainer/Policy mu Mean             -0.0827184
trainer/Policy mu Std               0.345054
trainer/Policy mu Max               1.86865
trainer/Policy mu Min              -2.93107
trainer/Policy log std Mean        -2.27284
trainer/Policy log std Std          0.334098
trainer/Policy log std Max         -0.522027
trainer/Policy log std Min         -2.71831
trainer/Alpha                       0.0687642
trainer/Alpha Loss                 -0.330121
exploration/num steps total    171700
exploration/num paths total      1717
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.525511
exploration/Rewards Std             0.680427
exploration/Rewards Max            -0.00509714
exploration/Rewards Min            -5.73507
exploration/Returns Mean          -52.5511
exploration/Returns Std            36.8467
exploration/Returns Max           -13.2881
exploration/Returns Min          -103.806
exploration/Actions Mean            0.00617847
exploration/Actions Std             0.182748
exploration/Actions Max             0.993317
exploration/Actions Min            -0.999359
exploration/Num Paths               5
exploration/Average Returns       -52.5511
evaluation/num steps total     514500
evaluation/num paths total       5145
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.222356
evaluation/Rewards Std              0.950599
evaluation/Rewards Max             -0.011972
evaluation/Rewards Min            -10.4486
evaluation/Returns Mean           -22.2356
evaluation/Returns Std             17.1196
evaluation/Returns Max             -3.41238
evaluation/Returns Min            -55.2088
evaluation/Actions Mean             0.0152551
evaluation/Actions Std              0.187727
evaluation/Actions Max              0.997624
evaluation/Actions Min             -0.997632
evaluation/Num Paths               15
evaluation/Average Returns        -22.2356
time/data storing (s)               0.00278973
time/evaluation sampling (s)        0.327084
time/exploration sampling (s)       0.140163
time/logging (s)                    0.00554146
time/saving (s)                     0.00220542
time/training (s)                   1.94748
time/epoch (s)                      2.42527
time/total (s)                    837.279
Epoch                             342
-----------------------------  ---------------
2019-04-22 23:41:14.316234 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 343 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.782757
trainer/QF2 Loss                    0.788751
trainer/Policy Loss                15.8953
trainer/Q1 Predictions Mean       -14.008
trainer/Q1 Predictions Std         15.1515
trainer/Q1 Predictions Max         -6.36572
trainer/Q1 Predictions Min        -49.8552
trainer/Q2 Predictions Mean       -13.97
trainer/Q2 Predictions Std         15.157
trainer/Q2 Predictions Max         -6.3448
trainer/Q2 Predictions Min        -49.8739
trainer/Q Targets Mean            -14.1665
trainer/Q Targets Std              15.3752
trainer/Q Targets Max              -0.108184
trainer/Q Targets Min             -50.481
trainer/Log Pis Mean                1.95873
trainer/Log Pis Std                 1.02919
trainer/Log Pis Max                 4.99906
trainer/Log Pis Min                -0.907107
trainer/Policy mu Mean             -0.0727872
trainer/Policy mu Std               0.364463
trainer/Policy mu Max               1.8475
trainer/Policy mu Min              -2.79139
trainer/Policy log std Mean        -2.32511
trainer/Policy log std Std          0.316647
trainer/Policy log std Max         -0.605289
trainer/Policy log std Min         -2.72593
trainer/Alpha                       0.0687601
trainer/Alpha Loss                 -0.110484
exploration/num steps total    172200
exploration/num paths total      1722
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.313787
exploration/Rewards Std             0.993386
exploration/Rewards Max            -0.00743571
exploration/Rewards Min           -10.7497
exploration/Returns Mean          -31.3787
exploration/Returns Std            19.4367
exploration/Returns Max           -13.0422
exploration/Returns Min           -68.026
exploration/Actions Mean           -0.0304396
exploration/Actions Std             0.231852
exploration/Actions Max             0.986616
exploration/Actions Min            -0.998421
exploration/Num Paths               5
exploration/Average Returns       -31.3787
evaluation/num steps total     516000
evaluation/num paths total       5160
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.413309
evaluation/Rewards Std              1.04598
evaluation/Rewards Max             -0.0164737
evaluation/Rewards Min             -9.23126
evaluation/Returns Mean           -41.3309
evaluation/Returns Std             37.9237
evaluation/Returns Max             -3.64588
evaluation/Returns Min           -124.476
evaluation/Actions Mean             0.00173651
evaluation/Actions Std              0.192615
evaluation/Actions Max              0.998925
evaluation/Actions Min             -0.997696
evaluation/Num Paths               15
evaluation/Average Returns        -41.3309
time/data storing (s)               0.00260979
time/evaluation sampling (s)        0.327458
time/exploration sampling (s)       0.140582
time/logging (s)                    0.00477016
time/saving (s)                     0.0019986
time/training (s)                   1.943
time/epoch (s)                      2.42042
time/total (s)                    839.704
Epoch                             343
-----------------------------  ---------------
2019-04-22 23:41:16.892286 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 344 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.69819
trainer/QF2 Loss                    1.6917
trainer/Policy Loss                14.0934
trainer/Q1 Predictions Mean       -12.1521
trainer/Q1 Predictions Std         13.0483
trainer/Q1 Predictions Max         -6.46412
trainer/Q1 Predictions Min        -51.402
trainer/Q2 Predictions Mean       -12.1313
trainer/Q2 Predictions Std         13.0492
trainer/Q2 Predictions Max         -6.42485
trainer/Q2 Predictions Min        -51.5694
trainer/Q Targets Mean            -12.1104
trainer/Q Targets Std              13.3355
trainer/Q Targets Max              -0.125918
trainer/Q Targets Min             -51.5664
trainer/Log Pis Mean                2.00312
trainer/Log Pis Std                 1.1742
trainer/Log Pis Max                 7.71212
trainer/Log Pis Min                -0.815128
trainer/Policy mu Mean             -0.0249587
trainer/Policy mu Std               0.613721
trainer/Policy mu Max               3.22308
trainer/Policy mu Min              -3.29662
trainer/Policy log std Mean        -2.21085
trainer/Policy log std Std          0.439873
trainer/Policy log std Max         -0.38403
trainer/Policy log std Min         -2.69999
trainer/Alpha                       0.068418
trainer/Alpha Loss                  0.00837925
exploration/num steps total    172700
exploration/num paths total      1727
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.483202
exploration/Rewards Std             1.34172
exploration/Rewards Max            -0.00486456
exploration/Rewards Min            -8.78534
exploration/Returns Mean          -48.3202
exploration/Returns Std             5.06305
exploration/Returns Max           -43.5339
exploration/Returns Min           -57.3806
exploration/Actions Mean           -0.0161094
exploration/Actions Std             0.255962
exploration/Actions Max             0.999722
exploration/Actions Min            -0.99965
exploration/Num Paths               5
exploration/Average Returns       -48.3202
evaluation/num steps total     517500
evaluation/num paths total       5175
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.591327
evaluation/Rewards Std              1.10989
evaluation/Rewards Max             -0.00286563
evaluation/Rewards Min             -9.8002
evaluation/Returns Mean           -59.1327
evaluation/Returns Std             47.5282
evaluation/Returns Max             -6.97814
evaluation/Returns Min           -131.897
evaluation/Actions Mean            -0.00348736
evaluation/Actions Std              0.196756
evaluation/Actions Max              0.999583
evaluation/Actions Min             -0.999329
evaluation/Num Paths               15
evaluation/Average Returns        -59.1327
time/data storing (s)               0.00286027
time/evaluation sampling (s)        0.332149
time/exploration sampling (s)       0.142445
time/logging (s)                    0.00492237
time/saving (s)                     0.00207644
time/training (s)                   2.08217
time/epoch (s)                      2.56662
time/total (s)                    842.275
Epoch                             344
-----------------------------  ---------------
2019-04-22 23:41:19.489677 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 345 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.124918
trainer/QF2 Loss                    0.107826
trainer/Policy Loss                15.4151
trainer/Q1 Predictions Mean       -13.548
trainer/Q1 Predictions Std         14.9057
trainer/Q1 Predictions Max         -6.33207
trainer/Q1 Predictions Min        -49.8626
trainer/Q2 Predictions Mean       -13.5525
trainer/Q2 Predictions Std         14.9136
trainer/Q2 Predictions Max         -6.3475
trainer/Q2 Predictions Min        -49.9737
trainer/Q Targets Mean            -13.7681
trainer/Q Targets Std              15.1337
trainer/Q Targets Max              -6.42356
trainer/Q Targets Min             -50.7897
trainer/Log Pis Mean                1.96539
trainer/Log Pis Std                 1.09518
trainer/Log Pis Max                 4.39094
trainer/Log Pis Min                -1.99971
trainer/Policy mu Mean             -0.0381831
trainer/Policy mu Std               0.418784
trainer/Policy mu Max               2.36328
trainer/Policy mu Min              -1.97558
trainer/Policy log std Mean        -2.27776
trainer/Policy log std Std          0.34542
trainer/Policy log std Max         -0.728741
trainer/Policy log std Min         -2.72004
trainer/Alpha                       0.0684042
trainer/Alpha Loss                 -0.0928417
exploration/num steps total    173200
exploration/num paths total      1732
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.393981
exploration/Rewards Std             1.13626
exploration/Rewards Max            -0.00701088
exploration/Rewards Min            -8.34592
exploration/Returns Mean          -39.3981
exploration/Returns Std             8.71739
exploration/Returns Max           -29.6176
exploration/Returns Min           -52.7812
exploration/Actions Mean           -0.000988751
exploration/Actions Std             0.241326
exploration/Actions Max             0.998457
exploration/Actions Min            -0.999509
exploration/Num Paths               5
exploration/Average Returns       -39.3981
evaluation/num steps total     519000
evaluation/num paths total       5190
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.255285
evaluation/Rewards Std              1.11458
evaluation/Rewards Max             -0.00919567
evaluation/Rewards Min            -10.2782
evaluation/Returns Mean           -25.5285
evaluation/Returns Std             18.2012
evaluation/Returns Max             -2.50315
evaluation/Returns Min            -57.1722
evaluation/Actions Mean            -0.00682531
evaluation/Actions Std              0.198025
evaluation/Actions Max              0.99862
evaluation/Actions Min             -0.998263
evaluation/Num Paths               15
evaluation/Average Returns        -25.5285
time/data storing (s)               0.00294207
time/evaluation sampling (s)        0.363848
time/exploration sampling (s)       0.162491
time/logging (s)                    0.00477089
time/saving (s)                     0.00191718
time/training (s)                   2.05125
time/epoch (s)                      2.58722
time/total (s)                    844.867
Epoch                             345
-----------------------------  ----------------
2019-04-22 23:41:21.899878 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 346 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.510291
trainer/QF2 Loss                    0.519539
trainer/Policy Loss                13.5541
trainer/Q1 Predictions Mean       -11.3637
trainer/Q1 Predictions Std         12.9617
trainer/Q1 Predictions Max         -6.3354
trainer/Q1 Predictions Min        -68.8211
trainer/Q2 Predictions Mean       -11.364
trainer/Q2 Predictions Std         12.9472
trainer/Q2 Predictions Max         -6.34917
trainer/Q2 Predictions Min        -68.6336
trainer/Q Targets Mean            -11.4324
trainer/Q Targets Std              13.0314
trainer/Q Targets Max              -0.114671
trainer/Q Targets Min             -68.5553
trainer/Log Pis Mean                2.28597
trainer/Log Pis Std                 0.916758
trainer/Log Pis Max                 4.0119
trainer/Log Pis Min                -3.16137
trainer/Policy mu Mean             -0.0361003
trainer/Policy mu Std               0.475158
trainer/Policy mu Max               3.06842
trainer/Policy mu Min              -3.10511
trainer/Policy log std Mean        -2.30452
trainer/Policy log std Std          0.353796
trainer/Policy log std Max         -0.617843
trainer/Policy log std Min         -2.6734
trainer/Alpha                       0.0670938
trainer/Alpha Loss                  0.772616
exploration/num steps total    173700
exploration/num paths total      1737
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.315511
exploration/Rewards Std             0.984109
exploration/Rewards Max            -0.00399047
exploration/Rewards Min            -8.58673
exploration/Returns Mean          -31.5511
exploration/Returns Std            14.6165
exploration/Returns Max           -10.4512
exploration/Returns Min           -50.6892
exploration/Actions Mean           -0.0161608
exploration/Actions Std             0.217276
exploration/Actions Max             0.99302
exploration/Actions Min            -0.999349
exploration/Num Paths               5
exploration/Average Returns       -31.5511
evaluation/num steps total     520500
evaluation/num paths total       5205
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.283225
evaluation/Rewards Std              1.10483
evaluation/Rewards Max             -0.00390921
evaluation/Rewards Min            -10.4169
evaluation/Returns Mean           -28.3225
evaluation/Returns Std             16.1975
evaluation/Returns Max             -7.01581
evaluation/Returns Min            -63.0098
evaluation/Actions Mean             0.0120008
evaluation/Actions Std              0.202212
evaluation/Actions Max              0.999432
evaluation/Actions Min             -0.998443
evaluation/Num Paths               15
evaluation/Average Returns        -28.3225
time/data storing (s)               0.00283895
time/evaluation sampling (s)        0.325324
time/exploration sampling (s)       0.139061
time/logging (s)                    0.00478037
time/saving (s)                     0.00175357
time/training (s)                   1.9268
time/epoch (s)                      2.40056
time/total (s)                    847.272
Epoch                             346
-----------------------------  ---------------
2019-04-22 23:41:24.327769 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 347 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.193572
trainer/QF2 Loss                    0.177963
trainer/Policy Loss                17.0589
trainer/Q1 Predictions Mean       -15.2242
trainer/Q1 Predictions Std         15.7432
trainer/Q1 Predictions Max         -6.43848
trainer/Q1 Predictions Min        -49.7105
trainer/Q2 Predictions Mean       -15.2687
trainer/Q2 Predictions Std         15.7623
trainer/Q2 Predictions Max         -6.46737
trainer/Q2 Predictions Min        -49.8989
trainer/Q Targets Mean            -15.4375
trainer/Q Targets Std              16.0894
trainer/Q Targets Max              -6.34331
trainer/Q Targets Min             -50.6259
trainer/Log Pis Mean                1.90732
trainer/Log Pis Std                 1.06412
trainer/Log Pis Max                 5.10523
trainer/Log Pis Min                -2.74845
trainer/Policy mu Mean             -0.0764459
trainer/Policy mu Std               0.521855
trainer/Policy mu Max               3.2456
trainer/Policy mu Min              -2.79465
trainer/Policy log std Mean        -2.2118
trainer/Policy log std Std          0.398245
trainer/Policy log std Max         -0.517984
trainer/Policy log std Min         -2.70632
trainer/Alpha                       0.0679542
trainer/Alpha Loss                 -0.249224
exploration/num steps total    174200
exploration/num paths total      1742
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.637646
exploration/Rewards Std             1.08506
exploration/Rewards Max            -0.00937988
exploration/Rewards Min           -10.8808
exploration/Returns Mean          -63.7646
exploration/Returns Std            39.2307
exploration/Returns Max           -11.8949
exploration/Returns Min          -114.6
exploration/Actions Mean            0.0179188
exploration/Actions Std             0.20689
exploration/Actions Max             0.999984
exploration/Actions Min            -0.996016
exploration/Num Paths               5
exploration/Average Returns       -63.7646
evaluation/num steps total     522000
evaluation/num paths total       5220
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.48482
evaluation/Rewards Std              0.914291
evaluation/Rewards Max             -0.0209094
evaluation/Rewards Min             -9.64906
evaluation/Returns Mean           -48.482
evaluation/Returns Std             37.4818
evaluation/Returns Max             -4.33241
evaluation/Returns Min           -102.143
evaluation/Actions Mean            -0.00145958
evaluation/Actions Std              0.164292
evaluation/Actions Max              0.997107
evaluation/Actions Min             -0.998085
evaluation/Num Paths               15
evaluation/Average Returns        -48.482
time/data storing (s)               0.00269177
time/evaluation sampling (s)        0.326907
time/exploration sampling (s)       0.140361
time/logging (s)                    0.00480692
time/saving (s)                     0.00199897
time/training (s)                   1.94157
time/epoch (s)                      2.41833
time/total (s)                    849.695
Epoch                             347
-----------------------------  ---------------
2019-04-22 23:41:26.784926 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 348 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0376119
trainer/QF2 Loss                    0.0420311
trainer/Policy Loss                16.3621
trainer/Q1 Predictions Mean       -14.3911
trainer/Q1 Predictions Std         14.9781
trainer/Q1 Predictions Max         -6.41155
trainer/Q1 Predictions Min        -49.9804
trainer/Q2 Predictions Mean       -14.3736
trainer/Q2 Predictions Std         14.9972
trainer/Q2 Predictions Max         -6.35444
trainer/Q2 Predictions Min        -49.9348
trainer/Q Targets Mean            -14.4794
trainer/Q Targets Std              14.9597
trainer/Q Targets Max              -6.30375
trainer/Q Targets Min             -49.7087
trainer/Log Pis Mean                2.05829
trainer/Log Pis Std                 1.09572
trainer/Log Pis Max                 6.3282
trainer/Log Pis Min                -1.33042
trainer/Policy mu Mean              0.00379346
trainer/Policy mu Std               0.55202
trainer/Policy mu Max               2.90022
trainer/Policy mu Min              -2.79175
trainer/Policy log std Mean        -2.20007
trainer/Policy log std Std          0.406915
trainer/Policy log std Max         -0.498099
trainer/Policy log std Min         -2.71022
trainer/Alpha                       0.0706093
trainer/Alpha Loss                  0.15452
exploration/num steps total    174700
exploration/num paths total      1747
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.282799
exploration/Rewards Std             0.778579
exploration/Rewards Max            -0.00995338
exploration/Rewards Min            -7.38012
exploration/Returns Mean          -28.2799
exploration/Returns Std             8.53932
exploration/Returns Max           -16.1436
exploration/Returns Min           -38.0355
exploration/Actions Mean            0.016366
exploration/Actions Std             0.224182
exploration/Actions Max             0.999276
exploration/Actions Min            -0.99636
exploration/Num Paths               5
exploration/Average Returns       -28.2799
evaluation/num steps total     523500
evaluation/num paths total       5235
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.293235
evaluation/Rewards Std              0.888926
evaluation/Rewards Max             -0.0233713
evaluation/Rewards Min             -7.61772
evaluation/Returns Mean           -29.3235
evaluation/Returns Std             26.9944
evaluation/Returns Max             -8.32387
evaluation/Returns Min           -125.623
evaluation/Actions Mean            -0.00679206
evaluation/Actions Std              0.192268
evaluation/Actions Max              0.996144
evaluation/Actions Min             -0.998699
evaluation/Num Paths               15
evaluation/Average Returns        -29.3235
time/data storing (s)               0.00276568
time/evaluation sampling (s)        0.324554
time/exploration sampling (s)       0.140572
time/logging (s)                    0.00438141
time/saving (s)                     0.00250467
time/training (s)                   1.97243
time/epoch (s)                      2.44721
time/total (s)                    852.147
Epoch                             348
-----------------------------  ---------------
2019-04-22 23:41:29.204374 PDT | [sac-pointmass-multitask-7_2019_04_22_23_27_13_0000--s-0] Epoch 349 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.40373
trainer/QF2 Loss                    1.40749
trainer/Policy Loss                15.6073
trainer/Q1 Predictions Mean       -13.5654
trainer/Q1 Predictions Std         14.3239
trainer/Q1 Predictions Max         -6.38999
trainer/Q1 Predictions Min        -50.0089
trainer/Q2 Predictions Mean       -13.5544
trainer/Q2 Predictions Std         14.3548
trainer/Q2 Predictions Max         -6.41209
trainer/Q2 Predictions Min        -49.7539
trainer/Q Targets Mean            -13.526
trainer/Q Targets Std              14.6816
trainer/Q Targets Max              -0.0200122
trainer/Q Targets Min             -49.9432
trainer/Log Pis Mean                2.11316
trainer/Log Pis Std                 1.37669
trainer/Log Pis Max                 8.04815
trainer/Log Pis Min                -3.78176
trainer/Policy mu Mean             -0.0677212
trainer/Policy mu Std               0.618062
trainer/Policy mu Max               2.86411
trainer/Policy mu Min              -3.12711
trainer/Policy log std Mean        -2.19919
trainer/Policy log std Std          0.43869
trainer/Policy log std Max         -0.502278
trainer/Policy log std Min         -2.63805
trainer/Alpha                       0.0679986
trainer/Alpha Loss                  0.304198
exploration/num steps total    175200
exploration/num paths total      1752
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.269941
exploration/Rewards Std             0.882952
exploration/Rewards Max            -0.00365892
exploration/Rewards Min           -10.7247
exploration/Returns Mean          -26.9941
exploration/Returns Std            17.4095
exploration/Returns Max           -15.4277
exploration/Returns Min           -61.5108
exploration/Actions Mean            0.0115385
exploration/Actions Std             0.213861
exploration/Actions Max             0.998389
exploration/Actions Min            -0.999512
exploration/Num Paths               5
exploration/Average Returns       -26.9941
evaluation/num steps total     525000
evaluation/num paths total       5250
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.415049
evaluation/Rewards Std              1.00424
evaluation/Rewards Max             -0.0106512
evaluation/Rewards Min            -10.417
evaluation/Returns Mean           -41.5049
evaluation/Returns Std             39.8866
evaluation/Returns Max             -7.2291
evaluation/Returns Min           -122.968
evaluation/Actions Mean             0.00512137
evaluation/Actions Std              0.188399
evaluation/Actions Max              0.999255
evaluation/Actions Min             -0.997758
evaluation/Num Paths               15
evaluation/Average Returns        -41.5049
time/data storing (s)               0.00273659
time/evaluation sampling (s)        0.326871
time/exploration sampling (s)       0.139193
time/logging (s)                    0.0047716
time/saving (s)                     0.00196441
time/training (s)                   1.93454
time/epoch (s)                      2.41007
time/total (s)                    854.561
Epoch                             349
-----------------------------  ---------------
