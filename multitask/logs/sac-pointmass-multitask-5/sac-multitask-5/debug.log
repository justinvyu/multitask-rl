2019-04-22 22:10:00.867294 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 0 finished
-----------------------------  ---------------
replay_buffer/size               700
trainer/QF1 Loss                  61.8441
trainer/QF2 Loss                  61.7951
trainer/Policy Loss               -1.34205
trainer/Q1 Predictions Mean        0.00216287
trainer/Q1 Predictions Std         0.000874931
trainer/Q1 Predictions Max         0.00435973
trainer/Q1 Predictions Min         0.000170843
trainer/Q2 Predictions Mean       -0.00129413
trainer/Q2 Predictions Std         0.000790882
trainer/Q2 Predictions Max         0.000682114
trainer/Q2 Predictions Min        -0.0035328
trainer/Q Targets Mean            -7.19599
trainer/Q Targets Std              3.16737
trainer/Q Targets Max             -0.525833
trainer/Q Targets Min            -12.692
trainer/Log Pis Mean              -1.34331
trainer/Log Pis Std                0.298959
trainer/Log Pis Max               -0.541009
trainer/Log Pis Min               -1.97514
trainer/Policy mu Mean             0.000338623
trainer/Policy mu Std              0.000508924
trainer/Policy mu Max              0.00101245
trainer/Policy mu Min             -0.00112704
trainer/Policy log std Mean        0.000830949
trainer/Policy log std Std         0.000539073
trainer/Policy log std Max         0.00169324
trainer/Policy log std Min        -0.000857572
trainer/Alpha                      0.9997
trainer/Alpha Loss                -0
exploration/num steps total      700
exploration/num paths total        7
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -5.96928
exploration/Rewards Std            2.79722
exploration/Rewards Max           -0.0860386
exploration/Rewards Min          -11.1184
exploration/Returns Mean        -596.928
exploration/Returns Std          216.344
exploration/Returns Max         -375.131
exploration/Returns Min         -972.78
exploration/Actions Mean          -0.0216303
exploration/Actions Std            0.62368
exploration/Actions Max            0.995294
exploration/Actions Min           -0.99807
exploration/Num Paths              5
exploration/Average Returns     -596.928
evaluation/num steps total      1500
evaluation/num paths total        15
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -6.54534
evaluation/Rewards Std             2.65929
evaluation/Rewards Max            -1.26395
evaluation/Rewards Min           -10.7066
evaluation/Returns Mean         -654.534
evaluation/Returns Std           265.924
evaluation/Returns Max          -126.445
evaluation/Returns Min         -1065.13
evaluation/Actions Mean            0.000189038
evaluation/Actions Std             0.000563578
evaluation/Actions Max             0.00101791
evaluation/Actions Min            -0.00122776
evaluation/Num Paths              15
evaluation/Average Returns      -654.534
time/data storing (s)              0.00400125
time/evaluation sampling (s)       0.318987
time/exploration sampling (s)      0.161205
time/logging (s)                   0.00537036
time/saving (s)                    0.00230341
time/training (s)                  2.13907
time/epoch (s)                     2.63093
time/total (s)                     2.87762
Epoch                              0
-----------------------------  ---------------
2019-04-22 22:10:03.510786 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 1 finished
-----------------------------  -------------
replay_buffer/size             1200
trainer/QF1 Loss                  2.31507
trainer/QF2 Loss                  2.85378
trainer/Policy Loss              10.8631
trainer/Q1 Predictions Mean     -12.2275
trainer/Q1 Predictions Std        4.07289
trainer/Q1 Predictions Max       -5.97589
trainer/Q1 Predictions Min      -22.094
trainer/Q2 Predictions Mean     -12.2017
trainer/Q2 Predictions Std        4.00172
trainer/Q2 Predictions Max       -6.2627
trainer/Q2 Predictions Min      -22.0899
trainer/Q Targets Mean          -12.5741
trainer/Q Targets Std             4.32828
trainer/Q Targets Max            -5.34723
trainer/Q Targets Min           -21.8345
trainer/Log Pis Mean             -1.23089
trainer/Log Pis Std               0.414921
trainer/Log Pis Max              -0.240579
trainer/Log Pis Min              -2.30667
trainer/Policy mu Mean            0.0747372
trainer/Policy mu Std             0.256667
trainer/Policy mu Max             0.628101
trainer/Policy mu Min            -0.467383
trainer/Policy log std Mean      -0.165206
trainer/Policy log std Std        0.0383157
trainer/Policy log std Max       -0.103369
trainer/Policy log std Min       -0.280821
trainer/Alpha                     0.861135
trainer/Alpha Loss               -0.482089
exploration/num steps total    1200
exploration/num paths total      12
exploration/path length Mean    100
exploration/path length Std       0
exploration/path length Max     100
exploration/path length Min     100
exploration/Rewards Mean         -4.71908
exploration/Rewards Std           2.00173
exploration/Rewards Max          -0.210235
exploration/Rewards Min          -9.94223
exploration/Returns Mean       -471.908
exploration/Returns Std          96.6668
exploration/Returns Max        -338.033
exploration/Returns Min        -585.288
exploration/Actions Mean          0.0120847
exploration/Actions Std           0.58152
exploration/Actions Max           0.991136
exploration/Actions Min          -0.988108
exploration/Num Paths             5
exploration/Average Returns    -471.908
evaluation/num steps total     3000
evaluation/num paths total       30
evaluation/path length Mean     100
evaluation/path length Std        0
evaluation/path length Max      100
evaluation/path length Min      100
evaluation/Rewards Mean          -4.95884
evaluation/Rewards Std            1.16715
evaluation/Rewards Max           -0.787666
evaluation/Rewards Min          -11.6054
evaluation/Returns Mean        -495.884
evaluation/Returns Std           69.0721
evaluation/Returns Max         -387.653
evaluation/Returns Min         -594.894
evaluation/Actions Mean           0.00261972
evaluation/Actions Std            0.0834302
evaluation/Actions Max            0.47957
evaluation/Actions Min           -0.453882
evaluation/Num Paths             15
evaluation/Average Returns     -495.884
time/data storing (s)             0.00319451
time/evaluation sampling (s)      0.346755
time/exploration sampling (s)     0.156608
time/logging (s)                  0.00516165
time/saving (s)                   0.00236786
time/training (s)                 2.12351
time/epoch (s)                    2.6376
time/total (s)                    5.52007
Epoch                             1
-----------------------------  -------------
2019-04-22 22:10:06.206408 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 2 finished
-----------------------------  --------------
replay_buffer/size             1700
trainer/QF1 Loss                  1.46403
trainer/QF2 Loss                  1.40528
trainer/Policy Loss              17.586
trainer/Q1 Predictions Mean     -19.3634
trainer/Q1 Predictions Std        7.26947
trainer/Q1 Predictions Max      -11.3557
trainer/Q1 Predictions Min      -39.4296
trainer/Q2 Predictions Mean     -19.3015
trainer/Q2 Predictions Std        7.22016
trainer/Q2 Predictions Max      -11.1815
trainer/Q2 Predictions Min      -39.7046
trainer/Q Targets Mean          -19.748
trainer/Q Targets Std             7.30932
trainer/Q Targets Max           -11.0006
trainer/Q Targets Min           -39.7024
trainer/Log Pis Mean             -0.77084
trainer/Log Pis Std               0.921726
trainer/Log Pis Max               1.80187
trainer/Log Pis Min              -2.42845
trainer/Policy mu Mean            0.0586666
trainer/Policy mu Std             0.598884
trainer/Policy mu Max             1.44892
trainer/Policy mu Min            -1.12605
trainer/Policy log std Mean      -0.350157
trainer/Policy log std Std        0.0701133
trainer/Policy log std Max       -0.233395
trainer/Policy log std Min       -0.561498
trainer/Alpha                     0.753594
trainer/Alpha Loss               -0.783187
exploration/num steps total    1700
exploration/num paths total      17
exploration/path length Mean    100
exploration/path length Std       0
exploration/path length Max     100
exploration/path length Min     100
exploration/Rewards Mean         -3.98034
exploration/Rewards Std           1.65417
exploration/Rewards Max          -0.842619
exploration/Rewards Min          -9.15414
exploration/Returns Mean       -398.034
exploration/Returns Std         135.916
exploration/Returns Max        -278.592
exploration/Returns Min        -577.116
exploration/Actions Mean         -2.06327e-06
exploration/Actions Std           0.569155
exploration/Actions Max           0.993219
exploration/Actions Min          -0.977666
exploration/Num Paths             5
exploration/Average Returns    -398.034
evaluation/num steps total     4500
evaluation/num paths total       45
evaluation/path length Mean     100
evaluation/path length Std        0
evaluation/path length Max      100
evaluation/path length Min      100
evaluation/Rewards Mean          -4.15611
evaluation/Rewards Std            1.63076
evaluation/Rewards Max           -1.73526
evaluation/Rewards Min           -9.83401
evaluation/Returns Mean        -415.611
evaluation/Returns Std          146.335
evaluation/Returns Max         -240.686
evaluation/Returns Min         -596.526
evaluation/Actions Mean           0.00434791
evaluation/Actions Std            0.139257
evaluation/Actions Max            0.906497
evaluation/Actions Min           -0.876031
evaluation/Num Paths             15
evaluation/Average Returns     -415.611
time/data storing (s)             0.00327166
time/evaluation sampling (s)      0.394537
time/exploration sampling (s)     0.164194
time/logging (s)                  0.00502463
time/saving (s)                   0.00219524
time/training (s)                 2.1208
time/epoch (s)                    2.69002
time/total (s)                    8.21478
Epoch                             2
-----------------------------  --------------
2019-04-22 22:10:08.876838 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 3 finished
-----------------------------  -------------
replay_buffer/size             2200
trainer/QF1 Loss                 11.708
trainer/QF2 Loss                 11.6816
trainer/Policy Loss              25.4597
trainer/Q1 Predictions Mean     -27.231
trainer/Q1 Predictions Std       10.4082
trainer/Q1 Predictions Max      -13.9272
trainer/Q1 Predictions Min      -51.1216
trainer/Q2 Predictions Mean     -27.2776
trainer/Q2 Predictions Std       10.4788
trainer/Q2 Predictions Max      -13.9753
trainer/Q2 Predictions Min      -51.3151
trainer/Q Targets Mean          -27.2695
trainer/Q Targets Std            11.0617
trainer/Q Targets Max            -3.0163
trainer/Q Targets Min           -52.6672
trainer/Log Pis Mean             -0.439568
trainer/Log Pis Std               1.2778
trainer/Log Pis Max               2.55235
trainer/Log Pis Min              -4.10684
trainer/Policy mu Mean            0.196363
trainer/Policy mu Std             0.75651
trainer/Policy mu Max             1.58009
trainer/Policy mu Min            -1.49097
trainer/Policy log std Mean      -0.441994
trainer/Policy log std Std        0.0821736
trainer/Policy log std Max       -0.254621
trainer/Policy log std Min       -0.649983
trainer/Alpha                     0.66391
trainer/Alpha Loss               -0.99867
exploration/num steps total    2200
exploration/num paths total      22
exploration/path length Mean    100
exploration/path length Std       0
exploration/path length Max     100
exploration/path length Min     100
exploration/Rewards Mean         -4.65108
exploration/Rewards Std           2.78808
exploration/Rewards Max          -0.0971437
exploration/Rewards Min         -10.0537
exploration/Returns Mean       -465.108
exploration/Returns Std         263.724
exploration/Returns Max        -138.219
exploration/Returns Min        -723.168
exploration/Actions Mean          0.00395108
exploration/Actions Std           0.536612
exploration/Actions Max           0.982506
exploration/Actions Min          -0.98307
exploration/Num Paths             5
exploration/Average Returns    -465.108
evaluation/num steps total     6000
evaluation/num paths total       60
evaluation/path length Mean     100
evaluation/path length Std        0
evaluation/path length Max      100
evaluation/path length Min      100
evaluation/Rewards Mean          -4.25133
evaluation/Rewards Std            2.69071
evaluation/Rewards Max           -1.19295
evaluation/Rewards Min           -9.7624
evaluation/Returns Mean        -425.133
evaluation/Returns Std          256.545
evaluation/Returns Max         -125.792
evaluation/Returns Min         -717.911
evaluation/Actions Mean           0.0135541
evaluation/Actions Std            0.158857
evaluation/Actions Max            0.933273
evaluation/Actions Min           -0.933966
evaluation/Num Paths             15
evaluation/Average Returns     -425.133
time/data storing (s)             0.00346172
time/evaluation sampling (s)      0.352321
time/exploration sampling (s)     0.157849
time/logging (s)                  0.00485608
time/saving (s)                   0.0024055
time/training (s)                 2.14412
time/epoch (s)                    2.66501
time/total (s)                   10.8844
Epoch                             3
-----------------------------  -------------
2019-04-22 22:10:11.583276 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 4 finished
-----------------------------  -------------
replay_buffer/size             2700
trainer/QF1 Loss                 25.6108
trainer/QF2 Loss                 25.822
trainer/Policy Loss              31.7797
trainer/Q1 Predictions Mean     -33.9373
trainer/Q1 Predictions Std       13.3481
trainer/Q1 Predictions Max      -15.9359
trainer/Q1 Predictions Min      -69.2564
trainer/Q2 Predictions Mean     -33.9077
trainer/Q2 Predictions Std       13.3388
trainer/Q2 Predictions Max      -15.9185
trainer/Q2 Predictions Min      -68.764
trainer/Q Targets Mean          -33.5737
trainer/Q Targets Std            13.8463
trainer/Q Targets Max            -6.24209
trainer/Q Targets Min           -66.4275
trainer/Log Pis Mean             -0.35841
trainer/Log Pis Std               1.44861
trainer/Log Pis Max               2.83033
trainer/Log Pis Min              -5.63664
trainer/Policy mu Mean            0.118199
trainer/Policy mu Std             0.785364
trainer/Policy mu Max             1.66301
trainer/Policy mu Min            -1.33088
trainer/Policy log std Mean      -0.466934
trainer/Policy log std Std        0.09904
trainer/Policy log std Max       -0.251681
trainer/Policy log std Min       -0.659374
trainer/Alpha                     0.581963
trainer/Alpha Loss               -1.27611
exploration/num steps total    2700
exploration/num paths total      27
exploration/path length Mean    100
exploration/path length Std       0
exploration/path length Max     100
exploration/path length Min     100
exploration/Rewards Mean         -4.17037
exploration/Rewards Std           2.41821
exploration/Rewards Max          -0.483222
exploration/Rewards Min         -12.4602
exploration/Returns Mean       -417.037
exploration/Returns Std         210.844
exploration/Returns Max        -167.454
exploration/Returns Min        -739.347
exploration/Actions Mean         -0.00902061
exploration/Actions Std           0.5353
exploration/Actions Max           0.962511
exploration/Actions Min          -0.981946
exploration/Num Paths             5
exploration/Average Returns    -417.037
evaluation/num steps total     7500
evaluation/num paths total       75
evaluation/path length Mean     100
evaluation/path length Std        0
evaluation/path length Max      100
evaluation/path length Min      100
evaluation/Rewards Mean          -3.96854
evaluation/Rewards Std            2.60852
evaluation/Rewards Max           -0.387407
evaluation/Rewards Min           -9.94507
evaluation/Returns Mean        -396.854
evaluation/Returns Std          254.664
evaluation/Returns Max         -119.321
evaluation/Returns Min         -748.956
evaluation/Actions Mean           0.0078098
evaluation/Actions Std            0.125149
evaluation/Actions Max            0.955088
evaluation/Actions Min           -0.836478
evaluation/Num Paths             15
evaluation/Average Returns     -396.854
time/data storing (s)             0.00343821
time/evaluation sampling (s)      0.360661
time/exploration sampling (s)     0.182901
time/logging (s)                  0.00503373
time/saving (s)                   0.00193767
time/training (s)                 2.14731
time/epoch (s)                    2.70128
time/total (s)                   13.59
Epoch                             4
-----------------------------  -------------
2019-04-22 22:10:14.255933 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 5 finished
-----------------------------  -------------
replay_buffer/size             3200
trainer/QF1 Loss                 22.1433
trainer/QF2 Loss                 22.8835
trainer/Policy Loss              42.8835
trainer/Q1 Predictions Mean     -44.5496
trainer/Q1 Predictions Std       19.2027
trainer/Q1 Predictions Max      -18.1109
trainer/Q1 Predictions Min      -85.0237
trainer/Q2 Predictions Mean     -44.5312
trainer/Q2 Predictions Std       19.2291
trainer/Q2 Predictions Max      -18.0081
trainer/Q2 Predictions Min      -85.2844
trainer/Q Targets Mean          -43.9493
trainer/Q Targets Std            19.9914
trainer/Q Targets Max            -3.25203
trainer/Q Targets Min           -86.8983
trainer/Log Pis Mean             -0.318275
trainer/Log Pis Std               1.61973
trainer/Log Pis Max               3.46134
trainer/Log Pis Min              -4.75803
trainer/Policy mu Mean            0.053463
trainer/Policy mu Std             0.791303
trainer/Policy mu Max             1.90749
trainer/Policy mu Min            -1.7503
trainer/Policy log std Mean      -0.52171
trainer/Policy log std Std        0.131681
trainer/Policy log std Max       -0.241351
trainer/Policy log std Min       -0.82564
trainer/Alpha                     0.508348
trainer/Alpha Loss               -1.56791
exploration/num steps total    3200
exploration/num paths total      32
exploration/path length Mean    100
exploration/path length Std       0
exploration/path length Max     100
exploration/path length Min     100
exploration/Rewards Mean         -3.89036
exploration/Rewards Std           1.50106
exploration/Rewards Max          -0.283038
exploration/Rewards Min          -9.53669
exploration/Returns Mean       -389.036
exploration/Returns Std         130.807
exploration/Returns Max        -135.522
exploration/Returns Min        -514.17
exploration/Actions Mean         -0.0202977
exploration/Actions Std           0.534074
exploration/Actions Max           0.982321
exploration/Actions Min          -0.985809
exploration/Num Paths             5
exploration/Average Returns    -389.036
evaluation/num steps total     9000
evaluation/num paths total       90
evaluation/path length Mean     100
evaluation/path length Std        0
evaluation/path length Max      100
evaluation/path length Min      100
evaluation/Rewards Mean          -4.11843
evaluation/Rewards Std            2.21059
evaluation/Rewards Max           -0.331013
evaluation/Rewards Min          -10.2561
evaluation/Returns Mean        -411.843
evaluation/Returns Std          214.036
evaluation/Returns Max         -122.072
evaluation/Returns Min         -685.975
evaluation/Actions Mean           0.00370236
evaluation/Actions Std            0.15646
evaluation/Actions Max            0.917171
evaluation/Actions Min           -0.91763
evaluation/Num Paths             15
evaluation/Average Returns     -411.843
time/data storing (s)             0.00305264
time/evaluation sampling (s)      0.372392
time/exploration sampling (s)     0.163689
time/logging (s)                  0.00486251
time/saving (s)                   0.0187459
time/training (s)                 2.10447
time/epoch (s)                    2.66721
time/total (s)                   16.2616
Epoch                             5
-----------------------------  -------------
2019-04-22 22:10:16.962212 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 6 finished
-----------------------------  --------------
replay_buffer/size              3700
trainer/QF1 Loss                   1.65631
trainer/QF2 Loss                   1.63012
trainer/Policy Loss               46.6868
trainer/Q1 Predictions Mean      -48.6949
trainer/Q1 Predictions Std        20.1215
trainer/Q1 Predictions Max       -19.5815
trainer/Q1 Predictions Min       -94.9659
trainer/Q2 Predictions Mean      -48.6893
trainer/Q2 Predictions Std        20.1363
trainer/Q2 Predictions Max       -19.6623
trainer/Q2 Predictions Min       -94.9344
trainer/Q Targets Mean           -48.8583
trainer/Q Targets Std             20.2169
trainer/Q Targets Max            -20.2279
trainer/Q Targets Min            -93.7777
trainer/Log Pis Mean               0.128316
trainer/Log Pis Std                1.68043
trainer/Log Pis Max                4.2918
trainer/Log Pis Min               -5.32631
trainer/Policy mu Mean             0.12538
trainer/Policy mu Std              0.928794
trainer/Policy mu Max              1.98354
trainer/Policy mu Min             -1.88326
trainer/Policy log std Mean       -0.601786
trainer/Policy log std Std         0.127675
trainer/Policy log std Max        -0.274558
trainer/Policy log std Min        -0.831161
trainer/Alpha                      0.44348
trainer/Alpha Loss                -1.52137
exploration/num steps total     3700
exploration/num paths total       37
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.80809
exploration/Rewards Std            1.29128
exploration/Rewards Max           -0.372056
exploration/Rewards Min           -8.02091
exploration/Returns Mean        -280.809
exploration/Returns Std          100.243
exploration/Returns Max         -148.47
exploration/Returns Min         -364.546
exploration/Actions Mean           0.00532232
exploration/Actions Std            0.506173
exploration/Actions Max            0.991189
exploration/Actions Min           -0.979596
exploration/Num Paths              5
exploration/Average Returns     -280.809
evaluation/num steps total     10500
evaluation/num paths total       105
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -3.89595
evaluation/Rewards Std             1.59016
evaluation/Rewards Max            -1.24399
evaluation/Rewards Min           -10.5541
evaluation/Returns Mean         -389.595
evaluation/Returns Std           152.62
evaluation/Returns Max          -130.73
evaluation/Returns Min          -618.643
evaluation/Actions Mean            0.00140181
evaluation/Actions Std             0.137697
evaluation/Actions Max             0.934536
evaluation/Actions Min            -0.899597
evaluation/Num Paths              15
evaluation/Average Returns      -389.595
time/data storing (s)              0.00370687
time/evaluation sampling (s)       0.353519
time/exploration sampling (s)      0.160394
time/logging (s)                   0.00431677
time/saving (s)                    0.00201289
time/training (s)                  2.17663
time/epoch (s)                     2.70058
time/total (s)                    18.9666
Epoch                              6
-----------------------------  --------------
2019-04-22 22:10:19.623135 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 7 finished
-----------------------------  --------------
replay_buffer/size              4200
trainer/QF1 Loss                  37.7283
trainer/QF2 Loss                  37.2949
trainer/Policy Loss               48.4458
trainer/Q1 Predictions Mean      -49.8618
trainer/Q1 Predictions Std        24.8582
trainer/Q1 Predictions Max       -21.0737
trainer/Q1 Predictions Min      -104.931
trainer/Q2 Predictions Mean      -49.8489
trainer/Q2 Predictions Std        24.8889
trainer/Q2 Predictions Max       -20.9943
trainer/Q2 Predictions Min      -105.004
trainer/Q Targets Mean           -49.8522
trainer/Q Targets Std             25.6691
trainer/Q Targets Max             -4.64249
trainer/Q Targets Min           -105.083
trainer/Log Pis Mean              -0.041428
trainer/Log Pis Std                1.4246
trainer/Log Pis Max                2.98448
trainer/Log Pis Min               -4.13565
trainer/Policy mu Mean            -0.0356128
trainer/Policy mu Std              0.785636
trainer/Policy mu Max              1.95145
trainer/Policy mu Min             -2.02816
trainer/Policy log std Mean       -0.669051
trainer/Policy log std Std         0.161619
trainer/Policy log std Max        -0.296682
trainer/Policy log std Min        -0.91615
trainer/Alpha                      0.386301
trainer/Alpha Loss                -1.94112
exploration/num steps total     4200
exploration/num paths total       42
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -3.75362
exploration/Rewards Std            2.18865
exploration/Rewards Max           -0.457634
exploration/Rewards Min          -11.0478
exploration/Returns Mean        -375.362
exploration/Returns Std          200.727
exploration/Returns Max         -146.612
exploration/Returns Min         -629.738
exploration/Actions Mean           0.0228493
exploration/Actions Std            0.509813
exploration/Actions Max            0.984362
exploration/Actions Min           -0.987686
exploration/Num Paths              5
exploration/Average Returns     -375.362
evaluation/num steps total     12000
evaluation/num paths total       120
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -3.56343
evaluation/Rewards Std             1.6038
evaluation/Rewards Max            -0.332358
evaluation/Rewards Min           -10.5047
evaluation/Returns Mean         -356.343
evaluation/Returns Std           152.861
evaluation/Returns Max          -132.026
evaluation/Returns Min          -584.431
evaluation/Actions Mean           -0.00234908
evaluation/Actions Std             0.131824
evaluation/Actions Max             0.908037
evaluation/Actions Min            -0.966611
evaluation/Num Paths              15
evaluation/Average Returns      -356.343
time/data storing (s)              0.00326466
time/evaluation sampling (s)       0.360987
time/exploration sampling (s)      0.164363
time/logging (s)                   0.00486208
time/saving (s)                    0.00198689
time/training (s)                  2.12112
time/epoch (s)                     2.65659
time/total (s)                    21.6273
Epoch                              7
-----------------------------  --------------
2019-04-22 22:10:22.333702 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 8 finished
-----------------------------  --------------
replay_buffer/size              4700
trainer/QF1 Loss                 135.256
trainer/QF2 Loss                 134.593
trainer/Policy Loss               58.9604
trainer/Q1 Predictions Mean      -60.4961
trainer/Q1 Predictions Std        25.3058
trainer/Q1 Predictions Max       -22.7662
trainer/Q1 Predictions Min      -101.72
trainer/Q2 Predictions Mean      -60.5157
trainer/Q2 Predictions Std        25.2827
trainer/Q2 Predictions Max       -22.3911
trainer/Q2 Predictions Min      -101.745
trainer/Q Targets Mean           -59.3018
trainer/Q Targets Std             26.2521
trainer/Q Targets Max             -6.13814
trainer/Q Targets Min           -103.664
trainer/Log Pis Mean              -0.0460693
trainer/Log Pis Std                1.45061
trainer/Log Pis Max                4.06872
trainer/Log Pis Min               -3.80929
trainer/Policy mu Mean            -0.129132
trainer/Policy mu Std              0.818437
trainer/Policy mu Max              2.10914
trainer/Policy mu Min             -1.8225
trainer/Policy log std Mean       -0.697184
trainer/Policy log std Std         0.174705
trainer/Policy log std Max        -0.294263
trainer/Policy log std Min        -0.971016
trainer/Alpha                      0.336729
trainer/Alpha Loss                -2.22654
exploration/num steps total     4700
exploration/num paths total       47
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -3.32025
exploration/Rewards Std            1.36045
exploration/Rewards Max           -0.877042
exploration/Rewards Min           -9.5045
exploration/Returns Mean        -332.025
exploration/Returns Std          105.873
exploration/Returns Max         -204.702
exploration/Returns Min         -495.94
exploration/Actions Mean           0.0157536
exploration/Actions Std            0.49352
exploration/Actions Max            0.992327
exploration/Actions Min           -0.979002
exploration/Num Paths              5
exploration/Average Returns     -332.025
evaluation/num steps total     13500
evaluation/num paths total       135
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.85804
evaluation/Rewards Std             1.37723
evaluation/Rewards Max            -0.6308
evaluation/Rewards Min           -10.1372
evaluation/Returns Mean         -285.804
evaluation/Returns Std           123.267
evaluation/Returns Max          -143.563
evaluation/Returns Min          -497.922
evaluation/Actions Mean           -0.0143735
evaluation/Actions Std             0.163522
evaluation/Actions Max             0.967665
evaluation/Actions Min            -0.939698
evaluation/Num Paths              15
evaluation/Average Returns      -285.804
time/data storing (s)              0.00332166
time/evaluation sampling (s)       0.350373
time/exploration sampling (s)      0.161001
time/logging (s)                   0.0046061
time/saving (s)                    0.00194887
time/training (s)                  2.18365
time/epoch (s)                     2.7049
time/total (s)                    24.3367
Epoch                              8
-----------------------------  --------------
2019-04-22 22:10:24.984671 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 9 finished
-----------------------------  --------------
replay_buffer/size              5200
trainer/QF1 Loss                  16.8781
trainer/QF2 Loss                  18.1764
trainer/Policy Loss               68.1149
trainer/Q1 Predictions Mean      -69.4467
trainer/Q1 Predictions Std        30.4219
trainer/Q1 Predictions Max       -24.2762
trainer/Q1 Predictions Min      -123.802
trainer/Q2 Predictions Mean      -69.4815
trainer/Q2 Predictions Std        30.4619
trainer/Q2 Predictions Max       -23.8288
trainer/Q2 Predictions Min      -123.778
trainer/Q Targets Mean           -69.6483
trainer/Q Targets Std             31.0723
trainer/Q Targets Max             -7.25931
trainer/Q Targets Min           -124.017
trainer/Log Pis Mean               0.135018
trainer/Log Pis Std                1.53756
trainer/Log Pis Max                5.06506
trainer/Log Pis Min               -4.14047
trainer/Policy mu Mean            -0.0819691
trainer/Policy mu Std              0.895447
trainer/Policy mu Max              2.14693
trainer/Policy mu Min             -2.03738
trainer/Policy log std Mean       -0.731343
trainer/Policy log std Std         0.187392
trainer/Policy log std Max        -0.358807
trainer/Policy log std Min        -1.05833
trainer/Alpha                      0.294445
trainer/Alpha Loss                -2.27979
exploration/num steps total     5200
exploration/num paths total       52
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.92436
exploration/Rewards Std            1.54485
exploration/Rewards Max           -0.154511
exploration/Rewards Min          -10.938
exploration/Returns Mean        -292.436
exploration/Returns Std          104.533
exploration/Returns Max         -174.749
exploration/Returns Min         -432.936
exploration/Actions Mean          -0.011688
exploration/Actions Std            0.464821
exploration/Actions Max            0.994458
exploration/Actions Min           -0.971958
exploration/Num Paths              5
exploration/Average Returns     -292.436
evaluation/num steps total     15000
evaluation/num paths total       150
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.43306
evaluation/Rewards Std             1.15398
evaluation/Rewards Max            -1.29768
evaluation/Rewards Min           -10.0228
evaluation/Returns Mean         -243.306
evaluation/Returns Std            94.2155
evaluation/Returns Max          -137.944
evaluation/Returns Min          -417.665
evaluation/Actions Mean            0.00653618
evaluation/Actions Std             0.162929
evaluation/Actions Max             0.975777
evaluation/Actions Min            -0.95837
evaluation/Num Paths              15
evaluation/Average Returns      -243.306
time/data storing (s)              0.00299334
time/evaluation sampling (s)       0.357701
time/exploration sampling (s)      0.163711
time/logging (s)                   0.00448375
time/saving (s)                    0.00194738
time/training (s)                  2.11483
time/epoch (s)                     2.64567
time/total (s)                    26.9868
Epoch                              9
-----------------------------  --------------
2019-04-22 22:10:27.693088 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 10 finished
-----------------------------  --------------
replay_buffer/size              5700
trainer/QF1 Loss                   2.49616
trainer/QF2 Loss                   2.52079
trainer/Policy Loss               61.6217
trainer/Q1 Predictions Mean      -62.7224
trainer/Q1 Predictions Std        30.3186
trainer/Q1 Predictions Max       -25.4707
trainer/Q1 Predictions Min      -125.795
trainer/Q2 Predictions Mean      -62.6932
trainer/Q2 Predictions Std        30.3162
trainer/Q2 Predictions Max       -25.221
trainer/Q2 Predictions Min      -126.102
trainer/Q Targets Mean           -63.9996
trainer/Q Targets Std             30.8445
trainer/Q Targets Max            -26.0458
trainer/Q Targets Min           -130.467
trainer/Log Pis Mean               0.0932282
trainer/Log Pis Std                1.29144
trainer/Log Pis Max                4.13683
trainer/Log Pis Min               -4.3764
trainer/Policy mu Mean            -0.215216
trainer/Policy mu Std              0.783494
trainer/Policy mu Max              2.06825
trainer/Policy mu Min             -2.15251
trainer/Policy log std Mean       -0.867015
trainer/Policy log std Std         0.145314
trainer/Policy log std Max        -0.477878
trainer/Policy log std Min        -1.16171
trainer/Alpha                      0.257977
trainer/Alpha Loss                -2.58296
exploration/num steps total     5700
exploration/num paths total       57
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.23966
exploration/Rewards Std            1.38922
exploration/Rewards Max           -0.338491
exploration/Rewards Min           -7.70447
exploration/Returns Mean        -223.966
exploration/Returns Std          109.352
exploration/Returns Max         -157.1
exploration/Returns Min         -442.005
exploration/Actions Mean          -0.0177243
exploration/Actions Std            0.406571
exploration/Actions Max            0.941051
exploration/Actions Min           -0.984855
exploration/Num Paths              5
exploration/Average Returns     -223.966
evaluation/num steps total     16500
evaluation/num paths total       165
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.96985
evaluation/Rewards Std             1.34906
evaluation/Rewards Max            -1.43536
evaluation/Rewards Min            -9.35422
evaluation/Returns Mean         -296.985
evaluation/Returns Std           118.789
evaluation/Returns Max          -158.736
evaluation/Returns Min          -444.757
evaluation/Actions Mean           -0.0086192
evaluation/Actions Std             0.161717
evaluation/Actions Max             0.965433
evaluation/Actions Min            -0.955694
evaluation/Num Paths              15
evaluation/Average Returns      -296.985
time/data storing (s)              0.00328027
time/evaluation sampling (s)       0.35917
time/exploration sampling (s)      0.159148
time/logging (s)                   0.00517448
time/saving (s)                    0.00242786
time/training (s)                  2.17435
time/epoch (s)                     2.70355
time/total (s)                    29.695
Epoch                             10
-----------------------------  --------------
2019-04-22 22:10:30.380580 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 11 finished
-----------------------------  --------------
replay_buffer/size              6200
trainer/QF1 Loss                  90.6948
trainer/QF2 Loss                  91.4514
trainer/Policy Loss               67.3012
trainer/Q1 Predictions Mean      -68.017
trainer/Q1 Predictions Std        34.2315
trainer/Q1 Predictions Max       -27.3837
trainer/Q1 Predictions Min      -137.939
trainer/Q2 Predictions Mean      -68.0538
trainer/Q2 Predictions Std        34.1659
trainer/Q2 Predictions Max       -27.067
trainer/Q2 Predictions Min      -138.151
trainer/Q Targets Mean           -66.9784
trainer/Q Targets Std             36.2108
trainer/Q Targets Max             -1.51233
trainer/Q Targets Min           -140.676
trainer/Log Pis Mean               0.218325
trainer/Log Pis Std                1.41915
trainer/Log Pis Max                4.66466
trainer/Log Pis Min               -6.85793
trainer/Policy mu Mean            -0.178656
trainer/Policy mu Std              0.817416
trainer/Policy mu Max              2.35113
trainer/Policy mu Min             -2.49183
trainer/Policy log std Mean       -0.913411
trainer/Policy log std Std         0.172733
trainer/Policy log std Max        -0.473026
trainer/Policy log std Min        -1.25224
trainer/Alpha                      0.226787
trainer/Alpha Loss                -2.64308
exploration/num steps total     6200
exploration/num paths total       62
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.90687
exploration/Rewards Std            1.91275
exploration/Rewards Max           -0.200176
exploration/Rewards Min          -10.0271
exploration/Returns Mean        -290.687
exploration/Returns Std          164.241
exploration/Returns Max          -94.1311
exploration/Returns Min         -529.094
exploration/Actions Mean          -0.0306567
exploration/Actions Std            0.409869
exploration/Actions Max            0.969589
exploration/Actions Min           -0.993801
exploration/Num Paths              5
exploration/Average Returns     -290.687
evaluation/num steps total     18000
evaluation/num paths total       180
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.84413
evaluation/Rewards Std             2.01859
evaluation/Rewards Max            -0.376263
evaluation/Rewards Min           -10.2756
evaluation/Returns Mean         -284.413
evaluation/Returns Std           191.074
evaluation/Returns Max           -82.6701
evaluation/Returns Min          -525.972
evaluation/Actions Mean           -0.00147127
evaluation/Actions Std             0.152546
evaluation/Actions Max             0.982464
evaluation/Actions Min            -0.981814
evaluation/Num Paths              15
evaluation/Average Returns      -284.413
time/data storing (s)              0.00307309
time/evaluation sampling (s)       0.361842
time/exploration sampling (s)      0.160699
time/logging (s)                   0.00499414
time/saving (s)                    0.00207278
time/training (s)                  2.14937
time/epoch (s)                     2.68205
time/total (s)                    32.3814
Epoch                             11
-----------------------------  --------------
2019-04-22 22:10:33.079916 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 12 finished
-----------------------------  ---------------
replay_buffer/size              6700
trainer/QF1 Loss                 191.313
trainer/QF2 Loss                 191.723
trainer/Policy Loss               69.6076
trainer/Q1 Predictions Mean      -70.6366
trainer/Q1 Predictions Std        33.0414
trainer/Q1 Predictions Max       -29.0001
trainer/Q1 Predictions Min      -132.091
trainer/Q2 Predictions Mean      -70.6445
trainer/Q2 Predictions Std        33.0973
trainer/Q2 Predictions Max       -28.9528
trainer/Q2 Predictions Min      -132.469
trainer/Q Targets Mean           -69.1961
trainer/Q Targets Std             35.3785
trainer/Q Targets Max             -3.3729
trainer/Q Targets Min           -136.159
trainer/Log Pis Mean               0.339468
trainer/Log Pis Std                1.47958
trainer/Log Pis Max                4.60649
trainer/Log Pis Min               -3.57017
trainer/Policy mu Mean            -0.174507
trainer/Policy mu Std              0.864093
trainer/Policy mu Max              2.47645
trainer/Policy mu Min             -2.12183
trainer/Policy log std Mean       -0.995721
trainer/Policy log std Std         0.199076
trainer/Policy log std Max        -0.596308
trainer/Policy log std Min        -1.50501
trainer/Alpha                      0.199737
trainer/Alpha Loss                -2.67428
exploration/num steps total     6700
exploration/num paths total       67
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.94126
exploration/Rewards Std            1.62282
exploration/Rewards Max           -0.413803
exploration/Rewards Min           -9.63758
exploration/Returns Mean        -294.126
exploration/Returns Std          132.305
exploration/Returns Max         -152.96
exploration/Returns Min         -471.163
exploration/Actions Mean          -0.000511469
exploration/Actions Std            0.380799
exploration/Actions Max            0.997739
exploration/Actions Min           -0.985554
exploration/Num Paths              5
exploration/Average Returns     -294.126
evaluation/num steps total     19500
evaluation/num paths total       195
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.69307
evaluation/Rewards Std             1.12953
evaluation/Rewards Max            -1.35817
evaluation/Rewards Min           -10.0396
evaluation/Returns Mean         -269.307
evaluation/Returns Std            96.5057
evaluation/Returns Max          -151.048
evaluation/Returns Min          -451.512
evaluation/Actions Mean           -0.0087153
evaluation/Actions Std             0.141016
evaluation/Actions Max             0.979992
evaluation/Actions Min            -0.976498
evaluation/Num Paths              15
evaluation/Average Returns      -269.307
time/data storing (s)              0.00324561
time/evaluation sampling (s)       0.362861
time/exploration sampling (s)      0.161241
time/logging (s)                   0.00500693
time/saving (s)                    0.00185113
time/training (s)                  2.16022
time/epoch (s)                     2.69442
time/total (s)                    35.0799
Epoch                             12
-----------------------------  ---------------
2019-04-22 22:10:35.926668 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 13 finished
-----------------------------  --------------
replay_buffer/size              7200
trainer/QF1 Loss                  26.7472
trainer/QF2 Loss                  27.4245
trainer/Policy Loss               69.907
trainer/Q1 Predictions Mean      -70.5016
trainer/Q1 Predictions Std        32.5447
trainer/Q1 Predictions Max       -30.441
trainer/Q1 Predictions Min      -148.492
trainer/Q2 Predictions Mean      -70.4776
trainer/Q2 Predictions Std        32.5272
trainer/Q2 Predictions Max       -30.1281
trainer/Q2 Predictions Min      -148.388
trainer/Q Targets Mean           -70.0618
trainer/Q Targets Std             33.1931
trainer/Q Targets Max             -6.24209
trainer/Q Targets Min           -148.714
trainer/Log Pis Mean               0.806737
trainer/Log Pis Std                1.77408
trainer/Log Pis Max                5.80403
trainer/Log Pis Min               -3.90009
trainer/Policy mu Mean            -0.226657
trainer/Policy mu Std              0.918591
trainer/Policy mu Max              2.35471
trainer/Policy mu Min             -2.26005
trainer/Policy log std Mean       -1.09154
trainer/Policy log std Std         0.240258
trainer/Policy log std Max        -0.527689
trainer/Policy log std Min        -1.60589
trainer/Alpha                      0.176322
trainer/Alpha Loss                -2.07055
exploration/num steps total     7200
exploration/num paths total       72
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.34015
exploration/Rewards Std            0.974487
exploration/Rewards Max           -0.81807
exploration/Rewards Min           -8.86434
exploration/Returns Mean        -234.015
exploration/Returns Std           68.1701
exploration/Returns Max         -140.808
exploration/Returns Min         -351.506
exploration/Actions Mean          -0.00605653
exploration/Actions Std            0.358384
exploration/Actions Max            0.98595
exploration/Actions Min           -0.985575
exploration/Num Paths              5
exploration/Average Returns     -234.015
evaluation/num steps total     21000
evaluation/num paths total       210
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.38018
evaluation/Rewards Std             1.36269
evaluation/Rewards Max            -0.934525
evaluation/Rewards Min            -8.58072
evaluation/Returns Mean         -238.018
evaluation/Returns Std           127.578
evaluation/Returns Max          -138.241
evaluation/Returns Min          -513.37
evaluation/Actions Mean           -0.00390633
evaluation/Actions Std             0.134963
evaluation/Actions Max             0.983155
evaluation/Actions Min            -0.964902
evaluation/Num Paths              15
evaluation/Average Returns      -238.018
time/data storing (s)              0.00306097
time/evaluation sampling (s)       0.412049
time/exploration sampling (s)      0.189101
time/logging (s)                   0.00525356
time/saving (s)                    0.00206467
time/training (s)                  2.2297
time/epoch (s)                     2.84123
time/total (s)                    37.926
Epoch                             13
-----------------------------  --------------
2019-04-22 22:10:38.612875 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 14 finished
-----------------------------  --------------
replay_buffer/size              7700
trainer/QF1 Loss                 298.449
trainer/QF2 Loss                 298.16
trainer/Policy Loss               74.6743
trainer/Q1 Predictions Mean      -75.2887
trainer/Q1 Predictions Std        34.2425
trainer/Q1 Predictions Max       -32.2041
trainer/Q1 Predictions Min      -147.968
trainer/Q2 Predictions Mean      -75.2506
trainer/Q2 Predictions Std        34.2482
trainer/Q2 Predictions Max       -32.089
trainer/Q2 Predictions Min      -148.023
trainer/Q Targets Mean           -73.1403
trainer/Q Targets Std             36.293
trainer/Q Targets Max             -4.5132
trainer/Q Targets Min           -151.302
trainer/Log Pis Mean               0.645944
trainer/Log Pis Std                1.47236
trainer/Log Pis Max                4.22012
trainer/Log Pis Min               -2.55939
trainer/Policy mu Mean            -0.354345
trainer/Policy mu Std              0.818474
trainer/Policy mu Max              2.13156
trainer/Policy mu Min             -2.45205
trainer/Policy log std Mean       -1.11507
trainer/Policy log std Std         0.241322
trainer/Policy log std Max        -0.430527
trainer/Policy log std Min        -1.68879
trainer/Alpha                      0.156005
trainer/Alpha Loss                -2.51532
exploration/num steps total     7700
exploration/num paths total       77
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.56441
exploration/Rewards Std            1.59146
exploration/Rewards Max           -0.630429
exploration/Rewards Min           -7.72006
exploration/Returns Mean        -256.441
exploration/Returns Std          147.768
exploration/Returns Max         -133.834
exploration/Returns Min         -504.794
exploration/Actions Mean          -0.0272174
exploration/Actions Std            0.32274
exploration/Actions Max            0.762976
exploration/Actions Min           -0.987625
exploration/Num Paths              5
exploration/Average Returns     -256.441
evaluation/num steps total     22500
evaluation/num paths total       225
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.48745
evaluation/Rewards Std             1.32649
evaluation/Rewards Max            -0.4785
evaluation/Rewards Min            -9.62824
evaluation/Returns Mean         -248.745
evaluation/Returns Std           113.386
evaluation/Returns Max          -125.726
evaluation/Returns Min          -514.4
evaluation/Actions Mean           -0.00561193
evaluation/Actions Std             0.159581
evaluation/Actions Max             0.990616
evaluation/Actions Min            -0.983429
evaluation/Num Paths              15
evaluation/Average Returns      -248.745
time/data storing (s)              0.00329385
time/evaluation sampling (s)       0.366492
time/exploration sampling (s)      0.163397
time/logging (s)                   0.00516243
time/saving (s)                    0.00215082
time/training (s)                  2.13995
time/epoch (s)                     2.68045
time/total (s)                    40.611
Epoch                             14
-----------------------------  --------------
2019-04-22 22:10:41.349348 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 15 finished
-----------------------------  --------------
replay_buffer/size              8200
trainer/QF1 Loss                   2.50683
trainer/QF2 Loss                   2.42656
trainer/Policy Loss               78.349
trainer/Q1 Predictions Mean      -78.5516
trainer/Q1 Predictions Std        37.6666
trainer/Q1 Predictions Max       -33.4735
trainer/Q1 Predictions Min      -153.268
trainer/Q2 Predictions Mean      -78.6018
trainer/Q2 Predictions Std        37.6351
trainer/Q2 Predictions Max       -33.602
trainer/Q2 Predictions Min      -153.147
trainer/Q Targets Mean           -79.669
trainer/Q Targets Std             38.3466
trainer/Q Targets Max            -33.542
trainer/Q Targets Min           -155.844
trainer/Log Pis Mean               0.863473
trainer/Log Pis Std                1.30747
trainer/Log Pis Max                5.73315
trainer/Log Pis Min               -1.90241
trainer/Policy mu Mean            -0.226664
trainer/Policy mu Std              0.869803
trainer/Policy mu Max              2.7947
trainer/Policy mu Min             -2.44417
trainer/Policy log std Mean       -1.18665
trainer/Policy log std Std         0.288167
trainer/Policy log std Max        -0.427304
trainer/Policy log std Min        -1.73628
trainer/Alpha                      0.137785
trainer/Alpha Loss                -2.2524
exploration/num steps total     8200
exploration/num paths total       82
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.70213
exploration/Rewards Std            1.70753
exploration/Rewards Max           -0.647401
exploration/Rewards Min           -8.4954
exploration/Returns Mean        -270.213
exploration/Returns Std          156.35
exploration/Returns Max         -117.996
exploration/Returns Min         -521.047
exploration/Actions Mean           0.00767902
exploration/Actions Std            0.333817
exploration/Actions Max            0.9946
exploration/Actions Min           -0.990655
exploration/Num Paths              5
exploration/Average Returns     -270.213
evaluation/num steps total     24000
evaluation/num paths total       240
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.29375
evaluation/Rewards Std             1.54665
evaluation/Rewards Max            -0.964188
evaluation/Rewards Min           -10.9913
evaluation/Returns Mean         -229.375
evaluation/Returns Std           129.694
evaluation/Returns Max          -150.802
evaluation/Returns Min          -533.995
evaluation/Actions Mean           -0.00278888
evaluation/Actions Std             0.177785
evaluation/Actions Max             0.993482
evaluation/Actions Min            -0.983357
evaluation/Num Paths              15
evaluation/Average Returns      -229.375
time/data storing (s)              0.00320479
time/evaluation sampling (s)       0.361882
time/exploration sampling (s)      0.170432
time/logging (s)                   0.00475929
time/saving (s)                    0.00193958
time/training (s)                  2.18816
time/epoch (s)                     2.73038
time/total (s)                    43.346
Epoch                             15
-----------------------------  --------------
2019-04-22 22:10:44.060241 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 16 finished
-----------------------------  ---------------
replay_buffer/size              8700
trainer/QF1 Loss                 139.035
trainer/QF2 Loss                 139.23
trainer/Policy Loss               83.1623
trainer/Q1 Predictions Mean      -83.5603
trainer/Q1 Predictions Std        36.3899
trainer/Q1 Predictions Max       -35.6089
trainer/Q1 Predictions Min      -160.437
trainer/Q2 Predictions Mean      -83.5089
trainer/Q2 Predictions Std        36.4301
trainer/Q2 Predictions Max       -35.6467
trainer/Q2 Predictions Min      -160.144
trainer/Q Targets Mean           -83.0253
trainer/Q Targets Std             38.2334
trainer/Q Targets Max             -3.78077
trainer/Q Targets Min           -162.578
trainer/Log Pis Mean               0.808118
trainer/Log Pis Std                1.67664
trainer/Log Pis Max                4.56503
trainer/Log Pis Min               -4.74507
trainer/Policy mu Mean            -0.232487
trainer/Policy mu Std              0.875653
trainer/Policy mu Max              2.37062
trainer/Policy mu Min             -2.4729
trainer/Policy log std Mean       -1.27537
trainer/Policy log std Std         0.296065
trainer/Policy log std Max        -0.394933
trainer/Policy log std Min        -1.87618
trainer/Alpha                      0.121996
trainer/Alpha Loss                -2.50715
exploration/num steps total     8700
exploration/num paths total       87
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -4.76479
exploration/Rewards Std            1.55848
exploration/Rewards Max           -1.17093
exploration/Rewards Min          -11.1804
exploration/Returns Mean        -476.479
exploration/Returns Std          146.204
exploration/Returns Max         -184.783
exploration/Returns Min         -567.46
exploration/Actions Mean           0.0245833
exploration/Actions Std            0.314959
exploration/Actions Max            0.990829
exploration/Actions Min           -0.927037
exploration/Num Paths              5
exploration/Average Returns     -476.479
evaluation/num steps total     25500
evaluation/num paths total       255
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -3.47202
evaluation/Rewards Std             1.74428
evaluation/Rewards Max            -0.858947
evaluation/Rewards Min            -9.36121
evaluation/Returns Mean         -347.202
evaluation/Returns Std           163.622
evaluation/Returns Max          -141.027
evaluation/Returns Min          -552.947
evaluation/Actions Mean           -0.000308445
evaluation/Actions Std             0.159644
evaluation/Actions Max             0.989708
evaluation/Actions Min            -0.990635
evaluation/Num Paths              15
evaluation/Average Returns      -347.202
time/data storing (s)              0.00311235
time/evaluation sampling (s)       0.37104
time/exploration sampling (s)      0.1745
time/logging (s)                   0.0051959
time/saving (s)                    0.00212737
time/training (s)                  2.15003
time/epoch (s)                     2.70601
time/total (s)                    46.0564
Epoch                             16
-----------------------------  ---------------
2019-04-22 22:10:46.782486 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 17 finished
-----------------------------  --------------
replay_buffer/size              9200
trainer/QF1 Loss                   1.24152
trainer/QF2 Loss                   1.2912
trainer/Policy Loss               84.3295
trainer/Q1 Predictions Mean      -84.0254
trainer/Q1 Predictions Std        40.3417
trainer/Q1 Predictions Max       -36.3867
trainer/Q1 Predictions Min      -159.669
trainer/Q2 Predictions Mean      -84.0337
trainer/Q2 Predictions Std        40.3475
trainer/Q2 Predictions Max       -36.2446
trainer/Q2 Predictions Min      -159.484
trainer/Q Targets Mean           -84.8211
trainer/Q Targets Std             40.3692
trainer/Q Targets Max            -36.9136
trainer/Q Targets Min           -161.205
trainer/Log Pis Mean               1.32547
trainer/Log Pis Std                1.44701
trainer/Log Pis Max                7.13737
trainer/Log Pis Min               -1.99339
trainer/Policy mu Mean            -0.330287
trainer/Policy mu Std              0.896777
trainer/Policy mu Max              2.73615
trainer/Policy mu Min             -2.75675
trainer/Policy log std Mean       -1.29472
trainer/Policy log std Std         0.327964
trainer/Policy log std Max        -0.582274
trainer/Policy log std Min        -1.93253
trainer/Alpha                      0.108546
trainer/Alpha Loss                -1.49768
exploration/num steps total     9200
exploration/num paths total       92
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.36171
exploration/Rewards Std            2.17382
exploration/Rewards Max           -0.452363
exploration/Rewards Min           -9.71997
exploration/Returns Mean        -236.171
exploration/Returns Std          190.21
exploration/Returns Max         -126.617
exploration/Returns Min         -615.226
exploration/Actions Mean          -0.0461179
exploration/Actions Std            0.320258
exploration/Actions Max            0.843984
exploration/Actions Min           -0.99628
exploration/Num Paths              5
exploration/Average Returns     -236.171
evaluation/num steps total     27000
evaluation/num paths total       270
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -3.60003
evaluation/Rewards Std             1.96782
evaluation/Rewards Max            -1.00566
evaluation/Rewards Min            -9.87079
evaluation/Returns Mean         -360.003
evaluation/Returns Std           187.373
evaluation/Returns Max          -107.562
evaluation/Returns Min          -642.513
evaluation/Actions Mean           -0.0101333
evaluation/Actions Std             0.159652
evaluation/Actions Max             0.994109
evaluation/Actions Min            -0.990626
evaluation/Num Paths              15
evaluation/Average Returns      -360.003
time/data storing (s)              0.00315427
time/evaluation sampling (s)       0.360475
time/exploration sampling (s)      0.163075
time/logging (s)                   0.00464985
time/saving (s)                    0.00220132
time/training (s)                  2.18205
time/epoch (s)                     2.71561
time/total (s)                    48.7771
Epoch                             17
-----------------------------  --------------
2019-04-22 22:10:49.536564 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 18 finished
-----------------------------  --------------
replay_buffer/size              9700
trainer/QF1 Loss                 248.921
trainer/QF2 Loss                 246.798
trainer/Policy Loss               85.7807
trainer/Q1 Predictions Mean      -85.6691
trainer/Q1 Predictions Std        41.2225
trainer/Q1 Predictions Max       -37.9153
trainer/Q1 Predictions Min      -149.104
trainer/Q2 Predictions Mean      -85.7321
trainer/Q2 Predictions Std        41.2095
trainer/Q2 Predictions Max       -38.2531
trainer/Q2 Predictions Min      -149.758
trainer/Q Targets Mean           -84.1628
trainer/Q Targets Std             42.9015
trainer/Q Targets Max             -4.46247
trainer/Q Targets Min           -151.649
trainer/Log Pis Mean               0.98213
trainer/Log Pis Std                1.57177
trainer/Log Pis Max                6.11631
trainer/Log Pis Min               -1.54795
trainer/Policy mu Mean            -0.109507
trainer/Policy mu Std              0.927072
trainer/Policy mu Max              2.8675
trainer/Policy mu Min             -2.80364
trainer/Policy log std Mean       -1.26595
trainer/Policy log std Std         0.309684
trainer/Policy log std Max        -0.435225
trainer/Policy log std Min        -1.97134
trainer/Alpha                      0.0960606
trainer/Alpha Loss                -2.38438
exploration/num steps total     9700
exploration/num paths total       97
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.39597
exploration/Rewards Std            2.15083
exploration/Rewards Max           -0.399801
exploration/Rewards Min           -7.12102
exploration/Returns Mean        -239.597
exploration/Returns Std          205.128
exploration/Returns Max         -126.677
exploration/Returns Min         -649.624
exploration/Actions Mean          -0.00811562
exploration/Actions Std            0.316985
exploration/Actions Max            0.993989
exploration/Actions Min           -0.985638
exploration/Num Paths              5
exploration/Average Returns     -239.597
evaluation/num steps total     28500
evaluation/num paths total       285
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.96727
evaluation/Rewards Std             1.96139
evaluation/Rewards Max            -1.09301
evaluation/Rewards Min            -9.71699
evaluation/Returns Mean         -296.727
evaluation/Returns Std           178.979
evaluation/Returns Max          -116.595
evaluation/Returns Min          -666.037
evaluation/Actions Mean           -0.0210711
evaluation/Actions Std             0.173428
evaluation/Actions Max             0.985497
evaluation/Actions Min            -0.99489
evaluation/Num Paths              15
evaluation/Average Returns      -296.727
time/data storing (s)              0.00351222
time/evaluation sampling (s)       0.368192
time/exploration sampling (s)      0.178092
time/logging (s)                   0.0050013
time/saving (s)                    0.00207708
time/training (s)                  2.19188
time/epoch (s)                     2.74875
time/total (s)                    51.5305
Epoch                             18
-----------------------------  --------------
2019-04-22 22:10:52.278660 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 19 finished
-----------------------------  --------------
replay_buffer/size             10200
trainer/QF1 Loss                 166.704
trainer/QF2 Loss                 164.713
trainer/Policy Loss               88.8573
trainer/Q1 Predictions Mean      -88.5504
trainer/Q1 Predictions Std        42.5735
trainer/Q1 Predictions Max       -40.7047
trainer/Q1 Predictions Min      -167.209
trainer/Q2 Predictions Mean      -88.5762
trainer/Q2 Predictions Std        42.5207
trainer/Q2 Predictions Max       -40.6012
trainer/Q2 Predictions Min      -166.476
trainer/Q Targets Mean           -87.9175
trainer/Q Targets Std             43.3962
trainer/Q Targets Max             -5.79905
trainer/Q Targets Min           -169.569
trainer/Log Pis Mean               1.34376
trainer/Log Pis Std                1.57099
trainer/Log Pis Max                7.31476
trainer/Log Pis Min               -2.72887
trainer/Policy mu Mean            -0.28524
trainer/Policy mu Std              0.998079
trainer/Policy mu Max              2.84589
trainer/Policy mu Min             -2.55796
trainer/Policy log std Mean       -1.32553
trainer/Policy log std Std         0.370239
trainer/Policy log std Max        -0.51278
trainer/Policy log std Min        -2.12627
trainer/Alpha                      0.0851669
trainer/Alpha Loss                -1.61627
exploration/num steps total    10200
exploration/num paths total      102
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -4.31044
exploration/Rewards Std            2.857
exploration/Rewards Max           -0.530396
exploration/Rewards Min           -8.61967
exploration/Returns Mean        -431.044
exploration/Returns Std          274.557
exploration/Returns Max         -130.916
exploration/Returns Min         -757.626
exploration/Actions Mean          -0.0124961
exploration/Actions Std            0.273721
exploration/Actions Max            0.976339
exploration/Actions Min           -0.998949
exploration/Num Paths              5
exploration/Average Returns     -431.044
evaluation/num steps total     30000
evaluation/num paths total       300
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -3.06702
evaluation/Rewards Std             2.51674
evaluation/Rewards Max            -0.263222
evaluation/Rewards Min            -9.05086
evaluation/Returns Mean         -306.702
evaluation/Returns Std           241.185
evaluation/Returns Max          -104.229
evaluation/Returns Min          -752.174
evaluation/Actions Mean           -0.0056727
evaluation/Actions Std             0.167982
evaluation/Actions Max             0.992158
evaluation/Actions Min            -0.993648
evaluation/Num Paths              15
evaluation/Average Returns      -306.702
time/data storing (s)              0.00348576
time/evaluation sampling (s)       0.361465
time/exploration sampling (s)      0.164164
time/logging (s)                   0.00477978
time/saving (s)                    0.00202661
time/training (s)                  2.20064
time/epoch (s)                     2.73656
time/total (s)                    54.2715
Epoch                             19
-----------------------------  --------------
2019-04-22 22:10:54.951541 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 20 finished
-----------------------------  --------------
replay_buffer/size             10700
trainer/QF1 Loss                  20.1762
trainer/QF2 Loss                  19.9021
trainer/Policy Loss               87.576
trainer/Q1 Predictions Mean      -87.5886
trainer/Q1 Predictions Std        44.0542
trainer/Q1 Predictions Max       -41.3611
trainer/Q1 Predictions Min      -169.297
trainer/Q2 Predictions Mean      -87.5332
trainer/Q2 Predictions Std        44.0747
trainer/Q2 Predictions Max       -41.2879
trainer/Q2 Predictions Min      -168.594
trainer/Q Targets Mean           -88.2689
trainer/Q Targets Std             45.3442
trainer/Q Targets Max             -2.08846
trainer/Q Targets Min           -168.82
trainer/Log Pis Mean               1.02051
trainer/Log Pis Std                1.67359
trainer/Log Pis Max                6.70771
trainer/Log Pis Min               -3.45174
trainer/Policy mu Mean            -0.0137788
trainer/Policy mu Std              0.870006
trainer/Policy mu Max              2.79484
trainer/Policy mu Min             -2.6906
trainer/Policy log std Mean       -1.43262
trainer/Policy log std Std         0.417442
trainer/Policy log std Max        -0.424793
trainer/Policy log std Min        -2.2476
trainer/Alpha                      0.0757833
trainer/Alpha Loss                -2.52674
exploration/num steps total    10700
exploration/num paths total      107
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.73798
exploration/Rewards Std            1.13699
exploration/Rewards Max           -0.636015
exploration/Rewards Min           -8.51784
exploration/Returns Mean        -173.798
exploration/Returns Std          101.042
exploration/Returns Max         -118.47
exploration/Returns Min         -375.578
exploration/Actions Mean           0.00824212
exploration/Actions Std            0.238891
exploration/Actions Max            0.992742
exploration/Actions Min           -0.987654
exploration/Num Paths              5
exploration/Average Returns     -173.798
evaluation/num steps total     31500
evaluation/num paths total       315
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.84934
evaluation/Rewards Std             1.96542
evaluation/Rewards Max            -0.982676
evaluation/Rewards Min           -10.2128
evaluation/Returns Mean         -284.934
evaluation/Returns Std           179.786
evaluation/Returns Max          -122.671
evaluation/Returns Min          -669.193
evaluation/Actions Mean           -0.00818549
evaluation/Actions Std             0.170892
evaluation/Actions Max             0.994786
evaluation/Actions Min            -0.98774
evaluation/Num Paths              15
evaluation/Average Returns      -284.934
time/data storing (s)              0.00304464
time/evaluation sampling (s)       0.368257
time/exploration sampling (s)      0.157746
time/logging (s)                   0.0047959
time/saving (s)                    0.00203941
time/training (s)                  2.13097
time/epoch (s)                     2.66685
time/total (s)                    56.9432
Epoch                             20
-----------------------------  --------------
2019-04-22 22:10:57.688806 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 21 finished
-----------------------------  --------------
replay_buffer/size             11200
trainer/QF1 Loss                   1.16205
trainer/QF2 Loss                   1.14545
trainer/Policy Loss               77.1389
trainer/Q1 Predictions Mean      -76.8013
trainer/Q1 Predictions Std        41.0826
trainer/Q1 Predictions Max       -43.4732
trainer/Q1 Predictions Min      -178.99
trainer/Q2 Predictions Mean      -76.8256
trainer/Q2 Predictions Std        41.0872
trainer/Q2 Predictions Max       -43.4322
trainer/Q2 Predictions Min      -178.983
trainer/Q Targets Mean           -77.0645
trainer/Q Targets Std             41.5481
trainer/Q Targets Max            -42.9087
trainer/Q Targets Min           -176.952
trainer/Log Pis Mean               1.28818
trainer/Log Pis Std                1.37924
trainer/Log Pis Max                5.48015
trainer/Log Pis Min               -2.34323
trainer/Policy mu Mean             0.0073767
trainer/Policy mu Std              0.818477
trainer/Policy mu Max              2.77355
trainer/Policy mu Min             -2.8885
trainer/Policy log std Mean       -1.60978
trainer/Policy log std Std         0.416639
trainer/Policy log std Max        -0.470779
trainer/Policy log std Min        -2.43241
trainer/Alpha                      0.0674917
trainer/Alpha Loss                -1.91873
exploration/num steps total    11200
exploration/num paths total      112
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.3031
exploration/Rewards Std            1.17436
exploration/Rewards Max           -0.637048
exploration/Rewards Min           -7.6998
exploration/Returns Mean        -230.31
exploration/Returns Std          104.494
exploration/Returns Max         -127.228
exploration/Returns Min         -361.322
exploration/Actions Mean          -0.0100791
exploration/Actions Std            0.216362
exploration/Actions Max            0.951641
exploration/Actions Min           -0.991768
exploration/Num Paths              5
exploration/Average Returns     -230.31
evaluation/num steps total     33000
evaluation/num paths total       330
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.76981
evaluation/Rewards Std             1.64415
evaluation/Rewards Max            -0.531018
evaluation/Rewards Min           -11.2723
evaluation/Returns Mean         -276.981
evaluation/Returns Std           148.453
evaluation/Returns Max          -109.425
evaluation/Returns Min          -470.595
evaluation/Actions Mean           -0.00250269
evaluation/Actions Std             0.167186
evaluation/Actions Max             0.997108
evaluation/Actions Min            -0.991864
evaluation/Num Paths              15
evaluation/Average Returns      -276.981
time/data storing (s)              0.00333544
time/evaluation sampling (s)       0.368871
time/exploration sampling (s)      0.160291
time/logging (s)                   0.00681483
time/saving (s)                    0.00221426
time/training (s)                  2.19167
time/epoch (s)                     2.73319
time/total (s)                    59.6814
Epoch                             21
-----------------------------  --------------
2019-04-22 22:11:00.374639 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 22 finished
-----------------------------  --------------
replay_buffer/size             11700
trainer/QF1 Loss                  21.8699
trainer/QF2 Loss                  21.7444
trainer/Policy Loss               97.5276
trainer/Q1 Predictions Mean      -96.6933
trainer/Q1 Predictions Std        44.7643
trainer/Q1 Predictions Max       -43.8685
trainer/Q1 Predictions Min      -165.024
trainer/Q2 Predictions Mean      -96.6676
trainer/Q2 Predictions Std        44.7849
trainer/Q2 Predictions Max       -43.7206
trainer/Q2 Predictions Min      -165.054
trainer/Q Targets Mean           -97.489
trainer/Q Targets Std             46.1467
trainer/Q Targets Max             -1.71504
trainer/Q Targets Min           -168.313
trainer/Log Pis Mean               1.82625
trainer/Log Pis Std                1.56245
trainer/Log Pis Max                7.91367
trainer/Log Pis Min               -3.37281
trainer/Policy mu Mean             0.0638771
trainer/Policy mu Std              0.984816
trainer/Policy mu Max              3.15015
trainer/Policy mu Min             -2.42938
trainer/Policy log std Mean       -1.54705
trainer/Policy log std Std         0.47467
trainer/Policy log std Max        -0.487604
trainer/Policy log std Min        -2.46508
trainer/Alpha                      0.0610404
trainer/Alpha Loss                -0.485804
exploration/num steps total    11700
exploration/num paths total      117
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.61816
exploration/Rewards Std            1.24328
exploration/Rewards Max           -0.666627
exploration/Rewards Min           -9.73847
exploration/Returns Mean        -261.816
exploration/Returns Std          105.645
exploration/Returns Max         -106.248
exploration/Returns Min         -373.036
exploration/Actions Mean           0.0147855
exploration/Actions Std            0.296296
exploration/Actions Max            0.996505
exploration/Actions Min           -0.993649
exploration/Num Paths              5
exploration/Average Returns     -261.816
evaluation/num steps total     34500
evaluation/num paths total       345
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.20989
evaluation/Rewards Std             1.43725
evaluation/Rewards Max            -1.02282
evaluation/Rewards Min           -11.5483
evaluation/Returns Mean         -220.989
evaluation/Returns Std            94.0513
evaluation/Returns Max          -118.256
evaluation/Returns Min          -374.957
evaluation/Actions Mean            0.0032536
evaluation/Actions Std             0.208232
evaluation/Actions Max             0.998673
evaluation/Actions Min            -0.992094
evaluation/Num Paths              15
evaluation/Average Returns      -220.989
time/data storing (s)              0.00333791
time/evaluation sampling (s)       0.371417
time/exploration sampling (s)      0.166039
time/logging (s)                   0.0051183
time/saving (s)                    0.00234727
time/training (s)                  2.12957
time/epoch (s)                     2.67783
time/total (s)                    62.364
Epoch                             22
-----------------------------  --------------
2019-04-22 22:11:03.068263 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 23 finished
-----------------------------  --------------
replay_buffer/size             12200
trainer/QF1 Loss                   1.86021
trainer/QF2 Loss                   1.87351
trainer/Policy Loss               96.5314
trainer/Q1 Predictions Mean      -95.6857
trainer/Q1 Predictions Std        48.4028
trainer/Q1 Predictions Max       -43.8468
trainer/Q1 Predictions Min      -171.024
trainer/Q2 Predictions Mean      -95.681
trainer/Q2 Predictions Std        48.4324
trainer/Q2 Predictions Max       -43.7333
trainer/Q2 Predictions Min      -170.709
trainer/Q Targets Mean           -96.5521
trainer/Q Targets Std             48.7278
trainer/Q Targets Max            -44.4693
trainer/Q Targets Min           -174.455
trainer/Log Pis Mean               1.648
trainer/Log Pis Std                1.5663
trainer/Log Pis Max                7.80144
trainer/Log Pis Min               -3.0363
trainer/Policy mu Mean             0.0514057
trainer/Policy mu Std              0.8121
trainer/Policy mu Max              3.50617
trainer/Policy mu Min             -3.19561
trainer/Policy log std Mean       -1.77605
trainer/Policy log std Std         0.508909
trainer/Policy log std Max        -0.465517
trainer/Policy log std Min        -2.47352
trainer/Alpha                      0.0562317
trainer/Alpha Loss                -1.01309
exploration/num steps total    12200
exploration/num paths total      122
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.71302
exploration/Rewards Std            1.60578
exploration/Rewards Max           -0.365191
exploration/Rewards Min           -8.48194
exploration/Returns Mean        -271.302
exploration/Returns Std          153.706
exploration/Returns Max          -81.9079
exploration/Returns Min         -426.809
exploration/Actions Mean          -0.00330194
exploration/Actions Std            0.215258
exploration/Actions Max            0.988398
exploration/Actions Min           -0.983331
exploration/Num Paths              5
exploration/Average Returns     -271.302
evaluation/num steps total     36000
evaluation/num paths total       360
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.50685
evaluation/Rewards Std             1.69466
evaluation/Rewards Max            -0.75937
evaluation/Rewards Min           -10.4355
evaluation/Returns Mean         -250.685
evaluation/Returns Std           151.229
evaluation/Returns Max           -86.5608
evaluation/Returns Min          -449.063
evaluation/Actions Mean            0.00145193
evaluation/Actions Std             0.180317
evaluation/Actions Max             0.995691
evaluation/Actions Min            -0.996445
evaluation/Num Paths              15
evaluation/Average Returns      -250.685
time/data storing (s)              0.00326036
time/evaluation sampling (s)       0.363316
time/exploration sampling (s)      0.162831
time/logging (s)                   0.00530155
time/saving (s)                    0.00208434
time/training (s)                  2.15163
time/epoch (s)                     2.68842
time/total (s)                    65.0567
Epoch                             23
-----------------------------  --------------
2019-04-22 22:11:05.802457 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 24 finished
-----------------------------  ---------------
replay_buffer/size             12700
trainer/QF1 Loss                  30.1153
trainer/QF2 Loss                  31.2203
trainer/Policy Loss               94.4984
trainer/Q1 Predictions Mean      -93.6432
trainer/Q1 Predictions Std        46.1773
trainer/Q1 Predictions Max       -44.0336
trainer/Q1 Predictions Min      -179.435
trainer/Q2 Predictions Mean      -93.6292
trainer/Q2 Predictions Std        46.1513
trainer/Q2 Predictions Max       -44.1826
trainer/Q2 Predictions Min      -179.488
trainer/Q Targets Mean           -93.8059
trainer/Q Targets Std             47.4159
trainer/Q Targets Max             -7.25931
trainer/Q Targets Min           -180.726
trainer/Log Pis Mean               1.98307
trainer/Log Pis Std                1.51994
trainer/Log Pis Max                7.38667
trainer/Log Pis Min               -1.45916
trainer/Policy mu Mean            -0.0399373
trainer/Policy mu Std              0.996695
trainer/Policy mu Max              2.77622
trainer/Policy mu Min             -3.54319
trainer/Policy log std Mean       -1.67166
trainer/Policy log std Std         0.500313
trainer/Policy log std Max        -0.334184
trainer/Policy log std Min        -2.41539
trainer/Alpha                      0.0521577
trainer/Alpha Loss                -0.0499872
exploration/num steps total    12700
exploration/num paths total      127
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.90227
exploration/Rewards Std            1.63105
exploration/Rewards Max           -0.5873
exploration/Rewards Min           -7.99987
exploration/Returns Mean        -290.227
exploration/Returns Std          151.622
exploration/Returns Max          -94.0544
exploration/Returns Min         -422.217
exploration/Actions Mean           0.0192582
exploration/Actions Std            0.243362
exploration/Actions Max            0.995086
exploration/Actions Min           -0.972885
exploration/Num Paths              5
exploration/Average Returns     -290.227
evaluation/num steps total     37500
evaluation/num paths total       375
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.37246
evaluation/Rewards Std             1.53109
evaluation/Rewards Max            -0.218237
evaluation/Rewards Min           -11.8373
evaluation/Returns Mean         -137.246
evaluation/Returns Std           112.228
evaluation/Returns Max           -60.5032
evaluation/Returns Min          -419.783
evaluation/Actions Mean           -0.000417104
evaluation/Actions Std             0.197477
evaluation/Actions Max             0.998626
evaluation/Actions Min            -0.996809
evaluation/Num Paths              15
evaluation/Average Returns      -137.246
time/data storing (s)              0.00343392
time/evaluation sampling (s)       0.379721
time/exploration sampling (s)      0.199224
time/logging (s)                   0.00547264
time/saving (s)                    0.0022194
time/training (s)                  2.13866
time/epoch (s)                     2.72873
time/total (s)                    67.79
Epoch                             24
-----------------------------  ---------------
2019-04-22 22:11:08.475867 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 25 finished
-----------------------------  --------------
replay_buffer/size             13200
trainer/QF1 Loss                  31.3664
trainer/QF2 Loss                  32.4374
trainer/Policy Loss              103.522
trainer/Q1 Predictions Mean     -102.769
trainer/Q1 Predictions Std        51.5895
trainer/Q1 Predictions Max       -44.86
trainer/Q1 Predictions Min      -184.636
trainer/Q2 Predictions Mean     -102.742
trainer/Q2 Predictions Std        51.5833
trainer/Q2 Predictions Max       -45.0063
trainer/Q2 Predictions Min      -184.615
trainer/Q Targets Mean          -103.258
trainer/Q Targets Std             52.8804
trainer/Q Targets Max             -7.25931
trainer/Q Targets Min           -186.926
trainer/Log Pis Mean               2.04782
trainer/Log Pis Std                1.89278
trainer/Log Pis Max                9.23271
trainer/Log Pis Min               -3.19971
trainer/Policy mu Mean            -0.00196441
trainer/Policy mu Std              1.09733
trainer/Policy mu Max              3.33751
trainer/Policy mu Min             -3.51487
trainer/Policy log std Mean       -1.6993
trainer/Policy log std Std         0.537823
trainer/Policy log std Max        -0.33322
trainer/Policy log std Min        -2.57535
trainer/Alpha                      0.0483706
trainer/Alpha Loss                 0.144827
exploration/num steps total    13200
exploration/num paths total      132
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.39718
exploration/Rewards Std            1.66313
exploration/Rewards Max           -0.0359647
exploration/Rewards Min           -4.95859
exploration/Returns Mean        -239.718
exploration/Returns Std          159.962
exploration/Returns Max          -39.2689
exploration/Returns Min         -378.499
exploration/Actions Mean           0.00903252
exploration/Actions Std            0.22079
exploration/Actions Max            0.979331
exploration/Actions Min           -0.953461
exploration/Num Paths              5
exploration/Average Returns     -239.718
evaluation/num steps total     39000
evaluation/num paths total       390
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.04189
evaluation/Rewards Std             1.57379
evaluation/Rewards Max            -0.0983897
evaluation/Rewards Min           -10.1521
evaluation/Returns Mean         -204.189
evaluation/Returns Std           144.508
evaluation/Returns Max           -27.6009
evaluation/Returns Min          -379.698
evaluation/Actions Mean           -0.00267669
evaluation/Actions Std             0.157911
evaluation/Actions Max             0.998382
evaluation/Actions Min            -0.990484
evaluation/Num Paths              15
evaluation/Average Returns      -204.189
time/data storing (s)              0.0033155
time/evaluation sampling (s)       0.36257
time/exploration sampling (s)      0.160149
time/logging (s)                   0.00496563
time/saving (s)                    0.00200961
time/training (s)                  2.13407
time/epoch (s)                     2.66708
time/total (s)                    70.4618
Epoch                             25
-----------------------------  --------------
2019-04-22 22:11:11.209306 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 26 finished
-----------------------------  --------------
replay_buffer/size             13700
trainer/QF1 Loss                  24.2904
trainer/QF2 Loss                  24.3642
trainer/Policy Loss              101.434
trainer/Q1 Predictions Mean     -100.428
trainer/Q1 Predictions Std        52.3958
trainer/Q1 Predictions Max       -45.4032
trainer/Q1 Predictions Min      -171.283
trainer/Q2 Predictions Mean     -100.407
trainer/Q2 Predictions Std        52.3938
trainer/Q2 Predictions Max       -45.5455
trainer/Q2 Predictions Min      -171.419
trainer/Q Targets Mean          -101.295
trainer/Q Targets Std             53.9513
trainer/Q Targets Max             -0.506286
trainer/Q Targets Min           -177.199
trainer/Log Pis Mean               1.95761
trainer/Log Pis Std                1.43792
trainer/Log Pis Max                6.43039
trainer/Log Pis Min               -2.69647
trainer/Policy mu Mean             0.0476999
trainer/Policy mu Std              0.879192
trainer/Policy mu Max              3.06688
trainer/Policy mu Min             -2.9538
trainer/Policy log std Mean       -1.80948
trainer/Policy log std Std         0.454442
trainer/Policy log std Max        -0.22847
trainer/Policy log std Min        -2.40271
trainer/Alpha                      0.0453835
trainer/Alpha Loss                -0.131086
exploration/num steps total    13700
exploration/num paths total      137
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.68662
exploration/Rewards Std            1.56299
exploration/Rewards Max           -0.215697
exploration/Rewards Min           -9.61015
exploration/Returns Mean        -168.662
exploration/Returns Std          137.146
exploration/Returns Max          -62.7279
exploration/Returns Min         -428.305
exploration/Actions Mean           0.011196
exploration/Actions Std            0.224577
exploration/Actions Max            0.995514
exploration/Actions Min           -0.999613
exploration/Num Paths              5
exploration/Average Returns     -168.662
evaluation/num steps total     40500
evaluation/num paths total       405
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.31323
evaluation/Rewards Std             1.65101
evaluation/Rewards Max            -0.544174
evaluation/Rewards Min            -9.61151
evaluation/Returns Mean         -231.323
evaluation/Returns Std           147.622
evaluation/Returns Max           -74.6609
evaluation/Returns Min          -425.965
evaluation/Actions Mean           -0.00328993
evaluation/Actions Std             0.166429
evaluation/Actions Max             0.999265
evaluation/Actions Min            -0.99394
evaluation/Num Paths              15
evaluation/Average Returns      -231.323
time/data storing (s)              0.00307288
time/evaluation sampling (s)       0.361869
time/exploration sampling (s)      0.158586
time/logging (s)                   0.00524768
time/saving (s)                    0.00207947
time/training (s)                  2.19692
time/epoch (s)                     2.72777
time/total (s)                    73.1944
Epoch                             26
-----------------------------  --------------
2019-04-22 22:11:13.913466 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 27 finished
-----------------------------  --------------
replay_buffer/size             14200
trainer/QF1 Loss                 261.392
trainer/QF2 Loss                 259.903
trainer/Policy Loss               98.7605
trainer/Q1 Predictions Mean      -97.7364
trainer/Q1 Predictions Std        53.8207
trainer/Q1 Predictions Max       -46.3379
trainer/Q1 Predictions Min      -185.148
trainer/Q2 Predictions Mean      -97.5993
trainer/Q2 Predictions Std        53.8619
trainer/Q2 Predictions Max       -46.2611
trainer/Q2 Predictions Min      -185.286
trainer/Q Targets Mean           -96.7982
trainer/Q Targets Std             54.8593
trainer/Q Targets Max             -4.55125
trainer/Q Targets Min           -186.533
trainer/Log Pis Mean               2.33512
trainer/Log Pis Std                1.50053
trainer/Log Pis Max                8.58243
trainer/Log Pis Min               -2.94529
trainer/Policy mu Mean             0.204586
trainer/Policy mu Std              0.973821
trainer/Policy mu Max              3.16081
trainer/Policy mu Min             -3.12447
trainer/Policy log std Mean       -1.82155
trainer/Policy log std Std         0.461083
trainer/Policy log std Max        -0.484339
trainer/Policy log std Min        -2.52657
trainer/Alpha                      0.0463772
trainer/Alpha Loss                 1.02917
exploration/num steps total    14200
exploration/num paths total      142
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.0885
exploration/Rewards Std            1.47846
exploration/Rewards Max           -0.44831
exploration/Rewards Min          -10.8639
exploration/Returns Mean        -208.85
exploration/Returns Std          114.092
exploration/Returns Max          -88.2181
exploration/Returns Min         -348.394
exploration/Actions Mean           0.0200317
exploration/Actions Std            0.249901
exploration/Actions Max            0.997351
exploration/Actions Min           -0.987284
exploration/Num Paths              5
exploration/Average Returns     -208.85
evaluation/num steps total     42000
evaluation/num paths total       420
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.58454
evaluation/Rewards Std             1.23653
evaluation/Rewards Max            -0.214364
evaluation/Rewards Min            -9.83443
evaluation/Returns Mean         -258.454
evaluation/Returns Std           100.74
evaluation/Returns Max           -73.113
evaluation/Returns Min          -361.048
evaluation/Actions Mean            0.0210721
evaluation/Actions Std             0.170944
evaluation/Actions Max             0.998544
evaluation/Actions Min            -0.98726
evaluation/Num Paths              15
evaluation/Average Returns      -258.454
time/data storing (s)              0.00500274
time/evaluation sampling (s)       0.362787
time/exploration sampling (s)      0.186726
time/logging (s)                   0.0044483
time/saving (s)                    0.00998728
time/training (s)                  2.12854
time/epoch (s)                     2.69749
time/total (s)                    75.8966
Epoch                             27
-----------------------------  --------------
2019-04-22 22:11:16.624819 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 28 finished
-----------------------------  --------------
replay_buffer/size             14700
trainer/QF1 Loss                  22.0474
trainer/QF2 Loss                  21.5399
trainer/Policy Loss               88.0893
trainer/Q1 Predictions Mean      -86.7188
trainer/Q1 Predictions Std        50.543
trainer/Q1 Predictions Max       -45.1274
trainer/Q1 Predictions Min      -174.292
trainer/Q2 Predictions Mean      -86.7676
trainer/Q2 Predictions Std        50.5662
trainer/Q2 Predictions Max       -44.9069
trainer/Q2 Predictions Min      -174.357
trainer/Q Targets Mean           -87.2479
trainer/Q Targets Std             51.4298
trainer/Q Targets Max             -1.20324
trainer/Q Targets Min           -176.736
trainer/Log Pis Mean               2.12385
trainer/Log Pis Std                1.23007
trainer/Log Pis Max                5.82245
trainer/Log Pis Min               -1.50949
trainer/Policy mu Mean            -0.0795046
trainer/Policy mu Std              0.854587
trainer/Policy mu Max              2.60972
trainer/Policy mu Min             -3.58447
trainer/Policy log std Mean       -1.88555
trainer/Policy log std Std         0.443535
trainer/Policy log std Max        -0.231184
trainer/Policy log std Min        -2.50657
trainer/Alpha                      0.0491135
trainer/Alpha Loss                 0.37325
exploration/num steps total    14700
exploration/num paths total      147
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.24489
exploration/Rewards Std            1.631
exploration/Rewards Max           -0.518435
exploration/Rewards Min           -9.42635
exploration/Returns Mean        -224.489
exploration/Returns Std          130.421
exploration/Returns Max         -110.737
exploration/Returns Min         -394.408
exploration/Actions Mean          -0.0106492
exploration/Actions Std            0.229441
exploration/Actions Max            0.998338
exploration/Actions Min           -0.985101
exploration/Num Paths              5
exploration/Average Returns     -224.489
evaluation/num steps total     43500
evaluation/num paths total       435
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.49696
evaluation/Rewards Std             1.37178
evaluation/Rewards Max            -0.369758
evaluation/Rewards Min            -9.04156
evaluation/Returns Mean         -149.696
evaluation/Returns Std           113.449
evaluation/Returns Max           -42.26
evaluation/Returns Min          -378.738
evaluation/Actions Mean           -0.00791605
evaluation/Actions Std             0.164269
evaluation/Actions Max             0.998552
evaluation/Actions Min            -0.996403
evaluation/Num Paths              15
evaluation/Average Returns      -149.696
time/data storing (s)              0.00307417
time/evaluation sampling (s)       0.353314
time/exploration sampling (s)      0.155994
time/logging (s)                   0.00490295
time/saving (s)                    0.00215777
time/training (s)                  2.18643
time/epoch (s)                     2.70587
time/total (s)                    78.6073
Epoch                             28
-----------------------------  --------------
2019-04-22 22:11:19.282033 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 29 finished
-----------------------------  --------------
replay_buffer/size             15200
trainer/QF1 Loss                 562.792
trainer/QF2 Loss                 561.718
trainer/Policy Loss               94.12
trainer/Q1 Predictions Mean      -93.5104
trainer/Q1 Predictions Std        51.4408
trainer/Q1 Predictions Max       -45.8722
trainer/Q1 Predictions Min      -176.144
trainer/Q2 Predictions Mean      -93.3823
trainer/Q2 Predictions Std        51.4863
trainer/Q2 Predictions Max       -45.8109
trainer/Q2 Predictions Min      -176.465
trainer/Q Targets Mean           -90.5702
trainer/Q Targets Std             52.0751
trainer/Q Targets Max             -5.03248
trainer/Q Targets Min           -179.709
trainer/Log Pis Mean               1.98531
trainer/Log Pis Std                1.64432
trainer/Log Pis Max                6.44423
trainer/Log Pis Min               -3.76694
trainer/Policy mu Mean             0.106711
trainer/Policy mu Std              0.97639
trainer/Policy mu Max              3.3454
trainer/Policy mu Min             -2.79393
trainer/Policy log std Mean       -1.77261
trainer/Policy log std Std         0.515594
trainer/Policy log std Max        -0.120853
trainer/Policy log std Min        -2.4736
trainer/Alpha                      0.0523339
trainer/Alpha Loss                -0.0433343
exploration/num steps total    15200
exploration/num paths total      152
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.03633
exploration/Rewards Std            0.653497
exploration/Rewards Max           -0.328264
exploration/Rewards Min           -8.18149
exploration/Returns Mean        -103.633
exploration/Returns Std           16.0842
exploration/Returns Max          -78.2857
exploration/Returns Min         -126.171
exploration/Actions Mean           0.0184173
exploration/Actions Std            0.205485
exploration/Actions Max            0.993174
exploration/Actions Min           -0.986913
exploration/Num Paths              5
exploration/Average Returns     -103.633
evaluation/num steps total     45000
evaluation/num paths total       450
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.08478
evaluation/Rewards Std             1.59001
evaluation/Rewards Max            -0.290946
evaluation/Rewards Min           -10.4802
evaluation/Returns Mean         -208.478
evaluation/Returns Std           136.814
evaluation/Returns Max           -60.3675
evaluation/Returns Min          -391.588
evaluation/Actions Mean           -0.0115278
evaluation/Actions Std             0.17517
evaluation/Actions Max             0.997672
evaluation/Actions Min            -0.996475
evaluation/Num Paths              15
evaluation/Average Returns      -208.478
time/data storing (s)              0.00312827
time/evaluation sampling (s)       0.364068
time/exploration sampling (s)      0.165203
time/logging (s)                   0.00448262
time/saving (s)                    0.00238394
time/training (s)                  2.11195
time/epoch (s)                     2.65122
time/total (s)                    81.2629
Epoch                             29
-----------------------------  --------------
2019-04-22 22:11:21.990861 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 30 finished
-----------------------------  --------------
replay_buffer/size             15700
trainer/QF1 Loss                  24.4233
trainer/QF2 Loss                  23.5541
trainer/Policy Loss               88.818
trainer/Q1 Predictions Mean      -87.9049
trainer/Q1 Predictions Std        51.5887
trainer/Q1 Predictions Max       -44.891
trainer/Q1 Predictions Min      -175.733
trainer/Q2 Predictions Mean      -87.9794
trainer/Q2 Predictions Std        51.5881
trainer/Q2 Predictions Max       -44.9603
trainer/Q2 Predictions Min      -176.237
trainer/Q Targets Mean           -88.0254
trainer/Q Targets Std             52.4366
trainer/Q Targets Max             -3.0163
trainer/Q Targets Min           -178.64
trainer/Log Pis Mean               1.58673
trainer/Log Pis Std                1.42802
trainer/Log Pis Max                7.60095
trainer/Log Pis Min               -2.03934
trainer/Policy mu Mean             0.0307843
trainer/Policy mu Std              0.802964
trainer/Policy mu Max              3.1669
trainer/Policy mu Min             -3.41231
trainer/Policy log std Mean       -1.81325
trainer/Policy log std Std         0.426907
trainer/Policy log std Max        -0.206441
trainer/Policy log std Min        -2.43499
trainer/Alpha                      0.0538602
trainer/Alpha Loss                -1.20723
exploration/num steps total    15700
exploration/num paths total      157
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.14814
exploration/Rewards Std            1.315
exploration/Rewards Max           -0.095114
exploration/Rewards Min           -9.50182
exploration/Returns Mean        -214.814
exploration/Returns Std          122.694
exploration/Returns Max          -36.9705
exploration/Returns Min         -364.062
exploration/Actions Mean           0.0174335
exploration/Actions Std            0.209529
exploration/Actions Max            0.995963
exploration/Actions Min           -0.914598
exploration/Num Paths              5
exploration/Average Returns     -214.814
evaluation/num steps total     46500
evaluation/num paths total       465
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.6205
evaluation/Rewards Std             1.63064
evaluation/Rewards Max            -0.0541905
evaluation/Rewards Min           -11.9132
evaluation/Returns Mean         -162.05
evaluation/Returns Std           125.44
evaluation/Returns Max            -8.36557
evaluation/Returns Min          -369.926
evaluation/Actions Mean           -0.0113425
evaluation/Actions Std             0.190795
evaluation/Actions Max             0.997867
evaluation/Actions Min            -0.997797
evaluation/Num Paths              15
evaluation/Average Returns      -162.05
time/data storing (s)              0.00344054
time/evaluation sampling (s)       0.356466
time/exploration sampling (s)      0.159069
time/logging (s)                   0.0047536
time/saving (s)                    0.00204466
time/training (s)                  2.1772
time/epoch (s)                     2.70298
time/total (s)                    83.9709
Epoch                             30
-----------------------------  --------------
2019-04-22 22:11:24.763259 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 31 finished
-----------------------------  --------------
replay_buffer/size             16200
trainer/QF1 Loss                 355.057
trainer/QF2 Loss                 354.198
trainer/Policy Loss               95.8004
trainer/Q1 Predictions Mean      -94.9031
trainer/Q1 Predictions Std        54.8566
trainer/Q1 Predictions Max       -45.3436
trainer/Q1 Predictions Min      -176.597
trainer/Q2 Predictions Mean      -94.9357
trainer/Q2 Predictions Std        54.8279
trainer/Q2 Predictions Max       -45.3958
trainer/Q2 Predictions Min      -176.857
trainer/Q Targets Mean           -92.728
trainer/Q Targets Std             56.7271
trainer/Q Targets Max             -1.67836
trainer/Q Targets Min           -179.272
trainer/Log Pis Mean               1.74966
trainer/Log Pis Std                1.29521
trainer/Log Pis Max                5.06225
trainer/Log Pis Min               -2.83591
trainer/Policy mu Mean             0.0431854
trainer/Policy mu Std              0.796738
trainer/Policy mu Max              2.74285
trainer/Policy mu Min             -2.94782
trainer/Policy log std Mean       -1.85395
trainer/Policy log std Std         0.403838
trainer/Policy log std Max        -0.433603
trainer/Policy log std Min        -2.45968
trainer/Alpha                      0.0562013
trainer/Alpha Loss                -0.720669
exploration/num steps total    16200
exploration/num paths total      162
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.29941
exploration/Rewards Std            1.58562
exploration/Rewards Max           -0.0442182
exploration/Rewards Min           -9.64151
exploration/Returns Mean        -129.941
exploration/Returns Std          124.114
exploration/Returns Max          -53.9448
exploration/Returns Min         -377.287
exploration/Actions Mean          -0.016088
exploration/Actions Std            0.233449
exploration/Actions Max            0.999259
exploration/Actions Min           -0.997245
exploration/Num Paths              5
exploration/Average Returns     -129.941
evaluation/num steps total     48000
evaluation/num paths total       480
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.94702
evaluation/Rewards Std             1.47715
evaluation/Rewards Max            -0.209229
evaluation/Rewards Min            -8.88431
evaluation/Returns Mean         -194.702
evaluation/Returns Std           134.146
evaluation/Returns Max           -51.9095
evaluation/Returns Min          -364.212
evaluation/Actions Mean            0.00171302
evaluation/Actions Std             0.161734
evaluation/Actions Max             0.998743
evaluation/Actions Min            -0.98946
evaluation/Num Paths              15
evaluation/Average Returns      -194.702
time/data storing (s)              0.00342608
time/evaluation sampling (s)       0.355003
time/exploration sampling (s)      0.157311
time/logging (s)                   0.005094
time/saving (s)                    0.00203203
time/training (s)                  2.24403
time/epoch (s)                     2.7669
time/total (s)                    86.7427
Epoch                             31
-----------------------------  --------------
2019-04-22 22:11:27.819860 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 32 finished
-----------------------------  ---------------
replay_buffer/size             16700
trainer/QF1 Loss                   1.73132
trainer/QF2 Loss                   1.83937
trainer/Policy Loss               92.1727
trainer/Q1 Predictions Mean      -90.948
trainer/Q1 Predictions Std        52.2629
trainer/Q1 Predictions Max       -43.9878
trainer/Q1 Predictions Min      -184.709
trainer/Q2 Predictions Mean      -90.8815
trainer/Q2 Predictions Std        52.2479
trainer/Q2 Predictions Max       -43.9063
trainer/Q2 Predictions Min      -184.068
trainer/Q Targets Mean           -91.8725
trainer/Q Targets Std             52.7709
trainer/Q Targets Max            -44.5737
trainer/Q Targets Min           -185.853
trainer/Log Pis Mean               2.33464
trainer/Log Pis Std                1.44844
trainer/Log Pis Max                6.89776
trainer/Log Pis Min               -2.3221
trainer/Policy mu Mean             0.0364875
trainer/Policy mu Std              0.920623
trainer/Policy mu Max              3.19134
trainer/Policy mu Min             -2.92009
trainer/Policy log std Mean       -1.86673
trainer/Policy log std Std         0.508297
trainer/Policy log std Max        -0.376063
trainer/Policy log std Min        -2.67356
trainer/Alpha                      0.0573718
trainer/Alpha Loss                 0.956509
exploration/num steps total    16700
exploration/num paths total      167
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.03988
exploration/Rewards Std            0.812397
exploration/Rewards Max           -0.370965
exploration/Rewards Min           -8.08675
exploration/Returns Mean        -103.988
exploration/Returns Std           30.2038
exploration/Returns Max          -67.4717
exploration/Returns Min         -149.967
exploration/Actions Mean          -0.00661887
exploration/Actions Std            0.198528
exploration/Actions Max            0.995482
exploration/Actions Min           -0.995357
exploration/Num Paths              5
exploration/Average Returns     -103.988
evaluation/num steps total     49500
evaluation/num paths total       495
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.50963
evaluation/Rewards Std             1.46656
evaluation/Rewards Max            -0.300887
evaluation/Rewards Min           -10.9724
evaluation/Returns Mean         -250.963
evaluation/Returns Std           134.622
evaluation/Returns Max           -70.0588
evaluation/Returns Min          -377.315
evaluation/Actions Mean           -0.000419925
evaluation/Actions Std             0.15345
evaluation/Actions Max             0.998986
evaluation/Actions Min            -0.996405
evaluation/Num Paths              15
evaluation/Average Returns      -250.963
time/data storing (s)              0.00379601
time/evaluation sampling (s)       0.385986
time/exploration sampling (s)      0.188169
time/logging (s)                   0.00516815
time/saving (s)                    0.00189189
time/training (s)                  2.46581
time/epoch (s)                     3.05082
time/total (s)                    89.7982
Epoch                             32
-----------------------------  ---------------
2019-04-22 22:11:30.402440 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 33 finished
-----------------------------  --------------
replay_buffer/size             17200
trainer/QF1 Loss                  20.9097
trainer/QF2 Loss                  20.2834
trainer/Policy Loss               97.4619
trainer/Q1 Predictions Mean      -96.0416
trainer/Q1 Predictions Std        55.4459
trainer/Q1 Predictions Max       -42.7535
trainer/Q1 Predictions Min      -179.073
trainer/Q2 Predictions Mean      -96.0843
trainer/Q2 Predictions Std        55.4681
trainer/Q2 Predictions Max       -43.0991
trainer/Q2 Predictions Min      -179.146
trainer/Q Targets Mean           -96.4046
trainer/Q Targets Std             56.5119
trainer/Q Targets Max             -0.446754
trainer/Q Targets Min           -183.022
trainer/Log Pis Mean               2.19131
trainer/Log Pis Std                1.44914
trainer/Log Pis Max                7.07563
trainer/Log Pis Min               -3.08025
trainer/Policy mu Mean             0.24783
trainer/Policy mu Std              0.880244
trainer/Policy mu Max              2.93354
trainer/Policy mu Min             -2.47607
trainer/Policy log std Mean       -1.84996
trainer/Policy log std Std         0.542867
trainer/Policy log std Max        -0.237041
trainer/Policy log std Min        -2.63073
trainer/Alpha                      0.0594064
trainer/Alpha Loss                 0.540166
exploration/num steps total    17200
exploration/num paths total      172
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.65026
exploration/Rewards Std            1.56031
exploration/Rewards Max           -0.51565
exploration/Rewards Min          -10.5428
exploration/Returns Mean        -165.026
exploration/Returns Std          115.098
exploration/Returns Max          -85.0826
exploration/Returns Min         -393.804
exploration/Actions Mean          -0.00198729
exploration/Actions Std            0.23434
exploration/Actions Max            0.998505
exploration/Actions Min           -0.998688
exploration/Num Paths              5
exploration/Average Returns     -165.026
evaluation/num steps total     51000
evaluation/num paths total       510
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.67974
evaluation/Rewards Std             1.45903
evaluation/Rewards Max            -0.529252
evaluation/Rewards Min            -8.82695
evaluation/Returns Mean         -167.974
evaluation/Returns Std           127.858
evaluation/Returns Max           -62.6084
evaluation/Returns Min          -384.612
evaluation/Actions Mean           -0.00788957
evaluation/Actions Std             0.157785
evaluation/Actions Max             0.9964
evaluation/Actions Min            -0.996679
evaluation/Num Paths              15
evaluation/Average Returns      -167.974
time/data storing (s)              0.00316759
time/evaluation sampling (s)       0.364449
time/exploration sampling (s)      0.160992
time/logging (s)                   0.00511437
time/saving (s)                    0.00246786
time/training (s)                  2.03885
time/epoch (s)                     2.57504
time/total (s)                    92.3794
Epoch                             33
-----------------------------  --------------
2019-04-22 22:11:33.317139 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 34 finished
-----------------------------  --------------
replay_buffer/size             17700
trainer/QF1 Loss                  23.3891
trainer/QF2 Loss                  23.5521
trainer/Policy Loss              100.593
trainer/Q1 Predictions Mean      -99.6787
trainer/Q1 Predictions Std        58.9994
trainer/Q1 Predictions Max       -42.8472
trainer/Q1 Predictions Min      -200.273
trainer/Q2 Predictions Mean      -99.668
trainer/Q2 Predictions Std        58.9377
trainer/Q2 Predictions Max       -42.9101
trainer/Q2 Predictions Min      -199.996
trainer/Q Targets Mean           -99.3156
trainer/Q Targets Std             59.6949
trainer/Q Targets Max             -0.863386
trainer/Q Targets Min           -200.801
trainer/Log Pis Mean               1.8112
trainer/Log Pis Std                1.19855
trainer/Log Pis Max                6.00219
trainer/Log Pis Min               -2.46783
trainer/Policy mu Mean             0.21877
trainer/Policy mu Std              0.85107
trainer/Policy mu Max              2.97051
trainer/Policy mu Min             -2.75544
trainer/Policy log std Mean       -1.76867
trainer/Policy log std Std         0.533061
trainer/Policy log std Max        -0.177518
trainer/Policy log std Min        -2.59817
trainer/Alpha                      0.0629583
trainer/Alpha Loss                -0.522082
exploration/num steps total    17700
exploration/num paths total      177
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -3.41342
exploration/Rewards Std            1.31053
exploration/Rewards Max           -0.252996
exploration/Rewards Min           -9.00583
exploration/Returns Mean        -341.342
exploration/Returns Std          117.198
exploration/Returns Max         -108.482
exploration/Returns Min         -418.566
exploration/Actions Mean          -0.0022957
exploration/Actions Std            0.210429
exploration/Actions Max            0.9993
exploration/Actions Min           -0.992614
exploration/Num Paths              5
exploration/Average Returns     -341.342
evaluation/num steps total     52500
evaluation/num paths total       525
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.86954
evaluation/Rewards Std             1.5529
evaluation/Rewards Max            -0.300538
evaluation/Rewards Min            -8.26452
evaluation/Returns Mean         -186.954
evaluation/Returns Std           145.544
evaluation/Returns Max           -61.3707
evaluation/Returns Min          -415.663
evaluation/Actions Mean           -0.00206994
evaluation/Actions Std             0.149408
evaluation/Actions Max             0.996894
evaluation/Actions Min            -0.998229
evaluation/Num Paths              15
evaluation/Average Returns      -186.954
time/data storing (s)              0.00324893
time/evaluation sampling (s)       0.357389
time/exploration sampling (s)      0.160253
time/logging (s)                   0.00559449
time/saving (s)                    0.00209808
time/training (s)                  2.38085
time/epoch (s)                     2.90944
time/total (s)                    95.2934
Epoch                             34
-----------------------------  --------------
2019-04-22 22:11:36.327445 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 35 finished
-----------------------------  --------------
replay_buffer/size             18200
trainer/QF1 Loss                 387.526
trainer/QF2 Loss                 388.515
trainer/Policy Loss               99.9475
trainer/Q1 Predictions Mean      -99.1671
trainer/Q1 Predictions Std        56.674
trainer/Q1 Predictions Max       -42.0882
trainer/Q1 Predictions Min      -197.525
trainer/Q2 Predictions Mean      -99.171
trainer/Q2 Predictions Std        56.6724
trainer/Q2 Predictions Max       -42.267
trainer/Q2 Predictions Min      -197.284
trainer/Q Targets Mean           -97.1593
trainer/Q Targets Std             59.6513
trainer/Q Targets Max             -0.455554
trainer/Q Targets Min           -199.296
trainer/Log Pis Mean               1.90475
trainer/Log Pis Std                1.28603
trainer/Log Pis Max                6.81868
trainer/Log Pis Min               -1.4603
trainer/Policy mu Mean             0.0327399
trainer/Policy mu Std              0.918391
trainer/Policy mu Max              2.88819
trainer/Policy mu Min             -3.12088
trainer/Policy log std Mean       -1.79602
trainer/Policy log std Std         0.491696
trainer/Policy log std Max        -0.333518
trainer/Policy log std Min        -2.56085
trainer/Alpha                      0.0605753
trainer/Alpha Loss                -0.26706
exploration/num steps total    18200
exploration/num paths total      182
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.13749
exploration/Rewards Std            1.30688
exploration/Rewards Max           -0.163165
exploration/Rewards Min           -7.26269
exploration/Returns Mean        -113.749
exploration/Returns Std          118.913
exploration/Returns Max          -44.8755
exploration/Returns Min         -350.727
exploration/Actions Mean          -0.00626173
exploration/Actions Std            0.178268
exploration/Actions Max            0.995139
exploration/Actions Min           -0.999082
exploration/Num Paths              5
exploration/Average Returns     -113.749
evaluation/num steps total     54000
evaluation/num paths total       540
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.7269
evaluation/Rewards Std             1.48526
evaluation/Rewards Max            -0.198608
evaluation/Rewards Min           -10.0556
evaluation/Returns Mean         -172.69
evaluation/Returns Std           134.566
evaluation/Returns Max           -44.9288
evaluation/Returns Min          -373.417
evaluation/Actions Mean            0.0150388
evaluation/Actions Std             0.173648
evaluation/Actions Max             0.994994
evaluation/Actions Min            -0.983932
evaluation/Num Paths              15
evaluation/Average Returns      -172.69
time/data storing (s)              0.00305074
time/evaluation sampling (s)       0.366238
time/exploration sampling (s)      0.160547
time/logging (s)                   0.00604883
time/saving (s)                    0.0024327
time/training (s)                  2.46523
time/epoch (s)                     3.00355
time/total (s)                    98.3029
Epoch                             35
-----------------------------  --------------
2019-04-22 22:11:38.988254 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 36 finished
-----------------------------  --------------
replay_buffer/size             18700
trainer/QF1 Loss                 576.194
trainer/QF2 Loss                 575.89
trainer/Policy Loss              101.497
trainer/Q1 Predictions Mean     -100.405
trainer/Q1 Predictions Std        59.019
trainer/Q1 Predictions Max       -42.0448
trainer/Q1 Predictions Min      -202.509
trainer/Q2 Predictions Mean     -100.45
trainer/Q2 Predictions Std        59.0237
trainer/Q2 Predictions Max       -42.0207
trainer/Q2 Predictions Min      -202.614
trainer/Q Targets Mean           -96.9023
trainer/Q Targets Std             60.3229
trainer/Q Targets Max             -0.834023
trainer/Q Targets Min           -202.05
trainer/Log Pis Mean               1.94502
trainer/Log Pis Std                1.42708
trainer/Log Pis Max                9.55539
trainer/Log Pis Min               -1.70133
trainer/Policy mu Mean             0.205998
trainer/Policy mu Std              0.863054
trainer/Policy mu Max              3.12042
trainer/Policy mu Min             -2.9085
trainer/Policy log std Mean       -1.83371
trainer/Policy log std Std         0.523557
trainer/Policy log std Max        -0.259774
trainer/Policy log std Min        -2.59891
trainer/Alpha                      0.0614031
trainer/Alpha Loss                -0.153429
exploration/num steps total    18700
exploration/num paths total      187
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -3.24961
exploration/Rewards Std            1.36305
exploration/Rewards Max           -0.334483
exploration/Rewards Min           -8.06919
exploration/Returns Mean        -324.961
exploration/Returns Std          120.232
exploration/Returns Max          -86.3825
exploration/Returns Min         -405.995
exploration/Actions Mean          -0.025265
exploration/Actions Std            0.202589
exploration/Actions Max            0.998265
exploration/Actions Min           -0.994792
exploration/Num Paths              5
exploration/Average Returns     -324.961
evaluation/num steps total     55500
evaluation/num paths total       555
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.40263
evaluation/Rewards Std             1.47423
evaluation/Rewards Max            -0.369373
evaluation/Rewards Min           -10.2075
evaluation/Returns Mean         -140.263
evaluation/Returns Std           111.687
evaluation/Returns Max           -51.615
evaluation/Returns Min          -365.062
evaluation/Actions Mean           -0.0154401
evaluation/Actions Std             0.180897
evaluation/Actions Max             0.993511
evaluation/Actions Min            -0.998641
evaluation/Num Paths              15
evaluation/Average Returns      -140.263
time/data storing (s)              0.00315426
time/evaluation sampling (s)       0.377449
time/exploration sampling (s)      0.153483
time/logging (s)                   0.00490514
time/saving (s)                    0.00202487
time/training (s)                  2.11149
time/epoch (s)                     2.6525
time/total (s)                   100.961
Epoch                             36
-----------------------------  --------------
2019-04-22 22:11:41.785432 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 37 finished
-----------------------------  --------------
replay_buffer/size             19200
trainer/QF1 Loss                   3.1826
trainer/QF2 Loss                   2.89184
trainer/Policy Loss               87.0161
trainer/Q1 Predictions Mean      -85.8328
trainer/Q1 Predictions Std        53.7625
trainer/Q1 Predictions Max       -41.4119
trainer/Q1 Predictions Min      -189.887
trainer/Q2 Predictions Mean      -85.8535
trainer/Q2 Predictions Std        53.7654
trainer/Q2 Predictions Max       -41.5404
trainer/Q2 Predictions Min      -188.86
trainer/Q Targets Mean           -86.797
trainer/Q Targets Std             54.8243
trainer/Q Targets Max            -41.2063
trainer/Q Targets Min           -191.649
trainer/Log Pis Mean               1.96035
trainer/Log Pis Std                1.50042
trainer/Log Pis Max                8.06574
trainer/Log Pis Min               -2.77161
trainer/Policy mu Mean             0.215993
trainer/Policy mu Std              0.831935
trainer/Policy mu Max              3.28695
trainer/Policy mu Min             -2.30503
trainer/Policy log std Mean       -1.87535
trainer/Policy log std Std         0.463589
trainer/Policy log std Max        -0.353383
trainer/Policy log std Min        -2.68974
trainer/Alpha                      0.0601125
trainer/Alpha Loss                -0.111488
exploration/num steps total    19200
exploration/num paths total      192
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.42799
exploration/Rewards Std            1.44199
exploration/Rewards Max           -0.100161
exploration/Rewards Min           -6.89512
exploration/Returns Mean        -142.799
exploration/Returns Std          115.023
exploration/Returns Max          -67.9625
exploration/Returns Min         -370.99
exploration/Actions Mean          -0.00388388
exploration/Actions Std            0.219094
exploration/Actions Max            0.997609
exploration/Actions Min           -0.996403
exploration/Num Paths              5
exploration/Average Returns     -142.799
evaluation/num steps total     57000
evaluation/num paths total       570
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.77857
evaluation/Rewards Std             1.5612
evaluation/Rewards Max            -0.27032
evaluation/Rewards Min            -9.19518
evaluation/Returns Mean         -177.857
evaluation/Returns Std           145.374
evaluation/Returns Max           -43.1548
evaluation/Returns Min          -406.798
evaluation/Actions Mean           -0.00670561
evaluation/Actions Std             0.152417
evaluation/Actions Max             0.994213
evaluation/Actions Min            -0.996608
evaluation/Num Paths              15
evaluation/Average Returns      -177.857
time/data storing (s)              0.00319295
time/evaluation sampling (s)       0.369014
time/exploration sampling (s)      0.155322
time/logging (s)                   0.00647463
time/saving (s)                    0.00250958
time/training (s)                  2.25638
time/epoch (s)                     2.79289
time/total (s)                   103.758
Epoch                             37
-----------------------------  --------------
2019-04-22 22:11:44.376305 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 38 finished
-----------------------------  --------------
replay_buffer/size             19700
trainer/QF1 Loss                   1.88109
trainer/QF2 Loss                   1.69137
trainer/Policy Loss              101.484
trainer/Q1 Predictions Mean     -100.519
trainer/Q1 Predictions Std        59.7255
trainer/Q1 Predictions Max       -40.3936
trainer/Q1 Predictions Min      -182.665
trainer/Q2 Predictions Mean     -100.543
trainer/Q2 Predictions Std        59.6983
trainer/Q2 Predictions Max       -40.4571
trainer/Q2 Predictions Min      -182.9
trainer/Q Targets Mean          -101.384
trainer/Q Targets Std             60.2233
trainer/Q Targets Max            -40.6663
trainer/Q Targets Min           -188.023
trainer/Log Pis Mean               1.92123
trainer/Log Pis Std                1.35898
trainer/Log Pis Max                5.9153
trainer/Log Pis Min               -3.06198
trainer/Policy mu Mean             0.210811
trainer/Policy mu Std              0.870928
trainer/Policy mu Max              2.60338
trainer/Policy mu Min             -2.35921
trainer/Policy log std Mean       -1.79457
trainer/Policy log std Std         0.515911
trainer/Policy log std Max        -0.402088
trainer/Policy log std Min        -2.58308
trainer/Alpha                      0.0612897
trainer/Alpha Loss                -0.219941
exploration/num steps total    19700
exploration/num paths total      197
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.07908
exploration/Rewards Std            1.68015
exploration/Rewards Max           -0.193566
exploration/Rewards Min           -9.0488
exploration/Returns Mean        -207.908
exploration/Returns Std          160.858
exploration/Returns Max          -72.6591
exploration/Returns Min         -421.076
exploration/Actions Mean          -0.00403789
exploration/Actions Std            0.193147
exploration/Actions Max            0.918297
exploration/Actions Min           -0.986907
exploration/Num Paths              5
exploration/Average Returns     -207.908
evaluation/num steps total     58500
evaluation/num paths total       585
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.79888
evaluation/Rewards Std             1.57058
evaluation/Rewards Max            -0.140347
evaluation/Rewards Min            -8.59062
evaluation/Returns Mean         -279.888
evaluation/Returns Std           149.89
evaluation/Returns Max           -70.572
evaluation/Returns Min          -441.701
evaluation/Actions Mean            0.00321029
evaluation/Actions Std             0.146756
evaluation/Actions Max             0.995874
evaluation/Actions Min            -0.985352
evaluation/Num Paths              15
evaluation/Average Returns      -279.888
time/data storing (s)              0.00408193
time/evaluation sampling (s)       0.355541
time/exploration sampling (s)      0.182743
time/logging (s)                   0.00551336
time/saving (s)                    0.00246916
time/training (s)                  2.03321
time/epoch (s)                     2.58356
time/total (s)                   106.347
Epoch                             38
-----------------------------  --------------
2019-04-22 22:11:46.819586 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 39 finished
-----------------------------  --------------
replay_buffer/size             20200
trainer/QF1 Loss                  32.7719
trainer/QF2 Loss                  32.531
trainer/Policy Loss               94.785
trainer/Q1 Predictions Mean      -94.0994
trainer/Q1 Predictions Std        56.8648
trainer/Q1 Predictions Max       -40.2893
trainer/Q1 Predictions Min      -181.26
trainer/Q2 Predictions Mean      -94.1227
trainer/Q2 Predictions Std        56.8586
trainer/Q2 Predictions Max       -40.3111
trainer/Q2 Predictions Min      -181.872
trainer/Q Targets Mean           -93.3318
trainer/Q Targets Std             58.3312
trainer/Q Targets Max             -0.681902
trainer/Q Targets Min           -185.359
trainer/Log Pis Mean               1.68158
trainer/Log Pis Std                1.52746
trainer/Log Pis Max                8.06245
trainer/Log Pis Min               -2.39943
trainer/Policy mu Mean            -0.0672505
trainer/Policy mu Std              0.892191
trainer/Policy mu Max              3.21179
trainer/Policy mu Min             -3.70297
trainer/Policy log std Mean       -1.83146
trainer/Policy log std Std         0.537924
trainer/Policy log std Max        -0.401108
trainer/Policy log std Min        -2.83019
trainer/Alpha                      0.0599903
trainer/Alpha Loss                -0.895897
exploration/num steps total    20200
exploration/num paths total      202
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.7572
exploration/Rewards Std            1.49082
exploration/Rewards Max           -0.0908149
exploration/Rewards Min           -8.26225
exploration/Returns Mean        -175.72
exploration/Returns Std          134.317
exploration/Returns Max          -58.0017
exploration/Returns Min         -344.331
exploration/Actions Mean           0.00792709
exploration/Actions Std            0.21681
exploration/Actions Max            0.997293
exploration/Actions Min           -0.997739
exploration/Num Paths              5
exploration/Average Returns     -175.72
evaluation/num steps total     60000
evaluation/num paths total       600
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.22246
evaluation/Rewards Std             1.51813
evaluation/Rewards Max            -0.207827
evaluation/Rewards Min           -10.3897
evaluation/Returns Mean         -222.246
evaluation/Returns Std           124.601
evaluation/Returns Max           -44.8834
evaluation/Returns Min          -365.311
evaluation/Actions Mean           -0.00681409
evaluation/Actions Std             0.189229
evaluation/Actions Max             0.997116
evaluation/Actions Min            -0.997762
evaluation/Num Paths              15
evaluation/Average Returns      -222.246
time/data storing (s)              0.00295192
time/evaluation sampling (s)       0.334245
time/exploration sampling (s)      0.142133
time/logging (s)                   0.0047832
time/saving (s)                    0.00195283
time/training (s)                  1.95033
time/epoch (s)                     2.43639
time/total (s)                   108.788
Epoch                             39
-----------------------------  --------------
2019-04-22 22:11:49.259686 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 40 finished
-----------------------------  --------------
replay_buffer/size             20700
trainer/QF1 Loss                   2.82227
trainer/QF2 Loss                   2.63078
trainer/Policy Loss               97.9945
trainer/Q1 Predictions Mean      -96.992
trainer/Q1 Predictions Std        59.2277
trainer/Q1 Predictions Max       -38.7244
trainer/Q1 Predictions Min      -186.565
trainer/Q2 Predictions Mean      -97.0112
trainer/Q2 Predictions Std        59.2305
trainer/Q2 Predictions Max       -38.8835
trainer/Q2 Predictions Min      -186.407
trainer/Q Targets Mean           -98.1471
trainer/Q Targets Std             59.7583
trainer/Q Targets Max            -39.2361
trainer/Q Targets Min           -189.173
trainer/Log Pis Mean               1.85167
trainer/Log Pis Std                1.29837
trainer/Log Pis Max                5.30435
trainer/Log Pis Min               -2.16437
trainer/Policy mu Mean             0.0926593
trainer/Policy mu Std              0.889397
trainer/Policy mu Max              3.08013
trainer/Policy mu Min             -2.55345
trainer/Policy log std Mean       -1.82984
trainer/Policy log std Std         0.551509
trainer/Policy log std Max        -0.359145
trainer/Policy log std Min        -2.81605
trainer/Alpha                      0.0598101
trainer/Alpha Loss                -0.417808
exploration/num steps total    20700
exploration/num paths total      207
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.07755
exploration/Rewards Std            1.77675
exploration/Rewards Max           -0.102013
exploration/Rewards Min          -10.3546
exploration/Returns Mean        -207.755
exploration/Returns Std          164.751
exploration/Returns Max          -64.4243
exploration/Returns Min         -410.899
exploration/Actions Mean           0.0203882
exploration/Actions Std            0.21983
exploration/Actions Max            0.999193
exploration/Actions Min           -0.990204
exploration/Num Paths              5
exploration/Average Returns     -207.755
evaluation/num steps total     61500
evaluation/num paths total       615
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.20457
evaluation/Rewards Std             1.59427
evaluation/Rewards Max            -0.393118
evaluation/Rewards Min           -11.0755
evaluation/Returns Mean         -220.457
evaluation/Returns Std           146.502
evaluation/Returns Max           -64.1748
evaluation/Returns Min          -401.683
evaluation/Actions Mean            0.00887248
evaluation/Actions Std             0.162695
evaluation/Actions Max             0.998729
evaluation/Actions Min            -0.993277
evaluation/Num Paths              15
evaluation/Average Returns      -220.457
time/data storing (s)              0.00304208
time/evaluation sampling (s)       0.330197
time/exploration sampling (s)      0.143129
time/logging (s)                   0.00476112
time/saving (s)                    0.0015722
time/training (s)                  1.95194
time/epoch (s)                     2.43464
time/total (s)                   111.227
Epoch                             40
-----------------------------  --------------
2019-04-22 22:11:51.927818 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 41 finished
-----------------------------  --------------
replay_buffer/size             21200
trainer/QF1 Loss                 601.457
trainer/QF2 Loss                 603.255
trainer/Policy Loss              105.188
trainer/Q1 Predictions Mean     -104.505
trainer/Q1 Predictions Std        59.909
trainer/Q1 Predictions Max       -38.646
trainer/Q1 Predictions Min      -184.31
trainer/Q2 Predictions Mean     -104.505
trainer/Q2 Predictions Std        59.878
trainer/Q2 Predictions Max       -38.8508
trainer/Q2 Predictions Min      -184.825
trainer/Q Targets Mean          -101.813
trainer/Q Targets Std             60.7613
trainer/Q Targets Max             -3.92942
trainer/Q Targets Min           -187.148
trainer/Log Pis Mean               1.80361
trainer/Log Pis Std                1.90989
trainer/Log Pis Max                8.1677
trainer/Log Pis Min               -5.37258
trainer/Policy mu Mean             0.234809
trainer/Policy mu Std              0.99847
trainer/Policy mu Max              3.27569
trainer/Policy mu Min             -3.68581
trainer/Policy log std Mean       -1.75958
trainer/Policy log std Std         0.581048
trainer/Policy log std Max        -0.322038
trainer/Policy log std Min        -2.7623
trainer/Alpha                      0.061391
trainer/Alpha Loss                -0.548005
exploration/num steps total    21200
exploration/num paths total      212
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.76646
exploration/Rewards Std            1.46245
exploration/Rewards Max           -0.184691
exploration/Rewards Min           -7.07709
exploration/Returns Mean        -176.646
exploration/Returns Std          136.396
exploration/Returns Max          -63.2038
exploration/Returns Min         -349.74
exploration/Actions Mean          -0.0210901
exploration/Actions Std            0.199936
exploration/Actions Max            0.946415
exploration/Actions Min           -0.99258
exploration/Num Paths              5
exploration/Average Returns     -176.646
evaluation/num steps total     63000
evaluation/num paths total       630
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.02681
evaluation/Rewards Std             1.57518
evaluation/Rewards Max            -0.362734
evaluation/Rewards Min            -9.37848
evaluation/Returns Mean         -202.681
evaluation/Returns Std           133.525
evaluation/Returns Max           -46.2788
evaluation/Returns Min          -361.695
evaluation/Actions Mean           -0.00107905
evaluation/Actions Std             0.177404
evaluation/Actions Max             0.997759
evaluation/Actions Min            -0.998727
evaluation/Num Paths              15
evaluation/Average Returns      -202.681
time/data storing (s)              0.00303624
time/evaluation sampling (s)       0.329099
time/exploration sampling (s)      0.140881
time/logging (s)                   0.00484063
time/saving (s)                    0.00154477
time/training (s)                  2.18337
time/epoch (s)                     2.66277
time/total (s)                   113.894
Epoch                             41
-----------------------------  --------------
2019-04-22 22:11:54.496111 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 42 finished
-----------------------------  --------------
replay_buffer/size             21700
trainer/QF1 Loss                 303.611
trainer/QF2 Loss                 303.236
trainer/Policy Loss               99.9099
trainer/Q1 Predictions Mean      -98.5652
trainer/Q1 Predictions Std        60.9765
trainer/Q1 Predictions Max       -37.6891
trainer/Q1 Predictions Min      -186.06
trainer/Q2 Predictions Mean      -98.5546
trainer/Q2 Predictions Std        60.9831
trainer/Q2 Predictions Max       -37.9239
trainer/Q2 Predictions Min      -185.426
trainer/Q Targets Mean           -97.9812
trainer/Q Targets Std             61.8917
trainer/Q Targets Max             -4.72891
trainer/Q Targets Min           -188.615
trainer/Log Pis Mean               2.13557
trainer/Log Pis Std                1.51228
trainer/Log Pis Max                6.27265
trainer/Log Pis Min               -3.80328
trainer/Policy mu Mean             0.195676
trainer/Policy mu Std              0.868692
trainer/Policy mu Max              2.97929
trainer/Policy mu Min             -2.51248
trainer/Policy log std Mean       -1.89737
trainer/Policy log std Std         0.545032
trainer/Policy log std Max        -0.384929
trainer/Policy log std Min        -2.86237
trainer/Alpha                      0.0632915
trainer/Alpha Loss                 0.374189
exploration/num steps total    21700
exploration/num paths total      217
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.83809
exploration/Rewards Std            1.62514
exploration/Rewards Max           -0.193237
exploration/Rewards Min           -8.8723
exploration/Returns Mean        -183.809
exploration/Returns Std          139.853
exploration/Returns Max          -45.3293
exploration/Returns Min         -359.095
exploration/Actions Mean           0.00287963
exploration/Actions Std            0.202349
exploration/Actions Max            0.998309
exploration/Actions Min           -0.988652
exploration/Num Paths              5
exploration/Average Returns     -183.809
evaluation/num steps total     64500
evaluation/num paths total       645
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.8191
evaluation/Rewards Std             1.61789
evaluation/Rewards Max            -0.433328
evaluation/Rewards Min           -10.9693
evaluation/Returns Mean         -181.91
evaluation/Returns Std           140.416
evaluation/Returns Max           -56.2285
evaluation/Returns Min          -368.676
evaluation/Actions Mean           -0.00371611
evaluation/Actions Std             0.171327
evaluation/Actions Max             0.998171
evaluation/Actions Min            -0.996839
evaluation/Num Paths              15
evaluation/Average Returns      -181.91
time/data storing (s)              0.0031258
time/evaluation sampling (s)       0.354128
time/exploration sampling (s)      0.15873
time/logging (s)                   0.00476795
time/saving (s)                    0.0019783
time/training (s)                  2.03999
time/epoch (s)                     2.56272
time/total (s)                   116.461
Epoch                             42
-----------------------------  --------------
2019-04-22 22:11:57.019073 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 43 finished
-----------------------------  ---------------
replay_buffer/size             22200
trainer/QF1 Loss                  27.3176
trainer/QF2 Loss                  27.2975
trainer/Policy Loss               94.6022
trainer/Q1 Predictions Mean      -93.3783
trainer/Q1 Predictions Std        59.3796
trainer/Q1 Predictions Max       -37.6253
trainer/Q1 Predictions Min      -192.189
trainer/Q2 Predictions Mean      -93.3968
trainer/Q2 Predictions Std        59.4402
trainer/Q2 Predictions Max       -37.6427
trainer/Q2 Predictions Min      -191.393
trainer/Q Targets Mean           -93.2235
trainer/Q Targets Std             60.2958
trainer/Q Targets Max             -0.54897
trainer/Q Targets Min           -191.208
trainer/Log Pis Mean               2.16354
trainer/Log Pis Std                1.59305
trainer/Log Pis Max                8.14668
trainer/Log Pis Min               -2.63483
trainer/Policy mu Mean             0.0740334
trainer/Policy mu Std              0.906009
trainer/Policy mu Max              2.92073
trainer/Policy mu Min             -2.74256
trainer/Policy log std Mean       -1.83251
trainer/Policy log std Std         0.59527
trainer/Policy log std Max        -0.395836
trainer/Policy log std Min        -2.93385
trainer/Alpha                      0.0645063
trainer/Alpha Loss                 0.448246
exploration/num steps total    22200
exploration/num paths total      222
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.37348
exploration/Rewards Std            1.51096
exploration/Rewards Max           -0.140112
exploration/Rewards Min           -9.76251
exploration/Returns Mean        -137.348
exploration/Returns Std          105.997
exploration/Returns Max          -51.7221
exploration/Returns Min         -344.511
exploration/Actions Mean           0.00855151
exploration/Actions Std            0.249194
exploration/Actions Max            0.995092
exploration/Actions Min           -0.999541
exploration/Num Paths              5
exploration/Average Returns     -137.348
evaluation/num steps total     66000
evaluation/num paths total       660
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.84581
evaluation/Rewards Std             1.51485
evaluation/Rewards Max            -0.152377
evaluation/Rewards Min            -8.39744
evaluation/Returns Mean         -184.581
evaluation/Returns Std           136.698
evaluation/Returns Max           -34.2683
evaluation/Returns Min          -338.313
evaluation/Actions Mean            0.000350684
evaluation/Actions Std             0.167237
evaluation/Actions Max             0.994194
evaluation/Actions Min            -0.997382
evaluation/Num Paths              15
evaluation/Average Returns      -184.581
time/data storing (s)              0.00314059
time/evaluation sampling (s)       0.354726
time/exploration sampling (s)      0.158917
time/logging (s)                   0.00475987
time/saving (s)                    0.00194644
time/training (s)                  1.99385
time/epoch (s)                     2.51734
time/total (s)                   118.983
Epoch                             43
-----------------------------  ---------------
2019-04-22 22:11:59.579292 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 44 finished
-----------------------------  --------------
replay_buffer/size             22700
trainer/QF1 Loss                   8.067
trainer/QF2 Loss                   7.80237
trainer/Policy Loss              100.116
trainer/Q1 Predictions Mean      -99.2694
trainer/Q1 Predictions Std        59.6296
trainer/Q1 Predictions Max       -36.4825
trainer/Q1 Predictions Min      -184.542
trainer/Q2 Predictions Mean      -99.2996
trainer/Q2 Predictions Std        59.6681
trainer/Q2 Predictions Max       -36.6699
trainer/Q2 Predictions Min      -184.9
trainer/Q Targets Mean          -101.245
trainer/Q Targets Std             61.0896
trainer/Q Targets Max            -37.1962
trainer/Q Targets Min           -190.622
trainer/Log Pis Mean               1.77354
trainer/Log Pis Std                1.50023
trainer/Log Pis Max                5.94723
trainer/Log Pis Min               -3.63715
trainer/Policy mu Mean             0.164967
trainer/Policy mu Std              0.968446
trainer/Policy mu Max              3.37372
trainer/Policy mu Min             -2.86566
trainer/Policy log std Mean       -1.73818
trainer/Policy log std Std         0.549266
trainer/Policy log std Max        -0.220235
trainer/Policy log std Min        -2.69385
trainer/Alpha                      0.0632099
trainer/Alpha Loss                -0.625357
exploration/num steps total    22700
exploration/num paths total      227
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -3.11259
exploration/Rewards Std            1.20502
exploration/Rewards Max           -0.171654
exploration/Rewards Min           -7.22096
exploration/Returns Mean        -311.259
exploration/Returns Std          113.48
exploration/Returns Max          -85.683
exploration/Returns Min         -383.571
exploration/Actions Mean           0.0118392
exploration/Actions Std            0.216441
exploration/Actions Max            0.995547
exploration/Actions Min           -0.987542
exploration/Num Paths              5
exploration/Average Returns     -311.259
evaluation/num steps total     67500
evaluation/num paths total       675
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.94183
evaluation/Rewards Std             1.69726
evaluation/Rewards Max            -0.337098
evaluation/Rewards Min           -10.6376
evaluation/Returns Mean         -194.183
evaluation/Returns Std           142.8
evaluation/Returns Max           -57.4671
evaluation/Returns Min          -404.592
evaluation/Actions Mean           -0.0100427
evaluation/Actions Std             0.187509
evaluation/Actions Max             0.996701
evaluation/Actions Min            -0.998703
evaluation/Num Paths              15
evaluation/Average Returns      -194.183
time/data storing (s)              0.00292083
time/evaluation sampling (s)       0.358843
time/exploration sampling (s)      0.142558
time/logging (s)                   0.00503335
time/saving (s)                    0.00161065
time/training (s)                  2.044
time/epoch (s)                     2.55497
time/total (s)                   121.542
Epoch                             44
-----------------------------  --------------
2019-04-22 22:12:02.259820 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 45 finished
-----------------------------  --------------
replay_buffer/size             23200
trainer/QF1 Loss                   1.57246
trainer/QF2 Loss                   1.63212
trainer/Policy Loss              103.144
trainer/Q1 Predictions Mean     -102.095
trainer/Q1 Predictions Std        62.4371
trainer/Q1 Predictions Max       -36.3287
trainer/Q1 Predictions Min      -188.166
trainer/Q2 Predictions Mean     -102.099
trainer/Q2 Predictions Std        62.4209
trainer/Q2 Predictions Max       -36.4895
trainer/Q2 Predictions Min      -187.358
trainer/Q Targets Mean          -102.812
trainer/Q Targets Std             62.8225
trainer/Q Targets Max            -36.5214
trainer/Q Targets Min           -190.976
trainer/Log Pis Mean               1.90608
trainer/Log Pis Std                1.67206
trainer/Log Pis Max                6.96517
trainer/Log Pis Min               -4.24273
trainer/Policy mu Mean             0.0712443
trainer/Policy mu Std              1.07818
trainer/Policy mu Max              2.96413
trainer/Policy mu Min             -2.55519
trainer/Policy log std Mean       -1.65138
trainer/Policy log std Std         0.586279
trainer/Policy log std Max        -0.386433
trainer/Policy log std Min        -2.76812
trainer/Alpha                      0.0615519
trainer/Alpha Loss                -0.261821
exploration/num steps total    23200
exploration/num paths total      232
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.64081
exploration/Rewards Std            1.4151
exploration/Rewards Max           -0.121057
exploration/Rewards Min           -4.00779
exploration/Returns Mean        -164.081
exploration/Returns Std          137.968
exploration/Returns Max          -49.9982
exploration/Returns Min         -335.229
exploration/Actions Mean          -0.0019729
exploration/Actions Std            0.196562
exploration/Actions Max            0.986063
exploration/Actions Min           -0.978853
exploration/Num Paths              5
exploration/Average Returns     -164.081
evaluation/num steps total     69000
evaluation/num paths total       690
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.85028
evaluation/Rewards Std             1.5303
evaluation/Rewards Max            -0.133749
evaluation/Rewards Min           -10.9331
evaluation/Returns Mean         -185.028
evaluation/Returns Std           133.41
evaluation/Returns Max           -39.0305
evaluation/Returns Min          -367.856
evaluation/Actions Mean            0.0153888
evaluation/Actions Std             0.175567
evaluation/Actions Max             0.999638
evaluation/Actions Min            -0.991625
evaluation/Num Paths              15
evaluation/Average Returns      -185.028
time/data storing (s)              0.00313484
time/evaluation sampling (s)       0.35425
time/exploration sampling (s)      0.166091
time/logging (s)                   0.00520405
time/saving (s)                    0.00217511
time/training (s)                  2.14412
time/epoch (s)                     2.67497
time/total (s)                   124.221
Epoch                             45
-----------------------------  --------------
2019-04-22 22:12:05.113045 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 46 finished
-----------------------------  --------------
replay_buffer/size             23700
trainer/QF1 Loss                 288.538
trainer/QF2 Loss                 290.087
trainer/Policy Loss               92.4712
trainer/Q1 Predictions Mean      -91.4006
trainer/Q1 Predictions Std        59.6367
trainer/Q1 Predictions Max       -35.4978
trainer/Q1 Predictions Min      -182.056
trainer/Q2 Predictions Mean      -91.441
trainer/Q2 Predictions Std        59.6594
trainer/Q2 Predictions Max       -35.6497
trainer/Q2 Predictions Min      -182.066
trainer/Q Targets Mean           -91.0792
trainer/Q Targets Std             60.6921
trainer/Q Targets Max             -3.85888
trainer/Q Targets Min           -185.274
trainer/Log Pis Mean               1.8152
trainer/Log Pis Std                1.52989
trainer/Log Pis Max                6.13902
trainer/Log Pis Min               -6.16202
trainer/Policy mu Mean             0.0971447
trainer/Policy mu Std              0.81407
trainer/Policy mu Max              2.77715
trainer/Policy mu Min             -2.99229
trainer/Policy log std Mean       -1.86397
trainer/Policy log std Std         0.513289
trainer/Policy log std Max        -0.421264
trainer/Policy log std Min        -2.71851
trainer/Alpha                      0.0600731
trainer/Alpha Loss                -0.519679
exploration/num steps total    23700
exploration/num paths total      237
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.94557
exploration/Rewards Std            1.87822
exploration/Rewards Max           -0.149581
exploration/Rewards Min          -11.8533
exploration/Returns Mean        -194.557
exploration/Returns Std          155.619
exploration/Returns Max          -48.1709
exploration/Returns Min         -401.186
exploration/Actions Mean          -0.0118599
exploration/Actions Std            0.238937
exploration/Actions Max            0.997926
exploration/Actions Min           -0.99697
exploration/Num Paths              5
exploration/Average Returns     -194.557
evaluation/num steps total     70500
evaluation/num paths total       705
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.10481
evaluation/Rewards Std             1.22367
evaluation/Rewards Max            -0.107296
evaluation/Rewards Min            -8.27457
evaluation/Returns Mean         -110.481
evaluation/Returns Std           103.053
evaluation/Returns Max           -44.4349
evaluation/Returns Min          -394.418
evaluation/Actions Mean            0.00446006
evaluation/Actions Std             0.159506
evaluation/Actions Max             0.996161
evaluation/Actions Min            -0.998184
evaluation/Num Paths              15
evaluation/Average Returns      -110.481
time/data storing (s)              0.00315339
time/evaluation sampling (s)       0.361542
time/exploration sampling (s)      0.158126
time/logging (s)                   0.00557779
time/saving (s)                    0.00214986
time/training (s)                  2.3169
time/epoch (s)                     2.84745
time/total (s)                   127.073
Epoch                             46
-----------------------------  --------------
2019-04-22 22:12:07.758777 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 47 finished
-----------------------------  --------------
replay_buffer/size             24200
trainer/QF1 Loss                  24.4073
trainer/QF2 Loss                  24.2409
trainer/Policy Loss               96.7172
trainer/Q1 Predictions Mean      -95.6132
trainer/Q1 Predictions Std        62.4223
trainer/Q1 Predictions Max       -35.237
trainer/Q1 Predictions Min      -185.89
trainer/Q2 Predictions Mean      -95.5357
trainer/Q2 Predictions Std        62.4268
trainer/Q2 Predictions Max       -35.4931
trainer/Q2 Predictions Min      -185.116
trainer/Q Targets Mean           -96.0037
trainer/Q Targets Std             63.6331
trainer/Q Targets Max             -1.14217
trainer/Q Targets Min           -186.581
trainer/Log Pis Mean               1.83321
trainer/Log Pis Std                1.19465
trainer/Log Pis Max                4.84676
trainer/Log Pis Min               -1.92754
trainer/Policy mu Mean             0.00922611
trainer/Policy mu Std              0.84353
trainer/Policy mu Max              2.32243
trainer/Policy mu Min             -2.27116
trainer/Policy log std Mean       -1.87756
trainer/Policy log std Std         0.556352
trainer/Policy log std Max        -0.516284
trainer/Policy log std Min        -2.74869
trainer/Alpha                      0.0626411
trainer/Alpha Loss                -0.46212
exploration/num steps total    24200
exploration/num paths total      242
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.2717
exploration/Rewards Std            2.06514
exploration/Rewards Max           -0.165474
exploration/Rewards Min          -10.196
exploration/Returns Mean        -227.17
exploration/Returns Std          194.355
exploration/Returns Max          -56.4155
exploration/Returns Min         -466.369
exploration/Actions Mean           0.0138666
exploration/Actions Std            0.227416
exploration/Actions Max            0.99748
exploration/Actions Min           -0.998255
exploration/Num Paths              5
exploration/Average Returns     -227.17
evaluation/num steps total     72000
evaluation/num paths total       720
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.91862
evaluation/Rewards Std             1.78328
evaluation/Rewards Max            -0.114385
evaluation/Rewards Min           -10.9779
evaluation/Returns Mean         -191.862
evaluation/Returns Std           161.398
evaluation/Returns Max           -47.0416
evaluation/Returns Min          -458.853
evaluation/Actions Mean            0.00711802
evaluation/Actions Std             0.172911
evaluation/Actions Max             0.997238
evaluation/Actions Min            -0.9981
evaluation/Num Paths              15
evaluation/Average Returns      -191.862
time/data storing (s)              0.00311187
time/evaluation sampling (s)       0.365081
time/exploration sampling (s)      0.160587
time/logging (s)                   0.00463425
time/saving (s)                    0.00196308
time/training (s)                  2.10364
time/epoch (s)                     2.63902
time/total (s)                   129.717
Epoch                             47
-----------------------------  --------------
2019-04-22 22:12:10.531513 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 48 finished
-----------------------------  --------------
replay_buffer/size             24700
trainer/QF1 Loss                 304.331
trainer/QF2 Loss                 304.059
trainer/Policy Loss               97.0903
trainer/Q1 Predictions Mean      -95.6451
trainer/Q1 Predictions Std        62.9803
trainer/Q1 Predictions Max       -35.2982
trainer/Q1 Predictions Min      -204.843
trainer/Q2 Predictions Mean      -95.7024
trainer/Q2 Predictions Std        62.9657
trainer/Q2 Predictions Max       -35.3925
trainer/Q2 Predictions Min      -204.517
trainer/Q Targets Mean           -94.1584
trainer/Q Targets Std             64.1945
trainer/Q Targets Max             -0.878218
trainer/Q Targets Min           -201.525
trainer/Log Pis Mean               2.09909
trainer/Log Pis Std                1.28762
trainer/Log Pis Max                7.45133
trainer/Log Pis Min               -1.15238
trainer/Policy mu Mean            -0.0195554
trainer/Policy mu Std              0.787532
trainer/Policy mu Max              2.9286
trainer/Policy mu Min             -2.85964
trainer/Policy log std Mean       -1.92054
trainer/Policy log std Std         0.537021
trainer/Policy log std Max        -0.381358
trainer/Policy log std Min        -2.84498
trainer/Alpha                      0.0614298
trainer/Alpha Loss                 0.276421
exploration/num steps total    24700
exploration/num paths total      247
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.65178
exploration/Rewards Std            1.43108
exploration/Rewards Max           -0.101972
exploration/Rewards Min           -5.65957
exploration/Returns Mean        -165.178
exploration/Returns Std          133.832
exploration/Returns Max          -39.9565
exploration/Returns Min         -338.693
exploration/Actions Mean           0.00317274
exploration/Actions Std            0.211998
exploration/Actions Max            0.99685
exploration/Actions Min           -0.992092
exploration/Num Paths              5
exploration/Average Returns     -165.178
evaluation/num steps total     73500
evaluation/num paths total       735
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.94708
evaluation/Rewards Std             1.61759
evaluation/Rewards Max            -0.211974
evaluation/Rewards Min            -9.48573
evaluation/Returns Mean         -194.708
evaluation/Returns Std           141.623
evaluation/Returns Max           -44.4937
evaluation/Returns Min          -361.83
evaluation/Actions Mean           -0.0183504
evaluation/Actions Std             0.174645
evaluation/Actions Max             0.983137
evaluation/Actions Min            -0.997666
evaluation/Num Paths              15
evaluation/Average Returns      -194.708
time/data storing (s)              0.00295251
time/evaluation sampling (s)       0.347176
time/exploration sampling (s)      0.148183
time/logging (s)                   0.00551861
time/saving (s)                    0.00346223
time/training (s)                  2.26067
time/epoch (s)                     2.76796
time/total (s)                   132.489
Epoch                             48
-----------------------------  --------------
2019-04-22 22:12:13.678272 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 49 finished
-----------------------------  --------------
replay_buffer/size             25200
trainer/QF1 Loss                   0.839168
trainer/QF2 Loss                   0.676543
trainer/Policy Loss               97.7879
trainer/Q1 Predictions Mean      -96.5982
trainer/Q1 Predictions Std        63.3383
trainer/Q1 Predictions Max       -34.3651
trainer/Q1 Predictions Min      -204.019
trainer/Q2 Predictions Mean      -96.7192
trainer/Q2 Predictions Std        63.265
trainer/Q2 Predictions Max       -34.4608
trainer/Q2 Predictions Min      -203.914
trainer/Q Targets Mean           -97.1037
trainer/Q Targets Std             63.514
trainer/Q Targets Max            -34.7615
trainer/Q Targets Min           -205.955
trainer/Log Pis Mean               2.27662
trainer/Log Pis Std                1.64253
trainer/Log Pis Max                8.91756
trainer/Log Pis Min               -3.18305
trainer/Policy mu Mean             0.00516661
trainer/Policy mu Std              1.04731
trainer/Policy mu Max              3.21497
trainer/Policy mu Min             -3.41923
trainer/Policy log std Mean       -1.80942
trainer/Policy log std Std         0.642737
trainer/Policy log std Max        -0.311579
trainer/Policy log std Min        -2.71908
trainer/Alpha                      0.062235
trainer/Alpha Loss                 0.768123
exploration/num steps total    25200
exploration/num paths total      252
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.62172
exploration/Rewards Std            1.42085
exploration/Rewards Max           -0.0298979
exploration/Rewards Min           -9.2562
exploration/Returns Mean        -162.172
exploration/Returns Std          110.115
exploration/Returns Max          -30.1922
exploration/Returns Min         -306.413
exploration/Actions Mean           0.0290464
exploration/Actions Std            0.239291
exploration/Actions Max            0.99827
exploration/Actions Min           -0.642529
exploration/Num Paths              5
exploration/Average Returns     -162.172
evaluation/num steps total     75000
evaluation/num paths total       750
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.03708
evaluation/Rewards Std             1.28487
evaluation/Rewards Max            -0.120251
evaluation/Rewards Min            -8.53723
evaluation/Returns Mean         -103.708
evaluation/Returns Std            99.2663
evaluation/Returns Max           -29.4646
evaluation/Returns Min          -313.746
evaluation/Actions Mean           -0.00327369
evaluation/Actions Std             0.166958
evaluation/Actions Max             0.993499
evaluation/Actions Min            -0.993315
evaluation/Num Paths              15
evaluation/Average Returns      -103.708
time/data storing (s)              0.00334169
time/evaluation sampling (s)       0.440873
time/exploration sampling (s)      0.208617
time/logging (s)                   0.00590267
time/saving (s)                    0.00244143
time/training (s)                  2.47965
time/epoch (s)                     3.14082
time/total (s)                   135.635
Epoch                             49
-----------------------------  --------------
2019-04-22 22:12:16.809128 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 50 finished
-----------------------------  --------------
replay_buffer/size             25700
trainer/QF1 Loss                 305.143
trainer/QF2 Loss                 305.882
trainer/Policy Loss               97.6225
trainer/Q1 Predictions Mean      -96.3805
trainer/Q1 Predictions Std        63.9428
trainer/Q1 Predictions Max       -34.0504
trainer/Q1 Predictions Min      -187.235
trainer/Q2 Predictions Mean      -96.4076
trainer/Q2 Predictions Std        63.8781
trainer/Q2 Predictions Max       -34.2075
trainer/Q2 Predictions Min      -186.759
trainer/Q Targets Mean           -95.0587
trainer/Q Targets Std             64.3853
trainer/Q Targets Max             -0.834023
trainer/Q Targets Min           -188.74
trainer/Log Pis Mean               2.0427
trainer/Log Pis Std                1.42595
trainer/Log Pis Max                5.26961
trainer/Log Pis Min               -2.85548
trainer/Policy mu Mean            -0.0253403
trainer/Policy mu Std              0.822456
trainer/Policy mu Max              3.39041
trainer/Policy mu Min             -2.38745
trainer/Policy log std Mean       -1.95163
trainer/Policy log std Std         0.557929
trainer/Policy log std Max        -0.278903
trainer/Policy log std Min        -2.76752
trainer/Alpha                      0.0616307
trainer/Alpha Loss                 0.118985
exploration/num steps total    25700
exploration/num paths total      257
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.77663
exploration/Rewards Std            1.61788
exploration/Rewards Max           -0.0735665
exploration/Rewards Min           -9.16718
exploration/Returns Mean        -177.663
exploration/Returns Std          132.433
exploration/Returns Max          -49.226
exploration/Returns Min         -356.155
exploration/Actions Mean          -0.0133306
exploration/Actions Std            0.245798
exploration/Actions Max            0.995647
exploration/Actions Min           -0.997553
exploration/Num Paths              5
exploration/Average Returns     -177.663
evaluation/num steps total     76500
evaluation/num paths total       765
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.75434
evaluation/Rewards Std             1.60814
evaluation/Rewards Max            -0.235987
evaluation/Rewards Min           -11.2318
evaluation/Returns Mean         -175.434
evaluation/Returns Std           144.26
evaluation/Returns Max           -40.4803
evaluation/Returns Min          -364.982
evaluation/Actions Mean            0.00181622
evaluation/Actions Std             0.161214
evaluation/Actions Max             0.997745
evaluation/Actions Min            -0.994158
evaluation/Num Paths              15
evaluation/Average Returns      -175.434
time/data storing (s)              0.00363739
time/evaluation sampling (s)       0.412956
time/exploration sampling (s)      0.226034
time/logging (s)                   0.00611886
time/saving (s)                    0.00239932
time/training (s)                  2.47213
time/epoch (s)                     3.12327
time/total (s)                   138.764
Epoch                             50
-----------------------------  --------------
2019-04-22 22:12:19.572938 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 51 finished
-----------------------------  --------------
replay_buffer/size             26200
trainer/QF1 Loss                 286.125
trainer/QF2 Loss                 286.918
trainer/Policy Loss               94.8114
trainer/Q1 Predictions Mean      -93.8609
trainer/Q1 Predictions Std        62.5629
trainer/Q1 Predictions Max       -34.1844
trainer/Q1 Predictions Min      -191.261
trainer/Q2 Predictions Mean      -93.8865
trainer/Q2 Predictions Std        62.5641
trainer/Q2 Predictions Max       -34.1465
trainer/Q2 Predictions Min      -191.137
trainer/Q Targets Mean           -92.6332
trainer/Q Targets Std             62.9828
trainer/Q Targets Max             -3.54864
trainer/Q Targets Min           -191.181
trainer/Log Pis Mean               2.04254
trainer/Log Pis Std                1.4325
trainer/Log Pis Max                6.17112
trainer/Log Pis Min               -2.30461
trainer/Policy mu Mean             0.0458364
trainer/Policy mu Std              0.966734
trainer/Policy mu Max              2.90353
trainer/Policy mu Min             -2.68091
trainer/Policy log std Mean       -1.84853
trainer/Policy log std Std         0.611152
trainer/Policy log std Max        -0.295899
trainer/Policy log std Min        -2.70438
trainer/Alpha                      0.0636513
trainer/Alpha Loss                 0.117179
exploration/num steps total    26200
exploration/num paths total      262
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.89076
exploration/Rewards Std            1.78918
exploration/Rewards Max           -0.0676912
exploration/Rewards Min           -8.63211
exploration/Returns Mean        -189.076
exploration/Returns Std          162.304
exploration/Returns Max          -33.5686
exploration/Returns Min         -400.111
exploration/Actions Mean          -0.0151812
exploration/Actions Std            0.227682
exploration/Actions Max            0.997718
exploration/Actions Min           -0.996985
exploration/Num Paths              5
exploration/Average Returns     -189.076
evaluation/num steps total     78000
evaluation/num paths total       780
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.14589
evaluation/Rewards Std             1.73212
evaluation/Rewards Max            -0.0487791
evaluation/Rewards Min           -10.8769
evaluation/Returns Mean         -214.589
evaluation/Returns Std           155.198
evaluation/Returns Max           -51.2153
evaluation/Returns Min          -411.682
evaluation/Actions Mean           -0.0122171
evaluation/Actions Std             0.172862
evaluation/Actions Max             0.99664
evaluation/Actions Min            -0.99826
evaluation/Num Paths              15
evaluation/Average Returns      -214.589
time/data storing (s)              0.00340519
time/evaluation sampling (s)       0.404536
time/exploration sampling (s)      0.158945
time/logging (s)                   0.00535966
time/saving (s)                    0.00211062
time/training (s)                  2.18072
time/epoch (s)                     2.75508
time/total (s)                   141.525
Epoch                             51
-----------------------------  --------------
2019-04-22 22:12:22.546119 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 52 finished
-----------------------------  --------------
replay_buffer/size             26700
trainer/QF1 Loss                   2.10327
trainer/QF2 Loss                   1.68716
trainer/Policy Loss               92.4586
trainer/Q1 Predictions Mean      -91.2042
trainer/Q1 Predictions Std        63.0469
trainer/Q1 Predictions Max       -33.4022
trainer/Q1 Predictions Min      -188.637
trainer/Q2 Predictions Mean      -91.3186
trainer/Q2 Predictions Std        63.0672
trainer/Q2 Predictions Max       -33.5441
trainer/Q2 Predictions Min      -188.908
trainer/Q Targets Mean           -92.1997
trainer/Q Targets Std             63.5914
trainer/Q Targets Max            -33.3783
trainer/Q Targets Min           -191.385
trainer/Log Pis Mean               1.99745
trainer/Log Pis Std                1.23746
trainer/Log Pis Max                5.29634
trainer/Log Pis Min               -1.72091
trainer/Policy mu Mean             0.0615142
trainer/Policy mu Std              0.85408
trainer/Policy mu Max              2.71036
trainer/Policy mu Min             -2.69958
trainer/Policy log std Mean       -1.88028
trainer/Policy log std Std         0.567439
trainer/Policy log std Max        -0.355922
trainer/Policy log std Min        -2.7358
trainer/Alpha                      0.0638091
trainer/Alpha Loss                -0.00701621
exploration/num steps total    26700
exploration/num paths total      267
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.46593
exploration/Rewards Std            1.30575
exploration/Rewards Max           -0.0651567
exploration/Rewards Min           -8.94922
exploration/Returns Mean        -146.593
exploration/Returns Std          106.003
exploration/Returns Max          -56.7099
exploration/Returns Min         -282.663
exploration/Actions Mean          -0.013184
exploration/Actions Std            0.232481
exploration/Actions Max            0.988651
exploration/Actions Min           -0.99113
exploration/Num Paths              5
exploration/Average Returns     -146.593
evaluation/num steps total     79500
evaluation/num paths total       795
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.79056
evaluation/Rewards Std             1.60155
evaluation/Rewards Max            -0.0734198
evaluation/Rewards Min           -10.8635
evaluation/Returns Mean         -179.056
evaluation/Returns Std           131.249
evaluation/Returns Max           -36.0831
evaluation/Returns Min          -353.809
evaluation/Actions Mean            0.00758771
evaluation/Actions Std             0.182542
evaluation/Actions Max             0.999764
evaluation/Actions Min            -0.992841
evaluation/Num Paths              15
evaluation/Average Returns      -179.056
time/data storing (s)              0.00316063
time/evaluation sampling (s)       0.379622
time/exploration sampling (s)      0.170972
time/logging (s)                   0.00591411
time/saving (s)                    0.00196943
time/training (s)                  2.406
time/epoch (s)                     2.96764
time/total (s)                   144.497
Epoch                             52
-----------------------------  --------------
2019-04-22 22:12:25.240410 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 53 finished
-----------------------------  --------------
replay_buffer/size             27200
trainer/QF1 Loss                   1.00481
trainer/QF2 Loss                   0.869172
trainer/Policy Loss               85.7547
trainer/Q1 Predictions Mean      -84.6464
trainer/Q1 Predictions Std        61.371
trainer/Q1 Predictions Max       -33.1823
trainer/Q1 Predictions Min      -187.953
trainer/Q2 Predictions Mean      -84.6218
trainer/Q2 Predictions Std        61.4285
trainer/Q2 Predictions Max       -33.1887
trainer/Q2 Predictions Min      -188.978
trainer/Q Targets Mean           -85.0991
trainer/Q Targets Std             61.7459
trainer/Q Targets Max            -32.9663
trainer/Q Targets Min           -192.785
trainer/Log Pis Mean               1.81521
trainer/Log Pis Std                1.4437
trainer/Log Pis Max                6.27484
trainer/Log Pis Min               -3.03793
trainer/Policy mu Mean             0.0822198
trainer/Policy mu Std              0.860384
trainer/Policy mu Max              2.47303
trainer/Policy mu Min             -3.23018
trainer/Policy log std Mean       -1.85258
trainer/Policy log std Std         0.543798
trainer/Policy log std Max        -0.456351
trainer/Policy log std Min        -2.66417
trainer/Alpha                      0.0633775
trainer/Alpha Loss                -0.509744
exploration/num steps total    27200
exploration/num paths total      272
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.68277
exploration/Rewards Std            1.48416
exploration/Rewards Max           -0.196524
exploration/Rewards Min          -10.3156
exploration/Returns Mean        -168.277
exploration/Returns Std          123.858
exploration/Returns Max          -53.0496
exploration/Returns Min         -318.961
exploration/Actions Mean           0.0108882
exploration/Actions Std            0.20193
exploration/Actions Max            0.997331
exploration/Actions Min           -0.987518
exploration/Num Paths              5
exploration/Average Returns     -168.277
evaluation/num steps total     81000
evaluation/num paths total       810
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.36643
evaluation/Rewards Std             1.54722
evaluation/Rewards Max            -0.268519
evaluation/Rewards Min           -11.9082
evaluation/Returns Mean         -136.643
evaluation/Returns Std           111.095
evaluation/Returns Max           -28.9928
evaluation/Returns Min          -327.226
evaluation/Actions Mean           -0.00948449
evaluation/Actions Std             0.198349
evaluation/Actions Max             0.998263
evaluation/Actions Min            -0.997925
evaluation/Num Paths              15
evaluation/Average Returns      -136.643
time/data storing (s)              0.0032676
time/evaluation sampling (s)       0.428006
time/exploration sampling (s)      0.161739
time/logging (s)                   0.00477483
time/saving (s)                    0.00201008
time/training (s)                  2.08714
time/epoch (s)                     2.68693
time/total (s)                   147.189
Epoch                             53
-----------------------------  --------------
2019-04-22 22:12:27.930883 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 54 finished
-----------------------------  --------------
replay_buffer/size             27700
trainer/QF1 Loss                 302.491
trainer/QF2 Loss                 301.266
trainer/Policy Loss               88.4486
trainer/Q1 Predictions Mean      -87.1085
trainer/Q1 Predictions Std        62.2911
trainer/Q1 Predictions Max       -32.3988
trainer/Q1 Predictions Min      -185.6
trainer/Q2 Predictions Mean      -87.0961
trainer/Q2 Predictions Std        62.2671
trainer/Q2 Predictions Max       -32.4601
trainer/Q2 Predictions Min      -185.3
trainer/Q Targets Mean           -86.0556
trainer/Q Targets Std             63.6867
trainer/Q Targets Max             -0.765033
trainer/Q Targets Min           -188.915
trainer/Log Pis Mean               2.13445
trainer/Log Pis Std                1.32695
trainer/Log Pis Max                8.47036
trainer/Log Pis Min               -2.05023
trainer/Policy mu Mean             0.117186
trainer/Policy mu Std              0.846873
trainer/Policy mu Max              2.92419
trainer/Policy mu Min             -2.52802
trainer/Policy log std Mean       -1.88845
trainer/Policy log std Std         0.538272
trainer/Policy log std Max        -0.500831
trainer/Policy log std Min        -2.77395
trainer/Alpha                      0.0648254
trainer/Alpha Loss                 0.36787
exploration/num steps total    27700
exploration/num paths total      277
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.98745
exploration/Rewards Std            1.35021
exploration/Rewards Max           -0.057569
exploration/Rewards Min           -8.71883
exploration/Returns Mean        -198.745
exploration/Returns Std          120.5
exploration/Returns Max          -48.5734
exploration/Returns Min         -320.3
exploration/Actions Mean          -0.00873859
exploration/Actions Std            0.211907
exploration/Actions Max            0.99321
exploration/Actions Min           -0.997611
exploration/Num Paths              5
exploration/Average Returns     -198.745
evaluation/num steps total     82500
evaluation/num paths total       825
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.11948
evaluation/Rewards Std             1.2589
evaluation/Rewards Max            -0.0412563
evaluation/Rewards Min           -11.1919
evaluation/Returns Mean         -111.948
evaluation/Returns Std            90.0574
evaluation/Returns Max           -33.8038
evaluation/Returns Min          -262.596
evaluation/Actions Mean            0.010487
evaluation/Actions Std             0.173298
evaluation/Actions Max             0.996626
evaluation/Actions Min            -0.992645
evaluation/Num Paths              15
evaluation/Average Returns      -111.948
time/data storing (s)              0.00326874
time/evaluation sampling (s)       0.348353
time/exploration sampling (s)      0.158797
time/logging (s)                   0.00486289
time/saving (s)                    0.00194137
time/training (s)                  2.16724
time/epoch (s)                     2.68446
time/total (s)                   149.878
Epoch                             54
-----------------------------  --------------
2019-04-22 22:12:30.568615 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 55 finished
-----------------------------  --------------
replay_buffer/size             28200
trainer/QF1 Loss                  34.7914
trainer/QF2 Loss                  37.972
trainer/Policy Loss               91.3058
trainer/Q1 Predictions Mean      -89.8122
trainer/Q1 Predictions Std        63.0528
trainer/Q1 Predictions Max       -32.5877
trainer/Q1 Predictions Min      -198.977
trainer/Q2 Predictions Mean      -89.8683
trainer/Q2 Predictions Std        63.0272
trainer/Q2 Predictions Max       -32.5366
trainer/Q2 Predictions Min      -199.286
trainer/Q Targets Mean           -89.6319
trainer/Q Targets Std             63.9991
trainer/Q Targets Max             -6.24209
trainer/Q Targets Min           -198.403
trainer/Log Pis Mean               2.05761
trainer/Log Pis Std                1.39059
trainer/Log Pis Max                5.53813
trainer/Log Pis Min               -2.39266
trainer/Policy mu Mean            -0.0626801
trainer/Policy mu Std              0.844071
trainer/Policy mu Max              3.1516
trainer/Policy mu Min             -2.87454
trainer/Policy log std Mean       -1.98447
trainer/Policy log std Std         0.544117
trainer/Policy log std Max        -0.334396
trainer/Policy log std Min        -2.89101
trainer/Alpha                      0.0648528
trainer/Alpha Loss                 0.157593
exploration/num steps total    28200
exploration/num paths total      282
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.91538
exploration/Rewards Std            1.41734
exploration/Rewards Max           -0.00782268
exploration/Rewards Min           -9.33566
exploration/Returns Mean        -191.538
exploration/Returns Std          112.46
exploration/Returns Max          -52.3804
exploration/Returns Min         -294.646
exploration/Actions Mean           0.00944983
exploration/Actions Std            0.244048
exploration/Actions Max            0.992118
exploration/Actions Min           -0.99228
exploration/Num Paths              5
exploration/Average Returns     -191.538
evaluation/num steps total     84000
evaluation/num paths total       840
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.849478
evaluation/Rewards Std             1.24243
evaluation/Rewards Max            -0.0703607
evaluation/Rewards Min           -10.587
evaluation/Returns Mean          -84.9478
evaluation/Returns Std            81.8106
evaluation/Returns Max           -26.7312
evaluation/Returns Min          -296.653
evaluation/Actions Mean            0.00989246
evaluation/Actions Std             0.172899
evaluation/Actions Max             0.995701
evaluation/Actions Min            -0.993421
evaluation/Num Paths              15
evaluation/Average Returns       -84.9478
time/data storing (s)              0.00380935
time/evaluation sampling (s)       0.350521
time/exploration sampling (s)      0.169451
time/logging (s)                   0.0045563
time/saving (s)                    0.00161577
time/training (s)                  2.1013
time/epoch (s)                     2.63126
time/total (s)                   152.514
Epoch                             55
-----------------------------  --------------
2019-04-22 22:12:33.164157 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 56 finished
-----------------------------  ---------------
replay_buffer/size             28700
trainer/QF1 Loss                  37.1839
trainer/QF2 Loss                  36.1582
trainer/Policy Loss               74.1113
trainer/Q1 Predictions Mean      -72.8638
trainer/Q1 Predictions Std        56.2814
trainer/Q1 Predictions Max       -31.1878
trainer/Q1 Predictions Min      -193.268
trainer/Q2 Predictions Mean      -72.8095
trainer/Q2 Predictions Std        56.3064
trainer/Q2 Predictions Max       -31.4543
trainer/Q2 Predictions Min      -193.33
trainer/Q Targets Mean           -72.9101
trainer/Q Targets Std             57.6476
trainer/Q Targets Max             -0.169304
trainer/Q Targets Min           -200.872
trainer/Log Pis Mean               2.01957
trainer/Log Pis Std                1.50592
trainer/Log Pis Max                9.28144
trainer/Log Pis Min               -2.84644
trainer/Policy mu Mean             0.08997
trainer/Policy mu Std              0.834826
trainer/Policy mu Max              3.52415
trainer/Policy mu Min             -2.30831
trainer/Policy log std Mean       -1.93881
trainer/Policy log std Std         0.520673
trainer/Policy log std Max        -0.509133
trainer/Policy log std Min        -2.59702
trainer/Alpha                      0.0648594
trainer/Alpha Loss                 0.0535321
exploration/num steps total    28700
exploration/num paths total      287
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.1201
exploration/Rewards Std            1.21812
exploration/Rewards Max           -0.159254
exploration/Rewards Min           -7.67371
exploration/Returns Mean        -112.01
exploration/Returns Std          117.328
exploration/Returns Max          -42.1837
exploration/Returns Min         -346.19
exploration/Actions Mean           0.000918707
exploration/Actions Std            0.179156
exploration/Actions Max            0.99681
exploration/Actions Min           -0.938057
exploration/Num Paths              5
exploration/Average Returns     -112.01
evaluation/num steps total     85500
evaluation/num paths total       855
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.60471
evaluation/Rewards Std             1.57529
evaluation/Rewards Max            -0.158973
evaluation/Rewards Min           -11.0981
evaluation/Returns Mean         -160.471
evaluation/Returns Std           130.549
evaluation/Returns Max           -43.7458
evaluation/Returns Min          -359.831
evaluation/Actions Mean           -0.000299373
evaluation/Actions Std             0.192314
evaluation/Actions Max             0.994944
evaluation/Actions Min            -0.997565
evaluation/Num Paths              15
evaluation/Average Returns      -160.471
time/data storing (s)              0.00309881
time/evaluation sampling (s)       0.348053
time/exploration sampling (s)      0.154366
time/logging (s)                   0.0048484
time/saving (s)                    0.00176867
time/training (s)                  2.07768
time/epoch (s)                     2.58981
time/total (s)                   155.109
Epoch                             56
-----------------------------  ---------------
2019-04-22 22:12:35.759478 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 57 finished
-----------------------------  --------------
replay_buffer/size             29200
trainer/QF1 Loss                   6.36696
trainer/QF2 Loss                   6.3851
trainer/Policy Loss               93.5176
trainer/Q1 Predictions Mean      -92.3291
trainer/Q1 Predictions Std        63.4563
trainer/Q1 Predictions Max       -31.0595
trainer/Q1 Predictions Min      -187.63
trainer/Q2 Predictions Mean      -92.3509
trainer/Q2 Predictions Std        63.4253
trainer/Q2 Predictions Max       -30.8988
trainer/Q2 Predictions Min      -187.028
trainer/Q Targets Mean           -94.2899
trainer/Q Targets Std             64.7817
trainer/Q Targets Max            -31.899
trainer/Q Targets Min           -192.9
trainer/Log Pis Mean               2.15792
trainer/Log Pis Std                1.30186
trainer/Log Pis Max                6.59472
trainer/Log Pis Min               -1.48077
trainer/Policy mu Mean             0.169073
trainer/Policy mu Std              0.880611
trainer/Policy mu Max              2.67575
trainer/Policy mu Min             -2.25588
trainer/Policy log std Mean       -1.85188
trainer/Policy log std Std         0.568442
trainer/Policy log std Max        -0.443412
trainer/Policy log std Min        -2.65532
trainer/Alpha                      0.0670043
trainer/Alpha Loss                 0.426892
exploration/num steps total    29200
exploration/num paths total      292
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.51311
exploration/Rewards Std            1.39806
exploration/Rewards Max           -0.115497
exploration/Rewards Min           -9.3318
exploration/Returns Mean        -151.311
exploration/Returns Std          124.036
exploration/Returns Max          -46.2824
exploration/Returns Min         -347.263
exploration/Actions Mean          -0.00495774
exploration/Actions Std            0.204293
exploration/Actions Max            0.994581
exploration/Actions Min           -0.997755
exploration/Num Paths              5
exploration/Average Returns     -151.311
evaluation/num steps total     87000
evaluation/num paths total       870
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.75726
evaluation/Rewards Std             1.5617
evaluation/Rewards Max            -0.272995
evaluation/Rewards Min           -11.8096
evaluation/Returns Mean         -175.726
evaluation/Returns Std           123.17
evaluation/Returns Max           -41.9559
evaluation/Returns Min          -350.407
evaluation/Actions Mean            0.00516044
evaluation/Actions Std             0.191194
evaluation/Actions Max             0.998495
evaluation/Actions Min            -0.993589
evaluation/Num Paths              15
evaluation/Average Returns      -175.726
time/data storing (s)              0.00328001
time/evaluation sampling (s)       0.344152
time/exploration sampling (s)      0.156865
time/logging (s)                   0.00488725
time/saving (s)                    0.00194121
time/training (s)                  2.07814
time/epoch (s)                     2.58927
time/total (s)                   157.702
Epoch                             57
-----------------------------  --------------
2019-04-22 22:12:38.301526 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 58 finished
-----------------------------  --------------
replay_buffer/size             29700
trainer/QF1 Loss                 298.581
trainer/QF2 Loss                 297.948
trainer/Policy Loss               88.741
trainer/Q1 Predictions Mean      -87.7603
trainer/Q1 Predictions Std        63.0359
trainer/Q1 Predictions Max       -31.4259
trainer/Q1 Predictions Min      -192.569
trainer/Q2 Predictions Mean      -87.7318
trainer/Q2 Predictions Std        63.0932
trainer/Q2 Predictions Max       -31.5532
trainer/Q2 Predictions Min      -193.105
trainer/Q Targets Mean           -85.7688
trainer/Q Targets Std             63.6357
trainer/Q Targets Max             -1.94559
trainer/Q Targets Min           -194.911
trainer/Log Pis Mean               1.88504
trainer/Log Pis Std                1.30297
trainer/Log Pis Max                4.72748
trainer/Log Pis Min               -3.31543
trainer/Policy mu Mean             0.0458952
trainer/Policy mu Std              0.909843
trainer/Policy mu Max              2.62086
trainer/Policy mu Min             -2.70908
trainer/Policy log std Mean       -1.80925
trainer/Policy log std Std         0.641176
trainer/Policy log std Max        -0.3436
trainer/Policy log std Min        -2.76065
trainer/Alpha                      0.0690489
trainer/Alpha Loss                -0.307262
exploration/num steps total    29700
exploration/num paths total      297
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.49309
exploration/Rewards Std            1.4003
exploration/Rewards Max           -0.123046
exploration/Rewards Min          -10.8241
exploration/Returns Mean        -149.309
exploration/Returns Std           89.2216
exploration/Returns Max          -73.1678
exploration/Returns Min         -263.201
exploration/Actions Mean          -0.0257176
exploration/Actions Std            0.244045
exploration/Actions Max            0.993949
exploration/Actions Min           -0.999049
exploration/Num Paths              5
exploration/Average Returns     -149.309
evaluation/num steps total     88500
evaluation/num paths total       885
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.53874
evaluation/Rewards Std             1.33436
evaluation/Rewards Max            -0.0580489
evaluation/Rewards Min           -10.2107
evaluation/Returns Mean         -153.874
evaluation/Returns Std           115.219
evaluation/Returns Max           -10.32
evaluation/Returns Min          -294.107
evaluation/Actions Mean           -0.00226154
evaluation/Actions Std             0.16702
evaluation/Actions Max             0.992031
evaluation/Actions Min            -0.994709
evaluation/Num Paths              15
evaluation/Average Returns      -153.874
time/data storing (s)              0.00311567
time/evaluation sampling (s)       0.340105
time/exploration sampling (s)      0.152328
time/logging (s)                   0.00539018
time/saving (s)                    0.00211483
time/training (s)                  2.03327
time/epoch (s)                     2.53633
time/total (s)                   160.244
Epoch                             58
-----------------------------  --------------
2019-04-22 22:12:40.997721 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 59 finished
-----------------------------  --------------
replay_buffer/size             30200
trainer/QF1 Loss                  21.6274
trainer/QF2 Loss                  21.9014
trainer/Policy Loss               87.7988
trainer/Q1 Predictions Mean      -86.6089
trainer/Q1 Predictions Std        62.1326
trainer/Q1 Predictions Max       -30.6739
trainer/Q1 Predictions Min      -192.213
trainer/Q2 Predictions Mean      -86.6088
trainer/Q2 Predictions Std        62.0514
trainer/Q2 Predictions Max       -30.7626
trainer/Q2 Predictions Min      -191.969
trainer/Q Targets Mean           -87.1674
trainer/Q Targets Std             63.3742
trainer/Q Targets Max             -0.91531
trainer/Q Targets Min           -196.841
trainer/Log Pis Mean               2.17139
trainer/Log Pis Std                1.67679
trainer/Log Pis Max                8.99077
trainer/Log Pis Min               -3.97866
trainer/Policy mu Mean             0.077685
trainer/Policy mu Std              0.886709
trainer/Policy mu Max              3.01961
trainer/Policy mu Min             -2.592
trainer/Policy log std Mean       -1.97299
trainer/Policy log std Std         0.571569
trainer/Policy log std Max        -0.309396
trainer/Policy log std Min        -2.74436
trainer/Alpha                      0.0691525
trainer/Alpha Loss                 0.457892
exploration/num steps total    30200
exploration/num paths total      302
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.36734
exploration/Rewards Std            1.3474
exploration/Rewards Max           -0.0702132
exploration/Rewards Min           -9.10107
exploration/Returns Mean        -136.734
exploration/Returns Std          120.335
exploration/Returns Max          -28.6166
exploration/Returns Min         -298.964
exploration/Actions Mean          -0.022876
exploration/Actions Std            0.199617
exploration/Actions Max            0.998259
exploration/Actions Min           -0.990069
exploration/Num Paths              5
exploration/Average Returns     -136.734
evaluation/num steps total     90000
evaluation/num paths total       900
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.74314
evaluation/Rewards Std             1.34923
evaluation/Rewards Max            -0.181764
evaluation/Rewards Min           -10.6924
evaluation/Returns Mean         -174.314
evaluation/Returns Std           117.375
evaluation/Returns Max           -24.4462
evaluation/Returns Min          -302.217
evaluation/Actions Mean            0.0025959
evaluation/Actions Std             0.161873
evaluation/Actions Max             0.999271
evaluation/Actions Min            -0.997561
evaluation/Num Paths              15
evaluation/Average Returns      -174.314
time/data storing (s)              0.00298352
time/evaluation sampling (s)       0.359934
time/exploration sampling (s)      0.151905
time/logging (s)                   0.00486771
time/saving (s)                    0.00232657
time/training (s)                  2.16724
time/epoch (s)                     2.68925
time/total (s)                   162.937
Epoch                             59
-----------------------------  --------------
2019-04-22 22:12:43.911678 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 60 finished
-----------------------------  ---------------
replay_buffer/size             30700
trainer/QF1 Loss                   1.38669
trainer/QF2 Loss                   1.28735
trainer/Policy Loss               79.2092
trainer/Q1 Predictions Mean      -77.9983
trainer/Q1 Predictions Std        58.6164
trainer/Q1 Predictions Max       -30.4683
trainer/Q1 Predictions Min      -180.084
trainer/Q2 Predictions Mean      -78.0078
trainer/Q2 Predictions Std        58.6397
trainer/Q2 Predictions Max       -30.579
trainer/Q2 Predictions Min      -180.334
trainer/Q Targets Mean           -78.8711
trainer/Q Targets Std             59.2084
trainer/Q Targets Max            -30.6771
trainer/Q Targets Min           -180.968
trainer/Log Pis Mean               2.23488
trainer/Log Pis Std                1.39062
trainer/Log Pis Max                7.17336
trainer/Log Pis Min               -1.48088
trainer/Policy mu Mean            -0.000718038
trainer/Policy mu Std              0.872673
trainer/Policy mu Max              2.88448
trainer/Policy mu Min             -2.90944
trainer/Policy log std Mean       -1.90099
trainer/Policy log std Std         0.583178
trainer/Policy log std Max        -0.492987
trainer/Policy log std Min        -2.71753
trainer/Alpha                      0.0701598
trainer/Alpha Loss                 0.624072
exploration/num steps total    30700
exploration/num paths total      307
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.15679
exploration/Rewards Std            1.40164
exploration/Rewards Max           -0.0507676
exploration/Rewards Min           -7.98471
exploration/Returns Mean        -215.679
exploration/Returns Std          123.093
exploration/Returns Max          -55.0497
exploration/Returns Min         -341.712
exploration/Actions Mean          -0.00871258
exploration/Actions Std            0.213382
exploration/Actions Max            0.983845
exploration/Actions Min           -0.996273
exploration/Num Paths              5
exploration/Average Returns     -215.679
evaluation/num steps total     91500
evaluation/num paths total       915
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.55306
evaluation/Rewards Std             1.45374
evaluation/Rewards Max            -0.161885
evaluation/Rewards Min           -11.5951
evaluation/Returns Mean         -155.306
evaluation/Returns Std           115.992
evaluation/Returns Max           -18.9093
evaluation/Returns Min          -337.211
evaluation/Actions Mean            0.0180685
evaluation/Actions Std             0.181479
evaluation/Actions Max             0.997317
evaluation/Actions Min            -0.994845
evaluation/Num Paths              15
evaluation/Average Returns      -155.306
time/data storing (s)              0.00398142
time/evaluation sampling (s)       0.380004
time/exploration sampling (s)      0.227259
time/logging (s)                   0.00490961
time/saving (s)                    0.00198025
time/training (s)                  2.28971
time/epoch (s)                     2.90784
time/total (s)                   165.85
Epoch                             60
-----------------------------  ---------------
2019-04-22 22:12:46.574553 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 61 finished
-----------------------------  ---------------
replay_buffer/size             31200
trainer/QF1 Loss                  15.3181
trainer/QF2 Loss                  15.5328
trainer/Policy Loss               89.0369
trainer/Q1 Predictions Mean      -87.8194
trainer/Q1 Predictions Std        63.2916
trainer/Q1 Predictions Max       -30.4904
trainer/Q1 Predictions Min      -193.354
trainer/Q2 Predictions Mean      -87.8173
trainer/Q2 Predictions Std        63.2719
trainer/Q2 Predictions Max       -30.4985
trainer/Q2 Predictions Min      -193.74
trainer/Q Targets Mean           -88.4492
trainer/Q Targets Std             64.7233
trainer/Q Targets Max             -1.35714
trainer/Q Targets Min           -192.407
trainer/Log Pis Mean               2.01094
trainer/Log Pis Std                1.47524
trainer/Log Pis Max                7.4503
trainer/Log Pis Min               -4.49991
trainer/Policy mu Mean             0.109805
trainer/Policy mu Std              0.850599
trainer/Policy mu Max              2.65572
trainer/Policy mu Min             -2.33107
trainer/Policy log std Mean       -1.90781
trainer/Policy log std Std         0.5912
trainer/Policy log std Max        -0.5098
trainer/Policy log std Min        -2.79797
trainer/Alpha                      0.0706994
trainer/Alpha Loss                 0.028973
exploration/num steps total    31200
exploration/num paths total      312
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.526242
exploration/Rewards Std            0.995621
exploration/Rewards Max           -0.0201073
exploration/Rewards Min           -9.17963
exploration/Returns Mean         -52.6242
exploration/Returns Std           17.613
exploration/Returns Max          -31.2841
exploration/Returns Min          -72.9046
exploration/Actions Mean          -0.0181764
exploration/Actions Std            0.193372
exploration/Actions Max            0.919857
exploration/Actions Min           -0.998478
exploration/Num Paths              5
exploration/Average Returns      -52.6242
evaluation/num steps total     93000
evaluation/num paths total       930
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.67746
evaluation/Rewards Std             1.44542
evaluation/Rewards Max            -0.215616
evaluation/Rewards Min            -9.60492
evaluation/Returns Mean         -167.746
evaluation/Returns Std           108.252
evaluation/Returns Max           -27.9266
evaluation/Returns Min          -331.659
evaluation/Actions Mean           -0.000354815
evaluation/Actions Std             0.191464
evaluation/Actions Max             0.997358
evaluation/Actions Min            -0.997319
evaluation/Num Paths              15
evaluation/Average Returns      -167.746
time/data storing (s)              0.00305263
time/evaluation sampling (s)       0.356733
time/exploration sampling (s)      0.162109
time/logging (s)                   0.00478916
time/saving (s)                    0.0019977
time/training (s)                  2.12775
time/epoch (s)                     2.65643
time/total (s)                   168.511
Epoch                             61
-----------------------------  ---------------
2019-04-22 22:12:49.362177 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 62 finished
-----------------------------  --------------
replay_buffer/size             31700
trainer/QF1 Loss                 305.707
trainer/QF2 Loss                 308.711
trainer/Policy Loss               90.9588
trainer/Q1 Predictions Mean      -89.7301
trainer/Q1 Predictions Std        62.747
trainer/Q1 Predictions Max       -29.1124
trainer/Q1 Predictions Min      -179.889
trainer/Q2 Predictions Mean      -89.6894
trainer/Q2 Predictions Std        62.7261
trainer/Q2 Predictions Max       -29.186
trainer/Q2 Predictions Min      -179.682
trainer/Q Targets Mean           -88.4423
trainer/Q Targets Std             63.7294
trainer/Q Targets Max             -5.65893
trainer/Q Targets Min           -181.019
trainer/Log Pis Mean               2.16801
trainer/Log Pis Std                1.49306
trainer/Log Pis Max                7.5097
trainer/Log Pis Min               -1.97344
trainer/Policy mu Mean             0.142848
trainer/Policy mu Std              0.911953
trainer/Policy mu Max              2.9342
trainer/Policy mu Min             -3.81679
trainer/Policy log std Mean       -1.88677
trainer/Policy log std Std         0.583616
trainer/Policy log std Max        -0.45362
trainer/Policy log std Min        -2.76733
trainer/Alpha                      0.0698478
trainer/Alpha Loss                 0.447144
exploration/num steps total    31700
exploration/num paths total      317
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.40779
exploration/Rewards Std            1.28882
exploration/Rewards Max           -0.0322753
exploration/Rewards Min           -7.54386
exploration/Returns Mean        -140.779
exploration/Returns Std          104.524
exploration/Returns Max          -49.216
exploration/Returns Min         -306.039
exploration/Actions Mean           0.00778375
exploration/Actions Std            0.232104
exploration/Actions Max            0.994947
exploration/Actions Min           -0.990293
exploration/Num Paths              5
exploration/Average Returns     -140.779
evaluation/num steps total     94500
evaluation/num paths total       945
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.163
evaluation/Rewards Std             1.33859
evaluation/Rewards Max            -0.33401
evaluation/Rewards Min            -9.12734
evaluation/Returns Mean         -116.3
evaluation/Returns Std            96.9937
evaluation/Returns Max           -38.9872
evaluation/Returns Min          -319.004
evaluation/Actions Mean           -0.0262156
evaluation/Actions Std             0.182119
evaluation/Actions Max             0.98752
evaluation/Actions Min            -0.997439
evaluation/Num Paths              15
evaluation/Average Returns      -116.3
time/data storing (s)              0.00353683
time/evaluation sampling (s)       0.372542
time/exploration sampling (s)      0.173733
time/logging (s)                   0.00482127
time/saving (s)                    0.0015425
time/training (s)                  2.22548
time/epoch (s)                     2.78166
time/total (s)                   171.297
Epoch                             62
-----------------------------  --------------
2019-04-22 22:12:52.046561 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 63 finished
-----------------------------  ---------------
replay_buffer/size             32200
trainer/QF1 Loss                 295.81
trainer/QF2 Loss                 295.707
trainer/Policy Loss               96.7948
trainer/Q1 Predictions Mean      -95.6802
trainer/Q1 Predictions Std        63.3664
trainer/Q1 Predictions Max       -29.8898
trainer/Q1 Predictions Min      -183.098
trainer/Q2 Predictions Mean      -95.6469
trainer/Q2 Predictions Std        63.4254
trainer/Q2 Predictions Max       -30.0334
trainer/Q2 Predictions Min      -183.334
trainer/Q Targets Mean           -94.2966
trainer/Q Targets Std             64.8116
trainer/Q Targets Max             -1.64756
trainer/Q Targets Min           -188.321
trainer/Log Pis Mean               2.07453
trainer/Log Pis Std                1.57472
trainer/Log Pis Max                6.78526
trainer/Log Pis Min               -3.93084
trainer/Policy mu Mean             0.00808436
trainer/Policy mu Std              0.939633
trainer/Policy mu Max              2.75631
trainer/Policy mu Min             -2.71329
trainer/Policy log std Mean       -1.83747
trainer/Policy log std Std         0.583554
trainer/Policy log std Max        -0.483093
trainer/Policy log std Min        -2.84254
trainer/Alpha                      0.0686458
trainer/Alpha Loss                 0.199661
exploration/num steps total    32200
exploration/num paths total      322
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.935406
exploration/Rewards Std            1.13392
exploration/Rewards Max           -0.0103412
exploration/Rewards Min           -9.14797
exploration/Returns Mean         -93.5406
exploration/Returns Std           71.2721
exploration/Returns Max          -30.8741
exploration/Returns Min         -231.721
exploration/Actions Mean           0.0166802
exploration/Actions Std            0.22166
exploration/Actions Max            0.998274
exploration/Actions Min           -0.995558
exploration/Num Paths              5
exploration/Average Returns      -93.5406
evaluation/num steps total     96000
evaluation/num paths total       960
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.22526
evaluation/Rewards Std             1.08198
evaluation/Rewards Max            -0.3254
evaluation/Rewards Min           -10.1354
evaluation/Returns Mean         -222.526
evaluation/Returns Std            89.3669
evaluation/Returns Max           -48.3256
evaluation/Returns Min          -305.648
evaluation/Actions Mean            0.000768778
evaluation/Actions Std             0.166879
evaluation/Actions Max             0.997747
evaluation/Actions Min            -0.997108
evaluation/Num Paths              15
evaluation/Average Returns      -222.526
time/data storing (s)              0.00387987
time/evaluation sampling (s)       0.351155
time/exploration sampling (s)      0.163362
time/logging (s)                   0.00571618
time/saving (s)                    0.00278588
time/training (s)                  2.15196
time/epoch (s)                     2.67886
time/total (s)                   173.981
Epoch                             63
-----------------------------  ---------------
2019-04-22 22:12:54.961960 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 64 finished
-----------------------------  ---------------
replay_buffer/size             32700
trainer/QF1 Loss                   1.46172
trainer/QF2 Loss                   1.60305
trainer/Policy Loss               80.4264
trainer/Q1 Predictions Mean      -78.9801
trainer/Q1 Predictions Std        60.7143
trainer/Q1 Predictions Max       -29.1429
trainer/Q1 Predictions Min      -191.167
trainer/Q2 Predictions Mean      -78.9642
trainer/Q2 Predictions Std        60.708
trainer/Q2 Predictions Max       -29.219
trainer/Q2 Predictions Min      -190.534
trainer/Q Targets Mean           -79.8194
trainer/Q Targets Std             61.3014
trainer/Q Targets Max            -29.2772
trainer/Q Targets Min           -192.575
trainer/Log Pis Mean               2.292
trainer/Log Pis Std                1.47762
trainer/Log Pis Max                7.69391
trainer/Log Pis Min               -1.5528
trainer/Policy mu Mean            -0.0530423
trainer/Policy mu Std              0.903794
trainer/Policy mu Max              2.75596
trainer/Policy mu Min             -3.34417
trainer/Policy log std Mean       -1.92069
trainer/Policy log std Std         0.620343
trainer/Policy log std Max        -0.254942
trainer/Policy log std Min        -2.81897
trainer/Alpha                      0.0700254
trainer/Alpha Loss                 0.776397
exploration/num steps total    32700
exploration/num paths total      327
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.9092
exploration/Rewards Std            1.1136
exploration/Rewards Max           -0.0151807
exploration/Rewards Min           -4.81078
exploration/Returns Mean         -90.92
exploration/Returns Std          105.048
exploration/Returns Max          -19.6273
exploration/Returns Min         -296.251
exploration/Actions Mean           0.000924688
exploration/Actions Std            0.182739
exploration/Actions Max            0.992174
exploration/Actions Min           -0.949631
exploration/Num Paths              5
exploration/Average Returns      -90.92
evaluation/num steps total     97500
evaluation/num paths total       975
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.46899
evaluation/Rewards Std             1.45837
evaluation/Rewards Max            -0.112157
evaluation/Rewards Min           -10.1383
evaluation/Returns Mean         -146.899
evaluation/Returns Std           114.128
evaluation/Returns Max           -28.4676
evaluation/Returns Min          -322.153
evaluation/Actions Mean            0.0101917
evaluation/Actions Std             0.176663
evaluation/Actions Max             0.995588
evaluation/Actions Min            -0.998443
evaluation/Num Paths              15
evaluation/Average Returns      -146.899
time/data storing (s)              0.00320124
time/evaluation sampling (s)       0.369453
time/exploration sampling (s)      0.160255
time/logging (s)                   0.00501621
time/saving (s)                    0.00194635
time/training (s)                  2.36744
time/epoch (s)                     2.90731
time/total (s)                   176.894
Epoch                             64
-----------------------------  ---------------
2019-04-22 22:12:57.989556 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 65 finished
-----------------------------  --------------
replay_buffer/size             33200
trainer/QF1 Loss                   4.15125
trainer/QF2 Loss                   4.29179
trainer/Policy Loss               95.0873
trainer/Q1 Predictions Mean      -94.031
trainer/Q1 Predictions Std        62.5739
trainer/Q1 Predictions Max       -28.152
trainer/Q1 Predictions Min      -178.172
trainer/Q2 Predictions Mean      -94.0042
trainer/Q2 Predictions Std        62.5471
trainer/Q2 Predictions Max       -28.1581
trainer/Q2 Predictions Min      -178.611
trainer/Q Targets Mean           -95.6092
trainer/Q Targets Std             63.559
trainer/Q Targets Max            -28.9906
trainer/Q Targets Min           -181.623
trainer/Log Pis Mean               2.09677
trainer/Log Pis Std                1.32552
trainer/Log Pis Max                5.78389
trainer/Log Pis Min               -1.48628
trainer/Policy mu Mean             0.0905184
trainer/Policy mu Std              0.936887
trainer/Policy mu Max              3.27692
trainer/Policy mu Min             -2.79072
trainer/Policy log std Mean       -1.83102
trainer/Policy log std Std         0.578803
trainer/Policy log std Max        -0.317746
trainer/Policy log std Min        -2.76922
trainer/Alpha                      0.0712097
trainer/Alpha Loss                 0.255666
exploration/num steps total    33200
exploration/num paths total      332
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.57022
exploration/Rewards Std            1.40071
exploration/Rewards Max           -0.0440067
exploration/Rewards Min           -8.01558
exploration/Returns Mean        -157.022
exploration/Returns Std          122.814
exploration/Returns Max          -27.4196
exploration/Returns Min         -324.561
exploration/Actions Mean           0.00728515
exploration/Actions Std            0.207992
exploration/Actions Max            0.999031
exploration/Actions Min           -0.988892
exploration/Num Paths              5
exploration/Average Returns     -157.022
evaluation/num steps total     99000
evaluation/num paths total       990
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.60947
evaluation/Rewards Std             1.49086
evaluation/Rewards Max            -0.113073
evaluation/Rewards Min           -10.4859
evaluation/Returns Mean         -160.947
evaluation/Returns Std           129.387
evaluation/Returns Max           -25.6531
evaluation/Returns Min          -353.444
evaluation/Actions Mean           -0.00841705
evaluation/Actions Std             0.171209
evaluation/Actions Max             0.997562
evaluation/Actions Min            -0.997735
evaluation/Num Paths              15
evaluation/Average Returns      -160.947
time/data storing (s)              0.00357568
time/evaluation sampling (s)       0.419057
time/exploration sampling (s)      0.210386
time/logging (s)                   0.00485679
time/saving (s)                    0.00195344
time/training (s)                  2.38067
time/epoch (s)                     3.0205
time/total (s)                   179.92
Epoch                             65
-----------------------------  --------------
2019-04-22 22:13:00.639058 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 66 finished
-----------------------------  ---------------
replay_buffer/size              33700
trainer/QF1 Loss                    9.89079
trainer/QF2 Loss                    9.87724
trainer/Policy Loss                95.3668
trainer/Q1 Predictions Mean       -94.2513
trainer/Q1 Predictions Std         64.8562
trainer/Q1 Predictions Max        -28.6817
trainer/Q1 Predictions Min       -178.999
trainer/Q2 Predictions Mean       -94.2879
trainer/Q2 Predictions Std         64.844
trainer/Q2 Predictions Max        -28.732
trainer/Q2 Predictions Min       -180.197
trainer/Q Targets Mean            -94.3516
trainer/Q Targets Std              65.5299
trainer/Q Targets Max              -0.309515
trainer/Q Targets Min            -179.791
trainer/Log Pis Mean                1.81698
trainer/Log Pis Std                 1.25526
trainer/Log Pis Max                 5.6548
trainer/Log Pis Min                -1.91416
trainer/Policy mu Mean              0.103181
trainer/Policy mu Std               0.809796
trainer/Policy mu Max               2.52132
trainer/Policy mu Min              -2.26806
trainer/Policy log std Mean        -1.87627
trainer/Policy log std Std          0.566096
trainer/Policy log std Max         -0.385725
trainer/Policy log std Min         -2.76864
trainer/Alpha                       0.0721539
trainer/Alpha Loss                 -0.481143
exploration/num steps total     33700
exploration/num paths total       337
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.901004
exploration/Rewards Std             1.21967
exploration/Rewards Max            -0.036054
exploration/Rewards Min            -9.21459
exploration/Returns Mean          -90.1004
exploration/Returns Std            82.6456
exploration/Returns Max           -32.1929
exploration/Returns Min          -252.967
exploration/Actions Mean           -0.00217502
exploration/Actions Std             0.235009
exploration/Actions Max             0.999316
exploration/Actions Min            -0.99856
exploration/Num Paths               5
exploration/Average Returns       -90.1004
evaluation/num steps total     100500
evaluation/num paths total       1005
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.43265
evaluation/Rewards Std              1.33078
evaluation/Rewards Max             -0.155753
evaluation/Rewards Min             -9.64743
evaluation/Returns Mean          -143.265
evaluation/Returns Std            106.48
evaluation/Returns Max            -28.506
evaluation/Returns Min           -295.971
evaluation/Actions Mean            -0.00827275
evaluation/Actions Std              0.162958
evaluation/Actions Max              0.998044
evaluation/Actions Min             -0.996589
evaluation/Num Paths               15
evaluation/Average Returns       -143.265
time/data storing (s)               0.00303799
time/evaluation sampling (s)        0.346335
time/exploration sampling (s)       0.147893
time/logging (s)                    0.0049322
time/saving (s)                     0.0022149
time/training (s)                   2.13951
time/epoch (s)                      2.64393
time/total (s)                    182.568
Epoch                              66
-----------------------------  ---------------
2019-04-22 22:13:03.275214 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 67 finished
-----------------------------  ---------------
replay_buffer/size              34200
trainer/QF1 Loss                    9.62905
trainer/QF2 Loss                    9.75136
trainer/Policy Loss                77.7516
trainer/Q1 Predictions Mean       -76.3784
trainer/Q1 Predictions Std         57.7401
trainer/Q1 Predictions Max        -28.5036
trainer/Q1 Predictions Min       -167.957
trainer/Q2 Predictions Mean       -76.365
trainer/Q2 Predictions Std         57.7436
trainer/Q2 Predictions Max        -28.6058
trainer/Q2 Predictions Min       -167.495
trainer/Q Targets Mean            -76.4966
trainer/Q Targets Std              58.6554
trainer/Q Targets Max              -0.54897
trainer/Q Targets Min            -170.616
trainer/Log Pis Mean                2.14507
trainer/Log Pis Std                 1.25177
trainer/Log Pis Max                 5.90964
trainer/Log Pis Min                -0.942929
trainer/Policy mu Mean              0.0201718
trainer/Policy mu Std               0.862585
trainer/Policy mu Max               2.80662
trainer/Policy mu Min              -3.07644
trainer/Policy log std Mean        -1.92251
trainer/Policy log std Std          0.577115
trainer/Policy log std Max         -0.521957
trainer/Policy log std Min         -2.80569
trainer/Alpha                       0.072402
trainer/Alpha Loss                  0.380878
exploration/num steps total     34200
exploration/num paths total       342
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.62429
exploration/Rewards Std             1.4567
exploration/Rewards Max            -0.0839325
exploration/Rewards Min            -9.13384
exploration/Returns Mean         -162.429
exploration/Returns Std           112.607
exploration/Returns Max           -50.8537
exploration/Returns Min          -329.099
exploration/Actions Mean           -0.00989243
exploration/Actions Std             0.227758
exploration/Actions Max             0.997704
exploration/Actions Min            -0.997585
exploration/Num Paths               5
exploration/Average Returns      -162.429
evaluation/num steps total     102000
evaluation/num paths total       1020
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.69988
evaluation/Rewards Std              1.30618
evaluation/Rewards Max             -0.188191
evaluation/Rewards Min             -9.9017
evaluation/Returns Mean          -169.988
evaluation/Returns Std            118.344
evaluation/Returns Max            -47.8285
evaluation/Returns Min           -330.872
evaluation/Actions Mean            -0.0142248
evaluation/Actions Std              0.1579
evaluation/Actions Max              0.978953
evaluation/Actions Min             -0.995812
evaluation/Num Paths               15
evaluation/Average Returns       -169.988
time/data storing (s)               0.00305522
time/evaluation sampling (s)        0.348252
time/exploration sampling (s)       0.156344
time/logging (s)                    0.00479891
time/saving (s)                     0.00192828
time/training (s)                   2.11547
time/epoch (s)                      2.62985
time/total (s)                    185.202
Epoch                              67
-----------------------------  ---------------
2019-04-22 22:13:06.051614 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 68 finished
-----------------------------  ---------------
replay_buffer/size              34700
trainer/QF1 Loss                   17.1762
trainer/QF2 Loss                   17.6144
trainer/Policy Loss                77.8807
trainer/Q1 Predictions Mean       -76.7489
trainer/Q1 Predictions Std         59.8225
trainer/Q1 Predictions Max        -27.8673
trainer/Q1 Predictions Min       -186.627
trainer/Q2 Predictions Mean       -76.7636
trainer/Q2 Predictions Std         59.8159
trainer/Q2 Predictions Max        -27.9426
trainer/Q2 Predictions Min       -186.141
trainer/Q Targets Mean            -77.3217
trainer/Q Targets Std              60.8634
trainer/Q Targets Max              -0.751599
trainer/Q Targets Min            -190.744
trainer/Log Pis Mean                1.9847
trainer/Log Pis Std                 1.25983
trainer/Log Pis Max                 6.02489
trainer/Log Pis Min                -2.79182
trainer/Policy mu Mean              0.0836427
trainer/Policy mu Std               0.775081
trainer/Policy mu Max               2.62636
trainer/Policy mu Min              -2.8647
trainer/Policy log std Mean        -1.93898
trainer/Policy log std Std          0.570627
trainer/Policy log std Max         -0.427539
trainer/Policy log std Min         -2.75944
trainer/Alpha                       0.0732764
trainer/Alpha Loss                 -0.0399968
exploration/num steps total     34700
exploration/num paths total       347
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.31995
exploration/Rewards Std             1.31105
exploration/Rewards Max            -0.0377872
exploration/Rewards Min            -8.793
exploration/Returns Mean         -131.995
exploration/Returns Std           100.59
exploration/Returns Max           -43.2092
exploration/Returns Min          -279.007
exploration/Actions Mean           -0.0170411
exploration/Actions Std             0.198833
exploration/Actions Max             0.86119
exploration/Actions Min            -0.999474
exploration/Num Paths               5
exploration/Average Returns      -131.995
evaluation/num steps total     103500
evaluation/num paths total       1035
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.33434
evaluation/Rewards Std              1.23708
evaluation/Rewards Max             -0.109018
evaluation/Rewards Min            -10.0574
evaluation/Returns Mean          -133.434
evaluation/Returns Std             99.519
evaluation/Returns Max            -18.0712
evaluation/Returns Min           -282.539
evaluation/Actions Mean             0.016323
evaluation/Actions Std              0.164067
evaluation/Actions Max              0.997965
evaluation/Actions Min             -0.99402
evaluation/Num Paths               15
evaluation/Average Returns       -133.434
time/data storing (s)               0.0030165
time/evaluation sampling (s)        0.334201
time/exploration sampling (s)       0.148399
time/logging (s)                    0.00517656
time/saving (s)                     0.00196388
time/training (s)                   2.27797
time/epoch (s)                      2.77073
time/total (s)                    187.978
Epoch                              68
-----------------------------  ---------------
2019-04-22 22:13:08.982342 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 69 finished
-----------------------------  ---------------
replay_buffer/size              35200
trainer/QF1 Loss                    8.61311
trainer/QF2 Loss                    8.50816
trainer/Policy Loss                84.6113
trainer/Q1 Predictions Mean       -83.8689
trainer/Q1 Predictions Std         62.283
trainer/Q1 Predictions Max        -27.138
trainer/Q1 Predictions Min       -194.639
trainer/Q2 Predictions Mean       -83.8693
trainer/Q2 Predictions Std         62.2855
trainer/Q2 Predictions Max        -27.187
trainer/Q2 Predictions Min       -194.843
trainer/Q Targets Mean            -84.2793
trainer/Q Targets Std              63.0997
trainer/Q Targets Max              -0.190301
trainer/Q Targets Min            -195.337
trainer/Log Pis Mean                1.77685
trainer/Log Pis Std                 1.72873
trainer/Log Pis Max                 8.13045
trainer/Log Pis Min                -5.80895
trainer/Policy mu Mean             -0.0154846
trainer/Policy mu Std               0.924283
trainer/Policy mu Max               2.92123
trainer/Policy mu Min              -3.04813
trainer/Policy log std Mean        -1.84638
trainer/Policy log std Std          0.571998
trainer/Policy log std Max         -0.110882
trainer/Policy log std Min         -2.76034
trainer/Alpha                       0.0764837
trainer/Alpha Loss                 -0.573657
exploration/num steps total     35200
exploration/num paths total       352
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -2.06687
exploration/Rewards Std             1.37444
exploration/Rewards Max            -0.38595
exploration/Rewards Min            -9.96814
exploration/Returns Mean         -206.687
exploration/Returns Std            90.8657
exploration/Returns Max           -87.6667
exploration/Returns Min          -312.204
exploration/Actions Mean            0.0297676
exploration/Actions Std             0.239908
exploration/Actions Max             0.998528
exploration/Actions Min            -0.974736
exploration/Num Paths               5
exploration/Average Returns      -206.687
evaluation/num steps total     105000
evaluation/num paths total       1050
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.88643
evaluation/Rewards Std              1.39817
evaluation/Rewards Max             -0.11257
evaluation/Rewards Min            -10.396
evaluation/Returns Mean          -188.643
evaluation/Returns Std            116.134
evaluation/Returns Max            -29.7408
evaluation/Returns Min           -324.969
evaluation/Actions Mean            -0.00736631
evaluation/Actions Std              0.18408
evaluation/Actions Max              0.994301
evaluation/Actions Min             -0.994814
evaluation/Num Paths               15
evaluation/Average Returns       -188.643
time/data storing (s)               0.00359994
time/evaluation sampling (s)        0.391983
time/exploration sampling (s)       0.176705
time/logging (s)                    0.00485556
time/saving (s)                     0.00204618
time/training (s)                   2.34495
time/epoch (s)                      2.92414
time/total (s)                    190.906
Epoch                              69
-----------------------------  ---------------
2019-04-22 22:13:11.680307 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 70 finished
-----------------------------  ----------------
replay_buffer/size              35700
trainer/QF1 Loss                    1.56135
trainer/QF2 Loss                    1.73286
trainer/Policy Loss                90.835
trainer/Q1 Predictions Mean       -89.8085
trainer/Q1 Predictions Std         62.9952
trainer/Q1 Predictions Max        -26.7487
trainer/Q1 Predictions Min       -195.404
trainer/Q2 Predictions Mean       -89.7526
trainer/Q2 Predictions Std         63.0036
trainer/Q2 Predictions Max        -26.6863
trainer/Q2 Predictions Min       -194.851
trainer/Q Targets Mean            -90.5269
trainer/Q Targets Std              63.6962
trainer/Q Targets Max             -26.9061
trainer/Q Targets Min            -197.322
trainer/Log Pis Mean                2.06784
trainer/Log Pis Std                 1.59934
trainer/Log Pis Max                 7.70792
trainer/Log Pis Min                -1.56746
trainer/Policy mu Mean              0.0479633
trainer/Policy mu Std               1.01936
trainer/Policy mu Max               2.63893
trainer/Policy mu Min              -3.38139
trainer/Policy log std Mean        -1.79038
trainer/Policy log std Std          0.602371
trainer/Policy log std Max         -0.0786161
trainer/Policy log std Min         -2.74242
trainer/Alpha                       0.0767128
trainer/Alpha Loss                  0.174207
exploration/num steps total     35700
exploration/num paths total       357
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.70915
exploration/Rewards Std             1.11304
exploration/Rewards Max            -0.172337
exploration/Rewards Min            -7.59832
exploration/Returns Mean         -170.915
exploration/Returns Std            94.5658
exploration/Returns Max           -57.2902
exploration/Returns Min          -282.338
exploration/Actions Mean           -0.0105193
exploration/Actions Std             0.204029
exploration/Actions Max             0.999165
exploration/Actions Min            -0.997355
exploration/Num Paths               5
exploration/Average Returns      -170.915
evaluation/num steps total     106500
evaluation/num paths total       1065
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.08191
evaluation/Rewards Std              1.04375
evaluation/Rewards Max             -0.199889
evaluation/Rewards Min             -7.15499
evaluation/Returns Mean          -108.191
evaluation/Returns Std             91.1212
evaluation/Returns Max            -30.7427
evaluation/Returns Min           -281.834
evaluation/Actions Mean             0.000594717
evaluation/Actions Std              0.130936
evaluation/Actions Max              0.995051
evaluation/Actions Min             -0.987321
evaluation/Num Paths               15
evaluation/Average Returns       -108.191
time/data storing (s)               0.00362429
time/evaluation sampling (s)        0.390403
time/exploration sampling (s)       0.178213
time/logging (s)                    0.00524065
time/saving (s)                     0.00198257
time/training (s)                   2.11271
time/epoch (s)                      2.69218
time/total (s)                    193.603
Epoch                              70
-----------------------------  ----------------
2019-04-22 22:13:14.290078 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 71 finished
-----------------------------  ---------------
replay_buffer/size              36200
trainer/QF1 Loss                  223.269
trainer/QF2 Loss                  223.65
trainer/Policy Loss                86.1333
trainer/Q1 Predictions Mean       -84.909
trainer/Q1 Predictions Std         61.8936
trainer/Q1 Predictions Max        -26.1948
trainer/Q1 Predictions Min       -201.529
trainer/Q2 Predictions Mean       -84.883
trainer/Q2 Predictions Std         61.8857
trainer/Q2 Predictions Max        -26.2134
trainer/Q2 Predictions Min       -201.737
trainer/Q Targets Mean            -83.6629
trainer/Q Targets Std              61.9269
trainer/Q Targets Max              -3.3751
trainer/Q Targets Min            -201.879
trainer/Log Pis Mean                2.0543
trainer/Log Pis Std                 1.23467
trainer/Log Pis Max                 7.09165
trainer/Log Pis Min                -1.94356
trainer/Policy mu Mean              0.0942952
trainer/Policy mu Std               0.807379
trainer/Policy mu Max               3.30747
trainer/Policy mu Min              -2.44683
trainer/Policy log std Mean        -1.92048
trainer/Policy log std Std          0.565571
trainer/Policy log std Max         -0.393845
trainer/Policy log std Min         -2.80888
trainer/Alpha                       0.0749359
trainer/Alpha Loss                  0.140701
exploration/num steps total     36200
exploration/num paths total       362
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.55757
exploration/Rewards Std             1.49953
exploration/Rewards Max            -0.138126
exploration/Rewards Min           -10.5297
exploration/Returns Mean         -155.757
exploration/Returns Std           110.718
exploration/Returns Max           -40.4969
exploration/Returns Min          -301.194
exploration/Actions Mean            0.00350393
exploration/Actions Std             0.222596
exploration/Actions Max             0.998136
exploration/Actions Min            -0.996255
exploration/Num Paths               5
exploration/Average Returns      -155.757
evaluation/num steps total     108000
evaluation/num paths total       1080
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.32355
evaluation/Rewards Std              1.23317
evaluation/Rewards Max             -0.2451
evaluation/Rewards Min             -8.51326
evaluation/Returns Mean          -132.355
evaluation/Returns Std            107.497
evaluation/Returns Max            -26.304
evaluation/Returns Min           -284.948
evaluation/Actions Mean             0.0122414
evaluation/Actions Std              0.162911
evaluation/Actions Max              0.996227
evaluation/Actions Min             -0.990698
evaluation/Num Paths               15
evaluation/Average Returns       -132.355
time/data storing (s)               0.00320835
time/evaluation sampling (s)        0.353806
time/exploration sampling (s)       0.156506
time/logging (s)                    0.00481122
time/saving (s)                     0.00200164
time/training (s)                   2.08228
time/epoch (s)                      2.60261
time/total (s)                    196.211
Epoch                              71
-----------------------------  ---------------
2019-04-22 22:13:16.899856 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 72 finished
-----------------------------  ---------------
replay_buffer/size              36700
trainer/QF1 Loss                    7.90348
trainer/QF2 Loss                    7.67436
trainer/Policy Loss                83.1755
trainer/Q1 Predictions Mean       -81.949
trainer/Q1 Predictions Std         61.9312
trainer/Q1 Predictions Max        -26.0624
trainer/Q1 Predictions Min       -194.355
trainer/Q2 Predictions Mean       -82.0246
trainer/Q2 Predictions Std         61.9674
trainer/Q2 Predictions Max        -26.0363
trainer/Q2 Predictions Min       -194.018
trainer/Q Targets Mean            -82.2473
trainer/Q Targets Std              62.8335
trainer/Q Targets Max              -0.926372
trainer/Q Targets Min            -195.899
trainer/Log Pis Mean                2.02162
trainer/Log Pis Std                 1.26376
trainer/Log Pis Max                 7.43183
trainer/Log Pis Min                -0.592643
trainer/Policy mu Mean              0.151251
trainer/Policy mu Std               0.826494
trainer/Policy mu Max               3.1046
trainer/Policy mu Min              -3.22781
trainer/Policy log std Mean        -1.92587
trainer/Policy log std Std          0.566928
trainer/Policy log std Max         -0.128591
trainer/Policy log std Min         -2.76638
trainer/Alpha                       0.0758973
trainer/Alpha Loss                  0.0557414
exploration/num steps total     36700
exploration/num paths total       367
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.89971
exploration/Rewards Std             1.346
exploration/Rewards Max            -0.191175
exploration/Rewards Min           -10.3019
exploration/Returns Mean         -189.971
exploration/Returns Std           113.672
exploration/Returns Max           -44.1701
exploration/Returns Min          -287.227
exploration/Actions Mean            0.0162967
exploration/Actions Std             0.215195
exploration/Actions Max             0.999478
exploration/Actions Min            -0.983174
exploration/Num Paths               5
exploration/Average Returns      -189.971
evaluation/num steps total     109500
evaluation/num paths total       1095
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.41891
evaluation/Rewards Std              1.3622
evaluation/Rewards Max             -0.316772
evaluation/Rewards Min            -10.2447
evaluation/Returns Mean          -141.891
evaluation/Returns Std            103.301
evaluation/Returns Max            -38.768
evaluation/Returns Min           -305.974
evaluation/Actions Mean             0.00545863
evaluation/Actions Std              0.180856
evaluation/Actions Max              0.998046
evaluation/Actions Min             -0.997197
evaluation/Num Paths               15
evaluation/Average Returns       -141.891
time/data storing (s)               0.00318828
time/evaluation sampling (s)        0.350412
time/exploration sampling (s)       0.157522
time/logging (s)                    0.00499189
time/saving (s)                     0.00177198
time/training (s)                   2.0858
time/epoch (s)                      2.60369
time/total (s)                    198.819
Epoch                              72
-----------------------------  ---------------
2019-04-22 22:13:19.493922 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 73 finished
-----------------------------  ---------------
replay_buffer/size              37200
trainer/QF1 Loss                    7.71265
trainer/QF2 Loss                    7.79207
trainer/Policy Loss                75.3879
trainer/Q1 Predictions Mean       -74.1426
trainer/Q1 Predictions Std         59.3878
trainer/Q1 Predictions Max        -25.6699
trainer/Q1 Predictions Min       -195.047
trainer/Q2 Predictions Mean       -74.16
trainer/Q2 Predictions Std         59.3323
trainer/Q2 Predictions Max        -25.6766
trainer/Q2 Predictions Min       -195.032
trainer/Q Targets Mean            -74.6294
trainer/Q Targets Std              60.2492
trainer/Q Targets Max              -0.231457
trainer/Q Targets Min            -198.478
trainer/Log Pis Mean                1.9426
trainer/Log Pis Std                 1.20443
trainer/Log Pis Max                 7.01622
trainer/Log Pis Min                -1.80764
trainer/Policy mu Mean             -0.0309841
trainer/Policy mu Std               0.762395
trainer/Policy mu Max               2.81302
trainer/Policy mu Min              -3.66766
trainer/Policy log std Mean        -1.97096
trainer/Policy log std Std          0.52015
trainer/Policy log std Max         -0.0264702
trainer/Policy log std Min         -2.80723
trainer/Alpha                       0.0756099
trainer/Alpha Loss                 -0.14823
exploration/num steps total     37200
exploration/num paths total       372
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.60229
exploration/Rewards Std             1.48872
exploration/Rewards Max            -0.154914
exploration/Rewards Min            -9.37627
exploration/Returns Mean         -160.229
exploration/Returns Std           114.421
exploration/Returns Max           -50.4719
exploration/Returns Min          -300.518
exploration/Actions Mean           -0.00616754
exploration/Actions Std             0.215635
exploration/Actions Max             0.997938
exploration/Actions Min            -0.99854
exploration/Num Paths               5
exploration/Average Returns      -160.229
evaluation/num steps total     111000
evaluation/num paths total       1110
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.09674
evaluation/Rewards Std              1.43521
evaluation/Rewards Max             -0.192693
evaluation/Rewards Min             -9.64671
evaluation/Returns Mean          -109.674
evaluation/Returns Std             97.0866
evaluation/Returns Max            -42.093
evaluation/Returns Min           -310.311
evaluation/Actions Mean            -0.0118701
evaluation/Actions Std              0.200802
evaluation/Actions Max              0.998189
evaluation/Actions Min             -0.998978
evaluation/Num Paths               15
evaluation/Average Returns       -109.674
time/data storing (s)               0.00330612
time/evaluation sampling (s)        0.345764
time/exploration sampling (s)       0.156658
time/logging (s)                    0.00492134
time/saving (s)                     0.00194976
time/training (s)                   2.07541
time/epoch (s)                      2.58801
time/total (s)                    201.411
Epoch                              73
-----------------------------  ---------------
2019-04-22 22:13:22.088946 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 74 finished
-----------------------------  ---------------
replay_buffer/size              37700
trainer/QF1 Loss                   25.2179
trainer/QF2 Loss                   25.1966
trainer/Policy Loss                78.4183
trainer/Q1 Predictions Mean       -77.3571
trainer/Q1 Predictions Std         60.4079
trainer/Q1 Predictions Max        -24.8744
trainer/Q1 Predictions Min       -168.983
trainer/Q2 Predictions Mean       -77.3448
trainer/Q2 Predictions Std         60.4172
trainer/Q2 Predictions Max        -24.9509
trainer/Q2 Predictions Min       -167.743
trainer/Q Targets Mean            -77.5611
trainer/Q Targets Std              61.6255
trainer/Q Targets Max              -1.82501
trainer/Q Targets Min            -169.705
trainer/Log Pis Mean                1.85226
trainer/Log Pis Std                 1.17189
trainer/Log Pis Max                 5.60145
trainer/Log Pis Min                -1.58658
trainer/Policy mu Mean              0.00208375
trainer/Policy mu Std               0.775631
trainer/Policy mu Max               2.46972
trainer/Policy mu Min              -2.44467
trainer/Policy log std Mean        -1.88413
trainer/Policy log std Std          0.539576
trainer/Policy log std Max         -0.577076
trainer/Policy log std Min         -2.61637
trainer/Alpha                       0.0766043
trainer/Alpha Loss                 -0.379553
exploration/num steps total     37700
exploration/num paths total       377
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.30218
exploration/Rewards Std             1.1232
exploration/Rewards Max            -0.0793723
exploration/Rewards Min            -5.64514
exploration/Returns Mean         -130.218
exploration/Returns Std           104.254
exploration/Returns Max           -41.6513
exploration/Returns Min          -283.028
exploration/Actions Mean           -0.00319209
exploration/Actions Std             0.189501
exploration/Actions Max             0.972252
exploration/Actions Min            -0.989633
exploration/Num Paths               5
exploration/Average Returns      -130.218
evaluation/num steps total     112500
evaluation/num paths total       1125
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.46451
evaluation/Rewards Std              1.33232
evaluation/Rewards Max             -0.212123
evaluation/Rewards Min             -9.59935
evaluation/Returns Mean          -146.451
evaluation/Returns Std            109.188
evaluation/Returns Max            -34.863
evaluation/Returns Min           -297.058
evaluation/Actions Mean            -0.015007
evaluation/Actions Std              0.168324
evaluation/Actions Max              0.992426
evaluation/Actions Min             -0.998287
evaluation/Num Paths               15
evaluation/Average Returns       -146.451
time/data storing (s)               0.00346762
time/evaluation sampling (s)        0.347084
time/exploration sampling (s)       0.156984
time/logging (s)                    0.00429801
time/saving (s)                     0.00192182
time/training (s)                   2.0744
time/epoch (s)                      2.58815
time/total (s)                    204.004
Epoch                              74
-----------------------------  ---------------
2019-04-22 22:13:24.681058 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 75 finished
-----------------------------  ---------------
replay_buffer/size              38200
trainer/QF1 Loss                    0.59032
trainer/QF2 Loss                    0.664314
trainer/Policy Loss                70.573
trainer/Q1 Predictions Mean       -69.2355
trainer/Q1 Predictions Std         54.7729
trainer/Q1 Predictions Max        -25.3141
trainer/Q1 Predictions Min       -175.148
trainer/Q2 Predictions Mean       -69.2638
trainer/Q2 Predictions Std         54.7238
trainer/Q2 Predictions Max        -25.4709
trainer/Q2 Predictions Min       -175.504
trainer/Q Targets Mean            -69.1167
trainer/Q Targets Std              55.1603
trainer/Q Targets Max             -24.7527
trainer/Q Targets Min            -178.352
trainer/Log Pis Mean                1.94907
trainer/Log Pis Std                 1.46507
trainer/Log Pis Max                 5.71247
trainer/Log Pis Min                -3.20518
trainer/Policy mu Mean              0.117656
trainer/Policy mu Std               0.845961
trainer/Policy mu Max               3.14063
trainer/Policy mu Min              -2.45218
trainer/Policy log std Mean        -1.86478
trainer/Policy log std Std          0.525143
trainer/Policy log std Max         -0.561692
trainer/Policy log std Min         -2.64284
trainer/Alpha                       0.0754629
trainer/Alpha Loss                 -0.131612
exploration/num steps total     38200
exploration/num paths total       382
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.24463
exploration/Rewards Std             1.22135
exploration/Rewards Max            -0.00574422
exploration/Rewards Min            -9.0735
exploration/Returns Mean         -124.463
exploration/Returns Std            97.3693
exploration/Returns Max           -23.6374
exploration/Returns Min          -262.622
exploration/Actions Mean           -0.0086129
exploration/Actions Std             0.18667
exploration/Actions Max             0.950706
exploration/Actions Min            -0.998994
exploration/Num Paths               5
exploration/Average Returns      -124.463
evaluation/num steps total     114000
evaluation/num paths total       1140
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.02432
evaluation/Rewards Std              1.26788
evaluation/Rewards Max             -0.122817
evaluation/Rewards Min            -10.6868
evaluation/Returns Mean          -102.432
evaluation/Returns Std            100.679
evaluation/Returns Max            -13.9292
evaluation/Returns Min           -285.733
evaluation/Actions Mean            -0.00713484
evaluation/Actions Std              0.171646
evaluation/Actions Max              0.997034
evaluation/Actions Min             -0.997772
evaluation/Num Paths               15
evaluation/Average Returns       -102.432
time/data storing (s)               0.00337337
time/evaluation sampling (s)        0.342998
time/exploration sampling (s)       0.156369
time/logging (s)                    0.00504205
time/saving (s)                     0.00201135
time/training (s)                   2.07707
time/epoch (s)                      2.58686
time/total (s)                    206.595
Epoch                              75
-----------------------------  ---------------
2019-04-22 22:13:27.277141 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 76 finished
-----------------------------  ---------------
replay_buffer/size              38700
trainer/QF1 Loss                    1.16638
trainer/QF2 Loss                    1.19349
trainer/Policy Loss                74.6479
trainer/Q1 Predictions Mean       -73.2833
trainer/Q1 Predictions Std         57.8548
trainer/Q1 Predictions Max        -24.2933
trainer/Q1 Predictions Min       -175.222
trainer/Q2 Predictions Mean       -73.3026
trainer/Q2 Predictions Std         57.8231
trainer/Q2 Predictions Max        -24.3189
trainer/Q2 Predictions Min       -175.723
trainer/Q Targets Mean            -73.9493
trainer/Q Targets Std              58.5391
trainer/Q Targets Max             -24.2491
trainer/Q Targets Min            -176.879
trainer/Log Pis Mean                2.08789
trainer/Log Pis Std                 1.22208
trainer/Log Pis Max                 7.48039
trainer/Log Pis Min                -1.43299
trainer/Policy mu Mean              0.118925
trainer/Policy mu Std               0.895527
trainer/Policy mu Max               3.047
trainer/Policy mu Min              -3.69835
trainer/Policy log std Mean        -1.83593
trainer/Policy log std Std          0.581345
trainer/Policy log std Max         -0.323499
trainer/Policy log std Min         -2.621
trainer/Alpha                       0.0727749
trainer/Alpha Loss                  0.230289
exploration/num steps total     38700
exploration/num paths total       387
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.998295
exploration/Rewards Std             1.0563
exploration/Rewards Max            -0.0202838
exploration/Rewards Min            -8.2079
exploration/Returns Mean          -99.8295
exploration/Returns Std            91.5292
exploration/Returns Max           -31.192
exploration/Returns Min          -281.275
exploration/Actions Mean           -0.0132163
exploration/Actions Std             0.207042
exploration/Actions Max             0.987506
exploration/Actions Min            -0.999267
exploration/Num Paths               5
exploration/Average Returns       -99.8295
evaluation/num steps total     115500
evaluation/num paths total       1155
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.69957
evaluation/Rewards Std              1.18898
evaluation/Rewards Max             -0.179519
evaluation/Rewards Min            -10.4032
evaluation/Returns Mean          -169.957
evaluation/Returns Std             90.9112
evaluation/Returns Max            -21.6214
evaluation/Returns Min           -266.795
evaluation/Actions Mean             0.00628526
evaluation/Actions Std              0.164348
evaluation/Actions Max              0.996685
evaluation/Actions Min             -0.998079
evaluation/Num Paths               15
evaluation/Average Returns       -169.957
time/data storing (s)               0.0033115
time/evaluation sampling (s)        0.351443
time/exploration sampling (s)       0.159134
time/logging (s)                    0.00480741
time/saving (s)                     0.00194004
time/training (s)                   2.06883
time/epoch (s)                      2.58947
time/total (s)                    209.189
Epoch                              76
-----------------------------  ---------------
2019-04-22 22:13:29.872073 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 77 finished
-----------------------------  ---------------
replay_buffer/size              39200
trainer/QF1 Loss                    2.79824
trainer/QF2 Loss                    2.8294
trainer/Policy Loss                75.0583
trainer/Q1 Predictions Mean       -74.0853
trainer/Q1 Predictions Std         58.0704
trainer/Q1 Predictions Max        -24.2446
trainer/Q1 Predictions Min       -185.104
trainer/Q2 Predictions Mean       -74.0779
trainer/Q2 Predictions Std         58.0832
trainer/Q2 Predictions Max        -24.2148
trainer/Q2 Predictions Min       -184.599
trainer/Q Targets Mean            -75.1121
trainer/Q Targets Std              59.1086
trainer/Q Targets Max             -24.0246
trainer/Q Targets Min            -190.111
trainer/Log Pis Mean                1.98765
trainer/Log Pis Std                 1.39965
trainer/Log Pis Max                 6.33822
trainer/Log Pis Min                -2.3638
trainer/Policy mu Mean              0.015942
trainer/Policy mu Std               0.888685
trainer/Policy mu Max               2.85581
trainer/Policy mu Min              -2.77612
trainer/Policy log std Mean        -1.89919
trainer/Policy log std Std          0.562737
trainer/Policy log std Max         -0.31795
trainer/Policy log std Min         -2.68686
trainer/Alpha                       0.0745387
trainer/Alpha Loss                 -0.0320559
exploration/num steps total     39200
exploration/num paths total       392
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.847383
exploration/Rewards Std             1.18449
exploration/Rewards Max            -0.0257258
exploration/Rewards Min            -9.3473
exploration/Returns Mean          -84.7383
exploration/Returns Std            84.1639
exploration/Returns Max           -28.626
exploration/Returns Min          -251.184
exploration/Actions Mean            0.0120981
exploration/Actions Std             0.219191
exploration/Actions Max             0.999386
exploration/Actions Min            -0.998481
exploration/Num Paths               5
exploration/Average Returns       -84.7383
evaluation/num steps total     117000
evaluation/num paths total       1170
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.04836
evaluation/Rewards Std              1.25116
evaluation/Rewards Max             -0.141992
evaluation/Rewards Min             -9.64756
evaluation/Returns Mean          -104.836
evaluation/Returns Std             95.3188
evaluation/Returns Max            -24.5382
evaluation/Returns Min           -275.323
evaluation/Actions Mean            -0.00184894
evaluation/Actions Std              0.171305
evaluation/Actions Max              0.995168
evaluation/Actions Min             -0.996666
evaluation/Num Paths               15
evaluation/Average Returns       -104.836
time/data storing (s)               0.00361858
time/evaluation sampling (s)        0.343393
time/exploration sampling (s)       0.154586
time/logging (s)                    0.00488334
time/saving (s)                     0.00232243
time/training (s)                   2.07987
time/epoch (s)                      2.58868
time/total (s)                    211.783
Epoch                              77
-----------------------------  ---------------
2019-04-22 22:13:32.487648 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 78 finished
-----------------------------  ---------------
replay_buffer/size              39700
trainer/QF1 Loss                    2.04292
trainer/QF2 Loss                    1.98089
trainer/Policy Loss                81.1017
trainer/Q1 Predictions Mean       -80.0601
trainer/Q1 Predictions Std         59.4219
trainer/Q1 Predictions Max        -23.5707
trainer/Q1 Predictions Min       -173.198
trainer/Q2 Predictions Mean       -80.0845
trainer/Q2 Predictions Std         59.4427
trainer/Q2 Predictions Max        -23.6082
trainer/Q2 Predictions Min       -173.521
trainer/Q Targets Mean            -80.8253
trainer/Q Targets Std              60.2537
trainer/Q Targets Max             -23.4928
trainer/Q Targets Min            -175.935
trainer/Log Pis Mean                1.88679
trainer/Log Pis Std                 1.28559
trainer/Log Pis Max                 4.52079
trainer/Log Pis Min                -1.94524
trainer/Policy mu Mean              0.133722
trainer/Policy mu Std               0.876989
trainer/Policy mu Max               2.7562
trainer/Policy mu Min              -2.62402
trainer/Policy log std Mean        -1.80799
trainer/Policy log std Std          0.603188
trainer/Policy log std Max         -0.469533
trainer/Policy log std Min         -2.74272
trainer/Alpha                       0.0741109
trainer/Alpha Loss                 -0.294602
exploration/num steps total     39700
exploration/num paths total       397
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.67432
exploration/Rewards Std             1.25795
exploration/Rewards Max            -0.037534
exploration/Rewards Min           -10.3789
exploration/Returns Mean         -167.432
exploration/Returns Std            96.8552
exploration/Returns Max           -49.3862
exploration/Returns Min          -278.454
exploration/Actions Mean           -0.0111661
exploration/Actions Std             0.229199
exploration/Actions Max             0.996517
exploration/Actions Min            -0.999895
exploration/Num Paths               5
exploration/Average Returns      -167.432
evaluation/num steps total     118500
evaluation/num paths total       1185
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.49888
evaluation/Rewards Std              1.31841
evaluation/Rewards Max             -0.136774
evaluation/Rewards Min            -10.2288
evaluation/Returns Mean          -149.888
evaluation/Returns Std             98.2522
evaluation/Returns Max            -19.82
evaluation/Returns Min           -273.265
evaluation/Actions Mean            -0.00749461
evaluation/Actions Std              0.185861
evaluation/Actions Max              0.998062
evaluation/Actions Min             -0.99835
evaluation/Num Paths               15
evaluation/Average Returns       -149.888
time/data storing (s)               0.00333249
time/evaluation sampling (s)        0.347659
time/exploration sampling (s)       0.15644
time/logging (s)                    0.00485028
time/saving (s)                     0.00212755
time/training (s)                   2.09496
time/epoch (s)                      2.60937
time/total (s)                    214.396
Epoch                              78
-----------------------------  ---------------
2019-04-22 22:13:35.120969 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 79 finished
-----------------------------  ----------------
replay_buffer/size              40200
trainer/QF1 Loss                  197.361
trainer/QF2 Loss                  196.903
trainer/Policy Loss                69.9294
trainer/Q1 Predictions Mean       -68.8838
trainer/Q1 Predictions Std         57.1346
trainer/Q1 Predictions Max        -23.1954
trainer/Q1 Predictions Min       -197.087
trainer/Q2 Predictions Mean       -68.8152
trainer/Q2 Predictions Std         57.1247
trainer/Q2 Predictions Max        -23.1842
trainer/Q2 Predictions Min       -196.52
trainer/Q Targets Mean            -68.3083
trainer/Q Targets Std              57.7029
trainer/Q Targets Max              -4.28644
trainer/Q Targets Min            -195.429
trainer/Log Pis Mean                1.97266
trainer/Log Pis Std                 1.67882
trainer/Log Pis Max                 7.20155
trainer/Log Pis Min                -1.68644
trainer/Policy mu Mean              0.197052
trainer/Policy mu Std               0.945161
trainer/Policy mu Max               3.07403
trainer/Policy mu Min              -2.92431
trainer/Policy log std Mean        -1.88883
trainer/Policy log std Std          0.630782
trainer/Policy log std Max         -0.227255
trainer/Policy log std Min         -2.80549
trainer/Alpha                       0.0756885
trainer/Alpha Loss                 -0.0705525
exploration/num steps total     40200
exploration/num paths total       402
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.531592
exploration/Rewards Std             0.431992
exploration/Rewards Max            -0.0237979
exploration/Rewards Min            -4.20139
exploration/Returns Mean          -53.1592
exploration/Returns Std            17.635
exploration/Returns Max           -27.1162
exploration/Returns Min           -72.9748
exploration/Actions Mean            0.000431436
exploration/Actions Std             0.187518
exploration/Actions Max             0.979397
exploration/Actions Min            -0.984654
exploration/Num Paths               5
exploration/Average Returns       -53.1592
evaluation/num steps total     120000
evaluation/num paths total       1200
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.3992
evaluation/Rewards Std              1.17653
evaluation/Rewards Max             -0.2024
evaluation/Rewards Min             -9.06541
evaluation/Returns Mean          -139.92
evaluation/Returns Std             94.1926
evaluation/Returns Max            -31.7881
evaluation/Returns Min           -272.73
evaluation/Actions Mean             0.0090558
evaluation/Actions Std              0.173817
evaluation/Actions Max              0.995874
evaluation/Actions Min             -0.989528
evaluation/Num Paths               15
evaluation/Average Returns       -139.92
time/data storing (s)               0.00327774
time/evaluation sampling (s)        0.345708
time/exploration sampling (s)       0.157253
time/logging (s)                    0.00481618
time/saving (s)                     0.00239121
time/training (s)                   2.11383
time/epoch (s)                      2.62728
time/total (s)                    217.028
Epoch                              79
-----------------------------  ----------------
2019-04-22 22:13:37.702652 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 80 finished
-----------------------------  ---------------
replay_buffer/size              40700
trainer/QF1 Loss                   21.2887
trainer/QF2 Loss                   21.0226
trainer/Policy Loss                74.0527
trainer/Q1 Predictions Mean       -72.7066
trainer/Q1 Predictions Std         56.9886
trainer/Q1 Predictions Max        -23.6268
trainer/Q1 Predictions Min       -180.818
trainer/Q2 Predictions Mean       -72.689
trainer/Q2 Predictions Std         57.05
trainer/Q2 Predictions Max        -23.5923
trainer/Q2 Predictions Min       -181.153
trainer/Q Targets Mean            -72.7383
trainer/Q Targets Std              58.7721
trainer/Q Targets Max              -0.406054
trainer/Q Targets Min            -186.219
trainer/Log Pis Mean                2.18448
trainer/Log Pis Std                 1.11052
trainer/Log Pis Max                 7.29098
trainer/Log Pis Min                -0.341113
trainer/Policy mu Mean              0.135655
trainer/Policy mu Std               0.857392
trainer/Policy mu Max               3.6249
trainer/Policy mu Min              -2.88674
trainer/Policy log std Mean        -1.97385
trainer/Policy log std Std          0.583668
trainer/Policy log std Max         -0.207631
trainer/Policy log std Min         -2.83228
trainer/Alpha                       0.0741927
trainer/Alpha Loss                  0.47986
exploration/num steps total     40700
exploration/num paths total       407
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.850827
exploration/Rewards Std             0.998264
exploration/Rewards Max            -0.0374476
exploration/Rewards Min            -6.60853
exploration/Returns Mean          -85.0827
exploration/Returns Std            74.3914
exploration/Returns Max           -34.6335
exploration/Returns Min          -232.745
exploration/Actions Mean            0.0044197
exploration/Actions Std             0.199505
exploration/Actions Max             0.996578
exploration/Actions Min            -0.992749
exploration/Num Paths               5
exploration/Average Returns       -85.0827
evaluation/num steps total     121500
evaluation/num paths total       1215
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.735789
evaluation/Rewards Std              1.01198
evaluation/Rewards Max             -0.101537
evaluation/Rewards Min            -10.0286
evaluation/Returns Mean           -73.5789
evaluation/Returns Std             60.275
evaluation/Returns Max            -23.3436
evaluation/Returns Min           -233.4
evaluation/Actions Mean             0.00791984
evaluation/Actions Std              0.16636
evaluation/Actions Max              0.99698
evaluation/Actions Min             -0.997702
evaluation/Num Paths               15
evaluation/Average Returns        -73.5789
time/data storing (s)               0.00354069
time/evaluation sampling (s)        0.346541
time/exploration sampling (s)       0.155392
time/logging (s)                    0.00485535
time/saving (s)                     0.00194845
time/training (s)                   2.06345
time/epoch (s)                      2.57573
time/total (s)                    219.608
Epoch                              80
-----------------------------  ---------------
2019-04-22 22:13:40.298571 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 81 finished
-----------------------------  ---------------
replay_buffer/size              41200
trainer/QF1 Loss                   12.0744
trainer/QF2 Loss                   12.0041
trainer/Policy Loss                72.5673
trainer/Q1 Predictions Mean       -71.2435
trainer/Q1 Predictions Std         57.5039
trainer/Q1 Predictions Max        -22.2155
trainer/Q1 Predictions Min       -171.08
trainer/Q2 Predictions Mean       -71.1921
trainer/Q2 Predictions Std         57.3966
trainer/Q2 Predictions Max        -22.234
trainer/Q2 Predictions Min       -169.778
trainer/Q Targets Mean            -71.5241
trainer/Q Targets Std              57.7638
trainer/Q Targets Max              -0.543206
trainer/Q Targets Min            -170.307
trainer/Log Pis Mean                1.87269
trainer/Log Pis Std                 1.19048
trainer/Log Pis Max                 5.31162
trainer/Log Pis Min                -3.69046
trainer/Policy mu Mean             -0.0293915
trainer/Policy mu Std               0.733407
trainer/Policy mu Max               2.68985
trainer/Policy mu Min              -2.48036
trainer/Policy log std Mean        -1.98622
trainer/Policy log std Std          0.556798
trainer/Policy log std Max         -0.510826
trainer/Policy log std Min         -2.82866
trainer/Alpha                       0.0727267
trainer/Alpha Loss                 -0.333661
exploration/num steps total     41200
exploration/num paths total       412
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.24024
exploration/Rewards Std             1.20107
exploration/Rewards Max            -0.0220146
exploration/Rewards Min            -7.54557
exploration/Returns Mean         -124.024
exploration/Returns Std            91.9131
exploration/Returns Max           -33.3102
exploration/Returns Min          -247.595
exploration/Actions Mean           -0.00598081
exploration/Actions Std             0.21467
exploration/Actions Max             0.99477
exploration/Actions Min            -0.996801
exploration/Num Paths               5
exploration/Average Returns      -124.024
evaluation/num steps total     123000
evaluation/num paths total       1230
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.3753
evaluation/Rewards Std              1.42519
evaluation/Rewards Max             -0.188354
evaluation/Rewards Min            -10.2503
evaluation/Returns Mean          -137.53
evaluation/Returns Std            113.221
evaluation/Returns Max            -25.0881
evaluation/Returns Min           -299.323
evaluation/Actions Mean             0.00486197
evaluation/Actions Std              0.190918
evaluation/Actions Max              0.998057
evaluation/Actions Min             -0.996402
evaluation/Num Paths               15
evaluation/Average Returns       -137.53
time/data storing (s)               0.00359893
time/evaluation sampling (s)        0.347939
time/exploration sampling (s)       0.158115
time/logging (s)                    0.00491328
time/saving (s)                     0.00200147
time/training (s)                   2.07468
time/epoch (s)                      2.59124
time/total (s)                    222.203
Epoch                              81
-----------------------------  ---------------
2019-04-22 22:13:42.917376 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 82 finished
-----------------------------  ---------------
replay_buffer/size              41700
trainer/QF1 Loss                    8.4554
trainer/QF2 Loss                    8.45968
trainer/Policy Loss                77.6167
trainer/Q1 Predictions Mean       -76.6386
trainer/Q1 Predictions Std         58.5996
trainer/Q1 Predictions Max        -22.5694
trainer/Q1 Predictions Min       -191.754
trainer/Q2 Predictions Mean       -76.5953
trainer/Q2 Predictions Std         58.5884
trainer/Q2 Predictions Max        -22.6331
trainer/Q2 Predictions Min       -190.192
trainer/Q Targets Mean            -77.1568
trainer/Q Targets Std              59.697
trainer/Q Targets Max              -1.59774
trainer/Q Targets Min            -188.623
trainer/Log Pis Mean                1.95299
trainer/Log Pis Std                 1.35733
trainer/Log Pis Max                 6.571
trainer/Log Pis Min                -2.07894
trainer/Policy mu Mean              0.127235
trainer/Policy mu Std               0.868038
trainer/Policy mu Max               2.969
trainer/Policy mu Min              -2.7573
trainer/Policy log std Mean        -1.86052
trainer/Policy log std Std          0.534573
trainer/Policy log std Max         -0.366663
trainer/Policy log std Min         -2.85931
trainer/Alpha                       0.0756899
trainer/Alpha Loss                 -0.121345
exploration/num steps total     41700
exploration/num paths total       417
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.37106
exploration/Rewards Std             1.41458
exploration/Rewards Max            -0.0670741
exploration/Rewards Min            -9.52741
exploration/Returns Mean         -137.106
exploration/Returns Std            96.2969
exploration/Returns Max           -57.6141
exploration/Returns Min          -259.233
exploration/Actions Mean            0.00437672
exploration/Actions Std             0.243275
exploration/Actions Max             0.998175
exploration/Actions Min            -0.994572
exploration/Num Paths               5
exploration/Average Returns      -137.106
evaluation/num steps total     124500
evaluation/num paths total       1245
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.0185
evaluation/Rewards Std              1.1632
evaluation/Rewards Max             -0.171538
evaluation/Rewards Min             -9.23022
evaluation/Returns Mean          -101.85
evaluation/Returns Std             85.2663
evaluation/Returns Max            -23.9403
evaluation/Returns Min           -250.04
evaluation/Actions Mean             0.00338636
evaluation/Actions Std              0.174305
evaluation/Actions Max              0.993614
evaluation/Actions Min             -0.998429
evaluation/Num Paths               15
evaluation/Average Returns       -101.85
time/data storing (s)               0.00300933
time/evaluation sampling (s)        0.35115
time/exploration sampling (s)       0.157667
time/logging (s)                    0.00456701
time/saving (s)                     0.0107123
time/training (s)                   2.08484
time/epoch (s)                      2.61195
time/total (s)                    224.819
Epoch                              82
-----------------------------  ---------------
2019-04-22 22:13:45.516000 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 83 finished
-----------------------------  ---------------
replay_buffer/size              42200
trainer/QF1 Loss                   15.1851
trainer/QF2 Loss                   15.1454
trainer/Policy Loss                69.318
trainer/Q1 Predictions Mean       -68.238
trainer/Q1 Predictions Std         54.244
trainer/Q1 Predictions Max        -21.689
trainer/Q1 Predictions Min       -160.264
trainer/Q2 Predictions Mean       -68.2607
trainer/Q2 Predictions Std         54.2696
trainer/Q2 Predictions Max        -21.7842
trainer/Q2 Predictions Min       -160.494
trainer/Q Targets Mean            -69.403
trainer/Q Targets Std              55.5909
trainer/Q Targets Max              -1.27578
trainer/Q Targets Min            -161.912
trainer/Log Pis Mean                1.85328
trainer/Log Pis Std                 1.40977
trainer/Log Pis Max                 6.60153
trainer/Log Pis Min                -2.67772
trainer/Policy mu Mean              0.111339
trainer/Policy mu Std               0.80854
trainer/Policy mu Max               2.57381
trainer/Policy mu Min              -4.18659
trainer/Policy log std Mean        -1.95222
trainer/Policy log std Std          0.557703
trainer/Policy log std Max         -0.176035
trainer/Policy log std Min         -2.79339
trainer/Alpha                       0.0760138
trainer/Alpha Loss                 -0.378105
exploration/num steps total     42200
exploration/num paths total       422
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.571131
exploration/Rewards Std             1.05323
exploration/Rewards Max            -0.0084299
exploration/Rewards Min           -10.1187
exploration/Returns Mean          -57.1131
exploration/Returns Std            20.7131
exploration/Returns Max           -33.2984
exploration/Returns Min           -85.3408
exploration/Actions Mean            0.0117441
exploration/Actions Std             0.223475
exploration/Actions Max             0.999492
exploration/Actions Min            -0.999275
exploration/Num Paths               5
exploration/Average Returns       -57.1131
evaluation/num steps total     126000
evaluation/num paths total       1260
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.16119
evaluation/Rewards Std              1.12619
evaluation/Rewards Max             -0.280424
evaluation/Rewards Min            -10.2941
evaluation/Returns Mean          -116.119
evaluation/Returns Std             86.3898
evaluation/Returns Max            -31.5939
evaluation/Returns Min           -246.692
evaluation/Actions Mean             0.0029746
evaluation/Actions Std              0.15665
evaluation/Actions Max              0.998615
evaluation/Actions Min             -0.997687
evaluation/Num Paths               15
evaluation/Average Returns       -116.119
time/data storing (s)               0.00328458
time/evaluation sampling (s)        0.356056
time/exploration sampling (s)       0.155006
time/logging (s)                    0.00454999
time/saving (s)                     0.00197819
time/training (s)                   2.07132
time/epoch (s)                      2.5922
time/total (s)                    227.416
Epoch                              83
-----------------------------  ---------------
2019-04-22 22:13:48.100575 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 84 finished
-----------------------------  ----------------
replay_buffer/size              42700
trainer/QF1 Loss                   17.3699
trainer/QF2 Loss                   17.425
trainer/Policy Loss                70.944
trainer/Q1 Predictions Mean       -69.5066
trainer/Q1 Predictions Std         57.1954
trainer/Q1 Predictions Max        -22.1061
trainer/Q1 Predictions Min       -168.382
trainer/Q2 Predictions Mean       -69.5246
trainer/Q2 Predictions Std         57.1973
trainer/Q2 Predictions Max        -22.1714
trainer/Q2 Predictions Min       -168.167
trainer/Q Targets Mean            -69.249
trainer/Q Targets Std              58.0956
trainer/Q Targets Max              -0.504879
trainer/Q Targets Min            -170.561
trainer/Log Pis Mean                2.16209
trainer/Log Pis Std                 1.08027
trainer/Log Pis Max                 5.84885
trainer/Log Pis Min                -0.604986
trainer/Policy mu Mean              0.0715085
trainer/Policy mu Std               0.769369
trainer/Policy mu Max               2.53095
trainer/Policy mu Min              -2.45061
trainer/Policy log std Mean        -1.95035
trainer/Policy log std Std          0.544499
trainer/Policy log std Max         -0.529125
trainer/Policy log std Min         -2.88493
trainer/Alpha                       0.0796801
trainer/Alpha Loss                  0.410041
exploration/num steps total     42700
exploration/num paths total       427
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.392188
exploration/Rewards Std             0.85447
exploration/Rewards Max            -0.00859779
exploration/Rewards Min            -8.04701
exploration/Returns Mean          -39.2188
exploration/Returns Std            15.4332
exploration/Returns Max           -24.9387
exploration/Returns Min           -59.336
exploration/Actions Mean            0.000434628
exploration/Actions Std             0.221375
exploration/Actions Max             0.998667
exploration/Actions Min            -0.999191
exploration/Num Paths               5
exploration/Average Returns       -39.2188
evaluation/num steps total     127500
evaluation/num paths total       1275
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.723278
evaluation/Rewards Std              1.03024
evaluation/Rewards Max             -0.108671
evaluation/Rewards Min            -10.0003
evaluation/Returns Mean           -72.3278
evaluation/Returns Std             73.2084
evaluation/Returns Max            -13.2538
evaluation/Returns Min           -255.403
evaluation/Actions Mean             0.0111646
evaluation/Actions Std              0.159916
evaluation/Actions Max              0.997265
evaluation/Actions Min             -0.995724
evaluation/Num Paths               15
evaluation/Average Returns        -72.3278
time/data storing (s)               0.0032477
time/evaluation sampling (s)        0.345803
time/exploration sampling (s)       0.155933
time/logging (s)                    0.00502195
time/saving (s)                     0.00159702
time/training (s)                   2.0671
time/epoch (s)                      2.5787
time/total (s)                    229.999
Epoch                              84
-----------------------------  ----------------
2019-04-22 22:13:50.694098 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 85 finished
-----------------------------  ----------------
replay_buffer/size              43200
trainer/QF1 Loss                  178.707
trainer/QF2 Loss                  178.734
trainer/Policy Loss                70.2836
trainer/Q1 Predictions Mean       -69.0069
trainer/Q1 Predictions Std         55.3915
trainer/Q1 Predictions Max        -21.3581
trainer/Q1 Predictions Min       -165.745
trainer/Q2 Predictions Mean       -69.0314
trainer/Q2 Predictions Std         55.4315
trainer/Q2 Predictions Max        -21.3611
trainer/Q2 Predictions Min       -166.353
trainer/Q Targets Mean            -68.4194
trainer/Q Targets Std              56.4359
trainer/Q Targets Max              -0.986062
trainer/Q Targets Min            -169.02
trainer/Log Pis Mean                1.77627
trainer/Log Pis Std                 1.21538
trainer/Log Pis Max                 7.20438
trainer/Log Pis Min                -1.4405
trainer/Policy mu Mean              0.070672
trainer/Policy mu Std               0.657068
trainer/Policy mu Max               2.62679
trainer/Policy mu Min              -2.42115
trainer/Policy log std Mean        -1.97055
trainer/Policy log std Std          0.512711
trainer/Policy log std Max         -0.524979
trainer/Policy log std Min         -2.84955
trainer/Alpha                       0.0788185
trainer/Alpha Loss                 -0.568376
exploration/num steps total     43200
exploration/num paths total       432
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.951197
exploration/Rewards Std             1.10104
exploration/Rewards Max            -0.0139105
exploration/Rewards Min            -8.99123
exploration/Returns Mean          -95.1197
exploration/Returns Std            64.168
exploration/Returns Max           -30.9648
exploration/Returns Min          -217.98
exploration/Actions Mean            0.000612812
exploration/Actions Std             0.215117
exploration/Actions Max             0.992533
exploration/Actions Min            -0.999355
exploration/Num Paths               5
exploration/Average Returns       -95.1197
evaluation/num steps total     129000
evaluation/num paths total       1290
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.62657
evaluation/Rewards Std              1.02428
evaluation/Rewards Max             -0.175754
evaluation/Rewards Min             -8.22197
evaluation/Returns Mean          -162.657
evaluation/Returns Std             78.4606
evaluation/Returns Max            -20.2489
evaluation/Returns Min           -239.964
evaluation/Actions Mean             0.0025592
evaluation/Actions Std              0.157805
evaluation/Actions Max              0.993934
evaluation/Actions Min             -0.996699
evaluation/Num Paths               15
evaluation/Average Returns       -162.657
time/data storing (s)               0.00322433
time/evaluation sampling (s)        0.347054
time/exploration sampling (s)       0.156593
time/logging (s)                    0.00480179
time/saving (s)                     0.00183059
time/training (s)                   2.07333
time/epoch (s)                      2.58683
time/total (s)                    232.591
Epoch                              85
-----------------------------  ----------------
2019-04-22 22:13:53.284822 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 86 finished
-----------------------------  ---------------
replay_buffer/size              43700
trainer/QF1 Loss                   12.0869
trainer/QF2 Loss                   11.8514
trainer/Policy Loss                61.5394
trainer/Q1 Predictions Mean       -60.3315
trainer/Q1 Predictions Std         50.3089
trainer/Q1 Predictions Max        -21.228
trainer/Q1 Predictions Min       -155.04
trainer/Q2 Predictions Mean       -60.3952
trainer/Q2 Predictions Std         50.3067
trainer/Q2 Predictions Max        -21.2781
trainer/Q2 Predictions Min       -155.025
trainer/Q Targets Mean            -60.7714
trainer/Q Targets Std              51.364
trainer/Q Targets Max              -0.606686
trainer/Q Targets Min            -156.78
trainer/Log Pis Mean                2.02979
trainer/Log Pis Std                 1.38825
trainer/Log Pis Max                 6.84091
trainer/Log Pis Min                -2.60468
trainer/Policy mu Mean              0.0177741
trainer/Policy mu Std               0.846595
trainer/Policy mu Max               2.47838
trainer/Policy mu Min              -2.95374
trainer/Policy log std Mean        -1.92214
trainer/Policy log std Std          0.585971
trainer/Policy log std Max         -0.452716
trainer/Policy log std Min         -2.86552
trainer/Alpha                       0.0774239
trainer/Alpha Loss                  0.076206
exploration/num steps total     43700
exploration/num paths total       437
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.56191
exploration/Rewards Std             1.16534
exploration/Rewards Max            -0.0191003
exploration/Rewards Min            -9.68982
exploration/Returns Mean         -156.191
exploration/Returns Std            83.0494
exploration/Returns Max           -48.7501
exploration/Returns Min          -244.288
exploration/Actions Mean            0.00751587
exploration/Actions Std             0.231155
exploration/Actions Max             0.999158
exploration/Actions Min            -0.999491
exploration/Num Paths               5
exploration/Average Returns      -156.191
evaluation/num steps total     130500
evaluation/num paths total       1305
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.96551
evaluation/Rewards Std              1.25478
evaluation/Rewards Max             -0.146823
evaluation/Rewards Min            -10.4924
evaluation/Returns Mean           -96.551
evaluation/Returns Std             79.6167
evaluation/Returns Max            -17.4688
evaluation/Returns Min           -239.603
evaluation/Actions Mean            -0.00895008
evaluation/Actions Std              0.189141
evaluation/Actions Max              0.998389
evaluation/Actions Min             -0.999473
evaluation/Num Paths               15
evaluation/Average Returns        -96.551
time/data storing (s)               0.00394069
time/evaluation sampling (s)        0.344383
time/exploration sampling (s)       0.155827
time/logging (s)                    0.00437734
time/saving (s)                     0.00193825
time/training (s)                   2.07339
time/epoch (s)                      2.58385
time/total (s)                    235.179
Epoch                              86
-----------------------------  ---------------
2019-04-22 22:13:55.873820 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 87 finished
-----------------------------  ---------------
replay_buffer/size              44200
trainer/QF1 Loss                  175.862
trainer/QF2 Loss                  177.177
trainer/Policy Loss                67.3952
trainer/Q1 Predictions Mean       -66.2808
trainer/Q1 Predictions Std         54.6869
trainer/Q1 Predictions Max        -21.3811
trainer/Q1 Predictions Min       -163.656
trainer/Q2 Predictions Mean       -66.2545
trainer/Q2 Predictions Std         54.6824
trainer/Q2 Predictions Max        -21.4349
trainer/Q2 Predictions Min       -164.111
trainer/Q Targets Mean            -64.8866
trainer/Q Targets Std              55.0234
trainer/Q Targets Max              -0.367308
trainer/Q Targets Min            -166.321
trainer/Log Pis Mean                1.86736
trainer/Log Pis Std                 1.30425
trainer/Log Pis Max                 6.29985
trainer/Log Pis Min                -3.54642
trainer/Policy mu Mean              0.0261372
trainer/Policy mu Std               0.683208
trainer/Policy mu Max               2.47354
trainer/Policy mu Min              -2.26079
trainer/Policy log std Mean        -2.00267
trainer/Policy log std Std          0.497294
trainer/Policy log std Max         -0.544131
trainer/Policy log std Min         -2.84139
trainer/Alpha                       0.0767893
trainer/Alpha Loss                 -0.340455
exploration/num steps total     44200
exploration/num paths total       442
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.12708
exploration/Rewards Std             0.991308
exploration/Rewards Max            -0.0302609
exploration/Rewards Min            -6.26484
exploration/Returns Mean         -112.708
exploration/Returns Std            85.8426
exploration/Returns Max           -39.1717
exploration/Returns Min          -224.815
exploration/Actions Mean            0.001267
exploration/Actions Std             0.186443
exploration/Actions Max             0.994015
exploration/Actions Min            -0.997965
exploration/Num Paths               5
exploration/Average Returns      -112.708
evaluation/num steps total     132000
evaluation/num paths total       1320
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.39007
evaluation/Rewards Std              1.22033
evaluation/Rewards Max             -0.156178
evaluation/Rewards Min             -9.66426
evaluation/Returns Mean          -139.007
evaluation/Returns Std             88.2428
evaluation/Returns Max            -20.3339
evaluation/Returns Min           -240.579
evaluation/Actions Mean             0.00786242
evaluation/Actions Std              0.181785
evaluation/Actions Max              0.996146
evaluation/Actions Min             -0.997197
evaluation/Num Paths               15
evaluation/Average Returns       -139.007
time/data storing (s)               0.00311169
time/evaluation sampling (s)        0.344264
time/exploration sampling (s)       0.155284
time/logging (s)                    0.00491681
time/saving (s)                     0.0020217
time/training (s)                   2.07387
time/epoch (s)                      2.58347
time/total (s)                    237.767
Epoch                              87
-----------------------------  ---------------
2019-04-22 22:13:58.460587 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 88 finished
-----------------------------  ---------------
replay_buffer/size              44700
trainer/QF1 Loss                   10.7633
trainer/QF2 Loss                   11.2036
trainer/Policy Loss                61.7491
trainer/Q1 Predictions Mean       -60.6047
trainer/Q1 Predictions Std         53.2022
trainer/Q1 Predictions Max        -21.0286
trainer/Q1 Predictions Min       -160.31
trainer/Q2 Predictions Mean       -60.6061
trainer/Q2 Predictions Std         53.1119
trainer/Q2 Predictions Max        -21.0863
trainer/Q2 Predictions Min       -159.705
trainer/Q Targets Mean            -60.6722
trainer/Q Targets Std              53.9031
trainer/Q Targets Max              -0.609796
trainer/Q Targets Min            -159.93
trainer/Log Pis Mean                2.06548
trainer/Log Pis Std                 1.39492
trainer/Log Pis Max                 6.55253
trainer/Log Pis Min                -2.73507
trainer/Policy mu Mean              0.185884
trainer/Policy mu Std               0.836052
trainer/Policy mu Max               2.96466
trainer/Policy mu Min              -2.44772
trainer/Policy log std Mean        -1.92094
trainer/Policy log std Std          0.576614
trainer/Policy log std Max         -0.314675
trainer/Policy log std Min         -2.786
trainer/Alpha                       0.0794173
trainer/Alpha Loss                  0.165882
exploration/num steps total     44700
exploration/num paths total       447
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.88655
exploration/Rewards Std             1.02195
exploration/Rewards Max            -0.117047
exploration/Rewards Min            -9.86126
exploration/Returns Mean         -188.655
exploration/Returns Std            74.2588
exploration/Returns Max           -43.1839
exploration/Returns Min          -242.902
exploration/Actions Mean            0.00402182
exploration/Actions Std             0.184435
exploration/Actions Max             0.999742
exploration/Actions Min            -0.979001
exploration/Num Paths               5
exploration/Average Returns      -188.655
evaluation/num steps total     133500
evaluation/num paths total       1335
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.20292
evaluation/Rewards Std              1.18962
evaluation/Rewards Max             -0.106468
evaluation/Rewards Min            -10.4128
evaluation/Returns Mean          -120.292
evaluation/Returns Std             79.4151
evaluation/Returns Max            -16.3926
evaluation/Returns Min           -220.709
evaluation/Actions Mean             0.0237137
evaluation/Actions Std              0.180258
evaluation/Actions Max              0.99768
evaluation/Actions Min             -0.997288
evaluation/Num Paths               15
evaluation/Average Returns       -120.292
time/data storing (s)               0.00353669
time/evaluation sampling (s)        0.341903
time/exploration sampling (s)       0.156685
time/logging (s)                    0.00479325
time/saving (s)                     0.00192914
time/training (s)                   2.07123
time/epoch (s)                      2.58007
time/total (s)                    240.352
Epoch                              88
-----------------------------  ---------------
2019-04-22 22:14:01.053216 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 89 finished
-----------------------------  ---------------
replay_buffer/size              45200
trainer/QF1 Loss                   12.9684
trainer/QF2 Loss                   12.9379
trainer/Policy Loss                68.4305
trainer/Q1 Predictions Mean       -67.3401
trainer/Q1 Predictions Std         54.9609
trainer/Q1 Predictions Max        -20.5423
trainer/Q1 Predictions Min       -160.341
trainer/Q2 Predictions Mean       -67.3375
trainer/Q2 Predictions Std         54.9831
trainer/Q2 Predictions Max        -20.5015
trainer/Q2 Predictions Min       -160.813
trainer/Q Targets Mean            -67.7134
trainer/Q Targets Std              56.1695
trainer/Q Targets Max              -0.387937
trainer/Q Targets Min            -162.453
trainer/Log Pis Mean                2.09822
trainer/Log Pis Std                 1.37697
trainer/Log Pis Max                 6.41828
trainer/Log Pis Min                -1.82769
trainer/Policy mu Mean              0.13631
trainer/Policy mu Std               0.854405
trainer/Policy mu Max               2.64738
trainer/Policy mu Min              -2.73617
trainer/Policy log std Mean        -1.8843
trainer/Policy log std Std          0.554414
trainer/Policy log std Max         -0.416567
trainer/Policy log std Min         -2.7277
trainer/Alpha                       0.0781731
trainer/Alpha Loss                  0.250333
exploration/num steps total     45200
exploration/num paths total       452
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.80355
exploration/Rewards Std             1.03599
exploration/Rewards Max            -0.0295486
exploration/Rewards Min            -9.01289
exploration/Returns Mean          -80.355
exploration/Returns Std            66.0146
exploration/Returns Max           -30.9108
exploration/Returns Min          -210.883
exploration/Actions Mean           -0.00279626
exploration/Actions Std             0.207285
exploration/Actions Max             0.999642
exploration/Actions Min            -0.999796
exploration/Num Paths               5
exploration/Average Returns       -80.355
evaluation/num steps total     135000
evaluation/num paths total       1350
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.34036
evaluation/Rewards Std              1.18685
evaluation/Rewards Max             -0.218419
evaluation/Rewards Min            -11.6096
evaluation/Returns Mean          -134.036
evaluation/Returns Std             76.8296
evaluation/Returns Max            -23.8825
evaluation/Returns Min           -220.619
evaluation/Actions Mean             0.00897416
evaluation/Actions Std              0.184673
evaluation/Actions Max              0.998792
evaluation/Actions Min             -0.996315
evaluation/Num Paths               15
evaluation/Average Returns       -134.036
time/data storing (s)               0.00301314
time/evaluation sampling (s)        0.344778
time/exploration sampling (s)       0.157129
time/logging (s)                    0.00503749
time/saving (s)                     0.00206487
time/training (s)                   2.07424
time/epoch (s)                      2.58627
time/total (s)                    242.943
Epoch                              89
-----------------------------  ---------------
2019-04-22 22:14:03.642187 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 90 finished
-----------------------------  ---------------
replay_buffer/size              45700
trainer/QF1 Loss                   21.0561
trainer/QF2 Loss                   20.7779
trainer/Policy Loss                53.6957
trainer/Q1 Predictions Mean       -52.271
trainer/Q1 Predictions Std         44.6802
trainer/Q1 Predictions Max        -20.4717
trainer/Q1 Predictions Min       -150.405
trainer/Q2 Predictions Mean       -52.1838
trainer/Q2 Predictions Std         44.6634
trainer/Q2 Predictions Max        -20.4912
trainer/Q2 Predictions Min       -150.508
trainer/Q Targets Mean            -52.0987
trainer/Q Targets Std              45.8454
trainer/Q Targets Max              -0.403716
trainer/Q Targets Min            -151.681
trainer/Log Pis Mean                2.07244
trainer/Log Pis Std                 1.33736
trainer/Log Pis Max                 6.1039
trainer/Log Pis Min                -3.06525
trainer/Policy mu Mean              0.111106
trainer/Policy mu Std               0.717667
trainer/Policy mu Max               3.1721
trainer/Policy mu Min              -2.61157
trainer/Policy log std Mean        -2.04624
trainer/Policy log std Std          0.529015
trainer/Policy log std Max         -0.224581
trainer/Policy log std Min         -2.82804
trainer/Alpha                       0.0736659
trainer/Alpha Loss                  0.188937
exploration/num steps total     45700
exploration/num paths total       457
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -2.07513
exploration/Rewards Std             1.0258
exploration/Rewards Max            -0.0405887
exploration/Rewards Min            -6.92568
exploration/Returns Mean         -207.513
exploration/Returns Std            92.8744
exploration/Returns Max           -25.8746
exploration/Returns Min          -268.469
exploration/Actions Mean           -0.0156174
exploration/Actions Std             0.190279
exploration/Actions Max             0.959181
exploration/Actions Min            -0.994648
exploration/Num Paths               5
exploration/Average Returns      -207.513
evaluation/num steps total     136500
evaluation/num paths total       1365
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.40028
evaluation/Rewards Std              1.23329
evaluation/Rewards Max             -0.166331
evaluation/Rewards Min            -10.2248
evaluation/Returns Mean          -140.028
evaluation/Returns Std             99.4137
evaluation/Returns Max            -29.3884
evaluation/Returns Min           -263.002
evaluation/Actions Mean             0.00534638
evaluation/Actions Std              0.172123
evaluation/Actions Max              0.998812
evaluation/Actions Min             -0.992434
evaluation/Num Paths               15
evaluation/Average Returns       -140.028
time/data storing (s)               0.00351817
time/evaluation sampling (s)        0.346726
time/exploration sampling (s)       0.161147
time/logging (s)                    0.00477915
time/saving (s)                     0.00206758
time/training (s)                   2.06394
time/epoch (s)                      2.58218
time/total (s)                    245.53
Epoch                              90
-----------------------------  ---------------
2019-04-22 22:14:06.230460 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 91 finished
-----------------------------  ---------------
replay_buffer/size              46200
trainer/QF1 Loss                   10.6073
trainer/QF2 Loss                   10.4459
trainer/Policy Loss                70.4958
trainer/Q1 Predictions Mean       -69.0397
trainer/Q1 Predictions Std         54.7104
trainer/Q1 Predictions Max        -20.1364
trainer/Q1 Predictions Min       -155.64
trainer/Q2 Predictions Mean       -69.0923
trainer/Q2 Predictions Std         54.7223
trainer/Q2 Predictions Max        -20.1709
trainer/Q2 Predictions Min       -155.431
trainer/Q Targets Mean            -69.52
trainer/Q Targets Std              55.4269
trainer/Q Targets Max              -0.402147
trainer/Q Targets Min            -155.051
trainer/Log Pis Mean                2.0332
trainer/Log Pis Std                 1.34471
trainer/Log Pis Max                 7.19001
trainer/Log Pis Min                -3.59249
trainer/Policy mu Mean              0.0594281
trainer/Policy mu Std               0.710955
trainer/Policy mu Max               2.37054
trainer/Policy mu Min              -3.48587
trainer/Policy log std Mean        -2.03223
trainer/Policy log std Std          0.518856
trainer/Policy log std Max         -0.315223
trainer/Policy log std Min         -2.85934
trainer/Alpha                       0.0734974
trainer/Alpha Loss                  0.0866826
exploration/num steps total     46200
exploration/num paths total       462
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.956479
exploration/Rewards Std             1.36082
exploration/Rewards Max            -0.0318781
exploration/Rewards Min            -9.80771
exploration/Returns Mean          -95.6479
exploration/Returns Std            79.8274
exploration/Returns Max           -28.4343
exploration/Returns Min          -250.549
exploration/Actions Mean           -0.0134964
exploration/Actions Std             0.225338
exploration/Actions Max             0.999374
exploration/Actions Min            -0.999029
exploration/Num Paths               5
exploration/Average Returns       -95.6479
evaluation/num steps total     138000
evaluation/num paths total       1380
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.05427
evaluation/Rewards Std              1.09838
evaluation/Rewards Max             -0.199091
evaluation/Rewards Min             -7.80315
evaluation/Returns Mean          -105.427
evaluation/Returns Std             84.2333
evaluation/Returns Max            -31.7278
evaluation/Returns Min           -237.044
evaluation/Actions Mean            -0.0111303
evaluation/Actions Std              0.169844
evaluation/Actions Max              0.992116
evaluation/Actions Min             -0.99729
evaluation/Num Paths               15
evaluation/Average Returns       -105.427
time/data storing (s)               0.00317446
time/evaluation sampling (s)        0.345478
time/exploration sampling (s)       0.155319
time/logging (s)                    0.00439106
time/saving (s)                     0.00196107
time/training (s)                   2.07118
time/epoch (s)                      2.58151
time/total (s)                    248.116
Epoch                              91
-----------------------------  ---------------
2019-04-22 22:14:08.814576 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 92 finished
-----------------------------  ---------------
replay_buffer/size              46700
trainer/QF1 Loss                    0.259776
trainer/QF2 Loss                    0.290754
trainer/Policy Loss                74.0828
trainer/Q1 Predictions Mean       -72.5015
trainer/Q1 Predictions Std         55.475
trainer/Q1 Predictions Max        -20.2776
trainer/Q1 Predictions Min       -182.234
trainer/Q2 Predictions Mean       -72.5571
trainer/Q2 Predictions Std         55.5172
trainer/Q2 Predictions Max        -20.3236
trainer/Q2 Predictions Min       -183.209
trainer/Q Targets Mean            -72.5006
trainer/Q Targets Std              55.56
trainer/Q Targets Max             -19.9989
trainer/Q Targets Min            -183.807
trainer/Log Pis Mean                2.07548
trainer/Log Pis Std                 1.44358
trainer/Log Pis Max                 5.82484
trainer/Log Pis Min                -3.25447
trainer/Policy mu Mean              0.111596
trainer/Policy mu Std               0.979287
trainer/Policy mu Max               2.87395
trainer/Policy mu Min              -3.69147
trainer/Policy log std Mean        -1.87461
trainer/Policy log std Std          0.59995
trainer/Policy log std Max         -0.187484
trainer/Policy log std Min         -2.82974
trainer/Alpha                       0.074002
trainer/Alpha Loss                  0.196517
exploration/num steps total     46700
exploration/num paths total       467
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.25332
exploration/Rewards Std             1.26791
exploration/Rewards Max            -0.0256314
exploration/Rewards Min            -9.03235
exploration/Returns Mean         -125.332
exploration/Returns Std            77.9002
exploration/Returns Max           -44.2923
exploration/Returns Min          -228.901
exploration/Actions Mean           -0.00119189
exploration/Actions Std             0.247774
exploration/Actions Max             0.998026
exploration/Actions Min            -0.999463
exploration/Num Paths               5
exploration/Average Returns      -125.332
evaluation/num steps total     139500
evaluation/num paths total       1395
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.18089
evaluation/Rewards Std              1.13742
evaluation/Rewards Max             -0.222601
evaluation/Rewards Min             -9.1399
evaluation/Returns Mean          -118.089
evaluation/Returns Std             79.2883
evaluation/Returns Max            -26.2163
evaluation/Returns Min           -235.293
evaluation/Actions Mean             0.0124776
evaluation/Actions Std              0.173092
evaluation/Actions Max              0.995395
evaluation/Actions Min             -0.998475
evaluation/Num Paths               15
evaluation/Average Returns       -118.089
time/data storing (s)               0.00308511
time/evaluation sampling (s)        0.341884
time/exploration sampling (s)       0.156732
time/logging (s)                    0.00475331
time/saving (s)                     0.00182247
time/training (s)                   2.06974
time/epoch (s)                      2.57802
time/total (s)                    250.699
Epoch                              92
-----------------------------  ---------------
2019-04-22 22:14:11.419290 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 93 finished
-----------------------------  ---------------
replay_buffer/size              47200
trainer/QF1 Loss                  169.853
trainer/QF2 Loss                  170.05
trainer/Policy Loss                72.3036
trainer/Q1 Predictions Mean       -71.121
trainer/Q1 Predictions Std         54.0001
trainer/Q1 Predictions Max        -19.4748
trainer/Q1 Predictions Min       -146.592
trainer/Q2 Predictions Mean       -71.1097
trainer/Q2 Predictions Std         54.0332
trainer/Q2 Predictions Max        -19.4564
trainer/Q2 Predictions Min       -146.428
trainer/Q Targets Mean            -70.9511
trainer/Q Targets Std              55.8074
trainer/Q Targets Max              -0.403716
trainer/Q Targets Min            -148.93
trainer/Log Pis Mean                1.8749
trainer/Log Pis Std                 1.12038
trainer/Log Pis Max                 7.28585
trainer/Log Pis Min                -0.82697
trainer/Policy mu Mean              0.0855741
trainer/Policy mu Std               0.688837
trainer/Policy mu Max               3.22375
trainer/Policy mu Min              -2.31083
trainer/Policy log std Mean        -1.98664
trainer/Policy log std Std          0.488359
trainer/Policy log std Max         -0.45349
trainer/Policy log std Min         -2.78462
trainer/Alpha                       0.0728876
trainer/Alpha Loss                 -0.327599
exploration/num steps total     47200
exploration/num paths total       472
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.62958
exploration/Rewards Std             1.13208
exploration/Rewards Max            -0.275211
exploration/Rewards Min            -8.99997
exploration/Returns Mean         -162.958
exploration/Returns Std            84.4722
exploration/Returns Max           -49.1322
exploration/Returns Min          -240.003
exploration/Actions Mean            0.0245382
exploration/Actions Std             0.227216
exploration/Actions Max             0.998009
exploration/Actions Min            -0.987337
exploration/Num Paths               5
exploration/Average Returns      -162.958
evaluation/num steps total     141000
evaluation/num paths total       1410
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.31713
evaluation/Rewards Std              1.30801
evaluation/Rewards Max             -0.146629
evaluation/Rewards Min            -10.3422
evaluation/Returns Mean          -131.713
evaluation/Returns Std             95.3436
evaluation/Returns Max            -17.3828
evaluation/Returns Min           -248.458
evaluation/Actions Mean             0.0241709
evaluation/Actions Std              0.178295
evaluation/Actions Max              0.998607
evaluation/Actions Min             -0.994851
evaluation/Num Paths               15
evaluation/Average Returns       -131.713
time/data storing (s)               0.00308018
time/evaluation sampling (s)        0.346729
time/exploration sampling (s)       0.156943
time/logging (s)                    0.00499088
time/saving (s)                     0.0019571
time/training (s)                   2.08406
time/epoch (s)                      2.59776
time/total (s)                    253.301
Epoch                              93
-----------------------------  ---------------
2019-04-22 22:14:14.043202 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 94 finished
-----------------------------  ---------------
replay_buffer/size              47700
trainer/QF1 Loss                  200.95
trainer/QF2 Loss                  200.017
trainer/Policy Loss                68.9629
trainer/Q1 Predictions Mean       -67.838
trainer/Q1 Predictions Std         54.0208
trainer/Q1 Predictions Max        -19.3761
trainer/Q1 Predictions Min       -165.343
trainer/Q2 Predictions Mean       -67.8245
trainer/Q2 Predictions Std         54.0104
trainer/Q2 Predictions Max        -19.3508
trainer/Q2 Predictions Min       -165.416
trainer/Q Targets Mean            -67.0391
trainer/Q Targets Std              54.1105
trainer/Q Targets Max              -2.20506
trainer/Q Targets Min            -169.333
trainer/Log Pis Mean                1.8434
trainer/Log Pis Std                 1.35468
trainer/Log Pis Max                 5.27165
trainer/Log Pis Min                -2.75536
trainer/Policy mu Mean              0.0355084
trainer/Policy mu Std               0.647236
trainer/Policy mu Max               2.47151
trainer/Policy mu Min              -2.82147
trainer/Policy log std Mean        -2.05832
trainer/Policy log std Std          0.47656
trainer/Policy log std Max         -0.577433
trainer/Policy log std Min         -2.93111
trainer/Alpha                       0.0744771
trainer/Alpha Loss                 -0.406711
exploration/num steps total     47700
exploration/num paths total       477
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.20402
exploration/Rewards Std             1.15315
exploration/Rewards Max            -0.0777574
exploration/Rewards Min            -8.92044
exploration/Returns Mean         -120.402
exploration/Returns Std            81.0448
exploration/Returns Max           -35.7788
exploration/Returns Min          -220.694
exploration/Actions Mean            0.0109125
exploration/Actions Std             0.229436
exploration/Actions Max             0.998656
exploration/Actions Min            -0.999159
exploration/Num Paths               5
exploration/Average Returns      -120.402
evaluation/num steps total     142500
evaluation/num paths total       1425
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.21351
evaluation/Rewards Std              1.13598
evaluation/Rewards Max             -0.106682
evaluation/Rewards Min             -9.82705
evaluation/Returns Mean          -121.351
evaluation/Returns Std             87.9417
evaluation/Returns Max            -15.9722
evaluation/Returns Min           -226.315
evaluation/Actions Mean             0.0173536
evaluation/Actions Std              0.172749
evaluation/Actions Max              0.996915
evaluation/Actions Min             -0.994309
evaluation/Num Paths               15
evaluation/Average Returns       -121.351
time/data storing (s)               0.00309505
time/evaluation sampling (s)        0.372901
time/exploration sampling (s)       0.157313
time/logging (s)                    0.00487814
time/saving (s)                     0.0019988
time/training (s)                   2.07703
time/epoch (s)                      2.61722
time/total (s)                    255.923
Epoch                              94
-----------------------------  ---------------
2019-04-22 22:14:16.646771 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 95 finished
-----------------------------  ---------------
replay_buffer/size              48200
trainer/QF1 Loss                    1.8664
trainer/QF2 Loss                    1.81016
trainer/Policy Loss                80.9304
trainer/Q1 Predictions Mean       -79.746
trainer/Q1 Predictions Std         54.4576
trainer/Q1 Predictions Max        -19.4076
trainer/Q1 Predictions Min       -162.959
trainer/Q2 Predictions Mean       -79.7615
trainer/Q2 Predictions Std         54.4896
trainer/Q2 Predictions Max        -19.314
trainer/Q2 Predictions Min       -163.271
trainer/Q Targets Mean            -80.7879
trainer/Q Targets Std              55.0528
trainer/Q Targets Max             -19.5901
trainer/Q Targets Min            -165.521
trainer/Log Pis Mean                1.94605
trainer/Log Pis Std                 1.61163
trainer/Log Pis Max                11.3415
trainer/Log Pis Min                -3.14033
trainer/Policy mu Mean             -0.0576741
trainer/Policy mu Std               0.917655
trainer/Policy mu Max               2.55652
trainer/Policy mu Min              -4.25335
trainer/Policy log std Mean        -1.80399
trainer/Policy log std Std          0.584988
trainer/Policy log std Max         -0.0843449
trainer/Policy log std Min         -2.72469
trainer/Alpha                       0.0717376
trainer/Alpha Loss                 -0.142137
exploration/num steps total     48200
exploration/num paths total       482
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.51128
exploration/Rewards Std             1.09663
exploration/Rewards Max            -0.0143259
exploration/Rewards Min            -5.83338
exploration/Returns Mean         -151.128
exploration/Returns Std           100.67
exploration/Returns Max           -21.1043
exploration/Returns Min          -244.113
exploration/Actions Mean           -0.0127906
exploration/Actions Std             0.224186
exploration/Actions Max             0.9871
exploration/Actions Min            -0.999429
exploration/Num Paths               5
exploration/Average Returns      -151.128
evaluation/num steps total     144000
evaluation/num paths total       1440
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.2609
evaluation/Rewards Std              1.28554
evaluation/Rewards Max             -0.0928806
evaluation/Rewards Min             -9.70549
evaluation/Returns Mean          -126.09
evaluation/Returns Std             99.0885
evaluation/Returns Max            -17.0078
evaluation/Returns Min           -270.73
evaluation/Actions Mean            -0.00394613
evaluation/Actions Std              0.171524
evaluation/Actions Max              0.996922
evaluation/Actions Min             -0.99952
evaluation/Num Paths               15
evaluation/Average Returns       -126.09
time/data storing (s)               0.00430216
time/evaluation sampling (s)        0.350362
time/exploration sampling (s)       0.160255
time/logging (s)                    0.00506566
time/saving (s)                     0.00193117
time/training (s)                   2.07531
time/epoch (s)                      2.59723
time/total (s)                    258.524
Epoch                              95
-----------------------------  ---------------
2019-04-22 22:14:19.226866 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 96 finished
-----------------------------  ---------------
replay_buffer/size              48700
trainer/QF1 Loss                    1.96382
trainer/QF2 Loss                    2.02067
trainer/Policy Loss                66.7972
trainer/Q1 Predictions Mean       -65.273
trainer/Q1 Predictions Std         52.7884
trainer/Q1 Predictions Max        -19.1975
trainer/Q1 Predictions Min       -168.314
trainer/Q2 Predictions Mean       -65.2588
trainer/Q2 Predictions Std         52.7387
trainer/Q2 Predictions Max        -19.3512
trainer/Q2 Predictions Min       -167.938
trainer/Q Targets Mean            -66.17
trainer/Q Targets Std              53.6327
trainer/Q Targets Max             -19.2767
trainer/Q Targets Min            -173.524
trainer/Log Pis Mean                2.17178
trainer/Log Pis Std                 1.36908
trainer/Log Pis Max                 6.46651
trainer/Log Pis Min                -2.01922
trainer/Policy mu Mean              0.122942
trainer/Policy mu Std               0.770125
trainer/Policy mu Max               2.56788
trainer/Policy mu Min              -2.74912
trainer/Policy log std Mean        -2.06075
trainer/Policy log std Std          0.576921
trainer/Policy log std Max         -0.419224
trainer/Policy log std Min         -2.89817
trainer/Alpha                       0.0723202
trainer/Alpha Loss                  0.451229
exploration/num steps total     48700
exploration/num paths total       487
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.831703
exploration/Rewards Std             1.32252
exploration/Rewards Max            -0.0566386
exploration/Rewards Min           -10.4993
exploration/Returns Mean          -83.1703
exploration/Returns Std            75.178
exploration/Returns Max           -25.8484
exploration/Returns Min          -228.863
exploration/Actions Mean           -0.0171607
exploration/Actions Std             0.222802
exploration/Actions Max             0.997083
exploration/Actions Min            -0.997255
exploration/Num Paths               5
exploration/Average Returns       -83.1703
evaluation/num steps total     145500
evaluation/num paths total       1455
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.32173
evaluation/Rewards Std              1.28948
evaluation/Rewards Max             -0.15566
evaluation/Rewards Min            -10.4084
evaluation/Returns Mean          -132.173
evaluation/Returns Std             98.083
evaluation/Returns Max            -17.8466
evaluation/Returns Min           -251.431
evaluation/Actions Mean            -0.00827997
evaluation/Actions Std              0.183156
evaluation/Actions Max              0.996878
evaluation/Actions Min             -0.99876
evaluation/Num Paths               15
evaluation/Average Returns       -132.173
time/data storing (s)               0.00314845
time/evaluation sampling (s)        0.345479
time/exploration sampling (s)       0.15481
time/logging (s)                    0.00479975
time/saving (s)                     0.00194444
time/training (s)                   2.06317
time/epoch (s)                      2.57335
time/total (s)                    261.102
Epoch                              96
-----------------------------  ---------------
2019-04-22 22:14:21.835265 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 97 finished
-----------------------------  ---------------
replay_buffer/size              49200
trainer/QF1 Loss                    1.1983
trainer/QF2 Loss                    1.26743
trainer/Policy Loss                61.1238
trainer/Q1 Predictions Mean       -59.6737
trainer/Q1 Predictions Std         51.2714
trainer/Q1 Predictions Max        -19.0502
trainer/Q1 Predictions Min       -166.37
trainer/Q2 Predictions Mean       -59.6818
trainer/Q2 Predictions Std         51.2654
trainer/Q2 Predictions Max        -19.1176
trainer/Q2 Predictions Min       -166.502
trainer/Q Targets Mean            -60.3714
trainer/Q Targets Std              51.9296
trainer/Q Targets Max             -19.1212
trainer/Q Targets Min            -169.189
trainer/Log Pis Mean                2.08081
trainer/Log Pis Std                 1.44553
trainer/Log Pis Max                 6.09503
trainer/Log Pis Min                -1.82586
trainer/Policy mu Mean              0.0941585
trainer/Policy mu Std               0.824516
trainer/Policy mu Max               2.91536
trainer/Policy mu Min              -2.91733
trainer/Policy log std Mean        -1.94998
trainer/Policy log std Std          0.599468
trainer/Policy log std Max         -0.281878
trainer/Policy log std Min         -2.92003
trainer/Alpha                       0.0711904
trainer/Alpha Loss                  0.213538
exploration/num steps total     49200
exploration/num paths total       492
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.14191
exploration/Rewards Std             1.11155
exploration/Rewards Max            -0.011915
exploration/Rewards Min            -9.6232
exploration/Returns Mean         -114.191
exploration/Returns Std            71.6284
exploration/Returns Max           -53.8514
exploration/Returns Min          -218.536
exploration/Actions Mean           -0.00202053
exploration/Actions Std             0.235606
exploration/Actions Max             0.999621
exploration/Actions Min            -0.995901
exploration/Num Paths               5
exploration/Average Returns      -114.191
evaluation/num steps total     147000
evaluation/num paths total       1470
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.970707
evaluation/Rewards Std              1.2168
evaluation/Rewards Max             -0.123573
evaluation/Rewards Min             -9.96836
evaluation/Returns Mean           -97.0707
evaluation/Returns Std             81.9803
evaluation/Returns Max            -15.6842
evaluation/Returns Min           -230.872
evaluation/Actions Mean            -0.00916725
evaluation/Actions Std              0.181939
evaluation/Actions Max              0.997603
evaluation/Actions Min             -0.998188
evaluation/Num Paths               15
evaluation/Average Returns        -97.0707
time/data storing (s)               0.00315078
time/evaluation sampling (s)        0.349712
time/exploration sampling (s)       0.159761
time/logging (s)                    0.00426238
time/saving (s)                     0.00197362
time/training (s)                   2.083
time/epoch (s)                      2.60186
time/total (s)                    263.708
Epoch                              97
-----------------------------  ---------------
2019-04-22 22:14:24.436939 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 98 finished
-----------------------------  ---------------
replay_buffer/size              49700
trainer/QF1 Loss                  163.13
trainer/QF2 Loss                  163.778
trainer/Policy Loss                70.4801
trainer/Q1 Predictions Mean       -69.1776
trainer/Q1 Predictions Std         53.9364
trainer/Q1 Predictions Max        -19.0932
trainer/Q1 Predictions Min       -176.437
trainer/Q2 Predictions Mean       -69.17
trainer/Q2 Predictions Std         53.9366
trainer/Q2 Predictions Max        -19.0909
trainer/Q2 Predictions Min       -175.591
trainer/Q Targets Mean            -68.8461
trainer/Q Targets Std              54.8188
trainer/Q Targets Max              -5.65893
trainer/Q Targets Min            -177.288
trainer/Log Pis Mean                2.07034
trainer/Log Pis Std                 1.45839
trainer/Log Pis Max                 6.77231
trainer/Log Pis Min                -3.79706
trainer/Policy mu Mean              0.101306
trainer/Policy mu Std               0.80528
trainer/Policy mu Max               3.48917
trainer/Policy mu Min              -2.57424
trainer/Policy log std Mean        -2.00735
trainer/Policy log std Std          0.542225
trainer/Policy log std Max         -0.305864
trainer/Policy log std Min         -2.93334
trainer/Alpha                       0.0732205
trainer/Alpha Loss                  0.183881
exploration/num steps total     49700
exploration/num paths total       497
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.09855
exploration/Rewards Std             1.16626
exploration/Rewards Max            -0.0573118
exploration/Rewards Min            -8.54186
exploration/Returns Mean         -109.855
exploration/Returns Std            84.6324
exploration/Returns Max           -27.9365
exploration/Returns Min          -226.644
exploration/Actions Mean           -0.00417048
exploration/Actions Std             0.211115
exploration/Actions Max             0.997725
exploration/Actions Min            -0.994547
exploration/Num Paths               5
exploration/Average Returns      -109.855
evaluation/num steps total     148500
evaluation/num paths total       1485
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.40058
evaluation/Rewards Std              1.17497
evaluation/Rewards Max             -0.162768
evaluation/Rewards Min            -10.2109
evaluation/Returns Mean          -140.058
evaluation/Returns Std             87.8283
evaluation/Returns Max            -20.4005
evaluation/Returns Min           -231.193
evaluation/Actions Mean            -0.00804408
evaluation/Actions Std              0.176403
evaluation/Actions Max              0.998204
evaluation/Actions Min             -0.999502
evaluation/Num Paths               15
evaluation/Average Returns       -140.058
time/data storing (s)               0.00325739
time/evaluation sampling (s)        0.352072
time/exploration sampling (s)       0.157062
time/logging (s)                    0.00490534
time/saving (s)                     0.00209969
time/training (s)                   2.07698
time/epoch (s)                      2.59637
time/total (s)                    266.308
Epoch                              98
-----------------------------  ---------------
2019-04-22 22:14:27.040706 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 99 finished
-----------------------------  ---------------
replay_buffer/size              50200
trainer/QF1 Loss                    5.01677
trainer/QF2 Loss                    5.13654
trainer/Policy Loss                66.314
trainer/Q1 Predictions Mean       -65.3514
trainer/Q1 Predictions Std         52.5327
trainer/Q1 Predictions Max        -18.8024
trainer/Q1 Predictions Min       -168.092
trainer/Q2 Predictions Mean       -65.3254
trainer/Q2 Predictions Std         52.4571
trainer/Q2 Predictions Max        -18.9465
trainer/Q2 Predictions Min       -166.837
trainer/Q Targets Mean            -66.0235
trainer/Q Targets Std              53.342
trainer/Q Targets Max              -0.253236
trainer/Q Targets Min            -166.088
trainer/Log Pis Mean                1.84736
trainer/Log Pis Std                 1.52745
trainer/Log Pis Max                 6.61397
trainer/Log Pis Min                -3.21881
trainer/Policy mu Mean              0.0272923
trainer/Policy mu Std               0.836709
trainer/Policy mu Max               2.91811
trainer/Policy mu Min              -3.26618
trainer/Policy log std Mean        -1.87316
trainer/Policy log std Std          0.539933
trainer/Policy log std Max         -0.490464
trainer/Policy log std Min         -2.81055
trainer/Alpha                       0.0730069
trainer/Alpha Loss                 -0.399487
exploration/num steps total     50200
exploration/num paths total       502
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.845281
exploration/Rewards Std             1.12881
exploration/Rewards Max            -0.00652955
exploration/Rewards Min            -8.25975
exploration/Returns Mean          -84.5281
exploration/Returns Std            72.4715
exploration/Returns Max           -34.1109
exploration/Returns Min          -228.622
exploration/Actions Mean           -0.00714852
exploration/Actions Std             0.230861
exploration/Actions Max             0.997236
exploration/Actions Min            -0.999631
exploration/Num Paths               5
exploration/Average Returns       -84.5281
evaluation/num steps total     150000
evaluation/num paths total       1500
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.93669
evaluation/Rewards Std              1.20969
evaluation/Rewards Max             -0.0787443
evaluation/Rewards Min             -9.19308
evaluation/Returns Mean           -93.669
evaluation/Returns Std             78.1807
evaluation/Returns Max            -17.0195
evaluation/Returns Min           -235.589
evaluation/Actions Mean             0.00869955
evaluation/Actions Std              0.185193
evaluation/Actions Max              0.99646
evaluation/Actions Min             -0.998902
evaluation/Num Paths               15
evaluation/Average Returns        -93.669
time/data storing (s)               0.00321826
time/evaluation sampling (s)        0.347466
time/exploration sampling (s)       0.157795
time/logging (s)                    0.00454719
time/saving (s)                     0.00199101
time/training (s)                   2.08212
time/epoch (s)                      2.59714
time/total (s)                    268.91
Epoch                              99
-----------------------------  ---------------
2019-04-22 22:14:29.629029 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 100 finished
-----------------------------  ---------------
replay_buffer/size              50700
trainer/QF1 Loss                  179.055
trainer/QF2 Loss                  178.544
trainer/Policy Loss                62.0274
trainer/Q1 Predictions Mean       -60.8057
trainer/Q1 Predictions Std         49.5849
trainer/Q1 Predictions Max        -18.5365
trainer/Q1 Predictions Min       -157.751
trainer/Q2 Predictions Mean       -60.7666
trainer/Q2 Predictions Std         49.555
trainer/Q2 Predictions Max        -18.5505
trainer/Q2 Predictions Min       -157.316
trainer/Q Targets Mean            -60.1026
trainer/Q Targets Std              50.1827
trainer/Q Targets Max              -0.370588
trainer/Q Targets Min            -161.993
trainer/Log Pis Mean                1.97283
trainer/Log Pis Std                 1.44954
trainer/Log Pis Max                 8.05937
trainer/Log Pis Min                -2.81045
trainer/Policy mu Mean              0.118323
trainer/Policy mu Std               0.75223
trainer/Policy mu Max               2.97376
trainer/Policy mu Min              -3.28034
trainer/Policy log std Mean        -2.0179
trainer/Policy log std Std          0.518013
trainer/Policy log std Max         -0.389375
trainer/Policy log std Min         -2.73358
trainer/Alpha                       0.0713009
trainer/Alpha Loss                 -0.0717424
exploration/num steps total     50700
exploration/num paths total       507
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.97321
exploration/Rewards Std             1.11923
exploration/Rewards Max            -0.0240777
exploration/Rewards Min            -9.66811
exploration/Returns Mean         -197.321
exploration/Returns Std            64.0308
exploration/Returns Max           -69.9331
exploration/Returns Min          -240.865
exploration/Actions Mean           -0.0204675
exploration/Actions Std             0.239796
exploration/Actions Max             0.995812
exploration/Actions Min            -0.999263
exploration/Num Paths               5
exploration/Average Returns      -197.321
evaluation/num steps total     151500
evaluation/num paths total       1515
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.16256
evaluation/Rewards Std              1.30006
evaluation/Rewards Max             -0.182773
evaluation/Rewards Min             -9.98062
evaluation/Returns Mean          -116.256
evaluation/Returns Std             76.1538
evaluation/Returns Max            -51.6351
evaluation/Returns Min           -245.779
evaluation/Actions Mean            -0.0056379
evaluation/Actions Std              0.192848
evaluation/Actions Max              0.999064
evaluation/Actions Min             -0.998824
evaluation/Num Paths               15
evaluation/Average Returns       -116.256
time/data storing (s)               0.0032415
time/evaluation sampling (s)        0.353638
time/exploration sampling (s)       0.158989
time/logging (s)                    0.00476178
time/saving (s)                     0.00196856
time/training (s)                   2.05991
time/epoch (s)                      2.58251
time/total (s)                    271.497
Epoch                             100
-----------------------------  ---------------
2019-04-22 22:14:32.232598 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 101 finished
-----------------------------  ----------------
replay_buffer/size              51200
trainer/QF1 Loss                    4.37282
trainer/QF2 Loss                    4.37183
trainer/Policy Loss                61.6376
trainer/Q1 Predictions Mean       -60.1082
trainer/Q1 Predictions Std         50.9448
trainer/Q1 Predictions Max        -18.6239
trainer/Q1 Predictions Min       -146.126
trainer/Q2 Predictions Mean       -60.1164
trainer/Q2 Predictions Std         50.9426
trainer/Q2 Predictions Max        -18.6649
trainer/Q2 Predictions Min       -146.411
trainer/Q Targets Mean            -60.452
trainer/Q Targets Std              51.6623
trainer/Q Targets Max              -0.118624
trainer/Q Targets Min            -145.775
trainer/Log Pis Mean                1.99233
trainer/Log Pis Std                 1.50404
trainer/Log Pis Max                 7.17867
trainer/Log Pis Min                -1.71055
trainer/Policy mu Mean              0.0407745
trainer/Policy mu Std               0.835034
trainer/Policy mu Max               2.72228
trainer/Policy mu Min              -2.91901
trainer/Policy log std Mean        -1.96304
trainer/Policy log std Std          0.603784
trainer/Policy log std Max         -0.286018
trainer/Policy log std Min         -2.93426
trainer/Alpha                       0.0702792
trainer/Alpha Loss                 -0.02036
exploration/num steps total     51200
exploration/num paths total       512
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.09329
exploration/Rewards Std             1.24539
exploration/Rewards Max            -0.0317307
exploration/Rewards Min            -9.40507
exploration/Returns Mean         -109.329
exploration/Returns Std            66.1224
exploration/Returns Max           -55.3564
exploration/Returns Min          -225.254
exploration/Actions Mean           -0.00529019
exploration/Actions Std             0.265786
exploration/Actions Max             0.997709
exploration/Actions Min            -0.999936
exploration/Num Paths               5
exploration/Average Returns      -109.329
evaluation/num steps total     153000
evaluation/num paths total       1530
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.98633
evaluation/Rewards Std              1.09715
evaluation/Rewards Max             -0.102637
evaluation/Rewards Min             -8.4421
evaluation/Returns Mean           -98.633
evaluation/Returns Std             87.4833
evaluation/Returns Max            -15.0556
evaluation/Returns Min           -229.138
evaluation/Actions Mean            -0.000198098
evaluation/Actions Std              0.154623
evaluation/Actions Max              0.994143
evaluation/Actions Min             -0.996668
evaluation/Num Paths               15
evaluation/Average Returns        -98.633
time/data storing (s)               0.00319787
time/evaluation sampling (s)        0.349076
time/exploration sampling (s)       0.156331
time/logging (s)                    0.00459571
time/saving (s)                     0.0020017
time/training (s)                   2.08173
time/epoch (s)                      2.59693
time/total (s)                    274.098
Epoch                             101
-----------------------------  ----------------
2019-04-22 22:14:34.811629 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 102 finished
-----------------------------  ---------------
replay_buffer/size              51700
trainer/QF1 Loss                    8.59164
trainer/QF2 Loss                    8.63124
trainer/Policy Loss                60.3531
trainer/Q1 Predictions Mean       -58.8345
trainer/Q1 Predictions Std         50.4705
trainer/Q1 Predictions Max        -18.5137
trainer/Q1 Predictions Min       -165.888
trainer/Q2 Predictions Mean       -58.8539
trainer/Q2 Predictions Std         50.4493
trainer/Q2 Predictions Max        -18.6232
trainer/Q2 Predictions Min       -165.375
trainer/Q Targets Mean            -58.8832
trainer/Q Targets Std              51.0344
trainer/Q Targets Max              -0.538023
trainer/Q Targets Min            -164.624
trainer/Log Pis Mean                1.96867
trainer/Log Pis Std                 1.18341
trainer/Log Pis Max                 7.83226
trainer/Log Pis Min                -3.2522
trainer/Policy mu Mean              0.0737118
trainer/Policy mu Std               0.646877
trainer/Policy mu Max               2.94235
trainer/Policy mu Min              -2.56656
trainer/Policy log std Mean        -2.08468
trainer/Policy log std Std          0.478299
trainer/Policy log std Max         -0.336896
trainer/Policy log std Min         -2.77291
trainer/Alpha                       0.0716751
trainer/Alpha Loss                 -0.0825771
exploration/num steps total     51700
exploration/num paths total       517
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.58143
exploration/Rewards Std             1.1861
exploration/Rewards Max            -0.0535564
exploration/Rewards Min            -8.94246
exploration/Returns Mean         -158.143
exploration/Returns Std            78.9334
exploration/Returns Max           -55.8008
exploration/Returns Min          -224.15
exploration/Actions Mean            0.0107284
exploration/Actions Std             0.227974
exploration/Actions Max             0.998575
exploration/Actions Min            -0.994109
exploration/Num Paths               5
exploration/Average Returns      -158.143
evaluation/num steps total     154500
evaluation/num paths total       1545
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.825852
evaluation/Rewards Std              1.21586
evaluation/Rewards Max             -0.169205
evaluation/Rewards Min            -10.2636
evaluation/Returns Mean           -82.5852
evaluation/Returns Std             74.0502
evaluation/Returns Max            -23.6522
evaluation/Returns Min           -239.31
evaluation/Actions Mean            -0.01376
evaluation/Actions Std              0.184374
evaluation/Actions Max              0.994125
evaluation/Actions Min             -0.998779
evaluation/Num Paths               15
evaluation/Average Returns        -82.5852
time/data storing (s)               0.00355671
time/evaluation sampling (s)        0.346035
time/exploration sampling (s)       0.15659
time/logging (s)                    0.0047934
time/saving (s)                     0.00159002
time/training (s)                   2.06035
time/epoch (s)                      2.57292
time/total (s)                    276.675
Epoch                             102
-----------------------------  ---------------
2019-04-22 22:14:37.400881 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 103 finished
-----------------------------  ---------------
replay_buffer/size              52200
trainer/QF1 Loss                    0.561247
trainer/QF2 Loss                    0.568051
trainer/Policy Loss                66.282
trainer/Q1 Predictions Mean       -64.7682
trainer/Q1 Predictions Std         50.5181
trainer/Q1 Predictions Max        -18.4663
trainer/Q1 Predictions Min       -159.423
trainer/Q2 Predictions Mean       -64.7904
trainer/Q2 Predictions Std         50.4934
trainer/Q2 Predictions Max        -18.4351
trainer/Q2 Predictions Min       -159.375
trainer/Q Targets Mean            -65.1368
trainer/Q Targets Std              50.9297
trainer/Q Targets Max             -18.239
trainer/Q Targets Min            -161.106
trainer/Log Pis Mean                2.13328
trainer/Log Pis Std                 1.18038
trainer/Log Pis Max                 6.413
trainer/Log Pis Min                -0.708823
trainer/Policy mu Mean              0.112929
trainer/Policy mu Std               0.720046
trainer/Policy mu Max               2.9012
trainer/Policy mu Min              -2.92295
trainer/Policy log std Mean        -2.02935
trainer/Policy log std Std          0.517632
trainer/Policy log std Max         -0.37409
trainer/Policy log std Min         -2.96191
trainer/Alpha                       0.0727072
trainer/Alpha Loss                  0.349378
exploration/num steps total     52200
exploration/num paths total       522
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.16005
exploration/Rewards Std             1.37233
exploration/Rewards Max            -0.0735263
exploration/Rewards Min           -11.0996
exploration/Returns Mean         -116.005
exploration/Returns Std            75.839
exploration/Returns Max           -25.3664
exploration/Returns Min          -223.232
exploration/Actions Mean           -0.0117861
exploration/Actions Std             0.229827
exploration/Actions Max             0.995701
exploration/Actions Min            -0.999708
exploration/Num Paths               5
exploration/Average Returns      -116.005
evaluation/num steps total     156000
evaluation/num paths total       1560
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.957338
evaluation/Rewards Std              1.05962
evaluation/Rewards Max             -0.0718249
evaluation/Rewards Min             -8.32861
evaluation/Returns Mean           -95.7338
evaluation/Returns Std             75.9227
evaluation/Returns Max            -23.512
evaluation/Returns Min           -213.943
evaluation/Actions Mean            -0.0151278
evaluation/Actions Std              0.1657
evaluation/Actions Max              0.992448
evaluation/Actions Min             -0.998758
evaluation/Num Paths               15
evaluation/Average Returns        -95.7338
time/data storing (s)               0.00299953
time/evaluation sampling (s)        0.34755
time/exploration sampling (s)       0.156275
time/logging (s)                    0.00494479
time/saving (s)                     0.00201778
time/training (s)                   2.06891
time/epoch (s)                      2.5827
time/total (s)                    279.262
Epoch                             103
-----------------------------  ---------------
2019-04-22 22:14:39.995238 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 104 finished
-----------------------------  ---------------
replay_buffer/size              52700
trainer/QF1 Loss                    3.65035
trainer/QF2 Loss                    3.79893
trainer/Policy Loss                62.7764
trainer/Q1 Predictions Mean       -61.5847
trainer/Q1 Predictions Std         51.1147
trainer/Q1 Predictions Max        -17.6705
trainer/Q1 Predictions Min       -169.828
trainer/Q2 Predictions Mean       -61.5456
trainer/Q2 Predictions Std         51.1408
trainer/Q2 Predictions Max        -17.649
trainer/Q2 Predictions Min       -169.362
trainer/Q Targets Mean            -61.8304
trainer/Q Targets Std              51.5535
trainer/Q Targets Max              -0.307424
trainer/Q Targets Min            -171.539
trainer/Log Pis Mean                1.82952
trainer/Log Pis Std                 1.60415
trainer/Log Pis Max                 9.14505
trainer/Log Pis Min                -3.15475
trainer/Policy mu Mean             -0.151565
trainer/Policy mu Std               0.827358
trainer/Policy mu Max               3.19074
trainer/Policy mu Min              -2.68145
trainer/Policy log std Mean        -1.85634
trainer/Policy log std Std          0.638014
trainer/Policy log std Max         -0.325025
trainer/Policy log std Min         -2.82645
trainer/Alpha                       0.0715399
trainer/Alpha Loss                 -0.44962
exploration/num steps total     52700
exploration/num paths total       527
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.64234
exploration/Rewards Std             1.31272
exploration/Rewards Max            -0.0084022
exploration/Rewards Min            -9.18653
exploration/Returns Mean         -164.234
exploration/Returns Std           106.92
exploration/Returns Max           -26.1999
exploration/Returns Min          -282.401
exploration/Actions Mean           -0.0145228
exploration/Actions Std             0.297077
exploration/Actions Max             0.997377
exploration/Actions Min            -0.999831
exploration/Num Paths               5
exploration/Average Returns      -164.234
evaluation/num steps total     157500
evaluation/num paths total       1575
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.13506
evaluation/Rewards Std              1.25586
evaluation/Rewards Max             -0.0279504
evaluation/Rewards Min            -11.1637
evaluation/Returns Mean          -113.506
evaluation/Returns Std             87.5122
evaluation/Returns Max             -7.46574
evaluation/Returns Min           -273.931
evaluation/Actions Mean             0.0138167
evaluation/Actions Std              0.18051
evaluation/Actions Max              0.997631
evaluation/Actions Min             -0.997976
evaluation/Num Paths               15
evaluation/Average Returns       -113.506
time/data storing (s)               0.00342637
time/evaluation sampling (s)        0.347424
time/exploration sampling (s)       0.157946
time/logging (s)                    0.00480427
time/saving (s)                     0.00168593
time/training (s)                   2.07274
time/epoch (s)                      2.58802
time/total (s)                    281.854
Epoch                             104
-----------------------------  ---------------
2019-04-22 22:14:42.612134 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 105 finished
-----------------------------  ---------------
replay_buffer/size              53200
trainer/QF1 Loss                  280.869
trainer/QF2 Loss                  280.575
trainer/Policy Loss                65.9728
trainer/Q1 Predictions Mean       -64.6223
trainer/Q1 Predictions Std         50.9691
trainer/Q1 Predictions Max        -17.8608
trainer/Q1 Predictions Min       -138.835
trainer/Q2 Predictions Mean       -64.6458
trainer/Q2 Predictions Std         51.0207
trainer/Q2 Predictions Max        -17.9059
trainer/Q2 Predictions Min       -139.218
trainer/Q Targets Mean            -62.5368
trainer/Q Targets Std              51.6143
trainer/Q Targets Max              -0.309747
trainer/Q Targets Min            -137.499
trainer/Log Pis Mean                1.83013
trainer/Log Pis Std                 1.21727
trainer/Log Pis Max                 5.3355
trainer/Log Pis Min                -2.98521
trainer/Policy mu Mean              0.0299687
trainer/Policy mu Std               0.522626
trainer/Policy mu Max               2.0747
trainer/Policy mu Min              -2.10153
trainer/Policy log std Mean        -2.08145
trainer/Policy log std Std          0.442122
trainer/Policy log std Max         -0.536645
trainer/Policy log std Min         -2.91948
trainer/Alpha                       0.0696141
trainer/Alpha Loss                 -0.452649
exploration/num steps total     53200
exploration/num paths total       532
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.47636
exploration/Rewards Std             1.25483
exploration/Rewards Max            -0.0205625
exploration/Rewards Min            -9.61505
exploration/Returns Mean         -147.636
exploration/Returns Std            79.804
exploration/Returns Max           -45.4409
exploration/Returns Min          -238.003
exploration/Actions Mean            0.00472301
exploration/Actions Std             0.227618
exploration/Actions Max             0.998952
exploration/Actions Min            -0.99912
exploration/Num Paths               5
exploration/Average Returns      -147.636
evaluation/num steps total     159000
evaluation/num paths total       1590
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.25417
evaluation/Rewards Std              1.2389
evaluation/Rewards Max             -0.11841
evaluation/Rewards Min            -12.061
evaluation/Returns Mean          -125.417
evaluation/Returns Std             75.4027
evaluation/Returns Max            -34.891
evaluation/Returns Min           -224.457
evaluation/Actions Mean             0.00565495
evaluation/Actions Std              0.189377
evaluation/Actions Max              0.999581
evaluation/Actions Min             -0.998381
evaluation/Num Paths               15
evaluation/Average Returns       -125.417
time/data storing (s)               0.00303506
time/evaluation sampling (s)        0.3519
time/exploration sampling (s)       0.158105
time/logging (s)                    0.00502173
time/saving (s)                     0.0105585
time/training (s)                   2.08197
time/epoch (s)                      2.61059
time/total (s)                    284.47
Epoch                             105
-----------------------------  ---------------
2019-04-22 22:14:45.205552 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 106 finished
-----------------------------  ----------------
replay_buffer/size              53700
trainer/QF1 Loss                    8.62147
trainer/QF2 Loss                    8.51511
trainer/Policy Loss                59.491
trainer/Q1 Predictions Mean       -58.0365
trainer/Q1 Predictions Std         48.5257
trainer/Q1 Predictions Max        -17.8161
trainer/Q1 Predictions Min       -149.641
trainer/Q2 Predictions Mean       -58.0553
trainer/Q2 Predictions Std         48.5748
trainer/Q2 Predictions Max        -17.7958
trainer/Q2 Predictions Min       -149.984
trainer/Q Targets Mean            -58.2348
trainer/Q Targets Std              49.2226
trainer/Q Targets Max              -0.976667
trainer/Q Targets Min            -150.926
trainer/Log Pis Mean                1.96563
trainer/Log Pis Std                 1.31113
trainer/Log Pis Max                 5.99573
trainer/Log Pis Min                -4.73362
trainer/Policy mu Mean              0.0546705
trainer/Policy mu Std               0.628215
trainer/Policy mu Max               2.81729
trainer/Policy mu Min              -2.78825
trainer/Policy log std Mean        -2.08599
trainer/Policy log std Std          0.510416
trainer/Policy log std Max         -0.391421
trainer/Policy log std Min         -2.96356
trainer/Alpha                       0.0749469
trainer/Alpha Loss                 -0.0890604
exploration/num steps total     53700
exploration/num paths total       537
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.676601
exploration/Rewards Std             0.933493
exploration/Rewards Max            -0.00311301
exploration/Rewards Min            -6.58213
exploration/Returns Mean          -67.6601
exploration/Returns Std            65.441
exploration/Returns Max           -29.1979
exploration/Returns Min          -198.169
exploration/Actions Mean           -0.00239898
exploration/Actions Std             0.208649
exploration/Actions Max             0.996627
exploration/Actions Min            -0.993648
exploration/Num Paths               5
exploration/Average Returns       -67.6601
evaluation/num steps total     160500
evaluation/num paths total       1605
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.959179
evaluation/Rewards Std              1.06518
evaluation/Rewards Max             -0.0355633
evaluation/Rewards Min             -8.57933
evaluation/Returns Mean           -95.9179
evaluation/Returns Std             81.287
evaluation/Returns Max             -4.28558
evaluation/Returns Min           -211.661
evaluation/Actions Mean             0.000591153
evaluation/Actions Std              0.157328
evaluation/Actions Max              0.994383
evaluation/Actions Min             -0.996057
evaluation/Num Paths               15
evaluation/Average Returns        -95.9179
time/data storing (s)               0.00302168
time/evaluation sampling (s)        0.34859
time/exploration sampling (s)       0.165164
time/logging (s)                    0.00478643
time/saving (s)                     0.00201347
time/training (s)                   2.06288
time/epoch (s)                      2.58645
time/total (s)                    287.061
Epoch                             106
-----------------------------  ----------------
2019-04-22 22:14:47.822608 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 107 finished
-----------------------------  ---------------
replay_buffer/size              54200
trainer/QF1 Loss                    3.53049
trainer/QF2 Loss                    3.49989
trainer/Policy Loss                57.2764
trainer/Q1 Predictions Mean       -55.7838
trainer/Q1 Predictions Std         47.1154
trainer/Q1 Predictions Max        -17.7812
trainer/Q1 Predictions Min       -131.936
trainer/Q2 Predictions Mean       -55.7998
trainer/Q2 Predictions Std         47.1874
trainer/Q2 Predictions Max        -17.7426
trainer/Q2 Predictions Min       -131.775
trainer/Q Targets Mean            -55.8835
trainer/Q Targets Std              47.5223
trainer/Q Targets Max              -0.292855
trainer/Q Targets Min            -132.277
trainer/Log Pis Mean                2.14503
trainer/Log Pis Std                 1.27246
trainer/Log Pis Max                 7.25655
trainer/Log Pis Min                -1.522
trainer/Policy mu Mean             -0.0319775
trainer/Policy mu Std               0.807551
trainer/Policy mu Max               2.33757
trainer/Policy mu Min              -4.26505
trainer/Policy log std Mean        -1.94289
trainer/Policy log std Std          0.563646
trainer/Policy log std Max         -0.243867
trainer/Policy log std Min         -2.82651
trainer/Alpha                       0.0713418
trainer/Alpha Loss                  0.382917
exploration/num steps total     54200
exploration/num paths total       542
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.06306
exploration/Rewards Std             1.21189
exploration/Rewards Max            -0.0053355
exploration/Rewards Min            -9.27774
exploration/Returns Mean         -106.306
exploration/Returns Std            83.7707
exploration/Returns Max           -20.6305
exploration/Returns Min          -214.295
exploration/Actions Mean            0.0017631
exploration/Actions Std             0.251602
exploration/Actions Max             0.997796
exploration/Actions Min            -0.999892
exploration/Num Paths               5
exploration/Average Returns      -106.306
evaluation/num steps total     162000
evaluation/num paths total       1620
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.11194
evaluation/Rewards Std              1.39866
evaluation/Rewards Max             -0.0675433
evaluation/Rewards Min            -11.317
evaluation/Returns Mean          -111.194
evaluation/Returns Std             69.2055
evaluation/Returns Max            -33.7825
evaluation/Returns Min           -227.813
evaluation/Actions Mean             0.0139693
evaluation/Actions Std              0.216696
evaluation/Actions Max              0.998945
evaluation/Actions Min             -0.997898
evaluation/Num Paths               15
evaluation/Average Returns       -111.194
time/data storing (s)               0.0031755
time/evaluation sampling (s)        0.347097
time/exploration sampling (s)       0.155966
time/logging (s)                    0.00487098
time/saving (s)                     0.00164247
time/training (s)                   2.09762
time/epoch (s)                      2.61037
time/total (s)                    289.676
Epoch                             107
-----------------------------  ---------------
2019-04-22 22:14:50.414633 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 108 finished
-----------------------------  ---------------
replay_buffer/size              54700
trainer/QF1 Loss                    0.726183
trainer/QF2 Loss                    0.729317
trainer/Policy Loss                55.6225
trainer/Q1 Predictions Mean       -53.9712
trainer/Q1 Predictions Std         46.8589
trainer/Q1 Predictions Max        -17.357
trainer/Q1 Predictions Min       -135.623
trainer/Q2 Predictions Mean       -54.0145
trainer/Q2 Predictions Std         46.8564
trainer/Q2 Predictions Max        -17.3892
trainer/Q2 Predictions Min       -135.181
trainer/Q Targets Mean            -54.4945
trainer/Q Targets Std              47.3407
trainer/Q Targets Max             -17.2749
trainer/Q Targets Min            -138.546
trainer/Log Pis Mean                2.02758
trainer/Log Pis Std                 1.15598
trainer/Log Pis Max                 6.00873
trainer/Log Pis Min                -2.08229
trainer/Policy mu Mean             -0.0163813
trainer/Policy mu Std               0.708432
trainer/Policy mu Max               2.25069
trainer/Policy mu Min              -3.45392
trainer/Policy log std Mean        -1.98334
trainer/Policy log std Std          0.580262
trainer/Policy log std Max         -0.274112
trainer/Policy log std Min         -2.79554
trainer/Alpha                       0.0727749
trainer/Alpha Loss                  0.072273
exploration/num steps total     54700
exploration/num paths total       547
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.626451
exploration/Rewards Std             0.761736
exploration/Rewards Max            -0.0768039
exploration/Rewards Min            -8.19914
exploration/Returns Mean          -62.6451
exploration/Returns Std            14.3832
exploration/Returns Max           -48.3269
exploration/Returns Min           -80.2538
exploration/Actions Mean            0.00763727
exploration/Actions Std             0.227415
exploration/Actions Max             0.995314
exploration/Actions Min            -0.985882
exploration/Num Paths               5
exploration/Average Returns       -62.6451
evaluation/num steps total     163500
evaluation/num paths total       1635
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.94038
evaluation/Rewards Std              1.16746
evaluation/Rewards Max             -0.0195561
evaluation/Rewards Min            -10.5779
evaluation/Returns Mean           -94.038
evaluation/Returns Std             83.3018
evaluation/Returns Max            -10.7149
evaluation/Returns Min           -231.87
evaluation/Actions Mean             0.00874287
evaluation/Actions Std              0.174336
evaluation/Actions Max              0.996962
evaluation/Actions Min             -0.999713
evaluation/Num Paths               15
evaluation/Average Returns        -94.038
time/data storing (s)               0.0030943
time/evaluation sampling (s)        0.347863
time/exploration sampling (s)       0.157997
time/logging (s)                    0.00413682
time/saving (s)                     0.00197713
time/training (s)                   2.06995
time/epoch (s)                      2.58501
time/total (s)                    292.265
Epoch                             108
-----------------------------  ---------------
2019-04-22 22:14:52.997178 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 109 finished
-----------------------------  ---------------
replay_buffer/size              55200
trainer/QF1 Loss                  304.635
trainer/QF2 Loss                  303.477
trainer/Policy Loss                64.2924
trainer/Q1 Predictions Mean       -63.1975
trainer/Q1 Predictions Std         49.3768
trainer/Q1 Predictions Max        -17.0857
trainer/Q1 Predictions Min       -130.743
trainer/Q2 Predictions Mean       -63.1509
trainer/Q2 Predictions Std         49.3591
trainer/Q2 Predictions Max        -17.1414
trainer/Q2 Predictions Min       -130.798
trainer/Q Targets Mean            -61.3957
trainer/Q Targets Std              49.7904
trainer/Q Targets Max              -2.85915
trainer/Q Targets Min            -132.482
trainer/Log Pis Mean                1.8863
trainer/Log Pis Std                 1.46073
trainer/Log Pis Max                 6.88924
trainer/Log Pis Min                -2.41493
trainer/Policy mu Mean              0.0454291
trainer/Policy mu Std               0.81935
trainer/Policy mu Max               2.44582
trainer/Policy mu Min              -3.53841
trainer/Policy log std Mean        -1.87634
trainer/Policy log std Std          0.524506
trainer/Policy log std Max         -0.44465
trainer/Policy log std Min         -2.68147
trainer/Alpha                       0.0732649
trainer/Alpha Loss                 -0.297204
exploration/num steps total     55200
exploration/num paths total       552
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.762453
exploration/Rewards Std             1.03156
exploration/Rewards Max            -0.0164156
exploration/Rewards Min            -9.26471
exploration/Returns Mean          -76.2453
exploration/Returns Std            39.2494
exploration/Returns Max           -20.5663
exploration/Returns Min          -123.15
exploration/Actions Mean            0.00396669
exploration/Actions Std             0.258547
exploration/Actions Max             0.998371
exploration/Actions Min            -0.999319
exploration/Num Paths               5
exploration/Average Returns       -76.2453
evaluation/num steps total     165000
evaluation/num paths total       1650
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.02795
evaluation/Rewards Std              1.19565
evaluation/Rewards Max             -0.136494
evaluation/Rewards Min            -11.4999
evaluation/Returns Mean          -102.795
evaluation/Returns Std             74.2953
evaluation/Returns Max            -14.2894
evaluation/Returns Min           -231.228
evaluation/Actions Mean             0.0102901
evaluation/Actions Std              0.184292
evaluation/Actions Max              0.999287
evaluation/Actions Min             -0.998038
evaluation/Num Paths               15
evaluation/Average Returns       -102.795
time/data storing (s)               0.00320032
time/evaluation sampling (s)        0.345852
time/exploration sampling (s)       0.155352
time/logging (s)                    0.00475612
time/saving (s)                     0.00160829
time/training (s)                   2.06604
time/epoch (s)                      2.57681
time/total (s)                    294.846
Epoch                             109
-----------------------------  ---------------
2019-04-22 22:14:55.597241 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 110 finished
-----------------------------  ---------------
replay_buffer/size              55700
trainer/QF1 Loss                    3.85115
trainer/QF2 Loss                    4.00182
trainer/Policy Loss                68.98
trainer/Q1 Predictions Mean       -67.8449
trainer/Q1 Predictions Std         50.6727
trainer/Q1 Predictions Max        -16.9235
trainer/Q1 Predictions Min       -135.442
trainer/Q2 Predictions Mean       -67.8657
trainer/Q2 Predictions Std         50.6965
trainer/Q2 Predictions Max        -17.0528
trainer/Q2 Predictions Min       -135.245
trainer/Q Targets Mean            -68.4855
trainer/Q Targets Std              51.2757
trainer/Q Targets Max              -0.506286
trainer/Q Targets Min            -137.018
trainer/Log Pis Mean                1.86995
trainer/Log Pis Std                 1.05693
trainer/Log Pis Max                 4.53132
trainer/Log Pis Min                -2.19894
trainer/Policy mu Mean              0.113834
trainer/Policy mu Std               0.853767
trainer/Policy mu Max               2.90467
trainer/Policy mu Min              -2.51723
trainer/Policy log std Mean        -1.82929
trainer/Policy log std Std          0.559833
trainer/Policy log std Max         -0.586511
trainer/Policy log std Min         -2.77242
trainer/Alpha                       0.072295
trainer/Alpha Loss                 -0.341634
exploration/num steps total     55700
exploration/num paths total       557
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.699091
exploration/Rewards Std             1.37663
exploration/Rewards Max            -0.0113028
exploration/Rewards Min           -11.9426
exploration/Returns Mean          -69.9091
exploration/Returns Std            43.7379
exploration/Returns Max           -13.8056
exploration/Returns Min          -144.933
exploration/Actions Mean           -0.0213142
exploration/Actions Std             0.261336
exploration/Actions Max             0.998828
exploration/Actions Min            -0.999433
exploration/Num Paths               5
exploration/Average Returns       -69.9091
evaluation/num steps total     166500
evaluation/num paths total       1665
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.925346
evaluation/Rewards Std              1.10485
evaluation/Rewards Max             -0.065147
evaluation/Rewards Min             -8.61586
evaluation/Returns Mean           -92.5346
evaluation/Returns Std             80.1161
evaluation/Returns Max            -13.0619
evaluation/Returns Min           -215.109
evaluation/Actions Mean             0.00538245
evaluation/Actions Std              0.173893
evaluation/Actions Max              0.995028
evaluation/Actions Min             -0.997264
evaluation/Num Paths               15
evaluation/Average Returns        -92.5346
time/data storing (s)               0.00364078
time/evaluation sampling (s)        0.346254
time/exploration sampling (s)       0.157149
time/logging (s)                    0.00478515
time/saving (s)                     0.00194942
time/training (s)                   2.07976
time/epoch (s)                      2.59354
time/total (s)                    297.444
Epoch                             110
-----------------------------  ---------------
2019-04-22 22:14:58.177057 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 111 finished
-----------------------------  ---------------
replay_buffer/size              56200
trainer/QF1 Loss                  146.467
trainer/QF2 Loss                  146.448
trainer/Policy Loss                62.789
trainer/Q1 Predictions Mean       -61.625
trainer/Q1 Predictions Std         49.6208
trainer/Q1 Predictions Max        -16.9836
trainer/Q1 Predictions Min       -162.956
trainer/Q2 Predictions Mean       -61.6244
trainer/Q2 Predictions Std         49.6642
trainer/Q2 Predictions Max        -17.0293
trainer/Q2 Predictions Min       -162.326
trainer/Q Targets Mean            -60.6983
trainer/Q Targets Std              49.8521
trainer/Q Targets Max              -2.30005
trainer/Q Targets Min            -164.632
trainer/Log Pis Mean                1.91897
trainer/Log Pis Std                 1.42319
trainer/Log Pis Max                 7.96779
trainer/Log Pis Min                -3.01821
trainer/Policy mu Mean             -0.0344843
trainer/Policy mu Std               0.855263
trainer/Policy mu Max               3.23675
trainer/Policy mu Min              -2.88424
trainer/Policy log std Mean        -1.9183
trainer/Policy log std Std          0.638413
trainer/Policy log std Max         -0.384606
trainer/Policy log std Min         -2.89923
trainer/Alpha                       0.0736381
trainer/Alpha Loss                 -0.211382
exploration/num steps total     56200
exploration/num paths total       562
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.935003
exploration/Rewards Std             1.06261
exploration/Rewards Max            -0.0226371
exploration/Rewards Min            -9.73977
exploration/Returns Mean          -93.5003
exploration/Returns Std            61.0681
exploration/Returns Max           -26.7396
exploration/Returns Min          -199.681
exploration/Actions Mean            0.00747609
exploration/Actions Std             0.249796
exploration/Actions Max             0.998566
exploration/Actions Min            -0.994597
exploration/Num Paths               5
exploration/Average Returns       -93.5003
evaluation/num steps total     168000
evaluation/num paths total       1680
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.95365
evaluation/Rewards Std              0.991561
evaluation/Rewards Max             -0.138806
evaluation/Rewards Min             -9.47518
evaluation/Returns Mean           -95.365
evaluation/Returns Std             73.7595
evaluation/Returns Max            -15.7984
evaluation/Returns Min           -212.874
evaluation/Actions Mean            -0.00210949
evaluation/Actions Std              0.166719
evaluation/Actions Max              0.994871
evaluation/Actions Min             -0.999801
evaluation/Num Paths               15
evaluation/Average Returns        -95.365
time/data storing (s)               0.00307542
time/evaluation sampling (s)        0.342384
time/exploration sampling (s)       0.156894
time/logging (s)                    0.00476124
time/saving (s)                     0.00202981
time/training (s)                   2.06398
time/epoch (s)                      2.57313
time/total (s)                    300.022
Epoch                             111
-----------------------------  ---------------
2019-04-22 22:15:00.770158 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 112 finished
-----------------------------  ----------------
replay_buffer/size              56700
trainer/QF1 Loss                    0.643954
trainer/QF2 Loss                    0.697978
trainer/Policy Loss                76.4495
trainer/Q1 Predictions Mean       -75.4491
trainer/Q1 Predictions Std         49.8021
trainer/Q1 Predictions Max        -17.3027
trainer/Q1 Predictions Min       -143.237
trainer/Q2 Predictions Mean       -75.4742
trainer/Q2 Predictions Std         49.8347
trainer/Q2 Predictions Max        -17.3469
trainer/Q2 Predictions Min       -142.967
trainer/Q Targets Mean            -75.9111
trainer/Q Targets Std              50.2235
trainer/Q Targets Max             -16.9994
trainer/Q Targets Min            -146.302
trainer/Log Pis Mean                1.66158
trainer/Log Pis Std                 1.49239
trainer/Log Pis Max                 6.7719
trainer/Log Pis Min                -3.70754
trainer/Policy mu Mean              0.108555
trainer/Policy mu Std               0.78456
trainer/Policy mu Max               3.38945
trainer/Policy mu Min              -2.58519
trainer/Policy log std Mean        -1.8746
trainer/Policy log std Std          0.506686
trainer/Policy log std Max         -0.498595
trainer/Policy log std Min         -2.75247
trainer/Alpha                       0.0727842
trainer/Alpha Loss                 -0.88673
exploration/num steps total     56700
exploration/num paths total       567
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.59954
exploration/Rewards Std             1.1236
exploration/Rewards Max            -0.0938239
exploration/Rewards Min           -10.0793
exploration/Returns Mean         -159.954
exploration/Returns Std            47.1149
exploration/Returns Max           -76.2199
exploration/Returns Min          -215.377
exploration/Actions Mean           -0.00763916
exploration/Actions Std             0.237616
exploration/Actions Max             0.999151
exploration/Actions Min            -0.999414
exploration/Num Paths               5
exploration/Average Returns      -159.954
evaluation/num steps total     169500
evaluation/num paths total       1695
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.996457
evaluation/Rewards Std              1.17129
evaluation/Rewards Max             -0.177732
evaluation/Rewards Min             -9.34152
evaluation/Returns Mean           -99.6457
evaluation/Returns Std             65.7387
evaluation/Returns Max            -23.1779
evaluation/Returns Min           -213.296
evaluation/Actions Mean            -0.000796248
evaluation/Actions Std              0.188597
evaluation/Actions Max              0.996847
evaluation/Actions Min             -0.997939
evaluation/Num Paths               15
evaluation/Average Returns        -99.6457
time/data storing (s)               0.00321397
time/evaluation sampling (s)        0.347574
time/exploration sampling (s)       0.158149
time/logging (s)                    0.00487872
time/saving (s)                     0.00195654
time/training (s)                   2.07086
time/epoch (s)                      2.58663
time/total (s)                    302.613
Epoch                             112
-----------------------------  ----------------
2019-04-22 22:15:03.374126 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 113 finished
-----------------------------  ---------------
replay_buffer/size              57200
trainer/QF1 Loss                  131.591
trainer/QF2 Loss                  132.074
trainer/Policy Loss                54.5829
trainer/Q1 Predictions Mean       -53.0735
trainer/Q1 Predictions Std         45.9052
trainer/Q1 Predictions Max        -16.9133
trainer/Q1 Predictions Min       -137.291
trainer/Q2 Predictions Mean       -53.0747
trainer/Q2 Predictions Std         45.907
trainer/Q2 Predictions Max        -16.9628
trainer/Q2 Predictions Min       -136.772
trainer/Q Targets Mean            -52.1035
trainer/Q Targets Std              45.7604
trainer/Q Targets Max              -2.49096
trainer/Q Targets Min            -138.423
trainer/Log Pis Mean                2.25731
trainer/Log Pis Std                 1.36726
trainer/Log Pis Max                 6.81266
trainer/Log Pis Min                -2.06856
trainer/Policy mu Mean              0.0939172
trainer/Policy mu Std               0.883272
trainer/Policy mu Max               2.92188
trainer/Policy mu Min              -2.43043
trainer/Policy log std Mean        -1.98307
trainer/Policy log std Std          0.620306
trainer/Policy log std Max         -0.54103
trainer/Policy log std Min         -3.01026
trainer/Alpha                       0.0704755
trainer/Alpha Loss                  0.682561
exploration/num steps total     57200
exploration/num paths total       572
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.704669
exploration/Rewards Std             0.981381
exploration/Rewards Max            -0.0193576
exploration/Rewards Min            -7.64897
exploration/Returns Mean          -70.4669
exploration/Returns Std            62.8388
exploration/Returns Max           -18.2566
exploration/Returns Min          -192.736
exploration/Actions Mean           -0.00850101
exploration/Actions Std             0.188116
exploration/Actions Max             0.998969
exploration/Actions Min            -0.997454
exploration/Num Paths               5
exploration/Average Returns       -70.4669
evaluation/num steps total     171000
evaluation/num paths total       1710
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.25954
evaluation/Rewards Std              1.19896
evaluation/Rewards Max             -0.0640733
evaluation/Rewards Min            -10.097
evaluation/Returns Mean          -125.954
evaluation/Returns Std             72.1973
evaluation/Returns Max            -15.4999
evaluation/Returns Min           -220.849
evaluation/Actions Mean             0.00162821
evaluation/Actions Std              0.179141
evaluation/Actions Max              0.998863
evaluation/Actions Min             -0.998042
evaluation/Num Paths               15
evaluation/Average Returns       -125.954
time/data storing (s)               0.00314795
time/evaluation sampling (s)        0.350015
time/exploration sampling (s)       0.16192
time/logging (s)                    0.00477691
time/saving (s)                     0.00197339
time/training (s)                   2.07584
time/epoch (s)                      2.59767
time/total (s)                    305.215
Epoch                             113
-----------------------------  ---------------
2019-04-22 22:15:05.964602 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 114 finished
-----------------------------  ---------------
replay_buffer/size              57700
trainer/QF1 Loss                  138.992
trainer/QF2 Loss                  139.092
trainer/Policy Loss                60.5816
trainer/Q1 Predictions Mean       -59.0523
trainer/Q1 Predictions Std         48.552
trainer/Q1 Predictions Max        -17.1031
trainer/Q1 Predictions Min       -136.666
trainer/Q2 Predictions Mean       -59.0386
trainer/Q2 Predictions Std         48.5505
trainer/Q2 Predictions Max        -17.1777
trainer/Q2 Predictions Min       -136.318
trainer/Q Targets Mean            -58.3492
trainer/Q Targets Std              48.8646
trainer/Q Targets Max              -4.75381
trainer/Q Targets Min            -139.013
trainer/Log Pis Mean                2.12654
trainer/Log Pis Std                 1.49986
trainer/Log Pis Max                 7.11318
trainer/Log Pis Min                -3.22761
trainer/Policy mu Mean             -0.0510647
trainer/Policy mu Std               0.850575
trainer/Policy mu Max               2.84895
trainer/Policy mu Min              -3.25877
trainer/Policy log std Mean        -1.96337
trainer/Policy log std Std          0.596318
trainer/Policy log std Max         -0.0603044
trainer/Policy log std Min         -2.97476
trainer/Alpha                       0.0718818
trainer/Alpha Loss                  0.333149
exploration/num steps total     57700
exploration/num paths total       577
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.06097
exploration/Rewards Std             1.04762
exploration/Rewards Max            -0.0128852
exploration/Rewards Min           -10.9962
exploration/Returns Mean         -106.097
exploration/Returns Std            59.2446
exploration/Returns Max           -17.8765
exploration/Returns Min          -189.159
exploration/Actions Mean            0.00300755
exploration/Actions Std             0.239917
exploration/Actions Max             0.999395
exploration/Actions Min            -0.998783
exploration/Num Paths               5
exploration/Average Returns      -106.097
evaluation/num steps total     172500
evaluation/num paths total       1725
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.800671
evaluation/Rewards Std              1.04662
evaluation/Rewards Max             -0.0901222
evaluation/Rewards Min            -11.533
evaluation/Returns Mean           -80.0671
evaluation/Returns Std             54.6947
evaluation/Returns Max            -23.4679
evaluation/Returns Min           -182.565
evaluation/Actions Mean            -0.00195382
evaluation/Actions Std              0.175716
evaluation/Actions Max              0.997044
evaluation/Actions Min             -0.998286
evaluation/Num Paths               15
evaluation/Average Returns        -80.0671
time/data storing (s)               0.00314366
time/evaluation sampling (s)        0.349069
time/exploration sampling (s)       0.160307
time/logging (s)                    0.0045414
time/saving (s)                     0.00195872
time/training (s)                   2.06461
time/epoch (s)                      2.58363
time/total (s)                    307.802
Epoch                             114
-----------------------------  ---------------
2019-04-22 22:15:08.562153 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 115 finished
-----------------------------  ---------------
replay_buffer/size              58200
trainer/QF1 Loss                  137.534
trainer/QF2 Loss                  138.113
trainer/Policy Loss                63.596
trainer/Q1 Predictions Mean       -62.4336
trainer/Q1 Predictions Std         48.5077
trainer/Q1 Predictions Max        -16.8309
trainer/Q1 Predictions Min       -147.728
trainer/Q2 Predictions Mean       -62.4715
trainer/Q2 Predictions Std         48.4792
trainer/Q2 Predictions Max        -16.9542
trainer/Q2 Predictions Min       -146.177
trainer/Q Targets Mean            -61.6429
trainer/Q Targets Std              49.1541
trainer/Q Targets Max              -1.09927
trainer/Q Targets Min            -149.615
trainer/Log Pis Mean                1.76932
trainer/Log Pis Std                 1.1157
trainer/Log Pis Max                 6.3451
trainer/Log Pis Min                -1.39867
trainer/Policy mu Mean              0.118759
trainer/Policy mu Std               0.748502
trainer/Policy mu Max               2.98168
trainer/Policy mu Min              -2.51356
trainer/Policy log std Mean        -1.87208
trainer/Policy log std Std          0.555502
trainer/Policy log std Max         -0.503094
trainer/Policy log std Min         -3.12695
trainer/Alpha                       0.0721324
trainer/Alpha Loss                 -0.606472
exploration/num steps total     58200
exploration/num paths total       582
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.1333
exploration/Rewards Std             1.3564
exploration/Rewards Max            -0.0225768
exploration/Rewards Min            -9.91636
exploration/Returns Mean         -113.33
exploration/Returns Std            67.8336
exploration/Returns Max           -40.3217
exploration/Returns Min          -220.588
exploration/Actions Mean           -0.00194271
exploration/Actions Std             0.269649
exploration/Actions Max             0.998872
exploration/Actions Min            -0.999755
exploration/Num Paths               5
exploration/Average Returns      -113.33
evaluation/num steps total     174000
evaluation/num paths total       1740
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.789228
evaluation/Rewards Std              1.0456
evaluation/Rewards Max             -0.0654282
evaluation/Rewards Min            -10.3194
evaluation/Returns Mean           -78.9228
evaluation/Returns Std             62.3128
evaluation/Returns Max            -20.9593
evaluation/Returns Min           -194.375
evaluation/Actions Mean            -0.00526374
evaluation/Actions Std              0.17951
evaluation/Actions Max              0.996088
evaluation/Actions Min             -0.99827
evaluation/Num Paths               15
evaluation/Average Returns        -78.9228
time/data storing (s)               0.00311264
time/evaluation sampling (s)        0.347262
time/exploration sampling (s)       0.159118
time/logging (s)                    0.00434839
time/saving (s)                     0.00193916
time/training (s)                   2.07549
time/epoch (s)                      2.59127
time/total (s)                    310.398
Epoch                             115
-----------------------------  ---------------
2019-04-22 22:15:11.169506 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 116 finished
-----------------------------  ---------------
replay_buffer/size              58700
trainer/QF1 Loss                  131.243
trainer/QF2 Loss                  131.842
trainer/Policy Loss                56.2561
trainer/Q1 Predictions Mean       -54.6626
trainer/Q1 Predictions Std         45.7987
trainer/Q1 Predictions Max        -16.6765
trainer/Q1 Predictions Min       -136.849
trainer/Q2 Predictions Mean       -54.6552
trainer/Q2 Predictions Std         45.7752
trainer/Q2 Predictions Max        -16.8221
trainer/Q2 Predictions Min       -136.051
trainer/Q Targets Mean            -54.1523
trainer/Q Targets Std              46.1553
trainer/Q Targets Max              -4.5132
trainer/Q Targets Min            -139.725
trainer/Log Pis Mean                1.9849
trainer/Log Pis Std                 1.10131
trainer/Log Pis Max                 5.72096
trainer/Log Pis Min                -0.637974
trainer/Policy mu Mean              0.084944
trainer/Policy mu Std               0.765705
trainer/Policy mu Max               2.90949
trainer/Policy mu Min              -3.22736
trainer/Policy log std Mean        -1.99774
trainer/Policy log std Std          0.610101
trainer/Policy log std Max         -0.217693
trainer/Policy log std Min         -2.95411
trainer/Alpha                       0.0731603
trainer/Alpha Loss                 -0.039486
exploration/num steps total     58700
exploration/num paths total       587
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.00806
exploration/Rewards Std             0.978842
exploration/Rewards Max            -0.020592
exploration/Rewards Min            -6.78261
exploration/Returns Mean         -100.806
exploration/Returns Std            75.2278
exploration/Returns Max           -31.5889
exploration/Returns Min          -197.053
exploration/Actions Mean           -0.00160336
exploration/Actions Std             0.188139
exploration/Actions Max             0.998671
exploration/Actions Min            -0.991811
exploration/Num Paths               5
exploration/Average Returns      -100.806
evaluation/num steps total     175500
evaluation/num paths total       1755
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.427531
evaluation/Rewards Std              0.818762
evaluation/Rewards Max             -0.0939342
evaluation/Rewards Min             -8.3223
evaluation/Returns Mean           -42.7531
evaluation/Returns Std             43.9464
evaluation/Returns Max            -10.3733
evaluation/Returns Min           -196.931
evaluation/Actions Mean             0.00912104
evaluation/Actions Std              0.161291
evaluation/Actions Max              0.996982
evaluation/Actions Min             -0.996955
evaluation/Num Paths               15
evaluation/Average Returns        -42.7531
time/data storing (s)               0.00325814
time/evaluation sampling (s)        0.34707
time/exploration sampling (s)       0.157952
time/logging (s)                    0.00445404
time/saving (s)                     0.00196749
time/training (s)                   2.08653
time/epoch (s)                      2.60123
time/total (s)                    313.004
Epoch                             116
-----------------------------  ---------------
2019-04-22 22:15:13.794016 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 117 finished
-----------------------------  ---------------
replay_buffer/size              59200
trainer/QF1 Loss                  142.426
trainer/QF2 Loss                  143.294
trainer/Policy Loss                61.1805
trainer/Q1 Predictions Mean       -59.974
trainer/Q1 Predictions Std         47.1842
trainer/Q1 Predictions Max        -16.4521
trainer/Q1 Predictions Min       -143.761
trainer/Q2 Predictions Mean       -59.9662
trainer/Q2 Predictions Std         47.1607
trainer/Q2 Predictions Max        -16.4583
trainer/Q2 Predictions Min       -144.017
trainer/Q Targets Mean            -59.0216
trainer/Q Targets Std              47.2745
trainer/Q Targets Max              -0.273048
trainer/Q Targets Min            -144.992
trainer/Log Pis Mean                1.99109
trainer/Log Pis Std                 1.38611
trainer/Log Pis Max                 5.27691
trainer/Log Pis Min                -5.37596
trainer/Policy mu Mean             -0.0267801
trainer/Policy mu Std               0.865903
trainer/Policy mu Max               2.77269
trainer/Policy mu Min              -3.42711
trainer/Policy log std Mean        -1.85081
trainer/Policy log std Std          0.590066
trainer/Policy log std Max         -0.362458
trainer/Policy log std Min         -3.00556
trainer/Alpha                       0.0750888
trainer/Alpha Loss                 -0.0230767
exploration/num steps total     59200
exploration/num paths total       592
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.961742
exploration/Rewards Std             1.17293
exploration/Rewards Max            -0.00932196
exploration/Rewards Min            -9.41337
exploration/Returns Mean          -96.1742
exploration/Returns Std            83.6575
exploration/Returns Max           -17.547
exploration/Returns Min          -213.962
exploration/Actions Mean            0.00806436
exploration/Actions Std             0.212255
exploration/Actions Max             0.999698
exploration/Actions Min            -0.998235
exploration/Num Paths               5
exploration/Average Returns       -96.1742
evaluation/num steps total     177000
evaluation/num paths total       1770
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.609619
evaluation/Rewards Std              1.00294
evaluation/Rewards Max             -0.0376701
evaluation/Rewards Min            -10.9211
evaluation/Returns Mean           -60.9619
evaluation/Returns Std             38.4633
evaluation/Returns Max            -13.9805
evaluation/Returns Min           -173.619
evaluation/Actions Mean             0.00383616
evaluation/Actions Std              0.17801
evaluation/Actions Max              0.99668
evaluation/Actions Min             -0.999415
evaluation/Num Paths               15
evaluation/Average Returns        -60.9619
time/data storing (s)               0.003991
time/evaluation sampling (s)        0.34843
time/exploration sampling (s)       0.157959
time/logging (s)                    0.00481378
time/saving (s)                     0.00190848
time/training (s)                   2.10121
time/epoch (s)                      2.61831
time/total (s)                    315.626
Epoch                             117
-----------------------------  ---------------
2019-04-22 22:15:16.394471 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 118 finished
-----------------------------  ---------------
replay_buffer/size              59700
trainer/QF1 Loss                  129.488
trainer/QF2 Loss                  128.526
trainer/Policy Loss                62.6028
trainer/Q1 Predictions Mean       -61.4101
trainer/Q1 Predictions Std         47.0907
trainer/Q1 Predictions Max        -16.6446
trainer/Q1 Predictions Min       -133.611
trainer/Q2 Predictions Mean       -61.4332
trainer/Q2 Predictions Std         47.0565
trainer/Q2 Predictions Max        -16.6985
trainer/Q2 Predictions Min       -133.139
trainer/Q Targets Mean            -60.7808
trainer/Q Targets Std              47.8096
trainer/Q Targets Max              -0.465058
trainer/Q Targets Min            -134.688
trainer/Log Pis Mean                2.11727
trainer/Log Pis Std                 1.03171
trainer/Log Pis Max                 4.2663
trainer/Log Pis Min                -0.681164
trainer/Policy mu Mean              0.0189121
trainer/Policy mu Std               0.844929
trainer/Policy mu Max               2.47524
trainer/Policy mu Min              -2.81676
trainer/Policy log std Mean        -1.86373
trainer/Policy log std Std          0.578185
trainer/Policy log std Max         -0.341089
trainer/Policy log std Min         -3.11169
trainer/Alpha                       0.0756518
trainer/Alpha Loss                  0.302774
exploration/num steps total     59700
exploration/num paths total       597
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.579479
exploration/Rewards Std             1.2689
exploration/Rewards Max            -0.0189081
exploration/Rewards Min           -10.1647
exploration/Returns Mean          -57.9479
exploration/Returns Std            15.9477
exploration/Returns Max           -38.852
exploration/Returns Min           -76.7731
exploration/Actions Mean            0.00533073
exploration/Actions Std             0.258539
exploration/Actions Max             0.999639
exploration/Actions Min            -0.998817
exploration/Num Paths               5
exploration/Average Returns       -57.9479
evaluation/num steps total     178500
evaluation/num paths total       1785
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.67877
evaluation/Rewards Std              1.04878
evaluation/Rewards Max             -0.0160153
evaluation/Rewards Min             -9.7895
evaluation/Returns Mean           -67.877
evaluation/Returns Std             66.6416
evaluation/Returns Max             -7.10509
evaluation/Returns Min           -212.256
evaluation/Actions Mean            -0.00134885
evaluation/Actions Std              0.175033
evaluation/Actions Max              0.998774
evaluation/Actions Min             -0.999303
evaluation/Num Paths               15
evaluation/Average Returns        -67.877
time/data storing (s)               0.00434577
time/evaluation sampling (s)        0.3503
time/exploration sampling (s)       0.15897
time/logging (s)                    0.00461105
time/saving (s)                     0.00157765
time/training (s)                   2.0734
time/epoch (s)                      2.5932
time/total (s)                    318.224
Epoch                             118
-----------------------------  ---------------
2019-04-22 22:15:18.984275 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 119 finished
-----------------------------  ---------------
replay_buffer/size              60200
trainer/QF1 Loss                    0.749835
trainer/QF2 Loss                    0.805995
trainer/Policy Loss                63.0549
trainer/Q1 Predictions Mean       -61.6519
trainer/Q1 Predictions Std         47.1838
trainer/Q1 Predictions Max        -16.5137
trainer/Q1 Predictions Min       -156.934
trainer/Q2 Predictions Mean       -61.6281
trainer/Q2 Predictions Std         47.105
trainer/Q2 Predictions Max        -16.5136
trainer/Q2 Predictions Min       -156.761
trainer/Q Targets Mean            -62.1239
trainer/Q Targets Std              47.5455
trainer/Q Targets Max             -16.612
trainer/Q Targets Min            -159.766
trainer/Log Pis Mean                2.22396
trainer/Log Pis Std                 1.86309
trainer/Log Pis Max                 8.16998
trainer/Log Pis Min                -3.56655
trainer/Policy mu Mean             -0.0100657
trainer/Policy mu Std               1.08203
trainer/Policy mu Max               3.44081
trainer/Policy mu Min              -3.39866
trainer/Policy log std Mean        -1.85843
trainer/Policy log std Std          0.689564
trainer/Policy log std Max         -0.154734
trainer/Policy log std Min         -3.04153
trainer/Alpha                       0.0760649
trainer/Alpha Loss                  0.576964
exploration/num steps total     60200
exploration/num paths total       602
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.809332
exploration/Rewards Std             1.091
exploration/Rewards Max            -0.0168037
exploration/Rewards Min            -9.09252
exploration/Returns Mean          -80.9332
exploration/Returns Std            60.871
exploration/Returns Max           -28.2764
exploration/Returns Min          -198.773
exploration/Actions Mean            0.00712859
exploration/Actions Std             0.225439
exploration/Actions Max             0.999482
exploration/Actions Min            -0.996653
exploration/Num Paths               5
exploration/Average Returns       -80.9332
evaluation/num steps total     180000
evaluation/num paths total       1800
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.860944
evaluation/Rewards Std              1.08063
evaluation/Rewards Max             -0.283563
evaluation/Rewards Min            -10.2184
evaluation/Returns Mean           -86.0944
evaluation/Returns Std             56.5562
evaluation/Returns Max            -31.6679
evaluation/Returns Min           -183.092
evaluation/Actions Mean             0.0101946
evaluation/Actions Std              0.181514
evaluation/Actions Max              0.99723
evaluation/Actions Min             -0.995667
evaluation/Num Paths               15
evaluation/Average Returns        -86.0944
time/data storing (s)               0.00306419
time/evaluation sampling (s)        0.34779
time/exploration sampling (s)       0.154451
time/logging (s)                    0.00517345
time/saving (s)                     0.00193626
time/training (s)                   2.07096
time/epoch (s)                      2.58338
time/total (s)                    320.812
Epoch                             119
-----------------------------  ---------------
2019-04-22 22:15:21.588447 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 120 finished
-----------------------------  ---------------
replay_buffer/size              60700
trainer/QF1 Loss                    0.484944
trainer/QF2 Loss                    0.726903
trainer/Policy Loss                58.5815
trainer/Q1 Predictions Mean       -57.4203
trainer/Q1 Predictions Std         45.3357
trainer/Q1 Predictions Max        -16.5874
trainer/Q1 Predictions Min       -126.679
trainer/Q2 Predictions Mean       -57.3985
trainer/Q2 Predictions Std         45.3436
trainer/Q2 Predictions Max        -16.6346
trainer/Q2 Predictions Min       -127.173
trainer/Q Targets Mean            -57.8537
trainer/Q Targets Std              45.6343
trainer/Q Targets Max             -16.6369
trainer/Q Targets Min            -127.383
trainer/Log Pis Mean                1.76291
trainer/Log Pis Std                 1.237
trainer/Log Pis Max                 5.21849
trainer/Log Pis Min                -2.83604
trainer/Policy mu Mean             -0.0807201
trainer/Policy mu Std               0.800136
trainer/Policy mu Max               2.89442
trainer/Policy mu Min              -3.34774
trainer/Policy log std Mean        -1.85123
trainer/Policy log std Std          0.566191
trainer/Policy log std Max         -0.379675
trainer/Policy log std Min         -2.94633
trainer/Alpha                       0.0796103
trainer/Alpha Loss                 -0.599937
exploration/num steps total     60700
exploration/num paths total       607
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.878523
exploration/Rewards Std             1.06465
exploration/Rewards Max            -0.0825465
exploration/Rewards Min            -9.21073
exploration/Returns Mean          -87.8523
exploration/Returns Std            62.0065
exploration/Returns Max           -44.1386
exploration/Returns Min          -208.251
exploration/Actions Mean            0.0152112
exploration/Actions Std             0.232772
exploration/Actions Max             0.998249
exploration/Actions Min            -0.999381
exploration/Num Paths               5
exploration/Average Returns       -87.8523
evaluation/num steps total     181500
evaluation/num paths total       1815
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.629672
evaluation/Rewards Std              0.902913
evaluation/Rewards Max             -0.0500684
evaluation/Rewards Min            -10.3301
evaluation/Returns Mean           -62.9672
evaluation/Returns Std             58.9203
evaluation/Returns Max            -12.2865
evaluation/Returns Min           -211.649
evaluation/Actions Mean             0.00987483
evaluation/Actions Std              0.155302
evaluation/Actions Max              0.995308
evaluation/Actions Min             -0.994826
evaluation/Num Paths               15
evaluation/Average Returns        -62.9672
time/data storing (s)               0.00315135
time/evaluation sampling (s)        0.347156
time/exploration sampling (s)       0.155824
time/logging (s)                    0.00505505
time/saving (s)                     0.00198414
time/training (s)                   2.08378
time/epoch (s)                      2.59695
time/total (s)                    323.414
Epoch                             120
-----------------------------  ---------------
2019-04-22 22:15:24.183007 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 121 finished
-----------------------------  ---------------
replay_buffer/size              61200
trainer/QF1 Loss                  154.207
trainer/QF2 Loss                  155.73
trainer/Policy Loss                58.0935
trainer/Q1 Predictions Mean       -57.1968
trainer/Q1 Predictions Std         45.0539
trainer/Q1 Predictions Max        -16.4131
trainer/Q1 Predictions Min       -137.225
trainer/Q2 Predictions Mean       -57.2457
trainer/Q2 Predictions Std         45.0755
trainer/Q2 Predictions Max        -16.3253
trainer/Q2 Predictions Min       -138.071
trainer/Q Targets Mean            -56.3394
trainer/Q Targets Std              45.1585
trainer/Q Targets Max              -6.83751
trainer/Q Targets Min            -138.67
trainer/Log Pis Mean                1.65917
trainer/Log Pis Std                 1.55767
trainer/Log Pis Max                 5.36599
trainer/Log Pis Min                -4.45643
trainer/Policy mu Mean             -0.0101762
trainer/Policy mu Std               0.873027
trainer/Policy mu Max               2.32688
trainer/Policy mu Min              -2.92202
trainer/Policy log std Mean        -1.8081
trainer/Policy log std Std          0.544872
trainer/Policy log std Max         -0.424884
trainer/Policy log std Min         -2.88182
trainer/Alpha                       0.0788915
trainer/Alpha Loss                 -0.865584
exploration/num steps total     61200
exploration/num paths total       612
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.591974
exploration/Rewards Std             1.10538
exploration/Rewards Max            -0.0220149
exploration/Rewards Min           -10.4095
exploration/Returns Mean          -59.1974
exploration/Returns Std            18.3284
exploration/Returns Max           -37.4073
exploration/Returns Min           -83.7455
exploration/Actions Mean           -0.00590947
exploration/Actions Std             0.258297
exploration/Actions Max             0.997717
exploration/Actions Min            -0.99959
exploration/Num Paths               5
exploration/Average Returns       -59.1974
evaluation/num steps total     183000
evaluation/num paths total       1830
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.87095
evaluation/Rewards Std              1.06154
evaluation/Rewards Max             -0.173394
evaluation/Rewards Min            -11.8911
evaluation/Returns Mean           -87.095
evaluation/Returns Std             57.216
evaluation/Returns Max            -34.9735
evaluation/Returns Min           -184.976
evaluation/Actions Mean             0.00503432
evaluation/Actions Std              0.178817
evaluation/Actions Max              0.995929
evaluation/Actions Min             -0.998887
evaluation/Num Paths               15
evaluation/Average Returns        -87.095
time/data storing (s)               0.00317098
time/evaluation sampling (s)        0.344977
time/exploration sampling (s)       0.155738
time/logging (s)                    0.0048133
time/saving (s)                     0.0021253
time/training (s)                   2.0766
time/epoch (s)                      2.58743
time/total (s)                    326.006
Epoch                             121
-----------------------------  ---------------
2019-04-22 22:15:26.764037 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 122 finished
-----------------------------  ---------------
replay_buffer/size              61700
trainer/QF1 Loss                  119.156
trainer/QF2 Loss                  119.046
trainer/Policy Loss                57.7202
trainer/Q1 Predictions Mean       -56.9062
trainer/Q1 Predictions Std         43.2633
trainer/Q1 Predictions Max        -16.5744
trainer/Q1 Predictions Min       -129.185
trainer/Q2 Predictions Mean       -56.9086
trainer/Q2 Predictions Std         43.2517
trainer/Q2 Predictions Max        -16.6114
trainer/Q2 Predictions Min       -129.151
trainer/Q Targets Mean            -55.7527
trainer/Q Targets Std              43.9594
trainer/Q Targets Max              -0.125998
trainer/Q Targets Min            -131.018
trainer/Log Pis Mean                2.13703
trainer/Log Pis Std                 1.59683
trainer/Log Pis Max                 6.76656
trainer/Log Pis Min                -2.68227
trainer/Policy mu Mean              0.13188
trainer/Policy mu Std               1.0422
trainer/Policy mu Max               3.0685
trainer/Policy mu Min              -3.32664
trainer/Policy log std Mean        -1.70628
trainer/Policy log std Std          0.622485
trainer/Policy log std Max         -0.376215
trainer/Policy log std Min         -2.98765
trainer/Alpha                       0.0785119
trainer/Alpha Loss                  0.348693
exploration/num steps total     61700
exploration/num paths total       617
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.637972
exploration/Rewards Std             1.13293
exploration/Rewards Max            -0.0857757
exploration/Rewards Min           -10.0366
exploration/Returns Mean          -63.7972
exploration/Returns Std            21.439
exploration/Returns Max           -40.3346
exploration/Returns Min           -99.572
exploration/Actions Mean           -0.0109956
exploration/Actions Std             0.244547
exploration/Actions Max             0.998694
exploration/Actions Min            -0.998618
exploration/Num Paths               5
exploration/Average Returns       -63.7972
evaluation/num steps total     184500
evaluation/num paths total       1845
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.9447
evaluation/Rewards Std              1.22359
evaluation/Rewards Max             -0.280059
evaluation/Rewards Min            -10.6917
evaluation/Returns Mean           -94.47
evaluation/Returns Std             49.9552
evaluation/Returns Max            -28.4235
evaluation/Returns Min           -167.449
evaluation/Actions Mean            -0.00820903
evaluation/Actions Std              0.193023
evaluation/Actions Max              0.997493
evaluation/Actions Min             -0.99971
evaluation/Num Paths               15
evaluation/Average Returns        -94.47
time/data storing (s)               0.00307586
time/evaluation sampling (s)        0.346237
time/exploration sampling (s)       0.155056
time/logging (s)                    0.00473644
time/saving (s)                     0.00191741
time/training (s)                   2.06317
time/epoch (s)                      2.5742
time/total (s)                    328.584
Epoch                             122
-----------------------------  ---------------
2019-04-22 22:15:29.362246 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 123 finished
-----------------------------  ---------------
replay_buffer/size              62200
trainer/QF1 Loss                  124.84
trainer/QF2 Loss                  124.059
trainer/Policy Loss                47.795
trainer/Q1 Predictions Mean       -46.7812
trainer/Q1 Predictions Std         39.703
trainer/Q1 Predictions Max        -16.6776
trainer/Q1 Predictions Min       -131.111
trainer/Q2 Predictions Mean       -46.7561
trainer/Q2 Predictions Std         39.7016
trainer/Q2 Predictions Max        -16.632
trainer/Q2 Predictions Min       -131.887
trainer/Q Targets Mean            -45.7133
trainer/Q Targets Std              39.961
trainer/Q Targets Max              -0.576457
trainer/Q Targets Min            -133.96
trainer/Log Pis Mean                1.8183
trainer/Log Pis Std                 1.24552
trainer/Log Pis Max                 5.43678
trainer/Log Pis Min                -3.43856
trainer/Policy mu Mean             -0.157591
trainer/Policy mu Std               0.830866
trainer/Policy mu Max               2.46435
trainer/Policy mu Min              -2.81392
trainer/Policy log std Mean        -1.88026
trainer/Policy log std Std          0.563866
trainer/Policy log std Max         -0.536989
trainer/Policy log std Min         -2.80178
trainer/Alpha                       0.0798893
trainer/Alpha Loss                 -0.459139
exploration/num steps total     62200
exploration/num paths total       622
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.880617
exploration/Rewards Std             1.17081
exploration/Rewards Max            -0.00924222
exploration/Rewards Min            -9.65268
exploration/Returns Mean          -88.0617
exploration/Returns Std            53.3253
exploration/Returns Max           -41.1609
exploration/Returns Min          -191.336
exploration/Actions Mean           -0.00954904
exploration/Actions Std             0.243462
exploration/Actions Max             0.996454
exploration/Actions Min            -0.999069
exploration/Num Paths               5
exploration/Average Returns       -88.0617
evaluation/num steps total     186000
evaluation/num paths total       1860
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.701745
evaluation/Rewards Std              1.07693
evaluation/Rewards Max             -0.262598
evaluation/Rewards Min            -10.0104
evaluation/Returns Mean           -70.1745
evaluation/Returns Std             43.8388
evaluation/Returns Max            -32.339
evaluation/Returns Min           -221.147
evaluation/Actions Mean            -0.00363943
evaluation/Actions Std              0.181699
evaluation/Actions Max              0.994777
evaluation/Actions Min             -0.998699
evaluation/Num Paths               15
evaluation/Average Returns        -70.1745
time/data storing (s)               0.00394796
time/evaluation sampling (s)        0.350326
time/exploration sampling (s)       0.159298
time/logging (s)                    0.00482673
time/saving (s)                     0.00195764
time/training (s)                   2.07099
time/epoch (s)                      2.59135
time/total (s)                    331.18
Epoch                             123
-----------------------------  ---------------
2019-04-22 22:15:31.965769 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 124 finished
-----------------------------  ---------------
replay_buffer/size              62700
trainer/QF1 Loss                    1.21256
trainer/QF2 Loss                    1.36893
trainer/Policy Loss                56.2888
trainer/Q1 Predictions Mean       -55.3344
trainer/Q1 Predictions Std         43.7083
trainer/Q1 Predictions Max        -16.4991
trainer/Q1 Predictions Min       -131.207
trainer/Q2 Predictions Mean       -55.3155
trainer/Q2 Predictions Std         43.6703
trainer/Q2 Predictions Max        -16.5915
trainer/Q2 Predictions Min       -130.293
trainer/Q Targets Mean            -56.0807
trainer/Q Targets Std              44.3555
trainer/Q Targets Max             -16.3521
trainer/Q Targets Min            -133.379
trainer/Log Pis Mean                1.84933
trainer/Log Pis Std                 1.22181
trainer/Log Pis Max                 4.86928
trainer/Log Pis Min                -2.10313
trainer/Policy mu Mean              0.120726
trainer/Policy mu Std               0.869128
trainer/Policy mu Max               3.118
trainer/Policy mu Min              -2.81623
trainer/Policy log std Mean        -1.81161
trainer/Policy log std Std          0.567114
trainer/Policy log std Max         -0.507558
trainer/Policy log std Min         -2.93925
trainer/Alpha                       0.0784562
trainer/Alpha Loss                 -0.383499
exploration/num steps total     62700
exploration/num paths total       627
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.467095
exploration/Rewards Std             0.559914
exploration/Rewards Max            -0.00803145
exploration/Rewards Min            -7.2502
exploration/Returns Mean          -46.7095
exploration/Returns Std            18.3735
exploration/Returns Max           -24.2135
exploration/Returns Min           -67.734
exploration/Actions Mean            0.0150493
exploration/Actions Std             0.207227
exploration/Actions Max             0.995676
exploration/Actions Min            -0.962033
exploration/Num Paths               5
exploration/Average Returns       -46.7095
evaluation/num steps total     187500
evaluation/num paths total       1875
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.832883
evaluation/Rewards Std              1.09111
evaluation/Rewards Max             -0.142268
evaluation/Rewards Min            -11.0014
evaluation/Returns Mean           -83.2883
evaluation/Returns Std             53.5877
evaluation/Returns Max            -28.7111
evaluation/Returns Min           -184.284
evaluation/Actions Mean            -0.00846253
evaluation/Actions Std              0.190036
evaluation/Actions Max              0.995673
evaluation/Actions Min             -0.999282
evaluation/Num Paths               15
evaluation/Average Returns        -83.2883
time/data storing (s)               0.00306499
time/evaluation sampling (s)        0.345938
time/exploration sampling (s)       0.156613
time/logging (s)                    0.00419348
time/saving (s)                     0.00206482
time/training (s)                   2.08396
time/epoch (s)                      2.59584
time/total (s)                    333.781
Epoch                             124
-----------------------------  ---------------
2019-04-22 22:15:34.556428 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 125 finished
-----------------------------  ----------------
replay_buffer/size              63200
trainer/QF1 Loss                    0.884123
trainer/QF2 Loss                    0.890682
trainer/Policy Loss                58.1324
trainer/Q1 Predictions Mean       -56.9067
trainer/Q1 Predictions Std         41.0243
trainer/Q1 Predictions Max        -16.3302
trainer/Q1 Predictions Min       -122.449
trainer/Q2 Predictions Mean       -56.8682
trainer/Q2 Predictions Std         41.0147
trainer/Q2 Predictions Max        -16.4279
trainer/Q2 Predictions Min       -122.501
trainer/Q Targets Mean            -57.5079
trainer/Q Targets Std              41.378
trainer/Q Targets Max             -16.4027
trainer/Q Targets Min            -123.337
trainer/Log Pis Mean                2.05009
trainer/Log Pis Std                 1.29057
trainer/Log Pis Max                 6.59345
trainer/Log Pis Min                -3.18402
trainer/Policy mu Mean              0.0576945
trainer/Policy mu Std               0.960306
trainer/Policy mu Max               2.9843
trainer/Policy mu Min              -3.52121
trainer/Policy log std Mean        -1.82193
trainer/Policy log std Std          0.607457
trainer/Policy log std Max         -0.277989
trainer/Policy log std Min         -2.92675
trainer/Alpha                       0.0793776
trainer/Alpha Loss                  0.126897
exploration/num steps total     63200
exploration/num paths total       632
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.31175
exploration/Rewards Std             1.03406
exploration/Rewards Max            -0.0056673
exploration/Rewards Min            -7.7346
exploration/Returns Mean         -131.175
exploration/Returns Std            71.2007
exploration/Returns Max           -35.3417
exploration/Returns Min          -193.032
exploration/Actions Mean            0.000700054
exploration/Actions Std             0.21002
exploration/Actions Max             0.99783
exploration/Actions Min            -0.997665
exploration/Num Paths               5
exploration/Average Returns      -131.175
evaluation/num steps total     189000
evaluation/num paths total       1890
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.70334
evaluation/Rewards Std              0.856629
evaluation/Rewards Max             -0.134878
evaluation/Rewards Min             -9.20681
evaluation/Returns Mean           -70.334
evaluation/Returns Std             39.9742
evaluation/Returns Max            -19.3132
evaluation/Returns Min           -183.735
evaluation/Actions Mean            -0.00486253
evaluation/Actions Std              0.170138
evaluation/Actions Max              0.994794
evaluation/Actions Min             -0.991494
evaluation/Num Paths               15
evaluation/Average Returns        -70.334
time/data storing (s)               0.00309688
time/evaluation sampling (s)        0.34707
time/exploration sampling (s)       0.155839
time/logging (s)                    0.00400323
time/saving (s)                     0.00196562
time/training (s)                   2.0716
time/epoch (s)                      2.58358
time/total (s)                    336.369
Epoch                             125
-----------------------------  ----------------
2019-04-22 22:15:37.153937 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 126 finished
-----------------------------  ---------------
replay_buffer/size              63700
trainer/QF1 Loss                   85.4261
trainer/QF2 Loss                   85.1128
trainer/Policy Loss                53.4676
trainer/Q1 Predictions Mean       -52.3428
trainer/Q1 Predictions Std         40.3176
trainer/Q1 Predictions Max        -16.3275
trainer/Q1 Predictions Min       -135.166
trainer/Q2 Predictions Mean       -52.2998
trainer/Q2 Predictions Std         40.3207
trainer/Q2 Predictions Max        -16.232
trainer/Q2 Predictions Min       -135.23
trainer/Q Targets Mean            -51.4875
trainer/Q Targets Std              41.0107
trainer/Q Targets Max              -0.244669
trainer/Q Targets Min            -137.67
trainer/Log Pis Mean                1.98482
trainer/Log Pis Std                 1.46293
trainer/Log Pis Max                 7.10721
trainer/Log Pis Min                -1.36617
trainer/Policy mu Mean             -0.189779
trainer/Policy mu Std               0.989776
trainer/Policy mu Max               2.57864
trainer/Policy mu Min              -4.11125
trainer/Policy log std Mean        -1.8599
trainer/Policy log std Std          0.740571
trainer/Policy log std Max         -0.058192
trainer/Policy log std Min         -3.07697
trainer/Alpha                       0.080359
trainer/Alpha Loss                 -0.0382669
exploration/num steps total     63700
exploration/num paths total       637
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.840448
exploration/Rewards Std             0.97252
exploration/Rewards Max            -0.101302
exploration/Rewards Min            -6.94988
exploration/Returns Mean          -84.0448
exploration/Returns Std            55.2105
exploration/Returns Max           -50.7596
exploration/Returns Min          -194.19
exploration/Actions Mean            0.0295414
exploration/Actions Std             0.255566
exploration/Actions Max             0.998223
exploration/Actions Min            -0.973067
exploration/Num Paths               5
exploration/Average Returns       -84.0448
evaluation/num steps total     190500
evaluation/num paths total       1905
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.561613
evaluation/Rewards Std              1.02553
evaluation/Rewards Max             -0.0378215
evaluation/Rewards Min             -9.91526
evaluation/Returns Mean           -56.1613
evaluation/Returns Std             40.3239
evaluation/Returns Max             -7.718
evaluation/Returns Min           -193.115
evaluation/Actions Mean            -0.00583556
evaluation/Actions Std              0.18863
evaluation/Actions Max              0.997959
evaluation/Actions Min             -0.999529
evaluation/Num Paths               15
evaluation/Average Returns        -56.1613
time/data storing (s)               0.0029763
time/evaluation sampling (s)        0.352531
time/exploration sampling (s)       0.157775
time/logging (s)                    0.00481397
time/saving (s)                     0.00207507
time/training (s)                   2.07107
time/epoch (s)                      2.59125
time/total (s)                    338.965
Epoch                             126
-----------------------------  ---------------
2019-04-22 22:15:39.749270 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 127 finished
-----------------------------  ---------------
replay_buffer/size              64200
trainer/QF1 Loss                    8.78563
trainer/QF2 Loss                    8.99141
trainer/Policy Loss                54.9376
trainer/Q1 Predictions Mean       -53.8537
trainer/Q1 Predictions Std         41.3456
trainer/Q1 Predictions Max        -15.8826
trainer/Q1 Predictions Min       -131.698
trainer/Q2 Predictions Mean       -53.8179
trainer/Q2 Predictions Std         41.3479
trainer/Q2 Predictions Max        -16.004
trainer/Q2 Predictions Min       -130.578
trainer/Q Targets Mean            -54.3709
trainer/Q Targets Std              42.3564
trainer/Q Targets Max              -0.341511
trainer/Q Targets Min            -132.245
trainer/Log Pis Mean                1.9136
trainer/Log Pis Std                 1.36953
trainer/Log Pis Max                 5.52243
trainer/Log Pis Min                -2.1196
trainer/Policy mu Mean             -0.0921365
trainer/Policy mu Std               0.87486
trainer/Policy mu Max               2.64017
trainer/Policy mu Min              -2.54749
trainer/Policy log std Mean        -1.83471
trainer/Policy log std Std          0.668898
trainer/Policy log std Max         -0.538335
trainer/Policy log std Min         -3.12205
trainer/Alpha                       0.0806449
trainer/Alpha Loss                 -0.217524
exploration/num steps total     64200
exploration/num paths total       642
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.556496
exploration/Rewards Std             1.09469
exploration/Rewards Max            -0.032463
exploration/Rewards Min           -10.3838
exploration/Returns Mean          -55.6496
exploration/Returns Std            15.1431
exploration/Returns Max           -30.6559
exploration/Returns Min           -71.159
exploration/Actions Mean           -0.00939181
exploration/Actions Std             0.235743
exploration/Actions Max             0.998443
exploration/Actions Min            -0.999005
exploration/Num Paths               5
exploration/Average Returns       -55.6496
evaluation/num steps total     192000
evaluation/num paths total       1920
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.677444
evaluation/Rewards Std              0.954262
evaluation/Rewards Max             -0.0715662
evaluation/Rewards Min             -8.58202
evaluation/Returns Mean           -67.7444
evaluation/Returns Std             47.0006
evaluation/Returns Max            -13.7425
evaluation/Returns Min           -182.766
evaluation/Actions Mean            -0.00201326
evaluation/Actions Std              0.178242
evaluation/Actions Max              0.993266
evaluation/Actions Min             -0.998459
evaluation/Num Paths               15
evaluation/Average Returns        -67.7444
time/data storing (s)               0.00308201
time/evaluation sampling (s)        0.349613
time/exploration sampling (s)       0.159333
time/logging (s)                    0.00443948
time/saving (s)                     0.00208064
time/training (s)                   2.06943
time/epoch (s)                      2.58798
time/total (s)                    341.558
Epoch                             127
-----------------------------  ---------------
2019-04-22 22:15:42.408281 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 128 finished
-----------------------------  ---------------
replay_buffer/size              64700
trainer/QF1 Loss                    0.620424
trainer/QF2 Loss                    0.524483
trainer/Policy Loss                58.0678
trainer/Q1 Predictions Mean       -56.7878
trainer/Q1 Predictions Std         40.9024
trainer/Q1 Predictions Max        -15.8299
trainer/Q1 Predictions Min       -128.773
trainer/Q2 Predictions Mean       -56.8075
trainer/Q2 Predictions Std         40.8578
trainer/Q2 Predictions Max        -15.8341
trainer/Q2 Predictions Min       -124.883
trainer/Q Targets Mean            -57.0994
trainer/Q Targets Std              41.0741
trainer/Q Targets Max             -16.3833
trainer/Q Targets Min            -127.076
trainer/Log Pis Mean                1.99522
trainer/Log Pis Std                 1.82233
trainer/Log Pis Max                 9.8523
trainer/Log Pis Min                -4.8495
trainer/Policy mu Mean              0.112265
trainer/Policy mu Std               0.977347
trainer/Policy mu Max               3.72562
trainer/Policy mu Min              -3.31429
trainer/Policy log std Mean        -1.80542
trainer/Policy log std Std          0.613625
trainer/Policy log std Max         -0.609722
trainer/Policy log std Min         -3.01458
trainer/Alpha                       0.0813648
trainer/Alpha Loss                 -0.011985
exploration/num steps total     64700
exploration/num paths total       647
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.06808
exploration/Rewards Std             1.13015
exploration/Rewards Max            -0.047965
exploration/Rewards Min            -9.36394
exploration/Returns Mean         -106.808
exploration/Returns Std            68.7976
exploration/Returns Max           -28.2675
exploration/Returns Min          -190.383
exploration/Actions Mean           -0.00482169
exploration/Actions Std             0.25294
exploration/Actions Max             0.998681
exploration/Actions Min            -0.99927
exploration/Num Paths               5
exploration/Average Returns      -106.808
evaluation/num steps total     193500
evaluation/num paths total       1935
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.753571
evaluation/Rewards Std              1.08826
evaluation/Rewards Max             -0.20223
evaluation/Rewards Min            -11.1156
evaluation/Returns Mean           -75.3571
evaluation/Returns Std             58.3188
evaluation/Returns Max            -25.9504
evaluation/Returns Min           -223.424
evaluation/Actions Mean             0.00157945
evaluation/Actions Std              0.175869
evaluation/Actions Max              0.997037
evaluation/Actions Min             -0.998757
evaluation/Num Paths               15
evaluation/Average Returns        -75.3571
time/data storing (s)               0.00317148
time/evaluation sampling (s)        0.345988
time/exploration sampling (s)       0.160139
time/logging (s)                    0.00432051
time/saving (s)                     0.00190991
time/training (s)                   2.13622
time/epoch (s)                      2.65175
time/total (s)                    344.214
Epoch                             128
-----------------------------  ---------------
2019-04-22 22:15:45.001120 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 129 finished
-----------------------------  ---------------
replay_buffer/size              65200
trainer/QF1 Loss                    0.573523
trainer/QF2 Loss                    0.667699
trainer/Policy Loss                56.9467
trainer/Q1 Predictions Mean       -56.0159
trainer/Q1 Predictions Std         40.2509
trainer/Q1 Predictions Max        -16.083
trainer/Q1 Predictions Min       -127.474
trainer/Q2 Predictions Mean       -55.946
trainer/Q2 Predictions Std         40.2864
trainer/Q2 Predictions Max        -16.1369
trainer/Q2 Predictions Min       -126.358
trainer/Q Targets Mean            -56.463
trainer/Q Targets Std              40.5788
trainer/Q Targets Max             -16.2025
trainer/Q Targets Min            -128.104
trainer/Log Pis Mean                2.01912
trainer/Log Pis Std                 1.80162
trainer/Log Pis Max                 7.1625
trainer/Log Pis Min                -3.11802
trainer/Policy mu Mean             -0.0339369
trainer/Policy mu Std               1.08179
trainer/Policy mu Max               3.30454
trainer/Policy mu Min              -3.10466
trainer/Policy log std Mean        -1.65464
trainer/Policy log std Std          0.661693
trainer/Policy log std Max         -0.187859
trainer/Policy log std Min         -2.98168
trainer/Alpha                       0.0821596
trainer/Alpha Loss                  0.0477764
exploration/num steps total     65200
exploration/num paths total       652
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.56835
exploration/Rewards Std             1.21686
exploration/Rewards Max            -0.0205562
exploration/Rewards Min           -11.0003
exploration/Returns Mean          -56.835
exploration/Returns Std            14.3246
exploration/Returns Max           -34.3018
exploration/Returns Min           -76.2193
exploration/Actions Mean           -0.0146205
exploration/Actions Std             0.247471
exploration/Actions Max             0.998351
exploration/Actions Min            -0.996734
exploration/Num Paths               5
exploration/Average Returns       -56.835
evaluation/num steps total     195000
evaluation/num paths total       1950
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.6195
evaluation/Rewards Std              0.865193
evaluation/Rewards Max             -0.0661416
evaluation/Rewards Min             -9.07443
evaluation/Returns Mean           -61.95
evaluation/Returns Std             47.0702
evaluation/Returns Max            -14.6638
evaluation/Returns Min           -173.411
evaluation/Actions Mean            -0.00489627
evaluation/Actions Std              0.163286
evaluation/Actions Max              0.993423
evaluation/Actions Min             -0.999392
evaluation/Num Paths               15
evaluation/Average Returns        -61.95
time/data storing (s)               0.00316238
time/evaluation sampling (s)        0.35235
time/exploration sampling (s)       0.155604
time/logging (s)                    0.00481127
time/saving (s)                     0.00211287
time/training (s)                   2.06842
time/epoch (s)                      2.58646
time/total (s)                    346.805
Epoch                             129
-----------------------------  ---------------
2019-04-22 22:15:47.651660 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 130 finished
-----------------------------  ---------------
replay_buffer/size              65700
trainer/QF1 Loss                    1.54208
trainer/QF2 Loss                    1.62129
trainer/Policy Loss                50.7513
trainer/Q1 Predictions Mean       -49.7154
trainer/Q1 Predictions Std         38.6738
trainer/Q1 Predictions Max        -16.0747
trainer/Q1 Predictions Min       -136.491
trainer/Q2 Predictions Mean       -49.6606
trainer/Q2 Predictions Std         38.5907
trainer/Q2 Predictions Max        -16.2409
trainer/Q2 Predictions Min       -134.411
trainer/Q Targets Mean            -50.4715
trainer/Q Targets Std              39.2265
trainer/Q Targets Max             -16.1743
trainer/Q Targets Min            -137.732
trainer/Log Pis Mean                1.91335
trainer/Log Pis Std                 1.59226
trainer/Log Pis Max                 7.43697
trainer/Log Pis Min                -3.77871
trainer/Policy mu Mean              0.0668016
trainer/Policy mu Std               1.01518
trainer/Policy mu Max               2.93185
trainer/Policy mu Min              -3.09021
trainer/Policy log std Mean        -1.73847
trainer/Policy log std Std          0.653915
trainer/Policy log std Max         -0.3177
trainer/Policy log std Min         -2.9812
trainer/Alpha                       0.082817
trainer/Alpha Loss                 -0.215861
exploration/num steps total     65700
exploration/num paths total       657
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.592288
exploration/Rewards Std             0.939428
exploration/Rewards Max            -0.0310676
exploration/Rewards Min            -7.953
exploration/Returns Mean          -59.2288
exploration/Returns Std            12.8187
exploration/Returns Max           -41.3659
exploration/Returns Min           -79.2694
exploration/Actions Mean           -0.00322676
exploration/Actions Std             0.225739
exploration/Actions Max             0.997001
exploration/Actions Min            -0.999426
exploration/Num Paths               5
exploration/Average Returns       -59.2288
evaluation/num steps total     196500
evaluation/num paths total       1965
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.731628
evaluation/Rewards Std              0.897119
evaluation/Rewards Max             -0.142042
evaluation/Rewards Min            -10.0812
evaluation/Returns Mean           -73.1628
evaluation/Returns Std             40.4263
evaluation/Returns Max            -19.678
evaluation/Returns Min           -158.893
evaluation/Actions Mean             0.0048187
evaluation/Actions Std              0.175499
evaluation/Actions Max              0.99663
evaluation/Actions Min             -0.99938
evaluation/Num Paths               15
evaluation/Average Returns        -73.1628
time/data storing (s)               0.00354938
time/evaluation sampling (s)        0.347292
time/exploration sampling (s)       0.155422
time/logging (s)                    0.00479479
time/saving (s)                     0.00189108
time/training (s)                   2.13087
time/epoch (s)                      2.64382
time/total (s)                    349.453
Epoch                             130
-----------------------------  ---------------
2019-04-22 22:15:50.267933 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 131 finished
-----------------------------  ---------------
replay_buffer/size              66200
trainer/QF1 Loss                    0.936616
trainer/QF2 Loss                    1.08618
trainer/Policy Loss                45.283
trainer/Q1 Predictions Mean       -43.9345
trainer/Q1 Predictions Std         35.6316
trainer/Q1 Predictions Max        -16.112
trainer/Q1 Predictions Min       -118.771
trainer/Q2 Predictions Mean       -43.9476
trainer/Q2 Predictions Std         35.6619
trainer/Q2 Predictions Max        -16.3499
trainer/Q2 Predictions Min       -118.749
trainer/Q Targets Mean            -44.5366
trainer/Q Targets Std              36.1686
trainer/Q Targets Max             -16.1626
trainer/Q Targets Min            -119.939
trainer/Log Pis Mean                2.06254
trainer/Log Pis Std                 1.32347
trainer/Log Pis Max                 6.23382
trainer/Log Pis Min                -1.02609
trainer/Policy mu Mean              0.08588
trainer/Policy mu Std               0.808924
trainer/Policy mu Max               2.54928
trainer/Policy mu Min              -2.90241
trainer/Policy log std Mean        -1.8889
trainer/Policy log std Std          0.599074
trainer/Policy log std Max         -0.571397
trainer/Policy log std Min         -2.95777
trainer/Alpha                       0.0806729
trainer/Alpha Loss                  0.157442
exploration/num steps total     66200
exploration/num paths total       662
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.971808
exploration/Rewards Std             0.96608
exploration/Rewards Max            -0.00659289
exploration/Rewards Min            -7.98563
exploration/Returns Mean          -97.1808
exploration/Returns Std            69.7582
exploration/Returns Max           -25.0111
exploration/Returns Min          -184.786
exploration/Actions Mean           -0.00957428
exploration/Actions Std             0.225703
exploration/Actions Max             0.994749
exploration/Actions Min            -0.99946
exploration/Num Paths               5
exploration/Average Returns       -97.1808
evaluation/num steps total     198000
evaluation/num paths total       1980
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.708946
evaluation/Rewards Std              1.08616
evaluation/Rewards Max             -0.0276458
evaluation/Rewards Min            -10.6239
evaluation/Returns Mean           -70.8946
evaluation/Returns Std             53.2824
evaluation/Returns Max            -18.4347
evaluation/Returns Min           -215.915
evaluation/Actions Mean             0.00575201
evaluation/Actions Std              0.198872
evaluation/Actions Max              0.999377
evaluation/Actions Min             -0.998462
evaluation/Num Paths               15
evaluation/Average Returns        -70.8946
time/data storing (s)               0.00363507
time/evaluation sampling (s)        0.37175
time/exploration sampling (s)       0.164254
time/logging (s)                    0.0047837
time/saving (s)                     0.00203032
time/training (s)                   2.06247
time/epoch (s)                      2.60893
time/total (s)                    352.067
Epoch                             131
-----------------------------  ---------------
2019-04-22 22:15:52.858373 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 132 finished
-----------------------------  ---------------
replay_buffer/size              66700
trainer/QF1 Loss                  156.274
trainer/QF2 Loss                  156.588
trainer/Policy Loss                48.8595
trainer/Q1 Predictions Mean       -47.7577
trainer/Q1 Predictions Std         38.5386
trainer/Q1 Predictions Max        -16.2002
trainer/Q1 Predictions Min       -117.71
trainer/Q2 Predictions Mean       -47.761
trainer/Q2 Predictions Std         38.5295
trainer/Q2 Predictions Max        -16.2674
trainer/Q2 Predictions Min       -118.59
trainer/Q Targets Mean            -46.8003
trainer/Q Targets Std              39.3535
trainer/Q Targets Max              -1.55641
trainer/Q Targets Min            -119.808
trainer/Log Pis Mean                1.85965
trainer/Log Pis Std                 1.55397
trainer/Log Pis Max                 6.58627
trainer/Log Pis Min                -6.58721
trainer/Policy mu Mean              0.0999251
trainer/Policy mu Std               0.829516
trainer/Policy mu Max               2.59071
trainer/Policy mu Min              -2.90757
trainer/Policy log std Mean        -1.80978
trainer/Policy log std Std          0.576081
trainer/Policy log std Max         -0.41814
trainer/Policy log std Min         -2.93313
trainer/Alpha                       0.0791882
trainer/Alpha Loss                 -0.35591
exploration/num steps total     66700
exploration/num paths total       667
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.0711
exploration/Rewards Std             1.23307
exploration/Rewards Max            -0.0400709
exploration/Rewards Min           -10.708
exploration/Returns Mean         -107.11
exploration/Returns Std            54.0851
exploration/Returns Max           -34.8891
exploration/Returns Min          -178.105
exploration/Actions Mean            0.0173832
exploration/Actions Std             0.263113
exploration/Actions Max             0.999758
exploration/Actions Min            -0.999873
exploration/Num Paths               5
exploration/Average Returns      -107.11
evaluation/num steps total     199500
evaluation/num paths total       1995
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.478719
evaluation/Rewards Std              0.913014
evaluation/Rewards Max             -0.171535
evaluation/Rewards Min             -9.91241
evaluation/Returns Mean           -47.8719
evaluation/Returns Std             20.967
evaluation/Returns Max            -24.1397
evaluation/Returns Min           -103.46
evaluation/Actions Mean            -0.0213488
evaluation/Actions Std              0.176745
evaluation/Actions Max              0.989864
evaluation/Actions Min             -0.999537
evaluation/Num Paths               15
evaluation/Average Returns        -47.8719
time/data storing (s)               0.00321397
time/evaluation sampling (s)        0.345914
time/exploration sampling (s)       0.156538
time/logging (s)                    0.00490046
time/saving (s)                     0.00196462
time/training (s)                   2.07152
time/epoch (s)                      2.58405
time/total (s)                    354.655
Epoch                             132
-----------------------------  ---------------
2019-04-22 22:15:55.462121 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 133 finished
-----------------------------  ---------------
replay_buffer/size              67200
trainer/QF1 Loss                    0.690255
trainer/QF2 Loss                    0.752029
trainer/Policy Loss                50.398
trainer/Q1 Predictions Mean       -49.2472
trainer/Q1 Predictions Std         38.5043
trainer/Q1 Predictions Max        -15.965
trainer/Q1 Predictions Min       -125.183
trainer/Q2 Predictions Mean       -49.2442
trainer/Q2 Predictions Std         38.5089
trainer/Q2 Predictions Max        -16.0723
trainer/Q2 Predictions Min       -124.291
trainer/Q Targets Mean            -49.7975
trainer/Q Targets Std              38.7343
trainer/Q Targets Max             -16.2545
trainer/Q Targets Min            -127.152
trainer/Log Pis Mean                2.11107
trainer/Log Pis Std                 1.42185
trainer/Log Pis Max                 6.40537
trainer/Log Pis Min                -1.79221
trainer/Policy mu Mean              0.162682
trainer/Policy mu Std               0.963475
trainer/Policy mu Max               3.17067
trainer/Policy mu Min              -3.05816
trainer/Policy log std Mean        -1.83834
trainer/Policy log std Std          0.656732
trainer/Policy log std Max         -0.247281
trainer/Policy log std Min         -2.94064
trainer/Alpha                       0.0789105
trainer/Alpha Loss                  0.282053
exploration/num steps total     67200
exploration/num paths total       672
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.889813
exploration/Rewards Std             1.29564
exploration/Rewards Max            -0.0213907
exploration/Rewards Min            -8.67256
exploration/Returns Mean          -88.9813
exploration/Returns Std            63.7902
exploration/Returns Max           -29.1006
exploration/Returns Min          -210.541
exploration/Actions Mean            0.0245169
exploration/Actions Std             0.259585
exploration/Actions Max             0.996854
exploration/Actions Min            -0.999255
exploration/Num Paths               5
exploration/Average Returns       -88.9813
evaluation/num steps total     201000
evaluation/num paths total       2010
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.642668
evaluation/Rewards Std              0.894355
evaluation/Rewards Max             -0.0048839
evaluation/Rewards Min             -9.57603
evaluation/Returns Mean           -64.2668
evaluation/Returns Std             49.0642
evaluation/Returns Max            -17.7374
evaluation/Returns Min           -179.787
evaluation/Actions Mean             0.00182026
evaluation/Actions Std              0.166653
evaluation/Actions Max              0.996317
evaluation/Actions Min             -0.998756
evaluation/Num Paths               15
evaluation/Average Returns        -64.2668
time/data storing (s)               0.00375698
time/evaluation sampling (s)        0.350495
time/exploration sampling (s)       0.159587
time/logging (s)                    0.00489914
time/saving (s)                     0.00194256
time/training (s)                   2.07624
time/epoch (s)                      2.59692
time/total (s)                    357.256
Epoch                             133
-----------------------------  ---------------
2019-04-22 22:15:58.055148 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 134 finished
-----------------------------  ---------------
replay_buffer/size              67700
trainer/QF1 Loss                  107.097
trainer/QF2 Loss                  107.448
trainer/Policy Loss                49.7386
trainer/Q1 Predictions Mean       -48.7441
trainer/Q1 Predictions Std         38.133
trainer/Q1 Predictions Max        -16.1483
trainer/Q1 Predictions Min       -125.093
trainer/Q2 Predictions Mean       -48.7074
trainer/Q2 Predictions Std         38.1109
trainer/Q2 Predictions Max        -16.2396
trainer/Q2 Predictions Min       -124.359
trainer/Q Targets Mean            -47.9636
trainer/Q Targets Std              38.1819
trainer/Q Targets Max              -3.19583
trainer/Q Targets Min            -127.149
trainer/Log Pis Mean                1.66911
trainer/Log Pis Std                 1.2729
trainer/Log Pis Max                 5.16552
trainer/Log Pis Min                -1.89484
trainer/Policy mu Mean              0.0562493
trainer/Policy mu Std               0.875782
trainer/Policy mu Max               2.65402
trainer/Policy mu Min              -2.74998
trainer/Policy log std Mean        -1.79961
trainer/Policy log std Std          0.58776
trainer/Policy log std Max         -0.51614
trainer/Policy log std Min         -3.07126
trainer/Alpha                       0.0759187
trainer/Alpha Loss                 -0.853029
exploration/num steps total     67700
exploration/num paths total       677
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.918504
exploration/Rewards Std             1.24504
exploration/Rewards Max            -0.0887083
exploration/Rewards Min            -9.47465
exploration/Returns Mean          -91.8504
exploration/Returns Std            61.5435
exploration/Returns Max           -23.4377
exploration/Returns Min          -207.481
exploration/Actions Mean           -0.0101996
exploration/Actions Std             0.2518
exploration/Actions Max             0.998574
exploration/Actions Min            -0.99876
exploration/Num Paths               5
exploration/Average Returns       -91.8504
evaluation/num steps total     202500
evaluation/num paths total       2025
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.853633
evaluation/Rewards Std              1.18527
evaluation/Rewards Max             -0.114347
evaluation/Rewards Min            -10.545
evaluation/Returns Mean           -85.3633
evaluation/Returns Std             67.2352
evaluation/Returns Max            -22.0514
evaluation/Returns Min           -204.038
evaluation/Actions Mean             0.0136858
evaluation/Actions Std              0.191732
evaluation/Actions Max              0.996366
evaluation/Actions Min             -0.9984
evaluation/Num Paths               15
evaluation/Average Returns        -85.3633
time/data storing (s)               0.00312786
time/evaluation sampling (s)        0.341812
time/exploration sampling (s)       0.155949
time/logging (s)                    0.00480713
time/saving (s)                     0.0022489
time/training (s)                   2.07847
time/epoch (s)                      2.58642
time/total (s)                    359.846
Epoch                             134
-----------------------------  ---------------
2019-04-22 22:16:00.656197 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 135 finished
-----------------------------  ---------------
replay_buffer/size              68200
trainer/QF1 Loss                    4.72612
trainer/QF2 Loss                    4.38448
trainer/Policy Loss                49.2146
trainer/Q1 Predictions Mean       -48.0237
trainer/Q1 Predictions Std         36.2441
trainer/Q1 Predictions Max        -16.11
trainer/Q1 Predictions Min       -111.006
trainer/Q2 Predictions Mean       -48.086
trainer/Q2 Predictions Std         36.2792
trainer/Q2 Predictions Max        -16.1883
trainer/Q2 Predictions Min       -111.485
trainer/Q Targets Mean            -48.6848
trainer/Q Targets Std              37.14
trainer/Q Targets Max              -2.38283
trainer/Q Targets Min            -111.981
trainer/Log Pis Mean                1.79778
trainer/Log Pis Std                 1.45188
trainer/Log Pis Max                 9.26904
trainer/Log Pis Min                -1.86149
trainer/Policy mu Mean              0.196472
trainer/Policy mu Std               0.837459
trainer/Policy mu Max               3.22235
trainer/Policy mu Min              -2.82116
trainer/Policy log std Mean        -1.82267
trainer/Policy log std Std          0.586635
trainer/Policy log std Max         -0.40811
trainer/Policy log std Min         -2.95988
trainer/Alpha                       0.0772159
trainer/Alpha Loss                 -0.517931
exploration/num steps total     68200
exploration/num paths total       682
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.14336
exploration/Rewards Std             1.10253
exploration/Rewards Max            -0.0813945
exploration/Rewards Min            -9.54644
exploration/Returns Mean         -114.336
exploration/Returns Std            46.4159
exploration/Returns Max           -65.0352
exploration/Returns Min          -171.982
exploration/Actions Mean            0.0302282
exploration/Actions Std             0.220657
exploration/Actions Max             0.99935
exploration/Actions Min            -0.944859
exploration/Num Paths               5
exploration/Average Returns      -114.336
evaluation/num steps total     204000
evaluation/num paths total       2040
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.01391
evaluation/Rewards Std              1.02729
evaluation/Rewards Max             -0.179807
evaluation/Rewards Min             -8.45092
evaluation/Returns Mean          -101.391
evaluation/Returns Std             61.7635
evaluation/Returns Max            -24.8073
evaluation/Returns Min           -189.13
evaluation/Actions Mean             0.0132405
evaluation/Actions Std              0.1924
evaluation/Actions Max              0.996793
evaluation/Actions Min             -0.998037
evaluation/Num Paths               15
evaluation/Average Returns       -101.391
time/data storing (s)               0.00310166
time/evaluation sampling (s)        0.349925
time/exploration sampling (s)       0.159491
time/logging (s)                    0.00489196
time/saving (s)                     0.00215729
time/training (s)                   2.07495
time/epoch (s)                      2.59452
time/total (s)                    362.445
Epoch                             135
-----------------------------  ---------------
2019-04-22 22:16:03.268900 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 136 finished
-----------------------------  ---------------
replay_buffer/size              68700
trainer/QF1 Loss                    1.58379
trainer/QF2 Loss                    1.55808
trainer/Policy Loss                50.8996
trainer/Q1 Predictions Mean       -49.722
trainer/Q1 Predictions Std         37.7139
trainer/Q1 Predictions Max        -15.95
trainer/Q1 Predictions Min       -136.358
trainer/Q2 Predictions Mean       -49.6969
trainer/Q2 Predictions Std         37.6774
trainer/Q2 Predictions Max        -16.0295
trainer/Q2 Predictions Min       -134.084
trainer/Q Targets Mean            -50.3957
trainer/Q Targets Std              38.4437
trainer/Q Targets Max             -15.9872
trainer/Q Targets Min            -138.235
trainer/Log Pis Mean                2.31599
trainer/Log Pis Std                 1.48536
trainer/Log Pis Max                 9.39413
trainer/Log Pis Min                -1.01344
trainer/Policy mu Mean              0.0660876
trainer/Policy mu Std               0.997603
trainer/Policy mu Max               3.13602
trainer/Policy mu Min              -3.08411
trainer/Policy log std Mean        -1.85963
trainer/Policy log std Std          0.702191
trainer/Policy log std Max         -0.342853
trainer/Policy log std Min         -3.07905
trainer/Alpha                       0.0765571
trainer/Alpha Loss                  0.812048
exploration/num steps total     68700
exploration/num paths total       687
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.557127
exploration/Rewards Std             0.719813
exploration/Rewards Max            -0.0303851
exploration/Rewards Min            -7.17372
exploration/Returns Mean          -55.7127
exploration/Returns Std            26.3652
exploration/Returns Max           -19.5285
exploration/Returns Min           -81.2678
exploration/Actions Mean           -0.00776041
exploration/Actions Std             0.210208
exploration/Actions Max             0.99964
exploration/Actions Min            -0.997117
exploration/Num Paths               5
exploration/Average Returns       -55.7127
evaluation/num steps total     205500
evaluation/num paths total       2055
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.52657
evaluation/Rewards Std              1.12217
evaluation/Rewards Max             -0.0244813
evaluation/Rewards Min            -11.4737
evaluation/Returns Mean           -52.657
evaluation/Returns Std             42.3996
evaluation/Returns Max            -12.5102
evaluation/Returns Min           -188.996
evaluation/Actions Mean            -0.0028766
evaluation/Actions Std              0.188595
evaluation/Actions Max              0.998504
evaluation/Actions Min             -0.997915
evaluation/Num Paths               15
evaluation/Average Returns        -52.657
time/data storing (s)               0.00303917
time/evaluation sampling (s)        0.353235
time/exploration sampling (s)       0.160449
time/logging (s)                    0.00384628
time/saving (s)                     0.00190926
time/training (s)                   2.08253
time/epoch (s)                      2.60501
time/total (s)                    365.055
Epoch                             136
-----------------------------  ---------------
2019-04-22 22:16:05.862693 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 137 finished
-----------------------------  ---------------
replay_buffer/size              69200
trainer/QF1 Loss                    0.199608
trainer/QF2 Loss                    0.294069
trainer/Policy Loss                49.6673
trainer/Q1 Predictions Mean       -48.6303
trainer/Q1 Predictions Std         34.6954
trainer/Q1 Predictions Max        -15.9615
trainer/Q1 Predictions Min       -123.341
trainer/Q2 Predictions Mean       -48.593
trainer/Q2 Predictions Std         34.6359
trainer/Q2 Predictions Max        -16.0588
trainer/Q2 Predictions Min       -122.318
trainer/Q Targets Mean            -48.6814
trainer/Q Targets Std              34.8151
trainer/Q Targets Max             -15.9185
trainer/Q Targets Min            -124.602
trainer/Log Pis Mean                1.73057
trainer/Log Pis Std                 1.41861
trainer/Log Pis Max                 5.00375
trainer/Log Pis Min                -6.25183
trainer/Policy mu Mean             -0.0620744
trainer/Policy mu Std               0.860594
trainer/Policy mu Max               2.69642
trainer/Policy mu Min              -2.79807
trainer/Policy log std Mean        -1.80157
trainer/Policy log std Std          0.600856
trainer/Policy log std Max         -0.047272
trainer/Policy log std Min         -3.05316
trainer/Alpha                       0.0772655
trainer/Alpha Loss                 -0.689809
exploration/num steps total     69200
exploration/num paths total       692
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.472357
exploration/Rewards Std             0.395965
exploration/Rewards Max            -0.00520877
exploration/Rewards Min            -4.97017
exploration/Returns Mean          -47.2357
exploration/Returns Std             8.36144
exploration/Returns Max           -38.0086
exploration/Returns Min           -58.6514
exploration/Actions Mean           -0.00695935
exploration/Actions Std             0.211375
exploration/Actions Max             0.970643
exploration/Actions Min            -0.998703
exploration/Num Paths               5
exploration/Average Returns       -47.2357
evaluation/num steps total     207000
evaluation/num paths total       2070
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.19946
evaluation/Rewards Std              1.21153
evaluation/Rewards Max             -0.107395
evaluation/Rewards Min            -10.2071
evaluation/Returns Mean          -119.946
evaluation/Returns Std             65.6984
evaluation/Returns Max            -35.7088
evaluation/Returns Min           -211.969
evaluation/Actions Mean             0.0124762
evaluation/Actions Std              0.20002
evaluation/Actions Max              0.996366
evaluation/Actions Min             -0.998466
evaluation/Num Paths               15
evaluation/Average Returns       -119.946
time/data storing (s)               0.00366871
time/evaluation sampling (s)        0.346318
time/exploration sampling (s)       0.155582
time/logging (s)                    0.00475404
time/saving (s)                     0.00156742
time/training (s)                   2.07596
time/epoch (s)                      2.58785
time/total (s)                    367.647
Epoch                             137
-----------------------------  ---------------
2019-04-22 22:16:08.508604 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 138 finished
-----------------------------  ---------------
replay_buffer/size              69700
trainer/QF1 Loss                    0.454147
trainer/QF2 Loss                    0.484867
trainer/Policy Loss                52.5449
trainer/Q1 Predictions Mean       -51.4864
trainer/Q1 Predictions Std         38.7568
trainer/Q1 Predictions Max        -15.7418
trainer/Q1 Predictions Min       -120.706
trainer/Q2 Predictions Mean       -51.47
trainer/Q2 Predictions Std         38.6811
trainer/Q2 Predictions Max        -15.8286
trainer/Q2 Predictions Min       -121.278
trainer/Q Targets Mean            -51.9137
trainer/Q Targets Std              38.9614
trainer/Q Targets Max             -15.8568
trainer/Q Targets Min            -121.101
trainer/Log Pis Mean                1.79028
trainer/Log Pis Std                 1.36317
trainer/Log Pis Max                 5.16195
trainer/Log Pis Min                -4.05853
trainer/Policy mu Mean              0.112535
trainer/Policy mu Std               0.892096
trainer/Policy mu Max               2.81708
trainer/Policy mu Min              -2.97301
trainer/Policy log std Mean        -1.79261
trainer/Policy log std Std          0.569601
trainer/Policy log std Max         -0.504247
trainer/Policy log std Min         -2.94053
trainer/Alpha                       0.0765183
trainer/Alpha Loss                 -0.539045
exploration/num steps total     69700
exploration/num paths total       697
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.631155
exploration/Rewards Std             0.961157
exploration/Rewards Max            -0.00240945
exploration/Rewards Min            -8.53753
exploration/Returns Mean          -63.1155
exploration/Returns Std            44.6338
exploration/Returns Max           -20.3395
exploration/Returns Min          -147.041
exploration/Actions Mean           -0.00610041
exploration/Actions Std             0.223532
exploration/Actions Max             0.994497
exploration/Actions Min            -0.997912
exploration/Num Paths               5
exploration/Average Returns       -63.1155
evaluation/num steps total     208500
evaluation/num paths total       2085
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.757204
evaluation/Rewards Std              0.951126
evaluation/Rewards Max             -0.0639659
evaluation/Rewards Min            -10.5592
evaluation/Returns Mean           -75.7204
evaluation/Returns Std             55.6095
evaluation/Returns Max             -7.14762
evaluation/Returns Min           -158.199
evaluation/Actions Mean             0.00411863
evaluation/Actions Std              0.160792
evaluation/Actions Max              0.99491
evaluation/Actions Min             -0.998361
evaluation/Num Paths               15
evaluation/Average Returns        -75.7204
time/data storing (s)               0.00304193
time/evaluation sampling (s)        0.347289
time/exploration sampling (s)       0.156338
time/logging (s)                    0.00477539
time/saving (s)                     0.00196503
time/training (s)                   2.12572
time/epoch (s)                      2.63912
time/total (s)                    370.29
Epoch                             138
-----------------------------  ---------------
2019-04-22 22:16:11.105750 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 139 finished
-----------------------------  ----------------
replay_buffer/size              70200
trainer/QF1 Loss                    6.13579
trainer/QF2 Loss                    6.18507
trainer/Policy Loss                44.2921
trainer/Q1 Predictions Mean       -42.9484
trainer/Q1 Predictions Std         33.5184
trainer/Q1 Predictions Max        -15.532
trainer/Q1 Predictions Min       -111.028
trainer/Q2 Predictions Mean       -42.8816
trainer/Q2 Predictions Std         33.5052
trainer/Q2 Predictions Max        -15.6394
trainer/Q2 Predictions Min       -111.347
trainer/Q Targets Mean            -43.729
trainer/Q Targets Std              34.6023
trainer/Q Targets Max              -0.462391
trainer/Q Targets Min            -114.102
trainer/Log Pis Mean                1.86607
trainer/Log Pis Std                 1.3433
trainer/Log Pis Max                 4.91731
trainer/Log Pis Min                -1.9871
trainer/Policy mu Mean             -0.0423368
trainer/Policy mu Std               0.722564
trainer/Policy mu Max               2.34609
trainer/Policy mu Min              -3.02857
trainer/Policy log std Mean        -2.01513
trainer/Policy log std Std          0.59676
trainer/Policy log std Max         -0.290387
trainer/Policy log std Min         -3.10339
trainer/Alpha                       0.0778534
trainer/Alpha Loss                 -0.341937
exploration/num steps total     70200
exploration/num paths total       702
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.956452
exploration/Rewards Std             1.0128
exploration/Rewards Max            -0.0213777
exploration/Rewards Min            -7.91514
exploration/Returns Mean          -95.6452
exploration/Returns Std            69.5975
exploration/Returns Max           -20.3628
exploration/Returns Min          -185.844
exploration/Actions Mean            0.0270103
exploration/Actions Std             0.236856
exploration/Actions Max             0.997148
exploration/Actions Min            -0.997958
exploration/Num Paths               5
exploration/Average Returns       -95.6452
evaluation/num steps total     210000
evaluation/num paths total       2100
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.746794
evaluation/Rewards Std              0.935668
evaluation/Rewards Max             -0.0378143
evaluation/Rewards Min             -8.67995
evaluation/Returns Mean           -74.6794
evaluation/Returns Std             60.2518
evaluation/Returns Max            -14.6474
evaluation/Returns Min           -179.323
evaluation/Actions Mean            -0.000611646
evaluation/Actions Std              0.166391
evaluation/Actions Max              0.989371
evaluation/Actions Min             -0.999127
evaluation/Num Paths               15
evaluation/Average Returns        -74.6794
time/data storing (s)               0.00313956
time/evaluation sampling (s)        0.349658
time/exploration sampling (s)       0.159893
time/logging (s)                    0.00506764
time/saving (s)                     0.00194401
time/training (s)                   2.07097
time/epoch (s)                      2.59067
time/total (s)                    372.885
Epoch                             139
-----------------------------  ----------------
2019-04-22 22:16:14.040874 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 140 finished
-----------------------------  ---------------
replay_buffer/size              70700
trainer/QF1 Loss                   75.6838
trainer/QF2 Loss                   75.6094
trainer/Policy Loss                44.0842
trainer/Q1 Predictions Mean       -42.8078
trainer/Q1 Predictions Std         35.3574
trainer/Q1 Predictions Max        -15.6604
trainer/Q1 Predictions Min       -117.669
trainer/Q2 Predictions Mean       -42.7963
trainer/Q2 Predictions Std         35.3602
trainer/Q2 Predictions Max        -15.7316
trainer/Q2 Predictions Min       -117.557
trainer/Q Targets Mean            -41.9373
trainer/Q Targets Std              36.3363
trainer/Q Targets Max              -0.298256
trainer/Q Targets Min            -119.269
trainer/Log Pis Mean                2.09811
trainer/Log Pis Std                 1.2801
trainer/Log Pis Max                 6.31516
trainer/Log Pis Min                -2.06867
trainer/Policy mu Mean              0.0774948
trainer/Policy mu Std               0.918855
trainer/Policy mu Max               3.12528
trainer/Policy mu Min              -2.48526
trainer/Policy log std Mean        -1.81206
trainer/Policy log std Std          0.670728
trainer/Policy log std Max         -0.447133
trainer/Policy log std Min         -3.03369
trainer/Alpha                       0.0782809
trainer/Alpha Loss                  0.249943
exploration/num steps total     70700
exploration/num paths total       707
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.840374
exploration/Rewards Std             1.03817
exploration/Rewards Max            -0.0202806
exploration/Rewards Min           -10.8831
exploration/Returns Mean          -84.0374
exploration/Returns Std            63.465
exploration/Returns Max           -22.2492
exploration/Returns Min          -181.43
exploration/Actions Mean            0.0189994
exploration/Actions Std             0.253738
exploration/Actions Max             0.999628
exploration/Actions Min            -0.978724
exploration/Num Paths               5
exploration/Average Returns       -84.0374
evaluation/num steps total     211500
evaluation/num paths total       2115
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.573669
evaluation/Rewards Std              0.871061
evaluation/Rewards Max             -0.0317688
evaluation/Rewards Min            -10.2037
evaluation/Returns Mean           -57.3669
evaluation/Returns Std             42.0222
evaluation/Returns Max            -11.0967
evaluation/Returns Min           -136.013
evaluation/Actions Mean            -0.00193535
evaluation/Actions Std              0.166945
evaluation/Actions Max              0.997223
evaluation/Actions Min             -0.99941
evaluation/Num Paths               15
evaluation/Average Returns        -57.3669
time/data storing (s)               0.00420874
time/evaluation sampling (s)        0.378607
time/exploration sampling (s)       0.21399
time/logging (s)                    0.00480514
time/saving (s)                     0.0118175
time/training (s)                   2.31468
time/epoch (s)                      2.92811
time/total (s)                    375.817
Epoch                             140
-----------------------------  ---------------
2019-04-22 22:16:17.049541 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 141 finished
-----------------------------  ---------------
replay_buffer/size              71200
trainer/QF1 Loss                    6.51091
trainer/QF2 Loss                    6.93217
trainer/Policy Loss                46.5509
trainer/Q1 Predictions Mean       -45.609
trainer/Q1 Predictions Std         36.1377
trainer/Q1 Predictions Max        -15.7743
trainer/Q1 Predictions Min       -110.03
trainer/Q2 Predictions Mean       -45.652
trainer/Q2 Predictions Std         36.2021
trainer/Q2 Predictions Max        -15.8386
trainer/Q2 Predictions Min       -110.975
trainer/Q Targets Mean            -45.9367
trainer/Q Targets Std              36.8716
trainer/Q Targets Max              -3.0163
trainer/Q Targets Min            -110.487
trainer/Log Pis Mean                1.69178
trainer/Log Pis Std                 1.42649
trainer/Log Pis Max                 5.64946
trainer/Log Pis Min                -3.25048
trainer/Policy mu Mean              0.233239
trainer/Policy mu Std               0.877324
trainer/Policy mu Max               2.62157
trainer/Policy mu Min              -2.20568
trainer/Policy log std Mean        -1.75428
trainer/Policy log std Std          0.654201
trainer/Policy log std Max         -0.413361
trainer/Policy log std Min         -3.05876
trainer/Alpha                       0.0820301
trainer/Alpha Loss                 -0.770764
exploration/num steps total     71200
exploration/num paths total       712
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.80048
exploration/Rewards Std             1.03702
exploration/Rewards Max            -0.0124629
exploration/Rewards Min            -8.5228
exploration/Returns Mean          -80.048
exploration/Returns Std            40.113
exploration/Returns Max           -21.2329
exploration/Returns Min          -140.701
exploration/Actions Mean           -0.0127551
exploration/Actions Std             0.220851
exploration/Actions Max             0.997514
exploration/Actions Min            -0.999556
exploration/Num Paths               5
exploration/Average Returns       -80.048
evaluation/num steps total     213000
evaluation/num paths total       2130
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.598791
evaluation/Rewards Std              1.11123
evaluation/Rewards Max             -0.0155013
evaluation/Rewards Min            -10.244
evaluation/Returns Mean           -59.8791
evaluation/Returns Std             49.9131
evaluation/Returns Max             -2.08153
evaluation/Returns Min           -186.388
evaluation/Actions Mean            -0.00957412
evaluation/Actions Std              0.18546
evaluation/Actions Max              0.998147
evaluation/Actions Min             -0.9985
evaluation/Num Paths               15
evaluation/Average Returns        -59.8791
time/data storing (s)               0.00312518
time/evaluation sampling (s)        0.398766
time/exploration sampling (s)       0.202226
time/logging (s)                    0.00445664
time/saving (s)                     0.00225743
time/training (s)                   2.38999
time/epoch (s)                      3.00082
time/total (s)                    378.823
Epoch                             141
-----------------------------  ---------------
2019-04-22 22:16:19.945286 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 142 finished
-----------------------------  ---------------
replay_buffer/size              71700
trainer/QF1 Loss                    1.0175
trainer/QF2 Loss                    1.12434
trainer/Policy Loss                49.0606
trainer/Q1 Predictions Mean       -47.8569
trainer/Q1 Predictions Std         36.0376
trainer/Q1 Predictions Max        -15.5314
trainer/Q1 Predictions Min       -121.481
trainer/Q2 Predictions Mean       -47.8426
trainer/Q2 Predictions Std         36.0544
trainer/Q2 Predictions Max        -15.6152
trainer/Q2 Predictions Min       -120.687
trainer/Q Targets Mean            -48.6193
trainer/Q Targets Std              36.4894
trainer/Q Targets Max             -15.6585
trainer/Q Targets Min            -124.392
trainer/Log Pis Mean                2.18879
trainer/Log Pis Std                 1.4457
trainer/Log Pis Max                 6.7126
trainer/Log Pis Min                -2.79459
trainer/Policy mu Mean              0.225496
trainer/Policy mu Std               1.07269
trainer/Policy mu Max               3.12517
trainer/Policy mu Min              -2.93868
trainer/Policy log std Mean        -1.64622
trainer/Policy log std Std          0.655262
trainer/Policy log std Max         -0.320732
trainer/Policy log std Min         -2.96066
trainer/Alpha                       0.0835643
trainer/Alpha Loss                  0.468626
exploration/num steps total     71700
exploration/num paths total       717
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.676983
exploration/Rewards Std             0.695983
exploration/Rewards Max            -0.00214176
exploration/Rewards Min            -7.52106
exploration/Returns Mean          -67.6983
exploration/Returns Std            38.1431
exploration/Returns Max           -30.8637
exploration/Returns Min          -141.109
exploration/Actions Mean           -0.00551921
exploration/Actions Std             0.196258
exploration/Actions Max             0.999858
exploration/Actions Min            -0.999412
exploration/Num Paths               5
exploration/Average Returns       -67.6983
evaluation/num steps total     214500
evaluation/num paths total       2145
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.734621
evaluation/Rewards Std              1.03773
evaluation/Rewards Max             -0.0859228
evaluation/Rewards Min            -10.2635
evaluation/Returns Mean           -73.4621
evaluation/Returns Std             47.2583
evaluation/Returns Max            -27.281
evaluation/Returns Min           -172.006
evaluation/Actions Mean             0.00573843
evaluation/Actions Std              0.186689
evaluation/Actions Max              0.993029
evaluation/Actions Min             -0.998497
evaluation/Num Paths               15
evaluation/Average Returns        -73.4621
time/data storing (s)               0.00378059
time/evaluation sampling (s)        0.383319
time/exploration sampling (s)       0.180835
time/logging (s)                    0.00470765
time/saving (s)                     0.00214311
time/training (s)                   2.31374
time/epoch (s)                      2.88853
time/total (s)                    381.716
Epoch                             142
-----------------------------  ---------------
2019-04-22 22:16:22.793528 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 143 finished
-----------------------------  ---------------
replay_buffer/size              72200
trainer/QF1 Loss                  194.593
trainer/QF2 Loss                  194.69
trainer/Policy Loss                41.0669
trainer/Q1 Predictions Mean       -39.7878
trainer/Q1 Predictions Std         32.5785
trainer/Q1 Predictions Max        -15.5015
trainer/Q1 Predictions Min       -121.198
trainer/Q2 Predictions Mean       -39.7865
trainer/Q2 Predictions Std         32.5379
trainer/Q2 Predictions Max        -15.5058
trainer/Q2 Predictions Min       -120.401
trainer/Q Targets Mean            -38.1176
trainer/Q Targets Std              32.283
trainer/Q Targets Max              -1.76577
trainer/Q Targets Min            -120.683
trainer/Log Pis Mean                2.13316
trainer/Log Pis Std                 1.59555
trainer/Log Pis Max                 6.58514
trainer/Log Pis Min                -2.95201
trainer/Policy mu Mean              0.0761464
trainer/Policy mu Std               1.02145
trainer/Policy mu Max               2.64388
trainer/Policy mu Min              -3.15414
trainer/Policy log std Mean        -1.76435
trainer/Policy log std Std          0.674689
trainer/Policy log std Max         -0.447567
trainer/Policy log std Min         -3.06343
trainer/Alpha                       0.0799099
trainer/Alpha Loss                  0.336461
exploration/num steps total     72200
exploration/num paths total       722
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.500507
exploration/Rewards Std             1.24929
exploration/Rewards Max            -0.0246116
exploration/Rewards Min           -11.2248
exploration/Returns Mean          -50.0507
exploration/Returns Std            20.3253
exploration/Returns Max           -25.7923
exploration/Returns Min           -77.7135
exploration/Actions Mean           -0.0315611
exploration/Actions Std             0.239709
exploration/Actions Max             0.994542
exploration/Actions Min            -0.999694
exploration/Num Paths               5
exploration/Average Returns       -50.0507
evaluation/num steps total     216000
evaluation/num paths total       2160
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.748452
evaluation/Rewards Std              0.982953
evaluation/Rewards Max             -0.0166176
evaluation/Rewards Min            -10.5227
evaluation/Returns Mean           -74.8452
evaluation/Returns Std             49.2654
evaluation/Returns Max             -8.99331
evaluation/Returns Min           -156.896
evaluation/Actions Mean             0.00676228
evaluation/Actions Std              0.182823
evaluation/Actions Max              0.996777
evaluation/Actions Min             -0.997275
evaluation/Num Paths               15
evaluation/Average Returns        -74.8452
time/data storing (s)               0.00371696
time/evaluation sampling (s)        0.392826
time/exploration sampling (s)       0.180848
time/logging (s)                    0.00509807
time/saving (s)                     0.00197654
time/training (s)                   2.25679
time/epoch (s)                      2.84126
time/total (s)                    384.562
Epoch                             143
-----------------------------  ---------------
2019-04-22 22:16:25.774926 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 144 finished
-----------------------------  ---------------
replay_buffer/size              72700
trainer/QF1 Loss                    3.09148
trainer/QF2 Loss                    3.17893
trainer/Policy Loss                42.567
trainer/Q1 Predictions Mean       -41.167
trainer/Q1 Predictions Std         33.4295
trainer/Q1 Predictions Max        -15.433
trainer/Q1 Predictions Min       -118.616
trainer/Q2 Predictions Mean       -41.1297
trainer/Q2 Predictions Std         33.4229
trainer/Q2 Predictions Max        -15.4061
trainer/Q2 Predictions Min       -118.105
trainer/Q Targets Mean            -41.56
trainer/Q Targets Std              34.135
trainer/Q Targets Max              -0.179762
trainer/Q Targets Min            -120.466
trainer/Log Pis Mean                2.06759
trainer/Log Pis Std                 1.35083
trainer/Log Pis Max                 6.89097
trainer/Log Pis Min                -4.05319
trainer/Policy mu Mean              0.154185
trainer/Policy mu Std               0.864894
trainer/Policy mu Max               3.35225
trainer/Policy mu Min              -2.50685
trainer/Policy log std Mean        -1.86183
trainer/Policy log std Std          0.647977
trainer/Policy log std Max         -0.463027
trainer/Policy log std Min         -2.93798
trainer/Alpha                       0.0799196
trainer/Alpha Loss                  0.170771
exploration/num steps total     72700
exploration/num paths total       727
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.517924
exploration/Rewards Std             0.701918
exploration/Rewards Max            -0.005568
exploration/Rewards Min            -5.60211
exploration/Returns Mean          -51.7924
exploration/Returns Std            20.6083
exploration/Returns Max           -30.663
exploration/Returns Min           -80.8873
exploration/Actions Mean            0.0145675
exploration/Actions Std             0.213076
exploration/Actions Max             0.999207
exploration/Actions Min            -0.974498
exploration/Num Paths               5
exploration/Average Returns       -51.7924
evaluation/num steps total     217500
evaluation/num paths total       2175
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.652742
evaluation/Rewards Std              1.03594
evaluation/Rewards Max             -0.132193
evaluation/Rewards Min            -10.5596
evaluation/Returns Mean           -65.2742
evaluation/Returns Std             47.6707
evaluation/Returns Max            -17.1289
evaluation/Returns Min           -193.589
evaluation/Actions Mean            -0.00368704
evaluation/Actions Std              0.175233
evaluation/Actions Max              0.999158
evaluation/Actions Min             -0.997523
evaluation/Num Paths               15
evaluation/Average Returns        -65.2742
time/data storing (s)               0.00326772
time/evaluation sampling (s)        0.448656
time/exploration sampling (s)       0.187313
time/logging (s)                    0.00491026
time/saving (s)                     0.0022059
time/training (s)                   2.32756
time/epoch (s)                      2.97391
time/total (s)                    387.541
Epoch                             144
-----------------------------  ---------------
2019-04-22 22:16:28.577414 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 145 finished
-----------------------------  ---------------
replay_buffer/size              73200
trainer/QF1 Loss                    0.685012
trainer/QF2 Loss                    0.604844
trainer/Policy Loss                49.1459
trainer/Q1 Predictions Mean       -47.9231
trainer/Q1 Predictions Std         35.3159
trainer/Q1 Predictions Max        -15.177
trainer/Q1 Predictions Min       -103.192
trainer/Q2 Predictions Mean       -47.9722
trainer/Q2 Predictions Std         35.2869
trainer/Q2 Predictions Max        -15.2295
trainer/Q2 Predictions Min       -103.341
trainer/Q Targets Mean            -48.353
trainer/Q Targets Std              35.7635
trainer/Q Targets Max             -15.3961
trainer/Q Targets Min            -104.528
trainer/Log Pis Mean                1.90085
trainer/Log Pis Std                 1.40405
trainer/Log Pis Max                 7.38135
trainer/Log Pis Min                -3.89752
trainer/Policy mu Mean              0.195942
trainer/Policy mu Std               0.875079
trainer/Policy mu Max               2.88147
trainer/Policy mu Min              -2.83165
trainer/Policy log std Mean        -1.86247
trainer/Policy log std Std          0.614419
trainer/Policy log std Max         -0.392876
trainer/Policy log std Min         -2.89293
trainer/Alpha                       0.0794423
trainer/Alpha Loss                 -0.251139
exploration/num steps total     73200
exploration/num paths total       732
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.718225
exploration/Rewards Std             0.703936
exploration/Rewards Max            -0.0210776
exploration/Rewards Min            -6.45959
exploration/Returns Mean          -71.8225
exploration/Returns Std            50.0193
exploration/Returns Max           -23.7587
exploration/Returns Min          -160.643
exploration/Actions Mean           -0.00364715
exploration/Actions Std             0.200696
exploration/Actions Max             0.997941
exploration/Actions Min            -0.996966
exploration/Num Paths               5
exploration/Average Returns       -71.8225
evaluation/num steps total     219000
evaluation/num paths total       2190
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.719896
evaluation/Rewards Std              1.05055
evaluation/Rewards Max             -0.13956
evaluation/Rewards Min            -11.1027
evaluation/Returns Mean           -71.9896
evaluation/Returns Std             46.8706
evaluation/Returns Max            -16.6454
evaluation/Returns Min           -160.94
evaluation/Actions Mean            -0.0110016
evaluation/Actions Std              0.189154
evaluation/Actions Max              0.998039
evaluation/Actions Min             -0.997857
evaluation/Num Paths               15
evaluation/Average Returns        -71.9896
time/data storing (s)               0.00373568
time/evaluation sampling (s)        0.405521
time/exploration sampling (s)       0.197284
time/logging (s)                    0.00454198
time/saving (s)                     0.00193571
time/training (s)                   2.18124
time/epoch (s)                      2.79425
time/total (s)                    390.34
Epoch                             145
-----------------------------  ---------------
2019-04-22 22:16:31.195805 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 146 finished
-----------------------------  ---------------
replay_buffer/size              73700
trainer/QF1 Loss                    2.61633
trainer/QF2 Loss                    2.79491
trainer/Policy Loss                40.6762
trainer/Q1 Predictions Mean       -39.3887
trainer/Q1 Predictions Std         30.9291
trainer/Q1 Predictions Max        -15.4634
trainer/Q1 Predictions Min       -124.11
trainer/Q2 Predictions Mean       -39.3611
trainer/Q2 Predictions Std         30.8338
trainer/Q2 Predictions Max        -15.4327
trainer/Q2 Predictions Min       -121.97
trainer/Q Targets Mean            -39.4565
trainer/Q Targets Std              31.323
trainer/Q Targets Max              -0.24401
trainer/Q Targets Min            -125.612
trainer/Log Pis Mean                2.04638
trainer/Log Pis Std                 1.21636
trainer/Log Pis Max                 6.72748
trainer/Log Pis Min                -0.685444
trainer/Policy mu Mean              0.0356047
trainer/Policy mu Std               0.929136
trainer/Policy mu Max               2.79253
trainer/Policy mu Min              -2.82569
trainer/Policy log std Mean        -1.78888
trainer/Policy log std Std          0.608263
trainer/Policy log std Max         -0.440484
trainer/Policy log std Min         -2.85477
trainer/Alpha                       0.0794117
trainer/Alpha Loss                  0.11749
exploration/num steps total     73700
exploration/num paths total       737
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.544939
exploration/Rewards Std             1.23565
exploration/Rewards Max            -0.00745211
exploration/Rewards Min            -9.85922
exploration/Returns Mean          -54.4939
exploration/Returns Std            24.5248
exploration/Returns Max           -20.7204
exploration/Returns Min           -81.1261
exploration/Actions Mean           -0.0186967
exploration/Actions Std             0.225942
exploration/Actions Max             0.999381
exploration/Actions Min            -0.999231
exploration/Num Paths               5
exploration/Average Returns       -54.4939
evaluation/num steps total     220500
evaluation/num paths total       2205
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.57416
evaluation/Rewards Std              1.0779
evaluation/Rewards Max             -0.020802
evaluation/Rewards Min             -9.29722
evaluation/Returns Mean           -57.416
evaluation/Returns Std             51.0072
evaluation/Returns Max             -9.26729
evaluation/Returns Min           -186.154
evaluation/Actions Mean            -0.00921365
evaluation/Actions Std              0.183376
evaluation/Actions Max              0.994491
evaluation/Actions Min             -0.998168
evaluation/Num Paths               15
evaluation/Average Returns        -57.416
time/data storing (s)               0.00325324
time/evaluation sampling (s)        0.345874
time/exploration sampling (s)       0.158709
time/logging (s)                    0.00457525
time/saving (s)                     0.0016627
time/training (s)                   2.09718
time/epoch (s)                      2.61125
time/total (s)                    392.956
Epoch                             146
-----------------------------  ---------------
2019-04-22 22:16:33.809477 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 147 finished
-----------------------------  ---------------
replay_buffer/size              74200
trainer/QF1 Loss                    1.04221
trainer/QF2 Loss                    0.887725
trainer/Policy Loss                45.7679
trainer/Q1 Predictions Mean       -44.2915
trainer/Q1 Predictions Std         33.0883
trainer/Q1 Predictions Max        -15.3755
trainer/Q1 Predictions Min       -111.798
trainer/Q2 Predictions Mean       -44.3342
trainer/Q2 Predictions Std         33.1701
trainer/Q2 Predictions Max        -15.2945
trainer/Q2 Predictions Min       -111.751
trainer/Q Targets Mean            -44.736
trainer/Q Targets Std              33.4865
trainer/Q Targets Max             -15.2553
trainer/Q Targets Min            -112.875
trainer/Log Pis Mean                2.23223
trainer/Log Pis Std                 1.84886
trainer/Log Pis Max                 8.13953
trainer/Log Pis Min                -3.929
trainer/Policy mu Mean              0.144259
trainer/Policy mu Std               0.97322
trainer/Policy mu Max               3.13537
trainer/Policy mu Min              -3.16702
trainer/Policy log std Mean        -1.77205
trainer/Policy log std Std          0.639545
trainer/Policy log std Max         -0.370977
trainer/Policy log std Min         -2.76454
trainer/Alpha                       0.0785166
trainer/Alpha Loss                  0.590885
exploration/num steps total     74200
exploration/num paths total       742
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.492998
exploration/Rewards Std             0.946548
exploration/Rewards Max            -0.0186907
exploration/Rewards Min            -8.23362
exploration/Returns Mean          -49.2998
exploration/Returns Std            13.9096
exploration/Returns Max           -27.7985
exploration/Returns Min           -65.8148
exploration/Actions Mean           -0.00517742
exploration/Actions Std             0.238823
exploration/Actions Max             0.99893
exploration/Actions Min            -0.999869
exploration/Num Paths               5
exploration/Average Returns       -49.2998
evaluation/num steps total     222000
evaluation/num paths total       2220
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.908887
evaluation/Rewards Std              1.04339
evaluation/Rewards Max             -0.10106
evaluation/Rewards Min             -9.99066
evaluation/Returns Mean           -90.8887
evaluation/Returns Std             54.8796
evaluation/Returns Max            -25.3389
evaluation/Returns Min           -174.853
evaluation/Actions Mean             0.00511199
evaluation/Actions Std              0.184303
evaluation/Actions Max              0.997016
evaluation/Actions Min             -0.997712
evaluation/Num Paths               15
evaluation/Average Returns        -90.8887
time/data storing (s)               0.00326913
time/evaluation sampling (s)        0.34438
time/exploration sampling (s)       0.157398
time/logging (s)                    0.00510757
time/saving (s)                     0.00200071
time/training (s)                   2.0946
time/epoch (s)                      2.60675
time/total (s)                    395.568
Epoch                             147
-----------------------------  ---------------
2019-04-22 22:16:36.440535 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 148 finished
-----------------------------  ----------------
replay_buffer/size              74700
trainer/QF1 Loss                    4.47827
trainer/QF2 Loss                    4.54328
trainer/Policy Loss                40.6266
trainer/Q1 Predictions Mean       -39.5785
trainer/Q1 Predictions Std         30.8904
trainer/Q1 Predictions Max        -14.9007
trainer/Q1 Predictions Min       -117.501
trainer/Q2 Predictions Mean       -39.5388
trainer/Q2 Predictions Std         30.8609
trainer/Q2 Predictions Max        -14.8397
trainer/Q2 Predictions Min       -116.417
trainer/Q Targets Mean            -39.7919
trainer/Q Targets Std              31.3474
trainer/Q Targets Max              -0.266951
trainer/Q Targets Min            -118.197
trainer/Log Pis Mean                2.09045
trainer/Log Pis Std                 1.36096
trainer/Log Pis Max                 5.65567
trainer/Log Pis Min                -0.928243
trainer/Policy mu Mean              0.094089
trainer/Policy mu Std               0.951972
trainer/Policy mu Max               2.72455
trainer/Policy mu Min              -3.15106
trainer/Policy log std Mean        -1.87681
trainer/Policy log std Std          0.630262
trainer/Policy log std Max         -0.457165
trainer/Policy log std Min         -2.7413
trainer/Alpha                       0.0758949
trainer/Alpha Loss                  0.233237
exploration/num steps total     74700
exploration/num paths total       747
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.501325
exploration/Rewards Std             0.952844
exploration/Rewards Max            -0.0445426
exploration/Rewards Min            -9.91147
exploration/Returns Mean          -50.1325
exploration/Returns Std            20.0823
exploration/Returns Max           -19.6516
exploration/Returns Min           -77.083
exploration/Actions Mean            0.00717708
exploration/Actions Std             0.214507
exploration/Actions Max             0.998672
exploration/Actions Min            -0.997814
exploration/Num Paths               5
exploration/Average Returns       -50.1325
evaluation/num steps total     223500
evaluation/num paths total       2235
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.547561
evaluation/Rewards Std              0.949495
evaluation/Rewards Max             -0.100339
evaluation/Rewards Min            -11.4643
evaluation/Returns Mean           -54.7561
evaluation/Returns Std             47.9651
evaluation/Returns Max            -13.1041
evaluation/Returns Min           -153.733
evaluation/Actions Mean            -0.000232165
evaluation/Actions Std              0.170661
evaluation/Actions Max              0.997935
evaluation/Actions Min             -0.997765
evaluation/Num Paths               15
evaluation/Average Returns        -54.7561
time/data storing (s)               0.00316106
time/evaluation sampling (s)        0.349886
time/exploration sampling (s)       0.156976
time/logging (s)                    0.00481652
time/saving (s)                     0.0016576
time/training (s)                   2.10681
time/epoch (s)                      2.62331
time/total (s)                    398.196
Epoch                             148
-----------------------------  ----------------
2019-04-22 22:16:39.053761 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 149 finished
-----------------------------  ---------------
replay_buffer/size              75200
trainer/QF1 Loss                    0.814257
trainer/QF2 Loss                    0.722813
trainer/Policy Loss                43.2024
trainer/Q1 Predictions Mean       -42.3171
trainer/Q1 Predictions Std         32.931
trainer/Q1 Predictions Max        -15.2047
trainer/Q1 Predictions Min       -107.51
trainer/Q2 Predictions Mean       -42.3468
trainer/Q2 Predictions Std         32.9688
trainer/Q2 Predictions Max        -15.1634
trainer/Q2 Predictions Min       -108.178
trainer/Q Targets Mean            -42.8323
trainer/Q Targets Std              33.4006
trainer/Q Targets Max             -15.1068
trainer/Q Targets Min            -108.768
trainer/Log Pis Mean                2.00816
trainer/Log Pis Std                 1.55097
trainer/Log Pis Max                 7.2487
trainer/Log Pis Min                -4.2176
trainer/Policy mu Mean              0.178463
trainer/Policy mu Std               0.933178
trainer/Policy mu Max               2.9532
trainer/Policy mu Min              -3.29459
trainer/Policy log std Mean        -1.82922
trainer/Policy log std Std          0.635803
trainer/Policy log std Max         -0.256188
trainer/Policy log std Min         -2.74734
trainer/Alpha                       0.078572
trainer/Alpha Loss                  0.0207532
exploration/num steps total     75200
exploration/num paths total       752
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.741983
exploration/Rewards Std             0.600476
exploration/Rewards Max            -0.0127702
exploration/Rewards Min            -5.04125
exploration/Returns Mean          -74.1983
exploration/Returns Std            51.0496
exploration/Returns Max           -16.6885
exploration/Returns Min          -136.636
exploration/Actions Mean            0.0132728
exploration/Actions Std             0.202452
exploration/Actions Max             0.999065
exploration/Actions Min            -0.921652
exploration/Num Paths               5
exploration/Average Returns       -74.1983
evaluation/num steps total     225000
evaluation/num paths total       2250
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.496704
evaluation/Rewards Std              0.919935
evaluation/Rewards Max             -0.0871824
evaluation/Rewards Min            -11.0633
evaluation/Returns Mean           -49.6704
evaluation/Returns Std             40.4578
evaluation/Returns Max            -16.4316
evaluation/Returns Min           -148.388
evaluation/Actions Mean             0.0145331
evaluation/Actions Std              0.184327
evaluation/Actions Max              0.995265
evaluation/Actions Min             -0.98799
evaluation/Num Paths               15
evaluation/Average Returns        -49.6704
time/data storing (s)               0.00320614
time/evaluation sampling (s)        0.347302
time/exploration sampling (s)       0.160533
time/logging (s)                    0.00489677
time/saving (s)                     0.00207721
time/training (s)                   2.08807
time/epoch (s)                      2.60608
time/total (s)                    400.806
Epoch                             149
-----------------------------  ---------------
2019-04-22 22:16:41.669292 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 150 finished
-----------------------------  ---------------
replay_buffer/size              75700
trainer/QF1 Loss                   88.14
trainer/QF2 Loss                   88.2764
trainer/Policy Loss                51.0618
trainer/Q1 Predictions Mean       -50.0253
trainer/Q1 Predictions Std         35.5074
trainer/Q1 Predictions Max        -15.0521
trainer/Q1 Predictions Min       -110.354
trainer/Q2 Predictions Mean       -50.0227
trainer/Q2 Predictions Std         35.5071
trainer/Q2 Predictions Max        -14.9483
trainer/Q2 Predictions Min       -110.233
trainer/Q Targets Mean            -49.4553
trainer/Q Targets Std              35.6821
trainer/Q Targets Max              -3.47845
trainer/Q Targets Min            -110.564
trainer/Log Pis Mean                1.98544
trainer/Log Pis Std                 1.50607
trainer/Log Pis Max                 5.70448
trainer/Log Pis Min                -2.33452
trainer/Policy mu Mean              0.289883
trainer/Policy mu Std               0.94831
trainer/Policy mu Max               2.86754
trainer/Policy mu Min              -2.66174
trainer/Policy log std Mean        -1.75025
trainer/Policy log std Std          0.63146
trainer/Policy log std Max         -0.450282
trainer/Policy log std Min         -2.7854
trainer/Alpha                       0.0761461
trainer/Alpha Loss                 -0.0374938
exploration/num steps total     75700
exploration/num paths total       757
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.720129
exploration/Rewards Std             1.02498
exploration/Rewards Max            -0.0198048
exploration/Rewards Min            -8.03449
exploration/Returns Mean          -72.0129
exploration/Returns Std            50.3558
exploration/Returns Max           -37.7726
exploration/Returns Min          -172.233
exploration/Actions Mean            0.0130878
exploration/Actions Std             0.217459
exploration/Actions Max             0.996335
exploration/Actions Min            -0.99866
exploration/Num Paths               5
exploration/Average Returns       -72.0129
evaluation/num steps total     226500
evaluation/num paths total       2265
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.902044
evaluation/Rewards Std              1.11884
evaluation/Rewards Max             -0.108695
evaluation/Rewards Min            -10.926
evaluation/Returns Mean           -90.2044
evaluation/Returns Std             65.8687
evaluation/Returns Max            -19.8458
evaluation/Returns Min           -191.749
evaluation/Actions Mean            -0.012618
evaluation/Actions Std              0.173399
evaluation/Actions Max              0.99535
evaluation/Actions Min             -0.999275
evaluation/Num Paths               15
evaluation/Average Returns        -90.2044
time/data storing (s)               0.00326168
time/evaluation sampling (s)        0.360065
time/exploration sampling (s)       0.157385
time/logging (s)                    0.00515452
time/saving (s)                     0.00198555
time/training (s)                   2.08102
time/epoch (s)                      2.60888
time/total (s)                    403.419
Epoch                             150
-----------------------------  ---------------
2019-04-22 22:16:44.301481 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 151 finished
-----------------------------  ----------------
replay_buffer/size              76200
trainer/QF1 Loss                    1.21948
trainer/QF2 Loss                    1.26981
trainer/Policy Loss                42.9596
trainer/Q1 Predictions Mean       -42.0425
trainer/Q1 Predictions Std         31.3059
trainer/Q1 Predictions Max        -14.8918
trainer/Q1 Predictions Min       -104.532
trainer/Q2 Predictions Mean       -42.0087
trainer/Q2 Predictions Std         31.3578
trainer/Q2 Predictions Max        -14.808
trainer/Q2 Predictions Min       -105.291
trainer/Q Targets Mean            -42.8092
trainer/Q Targets Std              32.0115
trainer/Q Targets Max             -14.8722
trainer/Q Targets Min            -105.543
trainer/Log Pis Mean                1.53814
trainer/Log Pis Std                 1.7256
trainer/Log Pis Max                 8.73628
trainer/Log Pis Min                -4.81998
trainer/Policy mu Mean              0.125826
trainer/Policy mu Std               0.939959
trainer/Policy mu Max               3.57862
trainer/Policy mu Min              -3.21971
trainer/Policy log std Mean        -1.78585
trainer/Policy log std Std          0.609146
trainer/Policy log std Max         -0.447627
trainer/Policy log std Min         -2.7708
trainer/Alpha                       0.0753197
trainer/Alpha Loss                 -1.19433
exploration/num steps total     76200
exploration/num paths total       762
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.897473
exploration/Rewards Std             0.774691
exploration/Rewards Max            -0.0139678
exploration/Rewards Min            -5.65135
exploration/Returns Mean          -89.7473
exploration/Returns Std            56.7338
exploration/Returns Max           -24.2708
exploration/Returns Min          -156.288
exploration/Actions Mean           -0.000311106
exploration/Actions Std             0.22127
exploration/Actions Max             0.994227
exploration/Actions Min            -0.998209
exploration/Num Paths               5
exploration/Average Returns       -89.7473
evaluation/num steps total     228000
evaluation/num paths total       2280
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.879034
evaluation/Rewards Std              1.09055
evaluation/Rewards Max             -0.0785144
evaluation/Rewards Min             -8.90432
evaluation/Returns Mean           -87.9034
evaluation/Returns Std             64.5791
evaluation/Returns Max            -13.7282
evaluation/Returns Min           -183.792
evaluation/Actions Mean            -0.0050124
evaluation/Actions Std              0.179115
evaluation/Actions Max              0.998618
evaluation/Actions Min             -0.999339
evaluation/Num Paths               15
evaluation/Average Returns        -87.9034
time/data storing (s)               0.00301427
time/evaluation sampling (s)        0.359409
time/exploration sampling (s)       0.1625
time/logging (s)                    0.00428366
time/saving (s)                     0.00231799
time/training (s)                   2.09206
time/epoch (s)                      2.62359
time/total (s)                    406.048
Epoch                             151
-----------------------------  ----------------
2019-04-22 22:16:46.908160 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 152 finished
-----------------------------  ---------------
replay_buffer/size              76700
trainer/QF1 Loss                   59.9057
trainer/QF2 Loss                   60.0802
trainer/Policy Loss                44.5878
trainer/Q1 Predictions Mean       -43.4368
trainer/Q1 Predictions Std         32.2976
trainer/Q1 Predictions Max        -14.6985
trainer/Q1 Predictions Min       -113.001
trainer/Q2 Predictions Mean       -43.4832
trainer/Q2 Predictions Std         32.3278
trainer/Q2 Predictions Max        -14.6393
trainer/Q2 Predictions Min       -112.616
trainer/Q Targets Mean            -42.2938
trainer/Q Targets Std              32.6469
trainer/Q Targets Max              -3.76128
trainer/Q Targets Min            -113.166
trainer/Log Pis Mean                1.89784
trainer/Log Pis Std                 1.35581
trainer/Log Pis Max                 6.62568
trainer/Log Pis Min                -2.50646
trainer/Policy mu Mean              0.158575
trainer/Policy mu Std               0.900404
trainer/Policy mu Max               3.05632
trainer/Policy mu Min              -2.91353
trainer/Policy log std Mean        -1.77375
trainer/Policy log std Std          0.617078
trainer/Policy log std Max         -0.492118
trainer/Policy log std Min         -2.65757
trainer/Alpha                       0.0764692
trainer/Alpha Loss                 -0.262643
exploration/num steps total     76700
exploration/num paths total       767
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.995135
exploration/Rewards Std             1.33596
exploration/Rewards Max            -0.0267892
exploration/Rewards Min            -9.64938
exploration/Returns Mean          -99.5135
exploration/Returns Std            63.7646
exploration/Returns Max           -34.9686
exploration/Returns Min          -178.929
exploration/Actions Mean           -0.0018561
exploration/Actions Std             0.26216
exploration/Actions Max             0.99919
exploration/Actions Min            -0.997
exploration/Num Paths               5
exploration/Average Returns       -99.5135
evaluation/num steps total     229500
evaluation/num paths total       2295
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.395701
evaluation/Rewards Std              1.12447
evaluation/Rewards Max             -0.0825916
evaluation/Rewards Min            -10.9099
evaluation/Returns Mean           -39.5701
evaluation/Returns Std             16.4728
evaluation/Returns Max            -16.7416
evaluation/Returns Min            -65.1645
evaluation/Actions Mean            -0.00294766
evaluation/Actions Std              0.199342
evaluation/Actions Max              0.99462
evaluation/Actions Min             -0.998612
evaluation/Num Paths               15
evaluation/Average Returns        -39.5701
time/data storing (s)               0.0031087
time/evaluation sampling (s)        0.348479
time/exploration sampling (s)       0.158042
time/logging (s)                    0.00482342
time/saving (s)                     0.00197364
time/training (s)                   2.08372
time/epoch (s)                      2.60014
time/total (s)                    408.652
Epoch                             152
-----------------------------  ---------------
2019-04-22 22:16:49.535370 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 153 finished
-----------------------------  ----------------
replay_buffer/size              77200
trainer/QF1 Loss                   21.8218
trainer/QF2 Loss                   22.2019
trainer/Policy Loss                44.0841
trainer/Q1 Predictions Mean       -42.9456
trainer/Q1 Predictions Std         30.3898
trainer/Q1 Predictions Max        -14.6283
trainer/Q1 Predictions Min       -104.357
trainer/Q2 Predictions Mean       -43.0192
trainer/Q2 Predictions Std         30.436
trainer/Q2 Predictions Max        -14.4838
trainer/Q2 Predictions Min       -104.984
trainer/Q Targets Mean            -42.8639
trainer/Q Targets Std              30.9673
trainer/Q Targets Max              -0.435874
trainer/Q Targets Min            -105.833
trainer/Log Pis Mean                2.03453
trainer/Log Pis Std                 1.67904
trainer/Log Pis Max                 7.67829
trainer/Log Pis Min                -4.06618
trainer/Policy mu Mean              0.185948
trainer/Policy mu Std               1.06502
trainer/Policy mu Max               2.85243
trainer/Policy mu Min              -2.95554
trainer/Policy log std Mean        -1.66522
trainer/Policy log std Std          0.675705
trainer/Policy log std Max         -0.312609
trainer/Policy log std Min         -2.63203
trainer/Alpha                       0.0774472
trainer/Alpha Loss                  0.0883182
exploration/num steps total     77200
exploration/num paths total       772
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.17316
exploration/Rewards Std             0.863127
exploration/Rewards Max            -0.0237242
exploration/Rewards Min            -8.27441
exploration/Returns Mean         -117.316
exploration/Returns Std            50.9558
exploration/Returns Max           -50.3146
exploration/Returns Min          -173.405
exploration/Actions Mean           -7.67698e-05
exploration/Actions Std             0.223916
exploration/Actions Max             0.997304
exploration/Actions Min            -0.998896
exploration/Num Paths               5
exploration/Average Returns      -117.316
evaluation/num steps total     231000
evaluation/num paths total       2310
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.859154
evaluation/Rewards Std              1.01384
evaluation/Rewards Max             -0.127825
evaluation/Rewards Min            -10.8477
evaluation/Returns Mean           -85.9154
evaluation/Returns Std             55.6262
evaluation/Returns Max            -14.7
evaluation/Returns Min           -171.807
evaluation/Actions Mean             0.00105722
evaluation/Actions Std              0.180418
evaluation/Actions Max              0.997444
evaluation/Actions Min             -0.998338
evaluation/Num Paths               15
evaluation/Average Returns        -85.9154
time/data storing (s)               0.00326473
time/evaluation sampling (s)        0.354367
time/exploration sampling (s)       0.162524
time/logging (s)                    0.0050529
time/saving (s)                     0.00198735
time/training (s)                   2.09291
time/epoch (s)                      2.62011
time/total (s)                    411.277
Epoch                             153
-----------------------------  ----------------
2019-04-22 22:16:52.261096 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 154 finished
-----------------------------  ---------------
replay_buffer/size              77700
trainer/QF1 Loss                    0.247069
trainer/QF2 Loss                    0.247078
trainer/Policy Loss                46.8273
trainer/Q1 Predictions Mean       -45.6546
trainer/Q1 Predictions Std         31.7183
trainer/Q1 Predictions Max        -14.6752
trainer/Q1 Predictions Min       -103.65
trainer/Q2 Predictions Mean       -45.6638
trainer/Q2 Predictions Std         31.7421
trainer/Q2 Predictions Max        -14.6151
trainer/Q2 Predictions Min       -104.545
trainer/Q Targets Mean            -45.8481
trainer/Q Targets Std              31.9506
trainer/Q Targets Max             -14.4054
trainer/Q Targets Min            -105.1
trainer/Log Pis Mean                1.92869
trainer/Log Pis Std                 1.35409
trainer/Log Pis Max                 7.64841
trainer/Log Pis Min                -3.91108
trainer/Policy mu Mean              0.158446
trainer/Policy mu Std               0.889176
trainer/Policy mu Max               2.8627
trainer/Policy mu Min              -2.42442
trainer/Policy log std Mean        -1.77978
trainer/Policy log std Std          0.60618
trainer/Policy log std Max         -0.456972
trainer/Policy log std Min         -2.65164
trainer/Alpha                       0.0764812
trainer/Alpha Loss                 -0.183323
exploration/num steps total     77700
exploration/num paths total       777
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.659905
exploration/Rewards Std             1.00641
exploration/Rewards Max            -0.0128912
exploration/Rewards Min            -8.48331
exploration/Returns Mean          -65.9905
exploration/Returns Std            60.8055
exploration/Returns Max           -22.6128
exploration/Returns Min          -185.584
exploration/Actions Mean            0.00596291
exploration/Actions Std             0.22384
exploration/Actions Max             0.996905
exploration/Actions Min            -0.998573
exploration/Num Paths               5
exploration/Average Returns       -65.9905
evaluation/num steps total     232500
evaluation/num paths total       2325
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.48766
evaluation/Rewards Std              0.865878
evaluation/Rewards Max             -0.0220706
evaluation/Rewards Min             -9.37707
evaluation/Returns Mean           -48.766
evaluation/Returns Std             50.0242
evaluation/Returns Max             -7.80983
evaluation/Returns Min           -171.726
evaluation/Actions Mean             0.00607761
evaluation/Actions Std              0.161585
evaluation/Actions Max              0.997049
evaluation/Actions Min             -0.99704
evaluation/Num Paths               15
evaluation/Average Returns        -48.766
time/data storing (s)               0.00341605
time/evaluation sampling (s)        0.357138
time/exploration sampling (s)       0.16399
time/logging (s)                    0.00455859
time/saving (s)                     0.00193619
time/training (s)                   2.18766
time/epoch (s)                      2.7187
time/total (s)                    414
Epoch                             154
-----------------------------  ---------------
2019-04-22 22:16:55.275574 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 155 finished
-----------------------------  ---------------
replay_buffer/size              78200
trainer/QF1 Loss                  119.288
trainer/QF2 Loss                  117.328
trainer/Policy Loss                39.9125
trainer/Q1 Predictions Mean       -38.4938
trainer/Q1 Predictions Std         29.9191
trainer/Q1 Predictions Max        -14.2586
trainer/Q1 Predictions Min       -116.747
trainer/Q2 Predictions Mean       -38.4298
trainer/Q2 Predictions Std         29.8591
trainer/Q2 Predictions Max        -14.2066
trainer/Q2 Predictions Min       -115.775
trainer/Q Targets Mean            -37.9725
trainer/Q Targets Std              29.4275
trainer/Q Targets Max              -7.8129
trainer/Q Targets Min            -111.301
trainer/Log Pis Mean                2.02949
trainer/Log Pis Std                 1.26734
trainer/Log Pis Max                 6.00206
trainer/Log Pis Min                -0.721659
trainer/Policy mu Mean              0.038351
trainer/Policy mu Std               0.931019
trainer/Policy mu Max               2.54421
trainer/Policy mu Min              -2.83245
trainer/Policy log std Mean        -1.84105
trainer/Policy log std Std          0.648942
trainer/Policy log std Max         -0.378205
trainer/Policy log std Min         -2.74356
trainer/Alpha                       0.0731412
trainer/Alpha Loss                  0.0771272
exploration/num steps total     78200
exploration/num paths total       782
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.710624
exploration/Rewards Std             1.05193
exploration/Rewards Max            -0.00669293
exploration/Rewards Min           -10.0944
exploration/Returns Mean          -71.0624
exploration/Returns Std            47.3731
exploration/Returns Max           -33.7724
exploration/Returns Min          -162.658
exploration/Actions Mean           -0.0360178
exploration/Actions Std             0.211574
exploration/Actions Max             0.581824
exploration/Actions Min            -0.999511
exploration/Num Paths               5
exploration/Average Returns       -71.0624
evaluation/num steps total     234000
evaluation/num paths total       2340
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.721257
evaluation/Rewards Std              0.996113
evaluation/Rewards Max             -0.0285829
evaluation/Rewards Min             -8.69212
evaluation/Returns Mean           -72.1257
evaluation/Returns Std             53.6509
evaluation/Returns Max             -4.9687
evaluation/Returns Min           -175.498
evaluation/Actions Mean             0.00034017
evaluation/Actions Std              0.184305
evaluation/Actions Max              0.994048
evaluation/Actions Min             -0.999367
evaluation/Num Paths               15
evaluation/Average Returns        -72.1257
time/data storing (s)               0.00314782
time/evaluation sampling (s)        0.367216
time/exploration sampling (s)       0.199522
time/logging (s)                    0.00663918
time/saving (s)                     0.00226803
time/training (s)                   2.43055
time/epoch (s)                      3.00934
time/total (s)                    417.014
Epoch                             155
-----------------------------  ---------------
2019-04-22 22:16:59.012620 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 156 finished
-----------------------------  ---------------
replay_buffer/size              78700
trainer/QF1 Loss                    2.41156
trainer/QF2 Loss                    2.64691
trainer/Policy Loss                43.5233
trainer/Q1 Predictions Mean       -42.4855
trainer/Q1 Predictions Std         31.9446
trainer/Q1 Predictions Max        -14.2047
trainer/Q1 Predictions Min       -109.799
trainer/Q2 Predictions Mean       -42.4438
trainer/Q2 Predictions Std         31.9718
trainer/Q2 Predictions Max        -14.0961
trainer/Q2 Predictions Min       -109.402
trainer/Q Targets Mean            -42.3824
trainer/Q Targets Std              32.0669
trainer/Q Targets Max              -0.255605
trainer/Q Targets Min            -109.651
trainer/Log Pis Mean                2.18532
trainer/Log Pis Std                 1.29666
trainer/Log Pis Max                 6.3694
trainer/Log Pis Min                -1.05105
trainer/Policy mu Mean              0.17553
trainer/Policy mu Std               1.01006
trainer/Policy mu Max               2.75341
trainer/Policy mu Min              -2.80145
trainer/Policy log std Mean        -1.74689
trainer/Policy log std Std          0.613352
trainer/Policy log std Max         -0.461353
trainer/Policy log std Min         -2.64714
trainer/Alpha                       0.0752523
trainer/Alpha Loss                  0.479418
exploration/num steps total     78700
exploration/num paths total       787
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.04411
exploration/Rewards Std             0.837583
exploration/Rewards Max            -0.00180085
exploration/Rewards Min            -7.65306
exploration/Returns Mean         -104.411
exploration/Returns Std            48.0481
exploration/Returns Max           -37.7967
exploration/Returns Min          -146.868
exploration/Actions Mean           -0.0126579
exploration/Actions Std             0.204515
exploration/Actions Max             0.967468
exploration/Actions Min            -0.997869
exploration/Num Paths               5
exploration/Average Returns      -104.411
evaluation/num steps total     235500
evaluation/num paths total       2355
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.648327
evaluation/Rewards Std              0.912563
evaluation/Rewards Max             -0.182037
evaluation/Rewards Min             -8.95989
evaluation/Returns Mean           -64.8327
evaluation/Returns Std             43.7883
evaluation/Returns Max            -23.8775
evaluation/Returns Min           -152.466
evaluation/Actions Mean            -0.00964817
evaluation/Actions Std              0.174055
evaluation/Actions Max              0.997618
evaluation/Actions Min             -0.999002
evaluation/Num Paths               15
evaluation/Average Returns        -64.8327
time/data storing (s)               0.00478243
time/evaluation sampling (s)        0.370478
time/exploration sampling (s)       0.17964
time/logging (s)                    0.00499248
time/saving (s)                     0.00220661
time/training (s)                   3.16532
time/epoch (s)                      3.72742
time/total (s)                    420.745
Epoch                             156
-----------------------------  ---------------
2019-04-22 22:17:02.205930 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 157 finished
-----------------------------  ---------------
replay_buffer/size              79200
trainer/QF1 Loss                    0.181584
trainer/QF2 Loss                    0.242846
trainer/Policy Loss                40.7868
trainer/Q1 Predictions Mean       -39.7249
trainer/Q1 Predictions Std         29.2677
trainer/Q1 Predictions Max        -13.8822
trainer/Q1 Predictions Min       -105.082
trainer/Q2 Predictions Mean       -39.7555
trainer/Q2 Predictions Std         29.2559
trainer/Q2 Predictions Max        -13.9119
trainer/Q2 Predictions Min       -105.311
trainer/Q Targets Mean            -39.9183
trainer/Q Targets Std              29.3116
trainer/Q Targets Max             -13.951
trainer/Q Targets Min            -104.76
trainer/Log Pis Mean                2.00281
trainer/Log Pis Std                 1.5057
trainer/Log Pis Max                 5.26715
trainer/Log Pis Min                -3.92973
trainer/Policy mu Mean              0.182716
trainer/Policy mu Std               0.959488
trainer/Policy mu Max               2.87236
trainer/Policy mu Min              -2.59602
trainer/Policy log std Mean        -1.74349
trainer/Policy log std Std          0.630272
trainer/Policy log std Max         -0.505859
trainer/Policy log std Min         -2.70533
trainer/Alpha                       0.0744189
trainer/Alpha Loss                  0.00729688
exploration/num steps total     79200
exploration/num paths total       792
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.388338
exploration/Rewards Std             0.501141
exploration/Rewards Max            -0.0061794
exploration/Rewards Min            -6.02684
exploration/Returns Mean          -38.8338
exploration/Returns Std            21.5088
exploration/Returns Max           -17.9144
exploration/Returns Min           -71.4249
exploration/Actions Mean           -0.0105921
exploration/Actions Std             0.175756
exploration/Actions Max             0.979653
exploration/Actions Min            -0.996964
exploration/Num Paths               5
exploration/Average Returns       -38.8338
evaluation/num steps total     237000
evaluation/num paths total       2370
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.741733
evaluation/Rewards Std              1.05541
evaluation/Rewards Max             -0.113635
evaluation/Rewards Min             -8.79062
evaluation/Returns Mean           -74.1733
evaluation/Returns Std             51.4763
evaluation/Returns Max            -13.5061
evaluation/Returns Min           -165.517
evaluation/Actions Mean            -0.00313313
evaluation/Actions Std              0.188522
evaluation/Actions Max              0.994747
evaluation/Actions Min             -0.998166
evaluation/Num Paths               15
evaluation/Average Returns        -74.1733
time/data storing (s)               0.00426827
time/evaluation sampling (s)        0.432093
time/exploration sampling (s)       0.272599
time/logging (s)                    0.00553407
time/saving (s)                     0.00197559
time/training (s)                   2.4694
time/epoch (s)                      3.18587
time/total (s)                    423.936
Epoch                             157
-----------------------------  ---------------
2019-04-22 22:17:05.265229 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 158 finished
-----------------------------  ---------------
replay_buffer/size              79700
trainer/QF1 Loss                    3.39898
trainer/QF2 Loss                    3.31175
trainer/Policy Loss                44.9164
trainer/Q1 Predictions Mean       -43.4312
trainer/Q1 Predictions Std         30.8914
trainer/Q1 Predictions Max        -14.3852
trainer/Q1 Predictions Min       -124.093
trainer/Q2 Predictions Mean       -43.4552
trainer/Q2 Predictions Std         30.9182
trainer/Q2 Predictions Max        -14.2636
trainer/Q2 Predictions Min       -122.597
trainer/Q Targets Mean            -43.8312
trainer/Q Targets Std              31.737
trainer/Q Targets Max              -0.192429
trainer/Q Targets Min            -126.662
trainer/Log Pis Mean                2.29354
trainer/Log Pis Std                 1.49848
trainer/Log Pis Max                 7.37674
trainer/Log Pis Min                -1.23799
trainer/Policy mu Mean              0.0797254
trainer/Policy mu Std               1.11808
trainer/Policy mu Max               3.53439
trainer/Policy mu Min              -3.94711
trainer/Policy log std Mean        -1.71358
trainer/Policy log std Std          0.655197
trainer/Policy log std Max         -0.326121
trainer/Policy log std Min         -2.73327
trainer/Alpha                       0.0724777
trainer/Alpha Loss                  0.770406
exploration/num steps total     79700
exploration/num paths total       797
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.417819
exploration/Rewards Std             0.994616
exploration/Rewards Max            -0.00273163
exploration/Rewards Min            -9.97373
exploration/Returns Mean          -41.7819
exploration/Returns Std            13.3044
exploration/Returns Max           -21.1393
exploration/Returns Min           -59.7412
exploration/Actions Mean            0.0109345
exploration/Actions Std             0.239813
exploration/Actions Max             0.998311
exploration/Actions Min            -0.997888
exploration/Num Paths               5
exploration/Average Returns       -41.7819
evaluation/num steps total     238500
evaluation/num paths total       2385
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.881477
evaluation/Rewards Std              1.20129
evaluation/Rewards Max             -0.0151193
evaluation/Rewards Min            -11.2703
evaluation/Returns Mean           -88.1477
evaluation/Returns Std             65.2388
evaluation/Returns Max            -10.7243
evaluation/Returns Min           -207.892
evaluation/Actions Mean             0.00642854
evaluation/Actions Std              0.188705
evaluation/Actions Max              0.998601
evaluation/Actions Min             -0.998444
evaluation/Num Paths               15
evaluation/Average Returns        -88.1477
time/data storing (s)               0.00322389
time/evaluation sampling (s)        0.408942
time/exploration sampling (s)       0.196494
time/logging (s)                    0.00534585
time/saving (s)                     0.00206403
time/training (s)                   2.43524
time/epoch (s)                      3.05131
time/total (s)                    426.993
Epoch                             158
-----------------------------  ---------------
2019-04-22 22:17:08.149036 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 159 finished
-----------------------------  ---------------
replay_buffer/size              80200
trainer/QF1 Loss                   76.5519
trainer/QF2 Loss                   76.7111
trainer/Policy Loss                44.1541
trainer/Q1 Predictions Mean       -42.7689
trainer/Q1 Predictions Std         31.0035
trainer/Q1 Predictions Max        -13.6166
trainer/Q1 Predictions Min        -96.0185
trainer/Q2 Predictions Mean       -42.794
trainer/Q2 Predictions Std         30.9757
trainer/Q2 Predictions Max        -13.6387
trainer/Q2 Predictions Min        -95.3794
trainer/Q Targets Mean            -42.2465
trainer/Q Targets Std              31.1139
trainer/Q Targets Max              -2.28683
trainer/Q Targets Min             -95.8441
trainer/Log Pis Mean                1.89788
trainer/Log Pis Std                 1.27075
trainer/Log Pis Max                 4.58796
trainer/Log Pis Min                -3.09758
trainer/Policy mu Mean              0.106287
trainer/Policy mu Std               0.902748
trainer/Policy mu Max               2.73568
trainer/Policy mu Min              -3.24202
trainer/Policy log std Mean        -1.71979
trainer/Policy log std Std          0.604827
trainer/Policy log std Max         -0.249426
trainer/Policy log std Min         -2.57033
trainer/Alpha                       0.0721732
trainer/Alpha Loss                 -0.268433
exploration/num steps total     80200
exploration/num paths total       802
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.754717
exploration/Rewards Std             1.13662
exploration/Rewards Max            -0.00353328
exploration/Rewards Min            -8.29419
exploration/Returns Mean          -75.4717
exploration/Returns Std            56.605
exploration/Returns Max           -31.3417
exploration/Returns Min          -184.318
exploration/Actions Mean           -0.0258847
exploration/Actions Std             0.237886
exploration/Actions Max             0.996364
exploration/Actions Min            -0.999679
exploration/Num Paths               5
exploration/Average Returns       -75.4717
evaluation/num steps total     240000
evaluation/num paths total       2400
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.925407
evaluation/Rewards Std              1.09309
evaluation/Rewards Max             -0.0415559
evaluation/Rewards Min             -9.99695
evaluation/Returns Mean           -92.5407
evaluation/Returns Std             78.8048
evaluation/Returns Max             -8.39102
evaluation/Returns Min           -207.175
evaluation/Actions Mean             0.0133456
evaluation/Actions Std              0.16512
evaluation/Actions Max              0.998072
evaluation/Actions Min             -0.988686
evaluation/Num Paths               15
evaluation/Average Returns        -92.5407
time/data storing (s)               0.00368233
time/evaluation sampling (s)        0.37792
time/exploration sampling (s)       0.189236
time/logging (s)                    0.00392321
time/saving (s)                     0.00211548
time/training (s)                   2.29731
time/epoch (s)                      2.87419
time/total (s)                    429.872
Epoch                             159
-----------------------------  ---------------
2019-04-22 22:17:11.139972 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 160 finished
-----------------------------  ---------------
replay_buffer/size              80700
trainer/QF1 Loss                    4.10952
trainer/QF2 Loss                    4.0668
trainer/Policy Loss                44.8893
trainer/Q1 Predictions Mean       -43.6533
trainer/Q1 Predictions Std         31.6116
trainer/Q1 Predictions Max        -13.7281
trainer/Q1 Predictions Min       -114.542
trainer/Q2 Predictions Mean       -43.7013
trainer/Q2 Predictions Std         31.6275
trainer/Q2 Predictions Max        -13.7216
trainer/Q2 Predictions Min       -113.116
trainer/Q Targets Mean            -43.817
trainer/Q Targets Std              32.2576
trainer/Q Targets Max              -0.377207
trainer/Q Targets Min            -116.032
trainer/Log Pis Mean                2.08778
trainer/Log Pis Std                 1.25431
trainer/Log Pis Max                 6.62394
trainer/Log Pis Min                -1.34288
trainer/Policy mu Mean              0.0899712
trainer/Policy mu Std               0.971808
trainer/Policy mu Max               2.59867
trainer/Policy mu Min              -2.91716
trainer/Policy log std Mean        -1.72267
trainer/Policy log std Std          0.60153
trainer/Policy log std Max         -0.491827
trainer/Policy log std Min         -2.69897
trainer/Alpha                       0.0716932
trainer/Alpha Loss                  0.231348
exploration/num steps total     80700
exploration/num paths total       807
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.667985
exploration/Rewards Std             1.11822
exploration/Rewards Max            -0.0141318
exploration/Rewards Min            -9.3364
exploration/Returns Mean          -66.7985
exploration/Returns Std            46.0538
exploration/Returns Max           -30.743
exploration/Returns Min          -156.72
exploration/Actions Mean            0.032033
exploration/Actions Std             0.234903
exploration/Actions Max             0.997466
exploration/Actions Min            -0.993
exploration/Num Paths               5
exploration/Average Returns       -66.7985
evaluation/num steps total     241500
evaluation/num paths total       2415
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.66711
evaluation/Rewards Std              1.09413
evaluation/Rewards Max             -0.054766
evaluation/Rewards Min             -9.53211
evaluation/Returns Mean           -66.711
evaluation/Returns Std             56.8088
evaluation/Returns Max            -13.8984
evaluation/Returns Min           -194.104
evaluation/Actions Mean             0.00282995
evaluation/Actions Std              0.202525
evaluation/Actions Max              0.996593
evaluation/Actions Min             -0.997875
evaluation/Num Paths               15
evaluation/Average Returns        -66.711
time/data storing (s)               0.00335509
time/evaluation sampling (s)        0.348629
time/exploration sampling (s)       0.154762
time/logging (s)                    0.00510376
time/saving (s)                     0.00203111
time/training (s)                   2.47073
time/epoch (s)                      2.98461
time/total (s)                    432.861
Epoch                             160
-----------------------------  ---------------
2019-04-22 22:17:14.774055 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 161 finished
-----------------------------  ---------------
replay_buffer/size              81200
trainer/QF1 Loss                    0.202331
trainer/QF2 Loss                    0.102503
trainer/Policy Loss                36.2811
trainer/Q1 Predictions Mean       -35.1612
trainer/Q1 Predictions Std         26.3849
trainer/Q1 Predictions Max        -13.4667
trainer/Q1 Predictions Min        -93.8766
trainer/Q2 Predictions Mean       -35.2281
trainer/Q2 Predictions Std         26.4818
trainer/Q2 Predictions Max        -13.3621
trainer/Q2 Predictions Min        -94.8215
trainer/Q Targets Mean            -35.4408
trainer/Q Targets Std              26.5201
trainer/Q Targets Max             -13.4537
trainer/Q Targets Min             -94.7505
trainer/Log Pis Mean                1.9069
trainer/Log Pis Std                 1.82101
trainer/Log Pis Max                10.244
trainer/Log Pis Min                -4.57019
trainer/Policy mu Mean              0.051273
trainer/Policy mu Std               0.895306
trainer/Policy mu Max               2.59031
trainer/Policy mu Min              -3.41366
trainer/Policy log std Mean        -1.85094
trainer/Policy log std Std          0.615087
trainer/Policy log std Max         -0.164495
trainer/Policy log std Min         -2.67766
trainer/Alpha                       0.0738211
trainer/Alpha Loss                 -0.242638
exploration/num steps total     81200
exploration/num paths total       812
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.78472
exploration/Rewards Std             1.07129
exploration/Rewards Max            -0.0141471
exploration/Rewards Min            -9.22198
exploration/Returns Mean          -78.472
exploration/Returns Std            55.0201
exploration/Returns Max           -28.1216
exploration/Returns Min          -185.637
exploration/Actions Mean            0.00538532
exploration/Actions Std             0.223304
exploration/Actions Max             0.997617
exploration/Actions Min            -0.999864
exploration/Num Paths               5
exploration/Average Returns       -78.472
evaluation/num steps total     243000
evaluation/num paths total       2430
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.688349
evaluation/Rewards Std              1.17311
evaluation/Rewards Max             -0.0447771
evaluation/Rewards Min             -9.85803
evaluation/Returns Mean           -68.8349
evaluation/Returns Std             62.2046
evaluation/Returns Max            -13.6116
evaluation/Returns Min           -203.305
evaluation/Actions Mean             0.015258
evaluation/Actions Std              0.193219
evaluation/Actions Max              0.997596
evaluation/Actions Min             -0.997604
evaluation/Num Paths               15
evaluation/Average Returns        -68.8349
time/data storing (s)               0.0041946
time/evaluation sampling (s)        0.386101
time/exploration sampling (s)       0.205534
time/logging (s)                    0.00480583
time/saving (s)                     0.00168608
time/training (s)                   3.02392
time/epoch (s)                      3.62625
time/total (s)                    436.492
Epoch                             161
-----------------------------  ---------------
2019-04-22 22:17:17.607102 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 162 finished
-----------------------------  ---------------
replay_buffer/size              81700
trainer/QF1 Loss                   74.671
trainer/QF2 Loss                   74.6987
trainer/Policy Loss                38.4045
trainer/Q1 Predictions Mean       -37.1237
trainer/Q1 Predictions Std         29.9994
trainer/Q1 Predictions Max        -13.1607
trainer/Q1 Predictions Min       -100.104
trainer/Q2 Predictions Mean       -37.1127
trainer/Q2 Predictions Std         30.0099
trainer/Q2 Predictions Max        -13.1532
trainer/Q2 Predictions Min       -100.705
trainer/Q Targets Mean            -36.8076
trainer/Q Targets Std              30.2679
trainer/Q Targets Max              -2.44054
trainer/Q Targets Min            -102.175
trainer/Log Pis Mean                1.96728
trainer/Log Pis Std                 1.233
trainer/Log Pis Max                 5.41551
trainer/Log Pis Min                -0.92337
trainer/Policy mu Mean              0.0656017
trainer/Policy mu Std               0.959857
trainer/Policy mu Max               2.62055
trainer/Policy mu Min              -3.47902
trainer/Policy log std Mean        -1.76306
trainer/Policy log std Std          0.646427
trainer/Policy log std Max         -0.378992
trainer/Policy log std Min         -2.66558
trainer/Alpha                       0.0763219
trainer/Alpha Loss                 -0.084183
exploration/num steps total     81700
exploration/num paths total       817
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.582717
exploration/Rewards Std             1.29584
exploration/Rewards Max            -0.0272304
exploration/Rewards Min           -10.6581
exploration/Returns Mean          -58.2717
exploration/Returns Std            27.6049
exploration/Returns Max           -23.5184
exploration/Returns Min          -108.103
exploration/Actions Mean            0.0289075
exploration/Actions Std             0.241275
exploration/Actions Max             0.9983
exploration/Actions Min            -0.998154
exploration/Num Paths               5
exploration/Average Returns       -58.2717
evaluation/num steps total     244500
evaluation/num paths total       2445
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.519252
evaluation/Rewards Std              0.941901
evaluation/Rewards Max             -0.0512595
evaluation/Rewards Min            -11.6237
evaluation/Returns Mean           -51.9252
evaluation/Returns Std             37.1927
evaluation/Returns Max            -17.1576
evaluation/Returns Min           -162.484
evaluation/Actions Mean            -0.00588463
evaluation/Actions Std              0.173842
evaluation/Actions Max              0.99622
evaluation/Actions Min             -0.998751
evaluation/Num Paths               15
evaluation/Average Returns        -51.9252
time/data storing (s)               0.00337414
time/evaluation sampling (s)        0.391374
time/exploration sampling (s)       0.167104
time/logging (s)                    0.00474796
time/saving (s)                     0.00213969
time/training (s)                   2.2566
time/epoch (s)                      2.82534
time/total (s)                    439.322
Epoch                             162
-----------------------------  ---------------
2019-04-22 22:17:20.430425 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 163 finished
-----------------------------  ---------------
replay_buffer/size              82200
trainer/QF1 Loss                   16.1379
trainer/QF2 Loss                   16.2925
trainer/Policy Loss                36.6625
trainer/Q1 Predictions Mean       -35.3235
trainer/Q1 Predictions Std         28.7362
trainer/Q1 Predictions Max        -13.2445
trainer/Q1 Predictions Min       -113.552
trainer/Q2 Predictions Mean       -35.3293
trainer/Q2 Predictions Std         28.7142
trainer/Q2 Predictions Max        -13.1511
trainer/Q2 Predictions Min       -111.708
trainer/Q Targets Mean            -35.1627
trainer/Q Targets Std              29.1993
trainer/Q Targets Max              -2.86629
trainer/Q Targets Min            -114.336
trainer/Log Pis Mean                2.00935
trainer/Log Pis Std                 1.34711
trainer/Log Pis Max                 6.14633
trainer/Log Pis Min                -2.61182
trainer/Policy mu Mean              0.0568949
trainer/Policy mu Std               0.908047
trainer/Policy mu Max               2.6386
trainer/Policy mu Min              -2.65854
trainer/Policy log std Mean        -1.86794
trainer/Policy log std Std          0.658705
trainer/Policy log std Max         -0.555774
trainer/Policy log std Min         -2.88802
trainer/Alpha                       0.0732369
trainer/Alpha Loss                  0.0244543
exploration/num steps total     82200
exploration/num paths total       822
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.17274
exploration/Rewards Std             1.04499
exploration/Rewards Max            -0.024326
exploration/Rewards Min            -9.28441
exploration/Returns Mean         -117.274
exploration/Returns Std            56.5696
exploration/Returns Max           -33.6087
exploration/Returns Min          -182.192
exploration/Actions Mean            0.00941854
exploration/Actions Std             0.245764
exploration/Actions Max             0.997427
exploration/Actions Min            -0.9987
exploration/Num Paths               5
exploration/Average Returns      -117.274
evaluation/num steps total     246000
evaluation/num paths total       2460
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.712973
evaluation/Rewards Std              1.02829
evaluation/Rewards Max             -0.022027
evaluation/Rewards Min            -10.0715
evaluation/Returns Mean           -71.2973
evaluation/Returns Std             55.1113
evaluation/Returns Max            -17.5118
evaluation/Returns Min           -165.754
evaluation/Actions Mean            -0.00778097
evaluation/Actions Std              0.187607
evaluation/Actions Max              0.997204
evaluation/Actions Min             -0.999359
evaluation/Num Paths               15
evaluation/Average Returns        -71.2973
time/data storing (s)               0.00374608
time/evaluation sampling (s)        0.365768
time/exploration sampling (s)       0.175969
time/logging (s)                    0.00495543
time/saving (s)                     0.00199715
time/training (s)                   2.26485
time/epoch (s)                      2.81729
time/total (s)                    442.143
Epoch                             163
-----------------------------  ---------------
2019-04-22 22:17:23.158859 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 164 finished
-----------------------------  ---------------
replay_buffer/size              82700
trainer/QF1 Loss                   21.0929
trainer/QF2 Loss                   20.816
trainer/Policy Loss                30.6331
trainer/Q1 Predictions Mean       -29.4757
trainer/Q1 Predictions Std         23.6742
trainer/Q1 Predictions Max        -12.6561
trainer/Q1 Predictions Min        -93.6634
trainer/Q2 Predictions Mean       -29.5575
trainer/Q2 Predictions Std         23.7093
trainer/Q2 Predictions Max        -12.7917
trainer/Q2 Predictions Min        -93.5606
trainer/Q Targets Mean            -28.812
trainer/Q Targets Std              24.0857
trainer/Q Targets Max              -0.301169
trainer/Q Targets Min             -93.7341
trainer/Log Pis Mean                1.8573
trainer/Log Pis Std                 1.19488
trainer/Log Pis Max                 4.70364
trainer/Log Pis Min                -1.87832
trainer/Policy mu Mean             -0.0641276
trainer/Policy mu Std               0.765043
trainer/Policy mu Max               2.14496
trainer/Policy mu Min              -2.45221
trainer/Policy log std Mean        -1.84876
trainer/Policy log std Std          0.589142
trainer/Policy log std Max         -0.514688
trainer/Policy log std Min         -2.77525
trainer/Alpha                       0.0744275
trainer/Alpha Loss                 -0.370694
exploration/num steps total     82700
exploration/num paths total       827
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.784772
exploration/Rewards Std             0.850499
exploration/Rewards Max            -0.00408283
exploration/Rewards Min            -7.63404
exploration/Returns Mean          -78.4772
exploration/Returns Std            61.6836
exploration/Returns Max           -14.9213
exploration/Returns Min          -153.708
exploration/Actions Mean           -0.00303735
exploration/Actions Std             0.201714
exploration/Actions Max             0.986112
exploration/Actions Min            -0.998057
exploration/Num Paths               5
exploration/Average Returns       -78.4772
evaluation/num steps total     247500
evaluation/num paths total       2475
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.638549
evaluation/Rewards Std              0.962928
evaluation/Rewards Max             -0.0824755
evaluation/Rewards Min             -9.48652
evaluation/Returns Mean           -63.8549
evaluation/Returns Std             49.6687
evaluation/Returns Max             -9.96848
evaluation/Returns Min           -156.497
evaluation/Actions Mean            -0.0123958
evaluation/Actions Std              0.175915
evaluation/Actions Max              0.989337
evaluation/Actions Min             -0.998184
evaluation/Num Paths               15
evaluation/Average Returns        -63.8549
time/data storing (s)               0.00362309
time/evaluation sampling (s)        0.364178
time/exploration sampling (s)       0.167022
time/logging (s)                    0.00488509
time/saving (s)                     0.00203531
time/training (s)                   2.17894
time/epoch (s)                      2.72068
time/total (s)                    444.869
Epoch                             164
-----------------------------  ---------------
2019-04-22 22:17:25.980319 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 165 finished
-----------------------------  ----------------
replay_buffer/size              83200
trainer/QF1 Loss                    0.511785
trainer/QF2 Loss                    0.599838
trainer/Policy Loss                33.0129
trainer/Q1 Predictions Mean       -31.5562
trainer/Q1 Predictions Std         24.7156
trainer/Q1 Predictions Max        -13.05
trainer/Q1 Predictions Min        -93.4117
trainer/Q2 Predictions Mean       -31.5298
trainer/Q2 Predictions Std         24.6668
trainer/Q2 Predictions Max        -13.0518
trainer/Q2 Predictions Min        -93.4048
trainer/Q Targets Mean            -31.9629
trainer/Q Targets Std              25.0238
trainer/Q Targets Max             -12.9669
trainer/Q Targets Min             -95.1107
trainer/Log Pis Mean                2.11626
trainer/Log Pis Std                 1.56563
trainer/Log Pis Max                 7.38358
trainer/Log Pis Min                -2.61171
trainer/Policy mu Mean             -0.103586
trainer/Policy mu Std               0.971254
trainer/Policy mu Max               3.1879
trainer/Policy mu Min              -3.08168
trainer/Policy log std Mean        -1.8815
trainer/Policy log std Std          0.64903
trainer/Policy log std Max         -0.419387
trainer/Policy log std Min         -2.80621
trainer/Alpha                       0.0774736
trainer/Alpha Loss                  0.297385
exploration/num steps total     83200
exploration/num paths total       832
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.560758
exploration/Rewards Std             0.84132
exploration/Rewards Max            -0.0059081
exploration/Rewards Min            -8.79564
exploration/Returns Mean          -56.0758
exploration/Returns Std            41.7628
exploration/Returns Max           -19.5882
exploration/Returns Min          -135.138
exploration/Actions Mean            0.0195281
exploration/Actions Std             0.229135
exploration/Actions Max             0.998777
exploration/Actions Min            -0.959684
exploration/Num Paths               5
exploration/Average Returns       -56.0758
evaluation/num steps total     249000
evaluation/num paths total       2490
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.56448
evaluation/Rewards Std              1.04785
evaluation/Rewards Max             -0.0335328
evaluation/Rewards Min             -9.73905
evaluation/Returns Mean           -56.448
evaluation/Returns Std             50.3151
evaluation/Returns Max             -5.53711
evaluation/Returns Min           -161.702
evaluation/Actions Mean            -0.000591205
evaluation/Actions Std              0.178882
evaluation/Actions Max              0.998671
evaluation/Actions Min             -0.997331
evaluation/Num Paths               15
evaluation/Average Returns        -56.448
time/data storing (s)               0.00296665
time/evaluation sampling (s)        0.383804
time/exploration sampling (s)       0.167194
time/logging (s)                    0.00411654
time/saving (s)                     0.00459556
time/training (s)                   2.25012
time/epoch (s)                      2.8128
time/total (s)                    447.686
Epoch                             165
-----------------------------  ----------------
2019-04-22 22:17:28.549628 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 166 finished
-----------------------------  ---------------
replay_buffer/size              83700
trainer/QF1 Loss                   13.5618
trainer/QF2 Loss                   13.7376
trainer/Policy Loss                38.155
trainer/Q1 Predictions Mean       -36.8612
trainer/Q1 Predictions Std         28.2595
trainer/Q1 Predictions Max        -12.7224
trainer/Q1 Predictions Min       -108.74
trainer/Q2 Predictions Mean       -36.8951
trainer/Q2 Predictions Std         28.2967
trainer/Q2 Predictions Max        -12.6553
trainer/Q2 Predictions Min       -108.252
trainer/Q Targets Mean            -36.8793
trainer/Q Targets Std              28.9035
trainer/Q Targets Max              -0.573766
trainer/Q Targets Min            -110.616
trainer/Log Pis Mean                1.90835
trainer/Log Pis Std                 1.362
trainer/Log Pis Max                 6.85371
trainer/Log Pis Min                -2.25476
trainer/Policy mu Mean              0.0619887
trainer/Policy mu Std               0.890328
trainer/Policy mu Max               2.90768
trainer/Policy mu Min              -2.84399
trainer/Policy log std Mean        -1.83026
trainer/Policy log std Std          0.601003
trainer/Policy log std Max         -0.25736
trainer/Policy log std Min         -2.75695
trainer/Alpha                       0.0780387
trainer/Alpha Loss                 -0.233748
exploration/num steps total     83700
exploration/num paths total       837
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.466925
exploration/Rewards Std             1.04554
exploration/Rewards Max            -0.00909733
exploration/Rewards Min           -11.5213
exploration/Returns Mean          -46.6925
exploration/Returns Std            27.0852
exploration/Returns Max           -18.9081
exploration/Returns Min           -81.1194
exploration/Actions Mean           -0.00106798
exploration/Actions Std             0.220055
exploration/Actions Max             0.999696
exploration/Actions Min            -0.999669
exploration/Num Paths               5
exploration/Average Returns       -46.6925
evaluation/num steps total     250500
evaluation/num paths total       2505
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.684147
evaluation/Rewards Std              1.18057
evaluation/Rewards Max             -0.0400345
evaluation/Rewards Min            -10.0771
evaluation/Returns Mean           -68.4147
evaluation/Returns Std             50.0106
evaluation/Returns Max            -12.4029
evaluation/Returns Min           -186.965
evaluation/Actions Mean            -0.00423667
evaluation/Actions Std              0.216188
evaluation/Actions Max              0.996235
evaluation/Actions Min             -0.99877
evaluation/Num Paths               15
evaluation/Average Returns        -68.4147
time/data storing (s)               0.00315174
time/evaluation sampling (s)        0.346583
time/exploration sampling (s)       0.156388
time/logging (s)                    0.00359634
time/saving (s)                     0.00225885
time/training (s)                   2.04976
time/epoch (s)                      2.56174
time/total (s)                    450.252
Epoch                             166
-----------------------------  ---------------
2019-04-22 22:17:31.123685 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 167 finished
-----------------------------  ---------------
replay_buffer/size              84200
trainer/QF1 Loss                    0.245862
trainer/QF2 Loss                    0.234471
trainer/Policy Loss                36.2487
trainer/Q1 Predictions Mean       -35.1574
trainer/Q1 Predictions Std         29.8646
trainer/Q1 Predictions Max        -12.7345
trainer/Q1 Predictions Min       -100.418
trainer/Q2 Predictions Mean       -35.176
trainer/Q2 Predictions Std         29.8883
trainer/Q2 Predictions Max        -12.6926
trainer/Q2 Predictions Min       -100.832
trainer/Q Targets Mean            -35.5091
trainer/Q Targets Std              30.142
trainer/Q Targets Max             -12.6844
trainer/Q Targets Min            -101.484
trainer/Log Pis Mean                1.87622
trainer/Log Pis Std                 1.33699
trainer/Log Pis Max                 4.94855
trainer/Log Pis Min                -5.56613
trainer/Policy mu Mean              0.0534495
trainer/Policy mu Std               0.812367
trainer/Policy mu Max               2.65046
trainer/Policy mu Min              -2.84729
trainer/Policy log std Mean        -1.85964
trainer/Policy log std Std          0.583068
trainer/Policy log std Max         -0.565864
trainer/Policy log std Min         -2.76162
trainer/Alpha                       0.0754378
trainer/Alpha Loss                 -0.319911
exploration/num steps total     84200
exploration/num paths total       842
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.302824
exploration/Rewards Std             0.592061
exploration/Rewards Max            -0.00505845
exploration/Rewards Min            -5.57031
exploration/Returns Mean          -30.2824
exploration/Returns Std            11.7853
exploration/Returns Max           -16.1134
exploration/Returns Min           -51.853
exploration/Actions Mean           -0.00993555
exploration/Actions Std             0.208135
exploration/Actions Max             0.992402
exploration/Actions Min            -0.993502
exploration/Num Paths               5
exploration/Average Returns       -30.2824
evaluation/num steps total     252000
evaluation/num paths total       2520
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.451518
evaluation/Rewards Std              0.924178
evaluation/Rewards Max             -0.0387983
evaluation/Rewards Min            -10.0758
evaluation/Returns Mean           -45.1518
evaluation/Returns Std             46.3084
evaluation/Returns Max            -11.3578
evaluation/Returns Min           -164.729
evaluation/Actions Mean             0.00311664
evaluation/Actions Std              0.178285
evaluation/Actions Max              0.998632
evaluation/Actions Min             -0.996297
evaluation/Num Paths               15
evaluation/Average Returns        -45.1518
time/data storing (s)               0.00342603
time/evaluation sampling (s)        0.358249
time/exploration sampling (s)       0.159986
time/logging (s)                    0.00482735
time/saving (s)                     0.00198608
time/training (s)                   2.03924
time/epoch (s)                      2.56771
time/total (s)                    452.825
Epoch                             167
-----------------------------  ---------------
2019-04-22 22:17:33.675672 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 168 finished
-----------------------------  ---------------
replay_buffer/size              84700
trainer/QF1 Loss                    0.125658
trainer/QF2 Loss                    0.154104
trainer/Policy Loss                41.6041
trainer/Q1 Predictions Mean       -40.0803
trainer/Q1 Predictions Std         31.4433
trainer/Q1 Predictions Max        -12.7778
trainer/Q1 Predictions Min        -99.5095
trainer/Q2 Predictions Mean       -40.0976
trainer/Q2 Predictions Std         31.4247
trainer/Q2 Predictions Max        -12.7141
trainer/Q2 Predictions Min        -99.8261
trainer/Q Targets Mean            -40.1098
trainer/Q Targets Std              31.383
trainer/Q Targets Max             -12.5973
trainer/Q Targets Min             -99.4403
trainer/Log Pis Mean                2.14333
trainer/Log Pis Std                 1.26622
trainer/Log Pis Max                 6.83526
trainer/Log Pis Min                -1.48116
trainer/Policy mu Mean              0.185417
trainer/Policy mu Std               0.943173
trainer/Policy mu Max               2.96398
trainer/Policy mu Min              -2.71949
trainer/Policy log std Mean        -1.80233
trainer/Policy log std Std          0.64121
trainer/Policy log std Max         -0.441536
trainer/Policy log std Min         -2.69457
trainer/Alpha                       0.0742485
trainer/Alpha Loss                  0.372693
exploration/num steps total     84700
exploration/num paths total       847
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.49359
exploration/Rewards Std             1.033
exploration/Rewards Max            -0.00307579
exploration/Rewards Min            -9.18202
exploration/Returns Mean          -49.359
exploration/Returns Std            18.9118
exploration/Returns Max           -15.3541
exploration/Returns Min           -64.5397
exploration/Actions Mean           -0.00254532
exploration/Actions Std             0.234733
exploration/Actions Max             0.996398
exploration/Actions Min            -0.999763
exploration/Num Paths               5
exploration/Average Returns       -49.359
evaluation/num steps total     253500
evaluation/num paths total       2535
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.43536
evaluation/Rewards Std              1.05058
evaluation/Rewards Max             -0.0273691
evaluation/Rewards Min             -9.77965
evaluation/Returns Mean           -43.536
evaluation/Returns Std             34.3069
evaluation/Returns Max             -9.51683
evaluation/Returns Min           -140.233
evaluation/Actions Mean             0.00147317
evaluation/Actions Std              0.18291
evaluation/Actions Max              0.998251
evaluation/Actions Min             -0.998814
evaluation/Num Paths               15
evaluation/Average Returns        -43.536
time/data storing (s)               0.00309902
time/evaluation sampling (s)        0.349344
time/exploration sampling (s)       0.157284
time/logging (s)                    0.00423911
time/saving (s)                     0.0019576
time/training (s)                   2.02835
time/epoch (s)                      2.54428
time/total (s)                    455.373
Epoch                             168
-----------------------------  ---------------
2019-04-22 22:17:36.363673 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 169 finished
-----------------------------  ---------------
replay_buffer/size              85200
trainer/QF1 Loss                   12.8976
trainer/QF2 Loss                   12.7558
trainer/Policy Loss                35.675
trainer/Q1 Predictions Mean       -34.0827
trainer/Q1 Predictions Std         27.8333
trainer/Q1 Predictions Max        -12.8092
trainer/Q1 Predictions Min        -95.1279
trainer/Q2 Predictions Mean       -34.0842
trainer/Q2 Predictions Std         27.8434
trainer/Q2 Predictions Max        -12.6457
trainer/Q2 Predictions Min        -96.0031
trainer/Q Targets Mean            -34.3943
trainer/Q Targets Std              28.7106
trainer/Q Targets Max              -0.651683
trainer/Q Targets Min             -96.8625
trainer/Log Pis Mean                2.01706
trainer/Log Pis Std                 1.63075
trainer/Log Pis Max                 8.39549
trainer/Log Pis Min                -3.50242
trainer/Policy mu Mean              0.0594066
trainer/Policy mu Std               0.907705
trainer/Policy mu Max               3.0979
trainer/Policy mu Min              -3.22945
trainer/Policy log std Mean        -1.87777
trainer/Policy log std Std          0.647108
trainer/Policy log std Max         -0.34012
trainer/Policy log std Min         -2.90167
trainer/Alpha                       0.0727403
trainer/Alpha Loss                  0.0447155
exploration/num steps total     85200
exploration/num paths total       852
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.445824
exploration/Rewards Std             0.767988
exploration/Rewards Max            -0.0189019
exploration/Rewards Min            -8.03805
exploration/Returns Mean          -44.5824
exploration/Returns Std            18.686
exploration/Returns Max           -16.8013
exploration/Returns Min           -68.0698
exploration/Actions Mean            0.00275248
exploration/Actions Std             0.21178
exploration/Actions Max             0.999021
exploration/Actions Min            -0.998209
exploration/Num Paths               5
exploration/Average Returns       -44.5824
evaluation/num steps total     255000
evaluation/num paths total       2550
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.626712
evaluation/Rewards Std              1.10054
evaluation/Rewards Max             -0.086544
evaluation/Rewards Min            -10.5793
evaluation/Returns Mean           -62.6712
evaluation/Returns Std             49.7844
evaluation/Returns Max            -14.7894
evaluation/Returns Min           -180.614
evaluation/Actions Mean            -0.00611916
evaluation/Actions Std              0.194906
evaluation/Actions Max              0.998638
evaluation/Actions Min             -0.998264
evaluation/Num Paths               15
evaluation/Average Returns        -62.6712
time/data storing (s)               0.00284816
time/evaluation sampling (s)        0.343659
time/exploration sampling (s)       0.154525
time/logging (s)                    0.00488518
time/saving (s)                     0.00198059
time/training (s)                   2.1737
time/epoch (s)                      2.6816
time/total (s)                    458.059
Epoch                             169
-----------------------------  ---------------
2019-04-22 22:17:39.559465 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 170 finished
-----------------------------  ---------------
replay_buffer/size              85700
trainer/QF1 Loss                   12.4858
trainer/QF2 Loss                   12.6178
trainer/Policy Loss                38.1144
trainer/Q1 Predictions Mean       -36.9525
trainer/Q1 Predictions Std         27.8575
trainer/Q1 Predictions Max        -12.4028
trainer/Q1 Predictions Min        -93.9402
trainer/Q2 Predictions Mean       -36.9695
trainer/Q2 Predictions Std         27.883
trainer/Q2 Predictions Max        -12.3966
trainer/Q2 Predictions Min        -94.4933
trainer/Q Targets Mean            -37.2485
trainer/Q Targets Std              28.5792
trainer/Q Targets Max              -0.573766
trainer/Q Targets Min             -94.7384
trainer/Log Pis Mean                2.04935
trainer/Log Pis Std                 1.49428
trainer/Log Pis Max                 8.21839
trainer/Log Pis Min                -2.47965
trainer/Policy mu Mean              0.0158459
trainer/Policy mu Std               1.04919
trainer/Policy mu Max               2.50184
trainer/Policy mu Min              -2.87182
trainer/Policy log std Mean        -1.65326
trainer/Policy log std Std          0.632175
trainer/Policy log std Max         -0.545841
trainer/Policy log std Min         -2.77058
trainer/Alpha                       0.0722184
trainer/Alpha Loss                  0.129683
exploration/num steps total     85700
exploration/num paths total       857
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.567791
exploration/Rewards Std             1.22546
exploration/Rewards Max            -0.0149531
exploration/Rewards Min            -8.52774
exploration/Returns Mean          -56.7791
exploration/Returns Std             2.62818
exploration/Returns Max           -53.5463
exploration/Returns Min           -59.4966
exploration/Actions Mean           -0.00730443
exploration/Actions Std             0.266952
exploration/Actions Max             0.990945
exploration/Actions Min            -0.9998
exploration/Num Paths               5
exploration/Average Returns       -56.7791
evaluation/num steps total     256500
evaluation/num paths total       2565
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.520608
evaluation/Rewards Std              0.966706
evaluation/Rewards Max             -0.0525256
evaluation/Rewards Min             -9.83812
evaluation/Returns Mean           -52.0608
evaluation/Returns Std             31.1431
evaluation/Returns Max            -17.4555
evaluation/Returns Min           -135.566
evaluation/Actions Mean            -0.00763868
evaluation/Actions Std              0.178843
evaluation/Actions Max              0.99514
evaluation/Actions Min             -0.998847
evaluation/Num Paths               15
evaluation/Average Returns        -52.0608
time/data storing (s)               0.00342832
time/evaluation sampling (s)        0.395723
time/exploration sampling (s)       0.185196
time/logging (s)                    0.00479703
time/saving (s)                     0.00200561
time/training (s)                   2.59717
time/epoch (s)                      3.18832
time/total (s)                    461.252
Epoch                             170
-----------------------------  ---------------
2019-04-22 22:17:42.303452 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 171 finished
-----------------------------  ---------------
replay_buffer/size              86200
trainer/QF1 Loss                    4.78196
trainer/QF2 Loss                    4.86074
trainer/Policy Loss                37.5706
trainer/Q1 Predictions Mean       -36.3499
trainer/Q1 Predictions Std         28.4953
trainer/Q1 Predictions Max        -12.4092
trainer/Q1 Predictions Min       -109.474
trainer/Q2 Predictions Mean       -36.4038
trainer/Q2 Predictions Std         28.4479
trainer/Q2 Predictions Max        -12.4194
trainer/Q2 Predictions Min       -109.277
trainer/Q Targets Mean            -36.4076
trainer/Q Targets Std              29.0854
trainer/Q Targets Max              -0.289483
trainer/Q Targets Min            -111.874
trainer/Log Pis Mean                1.83051
trainer/Log Pis Std                 1.4516
trainer/Log Pis Max                 8.14036
trainer/Log Pis Min                -2.07745
trainer/Policy mu Mean             -0.00163329
trainer/Policy mu Std               0.878358
trainer/Policy mu Max               3.08829
trainer/Policy mu Min              -2.76956
trainer/Policy log std Mean        -1.87588
trainer/Policy log std Std          0.6092
trainer/Policy log std Max         -0.482049
trainer/Policy log std Min         -2.83872
trainer/Alpha                       0.0693208
trainer/Alpha Loss                 -0.452336
exploration/num steps total     86200
exploration/num paths total       862
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.09843
exploration/Rewards Std             1.21161
exploration/Rewards Max            -0.0478392
exploration/Rewards Min           -10.6135
exploration/Returns Mean         -109.843
exploration/Returns Std            60.8081
exploration/Returns Max           -40.7029
exploration/Returns Min          -198.555
exploration/Actions Mean            0.00493555
exploration/Actions Std             0.246229
exploration/Actions Max             0.999455
exploration/Actions Min            -0.997821
exploration/Num Paths               5
exploration/Average Returns      -109.843
evaluation/num steps total     258000
evaluation/num paths total       2580
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.598492
evaluation/Rewards Std              1.06039
evaluation/Rewards Max             -0.0653816
evaluation/Rewards Min            -10.4002
evaluation/Returns Mean           -59.8492
evaluation/Returns Std             58.4945
evaluation/Returns Max             -9.68444
evaluation/Returns Min           -184.887
evaluation/Actions Mean             0.0132221
evaluation/Actions Std              0.187387
evaluation/Actions Max              0.998417
evaluation/Actions Min             -0.996668
evaluation/Num Paths               15
evaluation/Average Returns        -59.8492
time/data storing (s)               0.00343674
time/evaluation sampling (s)        0.406722
time/exploration sampling (s)       0.167352
time/logging (s)                    0.00540783
time/saving (s)                     0.00161074
time/training (s)                   2.15299
time/epoch (s)                      2.73752
time/total (s)                    463.993
Epoch                             171
-----------------------------  ---------------
2019-04-22 22:17:44.936700 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 172 finished
-----------------------------  ---------------
replay_buffer/size              86700
trainer/QF1 Loss                    3.16459
trainer/QF2 Loss                    3.29593
trainer/Policy Loss                37.5131
trainer/Q1 Predictions Mean       -36.1338
trainer/Q1 Predictions Std         28.0678
trainer/Q1 Predictions Max        -11.9812
trainer/Q1 Predictions Min       -102.031
trainer/Q2 Predictions Mean       -36.1215
trainer/Q2 Predictions Std         28.0586
trainer/Q2 Predictions Max        -11.9245
trainer/Q2 Predictions Min       -101.56
trainer/Q Targets Mean            -36.008
trainer/Q Targets Std              28.2875
trainer/Q Targets Max              -0.402935
trainer/Q Targets Min            -101.499
trainer/Log Pis Mean                2.176
trainer/Log Pis Std                 1.40986
trainer/Log Pis Max                 8.28482
trainer/Log Pis Min                -0.779854
trainer/Policy mu Mean              0.152337
trainer/Policy mu Std               1.05343
trainer/Policy mu Max               2.9469
trainer/Policy mu Min              -2.87168
trainer/Policy log std Mean        -1.75262
trainer/Policy log std Std          0.701269
trainer/Policy log std Max         -0.443294
trainer/Policy log std Min         -2.78324
trainer/Alpha                       0.0681735
trainer/Alpha Loss                  0.472715
exploration/num steps total     86700
exploration/num paths total       867
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.660187
exploration/Rewards Std             0.796528
exploration/Rewards Max            -0.014422
exploration/Rewards Min            -7.63842
exploration/Returns Mean          -66.0187
exploration/Returns Std            40.8812
exploration/Returns Max           -24.6972
exploration/Returns Min          -137.982
exploration/Actions Mean           -0.00284444
exploration/Actions Std             0.215188
exploration/Actions Max             0.994927
exploration/Actions Min            -0.999615
exploration/Num Paths               5
exploration/Average Returns       -66.0187
evaluation/num steps total     259500
evaluation/num paths total       2595
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.484193
evaluation/Rewards Std              0.838701
evaluation/Rewards Max             -0.0880885
evaluation/Rewards Min             -9.18542
evaluation/Returns Mean           -48.4193
evaluation/Returns Std             42.3856
evaluation/Returns Max            -11.5516
evaluation/Returns Min           -162.511
evaluation/Actions Mean             0.00170372
evaluation/Actions Std              0.165885
evaluation/Actions Max              0.996852
evaluation/Actions Min             -0.99913
evaluation/Num Paths               15
evaluation/Average Returns        -48.4193
time/data storing (s)               0.00309236
time/evaluation sampling (s)        0.360876
time/exploration sampling (s)       0.153309
time/logging (s)                    0.00481381
time/saving (s)                     0.00182386
time/training (s)                   2.10107
time/epoch (s)                      2.62498
time/total (s)                    466.623
Epoch                             172
-----------------------------  ---------------
2019-04-22 22:17:47.649216 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 173 finished
-----------------------------  ---------------
replay_buffer/size              87200
trainer/QF1 Loss                    5.3582
trainer/QF2 Loss                    5.42251
trainer/Policy Loss                40.3988
trainer/Q1 Predictions Mean       -38.9521
trainer/Q1 Predictions Std         30.9921
trainer/Q1 Predictions Max        -11.9846
trainer/Q1 Predictions Min       -107.225
trainer/Q2 Predictions Mean       -38.9418
trainer/Q2 Predictions Std         30.9623
trainer/Q2 Predictions Max        -11.9296
trainer/Q2 Predictions Min       -106.67
trainer/Q Targets Mean            -38.8092
trainer/Q Targets Std              31.2872
trainer/Q Targets Max              -0.183608
trainer/Q Targets Min            -108.572
trainer/Log Pis Mean                2.15146
trainer/Log Pis Std                 1.41147
trainer/Log Pis Max                 7.22474
trainer/Log Pis Min                -1.80342
trainer/Policy mu Mean             -0.0133983
trainer/Policy mu Std               0.978484
trainer/Policy mu Max               2.98126
trainer/Policy mu Min              -3.008
trainer/Policy log std Mean        -1.75787
trainer/Policy log std Std          0.649275
trainer/Policy log std Max         -0.444454
trainer/Policy log std Min         -2.84062
trainer/Alpha                       0.0689132
trainer/Alpha Loss                  0.405121
exploration/num steps total     87200
exploration/num paths total       872
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.624674
exploration/Rewards Std             0.735536
exploration/Rewards Max            -0.0214763
exploration/Rewards Min            -6.50651
exploration/Returns Mean          -62.4674
exploration/Returns Std            44.7345
exploration/Returns Max           -27.4023
exploration/Returns Min          -149.753
exploration/Actions Mean           -0.0019531
exploration/Actions Std             0.22798
exploration/Actions Max             0.994607
exploration/Actions Min            -0.99826
exploration/Num Paths               5
exploration/Average Returns       -62.4674
evaluation/num steps total     261000
evaluation/num paths total       2610
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.534473
evaluation/Rewards Std              1.00948
evaluation/Rewards Max             -0.0638509
evaluation/Rewards Min             -9.18087
evaluation/Returns Mean           -53.4473
evaluation/Returns Std             40.5047
evaluation/Returns Max             -9.2541
evaluation/Returns Min           -150.611
evaluation/Actions Mean            -0.0128563
evaluation/Actions Std              0.194011
evaluation/Actions Max              0.991584
evaluation/Actions Min             -0.99823
evaluation/Num Paths               15
evaluation/Average Returns        -53.4473
time/data storing (s)               0.00337471
time/evaluation sampling (s)        0.357893
time/exploration sampling (s)       0.157642
time/logging (s)                    0.00468613
time/saving (s)                     0.00217321
time/training (s)                   2.17927
time/epoch (s)                      2.70504
time/total (s)                    469.332
Epoch                             173
-----------------------------  ---------------
2019-04-22 22:17:50.299045 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 174 finished
-----------------------------  ---------------
replay_buffer/size              87700
trainer/QF1 Loss                    1.4915
trainer/QF2 Loss                    1.47536
trainer/Policy Loss                37.5215
trainer/Q1 Predictions Mean       -36.3379
trainer/Q1 Predictions Std         29.3986
trainer/Q1 Predictions Max        -11.7551
trainer/Q1 Predictions Min        -96.6983
trainer/Q2 Predictions Mean       -36.3498
trainer/Q2 Predictions Std         29.436
trainer/Q2 Predictions Max        -11.7096
trainer/Q2 Predictions Min        -96.7612
trainer/Q Targets Mean            -36.412
trainer/Q Targets Std              29.6679
trainer/Q Targets Max              -0.319327
trainer/Q Targets Min             -98.1498
trainer/Log Pis Mean                1.80091
trainer/Log Pis Std                 1.38276
trainer/Log Pis Max                 4.52747
trainer/Log Pis Min                -4.73154
trainer/Policy mu Mean              0.145075
trainer/Policy mu Std               0.797124
trainer/Policy mu Max               2.6179
trainer/Policy mu Min              -2.41991
trainer/Policy log std Mean        -1.87767
trainer/Policy log std Std          0.622319
trainer/Policy log std Max         -0.383777
trainer/Policy log std Min         -2.71805
trainer/Alpha                       0.0701988
trainer/Alpha Loss                 -0.528849
exploration/num steps total     87700
exploration/num paths total       877
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.541855
exploration/Rewards Std             0.766528
exploration/Rewards Max            -0.0142762
exploration/Rewards Min            -6.95534
exploration/Returns Mean          -54.1855
exploration/Returns Std            44.5847
exploration/Returns Max           -24.1818
exploration/Returns Min          -141.083
exploration/Actions Mean           -0.00261023
exploration/Actions Std             0.222169
exploration/Actions Max             0.998013
exploration/Actions Min            -0.992381
exploration/Num Paths               5
exploration/Average Returns       -54.1855
evaluation/num steps total     262500
evaluation/num paths total       2625
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.733388
evaluation/Rewards Std              1.0421
evaluation/Rewards Max             -0.0712387
evaluation/Rewards Min            -10.4444
evaluation/Returns Mean           -73.3388
evaluation/Returns Std             49.7042
evaluation/Returns Max             -8.27754
evaluation/Returns Min           -157.225
evaluation/Actions Mean             0.010451
evaluation/Actions Std              0.184102
evaluation/Actions Max              0.99722
evaluation/Actions Min             -0.997965
evaluation/Num Paths               15
evaluation/Average Returns        -73.3388
time/data storing (s)               0.0045999
time/evaluation sampling (s)        0.359383
time/exploration sampling (s)       0.161603
time/logging (s)                    0.00484631
time/saving (s)                     0.0019873
time/training (s)                   2.11053
time/epoch (s)                      2.64295
time/total (s)                    471.98
Epoch                             174
-----------------------------  ---------------
2019-04-22 22:17:52.906712 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 175 finished
-----------------------------  ---------------
replay_buffer/size              88200
trainer/QF1 Loss                    4.03208
trainer/QF2 Loss                    3.98737
trainer/Policy Loss                35.4073
trainer/Q1 Predictions Mean       -34.1581
trainer/Q1 Predictions Std         28.6954
trainer/Q1 Predictions Max        -11.6801
trainer/Q1 Predictions Min        -90.4528
trainer/Q2 Predictions Mean       -34.1525
trainer/Q2 Predictions Std         28.7003
trainer/Q2 Predictions Max        -11.662
trainer/Q2 Predictions Min        -90.4537
trainer/Q Targets Mean            -34.4574
trainer/Q Targets Std              29.1218
trainer/Q Targets Max              -2.23608
trainer/Q Targets Min             -91.6011
trainer/Log Pis Mean                1.84027
trainer/Log Pis Std                 1.37607
trainer/Log Pis Max                 7.84623
trainer/Log Pis Min                -4.27749
trainer/Policy mu Mean              0.028715
trainer/Policy mu Std               0.857917
trainer/Policy mu Max               2.76953
trainer/Policy mu Min              -3.19731
trainer/Policy log std Mean        -1.86061
trainer/Policy log std Std          0.607109
trainer/Policy log std Max         -0.552936
trainer/Policy log std Min         -2.70928
trainer/Alpha                       0.0698638
trainer/Alpha Loss                 -0.425094
exploration/num steps total     88200
exploration/num paths total       882
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.326469
exploration/Rewards Std             0.751487
exploration/Rewards Max            -0.00759092
exploration/Rewards Min            -7.56369
exploration/Returns Mean          -32.6469
exploration/Returns Std            12.1053
exploration/Returns Max           -22.7005
exploration/Returns Min           -54.2837
exploration/Actions Mean           -0.00187857
exploration/Actions Std             0.208193
exploration/Actions Max             0.997641
exploration/Actions Min            -0.99843
exploration/Num Paths               5
exploration/Average Returns       -32.6469
evaluation/num steps total     264000
evaluation/num paths total       2640
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.390136
evaluation/Rewards Std              1.0515
evaluation/Rewards Max             -0.0459355
evaluation/Rewards Min            -11.2413
evaluation/Returns Mean           -39.0136
evaluation/Returns Std             37.739
evaluation/Returns Max            -10.7661
evaluation/Returns Min           -169.186
evaluation/Actions Mean             0.00408533
evaluation/Actions Std              0.193942
evaluation/Actions Max              0.99873
evaluation/Actions Min             -0.998457
evaluation/Num Paths               15
evaluation/Average Returns        -39.0136
time/data storing (s)               0.00309659
time/evaluation sampling (s)        0.342394
time/exploration sampling (s)       0.155868
time/logging (s)                    0.00480062
time/saving (s)                     0.00192054
time/training (s)                   2.09241
time/epoch (s)                      2.60049
time/total (s)                    474.585
Epoch                             175
-----------------------------  ---------------
2019-04-22 22:17:55.595516 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 176 finished
-----------------------------  ---------------
replay_buffer/size              88700
trainer/QF1 Loss                   71.6332
trainer/QF2 Loss                   71.263
trainer/Policy Loss                31.4205
trainer/Q1 Predictions Mean       -30.0004
trainer/Q1 Predictions Std         25.5084
trainer/Q1 Predictions Max        -11.526
trainer/Q1 Predictions Min        -99.4725
trainer/Q2 Predictions Mean       -29.9936
trainer/Q2 Predictions Std         25.5077
trainer/Q2 Predictions Max        -11.5447
trainer/Q2 Predictions Min        -99.4795
trainer/Q Targets Mean            -29.2205
trainer/Q Targets Std              25.4054
trainer/Q Targets Max              -1.16477
trainer/Q Targets Min            -101.339
trainer/Log Pis Mean                1.86851
trainer/Log Pis Std                 1.62106
trainer/Log Pis Max                 8.64155
trainer/Log Pis Min                -1.89495
trainer/Policy mu Mean              0.0137769
trainer/Policy mu Std               0.868086
trainer/Policy mu Max               2.86577
trainer/Policy mu Min              -3.36978
trainer/Policy log std Mean        -1.90761
trainer/Policy log std Std          0.568049
trainer/Policy log std Max         -0.598962
trainer/Policy log std Min         -2.81622
trainer/Alpha                       0.0703064
trainer/Alpha Loss                 -0.349093
exploration/num steps total     88700
exploration/num paths total       887
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.574534
exploration/Rewards Std             1.11234
exploration/Rewards Max            -0.00480008
exploration/Rewards Min            -9.49885
exploration/Returns Mean          -57.4534
exploration/Returns Std            31.8193
exploration/Returns Max           -18.7988
exploration/Returns Min          -110.842
exploration/Actions Mean            0.0224282
exploration/Actions Std             0.252633
exploration/Actions Max             0.999023
exploration/Actions Min            -0.999721
exploration/Num Paths               5
exploration/Average Returns       -57.4534
evaluation/num steps total     265500
evaluation/num paths total       2655
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.565324
evaluation/Rewards Std              0.836299
evaluation/Rewards Max             -0.021908
evaluation/Rewards Min             -9.71167
evaluation/Returns Mean           -56.5324
evaluation/Returns Std             29.3743
evaluation/Returns Max            -19.5267
evaluation/Returns Min           -111.123
evaluation/Actions Mean             0.00153964
evaluation/Actions Std              0.173939
evaluation/Actions Max              0.996532
evaluation/Actions Min             -0.996447
evaluation/Num Paths               15
evaluation/Average Returns        -56.5324
time/data storing (s)               0.0031035
time/evaluation sampling (s)        0.352954
time/exploration sampling (s)       0.161786
time/logging (s)                    0.00489751
time/saving (s)                     0.00172331
time/training (s)                   2.15727
time/epoch (s)                      2.68174
time/total (s)                    477.271
Epoch                             176
-----------------------------  ---------------
2019-04-22 22:17:58.220034 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 177 finished
-----------------------------  ---------------
replay_buffer/size              89200
trainer/QF1 Loss                   13.7877
trainer/QF2 Loss                   13.8834
trainer/Policy Loss                32.0127
trainer/Q1 Predictions Mean       -30.9108
trainer/Q1 Predictions Std         26.1488
trainer/Q1 Predictions Max        -11.2138
trainer/Q1 Predictions Min        -98.1147
trainer/Q2 Predictions Mean       -30.9601
trainer/Q2 Predictions Std         26.1186
trainer/Q2 Predictions Max        -11.2512
trainer/Q2 Predictions Min        -97.3208
trainer/Q Targets Mean            -30.5213
trainer/Q Targets Std              26.4697
trainer/Q Targets Max              -0.109966
trainer/Q Targets Min             -99.5464
trainer/Log Pis Mean                1.8833
trainer/Log Pis Std                 1.43247
trainer/Log Pis Max                 8.17173
trainer/Log Pis Min                -3.20386
trainer/Policy mu Mean              0.142982
trainer/Policy mu Std               0.902328
trainer/Policy mu Max               3.26604
trainer/Policy mu Min              -2.68235
trainer/Policy log std Mean        -1.81745
trainer/Policy log std Std          0.62421
trainer/Policy log std Max         -0.339852
trainer/Policy log std Min         -2.65465
trainer/Alpha                       0.0723026
trainer/Alpha Loss                 -0.306565
exploration/num steps total     89200
exploration/num paths total       892
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.469926
exploration/Rewards Std             0.963142
exploration/Rewards Max            -0.0161655
exploration/Rewards Min            -9.9445
exploration/Returns Mean          -46.9926
exploration/Returns Std            23.1138
exploration/Returns Max           -22.3542
exploration/Returns Min           -89.9127
exploration/Actions Mean           -0.0133154
exploration/Actions Std             0.208471
exploration/Actions Max             0.993018
exploration/Actions Min            -0.998286
exploration/Num Paths               5
exploration/Average Returns       -46.9926
evaluation/num steps total     267000
evaluation/num paths total       2670
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.426008
evaluation/Rewards Std              1.21834
evaluation/Rewards Max             -0.0779515
evaluation/Rewards Min            -11.1452
evaluation/Returns Mean           -42.6008
evaluation/Returns Std             29.4909
evaluation/Returns Max             -9.94639
evaluation/Returns Min           -114.68
evaluation/Actions Mean            -0.0071195
evaluation/Actions Std              0.20152
evaluation/Actions Max              0.998451
evaluation/Actions Min             -0.998116
evaluation/Num Paths               15
evaluation/Average Returns        -42.6008
time/data storing (s)               0.00353264
time/evaluation sampling (s)        0.347093
time/exploration sampling (s)       0.159894
time/logging (s)                    0.0051141
time/saving (s)                     0.00208515
time/training (s)                   2.09927
time/epoch (s)                      2.61699
time/total (s)                    479.893
Epoch                             177
-----------------------------  ---------------
2019-04-22 22:18:00.875630 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 178 finished
-----------------------------  ---------------
replay_buffer/size              89700
trainer/QF1 Loss                   13.8732
trainer/QF2 Loss                   13.0788
trainer/Policy Loss                37.2086
trainer/Q1 Predictions Mean       -35.9613
trainer/Q1 Predictions Std         27.1706
trainer/Q1 Predictions Max        -10.9859
trainer/Q1 Predictions Min        -95.3751
trainer/Q2 Predictions Mean       -35.9272
trainer/Q2 Predictions Std         27.1685
trainer/Q2 Predictions Max        -10.8682
trainer/Q2 Predictions Min        -95.8296
trainer/Q Targets Mean            -35.7732
trainer/Q Targets Std              27.5778
trainer/Q Targets Max              -0.158608
trainer/Q Targets Min             -95.8844
trainer/Log Pis Mean                1.9711
trainer/Log Pis Std                 1.44866
trainer/Log Pis Max                 7.62575
trainer/Log Pis Min                -1.13281
trainer/Policy mu Mean              0.0205181
trainer/Policy mu Std               1.0526
trainer/Policy mu Max               2.82435
trainer/Policy mu Min              -3.36067
trainer/Policy log std Mean        -1.76278
trainer/Policy log std Std          0.665837
trainer/Policy log std Max         -0.148515
trainer/Policy log std Min         -2.69795
trainer/Alpha                       0.0706821
trainer/Alpha Loss                 -0.0765652
exploration/num steps total     89700
exploration/num paths total       897
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.609007
exploration/Rewards Std             0.827104
exploration/Rewards Max            -0.0134966
exploration/Rewards Min            -7.16046
exploration/Returns Mean          -60.9007
exploration/Returns Std            43.6915
exploration/Returns Max           -16.1443
exploration/Returns Min          -140.459
exploration/Actions Mean           -0.00640929
exploration/Actions Std             0.230484
exploration/Actions Max             0.994882
exploration/Actions Min            -0.999376
exploration/Num Paths               5
exploration/Average Returns       -60.9007
evaluation/num steps total     268500
evaluation/num paths total       2685
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.807061
evaluation/Rewards Std              1.08066
evaluation/Rewards Max             -0.072124
evaluation/Rewards Min             -9.55829
evaluation/Returns Mean           -80.7061
evaluation/Returns Std             43.8777
evaluation/Returns Max            -21.7309
evaluation/Returns Min           -150.569
evaluation/Actions Mean            -0.00742897
evaluation/Actions Std              0.194843
evaluation/Actions Max              0.998144
evaluation/Actions Min             -0.998948
evaluation/Num Paths               15
evaluation/Average Returns        -80.7061
time/data storing (s)               0.00381859
time/evaluation sampling (s)        0.340619
time/exploration sampling (s)       0.154074
time/logging (s)                    0.00483272
time/saving (s)                     0.00220361
time/training (s)                   2.14202
time/epoch (s)                      2.64757
time/total (s)                    482.545
Epoch                             178
-----------------------------  ---------------
2019-04-22 22:18:03.459224 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 179 finished
-----------------------------  ---------------
replay_buffer/size              90200
trainer/QF1 Loss                    1.34426
trainer/QF2 Loss                    1.38435
trainer/Policy Loss                35.392
trainer/Q1 Predictions Mean       -34.2637
trainer/Q1 Predictions Std         28.7369
trainer/Q1 Predictions Max        -11.1051
trainer/Q1 Predictions Min       -120.956
trainer/Q2 Predictions Mean       -34.3006
trainer/Q2 Predictions Std         28.765
trainer/Q2 Predictions Max        -11.0614
trainer/Q2 Predictions Min       -120.333
trainer/Q Targets Mean            -34.1493
trainer/Q Targets Std              28.9173
trainer/Q Targets Max              -0.491126
trainer/Q Targets Min            -121.944
trainer/Log Pis Mean                1.94919
trainer/Log Pis Std                 1.32483
trainer/Log Pis Max                 6.22874
trainer/Log Pis Min                -1.74158
trainer/Policy mu Mean              0.075111
trainer/Policy mu Std               0.940679
trainer/Policy mu Max               3.08646
trainer/Policy mu Min              -3.22981
trainer/Policy log std Mean        -1.8161
trainer/Policy log std Std          0.624852
trainer/Policy log std Max         -0.45173
trainer/Policy log std Min         -2.73985
trainer/Alpha                       0.0705207
trainer/Alpha Loss                 -0.134726
exploration/num steps total     90200
exploration/num paths total       902
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.566065
exploration/Rewards Std             0.956432
exploration/Rewards Max            -0.00373989
exploration/Rewards Min            -8.94876
exploration/Returns Mean          -56.6065
exploration/Returns Std            33.8667
exploration/Returns Max           -23.5185
exploration/Returns Min          -118.89
exploration/Actions Mean           -0.0298574
exploration/Actions Std             0.226034
exploration/Actions Max             0.983134
exploration/Actions Min            -0.999319
exploration/Num Paths               5
exploration/Average Returns       -56.6065
evaluation/num steps total     270000
evaluation/num paths total       2700
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.501144
evaluation/Rewards Std              1.01436
evaluation/Rewards Max             -0.0366265
evaluation/Rewards Min            -10.672
evaluation/Returns Mean           -50.1144
evaluation/Returns Std             40.3522
evaluation/Returns Max             -5.90617
evaluation/Returns Min           -155.555
evaluation/Actions Mean             0.0137591
evaluation/Actions Std              0.183377
evaluation/Actions Max              0.998771
evaluation/Actions Min             -0.99655
evaluation/Num Paths               15
evaluation/Average Returns        -50.1144
time/data storing (s)               0.00327867
time/evaluation sampling (s)        0.346735
time/exploration sampling (s)       0.154074
time/logging (s)                    0.00480827
time/saving (s)                     0.00193674
time/training (s)                   2.06503
time/epoch (s)                      2.57587
time/total (s)                    485.125
Epoch                             179
-----------------------------  ---------------
2019-04-22 22:18:06.062926 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 180 finished
-----------------------------  ---------------
replay_buffer/size              90700
trainer/QF1 Loss                    1.35638
trainer/QF2 Loss                    1.38182
trainer/Policy Loss                37.1743
trainer/Q1 Predictions Mean       -35.7381
trainer/Q1 Predictions Std         27.7581
trainer/Q1 Predictions Max        -10.6526
trainer/Q1 Predictions Min       -105.905
trainer/Q2 Predictions Mean       -35.7841
trainer/Q2 Predictions Std         27.7341
trainer/Q2 Predictions Max        -10.6542
trainer/Q2 Predictions Min       -105.388
trainer/Q Targets Mean            -35.5657
trainer/Q Targets Std              27.7283
trainer/Q Targets Max              -0.315603
trainer/Q Targets Min            -106.355
trainer/Log Pis Mean                2.2235
trainer/Log Pis Std                 1.2549
trainer/Log Pis Max                 6.65481
trainer/Log Pis Min                -1.02836
trainer/Policy mu Mean              0.150333
trainer/Policy mu Std               0.935987
trainer/Policy mu Max               3.13899
trainer/Policy mu Min              -3.03234
trainer/Policy log std Mean        -1.8777
trainer/Policy log std Std          0.619762
trainer/Policy log std Max         -0.316877
trainer/Policy log std Min         -2.65119
trainer/Alpha                       0.0710348
trainer/Alpha Loss                  0.591104
exploration/num steps total     90700
exploration/num paths total       907
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.774238
exploration/Rewards Std             0.941696
exploration/Rewards Max            -0.023201
exploration/Rewards Min            -9.86424
exploration/Returns Mean          -77.4238
exploration/Returns Std            44.465
exploration/Returns Max           -27.6075
exploration/Returns Min          -150.283
exploration/Actions Mean            0.00439245
exploration/Actions Std             0.211227
exploration/Actions Max             0.998092
exploration/Actions Min            -0.992344
exploration/Num Paths               5
exploration/Average Returns       -77.4238
evaluation/num steps total     271500
evaluation/num paths total       2715
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.542495
evaluation/Rewards Std              0.949138
evaluation/Rewards Max             -0.045307
evaluation/Rewards Min            -10.0583
evaluation/Returns Mean           -54.2495
evaluation/Returns Std             42.5537
evaluation/Returns Max            -10.5338
evaluation/Returns Min           -143.882
evaluation/Actions Mean            -0.00674377
evaluation/Actions Std              0.179662
evaluation/Actions Max              0.997947
evaluation/Actions Min             -0.997448
evaluation/Num Paths               15
evaluation/Average Returns        -54.2495
time/data storing (s)               0.00315072
time/evaluation sampling (s)        0.346819
time/exploration sampling (s)       0.1583
time/logging (s)                    0.00557776
time/saving (s)                     0.00159183
time/training (s)                   2.08184
time/epoch (s)                      2.59728
time/total (s)                    487.727
Epoch                             180
-----------------------------  ---------------
2019-04-22 22:18:08.697641 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 181 finished
-----------------------------  ---------------
replay_buffer/size              91200
trainer/QF1 Loss                    9.5225
trainer/QF2 Loss                    9.69858
trainer/Policy Loss                36.1727
trainer/Q1 Predictions Mean       -34.6326
trainer/Q1 Predictions Std         28.8694
trainer/Q1 Predictions Max        -10.921
trainer/Q1 Predictions Min       -104.546
trainer/Q2 Predictions Mean       -34.6431
trainer/Q2 Predictions Std         28.8745
trainer/Q2 Predictions Max        -10.8542
trainer/Q2 Predictions Min       -104.059
trainer/Q Targets Mean            -34.4416
trainer/Q Targets Std              29.1392
trainer/Q Targets Max              -0.496638
trainer/Q Targets Min            -106.517
trainer/Log Pis Mean                2.18631
trainer/Log Pis Std                 1.43868
trainer/Log Pis Max                 8.51474
trainer/Log Pis Min                -1.59803
trainer/Policy mu Mean              0.119332
trainer/Policy mu Std               0.951141
trainer/Policy mu Max               3.04386
trainer/Policy mu Min              -3.7743
trainer/Policy log std Mean        -1.87642
trainer/Policy log std Std          0.627693
trainer/Policy log std Max         -0.441661
trainer/Policy log std Min         -2.6712
trainer/Alpha                       0.0713957
trainer/Alpha Loss                  0.491769
exploration/num steps total     91200
exploration/num paths total       912
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.563226
exploration/Rewards Std             0.902202
exploration/Rewards Max            -0.0173922
exploration/Rewards Min            -7.58527
exploration/Returns Mean          -56.3226
exploration/Returns Std            34.9513
exploration/Returns Max           -29.5457
exploration/Returns Min          -125.407
exploration/Actions Mean            0.00950578
exploration/Actions Std             0.239516
exploration/Actions Max             0.99659
exploration/Actions Min            -0.999382
exploration/Num Paths               5
exploration/Average Returns       -56.3226
evaluation/num steps total     273000
evaluation/num paths total       2730
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.48144
evaluation/Rewards Std              1.11232
evaluation/Rewards Max             -0.0757761
evaluation/Rewards Min            -10.0705
evaluation/Returns Mean           -48.144
evaluation/Returns Std             26.9617
evaluation/Returns Max            -11.6971
evaluation/Returns Min           -132.781
evaluation/Actions Mean             0.00803232
evaluation/Actions Std              0.205861
evaluation/Actions Max              0.998102
evaluation/Actions Min             -0.997904
evaluation/Num Paths               15
evaluation/Average Returns        -48.144
time/data storing (s)               0.00319957
time/evaluation sampling (s)        0.363664
time/exploration sampling (s)       0.154921
time/logging (s)                    0.00482856
time/saving (s)                     0.00193388
time/training (s)                   2.0973
time/epoch (s)                      2.62585
time/total (s)                    490.358
Epoch                             181
-----------------------------  ---------------
2019-04-22 22:18:11.295639 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 182 finished
-----------------------------  ---------------
replay_buffer/size              91700
trainer/QF1 Loss                   20.7897
trainer/QF2 Loss                   21.226
trainer/Policy Loss                35.8343
trainer/Q1 Predictions Mean       -34.6907
trainer/Q1 Predictions Std         28.4939
trainer/Q1 Predictions Max        -10.7779
trainer/Q1 Predictions Min        -86.3182
trainer/Q2 Predictions Mean       -34.6685
trainer/Q2 Predictions Std         28.4709
trainer/Q2 Predictions Max        -10.8082
trainer/Q2 Predictions Min        -86.3483
trainer/Q Targets Mean            -34.2212
trainer/Q Targets Std              28.937
trainer/Q Targets Max              -0.685101
trainer/Q Targets Min             -86.8585
trainer/Log Pis Mean                1.9966
trainer/Log Pis Std                 1.45332
trainer/Log Pis Max                 8.167
trainer/Log Pis Min                -3.52322
trainer/Policy mu Mean              0.193532
trainer/Policy mu Std               0.910662
trainer/Policy mu Max               3.33722
trainer/Policy mu Min              -2.79814
trainer/Policy log std Mean        -1.8594
trainer/Policy log std Std          0.593066
trainer/Policy log std Max         -0.418585
trainer/Policy log std Min         -2.62978
trainer/Alpha                       0.0718419
trainer/Alpha Loss                 -0.00896525
exploration/num steps total     91700
exploration/num paths total       917
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.606344
exploration/Rewards Std             1.05433
exploration/Rewards Max            -0.0195478
exploration/Rewards Min            -9.40457
exploration/Returns Mean          -60.6344
exploration/Returns Std            23.0383
exploration/Returns Max           -20.7815
exploration/Returns Min           -90.4582
exploration/Actions Mean           -0.00996312
exploration/Actions Std             0.212038
exploration/Actions Max             0.99961
exploration/Actions Min            -0.999152
exploration/Num Paths               5
exploration/Average Returns       -60.6344
evaluation/num steps total     274500
evaluation/num paths total       2745
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.419479
evaluation/Rewards Std              1.04378
evaluation/Rewards Max             -0.0812292
evaluation/Rewards Min            -10.636
evaluation/Returns Mean           -41.9479
evaluation/Returns Std             30.2257
evaluation/Returns Max             -9.70137
evaluation/Returns Min           -124.499
evaluation/Actions Mean             0.00504234
evaluation/Actions Std              0.193979
evaluation/Actions Max              0.998353
evaluation/Actions Min             -0.999211
evaluation/Num Paths               15
evaluation/Average Returns        -41.9479
time/data storing (s)               0.00294847
time/evaluation sampling (s)        0.338092
time/exploration sampling (s)       0.152259
time/logging (s)                    0.00476935
time/saving (s)                     0.00199155
time/training (s)                   2.09015
time/epoch (s)                      2.59021
time/total (s)                    492.953
Epoch                             182
-----------------------------  ---------------
2019-04-22 22:18:13.939190 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 183 finished
-----------------------------  ---------------
replay_buffer/size              92200
trainer/QF1 Loss                    2.2175
trainer/QF2 Loss                    2.21718
trainer/Policy Loss                36.1758
trainer/Q1 Predictions Mean       -34.9686
trainer/Q1 Predictions Std         28.6184
trainer/Q1 Predictions Max        -10.8822
trainer/Q1 Predictions Min       -104.677
trainer/Q2 Predictions Mean       -34.9521
trainer/Q2 Predictions Std         28.5876
trainer/Q2 Predictions Max        -10.9498
trainer/Q2 Predictions Min       -104.083
trainer/Q Targets Mean            -35.1521
trainer/Q Targets Std              28.9552
trainer/Q Targets Max              -0.281919
trainer/Q Targets Min            -106.523
trainer/Log Pis Mean                1.8093
trainer/Log Pis Std                 1.06136
trainer/Log Pis Max                 5.22014
trainer/Log Pis Min                -2.91955
trainer/Policy mu Mean              0.154962
trainer/Policy mu Std               0.905795
trainer/Policy mu Max               2.60787
trainer/Policy mu Min              -2.78118
trainer/Policy log std Mean        -1.76883
trainer/Policy log std Std          0.582738
trainer/Policy log std Max         -0.53979
trainer/Policy log std Min         -2.5462
trainer/Alpha                       0.0707903
trainer/Alpha Loss                 -0.504936
exploration/num steps total     92200
exploration/num paths total       922
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.672655
exploration/Rewards Std             1.31509
exploration/Rewards Max            -0.0253267
exploration/Rewards Min           -11.7461
exploration/Returns Mean          -67.2655
exploration/Returns Std            31.0966
exploration/Returns Max           -28.6294
exploration/Returns Min          -119.065
exploration/Actions Mean            0.0204901
exploration/Actions Std             0.257422
exploration/Actions Max             0.999593
exploration/Actions Min            -0.999699
exploration/Num Paths               5
exploration/Average Returns       -67.2655
evaluation/num steps total     276000
evaluation/num paths total       2760
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.567152
evaluation/Rewards Std              1.00029
evaluation/Rewards Max             -0.0623041
evaluation/Rewards Min             -9.69606
evaluation/Returns Mean           -56.7152
evaluation/Returns Std             33.5024
evaluation/Returns Max            -16.9183
evaluation/Returns Min           -136.784
evaluation/Actions Mean            -0.00523814
evaluation/Actions Std              0.194238
evaluation/Actions Max              0.996776
evaluation/Actions Min             -0.99911
evaluation/Num Paths               15
evaluation/Average Returns        -56.7152
time/data storing (s)               0.00461872
time/evaluation sampling (s)        0.367228
time/exploration sampling (s)       0.180633
time/logging (s)                    0.00489917
time/saving (s)                     0.00197983
time/training (s)                   2.0767
time/epoch (s)                      2.63606
time/total (s)                    495.593
Epoch                             183
-----------------------------  ---------------
2019-04-22 22:18:16.687187 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 184 finished
-----------------------------  ----------------
replay_buffer/size              92700
trainer/QF1 Loss                    0.369251
trainer/QF2 Loss                    0.32063
trainer/Policy Loss                30.8862
trainer/Q1 Predictions Mean       -29.5798
trainer/Q1 Predictions Std         24.3121
trainer/Q1 Predictions Max        -10.9756
trainer/Q1 Predictions Min        -83.3808
trainer/Q2 Predictions Mean       -29.5501
trainer/Q2 Predictions Std         24.3544
trainer/Q2 Predictions Max        -10.8205
trainer/Q2 Predictions Min        -83.795
trainer/Q Targets Mean            -29.9273
trainer/Q Targets Std              24.6801
trainer/Q Targets Max             -10.7155
trainer/Q Targets Min             -84.718
trainer/Log Pis Mean                1.82803
trainer/Log Pis Std                 1.33952
trainer/Log Pis Max                 4.69845
trainer/Log Pis Min                -4.27869
trainer/Policy mu Mean              0.0960896
trainer/Policy mu Std               0.818044
trainer/Policy mu Max               2.77739
trainer/Policy mu Min              -3.23561
trainer/Policy log std Mean        -1.94184
trainer/Policy log std Std          0.614816
trainer/Policy log std Max         -0.395521
trainer/Policy log std Min         -2.70568
trainer/Alpha                       0.0692025
trainer/Alpha Loss                 -0.45928
exploration/num steps total     92700
exploration/num paths total       927
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.661006
exploration/Rewards Std             1.16098
exploration/Rewards Max            -0.0242514
exploration/Rewards Min           -10.0787
exploration/Returns Mean          -66.1006
exploration/Returns Std            18.0595
exploration/Returns Max           -41.8115
exploration/Returns Min           -88.5918
exploration/Actions Mean           -9.28879e-07
exploration/Actions Std             0.247508
exploration/Actions Max             0.999473
exploration/Actions Min            -0.999062
exploration/Num Paths               5
exploration/Average Returns       -66.1006
evaluation/num steps total     277500
evaluation/num paths total       2775
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.512903
evaluation/Rewards Std              0.977587
evaluation/Rewards Max             -0.00310532
evaluation/Rewards Min            -11.4666
evaluation/Returns Mean           -51.2903
evaluation/Returns Std             35.1923
evaluation/Returns Max             -0.981238
evaluation/Returns Min           -127.854
evaluation/Actions Mean             0.00686587
evaluation/Actions Std              0.187188
evaluation/Actions Max              0.998926
evaluation/Actions Min             -0.998579
evaluation/Num Paths               15
evaluation/Average Returns        -51.2903
time/data storing (s)               0.00308432
time/evaluation sampling (s)        0.349395
time/exploration sampling (s)       0.15607
time/logging (s)                    0.00491461
time/saving (s)                     0.00247286
time/training (s)                   2.2244
time/epoch (s)                      2.74034
time/total (s)                    498.338
Epoch                             184
-----------------------------  ----------------
2019-04-22 22:18:19.325155 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 185 finished
-----------------------------  ---------------
replay_buffer/size              93200
trainer/QF1 Loss                    2.95319
trainer/QF2 Loss                    2.99733
trainer/Policy Loss                31.2038
trainer/Q1 Predictions Mean       -29.9991
trainer/Q1 Predictions Std         23.7245
trainer/Q1 Predictions Max        -10.7646
trainer/Q1 Predictions Min        -94.2825
trainer/Q2 Predictions Mean       -29.9914
trainer/Q2 Predictions Std         23.682
trainer/Q2 Predictions Max        -10.7441
trainer/Q2 Predictions Min        -93.9312
trainer/Q Targets Mean            -30.0625
trainer/Q Targets Std              24.0068
trainer/Q Targets Max              -0.260017
trainer/Q Targets Min             -96.5738
trainer/Log Pis Mean                1.9502
trainer/Log Pis Std                 1.30884
trainer/Log Pis Max                 4.98914
trainer/Log Pis Min                -2.78765
trainer/Policy mu Mean              0.0535166
trainer/Policy mu Std               0.872747
trainer/Policy mu Max               2.73372
trainer/Policy mu Min              -2.7532
trainer/Policy log std Mean        -1.83706
trainer/Policy log std Std          0.642628
trainer/Policy log std Max         -0.455686
trainer/Policy log std Min         -2.82664
trainer/Alpha                       0.069692
trainer/Alpha Loss                 -0.132665
exploration/num steps total     93200
exploration/num paths total       932
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.661159
exploration/Rewards Std             1.40459
exploration/Rewards Max            -0.0125257
exploration/Rewards Min           -10.7336
exploration/Returns Mean          -66.1159
exploration/Returns Std             9.4109
exploration/Returns Max           -57.847
exploration/Returns Min           -83.9296
exploration/Actions Mean           -0.0297362
exploration/Actions Std             0.267278
exploration/Actions Max             0.996718
exploration/Actions Min            -0.998777
exploration/Num Paths               5
exploration/Average Returns       -66.1159
evaluation/num steps total     279000
evaluation/num paths total       2790
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.447808
evaluation/Rewards Std              0.890197
evaluation/Rewards Max             -0.0681993
evaluation/Rewards Min            -10.3149
evaluation/Returns Mean           -44.7808
evaluation/Returns Std             24.3451
evaluation/Returns Max             -8.78757
evaluation/Returns Min           -104.54
evaluation/Actions Mean            -0.00653887
evaluation/Actions Std              0.166109
evaluation/Actions Max              0.998369
evaluation/Actions Min             -0.998081
evaluation/Num Paths               15
evaluation/Average Returns        -44.7808
time/data storing (s)               0.00309271
time/evaluation sampling (s)        0.355624
time/exploration sampling (s)       0.155341
time/logging (s)                    0.00492915
time/saving (s)                     0.00194139
time/training (s)                   2.11057
time/epoch (s)                      2.63149
time/total (s)                    500.974
Epoch                             185
-----------------------------  ---------------
2019-04-22 22:18:22.052770 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 186 finished
-----------------------------  ----------------
replay_buffer/size              93700
trainer/QF1 Loss                   58.7825
trainer/QF2 Loss                   58.837
trainer/Policy Loss                34.7551
trainer/Q1 Predictions Mean       -33.5722
trainer/Q1 Predictions Std         25.7634
trainer/Q1 Predictions Max        -10.4257
trainer/Q1 Predictions Min        -89.1833
trainer/Q2 Predictions Mean       -33.5723
trainer/Q2 Predictions Std         25.7371
trainer/Q2 Predictions Max        -10.4751
trainer/Q2 Predictions Min        -89.631
trainer/Q Targets Mean            -33.1528
trainer/Q Targets Std              25.6553
trainer/Q Targets Max              -2.30675
trainer/Q Targets Min             -89.2774
trainer/Log Pis Mean                1.99334
trainer/Log Pis Std                 1.39388
trainer/Log Pis Max                 7.38022
trainer/Log Pis Min                -2.1975
trainer/Policy mu Mean              0.134486
trainer/Policy mu Std               0.97781
trainer/Policy mu Max               2.83126
trainer/Policy mu Min              -2.37906
trainer/Policy log std Mean        -1.70855
trainer/Policy log std Std          0.623574
trainer/Policy log std Max         -0.470828
trainer/Policy log std Min         -2.67775
trainer/Alpha                       0.0734012
trainer/Alpha Loss                 -0.0174014
exploration/num steps total     93700
exploration/num paths total       937
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.494923
exploration/Rewards Std             0.694464
exploration/Rewards Max            -0.0154013
exploration/Rewards Min            -8.4593
exploration/Returns Mean          -49.4923
exploration/Returns Std            19.6081
exploration/Returns Max           -17.5075
exploration/Returns Min           -76.6554
exploration/Actions Mean           -0.00117566
exploration/Actions Std             0.224275
exploration/Actions Max             0.986886
exploration/Actions Min            -0.998631
exploration/Num Paths               5
exploration/Average Returns       -49.4923
evaluation/num steps total     280500
evaluation/num paths total       2805
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.452194
evaluation/Rewards Std              0.836637
evaluation/Rewards Max             -0.0223037
evaluation/Rewards Min             -9.6263
evaluation/Returns Mean           -45.2194
evaluation/Returns Std             26.9318
evaluation/Returns Max             -4.08908
evaluation/Returns Min           -101.754
evaluation/Actions Mean             6.71924e-05
evaluation/Actions Std              0.165692
evaluation/Actions Max              0.997503
evaluation/Actions Min             -0.997024
evaluation/Num Paths               15
evaluation/Average Returns        -45.2194
time/data storing (s)               0.00302674
time/evaluation sampling (s)        0.358056
time/exploration sampling (s)       0.15392
time/logging (s)                    0.00551827
time/saving (s)                     0.0022283
time/training (s)                   2.1978
time/epoch (s)                      2.72055
time/total (s)                    503.699
Epoch                             186
-----------------------------  ----------------
2019-04-22 22:18:25.469777 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 187 finished
-----------------------------  ---------------
replay_buffer/size              94200
trainer/QF1 Loss                    0.278424
trainer/QF2 Loss                    0.298797
trainer/Policy Loss                35.331
trainer/Q1 Predictions Mean       -33.9303
trainer/Q1 Predictions Std         26.0989
trainer/Q1 Predictions Max        -10.4078
trainer/Q1 Predictions Min        -95.244
trainer/Q2 Predictions Mean       -33.9176
trainer/Q2 Predictions Std         26.1371
trainer/Q2 Predictions Max        -10.5112
trainer/Q2 Predictions Min        -95.1649
trainer/Q Targets Mean            -34.2023
trainer/Q Targets Std              26.3912
trainer/Q Targets Max             -10.4187
trainer/Q Targets Min             -96.4552
trainer/Log Pis Mean                2.13353
trainer/Log Pis Std                 1.45533
trainer/Log Pis Max                 8.36353
trainer/Log Pis Min                -1.92197
trainer/Policy mu Mean              0.0615001
trainer/Policy mu Std               1.07793
trainer/Policy mu Max               3.31009
trainer/Policy mu Min              -2.93704
trainer/Policy log std Mean        -1.67486
trainer/Policy log std Std          0.637148
trainer/Policy log std Max         -0.450422
trainer/Policy log std Min         -2.68517
trainer/Alpha                       0.0730946
trainer/Alpha Loss                  0.349287
exploration/num steps total     94200
exploration/num paths total       942
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.663419
exploration/Rewards Std             1.21075
exploration/Rewards Max            -0.0146792
exploration/Rewards Min           -10.4854
exploration/Returns Mean          -66.3419
exploration/Returns Std            28.4873
exploration/Returns Max           -24.1604
exploration/Returns Min          -105.942
exploration/Actions Mean            0.0402253
exploration/Actions Std             0.267852
exploration/Actions Max             0.998164
exploration/Actions Min            -0.989856
exploration/Num Paths               5
exploration/Average Returns       -66.3419
evaluation/num steps total     282000
evaluation/num paths total       2820
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.423068
evaluation/Rewards Std              0.732655
evaluation/Rewards Max             -0.0360766
evaluation/Rewards Min             -9.29536
evaluation/Returns Mean           -42.3068
evaluation/Returns Std             20.7642
evaluation/Returns Max            -10.9758
evaluation/Returns Min            -80.5337
evaluation/Actions Mean            -0.0201321
evaluation/Actions Std              0.166434
evaluation/Actions Max              0.987625
evaluation/Actions Min             -0.99806
evaluation/Num Paths               15
evaluation/Average Returns        -42.3068
time/data storing (s)               0.00348086
time/evaluation sampling (s)        0.413695
time/exploration sampling (s)       0.199586
time/logging (s)                    0.00487794
time/saving (s)                     0.00158461
time/training (s)                   2.78441
time/epoch (s)                      3.40764
time/total (s)                    507.111
Epoch                             187
-----------------------------  ---------------
2019-04-22 22:18:28.187904 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 188 finished
-----------------------------  ---------------
replay_buffer/size              94700
trainer/QF1 Loss                   11.0528
trainer/QF2 Loss                   11.0662
trainer/Policy Loss                32.7675
trainer/Q1 Predictions Mean       -31.4885
trainer/Q1 Predictions Std         25.9959
trainer/Q1 Predictions Max        -10.2434
trainer/Q1 Predictions Min       -103.161
trainer/Q2 Predictions Mean       -31.4626
trainer/Q2 Predictions Std         25.9874
trainer/Q2 Predictions Max        -10.1792
trainer/Q2 Predictions Min       -102.106
trainer/Q Targets Mean            -31.3689
trainer/Q Targets Std              26.3834
trainer/Q Targets Max              -3.60208
trainer/Q Targets Min            -102.227
trainer/Log Pis Mean                1.84115
trainer/Log Pis Std                 1.21311
trainer/Log Pis Max                 8.04566
trainer/Log Pis Min                -1.52173
trainer/Policy mu Mean              0.0533505
trainer/Policy mu Std               0.857717
trainer/Policy mu Max               2.70592
trainer/Policy mu Min              -2.93905
trainer/Policy log std Mean        -1.77729
trainer/Policy log std Std          0.600528
trainer/Policy log std Max         -0.379468
trainer/Policy log std Min         -2.6809
trainer/Alpha                       0.0717219
trainer/Alpha Loss                 -0.418557
exploration/num steps total     94700
exploration/num paths total       947
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.565762
exploration/Rewards Std             1.2186
exploration/Rewards Max            -0.00658444
exploration/Rewards Min           -10.7171
exploration/Returns Mean          -56.5762
exploration/Returns Std            36.9156
exploration/Returns Max           -22.3536
exploration/Returns Min          -125.653
exploration/Actions Mean            0.011711
exploration/Actions Std             0.25926
exploration/Actions Max             0.997774
exploration/Actions Min            -0.998754
exploration/Num Paths               5
exploration/Average Returns       -56.5762
evaluation/num steps total     283500
evaluation/num paths total       2835
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.631463
evaluation/Rewards Std              1.08166
evaluation/Rewards Max             -0.0630469
evaluation/Rewards Min            -10.6803
evaluation/Returns Mean           -63.1463
evaluation/Returns Std             27.6126
evaluation/Returns Max             -7.21667
evaluation/Returns Min           -114.822
evaluation/Actions Mean             0.0142394
evaluation/Actions Std              0.201308
evaluation/Actions Max              0.996791
evaluation/Actions Min             -0.999094
evaluation/Num Paths               15
evaluation/Average Returns        -63.1463
time/data storing (s)               0.00342488
time/evaluation sampling (s)        0.372377
time/exploration sampling (s)       0.153235
time/logging (s)                    0.00477406
time/saving (s)                     0.00194816
time/training (s)                   2.1747
time/epoch (s)                      2.71046
time/total (s)                    509.826
Epoch                             188
-----------------------------  ---------------
2019-04-22 22:18:31.011662 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 189 finished
-----------------------------  ---------------
replay_buffer/size              95200
trainer/QF1 Loss                    0.160134
trainer/QF2 Loss                    0.314672
trainer/Policy Loss                31.5145
trainer/Q1 Predictions Mean       -30.236
trainer/Q1 Predictions Std         25.2221
trainer/Q1 Predictions Max        -10.0505
trainer/Q1 Predictions Min        -88.5576
trainer/Q2 Predictions Mean       -30.2835
trainer/Q2 Predictions Std         25.1797
trainer/Q2 Predictions Max        -10.1487
trainer/Q2 Predictions Min        -88.9981
trainer/Q Targets Mean            -30.3997
trainer/Q Targets Std              25.2423
trainer/Q Targets Max             -10.1391
trainer/Q Targets Min             -88.3088
trainer/Log Pis Mean                2.17705
trainer/Log Pis Std                 1.37901
trainer/Log Pis Max                 6.22309
trainer/Log Pis Min                -1.49769
trainer/Policy mu Mean              0.152007
trainer/Policy mu Std               0.979882
trainer/Policy mu Max               2.78314
trainer/Policy mu Min              -3.56076
trainer/Policy log std Mean        -1.7653
trainer/Policy log std Std          0.60851
trainer/Policy log std Max         -0.514657
trainer/Policy log std Min         -2.6042
trainer/Alpha                       0.0728938
trainer/Alpha Loss                  0.463645
exploration/num steps total     95200
exploration/num paths total       952
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.600035
exploration/Rewards Std             1.20889
exploration/Rewards Max            -0.0222549
exploration/Rewards Min           -10.6497
exploration/Returns Mean          -60.0035
exploration/Returns Std            32.6113
exploration/Returns Max           -25.767
exploration/Returns Min          -104.69
exploration/Actions Mean            0.0302006
exploration/Actions Std             0.244307
exploration/Actions Max             0.999283
exploration/Actions Min            -0.979938
exploration/Num Paths               5
exploration/Average Returns       -60.0035
evaluation/num steps total     285000
evaluation/num paths total       2850
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.349143
evaluation/Rewards Std              0.726615
evaluation/Rewards Max             -0.0642391
evaluation/Rewards Min             -8.57506
evaluation/Returns Mean           -34.9143
evaluation/Returns Std             22.1668
evaluation/Returns Max            -11.4193
evaluation/Returns Min            -80.4122
evaluation/Actions Mean             0.00817238
evaluation/Actions Std              0.156775
evaluation/Actions Max              0.995603
evaluation/Actions Min             -0.993444
evaluation/Num Paths               15
evaluation/Average Returns        -34.9143
time/data storing (s)               0.00321089
time/evaluation sampling (s)        0.358985
time/exploration sampling (s)       0.166359
time/logging (s)                    0.0041513
time/saving (s)                     0.0022041
time/training (s)                   2.28109
time/epoch (s)                      2.816
time/total (s)                    512.646
Epoch                             189
-----------------------------  ---------------
2019-04-22 22:18:33.914866 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 190 finished
-----------------------------  ----------------
replay_buffer/size              95700
trainer/QF1 Loss                    0.351427
trainer/QF2 Loss                    0.226822
trainer/Policy Loss                32.7951
trainer/Q1 Predictions Mean       -31.4143
trainer/Q1 Predictions Std         24.6655
trainer/Q1 Predictions Max         -9.87234
trainer/Q1 Predictions Min        -92.5485
trainer/Q2 Predictions Mean       -31.439
trainer/Q2 Predictions Std         24.6626
trainer/Q2 Predictions Max        -10.0338
trainer/Q2 Predictions Min        -93.1273
trainer/Q Targets Mean            -31.6171
trainer/Q Targets Std              24.7061
trainer/Q Targets Max             -10.0233
trainer/Q Targets Min             -94.1364
trainer/Log Pis Mean                2.14197
trainer/Log Pis Std                 1.41169
trainer/Log Pis Max                 6.67208
trainer/Log Pis Min                -1.92756
trainer/Policy mu Mean              0.157188
trainer/Policy mu Std               1.02342
trainer/Policy mu Max               3.05824
trainer/Policy mu Min              -3.08952
trainer/Policy log std Mean        -1.71472
trainer/Policy log std Std          0.668212
trainer/Policy log std Max         -0.257627
trainer/Policy log std Min         -2.69149
trainer/Alpha                       0.0745043
trainer/Alpha Loss                  0.368666
exploration/num steps total     95700
exploration/num paths total       957
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.41101
exploration/Rewards Std             0.826806
exploration/Rewards Max            -0.00758902
exploration/Rewards Min            -7.40094
exploration/Returns Mean          -41.101
exploration/Returns Std            21.1766
exploration/Returns Max           -18.8432
exploration/Returns Min           -79.192
exploration/Actions Mean           -0.000270763
exploration/Actions Std             0.228067
exploration/Actions Max             0.99747
exploration/Actions Min            -0.998445
exploration/Num Paths               5
exploration/Average Returns       -41.101
evaluation/num steps total     286500
evaluation/num paths total       2865
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.417076
evaluation/Rewards Std              1.004
evaluation/Rewards Max             -0.012874
evaluation/Rewards Min             -9.56518
evaluation/Returns Mean           -41.7076
evaluation/Returns Std             21.063
evaluation/Returns Max            -11.3906
evaluation/Returns Min            -83.8881
evaluation/Actions Mean            -0.00660934
evaluation/Actions Std              0.188016
evaluation/Actions Max              0.99817
evaluation/Actions Min             -0.998905
evaluation/Num Paths               15
evaluation/Average Returns        -41.7076
time/data storing (s)               0.00306591
time/evaluation sampling (s)        0.414514
time/exploration sampling (s)       0.156036
time/logging (s)                    0.00525389
time/saving (s)                     0.00217444
time/training (s)                   2.31469
time/epoch (s)                      2.89573
time/total (s)                    515.547
Epoch                             190
-----------------------------  ----------------
2019-04-22 22:18:36.829068 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 191 finished
-----------------------------  ---------------
replay_buffer/size              96200
trainer/QF1 Loss                    0.644308
trainer/QF2 Loss                    0.620684
trainer/Policy Loss                31.5763
trainer/Q1 Predictions Mean       -30.4263
trainer/Q1 Predictions Std         24.4756
trainer/Q1 Predictions Max         -9.94557
trainer/Q1 Predictions Min        -83.5259
trainer/Q2 Predictions Mean       -30.4318
trainer/Q2 Predictions Std         24.5181
trainer/Q2 Predictions Max         -9.87102
trainer/Q2 Predictions Min        -83.8784
trainer/Q Targets Mean            -30.8474
trainer/Q Targets Std              24.9544
trainer/Q Targets Max             -10.0595
trainer/Q Targets Min             -84.6687
trainer/Log Pis Mean                1.89762
trainer/Log Pis Std                 1.52434
trainer/Log Pis Max                 5.25759
trainer/Log Pis Min                -3.42047
trainer/Policy mu Mean              0.105872
trainer/Policy mu Std               0.940606
trainer/Policy mu Max               3.22675
trainer/Policy mu Min              -2.56179
trainer/Policy log std Mean        -1.77052
trainer/Policy log std Std          0.620415
trainer/Policy log std Max         -0.414129
trainer/Policy log std Min         -2.62816
trainer/Alpha                       0.073473
trainer/Alpha Loss                 -0.267273
exploration/num steps total     96200
exploration/num paths total       962
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.493846
exploration/Rewards Std             0.722232
exploration/Rewards Max            -0.0128572
exploration/Rewards Min            -8.10299
exploration/Returns Mean          -49.3846
exploration/Returns Std            24.2189
exploration/Returns Max           -29.4583
exploration/Returns Min           -90.9115
exploration/Actions Mean           -0.0160836
exploration/Actions Std             0.237384
exploration/Actions Max             0.987288
exploration/Actions Min            -0.997965
exploration/Num Paths               5
exploration/Average Returns       -49.3846
evaluation/num steps total     288000
evaluation/num paths total       2880
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.555849
evaluation/Rewards Std              1.10758
evaluation/Rewards Max             -0.0422326
evaluation/Rewards Min             -9.90434
evaluation/Returns Mean           -55.5849
evaluation/Returns Std             23.0896
evaluation/Returns Max            -22.2323
evaluation/Returns Min            -89.6053
evaluation/Actions Mean            -0.00700883
evaluation/Actions Std              0.194366
evaluation/Actions Max              0.997133
evaluation/Actions Min             -0.999298
evaluation/Num Paths               15
evaluation/Average Returns        -55.5849
time/data storing (s)               0.00289688
time/evaluation sampling (s)        0.353787
time/exploration sampling (s)       0.150821
time/logging (s)                    0.00494218
time/saving (s)                     0.00203302
time/training (s)                   2.3914
time/epoch (s)                      2.90588
time/total (s)                    518.458
Epoch                             191
-----------------------------  ---------------
2019-04-22 22:18:39.745333 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 192 finished
-----------------------------  ----------------
replay_buffer/size              96700
trainer/QF1 Loss                    2.79965
trainer/QF2 Loss                    2.87268
trainer/Policy Loss                30.695
trainer/Q1 Predictions Mean       -29.5748
trainer/Q1 Predictions Std         22.9386
trainer/Q1 Predictions Max         -9.79187
trainer/Q1 Predictions Min        -82.3555
trainer/Q2 Predictions Mean       -29.58
trainer/Q2 Predictions Std         22.9742
trainer/Q2 Predictions Max         -9.77219
trainer/Q2 Predictions Min        -82.8908
trainer/Q Targets Mean            -29.4179
trainer/Q Targets Std              23.0631
trainer/Q Targets Max              -0.311803
trainer/Q Targets Min             -81.5735
trainer/Log Pis Mean                1.86404
trainer/Log Pis Std                 1.14583
trainer/Log Pis Max                 4.91407
trainer/Log Pis Min                -1.70059
trainer/Policy mu Mean              0.169617
trainer/Policy mu Std               0.81575
trainer/Policy mu Max               2.57686
trainer/Policy mu Min              -2.92018
trainer/Policy log std Mean        -1.84763
trainer/Policy log std Std          0.600202
trainer/Policy log std Max         -0.569491
trainer/Policy log std Min         -2.76085
trainer/Alpha                       0.0697439
trainer/Alpha Loss                 -0.362004
exploration/num steps total     96700
exploration/num paths total       967
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.543424
exploration/Rewards Std             1.02039
exploration/Rewards Max            -0.00415776
exploration/Rewards Min            -9.37116
exploration/Returns Mean          -54.3424
exploration/Returns Std            23.6281
exploration/Returns Max           -12.788
exploration/Returns Min           -81.7312
exploration/Actions Mean            0.000745894
exploration/Actions Std             0.220204
exploration/Actions Max             0.997774
exploration/Actions Min            -0.999896
exploration/Num Paths               5
exploration/Average Returns       -54.3424
evaluation/num steps total     289500
evaluation/num paths total       2895
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.468949
evaluation/Rewards Std              0.902502
evaluation/Rewards Max             -0.0085054
evaluation/Rewards Min            -10.5258
evaluation/Returns Mean           -46.8949
evaluation/Returns Std             26.4755
evaluation/Returns Max             -2.77211
evaluation/Returns Min           -114.805
evaluation/Actions Mean             0.00539316
evaluation/Actions Std              0.17758
evaluation/Actions Max              0.997857
evaluation/Actions Min             -0.998683
evaluation/Num Paths               15
evaluation/Average Returns        -46.8949
time/data storing (s)               0.00323502
time/evaluation sampling (s)        0.392787
time/exploration sampling (s)       0.163575
time/logging (s)                    0.00507896
time/saving (s)                     0.00201157
time/training (s)                   2.34182
time/epoch (s)                      2.90851
time/total (s)                    521.371
Epoch                             192
-----------------------------  ----------------
2019-04-22 22:18:42.542737 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 193 finished
-----------------------------  ---------------
replay_buffer/size              97200
trainer/QF1 Loss                    0.190134
trainer/QF2 Loss                    0.210554
trainer/Policy Loss                31.2278
trainer/Q1 Predictions Mean       -30.1797
trainer/Q1 Predictions Std         22.4396
trainer/Q1 Predictions Max        -10.1092
trainer/Q1 Predictions Min        -94.5364
trainer/Q2 Predictions Mean       -30.1908
trainer/Q2 Predictions Std         22.4426
trainer/Q2 Predictions Max        -10.0514
trainer/Q2 Predictions Min        -94.2079
trainer/Q Targets Mean            -30.4318
trainer/Q Targets Std              22.6176
trainer/Q Targets Max              -9.99403
trainer/Q Targets Min             -95.4829
trainer/Log Pis Mean                2.07869
trainer/Log Pis Std                 1.42443
trainer/Log Pis Max                 5.8682
trainer/Log Pis Min                -3.72773
trainer/Policy mu Mean              0.0949438
trainer/Policy mu Std               1.12142
trainer/Policy mu Max               2.98159
trainer/Policy mu Min              -2.58252
trainer/Policy log std Mean        -1.52936
trainer/Policy log std Std          0.667437
trainer/Policy log std Max         -0.451037
trainer/Policy log std Min         -2.64527
trainer/Alpha                       0.0683698
trainer/Alpha Loss                  0.211105
exploration/num steps total     97200
exploration/num paths total       972
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.396721
exploration/Rewards Std             0.761053
exploration/Rewards Max            -0.0069161
exploration/Rewards Min            -7.67574
exploration/Returns Mean          -39.6721
exploration/Returns Std            13.4919
exploration/Returns Max           -24.1797
exploration/Returns Min           -60.3029
exploration/Actions Mean           -0.013849
exploration/Actions Std             0.239126
exploration/Actions Max             0.991969
exploration/Actions Min            -0.998708
exploration/Num Paths               5
exploration/Average Returns       -39.6721
evaluation/num steps total     291000
evaluation/num paths total       2910
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.495248
evaluation/Rewards Std              0.99074
evaluation/Rewards Max             -0.0642778
evaluation/Rewards Min             -9.50869
evaluation/Returns Mean           -49.5248
evaluation/Returns Std             21.4242
evaluation/Returns Max            -10.2654
evaluation/Returns Min            -96.088
evaluation/Actions Mean             0.00914629
evaluation/Actions Std              0.198485
evaluation/Actions Max              0.995809
evaluation/Actions Min             -0.998705
evaluation/Num Paths               15
evaluation/Average Returns        -49.5248
time/data storing (s)               0.00373959
time/evaluation sampling (s)        0.384042
time/exploration sampling (s)       0.174381
time/logging (s)                    0.0049091
time/saving (s)                     0.0104495
time/training (s)                   2.21109
time/epoch (s)                      2.78862
time/total (s)                    524.164
Epoch                             193
-----------------------------  ---------------
2019-04-22 22:18:45.187458 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 194 finished
-----------------------------  ----------------
replay_buffer/size              97700
trainer/QF1 Loss                    9.51797
trainer/QF2 Loss                    9.74107
trainer/Policy Loss                31.6261
trainer/Q1 Predictions Mean       -30.4482
trainer/Q1 Predictions Std         24.1296
trainer/Q1 Predictions Max        -10.0487
trainer/Q1 Predictions Min       -105.164
trainer/Q2 Predictions Mean       -30.4334
trainer/Q2 Predictions Std         24.0583
trainer/Q2 Predictions Max         -9.99453
trainer/Q2 Predictions Min       -103.387
trainer/Q Targets Mean            -30.3399
trainer/Q Targets Std              24.6841
trainer/Q Targets Max              -3.46559
trainer/Q Targets Min            -107.875
trainer/Log Pis Mean                1.9879
trainer/Log Pis Std                 1.49106
trainer/Log Pis Max                 5.61692
trainer/Log Pis Min                -2.55958
trainer/Policy mu Mean             -0.00798461
trainer/Policy mu Std               1.06794
trainer/Policy mu Max               3.17513
trainer/Policy mu Min              -3.01105
trainer/Policy log std Mean        -1.6432
trainer/Policy log std Std          0.624243
trainer/Policy log std Max         -0.423333
trainer/Policy log std Min         -2.79035
trainer/Alpha                       0.0661184
trainer/Alpha Loss                 -0.0328618
exploration/num steps total     97700
exploration/num paths total       977
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.427314
exploration/Rewards Std             1.03727
exploration/Rewards Max            -0.000812536
exploration/Rewards Min           -10.0884
exploration/Returns Mean          -42.7314
exploration/Returns Std            18.7439
exploration/Returns Max           -21.2903
exploration/Returns Min           -67.1361
exploration/Actions Mean            0.00402383
exploration/Actions Std             0.243043
exploration/Actions Max             0.999283
exploration/Actions Min            -0.997798
exploration/Num Paths               5
exploration/Average Returns       -42.7314
evaluation/num steps total     292500
evaluation/num paths total       2925
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.482186
evaluation/Rewards Std              1.0575
evaluation/Rewards Max             -0.0783163
evaluation/Rewards Min            -11.4236
evaluation/Returns Mean           -48.2186
evaluation/Returns Std             25.2634
evaluation/Returns Max            -13.1337
evaluation/Returns Min            -99.421
evaluation/Actions Mean             0.0110154
evaluation/Actions Std              0.191997
evaluation/Actions Max              0.998752
evaluation/Actions Min             -0.993466
evaluation/Num Paths               15
evaluation/Average Returns        -48.2186
time/data storing (s)               0.00317604
time/evaluation sampling (s)        0.392332
time/exploration sampling (s)       0.169131
time/logging (s)                    0.00481701
time/saving (s)                     0.00193973
time/training (s)                   2.06535
time/epoch (s)                      2.63675
time/total (s)                    526.806
Epoch                             194
-----------------------------  ----------------
2019-04-22 22:18:47.711592 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 195 finished
-----------------------------  ----------------
replay_buffer/size              98200
trainer/QF1 Loss                    1.35696
trainer/QF2 Loss                    1.19409
trainer/Policy Loss                29.6077
trainer/Q1 Predictions Mean       -28.3151
trainer/Q1 Predictions Std         22.6157
trainer/Q1 Predictions Max         -9.7016
trainer/Q1 Predictions Min        -76.3404
trainer/Q2 Predictions Mean       -28.3793
trainer/Q2 Predictions Std         22.6793
trainer/Q2 Predictions Max         -9.64675
trainer/Q2 Predictions Min        -76.34
trainer/Q Targets Mean            -28.6375
trainer/Q Targets Std              23.0561
trainer/Q Targets Max              -0.262387
trainer/Q Targets Min             -77.7405
trainer/Log Pis Mean                1.96929
trainer/Log Pis Std                 1.44933
trainer/Log Pis Max                 9.76991
trainer/Log Pis Min                -2.81608
trainer/Policy mu Mean             -0.00929998
trainer/Policy mu Std               0.943876
trainer/Policy mu Max               2.75832
trainer/Policy mu Min              -3.47237
trainer/Policy log std Mean        -1.76924
trainer/Policy log std Std          0.609185
trainer/Policy log std Max         -0.498152
trainer/Policy log std Min         -2.62496
trainer/Alpha                       0.0678508
trainer/Alpha Loss                 -0.0826342
exploration/num steps total     98200
exploration/num paths total       982
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.358538
exploration/Rewards Std             0.518025
exploration/Rewards Max            -0.00912546
exploration/Rewards Min            -6.76984
exploration/Returns Mean          -35.8538
exploration/Returns Std             9.49669
exploration/Returns Max           -23.1518
exploration/Returns Min           -49.7768
exploration/Actions Mean           -0.00198418
exploration/Actions Std             0.214613
exploration/Actions Max             0.996976
exploration/Actions Min            -0.998296
exploration/Num Paths               5
exploration/Average Returns       -35.8538
evaluation/num steps total     294000
evaluation/num paths total       2940
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.350134
evaluation/Rewards Std              0.797622
evaluation/Rewards Max             -0.0356247
evaluation/Rewards Min            -10.7743
evaluation/Returns Mean           -35.0134
evaluation/Returns Std             25.0152
evaluation/Returns Max             -5.72657
evaluation/Returns Min            -90.0251
evaluation/Actions Mean             0.000298629
evaluation/Actions Std              0.170565
evaluation/Actions Max              0.998766
evaluation/Actions Min             -0.996523
evaluation/Num Paths               15
evaluation/Average Returns        -35.0134
time/data storing (s)               0.0030277
time/evaluation sampling (s)        0.337479
time/exploration sampling (s)       0.148304
time/logging (s)                    0.00477322
time/saving (s)                     0.00196334
time/training (s)                   2.02074
time/epoch (s)                      2.51629
time/total (s)                    529.326
Epoch                             195
-----------------------------  ----------------
2019-04-22 22:18:50.246716 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 196 finished
-----------------------------  ---------------
replay_buffer/size              98700
trainer/QF1 Loss                   12.2035
trainer/QF2 Loss                   12.3612
trainer/Policy Loss                31.502
trainer/Q1 Predictions Mean       -30.1477
trainer/Q1 Predictions Std         23.3948
trainer/Q1 Predictions Max         -9.70014
trainer/Q1 Predictions Min        -94.6453
trainer/Q2 Predictions Mean       -30.1295
trainer/Q2 Predictions Std         23.367
trainer/Q2 Predictions Max         -9.7452
trainer/Q2 Predictions Min        -94.6256
trainer/Q Targets Mean            -30.088
trainer/Q Targets Std              23.9532
trainer/Q Targets Max              -0.623969
trainer/Q Targets Min             -95.2997
trainer/Log Pis Mean                1.98917
trainer/Log Pis Std                 1.38686
trainer/Log Pis Max                 7.06822
trainer/Log Pis Min                -1.76323
trainer/Policy mu Mean              0.20544
trainer/Policy mu Std               0.897412
trainer/Policy mu Max               2.68959
trainer/Policy mu Min              -3.11875
trainer/Policy log std Mean        -1.80534
trainer/Policy log std Std          0.613928
trainer/Policy log std Max         -0.477918
trainer/Policy log std Min         -2.67229
trainer/Alpha                       0.0681583
trainer/Alpha Loss                 -0.0290813
exploration/num steps total     98700
exploration/num paths total       987
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.462522
exploration/Rewards Std             0.793506
exploration/Rewards Max            -0.0136352
exploration/Rewards Min            -8.88685
exploration/Returns Mean          -46.2522
exploration/Returns Std            10.4594
exploration/Returns Max           -26.8952
exploration/Returns Min           -55.1623
exploration/Actions Mean            0.0101778
exploration/Actions Std             0.24576
exploration/Actions Max             0.998324
exploration/Actions Min            -0.998529
exploration/Num Paths               5
exploration/Average Returns       -46.2522
evaluation/num steps total     295500
evaluation/num paths total       2955
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.428861
evaluation/Rewards Std              0.990764
evaluation/Rewards Max             -0.025347
evaluation/Rewards Min            -10.8824
evaluation/Returns Mean           -42.8861
evaluation/Returns Std             23.434
evaluation/Returns Max             -4.94126
evaluation/Returns Min           -101.47
evaluation/Actions Mean             0.0131553
evaluation/Actions Std              0.188247
evaluation/Actions Max              0.998359
evaluation/Actions Min             -0.999011
evaluation/Num Paths               15
evaluation/Average Returns        -42.8861
time/data storing (s)               0.00331181
time/evaluation sampling (s)        0.336679
time/exploration sampling (s)       0.151785
time/logging (s)                    0.0048231
time/saving (s)                     0.00157782
time/training (s)                   2.02984
time/epoch (s)                      2.52802
time/total (s)                    531.858
Epoch                             196
-----------------------------  ---------------
2019-04-22 22:18:52.981943 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 197 finished
-----------------------------  ---------------
replay_buffer/size              99200
trainer/QF1 Loss                    0.548519
trainer/QF2 Loss                    0.544463
trainer/Policy Loss                31.074
trainer/Q1 Predictions Mean       -29.9261
trainer/Q1 Predictions Std         22.4422
trainer/Q1 Predictions Max         -9.7689
trainer/Q1 Predictions Min        -90.0847
trainer/Q2 Predictions Mean       -29.9024
trainer/Q2 Predictions Std         22.4358
trainer/Q2 Predictions Max         -9.71148
trainer/Q2 Predictions Min        -89.8528
trainer/Q Targets Mean            -30.3136
trainer/Q Targets Std              22.9128
trainer/Q Targets Max              -9.56123
trainer/Q Targets Min             -90.7649
trainer/Log Pis Mean                2.0845
trainer/Log Pis Std                 1.62872
trainer/Log Pis Max                 7.81941
trainer/Log Pis Min                -4.14972
trainer/Policy mu Mean              0.161205
trainer/Policy mu Std               1.04778
trainer/Policy mu Max               2.77023
trainer/Policy mu Min              -2.54986
trainer/Policy log std Mean        -1.66809
trainer/Policy log std Std          0.606308
trainer/Policy log std Max         -0.477696
trainer/Policy log std Min         -2.58046
trainer/Alpha                       0.067835
trainer/Alpha Loss                  0.227375
exploration/num steps total     99200
exploration/num paths total       992
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.502548
exploration/Rewards Std             0.873861
exploration/Rewards Max            -0.0318977
exploration/Rewards Min            -9.90547
exploration/Returns Mean          -50.2548
exploration/Returns Std            15.0564
exploration/Returns Max           -30.1749
exploration/Returns Min           -68.5659
exploration/Actions Mean            0.00898033
exploration/Actions Std             0.226599
exploration/Actions Max             0.999773
exploration/Actions Min            -0.986663
exploration/Num Paths               5
exploration/Average Returns       -50.2548
evaluation/num steps total     297000
evaluation/num paths total       2970
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.375969
evaluation/Rewards Std              0.879086
evaluation/Rewards Max             -0.0276658
evaluation/Rewards Min             -9.14388
evaluation/Returns Mean           -37.5969
evaluation/Returns Std             16.7531
evaluation/Returns Max            -14.2476
evaluation/Returns Min            -68.0749
evaluation/Actions Mean             0.00180491
evaluation/Actions Std              0.187391
evaluation/Actions Max              0.99703
evaluation/Actions Min             -0.999174
evaluation/Num Paths               15
evaluation/Average Returns        -37.5969
time/data storing (s)               0.00319409
time/evaluation sampling (s)        0.356344
time/exploration sampling (s)       0.154134
time/logging (s)                    0.00545235
time/saving (s)                     0.00194813
time/training (s)                   2.20698
time/epoch (s)                      2.72805
time/total (s)                    534.591
Epoch                             197
-----------------------------  ---------------
2019-04-22 22:18:55.999591 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 198 finished
-----------------------------  ---------------
replay_buffer/size              99700
trainer/QF1 Loss                    0.173643
trainer/QF2 Loss                    0.242566
trainer/Policy Loss                29.5684
trainer/Q1 Predictions Mean       -28.1684
trainer/Q1 Predictions Std         21.1642
trainer/Q1 Predictions Max         -9.45041
trainer/Q1 Predictions Min        -80.6344
trainer/Q2 Predictions Mean       -28.1117
trainer/Q2 Predictions Std         21.1698
trainer/Q2 Predictions Max         -9.38392
trainer/Q2 Predictions Min        -81.0353
trainer/Q Targets Mean            -28.3003
trainer/Q Targets Std              21.2965
trainer/Q Targets Max              -9.56011
trainer/Q Targets Min             -81.4682
trainer/Log Pis Mean                2.01546
trainer/Log Pis Std                 1.33568
trainer/Log Pis Max                 7.19168
trainer/Log Pis Min                -1.59772
trainer/Policy mu Mean              0.096388
trainer/Policy mu Std               0.853997
trainer/Policy mu Max               2.99769
trainer/Policy mu Min              -2.88768
trainer/Policy log std Mean        -1.86946
trainer/Policy log std Std          0.585051
trainer/Policy log std Max         -0.3654
trainer/Policy log std Min         -2.59539
trainer/Alpha                       0.0699127
trainer/Alpha Loss                  0.041133
exploration/num steps total     99700
exploration/num paths total       997
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.403388
exploration/Rewards Std             0.816115
exploration/Rewards Max            -0.0180511
exploration/Rewards Min            -9.22953
exploration/Returns Mean          -40.3388
exploration/Returns Std            14.8161
exploration/Returns Max           -22.7578
exploration/Returns Min           -61.5897
exploration/Actions Mean           -0.00744932
exploration/Actions Std             0.212991
exploration/Actions Max             0.993192
exploration/Actions Min            -0.999762
exploration/Num Paths               5
exploration/Average Returns       -40.3388
evaluation/num steps total     298500
evaluation/num paths total       2985
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.44226
evaluation/Rewards Std              1.14594
evaluation/Rewards Max             -0.0776146
evaluation/Rewards Min             -9.86548
evaluation/Returns Mean           -44.226
evaluation/Returns Std             18.8051
evaluation/Returns Max            -12.0445
evaluation/Returns Min            -81.8165
evaluation/Actions Mean            -0.0110655
evaluation/Actions Std              0.20243
evaluation/Actions Max              0.998025
evaluation/Actions Min             -0.998128
evaluation/Num Paths               15
evaluation/Average Returns        -44.226
time/data storing (s)               0.00411013
time/evaluation sampling (s)        0.34735
time/exploration sampling (s)       0.161359
time/logging (s)                    0.0049788
time/saving (s)                     0.00204015
time/training (s)                   2.48979
time/epoch (s)                      3.00963
time/total (s)                    537.605
Epoch                             198
-----------------------------  ---------------
2019-04-22 22:18:58.792965 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 199 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    5.60842
trainer/QF2 Loss                    5.89052
trainer/Policy Loss                25.5563
trainer/Q1 Predictions Mean       -24.4511
trainer/Q1 Predictions Std         18.4363
trainer/Q1 Predictions Max         -9.16599
trainer/Q1 Predictions Min        -78.2003
trainer/Q2 Predictions Mean       -24.4598
trainer/Q2 Predictions Std         18.4359
trainer/Q2 Predictions Max         -9.08225
trainer/Q2 Predictions Min        -77.9208
trainer/Q Targets Mean            -24.3688
trainer/Q Targets Std              19.0763
trainer/Q Targets Max              -0.151302
trainer/Q Targets Min             -80.0484
trainer/Log Pis Mean                1.65472
trainer/Log Pis Std                 1.47771
trainer/Log Pis Max                 4.99396
trainer/Log Pis Min                -3.08582
trainer/Policy mu Mean              0.229324
trainer/Policy mu Std               0.837816
trainer/Policy mu Max               3.0661
trainer/Policy mu Min              -2.61653
trainer/Policy log std Mean        -1.81592
trainer/Policy log std Std          0.57683
trainer/Policy log std Max         -0.339628
trainer/Policy log std Min         -2.59668
trainer/Alpha                       0.0726103
trainer/Alpha Loss                 -0.905565
exploration/num steps total    100200
exploration/num paths total      1002
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.479747
exploration/Rewards Std             0.759097
exploration/Rewards Max            -0.0129889
exploration/Rewards Min            -8.33875
exploration/Returns Mean          -47.9747
exploration/Returns Std            21.1391
exploration/Returns Max           -31.7848
exploration/Returns Min           -89.7782
exploration/Actions Mean           -0.00223182
exploration/Actions Std             0.230878
exploration/Actions Max             0.99913
exploration/Actions Min            -0.996864
exploration/Num Paths               5
exploration/Average Returns       -47.9747
evaluation/num steps total     300000
evaluation/num paths total       3000
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.415476
evaluation/Rewards Std              1.04508
evaluation/Rewards Max             -0.0468962
evaluation/Rewards Min             -9.85218
evaluation/Returns Mean           -41.5476
evaluation/Returns Std             18.9511
evaluation/Returns Max             -6.36727
evaluation/Returns Min            -80.1859
evaluation/Actions Mean            -0.0155821
evaluation/Actions Std              0.19125
evaluation/Actions Max              0.998752
evaluation/Actions Min             -0.999501
evaluation/Num Paths               15
evaluation/Average Returns        -41.5476
time/data storing (s)               0.003827
time/evaluation sampling (s)        0.382495
time/exploration sampling (s)       0.177772
time/logging (s)                    0.00474007
time/saving (s)                     0.00201058
time/training (s)                   2.214
time/epoch (s)                      2.78485
time/total (s)                    540.395
Epoch                             199
-----------------------------  ---------------
2019-04-22 22:19:01.659774 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 200 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   38.5592
trainer/QF2 Loss                   38.5266
trainer/Policy Loss                28.5338
trainer/Q1 Predictions Mean       -27.478
trainer/Q1 Predictions Std         19.9351
trainer/Q1 Predictions Max         -9.57153
trainer/Q1 Predictions Min        -91.437
trainer/Q2 Predictions Mean       -27.4928
trainer/Q2 Predictions Std         19.9587
trainer/Q2 Predictions Max         -9.54186
trainer/Q2 Predictions Min        -91.5047
trainer/Q Targets Mean            -27.1962
trainer/Q Targets Std              20.3399
trainer/Q Targets Max              -0.441435
trainer/Q Targets Min             -93.912
trainer/Log Pis Mean                1.73763
trainer/Log Pis Std                 1.27282
trainer/Log Pis Max                 5.82631
trainer/Log Pis Min                -2.53484
trainer/Policy mu Mean              0.0521489
trainer/Policy mu Std               0.840551
trainer/Policy mu Max               2.58604
trainer/Policy mu Min              -2.43954
trainer/Policy log std Mean        -1.79245
trainer/Policy log std Std          0.576356
trainer/Policy log std Max         -0.492803
trainer/Policy log std Min         -2.62126
trainer/Alpha                       0.0703426
trainer/Alpha Loss                 -0.696369
exploration/num steps total    100700
exploration/num paths total      1007
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.552941
exploration/Rewards Std             0.879152
exploration/Rewards Max            -0.0117708
exploration/Rewards Min            -8.34553
exploration/Returns Mean          -55.2941
exploration/Returns Std             7.54628
exploration/Returns Max           -41.8379
exploration/Returns Min           -63.6021
exploration/Actions Mean            0.0342878
exploration/Actions Std             0.2428
exploration/Actions Max             0.997808
exploration/Actions Min            -0.961602
exploration/Num Paths               5
exploration/Average Returns       -55.2941
evaluation/num steps total     301500
evaluation/num paths total       3015
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.382806
evaluation/Rewards Std              0.930078
evaluation/Rewards Max             -0.00443133
evaluation/Rewards Min            -10.5392
evaluation/Returns Mean           -38.2806
evaluation/Returns Std             19.5746
evaluation/Returns Max             -3.98164
evaluation/Returns Min            -86.3535
evaluation/Actions Mean            -0.0102502
evaluation/Actions Std              0.178884
evaluation/Actions Max              0.998158
evaluation/Actions Min             -0.997568
evaluation/Num Paths               15
evaluation/Average Returns        -38.2806
time/data storing (s)               0.00291902
time/evaluation sampling (s)        0.374351
time/exploration sampling (s)       0.159234
time/logging (s)                    0.00483568
time/saving (s)                     0.00198028
time/training (s)                   2.31624
time/epoch (s)                      2.85956
time/total (s)                    543.258
Epoch                             200
-----------------------------  ---------------
2019-04-22 22:19:04.592405 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 201 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   74.0274
trainer/QF2 Loss                   74.0157
trainer/Policy Loss                29.5571
trainer/Q1 Predictions Mean       -28.4265
trainer/Q1 Predictions Std         20.3667
trainer/Q1 Predictions Max         -9.58875
trainer/Q1 Predictions Min        -86.4934
trainer/Q2 Predictions Mean       -28.4555
trainer/Q2 Predictions Std         20.4006
trainer/Q2 Predictions Max         -9.568
trainer/Q2 Predictions Min        -86.3582
trainer/Q Targets Mean            -27.6206
trainer/Q Targets Std              20.7014
trainer/Q Targets Max              -2.79011
trainer/Q Targets Min             -88.0364
trainer/Log Pis Mean                1.81834
trainer/Log Pis Std                 1.27745
trainer/Log Pis Max                 5.20442
trainer/Log Pis Min                -1.71627
trainer/Policy mu Mean              0.113699
trainer/Policy mu Std               0.865655
trainer/Policy mu Max               2.59632
trainer/Policy mu Min              -2.77125
trainer/Policy log std Mean        -1.77291
trainer/Policy log std Std          0.569563
trainer/Policy log std Max         -0.563679
trainer/Policy log std Min         -2.64483
trainer/Alpha                       0.0668881
trainer/Alpha Loss                 -0.491338
exploration/num steps total    101200
exploration/num paths total      1012
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.447095
exploration/Rewards Std             0.891209
exploration/Rewards Max            -0.0176966
exploration/Rewards Min            -8.17661
exploration/Returns Mean          -44.7095
exploration/Returns Std             9.02583
exploration/Returns Max           -31.9946
exploration/Returns Min           -55.0397
exploration/Actions Mean           -0.00258459
exploration/Actions Std             0.224627
exploration/Actions Max             0.995043
exploration/Actions Min            -0.999452
exploration/Num Paths               5
exploration/Average Returns       -44.7095
evaluation/num steps total     303000
evaluation/num paths total       3030
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.412617
evaluation/Rewards Std              1.00848
evaluation/Rewards Max             -0.0074762
evaluation/Rewards Min            -10.2511
evaluation/Returns Mean           -41.2617
evaluation/Returns Std             16.2733
evaluation/Returns Max            -18.9025
evaluation/Returns Min            -65.1399
evaluation/Actions Mean            -0.00890797
evaluation/Actions Std              0.199596
evaluation/Actions Max              0.996704
evaluation/Actions Min             -0.999204
evaluation/Num Paths               15
evaluation/Average Returns        -41.2617
time/data storing (s)               0.00297374
time/evaluation sampling (s)        0.3687
time/exploration sampling (s)       0.164717
time/logging (s)                    0.00619653
time/saving (s)                     0.00212922
time/training (s)                   2.38139
time/epoch (s)                      2.9261
time/total (s)                    546.19
Epoch                             201
-----------------------------  ---------------
2019-04-22 22:19:07.530466 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 202 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    6.12329
trainer/QF2 Loss                    6.21171
trainer/Policy Loss                26.5017
trainer/Q1 Predictions Mean       -25.3483
trainer/Q1 Predictions Std         18.7751
trainer/Q1 Predictions Max         -9.34187
trainer/Q1 Predictions Min        -78.6692
trainer/Q2 Predictions Mean       -25.3541
trainer/Q2 Predictions Std         18.7658
trainer/Q2 Predictions Max         -9.35255
trainer/Q2 Predictions Min        -78.4887
trainer/Q Targets Mean            -25.0597
trainer/Q Targets Std              19.2075
trainer/Q Targets Max              -0.155389
trainer/Q Targets Min             -78.7224
trainer/Log Pis Mean                1.7115
trainer/Log Pis Std                 1.35037
trainer/Log Pis Max                 4.89967
trainer/Log Pis Min                -2.66561
trainer/Policy mu Mean              0.0869479
trainer/Policy mu Std               0.803203
trainer/Policy mu Max               2.73506
trainer/Policy mu Min              -2.71551
trainer/Policy log std Mean        -1.84914
trainer/Policy log std Std          0.555095
trainer/Policy log std Max         -0.482016
trainer/Policy log std Min         -2.63854
trainer/Alpha                       0.0674309
trainer/Alpha Loss                 -0.777966
exploration/num steps total    101700
exploration/num paths total      1017
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.376693
exploration/Rewards Std             1.00345
exploration/Rewards Max            -0.00554822
exploration/Rewards Min            -9.83781
exploration/Returns Mean          -37.6693
exploration/Returns Std            19.5076
exploration/Returns Max           -16.4759
exploration/Returns Min           -68.7086
exploration/Actions Mean            0.00254241
exploration/Actions Std             0.262303
exploration/Actions Max             0.998288
exploration/Actions Min            -0.999691
exploration/Num Paths               5
exploration/Average Returns       -37.6693
evaluation/num steps total     304500
evaluation/num paths total       3045
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.36247
evaluation/Rewards Std              0.981406
evaluation/Rewards Max             -0.00463152
evaluation/Rewards Min            -10.0131
evaluation/Returns Mean           -36.247
evaluation/Returns Std             20.8281
evaluation/Returns Max             -8.52266
evaluation/Returns Min            -79.0761
evaluation/Actions Mean            -0.00538837
evaluation/Actions Std              0.195718
evaluation/Actions Max              0.998341
evaluation/Actions Min             -0.998485
evaluation/Num Paths               15
evaluation/Average Returns        -36.247
time/data storing (s)               0.00284561
time/evaluation sampling (s)        0.411565
time/exploration sampling (s)       0.166958
time/logging (s)                    0.00486245
time/saving (s)                     0.00178442
time/training (s)                   2.33898
time/epoch (s)                      2.927
time/total (s)                    549.122
Epoch                             202
-----------------------------  ---------------
2019-04-22 22:19:10.579554 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 203 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    2.0858
trainer/QF2 Loss                    2.12559
trainer/Policy Loss                26.4096
trainer/Q1 Predictions Mean       -25.2618
trainer/Q1 Predictions Std         19.567
trainer/Q1 Predictions Max         -9.32
trainer/Q1 Predictions Min        -82.247
trainer/Q2 Predictions Mean       -25.2368
trainer/Q2 Predictions Std         19.5655
trainer/Q2 Predictions Max         -9.24351
trainer/Q2 Predictions Min        -82.1991
trainer/Q Targets Mean            -25.4406
trainer/Q Targets Std              19.9541
trainer/Q Targets Max              -0.095637
trainer/Q Targets Min             -84.2143
trainer/Log Pis Mean                1.83303
trainer/Log Pis Std                 1.55328
trainer/Log Pis Max                 9.93721
trainer/Log Pis Min                -1.98557
trainer/Policy mu Mean              0.0398539
trainer/Policy mu Std               0.882734
trainer/Policy mu Max               3.18082
trainer/Policy mu Min              -2.88771
trainer/Policy log std Mean        -1.82053
trainer/Policy log std Std          0.562101
trainer/Policy log std Max         -0.420112
trainer/Policy log std Min         -2.57855
trainer/Alpha                       0.0665905
trainer/Alpha Loss                 -0.452361
exploration/num steps total    102200
exploration/num paths total      1022
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.451286
exploration/Rewards Std             1.01243
exploration/Rewards Max            -0.00819475
exploration/Rewards Min            -8.70838
exploration/Returns Mean          -45.1286
exploration/Returns Std             5.53071
exploration/Returns Max           -35.649
exploration/Returns Min           -51.988
exploration/Actions Mean            0.00020676
exploration/Actions Std             0.265654
exploration/Actions Max             0.99946
exploration/Actions Min            -0.999473
exploration/Num Paths               5
exploration/Average Returns       -45.1286
evaluation/num steps total     306000
evaluation/num paths total       3060
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.463547
evaluation/Rewards Std              1.05263
evaluation/Rewards Max             -0.0510488
evaluation/Rewards Min             -9.81849
evaluation/Returns Mean           -46.3547
evaluation/Returns Std             27.1383
evaluation/Returns Max             -5.64404
evaluation/Returns Min            -90.6329
evaluation/Actions Mean            -0.00378405
evaluation/Actions Std              0.186333
evaluation/Actions Max              0.996902
evaluation/Actions Min             -0.998053
evaluation/Num Paths               15
evaluation/Average Returns        -46.3547
time/data storing (s)               0.00317758
time/evaluation sampling (s)        0.42499
time/exploration sampling (s)       0.191824
time/logging (s)                    0.0048929
time/saving (s)                     0.00202633
time/training (s)                   2.4135
time/epoch (s)                      3.04041
time/total (s)                    552.167
Epoch                             203
-----------------------------  ---------------
2019-04-22 22:19:13.489236 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 204 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.94435
trainer/QF2 Loss                    1.93743
trainer/Policy Loss                25.2972
trainer/Q1 Predictions Mean       -24.0022
trainer/Q1 Predictions Std         16.8643
trainer/Q1 Predictions Max         -9.10577
trainer/Q1 Predictions Min        -64.2739
trainer/Q2 Predictions Mean       -23.9781
trainer/Q2 Predictions Std         16.835
trainer/Q2 Predictions Max         -9.04644
trainer/Q2 Predictions Min        -64.2393
trainer/Q Targets Mean            -24.0774
trainer/Q Targets Std              17.1361
trainer/Q Targets Max              -0.367308
trainer/Q Targets Min             -64.7392
trainer/Log Pis Mean                1.9241
trainer/Log Pis Std                 1.34621
trainer/Log Pis Max                 5.72061
trainer/Log Pis Min                -1.99077
trainer/Policy mu Mean              0.0475603
trainer/Policy mu Std               0.890251
trainer/Policy mu Max               2.96654
trainer/Policy mu Min              -2.44177
trainer/Policy log std Mean        -1.83602
trainer/Policy log std Std          0.603211
trainer/Policy log std Max         -0.463088
trainer/Policy log std Min         -2.61694
trainer/Alpha                       0.0687692
trainer/Alpha Loss                 -0.203202
exploration/num steps total    102700
exploration/num paths total      1027
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.391624
exploration/Rewards Std             0.662477
exploration/Rewards Max            -0.00698299
exploration/Rewards Min            -7.19059
exploration/Returns Mean          -39.1624
exploration/Returns Std            13.6256
exploration/Returns Max           -14.4368
exploration/Returns Min           -54.0591
exploration/Actions Mean           -0.0218812
exploration/Actions Std             0.200758
exploration/Actions Max             0.984188
exploration/Actions Min            -0.999908
exploration/Num Paths               5
exploration/Average Returns       -39.1624
evaluation/num steps total     307500
evaluation/num paths total       3075
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.361086
evaluation/Rewards Std              0.760405
evaluation/Rewards Max             -0.0323049
evaluation/Rewards Min             -9.20875
evaluation/Returns Mean           -36.1086
evaluation/Returns Std             16.2745
evaluation/Returns Max            -11.0291
evaluation/Returns Min            -60.8304
evaluation/Actions Mean            -0.0115368
evaluation/Actions Std              0.168599
evaluation/Actions Max              0.995621
evaluation/Actions Min             -0.998031
evaluation/Num Paths               15
evaluation/Average Returns        -36.1086
time/data storing (s)               0.00364889
time/evaluation sampling (s)        0.372231
time/exploration sampling (s)       0.184295
time/logging (s)                    0.00482266
time/saving (s)                     0.00210149
time/training (s)                   2.33455
time/epoch (s)                      2.90164
time/total (s)                    555.073
Epoch                             204
-----------------------------  ---------------
2019-04-22 22:19:16.649128 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 205 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   30.148
trainer/QF2 Loss                   30.5289
trainer/Policy Loss                29.7983
trainer/Q1 Predictions Mean       -28.8354
trainer/Q1 Predictions Std         18.901
trainer/Q1 Predictions Max         -8.97979
trainer/Q1 Predictions Min        -76.0045
trainer/Q2 Predictions Mean       -28.844
trainer/Q2 Predictions Std         18.9519
trainer/Q2 Predictions Max         -8.96006
trainer/Q2 Predictions Min        -76.1635
trainer/Q Targets Mean            -28.4909
trainer/Q Targets Std              18.8888
trainer/Q Targets Max              -2.84155
trainer/Q Targets Min             -76.5949
trainer/Log Pis Mean                1.79446
trainer/Log Pis Std                 1.43363
trainer/Log Pis Max                 4.97696
trainer/Log Pis Min                -3.78894
trainer/Policy mu Mean              0.137743
trainer/Policy mu Std               0.975729
trainer/Policy mu Max               2.7369
trainer/Policy mu Min              -2.2926
trainer/Policy log std Mean        -1.69021
trainer/Policy log std Std          0.596468
trainer/Policy log std Max         -0.470687
trainer/Policy log std Min         -2.54937
trainer/Alpha                       0.0667439
trainer/Alpha Loss                 -0.556358
exploration/num steps total    103200
exploration/num paths total      1032
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.588138
exploration/Rewards Std             1.34823
exploration/Rewards Max            -0.0127821
exploration/Rewards Min           -10.7246
exploration/Returns Mean          -58.8138
exploration/Returns Std             9.16739
exploration/Returns Max           -47.2233
exploration/Returns Min           -74.5431
exploration/Actions Mean           -0.00852715
exploration/Actions Std             0.276376
exploration/Actions Max             0.999273
exploration/Actions Min            -0.999283
exploration/Num Paths               5
exploration/Average Returns       -58.8138
evaluation/num steps total     309000
evaluation/num paths total       3090
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.453557
evaluation/Rewards Std              1.10849
evaluation/Rewards Max             -0.0558297
evaluation/Rewards Min            -10.756
evaluation/Returns Mean           -45.3557
evaluation/Returns Std             24.5776
evaluation/Returns Max             -8.26607
evaluation/Returns Min           -102.963
evaluation/Actions Mean             0.0163258
evaluation/Actions Std              0.195266
evaluation/Actions Max              0.998926
evaluation/Actions Min             -0.998038
evaluation/Num Paths               15
evaluation/Average Returns        -45.3557
time/data storing (s)               0.00304966
time/evaluation sampling (s)        0.365465
time/exploration sampling (s)       0.170464
time/logging (s)                    0.00528021
time/saving (s)                     0.00211398
time/training (s)                   2.60566
time/epoch (s)                      3.15203
time/total (s)                    558.23
Epoch                             205
-----------------------------  ---------------
2019-04-22 22:19:19.475493 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 206 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.881164
trainer/QF2 Loss                    0.859545
trainer/Policy Loss                27.737
trainer/Q1 Predictions Mean       -26.2859
trainer/Q1 Predictions Std         18.0937
trainer/Q1 Predictions Max         -8.98733
trainer/Q1 Predictions Min        -69.1073
trainer/Q2 Predictions Mean       -26.2988
trainer/Q2 Predictions Std         18.0962
trainer/Q2 Predictions Max         -9.02313
trainer/Q2 Predictions Min        -69.1366
trainer/Q Targets Mean            -26.209
trainer/Q Targets Std              18.113
trainer/Q Targets Max              -0.339633
trainer/Q Targets Min             -68.2931
trainer/Log Pis Mean                2.12517
trainer/Log Pis Std                 1.14488
trainer/Log Pis Max                 5.70328
trainer/Log Pis Min                -1.24929
trainer/Policy mu Mean              0.0874103
trainer/Policy mu Std               0.904643
trainer/Policy mu Max               2.73433
trainer/Policy mu Min              -2.5712
trainer/Policy log std Mean        -1.82526
trainer/Policy log std Std          0.577461
trainer/Policy log std Max         -0.287842
trainer/Policy log std Min         -2.60678
trainer/Alpha                       0.0670341
trainer/Alpha Loss                  0.338274
exploration/num steps total    103700
exploration/num paths total      1037
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.390111
exploration/Rewards Std             0.698942
exploration/Rewards Max            -0.00295569
exploration/Rewards Min            -6.85142
exploration/Returns Mean          -39.0111
exploration/Returns Std            20.6012
exploration/Returns Max           -15.7621
exploration/Returns Min           -66.9365
exploration/Actions Mean            0.00237272
exploration/Actions Std             0.200541
exploration/Actions Max             0.989759
exploration/Actions Min            -0.999288
exploration/Num Paths               5
exploration/Average Returns       -39.0111
evaluation/num steps total     310500
evaluation/num paths total       3105
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.346068
evaluation/Rewards Std              0.924351
evaluation/Rewards Max             -0.0206379
evaluation/Rewards Min            -10.4906
evaluation/Returns Mean           -34.6068
evaluation/Returns Std             20.6074
evaluation/Returns Max             -8.8173
evaluation/Returns Min            -71.4795
evaluation/Actions Mean             0.00946568
evaluation/Actions Std              0.181721
evaluation/Actions Max              0.998357
evaluation/Actions Min             -0.997754
evaluation/Num Paths               15
evaluation/Average Returns        -34.6068
time/data storing (s)               0.00332388
time/evaluation sampling (s)        0.424123
time/exploration sampling (s)       0.170336
time/logging (s)                    0.00493807
time/saving (s)                     0.00230663
time/training (s)                   2.21326
time/epoch (s)                      2.81829
time/total (s)                    561.052
Epoch                             206
-----------------------------  ---------------
2019-04-22 22:19:22.393206 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 207 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                   30.5434
trainer/QF2 Loss                   30.6541
trainer/Policy Loss                24.7314
trainer/Q1 Predictions Mean       -23.6112
trainer/Q1 Predictions Std         16.6913
trainer/Q1 Predictions Max         -8.86075
trainer/Q1 Predictions Min        -84.1858
trainer/Q2 Predictions Mean       -23.6049
trainer/Q2 Predictions Std         16.6695
trainer/Q2 Predictions Max         -8.87053
trainer/Q2 Predictions Min        -83.1894
trainer/Q Targets Mean            -23.2772
trainer/Q Targets Std              16.6504
trainer/Q Targets Max              -4.16729
trainer/Q Targets Min             -85.1528
trainer/Log Pis Mean                1.80283
trainer/Log Pis Std                 1.72348
trainer/Log Pis Max                 8.8014
trainer/Log Pis Min                -2.40715
trainer/Policy mu Mean              0.129696
trainer/Policy mu Std               0.96986
trainer/Policy mu Max               3.11928
trainer/Policy mu Min              -2.95269
trainer/Policy log std Mean        -1.79164
trainer/Policy log std Std          0.620251
trainer/Policy log std Max         -0.390071
trainer/Policy log std Min         -2.70189
trainer/Alpha                       0.0656978
trainer/Alpha Loss                 -0.536808
exploration/num steps total    104200
exploration/num paths total      1042
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.512085
exploration/Rewards Std             1.14112
exploration/Rewards Max            -0.0150008
exploration/Rewards Min           -10.3142
exploration/Returns Mean          -51.2085
exploration/Returns Std            32.8388
exploration/Returns Max           -23.5508
exploration/Returns Min          -102.999
exploration/Actions Mean            0.000706344
exploration/Actions Std             0.256459
exploration/Actions Max             0.999146
exploration/Actions Min            -0.998152
exploration/Num Paths               5
exploration/Average Returns       -51.2085
evaluation/num steps total     312000
evaluation/num paths total       3120
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.333037
evaluation/Rewards Std              0.770004
evaluation/Rewards Max             -0.0555072
evaluation/Rewards Min             -8.74223
evaluation/Returns Mean           -33.3037
evaluation/Returns Std             23.7578
evaluation/Returns Max             -9.32201
evaluation/Returns Min            -82.0266
evaluation/Actions Mean            -0.000184913
evaluation/Actions Std              0.168032
evaluation/Actions Max              0.995509
evaluation/Actions Min             -0.999574
evaluation/Num Paths               15
evaluation/Average Returns        -33.3037
time/data storing (s)               0.00384425
time/evaluation sampling (s)        0.36721
time/exploration sampling (s)       0.177855
time/logging (s)                    0.00487832
time/saving (s)                     0.00189838
time/training (s)                   2.35357
time/epoch (s)                      2.90926
time/total (s)                    563.966
Epoch                             207
-----------------------------  ----------------
2019-04-22 22:19:25.286266 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 208 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   33.436
trainer/QF2 Loss                   33.4915
trainer/Policy Loss                24.031
trainer/Q1 Predictions Mean       -22.4806
trainer/Q1 Predictions Std         15.3568
trainer/Q1 Predictions Max         -8.87136
trainer/Q1 Predictions Min        -65.6747
trainer/Q2 Predictions Mean       -22.5072
trainer/Q2 Predictions Std         15.4026
trainer/Q2 Predictions Max         -8.91901
trainer/Q2 Predictions Min        -65.83
trainer/Q Targets Mean            -22.0197
trainer/Q Targets Std              14.9793
trainer/Q Targets Max              -4.75381
trainer/Q Targets Min             -65.9348
trainer/Log Pis Mean                2.0366
trainer/Log Pis Std                 1.35005
trainer/Log Pis Max                 7.51863
trainer/Log Pis Min                -0.851326
trainer/Policy mu Mean              0.152226
trainer/Policy mu Std               0.918555
trainer/Policy mu Max               2.8563
trainer/Policy mu Min              -2.65721
trainer/Policy log std Mean        -1.7671
trainer/Policy log std Std          0.602228
trainer/Policy log std Max         -0.295665
trainer/Policy log std Min         -2.58078
trainer/Alpha                       0.0635406
trainer/Alpha Loss                  0.100863
exploration/num steps total    104700
exploration/num paths total      1047
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.528636
exploration/Rewards Std             0.843604
exploration/Rewards Max            -0.0303225
exploration/Rewards Min            -8.75341
exploration/Returns Mean          -52.8636
exploration/Returns Std            19.8391
exploration/Returns Max           -20.6196
exploration/Returns Min           -82.7518
exploration/Actions Mean            0.00787018
exploration/Actions Std             0.239644
exploration/Actions Max             0.998104
exploration/Actions Min            -0.99934
exploration/Num Paths               5
exploration/Average Returns       -52.8636
evaluation/num steps total     313500
evaluation/num paths total       3135
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.391024
evaluation/Rewards Std              0.94175
evaluation/Rewards Max             -0.0121747
evaluation/Rewards Min             -8.58101
evaluation/Returns Mean           -39.1024
evaluation/Returns Std             25.8197
evaluation/Returns Max            -11.0443
evaluation/Returns Min            -80.6584
evaluation/Actions Mean             0.0107153
evaluation/Actions Std              0.202117
evaluation/Actions Max              0.998024
evaluation/Actions Min             -0.997474
evaluation/Num Paths               15
evaluation/Average Returns        -39.1024
time/data storing (s)               0.00333486
time/evaluation sampling (s)        0.363622
time/exploration sampling (s)       0.189498
time/logging (s)                    0.0049614
time/saving (s)                     0.00262091
time/training (s)                   2.32127
time/epoch (s)                      2.88531
time/total (s)                    566.856
Epoch                             208
-----------------------------  ---------------
2019-04-22 22:19:28.639224 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 209 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    2.77411
trainer/QF2 Loss                    2.70707
trainer/Policy Loss                26.4587
trainer/Q1 Predictions Mean       -25.4079
trainer/Q1 Predictions Std         17.7262
trainer/Q1 Predictions Max         -8.48893
trainer/Q1 Predictions Min        -62.1103
trainer/Q2 Predictions Mean       -25.4041
trainer/Q2 Predictions Std         17.7412
trainer/Q2 Predictions Max         -8.56615
trainer/Q2 Predictions Min        -62.392
trainer/Q Targets Mean            -25.7947
trainer/Q Targets Std              18.1571
trainer/Q Targets Max              -1.38324
trainer/Q Targets Min             -62.6375
trainer/Log Pis Mean                1.79393
trainer/Log Pis Std                 1.67246
trainer/Log Pis Max                 6.5477
trainer/Log Pis Min                -3.63596
trainer/Policy mu Mean              0.144383
trainer/Policy mu Std               1.10559
trainer/Policy mu Max               3.33591
trainer/Policy mu Min              -3.28768
trainer/Policy log std Mean        -1.6666
trainer/Policy log std Std          0.648424
trainer/Policy log std Max         -0.408562
trainer/Policy log std Min         -2.71047
trainer/Alpha                       0.0635817
trainer/Alpha Loss                 -0.56776
exploration/num steps total    105200
exploration/num paths total      1052
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.526172
exploration/Rewards Std             1.04257
exploration/Rewards Max            -0.00714798
exploration/Rewards Min            -8.33741
exploration/Returns Mean          -52.6172
exploration/Returns Std            14.0418
exploration/Returns Max           -38.6166
exploration/Returns Min           -77.923
exploration/Actions Mean            0.0225633
exploration/Actions Std             0.254449
exploration/Actions Max             0.998397
exploration/Actions Min            -0.999316
exploration/Num Paths               5
exploration/Average Returns       -52.6172
evaluation/num steps total     315000
evaluation/num paths total       3150
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.399359
evaluation/Rewards Std              1.03802
evaluation/Rewards Max             -0.0220583
evaluation/Rewards Min            -12.0848
evaluation/Returns Mean           -39.9359
evaluation/Returns Std             18.7033
evaluation/Returns Max             -3.484
evaluation/Returns Min            -71.2556
evaluation/Actions Mean             0.00769235
evaluation/Actions Std              0.198209
evaluation/Actions Max              0.999514
evaluation/Actions Min             -0.99868
evaluation/Num Paths               15
evaluation/Average Returns        -39.9359
time/data storing (s)               0.00331404
time/evaluation sampling (s)        0.419204
time/exploration sampling (s)       0.210922
time/logging (s)                    0.0054288
time/saving (s)                     0.00247455
time/training (s)                   2.70427
time/epoch (s)                      3.34561
time/total (s)                    570.206
Epoch                             209
-----------------------------  ---------------
2019-04-22 22:19:31.618885 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 210 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   37.3365
trainer/QF2 Loss                   37.532
trainer/Policy Loss                24.9281
trainer/Q1 Predictions Mean       -23.5306
trainer/Q1 Predictions Std         15.5836
trainer/Q1 Predictions Max         -8.83534
trainer/Q1 Predictions Min        -57.165
trainer/Q2 Predictions Mean       -23.4847
trainer/Q2 Predictions Std         15.5578
trainer/Q2 Predictions Max         -8.89386
trainer/Q2 Predictions Min        -57.0823
trainer/Q Targets Mean            -22.795
trainer/Q Targets Std              16.2349
trainer/Q Targets Max              -0.263356
trainer/Q Targets Min             -58.703
trainer/Log Pis Mean                1.91197
trainer/Log Pis Std                 1.3778
trainer/Log Pis Max                 5.70372
trainer/Log Pis Min                -2.48831
trainer/Policy mu Mean              0.152914
trainer/Policy mu Std               0.879755
trainer/Policy mu Max               3.41325
trainer/Policy mu Min              -2.54336
trainer/Policy log std Mean        -1.77012
trainer/Policy log std Std          0.547975
trainer/Policy log std Max         -0.354176
trainer/Policy log std Min         -2.53306
trainer/Alpha                       0.063331
trainer/Alpha Loss                 -0.242902
exploration/num steps total    105700
exploration/num paths total      1057
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.544662
exploration/Rewards Std             1.28212
exploration/Rewards Max            -0.00841618
exploration/Rewards Min            -9.44669
exploration/Returns Mean          -54.4662
exploration/Returns Std            13.5816
exploration/Returns Max           -35.2657
exploration/Returns Min           -72.1205
exploration/Actions Mean           -0.0177141
exploration/Actions Std             0.259238
exploration/Actions Max             0.995791
exploration/Actions Min            -0.999163
exploration/Num Paths               5
exploration/Average Returns       -54.4662
evaluation/num steps total     316500
evaluation/num paths total       3165
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.386545
evaluation/Rewards Std              0.902376
evaluation/Rewards Max             -0.040427
evaluation/Rewards Min             -9.64707
evaluation/Returns Mean           -38.6545
evaluation/Returns Std             16.7116
evaluation/Returns Max            -10.3001
evaluation/Returns Min            -60.5616
evaluation/Actions Mean             0.00726989
evaluation/Actions Std              0.184185
evaluation/Actions Max              0.998646
evaluation/Actions Min             -0.997543
evaluation/Num Paths               15
evaluation/Average Returns        -38.6545
time/data storing (s)               0.00354329
time/evaluation sampling (s)        0.454391
time/exploration sampling (s)       0.180685
time/logging (s)                    0.00518213
time/saving (s)                     0.00198867
time/training (s)                   2.32613
time/epoch (s)                      2.97192
time/total (s)                    573.182
Epoch                             210
-----------------------------  ---------------
2019-04-22 22:19:34.368150 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 211 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    2.29942
trainer/QF2 Loss                    2.38978
trainer/Policy Loss                24.9012
trainer/Q1 Predictions Mean       -23.6428
trainer/Q1 Predictions Std         16.1067
trainer/Q1 Predictions Max         -8.51531
trainer/Q1 Predictions Min        -74.1779
trainer/Q2 Predictions Mean       -23.6772
trainer/Q2 Predictions Std         16.1036
trainer/Q2 Predictions Max         -8.46682
trainer/Q2 Predictions Min        -74.2428
trainer/Q Targets Mean            -23.5234
trainer/Q Targets Std              16.166
trainer/Q Targets Max              -0.511309
trainer/Q Targets Min             -74.8599
trainer/Log Pis Mean                1.96748
trainer/Log Pis Std                 1.55795
trainer/Log Pis Max                 8.40793
trainer/Log Pis Min                -2.12319
trainer/Policy mu Mean              0.0526659
trainer/Policy mu Std               0.948923
trainer/Policy mu Max               2.78676
trainer/Policy mu Min              -2.80998
trainer/Policy log std Mean        -1.87465
trainer/Policy log std Std          0.589102
trainer/Policy log std Max         -0.540002
trainer/Policy log std Min         -2.63217
trainer/Alpha                       0.0637465
trainer/Alpha Loss                 -0.0895324
exploration/num steps total    106200
exploration/num paths total      1062
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.449108
exploration/Rewards Std             0.746045
exploration/Rewards Max            -0.00390496
exploration/Rewards Min            -6.94255
exploration/Returns Mean          -44.9108
exploration/Returns Std            17.5904
exploration/Returns Max           -20.7848
exploration/Returns Min           -65.1308
exploration/Actions Mean           -0.0116808
exploration/Actions Std             0.226363
exploration/Actions Max             0.990316
exploration/Actions Min            -0.995327
exploration/Num Paths               5
exploration/Average Returns       -44.9108
evaluation/num steps total     318000
evaluation/num paths total       3180
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.454084
evaluation/Rewards Std              0.848278
evaluation/Rewards Max             -0.0466579
evaluation/Rewards Min             -9.26945
evaluation/Returns Mean           -45.4084
evaluation/Returns Std             20.6834
evaluation/Returns Max            -16.5598
evaluation/Returns Min            -82.3331
evaluation/Actions Mean             0.00590262
evaluation/Actions Std              0.188797
evaluation/Actions Max              0.995156
evaluation/Actions Min             -0.998667
evaluation/Num Paths               15
evaluation/Average Returns        -45.4084
time/data storing (s)               0.00303616
time/evaluation sampling (s)        0.362114
time/exploration sampling (s)       0.159902
time/logging (s)                    0.00610785
time/saving (s)                     0.00215439
time/training (s)                   2.20892
time/epoch (s)                      2.74224
time/total (s)                    575.929
Epoch                             211
-----------------------------  ---------------
2019-04-22 22:19:37.137976 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 212 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    2.18971
trainer/QF2 Loss                    2.18247
trainer/Policy Loss                25.8196
trainer/Q1 Predictions Mean       -24.6415
trainer/Q1 Predictions Std         16.0668
trainer/Q1 Predictions Max         -8.40517
trainer/Q1 Predictions Min        -67.0581
trainer/Q2 Predictions Mean       -24.6482
trainer/Q2 Predictions Std         16.0686
trainer/Q2 Predictions Max         -8.41909
trainer/Q2 Predictions Min        -67.3579
trainer/Q Targets Mean            -24.841
trainer/Q Targets Std              16.3193
trainer/Q Targets Max              -0.573366
trainer/Q Targets Min             -68.3489
trainer/Log Pis Mean                1.88878
trainer/Log Pis Std                 1.2908
trainer/Log Pis Max                 5.39282
trainer/Log Pis Min                -2.79926
trainer/Policy mu Mean              0.0968666
trainer/Policy mu Std               0.787278
trainer/Policy mu Max               2.81838
trainer/Policy mu Min              -2.18521
trainer/Policy log std Mean        -1.9343
trainer/Policy log std Std          0.524683
trainer/Policy log std Max         -0.485185
trainer/Policy log std Min         -2.69888
trainer/Alpha                       0.0622539
trainer/Alpha Loss                 -0.30882
exploration/num steps total    106700
exploration/num paths total      1067
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.47011
exploration/Rewards Std             0.984872
exploration/Rewards Max            -0.0234313
exploration/Rewards Min            -7.9334
exploration/Returns Mean          -47.011
exploration/Returns Std            12.7523
exploration/Returns Max           -31.8372
exploration/Returns Min           -69.3342
exploration/Actions Mean           -0.0117052
exploration/Actions Std             0.244936
exploration/Actions Max             0.997349
exploration/Actions Min            -0.997857
exploration/Num Paths               5
exploration/Average Returns       -47.011
evaluation/num steps total     319500
evaluation/num paths total       3195
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.483994
evaluation/Rewards Std              1.09061
evaluation/Rewards Max             -0.0416627
evaluation/Rewards Min            -11.2491
evaluation/Returns Mean           -48.3994
evaluation/Returns Std             19.1023
evaluation/Returns Max            -13.6872
evaluation/Returns Min            -82.1497
evaluation/Actions Mean            -0.0142599
evaluation/Actions Std              0.200052
evaluation/Actions Max              0.998329
evaluation/Actions Min             -0.998916
evaluation/Num Paths               15
evaluation/Average Returns        -48.3994
time/data storing (s)               0.00358944
time/evaluation sampling (s)        0.359163
time/exploration sampling (s)       0.182178
time/logging (s)                    0.00559338
time/saving (s)                     0.00245877
time/training (s)                   2.20781
time/epoch (s)                      2.76079
time/total (s)                    578.694
Epoch                             212
-----------------------------  ---------------
2019-04-22 22:19:39.815077 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 213 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.102417
trainer/QF2 Loss                    0.113168
trainer/Policy Loss                24.6686
trainer/Q1 Predictions Mean       -23.0657
trainer/Q1 Predictions Std         14.5406
trainer/Q1 Predictions Max         -8.50378
trainer/Q1 Predictions Min        -59.9265
trainer/Q2 Predictions Mean       -23.0955
trainer/Q2 Predictions Std         14.5448
trainer/Q2 Predictions Max         -8.54637
trainer/Q2 Predictions Min        -60.846
trainer/Q Targets Mean            -23.3318
trainer/Q Targets Std              14.579
trainer/Q Targets Max              -8.65376
trainer/Q Targets Min             -59.7619
trainer/Log Pis Mean                2.31424
trainer/Log Pis Std                 1.34958
trainer/Log Pis Max                 5.45552
trainer/Log Pis Min                -1.68302
trainer/Policy mu Mean             -0.00668775
trainer/Policy mu Std               0.968626
trainer/Policy mu Max               2.7102
trainer/Policy mu Min              -3.11299
trainer/Policy log std Mean        -1.80073
trainer/Policy log std Std          0.654636
trainer/Policy log std Max         -0.482581
trainer/Policy log std Min         -2.71727
trainer/Alpha                       0.0624714
trainer/Alpha Loss                  0.871462
exploration/num steps total    107200
exploration/num paths total      1072
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.402444
exploration/Rewards Std             0.743082
exploration/Rewards Max            -0.0144145
exploration/Rewards Min            -6.91251
exploration/Returns Mean          -40.2444
exploration/Returns Std            18.2454
exploration/Returns Max           -21.3827
exploration/Returns Min           -73.9596
exploration/Actions Mean            0.0226379
exploration/Actions Std             0.223596
exploration/Actions Max             0.998247
exploration/Actions Min            -0.986487
exploration/Num Paths               5
exploration/Average Returns       -40.2444
evaluation/num steps total     321000
evaluation/num paths total       3210
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.289688
evaluation/Rewards Std              0.85154
evaluation/Rewards Max             -0.0440026
evaluation/Rewards Min             -9.2344
evaluation/Returns Mean           -28.9688
evaluation/Returns Std             16.8487
evaluation/Returns Max            -10.306
evaluation/Returns Min            -67.0134
evaluation/Actions Mean            -0.00691886
evaluation/Actions Std              0.181348
evaluation/Actions Max              0.997715
evaluation/Actions Min             -0.996526
evaluation/Num Paths               15
evaluation/Average Returns        -28.9688
time/data storing (s)               0.00295824
time/evaluation sampling (s)        0.357653
time/exploration sampling (s)       0.154383
time/logging (s)                    0.00523383
time/saving (s)                     0.00213326
time/training (s)                   2.14667
time/epoch (s)                      2.66903
time/total (s)                    581.368
Epoch                             213
-----------------------------  ---------------
2019-04-22 22:19:42.454596 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 214 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   26.4011
trainer/QF2 Loss                   26.2761
trainer/Policy Loss                23.4831
trainer/Q1 Predictions Mean       -22.1944
trainer/Q1 Predictions Std         15.0447
trainer/Q1 Predictions Max         -8.46106
trainer/Q1 Predictions Min        -64.4679
trainer/Q2 Predictions Mean       -22.1969
trainer/Q2 Predictions Std         15.0584
trainer/Q2 Predictions Max         -8.44107
trainer/Q2 Predictions Min        -64.5068
trainer/Q Targets Mean            -21.7016
trainer/Q Targets Std              15.1357
trainer/Q Targets Max              -0.457285
trainer/Q Targets Min             -64.7381
trainer/Log Pis Mean                2.02277
trainer/Log Pis Std                 1.39293
trainer/Log Pis Max                 6.02308
trainer/Log Pis Min                -1.57377
trainer/Policy mu Mean              0.0607739
trainer/Policy mu Std               0.888053
trainer/Policy mu Max               2.77865
trainer/Policy mu Min              -2.26105
trainer/Policy log std Mean        -1.84255
trainer/Policy log std Std          0.603803
trainer/Policy log std Max         -0.427433
trainer/Policy log std Min         -2.69721
trainer/Alpha                       0.0642155
trainer/Alpha Loss                  0.0625036
exploration/num steps total    107700
exploration/num paths total      1077
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.498678
exploration/Rewards Std             1.21539
exploration/Rewards Max            -0.0116362
exploration/Rewards Min           -11.4725
exploration/Returns Mean          -49.8678
exploration/Returns Std            22.7635
exploration/Returns Max           -21.0682
exploration/Returns Min           -79.5218
exploration/Actions Mean           -0.00329346
exploration/Actions Std             0.270011
exploration/Actions Max             0.999833
exploration/Actions Min            -0.999137
exploration/Num Paths               5
exploration/Average Returns       -49.8678
evaluation/num steps total     322500
evaluation/num paths total       3225
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.367532
evaluation/Rewards Std              0.799576
evaluation/Rewards Max             -0.0553076
evaluation/Rewards Min             -9.06444
evaluation/Returns Mean           -36.7532
evaluation/Returns Std             17.6353
evaluation/Returns Max             -9.43502
evaluation/Returns Min            -63.2434
evaluation/Actions Mean             0.010804
evaluation/Actions Std              0.178962
evaluation/Actions Max              0.998104
evaluation/Actions Min             -0.998475
evaluation/Num Paths               15
evaluation/Average Returns        -36.7532
time/data storing (s)               0.00364255
time/evaluation sampling (s)        0.363627
time/exploration sampling (s)       0.164928
time/logging (s)                    0.00483817
time/saving (s)                     0.00201628
time/training (s)                   2.09219
time/epoch (s)                      2.63125
time/total (s)                    584.003
Epoch                             214
-----------------------------  ---------------
2019-04-22 22:19:45.138119 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 215 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.723445
trainer/QF2 Loss                    0.706163
trainer/Policy Loss                22.5573
trainer/Q1 Predictions Mean       -20.8402
trainer/Q1 Predictions Std         14.3365
trainer/Q1 Predictions Max         -8.87186
trainer/Q1 Predictions Min        -74.6257
trainer/Q2 Predictions Mean       -20.8257
trainer/Q2 Predictions Std         14.3624
trainer/Q2 Predictions Max         -8.94998
trainer/Q2 Predictions Min        -74.5771
trainer/Q Targets Mean            -21.2734
trainer/Q Targets Std              14.8579
trainer/Q Targets Max              -8.6819
trainer/Q Targets Min             -75.0955
trainer/Log Pis Mean                2.10948
trainer/Log Pis Std                 1.30812
trainer/Log Pis Max                 6.45905
trainer/Log Pis Min                -1.8654
trainer/Policy mu Mean              0.0557614
trainer/Policy mu Std               0.791578
trainer/Policy mu Max               2.76759
trainer/Policy mu Min              -2.14061
trainer/Policy log std Mean        -1.93274
trainer/Policy log std Std          0.545129
trainer/Policy log std Max         -0.441889
trainer/Policy log std Min         -2.64364
trainer/Alpha                       0.0636579
trainer/Alpha Loss                  0.301526
exploration/num steps total    108200
exploration/num paths total      1082
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.47473
exploration/Rewards Std             1.07295
exploration/Rewards Max            -0.0230178
exploration/Rewards Min            -9.30523
exploration/Returns Mean          -47.473
exploration/Returns Std            17.858
exploration/Returns Max           -28.271
exploration/Returns Min           -69.5418
exploration/Actions Mean            0.00850614
exploration/Actions Std             0.235552
exploration/Actions Max             0.998645
exploration/Actions Min            -0.997958
exploration/Num Paths               5
exploration/Average Returns       -47.473
evaluation/num steps total     324000
evaluation/num paths total       3240
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.391183
evaluation/Rewards Std              0.871301
evaluation/Rewards Max             -0.0199055
evaluation/Rewards Min            -11.9137
evaluation/Returns Mean           -39.1183
evaluation/Returns Std             17.3197
evaluation/Returns Max            -11.7071
evaluation/Returns Min            -75.5118
evaluation/Actions Mean             0.00311212
evaluation/Actions Std              0.17906
evaluation/Actions Max              0.998329
evaluation/Actions Min             -0.998613
evaluation/Num Paths               15
evaluation/Average Returns        -39.1183
time/data storing (s)               0.0029728
time/evaluation sampling (s)        0.343449
time/exploration sampling (s)       0.160447
time/logging (s)                    0.00526201
time/saving (s)                     0.00221219
time/training (s)                   2.16147
time/epoch (s)                      2.67581
time/total (s)                    586.683
Epoch                             215
-----------------------------  ---------------
2019-04-22 22:19:48.074668 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 216 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.70711
trainer/QF2 Loss                    1.57676
trainer/Policy Loss                22.8439
trainer/Q1 Predictions Mean       -21.548
trainer/Q1 Predictions Std         14.1807
trainer/Q1 Predictions Max         -8.54794
trainer/Q1 Predictions Min        -52.931
trainer/Q2 Predictions Mean       -21.4966
trainer/Q2 Predictions Std         14.1186
trainer/Q2 Predictions Max         -8.56918
trainer/Q2 Predictions Min        -52.9751
trainer/Q Targets Mean            -21.585
trainer/Q Targets Std              14.239
trainer/Q Targets Max              -0.530785
trainer/Q Targets Min             -53.2424
trainer/Log Pis Mean                1.79769
trainer/Log Pis Std                 1.44171
trainer/Log Pis Max                 5.56296
trainer/Log Pis Min                -2.55784
trainer/Policy mu Mean             -0.00462697
trainer/Policy mu Std               0.852985
trainer/Policy mu Max               2.42188
trainer/Policy mu Min              -3.00051
trainer/Policy log std Mean        -1.87911
trainer/Policy log std Std          0.552547
trainer/Policy log std Max         -0.259149
trainer/Policy log std Min         -2.72301
trainer/Alpha                       0.0637472
trainer/Alpha Loss                 -0.556923
exploration/num steps total    108700
exploration/num paths total      1087
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.452343
exploration/Rewards Std             0.879683
exploration/Rewards Max            -0.0096243
exploration/Rewards Min            -7.80423
exploration/Returns Mean          -45.2343
exploration/Returns Std            10.6624
exploration/Returns Max           -31.124
exploration/Returns Min           -63.9185
exploration/Actions Mean           -0.015964
exploration/Actions Std             0.233137
exploration/Actions Max             0.997433
exploration/Actions Min            -0.999605
exploration/Num Paths               5
exploration/Average Returns       -45.2343
evaluation/num steps total     325500
evaluation/num paths total       3255
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.450194
evaluation/Rewards Std              1.15704
evaluation/Rewards Max             -0.0253231
evaluation/Rewards Min            -11.8272
evaluation/Returns Mean           -45.0194
evaluation/Returns Std             22.8891
evaluation/Returns Max            -10.8606
evaluation/Returns Min            -91.3255
evaluation/Actions Mean            -0.00739624
evaluation/Actions Std              0.20761
evaluation/Actions Max              0.999108
evaluation/Actions Min             -0.998915
evaluation/Num Paths               15
evaluation/Average Returns        -45.0194
time/data storing (s)               0.00365116
time/evaluation sampling (s)        0.361423
time/exploration sampling (s)       0.32533
time/logging (s)                    0.0047645
time/saving (s)                     0.00197179
time/training (s)                   2.23078
time/epoch (s)                      2.92792
time/total (s)                    589.616
Epoch                             216
-----------------------------  ---------------
2019-04-22 22:19:50.993732 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 217 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0605101
trainer/QF2 Loss                    0.0768564
trainer/Policy Loss                25.208
trainer/Q1 Predictions Mean       -24.171
trainer/Q1 Predictions Std         16.1815
trainer/Q1 Predictions Max         -8.36624
trainer/Q1 Predictions Min        -73.3438
trainer/Q2 Predictions Mean       -24.1423
trainer/Q2 Predictions Std         16.1575
trainer/Q2 Predictions Max         -8.41209
trainer/Q2 Predictions Min        -72.968
trainer/Q Targets Mean            -24.2593
trainer/Q Targets Std              16.1791
trainer/Q Targets Max              -8.51138
trainer/Q Targets Min             -73.3646
trainer/Log Pis Mean                1.81256
trainer/Log Pis Std                 1.60409
trainer/Log Pis Max                 5.75945
trainer/Log Pis Min                -3.77574
trainer/Policy mu Mean              0.086441
trainer/Policy mu Std               1.01332
trainer/Policy mu Max               2.7889
trainer/Policy mu Min              -3.07998
trainer/Policy log std Mean        -1.73448
trainer/Policy log std Std          0.606877
trainer/Policy log std Max         -0.522652
trainer/Policy log std Min         -2.59517
trainer/Alpha                       0.0630511
trainer/Alpha Loss                 -0.518019
exploration/num steps total    109200
exploration/num paths total      1092
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.441038
exploration/Rewards Std             1.25537
exploration/Rewards Max            -0.0057543
exploration/Rewards Min            -9.62569
exploration/Returns Mean          -44.1038
exploration/Returns Std            11.3303
exploration/Returns Max           -31.9817
exploration/Returns Min           -59.7308
exploration/Actions Mean            0.00291429
exploration/Actions Std             0.259218
exploration/Actions Max             0.999761
exploration/Actions Min            -0.9992
exploration/Num Paths               5
exploration/Average Returns       -44.1038
evaluation/num steps total     327000
evaluation/num paths total       3270
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.388529
evaluation/Rewards Std              0.95176
evaluation/Rewards Max             -0.0273777
evaluation/Rewards Min            -10.4078
evaluation/Returns Mean           -38.8529
evaluation/Returns Std             21.2745
evaluation/Returns Max             -9.58562
evaluation/Returns Min            -88.6738
evaluation/Actions Mean            -0.0108685
evaluation/Actions Std              0.194424
evaluation/Actions Max              0.996681
evaluation/Actions Min             -0.997974
evaluation/Num Paths               15
evaluation/Average Returns        -38.8529
time/data storing (s)               0.00370066
time/evaluation sampling (s)        0.341244
time/exploration sampling (s)       0.162102
time/logging (s)                    0.00714036
time/saving (s)                     0.00368509
time/training (s)                   2.39549
time/epoch (s)                      2.91336
time/total (s)                    592.535
Epoch                             217
-----------------------------  ---------------
2019-04-22 22:19:53.782796 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 218 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.21045
trainer/QF2 Loss                    0.220147
trainer/Policy Loss                24.2073
trainer/Q1 Predictions Mean       -22.7378
trainer/Q1 Predictions Std         14.2885
trainer/Q1 Predictions Max         -8.43156
trainer/Q1 Predictions Min        -51.9614
trainer/Q2 Predictions Mean       -22.7521
trainer/Q2 Predictions Std         14.2945
trainer/Q2 Predictions Max         -8.44501
trainer/Q2 Predictions Min        -51.9529
trainer/Q Targets Mean            -23.0819
trainer/Q Targets Std              14.4132
trainer/Q Targets Max              -8.47263
trainer/Q Targets Min             -52.5082
trainer/Log Pis Mean                2.18807
trainer/Log Pis Std                 1.2535
trainer/Log Pis Max                 6.72423
trainer/Log Pis Min                -2.13301
trainer/Policy mu Mean              0.110246
trainer/Policy mu Std               0.910523
trainer/Policy mu Max               3.05816
trainer/Policy mu Min              -2.31743
trainer/Policy log std Mean        -1.91397
trainer/Policy log std Std          0.583407
trainer/Policy log std Max         -0.351727
trainer/Policy log std Min         -2.7244
trainer/Alpha                       0.064604
trainer/Alpha Loss                  0.51526
exploration/num steps total    109700
exploration/num paths total      1097
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.578738
exploration/Rewards Std             1.43528
exploration/Rewards Max            -0.010592
exploration/Rewards Min           -10.0808
exploration/Returns Mean          -57.8738
exploration/Returns Std            23.5479
exploration/Returns Max           -16.4783
exploration/Returns Min           -84.232
exploration/Actions Mean            0.0105323
exploration/Actions Std             0.277805
exploration/Actions Max             0.999446
exploration/Actions Min            -0.999555
exploration/Num Paths               5
exploration/Average Returns       -57.8738
evaluation/num steps total     328500
evaluation/num paths total       3285
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.36569
evaluation/Rewards Std              1.0575
evaluation/Rewards Max             -0.0109551
evaluation/Rewards Min            -10.9098
evaluation/Returns Mean           -36.569
evaluation/Returns Std             20.1553
evaluation/Returns Max             -5.55456
evaluation/Returns Min            -90.3027
evaluation/Actions Mean            -0.00567389
evaluation/Actions Std              0.197397
evaluation/Actions Max              0.999203
evaluation/Actions Min             -0.997743
evaluation/Num Paths               15
evaluation/Average Returns        -36.569
time/data storing (s)               0.00353983
time/evaluation sampling (s)        0.406229
time/exploration sampling (s)       0.185429
time/logging (s)                    0.00482704
time/saving (s)                     0.00202481
time/training (s)                   2.17249
time/epoch (s)                      2.77454
time/total (s)                    595.316
Epoch                             218
-----------------------------  ---------------
2019-04-22 22:19:56.452720 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 219 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0540028
trainer/QF2 Loss                    0.0762767
trainer/Policy Loss                21.9209
trainer/Q1 Predictions Mean       -20.8161
trainer/Q1 Predictions Std         13.4807
trainer/Q1 Predictions Max         -8.24331
trainer/Q1 Predictions Min        -50.4759
trainer/Q2 Predictions Mean       -20.784
trainer/Q2 Predictions Std         13.4673
trainer/Q2 Predictions Max         -8.14275
trainer/Q2 Predictions Min        -50.35
trainer/Q Targets Mean            -20.9502
trainer/Q Targets Std              13.4341
trainer/Q Targets Max              -8.37641
trainer/Q Targets Min             -51.141
trainer/Log Pis Mean                1.76161
trainer/Log Pis Std                 1.25812
trainer/Log Pis Max                 4.97773
trainer/Log Pis Min                -2.31642
trainer/Policy mu Mean              0.0423727
trainer/Policy mu Std               0.813151
trainer/Policy mu Max               2.46527
trainer/Policy mu Min              -2.53481
trainer/Policy log std Mean        -1.9247
trainer/Policy log std Std          0.542097
trainer/Policy log std Max         -0.599148
trainer/Policy log std Min         -2.70492
trainer/Alpha                       0.0672551
trainer/Alpha Loss                 -0.643454
exploration/num steps total    110200
exploration/num paths total      1102
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.490427
exploration/Rewards Std             1.14717
exploration/Rewards Max            -0.0150594
exploration/Rewards Min            -8.7748
exploration/Returns Mean          -49.0427
exploration/Returns Std             2.13184
exploration/Returns Max           -46.9924
exploration/Returns Min           -51.7979
exploration/Actions Mean           -0.0193489
exploration/Actions Std             0.254496
exploration/Actions Max             0.997457
exploration/Actions Min            -0.998961
exploration/Num Paths               5
exploration/Average Returns       -49.0427
evaluation/num steps total     330000
evaluation/num paths total       3300
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.323316
evaluation/Rewards Std              1.05579
evaluation/Rewards Max             -0.0426436
evaluation/Rewards Min            -10.7551
evaluation/Returns Mean           -32.3316
evaluation/Returns Std             23.8471
evaluation/Returns Max             -7.06042
evaluation/Returns Min            -97.5775
evaluation/Actions Mean            -0.00766924
evaluation/Actions Std              0.191921
evaluation/Actions Max              0.998384
evaluation/Actions Min             -0.998923
evaluation/Num Paths               15
evaluation/Average Returns        -32.3316
time/data storing (s)               0.00308108
time/evaluation sampling (s)        0.343944
time/exploration sampling (s)       0.155224
time/logging (s)                    0.00492095
time/saving (s)                     0.00268607
time/training (s)                   2.1521
time/epoch (s)                      2.66195
time/total (s)                    597.982
Epoch                             219
-----------------------------  ---------------
2019-04-22 22:19:59.230297 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 220 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    5.03075
trainer/QF2 Loss                    4.9221
trainer/Policy Loss                24.1177
trainer/Q1 Predictions Mean       -22.9375
trainer/Q1 Predictions Std         13.6621
trainer/Q1 Predictions Max         -8.47815
trainer/Q1 Predictions Min        -56.978
trainer/Q2 Predictions Mean       -22.9157
trainer/Q2 Predictions Std         13.614
trainer/Q2 Predictions Max         -8.44921
trainer/Q2 Predictions Min        -57.6042
trainer/Q Targets Mean            -23.1129
trainer/Q Targets Std              14.1221
trainer/Q Targets Max              -0.573822
trainer/Q Targets Min             -59.3814
trainer/Log Pis Mean                1.98827
trainer/Log Pis Std                 1.97645
trainer/Log Pis Max                 6.8092
trainer/Log Pis Min                -6.31873
trainer/Policy mu Mean             -0.01574
trainer/Policy mu Std               1.09435
trainer/Policy mu Max               3.21188
trainer/Policy mu Min              -3.38327
trainer/Policy log std Mean        -1.75964
trainer/Policy log std Std          0.667741
trainer/Policy log std Max         -0.0738453
trainer/Policy log std Min         -2.70763
trainer/Alpha                       0.066165
trainer/Alpha Loss                 -0.0318633
exploration/num steps total    110700
exploration/num paths total      1107
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.492836
exploration/Rewards Std             0.964893
exploration/Rewards Max            -0.00839162
exploration/Rewards Min            -9.90344
exploration/Returns Mean          -49.2836
exploration/Returns Std            20.0488
exploration/Returns Max           -32.4657
exploration/Returns Min           -84.1095
exploration/Actions Mean            0.00671271
exploration/Actions Std             0.217394
exploration/Actions Max             0.995896
exploration/Actions Min            -0.999264
exploration/Num Paths               5
exploration/Average Returns       -49.2836
evaluation/num steps total     331500
evaluation/num paths total       3315
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.38269
evaluation/Rewards Std              0.934669
evaluation/Rewards Max             -0.0018869
evaluation/Rewards Min             -9.65573
evaluation/Returns Mean           -38.269
evaluation/Returns Std             25.6702
evaluation/Returns Max             -5.28021
evaluation/Returns Min            -88.106
evaluation/Actions Mean             0.00898825
evaluation/Actions Std              0.181489
evaluation/Actions Max              0.998492
evaluation/Actions Min             -0.998342
evaluation/Num Paths               15
evaluation/Average Returns        -38.269
time/data storing (s)               0.00293771
time/evaluation sampling (s)        0.367931
time/exploration sampling (s)       0.160506
time/logging (s)                    0.00419215
time/saving (s)                     0.00168292
time/training (s)                   2.2311
time/epoch (s)                      2.76835
time/total (s)                    600.756
Epoch                             220
-----------------------------  ---------------
2019-04-22 22:20:01.759284 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 221 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.112117
trainer/QF2 Loss                    0.104367
trainer/Policy Loss                21.1889
trainer/Q1 Predictions Mean       -19.7269
trainer/Q1 Predictions Std         12.0487
trainer/Q1 Predictions Max         -8.32906
trainer/Q1 Predictions Min        -49.3382
trainer/Q2 Predictions Mean       -19.735
trainer/Q2 Predictions Std         12.0784
trainer/Q2 Predictions Max         -8.38296
trainer/Q2 Predictions Min        -49.7831
trainer/Q Targets Mean            -19.9842
trainer/Q Targets Std              12.163
trainer/Q Targets Max              -8.41702
trainer/Q Targets Min             -49.6565
trainer/Log Pis Mean                1.93704
trainer/Log Pis Std                 1.39935
trainer/Log Pis Max                 6.18351
trainer/Log Pis Min                -3.13115
trainer/Policy mu Mean              0.0283942
trainer/Policy mu Std               0.794728
trainer/Policy mu Max               2.99497
trainer/Policy mu Min              -2.29588
trainer/Policy log std Mean        -1.91232
trainer/Policy log std Std          0.51885
trainer/Policy log std Max         -0.427831
trainer/Policy log std Min         -2.66102
trainer/Alpha                       0.0640279
trainer/Alpha Loss                 -0.173036
exploration/num steps total    111200
exploration/num paths total      1112
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.338165
exploration/Rewards Std             0.70372
exploration/Rewards Max            -0.00770239
exploration/Rewards Min            -7.41143
exploration/Returns Mean          -33.8165
exploration/Returns Std            12.1743
exploration/Returns Max           -19.8649
exploration/Returns Min           -48.5556
exploration/Actions Mean           -0.00246464
exploration/Actions Std             0.221775
exploration/Actions Max             0.996489
exploration/Actions Min            -0.997405
exploration/Num Paths               5
exploration/Average Returns       -33.8165
evaluation/num steps total     333000
evaluation/num paths total       3330
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.476253
evaluation/Rewards Std              0.91341
evaluation/Rewards Max             -0.0172156
evaluation/Rewards Min             -9.59549
evaluation/Returns Mean           -47.6253
evaluation/Returns Std             15.0489
evaluation/Returns Max            -23.763
evaluation/Returns Min            -87.6522
evaluation/Actions Mean             0.00305467
evaluation/Actions Std              0.194506
evaluation/Actions Max              0.996889
evaluation/Actions Min             -0.996975
evaluation/Num Paths               15
evaluation/Average Returns        -47.6253
time/data storing (s)               0.00301747
time/evaluation sampling (s)        0.350062
time/exploration sampling (s)       0.153249
time/logging (s)                    0.00488013
time/saving (s)                     0.00195233
time/training (s)                   2.00745
time/epoch (s)                      2.52061
time/total (s)                    603.281
Epoch                             221
-----------------------------  ---------------
2019-04-22 22:20:04.429635 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 222 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.47677
trainer/QF2 Loss                    1.48778
trainer/Policy Loss                20.928
trainer/Q1 Predictions Mean       -19.5658
trainer/Q1 Predictions Std         12.4504
trainer/Q1 Predictions Max         -8.48919
trainer/Q1 Predictions Min        -49.6523
trainer/Q2 Predictions Mean       -19.5388
trainer/Q2 Predictions Std         12.4574
trainer/Q2 Predictions Max         -8.48345
trainer/Q2 Predictions Min        -49.5153
trainer/Q Targets Mean            -19.5014
trainer/Q Targets Std              12.7043
trainer/Q Targets Max              -0.0225143
trainer/Q Targets Min             -49.5343
trainer/Log Pis Mean                1.88929
trainer/Log Pis Std                 1.15923
trainer/Log Pis Max                 6.0445
trainer/Log Pis Min                -0.743003
trainer/Policy mu Mean              0.0199707
trainer/Policy mu Std               0.771881
trainer/Policy mu Max               2.78177
trainer/Policy mu Min              -2.30179
trainer/Policy log std Mean        -1.93012
trainer/Policy log std Std          0.507598
trainer/Policy log std Max         -0.606667
trainer/Policy log std Min         -2.74505
trainer/Alpha                       0.0625854
trainer/Alpha Loss                 -0.306802
exploration/num steps total    111700
exploration/num paths total      1117
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.322951
exploration/Rewards Std             0.846433
exploration/Rewards Max            -0.00477293
exploration/Rewards Min            -8.32458
exploration/Returns Mean          -32.2951
exploration/Returns Std            10.1234
exploration/Returns Max           -19.8121
exploration/Returns Min           -48.9233
exploration/Actions Mean           -0.0100738
exploration/Actions Std             0.231059
exploration/Actions Max             0.998081
exploration/Actions Min            -0.997788
exploration/Num Paths               5
exploration/Average Returns       -32.2951
evaluation/num steps total     334500
evaluation/num paths total       3345
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.415407
evaluation/Rewards Std              0.990413
evaluation/Rewards Max             -0.0236403
evaluation/Rewards Min            -11.2621
evaluation/Returns Mean           -41.5407
evaluation/Returns Std             21.3465
evaluation/Returns Max             -4.27824
evaluation/Returns Min            -72.6174
evaluation/Actions Mean             0.0148003
evaluation/Actions Std              0.186179
evaluation/Actions Max              0.998702
evaluation/Actions Min             -0.998493
evaluation/Num Paths               15
evaluation/Average Returns        -41.5407
time/data storing (s)               0.00405993
time/evaluation sampling (s)        0.353361
time/exploration sampling (s)       0.163675
time/logging (s)                    0.00476177
time/saving (s)                     0.00196218
time/training (s)                   2.13454
time/epoch (s)                      2.66236
time/total (s)                    605.948
Epoch                             222
-----------------------------  ---------------
2019-04-22 22:20:07.276644 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 223 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.73588
trainer/QF2 Loss                    0.726366
trainer/Policy Loss                22.0613
trainer/Q1 Predictions Mean       -20.4822
trainer/Q1 Predictions Std         12.3706
trainer/Q1 Predictions Max         -8.40911
trainer/Q1 Predictions Min        -47.1047
trainer/Q2 Predictions Mean       -20.5288
trainer/Q2 Predictions Std         12.3428
trainer/Q2 Predictions Max         -8.42653
trainer/Q2 Predictions Min        -47.3161
trainer/Q Targets Mean            -20.4749
trainer/Q Targets Std              12.3987
trainer/Q Targets Max              -0.263101
trainer/Q Targets Min             -47.0949
trainer/Log Pis Mean                2.05742
trainer/Log Pis Std                 1.16317
trainer/Log Pis Max                 6.32686
trainer/Log Pis Min                -1.04535
trainer/Policy mu Mean              0.0153138
trainer/Policy mu Std               0.86625
trainer/Policy mu Max               3.13714
trainer/Policy mu Min              -2.39583
trainer/Policy log std Mean        -1.86358
trainer/Policy log std Std          0.560891
trainer/Policy log std Max         -0.161131
trainer/Policy log std Min         -2.75564
trainer/Alpha                       0.0664376
trainer/Alpha Loss                  0.155714
exploration/num steps total    112200
exploration/num paths total      1122
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.571256
exploration/Rewards Std             1.14369
exploration/Rewards Max            -0.0251846
exploration/Rewards Min            -9.72813
exploration/Returns Mean          -57.1256
exploration/Returns Std            21.995
exploration/Returns Max           -34.4835
exploration/Returns Min           -97.7943
exploration/Actions Mean           -0.0112763
exploration/Actions Std             0.244816
exploration/Actions Max             0.997582
exploration/Actions Min            -0.999916
exploration/Num Paths               5
exploration/Average Returns       -57.1256
evaluation/num steps total     336000
evaluation/num paths total       3360
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.461658
evaluation/Rewards Std              1.0478
evaluation/Rewards Max             -0.0271014
evaluation/Rewards Min            -10.3892
evaluation/Returns Mean           -46.1658
evaluation/Returns Std             22.6209
evaluation/Returns Max            -13.2301
evaluation/Returns Min            -96.8088
evaluation/Actions Mean             0.0114946
evaluation/Actions Std              0.194399
evaluation/Actions Max              0.998481
evaluation/Actions Min             -0.999519
evaluation/Num Paths               15
evaluation/Average Returns        -46.1658
time/data storing (s)               0.00294745
time/evaluation sampling (s)        0.342584
time/exploration sampling (s)       0.163846
time/logging (s)                    0.00481535
time/saving (s)                     0.00202306
time/training (s)                   2.32338
time/epoch (s)                      2.8396
time/total (s)                    608.792
Epoch                             223
-----------------------------  ---------------
2019-04-22 22:20:10.384780 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 224 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   15.3621
trainer/QF2 Loss                   15.3619
trainer/Policy Loss                21.5593
trainer/Q1 Predictions Mean       -20.1669
trainer/Q1 Predictions Std         11.5692
trainer/Q1 Predictions Max         -8.65297
trainer/Q1 Predictions Min        -45.0172
trainer/Q2 Predictions Mean       -20.1741
trainer/Q2 Predictions Std         11.5573
trainer/Q2 Predictions Max         -8.68061
trainer/Q2 Predictions Min        -44.9563
trainer/Q Targets Mean            -19.8482
trainer/Q Targets Std              11.6692
trainer/Q Targets Max              -0.320082
trainer/Q Targets Min             -45.2223
trainer/Log Pis Mean                1.90009
trainer/Log Pis Std                 1.38052
trainer/Log Pis Max                 5.21187
trainer/Log Pis Min                -2.95306
trainer/Policy mu Mean              0.0485591
trainer/Policy mu Std               0.759988
trainer/Policy mu Max               2.58412
trainer/Policy mu Min              -2.92415
trainer/Policy log std Mean        -1.97066
trainer/Policy log std Std          0.555582
trainer/Policy log std Max         -0.541131
trainer/Policy log std Min         -2.91658
trainer/Alpha                       0.0633103
trainer/Alpha Loss                 -0.27572
exploration/num steps total    112700
exploration/num paths total      1127
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.266417
exploration/Rewards Std             0.701457
exploration/Rewards Max            -0.00162012
exploration/Rewards Min            -7.10632
exploration/Returns Mean          -26.6417
exploration/Returns Std            10.2627
exploration/Returns Max           -15.836
exploration/Returns Min           -42.6323
exploration/Actions Mean            0.0118513
exploration/Actions Std             0.215957
exploration/Actions Max             0.998924
exploration/Actions Min            -0.994637
exploration/Num Paths               5
exploration/Average Returns       -26.6417
evaluation/num steps total     337500
evaluation/num paths total       3375
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.523414
evaluation/Rewards Std              1.05481
evaluation/Rewards Max             -0.00228949
evaluation/Rewards Min             -9.62008
evaluation/Returns Mean           -52.3414
evaluation/Returns Std             24.9978
evaluation/Returns Max            -11.3154
evaluation/Returns Min           -105.82
evaluation/Actions Mean             0.00529124
evaluation/Actions Std              0.200824
evaluation/Actions Max              0.999447
evaluation/Actions Min             -0.997011
evaluation/Num Paths               15
evaluation/Average Returns        -52.3414
time/data storing (s)               0.00348771
time/evaluation sampling (s)        0.421053
time/exploration sampling (s)       0.167327
time/logging (s)                    0.00518899
time/saving (s)                     0.00624639
time/training (s)                   2.49706
time/epoch (s)                      3.10037
time/total (s)                    611.896
Epoch                             224
-----------------------------  ---------------
2019-04-22 22:20:13.168832 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 225 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0431687
trainer/QF2 Loss                    0.0705057
trainer/Policy Loss                21.1019
trainer/Q1 Predictions Mean       -19.7546
trainer/Q1 Predictions Std         11.0021
trainer/Q1 Predictions Max         -8.45406
trainer/Q1 Predictions Min        -45.5257
trainer/Q2 Predictions Mean       -19.7377
trainer/Q2 Predictions Std         10.9848
trainer/Q2 Predictions Max         -8.45954
trainer/Q2 Predictions Min        -45.4806
trainer/Q Targets Mean            -19.8577
trainer/Q Targets Std              10.9544
trainer/Q Targets Max              -8.53884
trainer/Q Targets Min             -45.4828
trainer/Log Pis Mean                1.94137
trainer/Log Pis Std                 1.43026
trainer/Log Pis Max                 5.70588
trainer/Log Pis Min                -2.58738
trainer/Policy mu Mean             -0.0215522
trainer/Policy mu Std               0.919531
trainer/Policy mu Max               2.49132
trainer/Policy mu Min              -3.11841
trainer/Policy log std Mean        -1.87827
trainer/Policy log std Std          0.612783
trainer/Policy log std Max         -0.506851
trainer/Policy log std Min         -2.76808
trainer/Alpha                       0.0638609
trainer/Alpha Loss                 -0.1613
exploration/num steps total    113200
exploration/num paths total      1132
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.313557
exploration/Rewards Std             0.850465
exploration/Rewards Max            -0.00700014
exploration/Rewards Min            -8.16871
exploration/Returns Mean          -31.3557
exploration/Returns Std            10.4148
exploration/Returns Max           -21.3513
exploration/Returns Min           -48.9812
exploration/Actions Mean            0.00539539
exploration/Actions Std             0.228582
exploration/Actions Max             0.994487
exploration/Actions Min            -0.999572
exploration/Num Paths               5
exploration/Average Returns       -31.3557
evaluation/num steps total     339000
evaluation/num paths total       3390
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.339497
evaluation/Rewards Std              0.873284
evaluation/Rewards Max             -0.0179133
evaluation/Rewards Min             -9.73394
evaluation/Returns Mean           -33.9497
evaluation/Returns Std             14.9341
evaluation/Returns Max             -9.47529
evaluation/Returns Min            -62.443
evaluation/Actions Mean             0.00474507
evaluation/Actions Std              0.182186
evaluation/Actions Max              0.998586
evaluation/Actions Min             -0.997208
evaluation/Num Paths               15
evaluation/Average Returns        -33.9497
time/data storing (s)               0.00312893
time/evaluation sampling (s)        0.367155
time/exploration sampling (s)       0.152637
time/logging (s)                    0.00517772
time/saving (s)                     0.00193264
time/training (s)                   2.24568
time/epoch (s)                      2.77571
time/total (s)                    614.677
Epoch                             225
-----------------------------  ---------------
2019-04-22 22:20:16.368386 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 226 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0879637
trainer/QF2 Loss                    0.127035
trainer/Policy Loss                22.6281
trainer/Q1 Predictions Mean       -21.1333
trainer/Q1 Predictions Std         12.0701
trainer/Q1 Predictions Max         -8.55207
trainer/Q1 Predictions Min        -44.105
trainer/Q2 Predictions Mean       -21.0977
trainer/Q2 Predictions Std         12.0536
trainer/Q2 Predictions Max         -8.47797
trainer/Q2 Predictions Min        -44.2626
trainer/Q Targets Mean            -21.1866
trainer/Q Targets Std              12.1885
trainer/Q Targets Max              -8.59735
trainer/Q Targets Min             -45.1686
trainer/Log Pis Mean                1.94415
trainer/Log Pis Std                 1.2516
trainer/Log Pis Max                 5.09338
trainer/Log Pis Min                -2.39463
trainer/Policy mu Mean              0.0111332
trainer/Policy mu Std               0.811329
trainer/Policy mu Max               2.45683
trainer/Policy mu Min              -3.16894
trainer/Policy log std Mean        -1.90957
trainer/Policy log std Std          0.521442
trainer/Policy log std Max         -0.552954
trainer/Policy log std Min         -2.75103
trainer/Alpha                       0.0621543
trainer/Alpha Loss                 -0.155147
exploration/num steps total    113700
exploration/num paths total      1137
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.423325
exploration/Rewards Std             1.08457
exploration/Rewards Max            -0.00580883
exploration/Rewards Min            -8.81365
exploration/Returns Mean          -42.3325
exploration/Returns Std            13.4041
exploration/Returns Max           -17.8593
exploration/Returns Min           -54.3547
exploration/Actions Mean            0.0141787
exploration/Actions Std             0.244964
exploration/Actions Max             0.999742
exploration/Actions Min            -0.999341
exploration/Num Paths               5
exploration/Average Returns       -42.3325
evaluation/num steps total     340500
evaluation/num paths total       3405
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.347099
evaluation/Rewards Std              0.746689
evaluation/Rewards Max             -0.0513022
evaluation/Rewards Min            -11.45
evaluation/Returns Mean           -34.7099
evaluation/Returns Std             19.323
evaluation/Returns Max             -6.20753
evaluation/Returns Min            -63.2473
evaluation/Actions Mean            -0.00220748
evaluation/Actions Std              0.170227
evaluation/Actions Max              0.999082
evaluation/Actions Min             -0.997625
evaluation/Num Paths               15
evaluation/Average Returns        -34.7099
time/data storing (s)               0.00343043
time/evaluation sampling (s)        0.35513
time/exploration sampling (s)       0.157286
time/logging (s)                    0.00453316
time/saving (s)                     0.00213852
time/training (s)                   2.66858
time/epoch (s)                      3.1911
time/total (s)                    617.872
Epoch                             226
-----------------------------  ---------------
2019-04-22 22:20:19.215336 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 227 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    4.70888
trainer/QF2 Loss                    4.63924
trainer/Policy Loss                22.6245
trainer/Q1 Predictions Mean       -21.0966
trainer/Q1 Predictions Std         12.7287
trainer/Q1 Predictions Max         -8.60974
trainer/Q1 Predictions Min        -61.2985
trainer/Q2 Predictions Mean       -21.0745
trainer/Q2 Predictions Std         12.6868
trainer/Q2 Predictions Max         -8.6358
trainer/Q2 Predictions Min        -59.6944
trainer/Q Targets Mean            -20.8836
trainer/Q Targets Std              12.6659
trainer/Q Targets Max              -1.1575
trainer/Q Targets Min             -57.7296
trainer/Log Pis Mean                2.27747
trainer/Log Pis Std                 1.37959
trainer/Log Pis Max                 7.39055
trainer/Log Pis Min                -1.78278
trainer/Policy mu Mean              0.112992
trainer/Policy mu Std               0.953303
trainer/Policy mu Max               3.01896
trainer/Policy mu Min              -2.37049
trainer/Policy log std Mean        -1.91332
trainer/Policy log std Std          0.585335
trainer/Policy log std Max         -0.525028
trainer/Policy log std Min         -2.75946
trainer/Alpha                       0.0621846
trainer/Alpha Loss                  0.770752
exploration/num steps total    114200
exploration/num paths total      1142
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.288613
exploration/Rewards Std             0.747748
exploration/Rewards Max            -0.00515552
exploration/Rewards Min            -7.59592
exploration/Returns Mean          -28.8613
exploration/Returns Std            10.1063
exploration/Returns Max           -16.0355
exploration/Returns Min           -46.1171
exploration/Actions Mean            0.0218949
exploration/Actions Std             0.20172
exploration/Actions Max             0.99889
exploration/Actions Min            -0.980035
exploration/Num Paths               5
exploration/Average Returns       -28.8613
evaluation/num steps total     342000
evaluation/num paths total       3420
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.398256
evaluation/Rewards Std              1.08573
evaluation/Rewards Max             -0.0142583
evaluation/Rewards Min             -9.50229
evaluation/Returns Mean           -39.8256
evaluation/Returns Std             26.8603
evaluation/Returns Max             -8.93011
evaluation/Returns Min            -91.5904
evaluation/Actions Mean            -0.00277383
evaluation/Actions Std              0.196327
evaluation/Actions Max              0.998492
evaluation/Actions Min             -0.99835
evaluation/Num Paths               15
evaluation/Average Returns        -39.8256
time/data storing (s)               0.00394562
time/evaluation sampling (s)        0.418194
time/exploration sampling (s)       0.194196
time/logging (s)                    0.00418549
time/saving (s)                     0.00199612
time/training (s)                   2.21632
time/epoch (s)                      2.83883
time/total (s)                    620.716
Epoch                             227
-----------------------------  ---------------
2019-04-22 22:20:22.023985 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 228 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   15.7992
trainer/QF2 Loss                   15.6322
trainer/Policy Loss                19.7912
trainer/Q1 Predictions Mean       -18.371
trainer/Q1 Predictions Std         11.0268
trainer/Q1 Predictions Max         -8.50731
trainer/Q1 Predictions Min        -43.4793
trainer/Q2 Predictions Mean       -18.3967
trainer/Q2 Predictions Std         11.0303
trainer/Q2 Predictions Max         -8.55459
trainer/Q2 Predictions Min        -43.689
trainer/Q Targets Mean            -18.1837
trainer/Q Targets Std              11.2085
trainer/Q Targets Max              -0.1732
trainer/Q Targets Min             -44.3699
trainer/Log Pis Mean                1.88927
trainer/Log Pis Std                 1.25034
trainer/Log Pis Max                 6.9074
trainer/Log Pis Min                -2.19859
trainer/Policy mu Mean              0.0993285
trainer/Policy mu Std               0.799408
trainer/Policy mu Max               2.69316
trainer/Policy mu Min              -2.19362
trainer/Policy log std Mean        -1.90798
trainer/Policy log std Std          0.544139
trainer/Policy log std Max         -0.561806
trainer/Policy log std Min         -2.7103
trainer/Alpha                       0.0632743
trainer/Alpha Loss                 -0.305614
exploration/num steps total    114700
exploration/num paths total      1147
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.413763
exploration/Rewards Std             0.663723
exploration/Rewards Max            -0.0167448
exploration/Rewards Min            -6.88373
exploration/Returns Mean          -41.3763
exploration/Returns Std            14.6302
exploration/Returns Max           -16.1924
exploration/Returns Min           -60.1272
exploration/Actions Mean           -0.00796835
exploration/Actions Std             0.209381
exploration/Actions Max             0.994359
exploration/Actions Min            -0.997355
exploration/Num Paths               5
exploration/Average Returns       -41.3763
evaluation/num steps total     343500
evaluation/num paths total       3435
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.417264
evaluation/Rewards Std              1.09362
evaluation/Rewards Max             -0.0425641
evaluation/Rewards Min            -10.9193
evaluation/Returns Mean           -41.7264
evaluation/Returns Std             17.7313
evaluation/Returns Max             -5.40396
evaluation/Returns Min            -85.1418
evaluation/Actions Mean            -0.0167588
evaluation/Actions Std              0.199091
evaluation/Actions Max              0.998783
evaluation/Actions Min             -0.99684
evaluation/Num Paths               15
evaluation/Average Returns        -41.7264
time/data storing (s)               0.00308531
time/evaluation sampling (s)        0.345324
time/exploration sampling (s)       0.174035
time/logging (s)                    0.00482296
time/saving (s)                     0.00204777
time/training (s)                   2.27165
time/epoch (s)                      2.80096
time/total (s)                    623.522
Epoch                             228
-----------------------------  ---------------
2019-04-22 22:20:24.904741 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 229 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   13.0402
trainer/QF2 Loss                   12.9268
trainer/Policy Loss                20.1189
trainer/Q1 Predictions Mean       -18.594
trainer/Q1 Predictions Std         10.8083
trainer/Q1 Predictions Max         -8.81266
trainer/Q1 Predictions Min        -47.0478
trainer/Q2 Predictions Mean       -18.5788
trainer/Q2 Predictions Std         10.8271
trainer/Q2 Predictions Max         -8.77226
trainer/Q2 Predictions Min        -48.2139
trainer/Q Targets Mean            -18.2162
trainer/Q Targets Std              10.7679
trainer/Q Targets Max              -2.12937
trainer/Q Targets Min             -48.0093
trainer/Log Pis Mean                1.94727
trainer/Log Pis Std                 1.37781
trainer/Log Pis Max                 5.86723
trainer/Log Pis Min                -1.99705
trainer/Policy mu Mean              0.0274529
trainer/Policy mu Std               0.800449
trainer/Policy mu Max               3.21117
trainer/Policy mu Min              -3.07321
trainer/Policy log std Mean        -2.03769
trainer/Policy log std Std          0.539738
trainer/Policy log std Max         -0.449453
trainer/Policy log std Min         -2.87055
trainer/Alpha                       0.0638378
trainer/Alpha Loss                 -0.145094
exploration/num steps total    115200
exploration/num paths total      1152
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.325786
exploration/Rewards Std             0.825541
exploration/Rewards Max            -0.00723378
exploration/Rewards Min            -7.38979
exploration/Returns Mean          -32.5786
exploration/Returns Std             9.31612
exploration/Returns Max           -20.9946
exploration/Returns Min           -45.2742
exploration/Actions Mean           -0.021953
exploration/Actions Std             0.224926
exploration/Actions Max             0.998596
exploration/Actions Min            -0.997556
exploration/Num Paths               5
exploration/Average Returns       -32.5786
evaluation/num steps total     345000
evaluation/num paths total       3450
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.350738
evaluation/Rewards Std              0.965726
evaluation/Rewards Max             -0.0200137
evaluation/Rewards Min            -10.3889
evaluation/Returns Mean           -35.0738
evaluation/Returns Std             18.042
evaluation/Returns Max            -12.0353
evaluation/Returns Min            -74.2143
evaluation/Actions Mean            -0.00592097
evaluation/Actions Std              0.193413
evaluation/Actions Max              0.997508
evaluation/Actions Min             -0.998801
evaluation/Num Paths               15
evaluation/Average Returns        -35.0738
time/data storing (s)               0.00294317
time/evaluation sampling (s)        0.363569
time/exploration sampling (s)       0.160337
time/logging (s)                    0.00487837
time/saving (s)                     0.00215736
time/training (s)                   2.33745
time/epoch (s)                      2.87134
time/total (s)                    626.399
Epoch                             229
-----------------------------  ---------------
2019-04-22 22:20:27.684235 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 230 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   11.0399
trainer/QF2 Loss                   10.9884
trainer/Policy Loss                21.2901
trainer/Q1 Predictions Mean       -20.0713
trainer/Q1 Predictions Std         11.6287
trainer/Q1 Predictions Max         -8.71925
trainer/Q1 Predictions Min        -56.7052
trainer/Q2 Predictions Mean       -20.0505
trainer/Q2 Predictions Std         11.6548
trainer/Q2 Predictions Max         -8.67222
trainer/Q2 Predictions Min        -57.2974
trainer/Q Targets Mean            -19.9239
trainer/Q Targets Std              11.7594
trainer/Q Targets Max              -0.63471
trainer/Q Targets Min             -55.23
trainer/Log Pis Mean                1.68377
trainer/Log Pis Std                 1.06493
trainer/Log Pis Max                 4.65414
trainer/Log Pis Min                -1.81619
trainer/Policy mu Mean             -0.00757841
trainer/Policy mu Std               0.784651
trainer/Policy mu Max               2.84781
trainer/Policy mu Min              -2.65213
trainer/Policy log std Mean        -1.92759
trainer/Policy log std Std          0.529726
trainer/Policy log std Max         -0.577707
trainer/Policy log std Min         -2.79709
trainer/Alpha                       0.0652249
trainer/Alpha Loss                 -0.863225
exploration/num steps total    115700
exploration/num paths total      1157
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.411056
exploration/Rewards Std             0.908067
exploration/Rewards Max            -0.0123209
exploration/Rewards Min            -9.13924
exploration/Returns Mean          -41.1056
exploration/Returns Std            24.1409
exploration/Returns Max           -14.1442
exploration/Returns Min           -72.1983
exploration/Actions Mean           -0.0159407
exploration/Actions Std             0.208883
exploration/Actions Max             0.973595
exploration/Actions Min            -0.998792
exploration/Num Paths               5
exploration/Average Returns       -41.1056
evaluation/num steps total     346500
evaluation/num paths total       3465
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.462587
evaluation/Rewards Std              0.957967
evaluation/Rewards Max             -0.00579109
evaluation/Rewards Min            -10.4484
evaluation/Returns Mean           -46.2587
evaluation/Returns Std             31.7358
evaluation/Returns Max             -4.5131
evaluation/Returns Min           -104.577
evaluation/Actions Mean             0.00238493
evaluation/Actions Std              0.184633
evaluation/Actions Max              0.998275
evaluation/Actions Min             -0.99877
evaluation/Num Paths               15
evaluation/Average Returns        -46.2587
time/data storing (s)               0.00410295
time/evaluation sampling (s)        0.397502
time/exploration sampling (s)       0.155616
time/logging (s)                    0.00485518
time/saving (s)                     0.00233534
time/training (s)                   2.20645
time/epoch (s)                      2.77086
time/total (s)                    629.174
Epoch                             230
-----------------------------  ---------------
2019-04-22 22:20:30.349107 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 231 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    2.33306
trainer/QF2 Loss                    2.23028
trainer/Policy Loss                20.2351
trainer/Q1 Predictions Mean       -18.8243
trainer/Q1 Predictions Std         10.7502
trainer/Q1 Predictions Max         -8.61146
trainer/Q1 Predictions Min        -41.2525
trainer/Q2 Predictions Mean       -18.7955
trainer/Q2 Predictions Std         10.6753
trainer/Q2 Predictions Max         -8.62873
trainer/Q2 Predictions Min        -41.2468
trainer/Q Targets Mean            -18.6294
trainer/Q Targets Std              11.0021
trainer/Q Targets Max              -0.222683
trainer/Q Targets Min             -41.9713
trainer/Log Pis Mean                1.9267
trainer/Log Pis Std                 1.5186
trainer/Log Pis Max                 6.10817
trainer/Log Pis Min                -3.28155
trainer/Policy mu Mean              0.0729693
trainer/Policy mu Std               0.922139
trainer/Policy mu Max               2.85653
trainer/Policy mu Min              -2.69665
trainer/Policy log std Mean        -1.89403
trainer/Policy log std Std          0.596502
trainer/Policy log std Max         -0.453922
trainer/Policy log std Min         -2.82272
trainer/Alpha                       0.0657012
trainer/Alpha Loss                 -0.199563
exploration/num steps total    116200
exploration/num paths total      1162
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.524766
exploration/Rewards Std             1.01428
exploration/Rewards Max            -0.0117133
exploration/Rewards Min            -9.13272
exploration/Returns Mean          -52.4766
exploration/Returns Std            26.7675
exploration/Returns Max           -21.6478
exploration/Returns Min           -94.9452
exploration/Actions Mean            0.0245283
exploration/Actions Std             0.212474
exploration/Actions Max             0.999304
exploration/Actions Min            -0.990728
exploration/Num Paths               5
exploration/Average Returns       -52.4766
evaluation/num steps total     348000
evaluation/num paths total       3480
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.447987
evaluation/Rewards Std              0.906701
evaluation/Rewards Max             -0.0639391
evaluation/Rewards Min            -10.825
evaluation/Returns Mean           -44.7987
evaluation/Returns Std             24.1743
evaluation/Returns Max            -15.8158
evaluation/Returns Min           -102.81
evaluation/Actions Mean             0.00723254
evaluation/Actions Std              0.185947
evaluation/Actions Max              0.999007
evaluation/Actions Min             -0.997097
evaluation/Num Paths               15
evaluation/Average Returns        -44.7987
time/data storing (s)               0.00298219
time/evaluation sampling (s)        0.359207
time/exploration sampling (s)       0.152305
time/logging (s)                    0.00534864
time/saving (s)                     0.00196568
time/training (s)                   2.13575
time/epoch (s)                      2.65755
time/total (s)                    631.837
Epoch                             231
-----------------------------  ---------------
2019-04-22 22:20:32.991055 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 232 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    4.46727
trainer/QF2 Loss                    4.51033
trainer/Policy Loss                18.9521
trainer/Q1 Predictions Mean       -17.5681
trainer/Q1 Predictions Std         10.139
trainer/Q1 Predictions Max         -8.61334
trainer/Q1 Predictions Min        -37.4431
trainer/Q2 Predictions Mean       -17.5679
trainer/Q2 Predictions Std         10.1144
trainer/Q2 Predictions Max         -8.6715
trainer/Q2 Predictions Min        -37.2372
trainer/Q Targets Mean            -17.5796
trainer/Q Targets Std              10.307
trainer/Q Targets Max              -2.16952
trainer/Q Targets Min             -38.1115
trainer/Log Pis Mean                1.72257
trainer/Log Pis Std                 1.07949
trainer/Log Pis Max                 4.45345
trainer/Log Pis Min                -2.09566
trainer/Policy mu Mean             -0.00423169
trainer/Policy mu Std               0.640423
trainer/Policy mu Max               2.31726
trainer/Policy mu Min              -2.3078
trainer/Policy log std Mean        -1.99447
trainer/Policy log std Std          0.446773
trainer/Policy log std Max         -0.666292
trainer/Policy log std Min         -2.68963
trainer/Alpha                       0.0674435
trainer/Alpha Loss                 -0.748072
exploration/num steps total    116700
exploration/num paths total      1167
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.340512
exploration/Rewards Std             0.66815
exploration/Rewards Max            -0.010124
exploration/Rewards Min            -6.05608
exploration/Returns Mean          -34.0512
exploration/Returns Std            11.6259
exploration/Returns Max           -18.5319
exploration/Returns Min           -54.3125
exploration/Actions Mean            0.0114197
exploration/Actions Std             0.213065
exploration/Actions Max             0.994279
exploration/Actions Min            -0.997917
exploration/Num Paths               5
exploration/Average Returns       -34.0512
evaluation/num steps total     349500
evaluation/num paths total       3495
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.329006
evaluation/Rewards Std              0.952084
evaluation/Rewards Max             -0.0459723
evaluation/Rewards Min            -11.5351
evaluation/Returns Mean           -32.9006
evaluation/Returns Std             13.3261
evaluation/Returns Max             -6.39219
evaluation/Returns Min            -59.7882
evaluation/Actions Mean            -0.00851706
evaluation/Actions Std              0.194708
evaluation/Actions Max              0.998763
evaluation/Actions Min             -0.998395
evaluation/Num Paths               15
evaluation/Average Returns        -32.9006
time/data storing (s)               0.0028558
time/evaluation sampling (s)        0.362107
time/exploration sampling (s)       0.15085
time/logging (s)                    0.00486932
time/saving (s)                     0.00167843
time/training (s)                   2.11077
time/epoch (s)                      2.63313
time/total (s)                    634.475
Epoch                             232
-----------------------------  ---------------
2019-04-22 22:20:35.883528 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 233 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.126665
trainer/QF2 Loss                    0.128194
trainer/Policy Loss                19.6119
trainer/Q1 Predictions Mean       -18.0624
trainer/Q1 Predictions Std         10.6183
trainer/Q1 Predictions Max         -8.77292
trainer/Q1 Predictions Min        -60.1097
trainer/Q2 Predictions Mean       -18.0672
trainer/Q2 Predictions Std         10.644
trainer/Q2 Predictions Max         -8.742
trainer/Q2 Predictions Min        -60.2102
trainer/Q Targets Mean            -18.3029
trainer/Q Targets Std              10.816
trainer/Q Targets Max              -8.63176
trainer/Q Targets Min             -60.6721
trainer/Log Pis Mean                2.04766
trainer/Log Pis Std                 1.36009
trainer/Log Pis Max                 5.36663
trainer/Log Pis Min                -2.94117
trainer/Policy mu Mean             -0.00623064
trainer/Policy mu Std               0.830876
trainer/Policy mu Max               2.74344
trainer/Policy mu Min              -2.35804
trainer/Policy log std Mean        -1.85973
trainer/Policy log std Std          0.550395
trainer/Policy log std Max         -0.506155
trainer/Policy log std Min         -2.63251
trainer/Alpha                       0.0683581
trainer/Alpha Loss                  0.127867
exploration/num steps total    117200
exploration/num paths total      1172
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.397717
exploration/Rewards Std             0.985943
exploration/Rewards Max            -0.0141632
exploration/Rewards Min            -8.62476
exploration/Returns Mean          -39.7717
exploration/Returns Std            14.9362
exploration/Returns Max           -21.6417
exploration/Returns Min           -63.259
exploration/Actions Mean           -0.0113696
exploration/Actions Std             0.243645
exploration/Actions Max             0.996799
exploration/Actions Min            -0.999142
exploration/Num Paths               5
exploration/Average Returns       -39.7717
evaluation/num steps total     351000
evaluation/num paths total       3510
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.408462
evaluation/Rewards Std              0.935487
evaluation/Rewards Max             -0.0355315
evaluation/Rewards Min            -10.8198
evaluation/Returns Mean           -40.8462
evaluation/Returns Std             20.7087
evaluation/Returns Max            -12.4901
evaluation/Returns Min            -82.6006
evaluation/Actions Mean             0.00504008
evaluation/Actions Std              0.190822
evaluation/Actions Max              0.996803
evaluation/Actions Min             -0.998368
evaluation/Num Paths               15
evaluation/Average Returns        -40.8462
time/data storing (s)               0.00307736
time/evaluation sampling (s)        0.339226
time/exploration sampling (s)       0.147246
time/logging (s)                    0.0046176
time/saving (s)                     0.00200506
time/training (s)                   2.38749
time/epoch (s)                      2.88367
time/total (s)                    637.363
Epoch                             233
-----------------------------  ---------------
2019-04-22 22:20:38.494038 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 234 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   13.1647
trainer/QF2 Loss                   13.4444
trainer/Policy Loss                19.8843
trainer/Q1 Predictions Mean       -18.4249
trainer/Q1 Predictions Std         10.153
trainer/Q1 Predictions Max         -8.57107
trainer/Q1 Predictions Min        -40.0758
trainer/Q2 Predictions Mean       -18.4142
trainer/Q2 Predictions Std         10.1526
trainer/Q2 Predictions Max         -8.59824
trainer/Q2 Predictions Min        -40.1688
trainer/Q Targets Mean            -18.3602
trainer/Q Targets Std              10.323
trainer/Q Targets Max              -3.85888
trainer/Q Targets Min             -41.2746
trainer/Log Pis Mean                1.91293
trainer/Log Pis Std                 1.16578
trainer/Log Pis Max                 4.74708
trainer/Log Pis Min                -1.06562
trainer/Policy mu Mean              0.0131469
trainer/Policy mu Std               0.837341
trainer/Policy mu Max               2.69237
trainer/Policy mu Min              -2.77327
trainer/Policy log std Mean        -1.89865
trainer/Policy log std Std          0.549196
trainer/Policy log std Max         -0.529448
trainer/Policy log std Min         -2.67809
trainer/Alpha                       0.0662764
trainer/Alpha Loss                 -0.236291
exploration/num steps total    117700
exploration/num paths total      1177
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.45979
exploration/Rewards Std             0.767812
exploration/Rewards Max            -0.0131711
exploration/Rewards Min            -8.29705
exploration/Returns Mean          -45.979
exploration/Returns Std            11.4468
exploration/Returns Max           -34.3141
exploration/Returns Min           -65.7904
exploration/Actions Mean            0.0100325
exploration/Actions Std             0.219213
exploration/Actions Max             0.999571
exploration/Actions Min            -0.991424
exploration/Num Paths               5
exploration/Average Returns       -45.979
evaluation/num steps total     352500
evaluation/num paths total       3525
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.334889
evaluation/Rewards Std              0.984879
evaluation/Rewards Max             -0.0566432
evaluation/Rewards Min             -9.94663
evaluation/Returns Mean           -33.4889
evaluation/Returns Std             17.0147
evaluation/Returns Max            -13.2352
evaluation/Returns Min            -71.0864
evaluation/Actions Mean             0.00670907
evaluation/Actions Std              0.202973
evaluation/Actions Max              0.998219
evaluation/Actions Min             -0.996944
evaluation/Num Paths               15
evaluation/Average Returns        -33.4889
time/data storing (s)               0.00286936
time/evaluation sampling (s)        0.344465
time/exploration sampling (s)       0.14852
time/logging (s)                    0.00480854
time/saving (s)                     0.00208448
time/training (s)                   2.09977
time/epoch (s)                      2.60252
time/total (s)                    639.97
Epoch                             234
-----------------------------  ---------------
2019-04-22 22:20:41.135928 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 235 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   10.6878
trainer/QF2 Loss                   10.6884
trainer/Policy Loss                19.6837
trainer/Q1 Predictions Mean       -18.2528
trainer/Q1 Predictions Std         10.3036
trainer/Q1 Predictions Max         -8.50027
trainer/Q1 Predictions Min        -54.5385
trainer/Q2 Predictions Mean       -18.2483
trainer/Q2 Predictions Std         10.2688
trainer/Q2 Predictions Max         -8.51505
trainer/Q2 Predictions Min        -53.4352
trainer/Q Targets Mean            -18.1461
trainer/Q Targets Std              10.4234
trainer/Q Targets Max              -1.7818
trainer/Q Targets Min             -56.7897
trainer/Log Pis Mean                1.94375
trainer/Log Pis Std                 1.26328
trainer/Log Pis Max                 5.35608
trainer/Log Pis Min                -1.69692
trainer/Policy mu Mean              0.0315882
trainer/Policy mu Std               0.757518
trainer/Policy mu Max               2.24184
trainer/Policy mu Min              -3.60593
trainer/Policy log std Mean        -1.98533
trainer/Policy log std Std          0.523405
trainer/Policy log std Max         -0.527929
trainer/Policy log std Min         -2.66759
trainer/Alpha                       0.0674976
trainer/Alpha Loss                 -0.151634
exploration/num steps total    118200
exploration/num paths total      1182
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.33898
exploration/Rewards Std             0.664293
exploration/Rewards Max            -0.0123119
exploration/Rewards Min            -7.54115
exploration/Returns Mean          -33.898
exploration/Returns Std             8.94263
exploration/Returns Max           -23.1911
exploration/Returns Min           -47.3265
exploration/Actions Mean           -0.0279865
exploration/Actions Std             0.235701
exploration/Actions Max             0.977624
exploration/Actions Min            -0.998911
exploration/Num Paths               5
exploration/Average Returns       -33.898
evaluation/num steps total     354000
evaluation/num paths total       3540
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.371177
evaluation/Rewards Std              0.99348
evaluation/Rewards Max             -0.0187432
evaluation/Rewards Min            -10.2899
evaluation/Returns Mean           -37.1177
evaluation/Returns Std             23.6964
evaluation/Returns Max             -5.81807
evaluation/Returns Min            -84.969
evaluation/Actions Mean             0.00904381
evaluation/Actions Std              0.189762
evaluation/Actions Max              0.998429
evaluation/Actions Min             -0.997761
evaluation/Num Paths               15
evaluation/Average Returns        -37.1177
time/data storing (s)               0.00298275
time/evaluation sampling (s)        0.34514
time/exploration sampling (s)       0.154464
time/logging (s)                    0.00477679
time/saving (s)                     0.00155127
time/training (s)                   2.12413
time/epoch (s)                      2.63305
time/total (s)                    642.608
Epoch                             235
-----------------------------  ---------------
2019-04-22 22:20:43.760790 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 236 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.92001
trainer/QF2 Loss                    1.90692
trainer/Policy Loss                20.0733
trainer/Q1 Predictions Mean       -18.4807
trainer/Q1 Predictions Std          9.62063
trainer/Q1 Predictions Max         -8.65817
trainer/Q1 Predictions Min        -39.9284
trainer/Q2 Predictions Mean       -18.4735
trainer/Q2 Predictions Std          9.64082
trainer/Q2 Predictions Max         -8.65912
trainer/Q2 Predictions Min        -40.0696
trainer/Q Targets Mean            -18.3824
trainer/Q Targets Std               9.95112
trainer/Q Targets Max              -0.204219
trainer/Q Targets Min             -40.3154
trainer/Log Pis Mean                2.05796
trainer/Log Pis Std                 1.60895
trainer/Log Pis Max                 7.99493
trainer/Log Pis Min                -3.13968
trainer/Policy mu Mean              0.0860193
trainer/Policy mu Std               0.835898
trainer/Policy mu Max               2.88501
trainer/Policy mu Min              -2.5568
trainer/Policy log std Mean        -1.97013
trainer/Policy log std Std          0.563951
trainer/Policy log std Max         -0.416111
trainer/Policy log std Min         -2.71562
trainer/Alpha                       0.0668673
trainer/Alpha Loss                  0.156789
exploration/num steps total    118700
exploration/num paths total      1187
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.446649
exploration/Rewards Std             1.12941
exploration/Rewards Max            -0.00515353
exploration/Rewards Min            -9.14785
exploration/Returns Mean          -44.6649
exploration/Returns Std            10.4261
exploration/Returns Max           -30.3139
exploration/Returns Min           -58.7196
exploration/Actions Mean            0.00893558
exploration/Actions Std             0.250831
exploration/Actions Max             0.999821
exploration/Actions Min            -0.999266
exploration/Num Paths               5
exploration/Average Returns       -44.6649
evaluation/num steps total     355500
evaluation/num paths total       3555
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.493237
evaluation/Rewards Std              1.08548
evaluation/Rewards Max             -0.119698
evaluation/Rewards Min            -10.1462
evaluation/Returns Mean           -49.3237
evaluation/Returns Std             21.9665
evaluation/Returns Max            -18.4505
evaluation/Returns Min            -98.8408
evaluation/Actions Mean            -0.00143873
evaluation/Actions Std              0.202829
evaluation/Actions Max              0.998959
evaluation/Actions Min             -0.998052
evaluation/Num Paths               15
evaluation/Average Returns        -49.3237
time/data storing (s)               0.00314662
time/evaluation sampling (s)        0.340754
time/exploration sampling (s)       0.150383
time/logging (s)                    0.00488962
time/saving (s)                     0.00181459
time/training (s)                   2.11589
time/epoch (s)                      2.61688
time/total (s)                    645.229
Epoch                             236
-----------------------------  ---------------
2019-04-22 22:20:46.353677 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 237 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.068425
trainer/QF2 Loss                    0.104966
trainer/Policy Loss                19.3861
trainer/Q1 Predictions Mean       -17.8084
trainer/Q1 Predictions Std          9.6257
trainer/Q1 Predictions Max         -8.65142
trainer/Q1 Predictions Min        -41.6536
trainer/Q2 Predictions Mean       -17.7808
trainer/Q2 Predictions Std          9.61042
trainer/Q2 Predictions Max         -8.67696
trainer/Q2 Predictions Min        -41.6616
trainer/Q Targets Mean            -18.0075
trainer/Q Targets Std               9.64757
trainer/Q Targets Max              -8.63948
trainer/Q Targets Min             -41.7332
trainer/Log Pis Mean                2.00312
trainer/Log Pis Std                 1.24983
trainer/Log Pis Max                 5.56023
trainer/Log Pis Min                -0.83417
trainer/Policy mu Mean             -0.0288771
trainer/Policy mu Std               0.813923
trainer/Policy mu Max               2.50304
trainer/Policy mu Min              -2.7011
trainer/Policy log std Mean        -1.9417
trainer/Policy log std Std          0.549741
trainer/Policy log std Max         -0.49274
trainer/Policy log std Min         -2.71718
trainer/Alpha                       0.0663689
trainer/Alpha Loss                  0.00845013
exploration/num steps total    119200
exploration/num paths total      1192
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.543845
exploration/Rewards Std             1.00355
exploration/Rewards Max            -0.0291798
exploration/Rewards Min            -8.09849
exploration/Returns Mean          -54.3845
exploration/Returns Std            15.5811
exploration/Returns Max           -27.855
exploration/Returns Min           -74.7305
exploration/Actions Mean           -0.00379529
exploration/Actions Std             0.223195
exploration/Actions Max             0.999086
exploration/Actions Min            -0.99994
exploration/Num Paths               5
exploration/Average Returns       -54.3845
evaluation/num steps total     357000
evaluation/num paths total       3570
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.319561
evaluation/Rewards Std              0.900594
evaluation/Rewards Max             -0.0466679
evaluation/Rewards Min             -9.40908
evaluation/Returns Mean           -31.9561
evaluation/Returns Std             14.3856
evaluation/Returns Max            -13.4556
evaluation/Returns Min            -56.0512
evaluation/Actions Mean            -0.00805276
evaluation/Actions Std              0.189056
evaluation/Actions Max              0.998379
evaluation/Actions Min             -0.998136
evaluation/Num Paths               15
evaluation/Average Returns        -31.9561
time/data storing (s)               0.00307569
time/evaluation sampling (s)        0.337648
time/exploration sampling (s)       0.155368
time/logging (s)                    0.0048243
time/saving (s)                     0.00166624
time/training (s)                   2.08337
time/epoch (s)                      2.58595
time/total (s)                    647.819
Epoch                             237
-----------------------------  ---------------
2019-04-22 22:20:49.194032 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 238 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.194804
trainer/QF2 Loss                    0.229217
trainer/Policy Loss                18.836
trainer/Q1 Predictions Mean       -17.3238
trainer/Q1 Predictions Std          8.85833
trainer/Q1 Predictions Max         -8.68581
trainer/Q1 Predictions Min        -39.6228
trainer/Q2 Predictions Mean       -17.3182
trainer/Q2 Predictions Std          8.85117
trainer/Q2 Predictions Max         -8.68872
trainer/Q2 Predictions Min        -39.6255
trainer/Q Targets Mean            -17.6681
trainer/Q Targets Std               9.04937
trainer/Q Targets Max              -8.60131
trainer/Q Targets Min             -40.6102
trainer/Log Pis Mean                1.94656
trainer/Log Pis Std                 1.17919
trainer/Log Pis Max                 4.93192
trainer/Log Pis Min                -0.991943
trainer/Policy mu Mean              0.0359945
trainer/Policy mu Std               0.746858
trainer/Policy mu Max               3.01178
trainer/Policy mu Min              -2.28141
trainer/Policy log std Mean        -2.00733
trainer/Policy log std Std          0.487968
trainer/Policy log std Max         -0.519808
trainer/Policy log std Min         -2.6977
trainer/Alpha                       0.0672218
trainer/Alpha Loss                 -0.144269
exploration/num steps total    119700
exploration/num paths total      1197
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.411241
exploration/Rewards Std             1.07174
exploration/Rewards Max            -0.0105596
exploration/Rewards Min           -10.4616
exploration/Returns Mean          -41.1241
exploration/Returns Std            17.4905
exploration/Returns Max           -14.9923
exploration/Returns Min           -68.6606
exploration/Actions Mean           -0.00960122
exploration/Actions Std             0.229954
exploration/Actions Max             0.999841
exploration/Actions Min            -0.998194
exploration/Num Paths               5
exploration/Average Returns       -41.1241
evaluation/num steps total     358500
evaluation/num paths total       3585
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.368563
evaluation/Rewards Std              0.881195
evaluation/Rewards Max             -0.0922479
evaluation/Rewards Min             -8.54651
evaluation/Returns Mean           -36.8563
evaluation/Returns Std             22.2222
evaluation/Returns Max            -11.1994
evaluation/Returns Min            -81.4911
evaluation/Actions Mean            -0.00656894
evaluation/Actions Std              0.171513
evaluation/Actions Max              0.998684
evaluation/Actions Min             -0.998266
evaluation/Num Paths               15
evaluation/Average Returns        -36.8563
time/data storing (s)               0.00277857
time/evaluation sampling (s)        0.349612
time/exploration sampling (s)       0.145728
time/logging (s)                    0.00466399
time/saving (s)                     0.00197388
time/training (s)                   2.32714
time/epoch (s)                      2.8319
time/total (s)                    650.656
Epoch                             238
-----------------------------  ---------------
2019-04-22 22:20:51.778880 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 239 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.1269
trainer/QF2 Loss                    1.1115
trainer/Policy Loss                20.9673
trainer/Q1 Predictions Mean       -19.5467
trainer/Q1 Predictions Std         10.3961
trainer/Q1 Predictions Max         -8.74096
trainer/Q1 Predictions Min        -41.9512
trainer/Q2 Predictions Mean       -19.5423
trainer/Q2 Predictions Std         10.4432
trainer/Q2 Predictions Max         -8.72238
trainer/Q2 Predictions Min        -42.2306
trainer/Q Targets Mean            -19.6249
trainer/Q Targets Std              10.6791
trainer/Q Targets Max              -0.255659
trainer/Q Targets Min             -41.9355
trainer/Log Pis Mean                2.08574
trainer/Log Pis Std                 1.31788
trainer/Log Pis Max                 5.69418
trainer/Log Pis Min                -1.90125
trainer/Policy mu Mean              0.0125266
trainer/Policy mu Std               0.820013
trainer/Policy mu Max               2.98201
trainer/Policy mu Min              -2.68241
trainer/Policy log std Mean        -1.96595
trainer/Policy log std Std          0.553716
trainer/Policy log std Max         -0.498245
trainer/Policy log std Min         -2.73004
trainer/Alpha                       0.0680363
trainer/Alpha Loss                  0.23045
exploration/num steps total    120200
exploration/num paths total      1202
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.380619
exploration/Rewards Std             0.885704
exploration/Rewards Max            -0.0043906
exploration/Rewards Min            -8.64328
exploration/Returns Mean          -38.0619
exploration/Returns Std            17.6565
exploration/Returns Max           -14.7142
exploration/Returns Min           -61.6999
exploration/Actions Mean            0.0206872
exploration/Actions Std             0.207788
exploration/Actions Max             0.998158
exploration/Actions Min            -0.998349
exploration/Num Paths               5
exploration/Average Returns       -38.0619
evaluation/num steps total     360000
evaluation/num paths total       3600
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.306337
evaluation/Rewards Std              1.03102
evaluation/Rewards Max             -0.0396852
evaluation/Rewards Min            -10.817
evaluation/Returns Mean           -30.6337
evaluation/Returns Std             19.7708
evaluation/Returns Max             -6.02792
evaluation/Returns Min            -68.1643
evaluation/Actions Mean             0.00882766
evaluation/Actions Std              0.187707
evaluation/Actions Max              0.998321
evaluation/Actions Min             -0.99876
evaluation/Num Paths               15
evaluation/Average Returns        -30.6337
time/data storing (s)               0.00298474
time/evaluation sampling (s)        0.380797
time/exploration sampling (s)       0.158049
time/logging (s)                    0.0048168
time/saving (s)                     0.00191679
time/training (s)                   2.02784
time/epoch (s)                      2.5764
time/total (s)                    653.237
Epoch                             239
-----------------------------  ---------------
2019-04-22 22:20:54.290810 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 240 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.916916
trainer/QF2 Loss                    0.858311
trainer/Policy Loss                19.1748
trainer/Q1 Predictions Mean       -17.4734
trainer/Q1 Predictions Std         10.1815
trainer/Q1 Predictions Max         -8.63156
trainer/Q1 Predictions Min        -59.6936
trainer/Q2 Predictions Mean       -17.4723
trainer/Q2 Predictions Std         10.223
trainer/Q2 Predictions Max         -8.69963
trainer/Q2 Predictions Min        -60.6949
trainer/Q Targets Mean            -17.5376
trainer/Q Targets Std              10.5216
trainer/Q Targets Max              -0.177649
trainer/Q Targets Min             -62.985
trainer/Log Pis Mean                1.92869
trainer/Log Pis Std                 1.17977
trainer/Log Pis Max                 7.34129
trainer/Log Pis Min                -1.15835
trainer/Policy mu Mean              0.019102
trainer/Policy mu Std               0.630656
trainer/Policy mu Max               2.66557
trainer/Policy mu Min              -3.29883
trainer/Policy log std Mean        -2.09152
trainer/Policy log std Std          0.430105
trainer/Policy log std Max         -0.519135
trainer/Policy log std Min         -2.67697
trainer/Alpha                       0.0707816
trainer/Alpha Loss                 -0.188838
exploration/num steps total    120700
exploration/num paths total      1207
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.442253
exploration/Rewards Std             1.14832
exploration/Rewards Max            -0.00221924
exploration/Rewards Min           -11.0955
exploration/Returns Mean          -44.2253
exploration/Returns Std            28.4186
exploration/Returns Max           -16.9188
exploration/Returns Min           -89.6249
exploration/Actions Mean           -0.0145721
exploration/Actions Std             0.246036
exploration/Actions Max             0.998206
exploration/Actions Min            -0.999908
exploration/Num Paths               5
exploration/Average Returns       -44.2253
evaluation/num steps total     361500
evaluation/num paths total       3615
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.385604
evaluation/Rewards Std              0.999707
evaluation/Rewards Max             -0.028849
evaluation/Rewards Min             -8.89129
evaluation/Returns Mean           -38.5604
evaluation/Returns Std             24.7417
evaluation/Returns Max             -3.4684
evaluation/Returns Min            -82.6581
evaluation/Actions Mean            -0.00436381
evaluation/Actions Std              0.197022
evaluation/Actions Max              0.997198
evaluation/Actions Min             -0.999123
evaluation/Num Paths               15
evaluation/Average Returns        -38.5604
time/data storing (s)               0.00291481
time/evaluation sampling (s)        0.33666
time/exploration sampling (s)       0.148395
time/logging (s)                    0.00476534
time/saving (s)                     0.00196267
time/training (s)                   2.00892
time/epoch (s)                      2.50361
time/total (s)                    655.745
Epoch                             240
-----------------------------  ---------------
2019-04-22 22:20:56.833014 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 241 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.810483
trainer/QF2 Loss                    0.790399
trainer/Policy Loss                19.2334
trainer/Q1 Predictions Mean       -17.906
trainer/Q1 Predictions Std          9.25645
trainer/Q1 Predictions Max         -8.73634
trainer/Q1 Predictions Min        -39.2159
trainer/Q2 Predictions Mean       -17.9278
trainer/Q2 Predictions Std          9.30499
trainer/Q2 Predictions Max         -8.72947
trainer/Q2 Predictions Min        -39.0574
trainer/Q Targets Mean            -17.9335
trainer/Q Targets Std               9.5076
trainer/Q Targets Max              -0.211347
trainer/Q Targets Min             -39.1188
trainer/Log Pis Mean                1.73895
trainer/Log Pis Std                 1.53959
trainer/Log Pis Max                 5.2831
trainer/Log Pis Min                -6.31926
trainer/Policy mu Mean              0.00563079
trainer/Policy mu Std               0.711601
trainer/Policy mu Max               2.17023
trainer/Policy mu Min              -2.21009
trainer/Policy log std Mean        -1.99419
trainer/Policy log std Std          0.479927
trainer/Policy log std Max         -0.544425
trainer/Policy log std Min         -2.61155
trainer/Alpha                       0.070461
trainer/Alpha Loss                 -0.692455
exploration/num steps total    121200
exploration/num paths total      1212
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.364242
exploration/Rewards Std             1.0953
exploration/Rewards Max            -0.00654635
exploration/Rewards Min           -10.1744
exploration/Returns Mean          -36.4242
exploration/Returns Std            18.0722
exploration/Returns Max           -13.118
exploration/Returns Min           -64.5461
exploration/Actions Mean            0.0129798
exploration/Actions Std             0.232051
exploration/Actions Max             0.99942
exploration/Actions Min            -0.999164
exploration/Num Paths               5
exploration/Average Returns       -36.4242
evaluation/num steps total     363000
evaluation/num paths total       3630
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.480525
evaluation/Rewards Std              1.13196
evaluation/Rewards Max             -0.0180158
evaluation/Rewards Min            -10.1092
evaluation/Returns Mean           -48.0525
evaluation/Returns Std             32.5215
evaluation/Returns Max             -2.25745
evaluation/Returns Min            -99.6513
evaluation/Actions Mean             0.016928
evaluation/Actions Std              0.195349
evaluation/Actions Max              0.998495
evaluation/Actions Min             -0.995092
evaluation/Num Paths               15
evaluation/Average Returns        -48.0525
time/data storing (s)               0.002954
time/evaluation sampling (s)        0.336676
time/exploration sampling (s)       0.146068
time/logging (s)                    0.00476796
time/saving (s)                     0.00192483
time/training (s)                   2.04154
time/epoch (s)                      2.53393
time/total (s)                    658.283
Epoch                             241
-----------------------------  ---------------
2019-04-22 22:20:59.365192 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 242 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.118211
trainer/QF2 Loss                    0.139986
trainer/Policy Loss                18.5703
trainer/Q1 Predictions Mean       -17.004
trainer/Q1 Predictions Std          9.09331
trainer/Q1 Predictions Max         -8.78498
trainer/Q1 Predictions Min        -43.6298
trainer/Q2 Predictions Mean       -16.9944
trainer/Q2 Predictions Std          9.05871
trainer/Q2 Predictions Max         -8.78796
trainer/Q2 Predictions Min        -42.7008
trainer/Q Targets Mean            -17.2137
trainer/Q Targets Std               9.17276
trainer/Q Targets Max              -8.70245
trainer/Q Targets Min             -45.1344
trainer/Log Pis Mean                1.99892
trainer/Log Pis Std                 1.42304
trainer/Log Pis Max                 5.69976
trainer/Log Pis Min                -2.2892
trainer/Policy mu Mean              0.00416326
trainer/Policy mu Std               0.852871
trainer/Policy mu Max               2.73063
trainer/Policy mu Min              -3.45599
trainer/Policy log std Mean        -1.91041
trainer/Policy log std Std          0.540032
trainer/Policy log std Max         -0.493718
trainer/Policy log std Min         -2.60129
trainer/Alpha                       0.0695039
trainer/Alpha Loss                 -0.00288865
exploration/num steps total    121700
exploration/num paths total      1217
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.373294
exploration/Rewards Std             1.0033
exploration/Rewards Max            -0.00179512
exploration/Rewards Min            -8.06391
exploration/Returns Mean          -37.3294
exploration/Returns Std            14.7285
exploration/Returns Max           -12.3544
exploration/Returns Min           -54.2374
exploration/Actions Mean           -0.0276189
exploration/Actions Std             0.24108
exploration/Actions Max             0.988279
exploration/Actions Min            -0.999074
exploration/Num Paths               5
exploration/Average Returns       -37.3294
evaluation/num steps total     364500
evaluation/num paths total       3645
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.416169
evaluation/Rewards Std              1.07262
evaluation/Rewards Max             -0.0117309
evaluation/Rewards Min            -10.6974
evaluation/Returns Mean           -41.6169
evaluation/Returns Std             22.7402
evaluation/Returns Max             -7.15628
evaluation/Returns Min           -101.179
evaluation/Actions Mean            -0.000176879
evaluation/Actions Std              0.197174
evaluation/Actions Max              0.999002
evaluation/Actions Min             -0.998036
evaluation/Num Paths               15
evaluation/Average Returns        -41.6169
time/data storing (s)               0.00265208
time/evaluation sampling (s)        0.335921
time/exploration sampling (s)       0.155767
time/logging (s)                    0.0048062
time/saving (s)                     0.00205425
time/training (s)                   2.02304
time/epoch (s)                      2.52424
time/total (s)                    660.812
Epoch                             242
-----------------------------  ----------------
2019-04-22 22:21:01.875614 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 243 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    9.81528
trainer/QF2 Loss                    9.85334
trainer/Policy Loss                17.8952
trainer/Q1 Predictions Mean       -16.4083
trainer/Q1 Predictions Std          8.48811
trainer/Q1 Predictions Max         -8.63285
trainer/Q1 Predictions Min        -36.2746
trainer/Q2 Predictions Mean       -16.3744
trainer/Q2 Predictions Std          8.49394
trainer/Q2 Predictions Max         -8.63891
trainer/Q2 Predictions Min        -36.2233
trainer/Q Targets Mean            -15.913
trainer/Q Targets Std               8.85048
trainer/Q Targets Max              -0.213205
trainer/Q Targets Min             -36.689
trainer/Log Pis Mean                1.76305
trainer/Log Pis Std                 1.35369
trainer/Log Pis Max                 5.06833
trainer/Log Pis Min                -4.05721
trainer/Policy mu Mean             -0.00118855
trainer/Policy mu Std               0.670872
trainer/Policy mu Max               1.94801
trainer/Policy mu Min              -2.96799
trainer/Policy log std Mean        -2.00351
trainer/Policy log std Std          0.469366
trainer/Policy log std Max         -0.260983
trainer/Policy log std Min         -2.59488
trainer/Alpha                       0.0673097
trainer/Alpha Loss                 -0.639351
exploration/num steps total    122200
exploration/num paths total      1222
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.552298
exploration/Rewards Std             1.12871
exploration/Rewards Max            -0.0141046
exploration/Rewards Min           -11.1965
exploration/Returns Mean          -55.2298
exploration/Returns Std            12.7861
exploration/Returns Max           -34.9746
exploration/Returns Min           -70.7532
exploration/Actions Mean           -0.0106092
exploration/Actions Std             0.244296
exploration/Actions Max             0.99748
exploration/Actions Min            -0.999166
exploration/Num Paths               5
exploration/Average Returns       -55.2298
evaluation/num steps total     366000
evaluation/num paths total       3660
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.375559
evaluation/Rewards Std              0.818631
evaluation/Rewards Max             -0.051623
evaluation/Rewards Min            -10.3354
evaluation/Returns Mean           -37.5559
evaluation/Returns Std             22.4626
evaluation/Returns Max            -13.5935
evaluation/Returns Min            -95.3381
evaluation/Actions Mean            -0.000214513
evaluation/Actions Std              0.186298
evaluation/Actions Max              0.998356
evaluation/Actions Min             -0.995862
evaluation/Num Paths               15
evaluation/Average Returns        -37.5559
time/data storing (s)               0.00291078
time/evaluation sampling (s)        0.336842
time/exploration sampling (s)       0.145198
time/logging (s)                    0.00533021
time/saving (s)                     0.00211621
time/training (s)                   2.01081
time/epoch (s)                      2.50321
time/total (s)                    663.319
Epoch                             243
-----------------------------  ----------------
2019-04-22 22:21:04.406604 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 244 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    2.93631
trainer/QF2 Loss                    2.93026
trainer/Policy Loss                18.4568
trainer/Q1 Predictions Mean       -16.9152
trainer/Q1 Predictions Std          9.51083
trainer/Q1 Predictions Max         -8.66597
trainer/Q1 Predictions Min        -47.4644
trainer/Q2 Predictions Mean       -16.91
trainer/Q2 Predictions Std          9.53987
trainer/Q2 Predictions Max         -8.65905
trainer/Q2 Predictions Min        -47.7981
trainer/Q Targets Mean            -16.8665
trainer/Q Targets Std              10.0592
trainer/Q Targets Max              -0.128247
trainer/Q Targets Min             -50.8169
trainer/Log Pis Mean                1.82111
trainer/Log Pis Std                 1.29664
trainer/Log Pis Max                 6.22631
trainer/Log Pis Min                -3.00164
trainer/Policy mu Mean             -0.0161422
trainer/Policy mu Std               0.689824
trainer/Policy mu Max               2.61943
trainer/Policy mu Min              -3.61276
trainer/Policy log std Mean        -2.05596
trainer/Policy log std Std          0.462473
trainer/Policy log std Max         -0.57785
trainer/Policy log std Min         -2.68991
trainer/Alpha                       0.0659336
trainer/Alpha Loss                 -0.486378
exploration/num steps total    122700
exploration/num paths total      1227
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.489902
exploration/Rewards Std             0.838257
exploration/Rewards Max            -0.00806519
exploration/Rewards Min            -8.136
exploration/Returns Mean          -48.9902
exploration/Returns Std             9.18816
exploration/Returns Max           -36.2691
exploration/Returns Min           -61.083
exploration/Actions Mean            0.00652683
exploration/Actions Std             0.233234
exploration/Actions Max             0.999215
exploration/Actions Min            -0.996703
exploration/Num Paths               5
exploration/Average Returns       -48.9902
evaluation/num steps total     367500
evaluation/num paths total       3675
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.529804
evaluation/Rewards Std              1.11684
evaluation/Rewards Max             -0.105317
evaluation/Rewards Min            -10.9995
evaluation/Returns Mean           -52.9804
evaluation/Returns Std             21.6208
evaluation/Returns Max            -25.873
evaluation/Returns Min           -102.027
evaluation/Actions Mean             0.00353331
evaluation/Actions Std              0.211615
evaluation/Actions Max              0.999114
evaluation/Actions Min             -0.998831
evaluation/Num Paths               15
evaluation/Average Returns        -52.9804
time/data storing (s)               0.0028945
time/evaluation sampling (s)        0.335351
time/exploration sampling (s)       0.147431
time/logging (s)                    0.00474488
time/saving (s)                     0.00196209
time/training (s)                   2.02942
time/epoch (s)                      2.52181
time/total (s)                    665.845
Epoch                             244
-----------------------------  ---------------
2019-04-22 22:21:06.927979 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 245 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    5.0409
trainer/QF2 Loss                    5.00455
trainer/Policy Loss                17.7801
trainer/Q1 Predictions Mean       -15.9743
trainer/Q1 Predictions Std          8.81868
trainer/Q1 Predictions Max         -8.48173
trainer/Q1 Predictions Min        -45.5808
trainer/Q2 Predictions Mean       -15.9881
trainer/Q2 Predictions Std          8.82088
trainer/Q2 Predictions Max         -8.50442
trainer/Q2 Predictions Min        -45.5941
trainer/Q Targets Mean            -15.8595
trainer/Q Targets Std               9.10998
trainer/Q Targets Max              -0.185268
trainer/Q Targets Min             -47.4572
trainer/Log Pis Mean                2.0444
trainer/Log Pis Std                 1.1908
trainer/Log Pis Max                 6.3447
trainer/Log Pis Min                -1.41401
trainer/Policy mu Mean              0.0223343
trainer/Policy mu Std               0.600659
trainer/Policy mu Max               2.16309
trainer/Policy mu Min              -3.41443
trainer/Policy log std Mean        -2.13782
trainer/Policy log std Std          0.446078
trainer/Policy log std Max         -0.544491
trainer/Policy log std Min         -2.82855
trainer/Alpha                       0.066159
trainer/Alpha Loss                  0.120568
exploration/num steps total    123200
exploration/num paths total      1232
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.520148
exploration/Rewards Std             1.22235
exploration/Rewards Max            -0.012
exploration/Rewards Min           -10.027
exploration/Returns Mean          -52.0148
exploration/Returns Std            24.4875
exploration/Returns Max           -28.4222
exploration/Returns Min           -98.34
exploration/Actions Mean            0.0408969
exploration/Actions Std             0.24526
exploration/Actions Max             0.998847
exploration/Actions Min            -0.985757
exploration/Num Paths               5
exploration/Average Returns       -52.0148
evaluation/num steps total     369000
evaluation/num paths total       3690
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.454521
evaluation/Rewards Std              1.16468
evaluation/Rewards Max             -0.0275347
evaluation/Rewards Min            -11.0665
evaluation/Returns Mean           -45.4521
evaluation/Returns Std             20.4043
evaluation/Returns Max            -13.4416
evaluation/Returns Min            -80.8289
evaluation/Actions Mean             0.0178592
evaluation/Actions Std              0.205048
evaluation/Actions Max              0.998764
evaluation/Actions Min             -0.998609
evaluation/Num Paths               15
evaluation/Average Returns        -45.4521
time/data storing (s)               0.00265193
time/evaluation sampling (s)        0.340197
time/exploration sampling (s)       0.144326
time/logging (s)                    0.00453803
time/saving (s)                     0.00197179
time/training (s)                   2.01986
time/epoch (s)                      2.51355
time/total (s)                    668.363
Epoch                             245
-----------------------------  ---------------
2019-04-22 22:21:09.453781 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 246 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.27944
trainer/QF2 Loss                    1.25896
trainer/Policy Loss                17.6603
trainer/Q1 Predictions Mean       -15.9391
trainer/Q1 Predictions Std          8.72561
trainer/Q1 Predictions Max         -8.44024
trainer/Q1 Predictions Min        -41.4759
trainer/Q2 Predictions Mean       -15.9164
trainer/Q2 Predictions Std          8.73484
trainer/Q2 Predictions Max         -8.44255
trainer/Q2 Predictions Min        -41.6614
trainer/Q Targets Mean            -15.9759
trainer/Q Targets Std               8.83546
trainer/Q Targets Max              -0.316836
trainer/Q Targets Min             -41.0753
trainer/Log Pis Mean                2.02475
trainer/Log Pis Std                 1.09062
trainer/Log Pis Max                 5.56001
trainer/Log Pis Min                -1.89812
trainer/Policy mu Mean              0.0313839
trainer/Policy mu Std               0.621863
trainer/Policy mu Max               2.83318
trainer/Policy mu Min              -2.51099
trainer/Policy log std Mean        -2.08786
trainer/Policy log std Std          0.46008
trainer/Policy log std Max         -0.417025
trainer/Policy log std Min         -2.65819
trainer/Alpha                       0.0681762
trainer/Alpha Loss                  0.0664691
exploration/num steps total    123700
exploration/num paths total      1237
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.33381
exploration/Rewards Std             0.595254
exploration/Rewards Max            -0.00675309
exploration/Rewards Min            -8.13907
exploration/Returns Mean          -33.381
exploration/Returns Std            13.4482
exploration/Returns Max           -16.5222
exploration/Returns Min           -48.7786
exploration/Actions Mean           -0.00752759
exploration/Actions Std             0.205981
exploration/Actions Max             0.999181
exploration/Actions Min            -0.997375
exploration/Num Paths               5
exploration/Average Returns       -33.381
evaluation/num steps total     370500
evaluation/num paths total       3705
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.335304
evaluation/Rewards Std              0.901119
evaluation/Rewards Max             -0.0450518
evaluation/Rewards Min            -10.7978
evaluation/Returns Mean           -33.5304
evaluation/Returns Std             16.7889
evaluation/Returns Max            -14.7157
evaluation/Returns Min            -68.8919
evaluation/Actions Mean            -0.00980983
evaluation/Actions Std              0.193134
evaluation/Actions Max              0.99753
evaluation/Actions Min             -0.998257
evaluation/Num Paths               15
evaluation/Average Returns        -33.5304
time/data storing (s)               0.00294466
time/evaluation sampling (s)        0.332974
time/exploration sampling (s)       0.1443
time/logging (s)                    0.00496964
time/saving (s)                     0.00195297
time/training (s)                   2.03096
time/epoch (s)                      2.5181
time/total (s)                    670.885
Epoch                             246
-----------------------------  ---------------
2019-04-22 22:21:12.060102 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 247 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.220242
trainer/QF2 Loss                    0.225781
trainer/Policy Loss                19.8503
trainer/Q1 Predictions Mean       -18.3282
trainer/Q1 Predictions Std          9.66762
trainer/Q1 Predictions Max         -8.35122
trainer/Q1 Predictions Min        -41.1488
trainer/Q2 Predictions Mean       -18.3365
trainer/Q2 Predictions Std          9.6581
trainer/Q2 Predictions Max         -8.37056
trainer/Q2 Predictions Min        -41.5108
trainer/Q Targets Mean            -18.6488
trainer/Q Targets Std               9.84919
trainer/Q Targets Max              -8.60903
trainer/Q Targets Min             -40.9326
trainer/Log Pis Mean                1.82777
trainer/Log Pis Std                 1.20264
trainer/Log Pis Max                 5.81163
trainer/Log Pis Min                -1.79942
trainer/Policy mu Mean              0.00913229
trainer/Policy mu Std               0.700774
trainer/Policy mu Max               2.2342
trainer/Policy mu Min              -2.99434
trainer/Policy log std Mean        -2.02231
trainer/Policy log std Std          0.475251
trainer/Policy log std Max         -0.485518
trainer/Policy log std Min         -2.64358
trainer/Alpha                       0.0706476
trainer/Alpha Loss                 -0.456396
exploration/num steps total    124200
exploration/num paths total      1242
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.327447
exploration/Rewards Std             0.92939
exploration/Rewards Max            -0.00584432
exploration/Rewards Min            -9.8794
exploration/Returns Mean          -32.7447
exploration/Returns Std            18.3491
exploration/Returns Max           -17.3268
exploration/Returns Min           -65.7404
exploration/Actions Mean            0.0141826
exploration/Actions Std             0.216911
exploration/Actions Max             0.998518
exploration/Actions Min            -0.996664
exploration/Num Paths               5
exploration/Average Returns       -32.7447
evaluation/num steps total     372000
evaluation/num paths total       3720
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.39971
evaluation/Rewards Std              0.768934
evaluation/Rewards Max             -0.0925632
evaluation/Rewards Min             -9.58182
evaluation/Returns Mean           -39.971
evaluation/Returns Std             21.1025
evaluation/Returns Max            -11.9134
evaluation/Returns Min            -84.2017
evaluation/Actions Mean            -0.00107703
evaluation/Actions Std              0.175679
evaluation/Actions Max              0.998149
evaluation/Actions Min             -0.992837
evaluation/Num Paths               15
evaluation/Average Returns        -39.971
time/data storing (s)               0.00316374
time/evaluation sampling (s)        0.34233
time/exploration sampling (s)       0.149896
time/logging (s)                    0.00434442
time/saving (s)                     0.0101304
time/training (s)                   2.08843
time/epoch (s)                      2.59829
time/total (s)                    673.487
Epoch                             247
-----------------------------  ---------------
2019-04-22 22:21:14.640160 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 248 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.214578
trainer/QF2 Loss                    0.171634
trainer/Policy Loss                18.9001
trainer/Q1 Predictions Mean       -17.1219
trainer/Q1 Predictions Std          9.41265
trainer/Q1 Predictions Max         -8.501
trainer/Q1 Predictions Min        -41.5679
trainer/Q2 Predictions Mean       -17.1177
trainer/Q2 Predictions Std          9.40412
trainer/Q2 Predictions Max         -8.50133
trainer/Q2 Predictions Min        -40.9089
trainer/Q Targets Mean            -17.3141
trainer/Q Targets Std               9.56893
trainer/Q Targets Max              -8.50749
trainer/Q Targets Min             -40.6616
trainer/Log Pis Mean                2.08476
trainer/Log Pis Std                 1.42177
trainer/Log Pis Max                 8.73614
trainer/Log Pis Min                -1.3513
trainer/Policy mu Mean              0.0462112
trainer/Policy mu Std               0.763782
trainer/Policy mu Max               2.8056
trainer/Policy mu Min              -3.52387
trainer/Policy log std Mean        -2.05424
trainer/Policy log std Std          0.504345
trainer/Policy log std Max         -0.194895
trainer/Policy log std Min         -2.62624
trainer/Alpha                       0.0708146
trainer/Alpha Loss                  0.224408
exploration/num steps total    124700
exploration/num paths total      1247
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.450581
exploration/Rewards Std             0.787482
exploration/Rewards Max            -0.000726303
exploration/Rewards Min            -6.70639
exploration/Returns Mean          -45.0581
exploration/Returns Std            17.1272
exploration/Returns Max           -18.709
exploration/Returns Min           -68.801
exploration/Actions Mean            0.00525512
exploration/Actions Std             0.206283
exploration/Actions Max             0.998949
exploration/Actions Min            -0.994107
exploration/Num Paths               5
exploration/Average Returns       -45.0581
evaluation/num steps total     373500
evaluation/num paths total       3735
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.374655
evaluation/Rewards Std              0.922774
evaluation/Rewards Max             -0.0195523
evaluation/Rewards Min             -9.7294
evaluation/Returns Mean           -37.4655
evaluation/Returns Std             17.7763
evaluation/Returns Max             -3.05842
evaluation/Returns Min            -65.0308
evaluation/Actions Mean            -0.00747468
evaluation/Actions Std              0.195888
evaluation/Actions Max              0.99876
evaluation/Actions Min             -0.997497
evaluation/Num Paths               15
evaluation/Average Returns        -37.4655
time/data storing (s)               0.00312274
time/evaluation sampling (s)        0.345293
time/exploration sampling (s)       0.159526
time/logging (s)                    0.00477815
time/saving (s)                     0.00195669
time/training (s)                   2.05681
time/epoch (s)                      2.57148
time/total (s)                    676.063
Epoch                             248
-----------------------------  ----------------
2019-04-22 22:21:17.203423 PDT | [sac-pointmass-multitask-5_2019_04_22_22_09_58_0000--s-0] Epoch 249 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.22286
trainer/QF2 Loss                    1.24642
trainer/Policy Loss                16.8678
trainer/Q1 Predictions Mean       -15.1796
trainer/Q1 Predictions Std          7.86184
trainer/Q1 Predictions Max         -8.45777
trainer/Q1 Predictions Min        -32.7528
trainer/Q2 Predictions Mean       -15.1875
trainer/Q2 Predictions Std          7.86352
trainer/Q2 Predictions Max         -8.44768
trainer/Q2 Predictions Min        -32.6571
trainer/Q Targets Mean            -15.1633
trainer/Q Targets Std               7.99072
trainer/Q Targets Max              -0.233039
trainer/Q Targets Min             -32.8506
trainer/Log Pis Mean                1.93177
trainer/Log Pis Std                 1.33956
trainer/Log Pis Max                 5.46326
trainer/Log Pis Min                -5.88332
trainer/Policy mu Mean              0.0694423
trainer/Policy mu Std               0.551098
trainer/Policy mu Max               2.63972
trainer/Policy mu Min              -2.43695
trainer/Policy log std Mean        -2.15238
trainer/Policy log std Std          0.426427
trainer/Policy log std Max         -0.475781
trainer/Policy log std Min         -2.72851
trainer/Alpha                       0.070703
trainer/Alpha Loss                 -0.180777
exploration/num steps total    125200
exploration/num paths total      1252
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.591358
exploration/Rewards Std             1.40982
exploration/Rewards Max            -0.00837188
exploration/Rewards Min            -9.54974
exploration/Returns Mean          -59.1358
exploration/Returns Std            20.6511
exploration/Returns Max           -22.3681
exploration/Returns Min           -78.7721
exploration/Actions Mean           -0.012144
exploration/Actions Std             0.266246
exploration/Actions Max             0.99939
exploration/Actions Min            -0.999406
exploration/Num Paths               5
exploration/Average Returns       -59.1358
evaluation/num steps total     375000
evaluation/num paths total       3750
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.429076
evaluation/Rewards Std              1.02406
evaluation/Rewards Max             -0.00185457
evaluation/Rewards Min            -10.2446
evaluation/Returns Mean           -42.9076
evaluation/Returns Std             24.2303
evaluation/Returns Max             -8.2565
evaluation/Returns Min            -95.4887
evaluation/Actions Mean             0.0083807
evaluation/Actions Std              0.196598
evaluation/Actions Max              0.997743
evaluation/Actions Min             -0.998969
evaluation/Num Paths               15
evaluation/Average Returns        -42.9076
time/data storing (s)               0.00292351
time/evaluation sampling (s)        0.351337
time/exploration sampling (s)       0.158084
time/logging (s)                    0.00450621
time/saving (s)                     0.00209238
time/training (s)                   2.03662
time/epoch (s)                      2.55556
time/total (s)                    678.623
Epoch                             249
-----------------------------  ---------------
