2019-04-23 01:13:33.393329 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 0 finished
-----------------------------  ---------------
replay_buffer/size               700
trainer/QF1 Loss                  53.9818
trainer/QF2 Loss                  53.9063
trainer/Policy Loss               -1.38457
trainer/Q1 Predictions Mean        0.00452817
trainer/Q1 Predictions Std         0.00196051
trainer/Q1 Predictions Max         0.00883548
trainer/Q1 Predictions Min         0.00161375
trainer/Q2 Predictions Mean       -0.000726598
trainer/Q2 Predictions Std         0.00166842
trainer/Q2 Predictions Max         0.00350611
trainer/Q2 Predictions Min        -0.00335898
trainer/Q Targets Mean            -6.79144
trainer/Q Targets Std              2.79208
trainer/Q Targets Max             -1.02833
trainer/Q Targets Min            -12.2377
trainer/Log Pis Mean              -1.38528
trainer/Log Pis Std                0.301794
trainer/Log Pis Max               -0.62864
trainer/Log Pis Min               -2.56625
trainer/Policy mu Mean            -0.000160471
trainer/Policy mu Std              0.00159543
trainer/Policy mu Max              0.0020127
trainer/Policy mu Min             -0.00341834
trainer/Policy log std Mean       -6.25541e-05
trainer/Policy log std Std         0.000739768
trainer/Policy log std Max         0.00128099
trainer/Policy log std Min        -0.001497
trainer/Alpha                      0.9997
trainer/Alpha Loss                -0
exploration/num steps total      700
exploration/num paths total        7
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -6.98642
exploration/Rewards Std            2.87979
exploration/Rewards Max           -1.24872
exploration/Rewards Min          -13.4651
exploration/Returns Mean        -698.642
exploration/Returns Std          238.765
exploration/Returns Max         -396.132
exploration/Returns Min        -1081.24
exploration/Actions Mean           0.0299355
exploration/Actions Std            0.634352
exploration/Actions Max            0.996264
exploration/Actions Min           -0.997331
exploration/Num Paths              5
exploration/Average Returns     -698.642
evaluation/num steps total      1500
evaluation/num paths total        15
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -7.89903
evaluation/Rewards Std             3.14272
evaluation/Rewards Max            -2.06107
evaluation/Rewards Min           -11.1003
evaluation/Returns Mean         -789.903
evaluation/Returns Std           314.241
evaluation/Returns Max          -215.597
evaluation/Returns Min         -1104.92
evaluation/Actions Mean           -0.000290774
evaluation/Actions Std             0.0014278
evaluation/Actions Max             0.00196177
evaluation/Actions Min            -0.00254052
evaluation/Num Paths              15
evaluation/Average Returns      -789.903
time/data storing (s)              0.00284609
time/evaluation sampling (s)       0.304161
time/exploration sampling (s)      0.144019
time/logging (s)                   0.00496747
time/saving (s)                    0.00232258
time/training (s)                  2.01353
time/epoch (s)                     2.47185
time/total (s)                     2.68826
Epoch                              0
-----------------------------  ---------------
2019-04-23 01:13:35.867874 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 1 finished
-----------------------------  --------------
replay_buffer/size              1200
trainer/QF1 Loss                   3.20559
trainer/QF2 Loss                   3.03841
trainer/Policy Loss               10.7507
trainer/Q1 Predictions Mean      -12.0611
trainer/Q1 Predictions Std         3.66131
trainer/Q1 Predictions Max        -6.58387
trainer/Q1 Predictions Min       -23.4223
trainer/Q2 Predictions Mean      -12.1034
trainer/Q2 Predictions Std         3.65235
trainer/Q2 Predictions Max        -6.36128
trainer/Q2 Predictions Min       -23.3967
trainer/Q Targets Mean           -12.4827
trainer/Q Targets Std              3.79284
trainer/Q Targets Max             -6.14239
trainer/Q Targets Min            -24.0029
trainer/Log Pis Mean              -1.11574
trainer/Log Pis Std                0.492376
trainer/Log Pis Max                0.049453
trainer/Log Pis Min               -2.36364
trainer/Policy mu Mean             0.0789231
trainer/Policy mu Std              0.32081
trainer/Policy mu Max              0.865062
trainer/Policy mu Min             -0.53873
trainer/Policy log std Mean       -0.194796
trainer/Policy log std Std         0.0390622
trainer/Policy log std Max        -0.1329
trainer/Policy log std Min        -0.30593
trainer/Alpha                      0.861521
trainer/Alpha Loss                -0.463516
exploration/num steps total     1200
exploration/num paths total       12
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -4.88726
exploration/Rewards Std            1.92104
exploration/Rewards Max           -0.761305
exploration/Rewards Min          -10.4005
exploration/Returns Mean        -488.726
exploration/Returns Std           83.0454
exploration/Returns Max         -368.295
exploration/Returns Min         -595.336
exploration/Actions Mean           0.027616
exploration/Actions Std            0.576859
exploration/Actions Max            0.998427
exploration/Actions Min           -0.983741
exploration/Num Paths              5
exploration/Average Returns     -488.726
evaluation/num steps total      3000
evaluation/num paths total        30
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -6.85674
evaluation/Rewards Std             2.50378
evaluation/Rewards Max            -0.187015
evaluation/Rewards Min           -12.1556
evaluation/Returns Mean         -685.674
evaluation/Returns Std           218.903
evaluation/Returns Max          -430.805
evaluation/Returns Min         -1096.48
evaluation/Actions Mean            0.0397
evaluation/Actions Std             0.0743109
evaluation/Actions Max             0.618399
evaluation/Actions Min            -0.411354
evaluation/Num Paths              15
evaluation/Average Returns      -685.674
time/data storing (s)              0.00289893
time/evaluation sampling (s)       0.331165
time/exploration sampling (s)      0.140732
time/logging (s)                   0.00480337
time/saving (s)                    0.0019542
time/training (s)                  1.98694
time/epoch (s)                     2.46849
time/total (s)                     5.16182
Epoch                              1
-----------------------------  --------------
2019-04-23 01:13:38.333410 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 2 finished
-----------------------------  --------------
replay_buffer/size             1700
trainer/QF1 Loss                  5.05168
trainer/QF2 Loss                  5.15765
trainer/Policy Loss              20.4524
trainer/Q1 Predictions Mean     -22.0111
trainer/Q1 Predictions Std        8.64387
trainer/Q1 Predictions Max      -13.1317
trainer/Q1 Predictions Min      -47.358
trainer/Q2 Predictions Mean     -22.0482
trainer/Q2 Predictions Std        8.59565
trainer/Q2 Predictions Max      -13.16
trainer/Q2 Predictions Min      -47.6235
trainer/Q Targets Mean          -22.4451
trainer/Q Targets Std             8.79182
trainer/Q Targets Max            -4.32487
trainer/Q Targets Min           -47.3095
trainer/Log Pis Mean             -0.790903
trainer/Log Pis Std               0.969943
trainer/Log Pis Max               1.9391
trainer/Log Pis Min              -4.04577
trainer/Policy mu Mean            0.0604491
trainer/Policy mu Std             0.590419
trainer/Policy mu Max             1.38934
trainer/Policy mu Min            -1.27837
trainer/Policy log std Mean      -0.314094
trainer/Policy log std Std        0.0720212
trainer/Policy log std Max       -0.166516
trainer/Policy log std Min       -0.469196
trainer/Alpha                     0.750316
trainer/Alpha Loss               -0.800981
exploration/num steps total    1700
exploration/num paths total      17
exploration/path length Mean    100
exploration/path length Std       0
exploration/path length Max     100
exploration/path length Min     100
exploration/Rewards Mean         -5.00686
exploration/Rewards Std           1.80022
exploration/Rewards Max          -0.740134
exploration/Rewards Min         -12.0115
exploration/Returns Mean       -500.686
exploration/Returns Std         137.06
exploration/Returns Max        -311.651
exploration/Returns Min        -668.005
exploration/Actions Mean          0.000272409
exploration/Actions Std           0.561434
exploration/Actions Max           0.99251
exploration/Actions Min          -0.97431
exploration/Num Paths             5
exploration/Average Returns    -500.686
evaluation/num steps total     4500
evaluation/num paths total       45
evaluation/path length Mean     100
evaluation/path length Std        0
evaluation/path length Max      100
evaluation/path length Min      100
evaluation/Rewards Mean          -5.13804
evaluation/Rewards Std            1.10542
evaluation/Rewards Max           -3.04023
evaluation/Rewards Min           -9.75135
evaluation/Returns Mean        -513.804
evaluation/Returns Std          102.012
evaluation/Returns Max         -349.88
evaluation/Returns Min         -644.563
evaluation/Actions Mean           0.0167311
evaluation/Actions Std            0.1214
evaluation/Actions Max            0.878619
evaluation/Actions Min           -0.861236
evaluation/Num Paths             15
evaluation/Average Returns     -513.804
time/data storing (s)             0.00308519
time/evaluation sampling (s)      0.334334
time/exploration sampling (s)     0.138002
time/logging (s)                  0.00471757
time/saving (s)                   0.00194446
time/training (s)                 1.9784
time/epoch (s)                    2.46048
time/total (s)                    7.62651
Epoch                             2
-----------------------------  --------------
2019-04-23 01:13:40.767416 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 3 finished
-----------------------------  -------------
replay_buffer/size             2200
trainer/QF1 Loss                  4.20033
trainer/QF2 Loss                  4.28323
trainer/Policy Loss              27.6409
trainer/Q1 Predictions Mean     -29.1752
trainer/Q1 Predictions Std        8.49075
trainer/Q1 Predictions Max      -15.3391
trainer/Q1 Predictions Min      -59.6436
trainer/Q2 Predictions Mean     -29.2123
trainer/Q2 Predictions Std        8.41395
trainer/Q2 Predictions Max      -15.3627
trainer/Q2 Predictions Min      -59.463
trainer/Q Targets Mean          -29.2919
trainer/Q Targets Std             8.82246
trainer/Q Targets Max            -1.36194
trainer/Q Targets Min           -60.8339
trainer/Log Pis Mean             -0.605568
trainer/Log Pis Std               0.905997
trainer/Log Pis Max               1.7553
trainer/Log Pis Min              -3.90977
trainer/Policy mu Mean           -0.0537295
trainer/Policy mu Std             0.601864
trainer/Policy mu Max             1.39979
trainer/Policy mu Min            -1.5177
trainer/Policy log std Mean      -0.389744
trainer/Policy log std Std        0.0769663
trainer/Policy log std Max       -0.241278
trainer/Policy log std Min       -0.597841
trainer/Alpha                     0.655503
trainer/Alpha Loss               -1.09979
exploration/num steps total    2200
exploration/num paths total      22
exploration/path length Mean    100
exploration/path length Std       0
exploration/path length Max     100
exploration/path length Min     100
exploration/Rewards Mean         -4.51803
exploration/Rewards Std           1.07157
exploration/Rewards Max          -2.24461
exploration/Rewards Min         -11.2003
exploration/Returns Mean       -451.803
exploration/Returns Std          49.8694
exploration/Returns Max        -392.363
exploration/Returns Min        -538.326
exploration/Actions Mean          0.0173828
exploration/Actions Std           0.557499
exploration/Actions Max           0.991724
exploration/Actions Min          -0.989276
exploration/Num Paths             5
exploration/Average Returns    -451.803
evaluation/num steps total     6000
evaluation/num paths total       60
evaluation/path length Mean     100
evaluation/path length Std        0
evaluation/path length Max      100
evaluation/path length Min      100
evaluation/Rewards Mean          -3.75533
evaluation/Rewards Std            1.18933
evaluation/Rewards Max           -0.250727
evaluation/Rewards Min          -10.2973
evaluation/Returns Mean        -375.533
evaluation/Returns Std          102.624
evaluation/Returns Max         -203.363
evaluation/Returns Min         -580.473
evaluation/Actions Mean           0.01193
evaluation/Actions Std            0.131447
evaluation/Actions Max            0.903637
evaluation/Actions Min           -0.836371
evaluation/Num Paths             15
evaluation/Average Returns     -375.533
time/data storing (s)             0.00284474
time/evaluation sampling (s)      0.32357
time/exploration sampling (s)     0.137692
time/logging (s)                  0.00473934
time/saving (s)                   0.00193551
time/training (s)                 1.95821
time/epoch (s)                    2.42899
time/total (s)                   10.0598
Epoch                             3
-----------------------------  -------------
2019-04-23 01:13:43.220242 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 4 finished
-----------------------------  -------------
replay_buffer/size             2700
trainer/QF1 Loss                 14.0144
trainer/QF2 Loss                 14.301
trainer/Policy Loss              36.151
trainer/Q1 Predictions Mean     -37.4018
trainer/Q1 Predictions Std       10.337
trainer/Q1 Predictions Max      -18.4955
trainer/Q1 Predictions Min      -74.0768
trainer/Q2 Predictions Mean     -37.4251
trainer/Q2 Predictions Std       10.3237
trainer/Q2 Predictions Max      -18.5871
trainer/Q2 Predictions Min      -74.4775
trainer/Q Targets Mean          -37.3552
trainer/Q Targets Std            10.8945
trainer/Q Targets Max            -6.75106
trainer/Q Targets Min           -77.506
trainer/Log Pis Mean             -0.312502
trainer/Log Pis Std               1.31372
trainer/Log Pis Max               3.28945
trainer/Log Pis Min              -3.10102
trainer/Policy mu Mean            0.112473
trainer/Policy mu Std             0.709637
trainer/Policy mu Max             1.658
trainer/Policy mu Min            -1.36807
trainer/Policy log std Mean      -0.452299
trainer/Policy log std Std        0.0830011
trainer/Policy log std Max       -0.281014
trainer/Policy log std Min       -0.676285
trainer/Alpha                     0.572066
trainer/Alpha Loss               -1.29092
exploration/num steps total    2700
exploration/num paths total      27
exploration/path length Mean    100
exploration/path length Std       0
exploration/path length Max     100
exploration/path length Min     100
exploration/Rewards Mean         -3.26974
exploration/Rewards Std           1.24521
exploration/Rewards Max          -0.475215
exploration/Rewards Min          -9.60608
exploration/Returns Mean       -326.974
exploration/Returns Std          88.2125
exploration/Returns Max        -216.543
exploration/Returns Min        -479.65
exploration/Actions Mean          0.0276464
exploration/Actions Std           0.531683
exploration/Actions Max           0.98678
exploration/Actions Min          -0.950657
exploration/Num Paths             5
exploration/Average Returns    -326.974
evaluation/num steps total     7500
evaluation/num paths total       75
evaluation/path length Mean     100
evaluation/path length Std        0
evaluation/path length Max      100
evaluation/path length Min      100
evaluation/Rewards Mean          -3.67403
evaluation/Rewards Std            1.80695
evaluation/Rewards Max           -1.09161
evaluation/Rewards Min          -11.2553
evaluation/Returns Mean        -367.403
evaluation/Returns Std          167.204
evaluation/Returns Max         -125.259
evaluation/Returns Min         -624.029
evaluation/Actions Mean           0.0105978
evaluation/Actions Std            0.150005
evaluation/Actions Max            0.951102
evaluation/Actions Min           -0.859653
evaluation/Num Paths             15
evaluation/Average Returns     -367.403
time/data storing (s)             0.00281504
time/evaluation sampling (s)      0.327803
time/exploration sampling (s)     0.136137
time/logging (s)                  0.00475106
time/saving (s)                   0.0109939
time/training (s)                 1.96527
time/epoch (s)                    2.44777
time/total (s)                   12.5119
Epoch                             4
-----------------------------  -------------
2019-04-23 01:13:45.656621 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 5 finished
-----------------------------  -------------
replay_buffer/size             3200
trainer/QF1 Loss                  1.95311
trainer/QF2 Loss                  2.26728
trainer/Policy Loss              41.1098
trainer/Q1 Predictions Mean     -42.8303
trainer/Q1 Predictions Std       12.9692
trainer/Q1 Predictions Max      -20.9185
trainer/Q1 Predictions Min      -87.9742
trainer/Q2 Predictions Mean     -42.7737
trainer/Q2 Predictions Std       13.0149
trainer/Q2 Predictions Max      -20.488
trainer/Q2 Predictions Min      -87.944
trainer/Q Targets Mean          -43.4229
trainer/Q Targets Std            12.7383
trainer/Q Targets Max           -20.4093
trainer/Q Targets Min           -85.5502
trainer/Log Pis Mean             -0.529344
trainer/Log Pis Std               1.32536
trainer/Log Pis Max               3.64517
trainer/Log Pis Min              -4.00106
trainer/Policy mu Mean            0.0975251
trainer/Policy mu Std             0.739833
trainer/Policy mu Max             1.76598
trainer/Policy mu Min            -1.99203
trainer/Policy log std Mean      -0.497144
trainer/Policy log std Std        0.0866661
trainer/Policy log std Max       -0.320969
trainer/Policy log std Min       -0.686348
trainer/Alpha                     0.499708
trainer/Alpha Loss               -1.754
exploration/num steps total    3200
exploration/num paths total      32
exploration/path length Mean    100
exploration/path length Std       0
exploration/path length Max     100
exploration/path length Min     100
exploration/Rewards Mean         -3.71675
exploration/Rewards Std           1.52617
exploration/Rewards Max          -0.94899
exploration/Rewards Min          -6.89947
exploration/Returns Mean       -371.675
exploration/Returns Std         140.297
exploration/Returns Max        -213.705
exploration/Returns Min        -541.162
exploration/Actions Mean         -0.0088711
exploration/Actions Std           0.500681
exploration/Actions Max           0.982126
exploration/Actions Min          -0.967764
exploration/Num Paths             5
exploration/Average Returns    -371.675
evaluation/num steps total     9000
evaluation/num paths total       90
evaluation/path length Mean     100
evaluation/path length Std        0
evaluation/path length Max      100
evaluation/path length Min      100
evaluation/Rewards Mean          -4.12357
evaluation/Rewards Std            1.70252
evaluation/Rewards Max           -0.928956
evaluation/Rewards Min           -9.28612
evaluation/Returns Mean        -412.357
evaluation/Returns Std          164.437
evaluation/Returns Max          -99.5355
evaluation/Returns Min         -618.107
evaluation/Actions Mean           0.00536021
evaluation/Actions Std            0.127368
evaluation/Actions Max            0.94739
evaluation/Actions Min           -0.899794
evaluation/Num Paths             15
evaluation/Average Returns     -412.357
time/data storing (s)             0.00285702
time/evaluation sampling (s)      0.326251
time/exploration sampling (s)     0.138205
time/logging (s)                  0.00473752
time/saving (s)                   0.00184675
time/training (s)                 1.95725
time/epoch (s)                    2.43114
time/total (s)                   14.9475
Epoch                             5
-----------------------------  -------------
2019-04-23 01:13:48.072838 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 6 finished
-----------------------------  --------------
replay_buffer/size              3700
trainer/QF1 Loss                  37.8006
trainer/QF2 Loss                  38.3862
trainer/Policy Loss               49.5665
trainer/Q1 Predictions Mean      -51.3704
trainer/Q1 Predictions Std        15.7142
trainer/Q1 Predictions Max       -17.3392
trainer/Q1 Predictions Min       -92.8359
trainer/Q2 Predictions Mean      -51.3699
trainer/Q2 Predictions Std        15.6896
trainer/Q2 Predictions Max       -16.8848
trainer/Q2 Predictions Min       -92.9056
trainer/Q Targets Mean           -51.0521
trainer/Q Targets Std             16.753
trainer/Q Targets Max             -1.54914
trainer/Q Targets Min            -92.0033
trainer/Log Pis Mean              -0.182833
trainer/Log Pis Std                1.39616
trainer/Log Pis Max                3.4704
trainer/Log Pis Min               -5.06939
trainer/Policy mu Mean             0.0416224
trainer/Policy mu Std              0.824636
trainer/Policy mu Max              1.88953
trainer/Policy mu Min             -1.85632
trainer/Policy log std Mean       -0.582311
trainer/Policy log std Std         0.104545
trainer/Policy log std Max        -0.367018
trainer/Policy log std Min        -0.838943
trainer/Alpha                      0.43635
trainer/Alpha Loss                -1.80967
exploration/num steps total     3700
exploration/num paths total       37
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -3.87846
exploration/Rewards Std            1.92453
exploration/Rewards Max           -0.0497068
exploration/Rewards Min          -10.1504
exploration/Returns Mean        -387.846
exploration/Returns Std          169.649
exploration/Returns Max         -120.783
exploration/Returns Min         -620.111
exploration/Actions Mean          -0.00330112
exploration/Actions Std            0.522483
exploration/Actions Max            0.987635
exploration/Actions Min           -0.975523
exploration/Num Paths              5
exploration/Average Returns     -387.846
evaluation/num steps total     10500
evaluation/num paths total       105
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -3.75109
evaluation/Rewards Std             1.71403
evaluation/Rewards Max            -0.100183
evaluation/Rewards Min            -9.54679
evaluation/Returns Mean         -375.109
evaluation/Returns Std           164.618
evaluation/Returns Max           -90.8201
evaluation/Returns Min          -598.968
evaluation/Actions Mean           -0.00292659
evaluation/Actions Std             0.130391
evaluation/Actions Max             0.948003
evaluation/Actions Min            -0.900467
evaluation/Num Paths              15
evaluation/Average Returns      -375.109
time/data storing (s)              0.00284589
time/evaluation sampling (s)       0.333223
time/exploration sampling (s)      0.140917
time/logging (s)                   0.00483806
time/saving (s)                    0.00192621
time/training (s)                  1.92834
time/epoch (s)                     2.41209
time/total (s)                    17.363
Epoch                              6
-----------------------------  --------------
2019-04-23 01:13:50.475162 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 7 finished
-----------------------------  --------------
replay_buffer/size              4200
trainer/QF1 Loss                  32.4776
trainer/QF2 Loss                  32.8257
trainer/Policy Loss               51.0152
trainer/Q1 Predictions Mean      -52.671
trainer/Q1 Predictions Std        16.8383
trainer/Q1 Predictions Max       -17.692
trainer/Q1 Predictions Min       -89.5105
trainer/Q2 Predictions Mean      -52.6855
trainer/Q2 Predictions Std        16.8376
trainer/Q2 Predictions Max       -17.5879
trainer/Q2 Predictions Min       -89.8452
trainer/Q Targets Mean           -52.6914
trainer/Q Targets Std             17.645
trainer/Q Targets Max             -4.41001
trainer/Q Targets Min            -92.873
trainer/Log Pis Mean              -0.23844
trainer/Log Pis Std                1.0638
trainer/Log Pis Max                2.46245
trainer/Log Pis Min               -2.52552
trainer/Policy mu Mean            -0.014991
trainer/Policy mu Std              0.810554
trainer/Policy mu Max              1.82774
trainer/Policy mu Min             -2.03934
trainer/Policy log std Mean       -0.63711
trainer/Policy log std Std         0.140097
trainer/Policy log std Max        -0.344472
trainer/Policy log std Min        -0.897256
trainer/Alpha                      0.380743
trainer/Alpha Loss                -2.16091
exploration/num steps total     4200
exploration/num paths total       42
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -3.89393
exploration/Rewards Std            1.82222
exploration/Rewards Max           -0.19335
exploration/Rewards Min           -8.45386
exploration/Returns Mean        -389.393
exploration/Returns Std          159.341
exploration/Returns Max         -158.03
exploration/Returns Min         -642.295
exploration/Actions Mean           0.00416098
exploration/Actions Std            0.498104
exploration/Actions Max            0.986309
exploration/Actions Min           -0.98242
exploration/Num Paths              5
exploration/Average Returns     -389.393
evaluation/num steps total     12000
evaluation/num paths total       120
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -3.38555
evaluation/Rewards Std             1.92272
evaluation/Rewards Max            -0.899125
evaluation/Rewards Min            -9.99094
evaluation/Returns Mean         -338.555
evaluation/Returns Std           169.965
evaluation/Returns Max          -154.137
evaluation/Returns Min          -638.996
evaluation/Actions Mean            0.014594
evaluation/Actions Std             0.185209
evaluation/Actions Max             0.970465
evaluation/Actions Min            -0.939635
evaluation/Num Paths              15
evaluation/Average Returns      -338.555
time/data storing (s)              0.00277721
time/evaluation sampling (s)       0.328483
time/exploration sampling (s)      0.136329
time/logging (s)                   0.00349603
time/saving (s)                    0.00193108
time/training (s)                  1.92282
time/epoch (s)                     2.39584
time/total (s)                    19.7632
Epoch                              7
-----------------------------  --------------
2019-04-23 01:13:52.911917 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 8 finished
-----------------------------  --------------
replay_buffer/size              4700
trainer/QF1 Loss                  16.2779
trainer/QF2 Loss                  16.1999
trainer/Policy Loss               56.843
trainer/Q1 Predictions Mean      -58.1203
trainer/Q1 Predictions Std        17.3085
trainer/Q1 Predictions Max       -18.4673
trainer/Q1 Predictions Min      -100.053
trainer/Q2 Predictions Mean      -58.0572
trainer/Q2 Predictions Std        17.2968
trainer/Q2 Predictions Max       -18.697
trainer/Q2 Predictions Min       -99.796
trainer/Q Targets Mean           -58.3211
trainer/Q Targets Std             18.2837
trainer/Q Targets Max             -5.13837
trainer/Q Targets Min           -100.266
trainer/Log Pis Mean              -0.0470492
trainer/Log Pis Std                1.48101
trainer/Log Pis Max                3.64462
trainer/Log Pis Min               -7.24515
trainer/Policy mu Mean             0.0501428
trainer/Policy mu Std              0.785416
trainer/Policy mu Max              2.13898
trainer/Policy mu Min             -1.87129
trainer/Policy log std Mean       -0.744706
trainer/Policy log std Std         0.144767
trainer/Policy log std Max        -0.432456
trainer/Policy log std Min        -1.06068
trainer/Alpha                      0.332165
trainer/Alpha Loss                -2.25555
exploration/num steps total     4700
exploration/num paths total       47
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -3.29001
exploration/Rewards Std            1.67064
exploration/Rewards Max           -0.123529
exploration/Rewards Min           -8.92569
exploration/Returns Mean        -329.001
exploration/Returns Std          146.609
exploration/Returns Max          -94.4098
exploration/Returns Min         -504.484
exploration/Actions Mean           0.0193838
exploration/Actions Std            0.466796
exploration/Actions Max            0.983069
exploration/Actions Min           -0.958855
exploration/Num Paths              5
exploration/Average Returns     -329.001
evaluation/num steps total     13500
evaluation/num paths total       135
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -3.6581
evaluation/Rewards Std             1.91915
evaluation/Rewards Max            -0.150891
evaluation/Rewards Min           -11.3089
evaluation/Returns Mean         -365.81
evaluation/Returns Std           183.471
evaluation/Returns Max           -57.325
evaluation/Returns Min          -623.927
evaluation/Actions Mean            0.00715128
evaluation/Actions Std             0.146209
evaluation/Actions Max             0.985538
evaluation/Actions Min            -0.932153
evaluation/Num Paths              15
evaluation/Average Returns      -365.81
time/data storing (s)              0.0028452
time/evaluation sampling (s)       0.330623
time/exploration sampling (s)      0.139178
time/logging (s)                   0.00479184
time/saving (s)                    0.00197269
time/training (s)                  1.95364
time/epoch (s)                     2.43305
time/total (s)                    22.2004
Epoch                              8
-----------------------------  --------------
2019-04-23 01:13:55.352583 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 9 finished
-----------------------------  --------------
replay_buffer/size              5200
trainer/QF1 Loss                  70.2913
trainer/QF2 Loss                  70.0726
trainer/Policy Loss               64.2446
trainer/Q1 Predictions Mean      -65.4914
trainer/Q1 Predictions Std        16.3487
trainer/Q1 Predictions Max       -20.665
trainer/Q1 Predictions Min       -98.8118
trainer/Q2 Predictions Mean      -65.5096
trainer/Q2 Predictions Std        16.3118
trainer/Q2 Predictions Max       -20.7044
trainer/Q2 Predictions Min       -98.549
trainer/Q Targets Mean           -64.5046
trainer/Q Targets Std             18.4405
trainer/Q Targets Max             -1.54914
trainer/Q Targets Min            -96.2629
trainer/Log Pis Mean               0.0613176
trainer/Log Pis Std                1.35226
trainer/Log Pis Max                4.936
trainer/Log Pis Min               -2.41197
trainer/Policy mu Mean            -0.0941585
trainer/Policy mu Std              0.804273
trainer/Policy mu Max              2.10399
trainer/Policy mu Min             -2.26542
trainer/Policy log std Mean       -0.750583
trainer/Policy log std Std         0.151431
trainer/Policy log std Max        -0.371547
trainer/Policy log std Min        -1.12924
trainer/Alpha                      0.290024
trainer/Alpha Loss                -2.39916
exploration/num steps total     5200
exploration/num paths total       52
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.39902
exploration/Rewards Std            1.12934
exploration/Rewards Max           -0.0915613
exploration/Rewards Min          -10.499
exploration/Returns Mean        -239.902
exploration/Returns Std           65.8834
exploration/Returns Max         -108.22
exploration/Returns Min         -276.272
exploration/Actions Mean           0.00670226
exploration/Actions Std            0.428214
exploration/Actions Max            0.983046
exploration/Actions Min           -0.9446
exploration/Num Paths              5
exploration/Average Returns     -239.902
evaluation/num steps total     15000
evaluation/num paths total       150
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -3.51693
evaluation/Rewards Std             1.66544
evaluation/Rewards Max            -0.0538158
evaluation/Rewards Min           -10.7437
evaluation/Returns Mean         -351.693
evaluation/Returns Std           152.856
evaluation/Returns Max           -80.762
evaluation/Returns Min          -601.95
evaluation/Actions Mean            0.021031
evaluation/Actions Std             0.147104
evaluation/Actions Max             0.987102
evaluation/Actions Min            -0.910902
evaluation/Num Paths              15
evaluation/Average Returns      -351.693
time/data storing (s)              0.00305946
time/evaluation sampling (s)       0.333472
time/exploration sampling (s)      0.140163
time/logging (s)                   0.00475963
time/saving (s)                    0.00202104
time/training (s)                  1.95201
time/epoch (s)                     2.43548
time/total (s)                    24.6402
Epoch                              9
-----------------------------  --------------
2019-04-23 01:13:57.780245 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 10 finished
-----------------------------  --------------
replay_buffer/size              5700
trainer/QF1 Loss                   1.72629
trainer/QF2 Loss                   1.58668
trainer/Policy Loss               66.2446
trainer/Q1 Predictions Mean      -67.2454
trainer/Q1 Predictions Std        19.4884
trainer/Q1 Predictions Max       -18.876
trainer/Q1 Predictions Min      -103.117
trainer/Q2 Predictions Mean      -67.2579
trainer/Q2 Predictions Std        19.5016
trainer/Q2 Predictions Max       -18.8927
trainer/Q2 Predictions Min      -102.424
trainer/Q Targets Mean           -67.9321
trainer/Q Targets Std             19.669
trainer/Q Targets Max            -19.6438
trainer/Q Targets Min           -104.602
trainer/Log Pis Mean              -0.00128029
trainer/Log Pis Std                1.50449
trainer/Log Pis Max                4.20645
trainer/Log Pis Min               -6.07241
trainer/Policy mu Mean             0.0659082
trainer/Policy mu Std              0.725494
trainer/Policy mu Max              2.22891
trainer/Policy mu Min             -2.23974
trainer/Policy log std Mean       -0.863423
trainer/Policy log std Std         0.187775
trainer/Policy log std Max        -0.479052
trainer/Policy log std Min        -1.31964
trainer/Alpha                      0.253261
trainer/Alpha Loss                -2.74789
exploration/num steps total     5700
exploration/num paths total       57
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.89416
exploration/Rewards Std            1.01722
exploration/Rewards Max           -1.25456
exploration/Rewards Min           -5.88764
exploration/Returns Mean        -289.416
exploration/Returns Std           93.6012
exploration/Returns Max         -227.783
exploration/Returns Min         -473.407
exploration/Actions Mean           0.00375531
exploration/Actions Std            0.403117
exploration/Actions Max            0.952579
exploration/Actions Min           -0.881927
exploration/Num Paths              5
exploration/Average Returns     -289.416
evaluation/num steps total     16500
evaluation/num paths total       165
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -3.59661
evaluation/Rewards Std             1.7853
evaluation/Rewards Max            -1.10489
evaluation/Rewards Min            -8.8324
evaluation/Returns Mean         -359.661
evaluation/Returns Std           172.283
evaluation/Returns Max          -114.687
evaluation/Returns Min          -611.757
evaluation/Actions Mean            0.00507302
evaluation/Actions Std             0.129143
evaluation/Actions Max             0.989979
evaluation/Actions Min            -0.94804
evaluation/Num Paths              15
evaluation/Average Returns      -359.661
time/data storing (s)              0.00285399
time/evaluation sampling (s)       0.327087
time/exploration sampling (s)      0.139436
time/logging (s)                   0.00473512
time/saving (s)                    0.00166306
time/training (s)                  1.9467
time/epoch (s)                     2.42247
time/total (s)                    27.067
Epoch                             10
-----------------------------  --------------
2019-04-23 01:14:00.185288 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 11 finished
-----------------------------  --------------
replay_buffer/size              6200
trainer/QF1 Loss                   2.34765
trainer/QF2 Loss                   1.7139
trainer/Policy Loss               69.654
trainer/Q1 Predictions Mean      -70.2702
trainer/Q1 Predictions Std        20.9949
trainer/Q1 Predictions Max       -19.106
trainer/Q1 Predictions Min      -119.617
trainer/Q2 Predictions Mean      -70.3275
trainer/Q2 Predictions Std        20.9915
trainer/Q2 Predictions Max       -19.1744
trainer/Q2 Predictions Min      -120.101
trainer/Q Targets Mean           -71.0421
trainer/Q Targets Std             21.1746
trainer/Q Targets Max            -19.8287
trainer/Q Targets Min           -122.027
trainer/Log Pis Mean               0.296323
trainer/Log Pis Std                1.32912
trainer/Log Pis Max                4.24278
trainer/Log Pis Min               -3.68083
trainer/Policy mu Mean             0.0927969
trainer/Policy mu Std              0.754429
trainer/Policy mu Max              2.34631
trainer/Policy mu Min             -2.16677
trainer/Policy log std Mean       -0.988503
trainer/Policy log std Std         0.191003
trainer/Policy log std Max        -0.504711
trainer/Policy log std Min        -1.40689
trainer/Alpha                      0.222051
trainer/Alpha Loss                -2.56333
exploration/num steps total     6200
exploration/num paths total       62
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -3.77772
exploration/Rewards Std            1.9471
exploration/Rewards Max           -0.32576
exploration/Rewards Min           -8.7675
exploration/Returns Mean        -377.772
exploration/Returns Std          178.697
exploration/Returns Max         -132.275
exploration/Returns Min         -629.924
exploration/Actions Mean           0.0173705
exploration/Actions Std            0.415654
exploration/Actions Max            0.994977
exploration/Actions Min           -0.948046
exploration/Num Paths              5
exploration/Average Returns     -377.772
evaluation/num steps total     18000
evaluation/num paths total       180
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -3.3017
evaluation/Rewards Std             1.75724
evaluation/Rewards Max            -0.221739
evaluation/Rewards Min           -11.3473
evaluation/Returns Mean         -330.17
evaluation/Returns Std           165.572
evaluation/Returns Max           -44.7029
evaluation/Returns Min          -623.288
evaluation/Actions Mean           -0.00499965
evaluation/Actions Std             0.160165
evaluation/Actions Max             0.966937
evaluation/Actions Min            -0.968245
evaluation/Num Paths              15
evaluation/Average Returns      -330.17
time/data storing (s)              0.00279727
time/evaluation sampling (s)       0.332715
time/exploration sampling (s)      0.137138
time/logging (s)                   0.00473694
time/saving (s)                    0.00192159
time/training (s)                  1.92058
time/epoch (s)                     2.39989
time/total (s)                    29.4712
Epoch                             11
-----------------------------  --------------
2019-04-23 01:14:02.592822 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 12 finished
-----------------------------  --------------
replay_buffer/size              6700
trainer/QF1 Loss                  13.215
trainer/QF2 Loss                  13.2717
trainer/Policy Loss               71.187
trainer/Q1 Predictions Mean      -71.9194
trainer/Q1 Predictions Std        25.8831
trainer/Q1 Predictions Max       -19.9979
trainer/Q1 Predictions Min      -128.418
trainer/Q2 Predictions Mean      -71.9435
trainer/Q2 Predictions Std        25.8855
trainer/Q2 Predictions Max       -19.705
trainer/Q2 Predictions Min      -128.702
trainer/Q Targets Mean           -72.1225
trainer/Q Targets Std             26.8302
trainer/Q Targets Max             -0.236605
trainer/Q Targets Min           -127.265
trainer/Log Pis Mean               0.458615
trainer/Log Pis Std                1.48961
trainer/Log Pis Max                4.98093
trainer/Log Pis Min               -2.90066
trainer/Policy mu Mean             0.115003
trainer/Policy mu Std              0.881723
trainer/Policy mu Max              2.76476
trainer/Policy mu Min             -2.37646
trainer/Policy log std Mean       -1.02654
trainer/Policy log std Std         0.267995
trainer/Policy log std Max        -0.348978
trainer/Policy log std Min        -1.48005
trainer/Alpha                      0.195196
trainer/Alpha Loss                -2.51784
exploration/num steps total     6700
exploration/num paths total       67
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -3.13591
exploration/Rewards Std            1.51583
exploration/Rewards Max           -0.558239
exploration/Rewards Min           -7.93283
exploration/Returns Mean        -313.591
exploration/Returns Std          139.035
exploration/Returns Max         -168.597
exploration/Returns Min         -492.114
exploration/Actions Mean          -0.00510695
exploration/Actions Std            0.382731
exploration/Actions Max            0.97068
exploration/Actions Min           -0.983133
exploration/Num Paths              5
exploration/Average Returns     -313.591
evaluation/num steps total     19500
evaluation/num paths total       195
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -3.94732
evaluation/Rewards Std             1.38568
evaluation/Rewards Max            -0.690812
evaluation/Rewards Min           -11.6002
evaluation/Returns Mean         -394.732
evaluation/Returns Std           131.113
evaluation/Returns Max          -195.598
evaluation/Returns Min          -612.775
evaluation/Actions Mean           -0.00610411
evaluation/Actions Std             0.150877
evaluation/Actions Max             0.952734
evaluation/Actions Min            -0.97567
evaluation/Num Paths              15
evaluation/Average Returns      -394.732
time/data storing (s)              0.00287804
time/evaluation sampling (s)       0.331878
time/exploration sampling (s)      0.139975
time/logging (s)                   0.00481978
time/saving (s)                    0.00192724
time/training (s)                  1.92104
time/epoch (s)                     2.40252
time/total (s)                    31.878
Epoch                             12
-----------------------------  --------------
2019-04-23 01:14:05.000457 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 13 finished
-----------------------------  --------------
replay_buffer/size              7200
trainer/QF1 Loss                   2.311
trainer/QF2 Loss                   2.31817
trainer/Policy Loss               77.2094
trainer/Q1 Predictions Mean      -77.8873
trainer/Q1 Predictions Std        25.8437
trainer/Q1 Predictions Max       -19.9117
trainer/Q1 Predictions Min      -139.448
trainer/Q2 Predictions Mean      -77.891
trainer/Q2 Predictions Std        25.8427
trainer/Q2 Predictions Max       -19.8928
trainer/Q2 Predictions Min      -139.734
trainer/Q Targets Mean           -78.8591
trainer/Q Targets Std             25.9753
trainer/Q Targets Max            -21.2798
trainer/Q Targets Min           -134.877
trainer/Log Pis Mean               0.503892
trainer/Log Pis Std                1.8738
trainer/Log Pis Max                5.62853
trainer/Log Pis Min               -4.91112
trainer/Policy mu Mean             0.122009
trainer/Policy mu Std              0.823428
trainer/Policy mu Max              2.43522
trainer/Policy mu Min             -2.1695
trainer/Policy log std Mean       -1.07554
trainer/Policy log std Std         0.275793
trainer/Policy log std Max        -0.395564
trainer/Policy log std Min        -1.60016
trainer/Alpha                      0.171532
trainer/Alpha Loss                -2.63723
exploration/num steps total     7200
exploration/num paths total       72
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -3.84597
exploration/Rewards Std            1.46067
exploration/Rewards Max           -1.58638
exploration/Rewards Min           -8.09721
exploration/Returns Mean        -384.597
exploration/Returns Std          139.645
exploration/Returns Max         -231.71
exploration/Returns Min         -587.335
exploration/Actions Mean           0.00340988
exploration/Actions Std            0.347286
exploration/Actions Max            0.985282
exploration/Actions Min           -0.943968
exploration/Num Paths              5
exploration/Average Returns     -384.597
evaluation/num steps total     21000
evaluation/num paths total       210
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -3.57316
evaluation/Rewards Std             1.72979
evaluation/Rewards Max            -0.6583
evaluation/Rewards Min           -10.1785
evaluation/Returns Mean         -357.316
evaluation/Returns Std           167.887
evaluation/Returns Max           -74.2037
evaluation/Returns Min          -663.81
evaluation/Actions Mean            0.00954138
evaluation/Actions Std             0.140733
evaluation/Actions Max             0.983434
evaluation/Actions Min            -0.940279
evaluation/Num Paths              15
evaluation/Average Returns      -357.316
time/data storing (s)              0.00309267
time/evaluation sampling (s)       0.326752
time/exploration sampling (s)      0.139748
time/logging (s)                   0.0047572
time/saving (s)                    0.00195515
time/training (s)                  1.92685
time/epoch (s)                     2.40315
time/total (s)                    34.2847
Epoch                             13
-----------------------------  --------------
2019-04-23 01:14:07.417881 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 14 finished
-----------------------------  ---------------
replay_buffer/size              7700
trainer/QF1 Loss                  47.874
trainer/QF2 Loss                  47.3592
trainer/Policy Loss               82.6111
trainer/Q1 Predictions Mean      -82.8813
trainer/Q1 Predictions Std        25.7881
trainer/Q1 Predictions Max       -21.7113
trainer/Q1 Predictions Min      -127.38
trainer/Q2 Predictions Mean      -82.9034
trainer/Q2 Predictions Std        25.8225
trainer/Q2 Predictions Max       -21.597
trainer/Q2 Predictions Min      -127.67
trainer/Q Targets Mean           -83.397
trainer/Q Targets Std             28.207
trainer/Q Targets Max             -1.36194
trainer/Q Targets Min           -131.203
trainer/Log Pis Mean               0.578686
trainer/Log Pis Std                1.37791
trainer/Log Pis Max                5.43315
trainer/Log Pis Min               -3.67201
trainer/Policy mu Mean             0.028286
trainer/Policy mu Std              0.784073
trainer/Policy mu Max              3.0577
trainer/Policy mu Min             -2.71031
trainer/Policy log std Mean       -1.20135
trainer/Policy log std Std         0.288913
trainer/Policy log std Max        -0.445603
trainer/Policy log std Min        -1.70939
trainer/Alpha                      0.151161
trainer/Alpha Loss                -2.68509
exploration/num steps total     7700
exploration/num paths total       77
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -4.54969
exploration/Rewards Std            2.10977
exploration/Rewards Max           -1.0849
exploration/Rewards Min           -8.39799
exploration/Returns Mean        -454.969
exploration/Returns Std          208.579
exploration/Returns Max         -209.687
exploration/Returns Min         -678.252
exploration/Actions Mean           0.000130222
exploration/Actions Std            0.344323
exploration/Actions Max            0.917513
exploration/Actions Min           -0.933577
exploration/Num Paths              5
exploration/Average Returns     -454.969
evaluation/num steps total     22500
evaluation/num paths total       225
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.99154
evaluation/Rewards Std             1.60842
evaluation/Rewards Max            -0.937075
evaluation/Rewards Min           -10.3497
evaluation/Returns Mean         -299.154
evaluation/Returns Std           145.399
evaluation/Returns Max          -124.681
evaluation/Returns Min          -673.11
evaluation/Actions Mean            0.0123553
evaluation/Actions Std             0.166507
evaluation/Actions Max             0.989741
evaluation/Actions Min            -0.992601
evaluation/Num Paths              15
evaluation/Average Returns      -299.154
time/data storing (s)              0.0028262
time/evaluation sampling (s)       0.332141
time/exploration sampling (s)      0.132315
time/logging (s)                   0.00423672
time/saving (s)                    0.00193701
time/training (s)                  1.9382
time/epoch (s)                     2.41166
time/total (s)                    36.7006
Epoch                             14
-----------------------------  ---------------
2019-04-23 01:14:09.836220 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 15 finished
-----------------------------  --------------
replay_buffer/size              8200
trainer/QF1 Loss                   0.847275
trainer/QF2 Loss                   0.867972
trainer/Policy Loss               84.6289
trainer/Q1 Predictions Mean      -84.8852
trainer/Q1 Predictions Std        31.521
trainer/Q1 Predictions Max       -21.8959
trainer/Q1 Predictions Min      -138.181
trainer/Q2 Predictions Mean      -84.8519
trainer/Q2 Predictions Std        31.5077
trainer/Q2 Predictions Max       -21.7401
trainer/Q2 Predictions Min      -137.891
trainer/Q Targets Mean           -84.8569
trainer/Q Targets Std             31.8296
trainer/Q Targets Max            -21.973
trainer/Q Targets Min           -139.978
trainer/Log Pis Mean               0.543353
trainer/Log Pis Std                1.37882
trainer/Log Pis Max                3.98419
trainer/Log Pis Min               -3.46581
trainer/Policy mu Mean            -0.0624984
trainer/Policy mu Std              0.785428
trainer/Policy mu Max              2.48287
trainer/Policy mu Min             -2.29476
trainer/Policy log std Mean       -1.25686
trainer/Policy log std Std         0.309151
trainer/Policy log std Max        -0.36078
trainer/Policy log std Min        -1.8448
trainer/Alpha                      0.133415
trainer/Alpha Loss                -2.93373
exploration/num steps total     8200
exploration/num paths total       82
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -3.4156
exploration/Rewards Std            1.20175
exploration/Rewards Max           -1.05995
exploration/Rewards Min           -8.09553
exploration/Returns Mean        -341.56
exploration/Returns Std          104.561
exploration/Returns Max         -198.301
exploration/Returns Min         -466.672
exploration/Actions Mean           0.0103459
exploration/Actions Std            0.319453
exploration/Actions Max            0.964099
exploration/Actions Min           -0.986163
exploration/Num Paths              5
exploration/Average Returns     -341.56
evaluation/num steps total     24000
evaluation/num paths total       240
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.84237
evaluation/Rewards Std             1.95084
evaluation/Rewards Max            -0.0517987
evaluation/Rewards Min           -11.0011
evaluation/Returns Mean         -284.237
evaluation/Returns Std           180.128
evaluation/Returns Max           -50.4356
evaluation/Returns Min          -666.507
evaluation/Actions Mean            0.0137431
evaluation/Actions Std             0.166967
evaluation/Actions Max             0.987172
evaluation/Actions Min            -0.990501
evaluation/Num Paths              15
evaluation/Average Returns      -284.237
time/data storing (s)              0.00282297
time/evaluation sampling (s)       0.328457
time/exploration sampling (s)      0.139502
time/logging (s)                   0.00474833
time/saving (s)                    0.00196931
time/training (s)                  1.9362
time/epoch (s)                     2.4137
time/total (s)                    39.1186
Epoch                             15
-----------------------------  --------------
2019-04-23 01:14:12.252927 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 16 finished
-----------------------------  --------------
replay_buffer/size              8700
trainer/QF1 Loss                  55.3754
trainer/QF2 Loss                  55.3321
trainer/Policy Loss               90.3368
trainer/Q1 Predictions Mean      -90.5783
trainer/Q1 Predictions Std        30.0885
trainer/Q1 Predictions Max       -22.3243
trainer/Q1 Predictions Min      -141.073
trainer/Q2 Predictions Mean      -90.5958
trainer/Q2 Predictions Std        30.1067
trainer/Q2 Predictions Max       -22.361
trainer/Q2 Predictions Min      -141.1
trainer/Q Targets Mean           -90.2314
trainer/Q Targets Std             31.6488
trainer/Q Targets Max             -4.1726
trainer/Q Targets Min           -142.877
trainer/Log Pis Mean               0.794591
trainer/Log Pis Std                1.3945
trainer/Log Pis Max                4.37268
trainer/Log Pis Min               -4.64881
trainer/Policy mu Mean             0.0341905
trainer/Policy mu Std              0.810059
trainer/Policy mu Max              2.30781
trainer/Policy mu Min             -2.73384
trainer/Policy log std Mean       -1.31844
trainer/Policy log std Std         0.335979
trainer/Policy log std Max        -0.390643
trainer/Policy log std Min        -1.92814
trainer/Alpha                      0.118279
trainer/Alpha Loss                -2.57291
exploration/num steps total     8700
exploration/num paths total       87
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.51516
exploration/Rewards Std            0.852891
exploration/Rewards Max           -0.179097
exploration/Rewards Min           -6.694
exploration/Returns Mean        -251.516
exploration/Returns Std           68.075
exploration/Returns Max         -132.605
exploration/Returns Min         -344.45
exploration/Actions Mean           0.0101097
exploration/Actions Std            0.306645
exploration/Actions Max            0.976324
exploration/Actions Min           -0.895436
exploration/Num Paths              5
exploration/Average Returns     -251.516
evaluation/num steps total     25500
evaluation/num paths total       255
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -3.47579
evaluation/Rewards Std             1.75682
evaluation/Rewards Max            -0.937642
evaluation/Rewards Min            -9.9791
evaluation/Returns Mean         -347.579
evaluation/Returns Std           166.06
evaluation/Returns Max           -94.7572
evaluation/Returns Min          -681.897
evaluation/Actions Mean            0.00802869
evaluation/Actions Std             0.168712
evaluation/Actions Max             0.995586
evaluation/Actions Min            -0.978889
evaluation/Num Paths              15
evaluation/Average Returns      -347.579
time/data storing (s)              0.00277283
time/evaluation sampling (s)       0.335874
time/exploration sampling (s)      0.132938
time/logging (s)                   0.00477931
time/saving (s)                    0.0101458
time/training (s)                  1.92497
time/epoch (s)                     2.41148
time/total (s)                    41.5343
Epoch                             16
-----------------------------  --------------
2019-04-23 01:14:14.655513 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 17 finished
-----------------------------  --------------
replay_buffer/size              9200
trainer/QF1 Loss                   2.80494
trainer/QF2 Loss                   2.58019
trainer/Policy Loss               91.2451
trainer/Q1 Predictions Mean      -91.3313
trainer/Q1 Predictions Std        33.5278
trainer/Q1 Predictions Max       -22.793
trainer/Q1 Predictions Min      -145.398
trainer/Q2 Predictions Mean      -91.396
trainer/Q2 Predictions Std        33.5607
trainer/Q2 Predictions Max       -22.7638
trainer/Q2 Predictions Min      -144.573
trainer/Q Targets Mean           -92.463
trainer/Q Targets Std             34.2398
trainer/Q Targets Max            -22.804
trainer/Q Targets Min           -147.312
trainer/Log Pis Mean               1.01906
trainer/Log Pis Std                1.56092
trainer/Log Pis Max                7.26586
trainer/Log Pis Min               -3.27274
trainer/Policy mu Mean            -0.00659209
trainer/Policy mu Std              0.862749
trainer/Policy mu Max              2.68321
trainer/Policy mu Min             -2.62607
trainer/Policy log std Mean       -1.38869
trainer/Policy log std Std         0.327565
trainer/Policy log std Max        -0.500643
trainer/Policy log std Min        -1.97475
trainer/Alpha                      0.105233
trainer/Alpha Loss                -2.20843
exploration/num steps total     9200
exploration/num paths total       92
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -3.86175
exploration/Rewards Std            1.7516
exploration/Rewards Max           -0.659092
exploration/Rewards Min           -8.40025
exploration/Returns Mean        -386.175
exploration/Returns Std          165.952
exploration/Returns Max         -135.124
exploration/Returns Min         -553.197
exploration/Actions Mean           0.0119232
exploration/Actions Std            0.278904
exploration/Actions Max            0.999021
exploration/Actions Min           -0.929839
exploration/Num Paths              5
exploration/Average Returns     -386.175
evaluation/num steps total     27000
evaluation/num paths total       270
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -3.67334
evaluation/Rewards Std             2.1548
evaluation/Rewards Max            -0.192338
evaluation/Rewards Min            -9.88398
evaluation/Returns Mean         -367.334
evaluation/Returns Std           203.527
evaluation/Returns Max          -129.915
evaluation/Returns Min          -685.892
evaluation/Actions Mean            0.00550008
evaluation/Actions Std             0.18772
evaluation/Actions Max             0.997987
evaluation/Actions Min            -0.995899
evaluation/Num Paths              15
evaluation/Average Returns      -367.334
time/data storing (s)              0.00291982
time/evaluation sampling (s)       0.331504
time/exploration sampling (s)      0.13446
time/logging (s)                   0.00472977
time/saving (s)                    0.00194506
time/training (s)                  1.9216
time/epoch (s)                     2.39716
time/total (s)                    43.9359
Epoch                             17
-----------------------------  --------------
2019-04-23 01:14:17.093884 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 18 finished
-----------------------------  --------------
replay_buffer/size              9700
trainer/QF1 Loss                   2.4696
trainer/QF2 Loss                   2.60619
trainer/Policy Loss               93.4133
trainer/Q1 Predictions Mean      -93.3245
trainer/Q1 Predictions Std        32.6832
trainer/Q1 Predictions Max       -23.9258
trainer/Q1 Predictions Min      -148.908
trainer/Q2 Predictions Mean      -93.3096
trainer/Q2 Predictions Std        32.7077
trainer/Q2 Predictions Max       -23.7125
trainer/Q2 Predictions Min      -148.829
trainer/Q Targets Mean           -94.4005
trainer/Q Targets Std             32.9179
trainer/Q Targets Max            -24.1768
trainer/Q Targets Min           -150.914
trainer/Log Pis Mean               0.804612
trainer/Log Pis Std                1.33067
trainer/Log Pis Max                4.38326
trainer/Log Pis Min               -4.78153
trainer/Policy mu Mean             0.0339006
trainer/Policy mu Std              0.730804
trainer/Policy mu Max              1.87382
trainer/Policy mu Min             -2.56351
trainer/Policy log std Mean       -1.33771
trainer/Policy log std Std         0.33494
trainer/Policy log std Max        -0.345581
trainer/Policy log std Min        -1.95137
trainer/Alpha                      0.0936118
trainer/Alpha Loss                -2.83107
exploration/num steps total     9700
exploration/num paths total       97
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -3.28257
exploration/Rewards Std            1.72748
exploration/Rewards Max           -1.24167
exploration/Rewards Min           -9.4134
exploration/Returns Mean        -328.257
exploration/Returns Std          151.188
exploration/Returns Max         -211.702
exploration/Returns Min         -622.404
exploration/Actions Mean           0.00110992
exploration/Actions Std            0.345071
exploration/Actions Max            0.998521
exploration/Actions Min           -0.996303
exploration/Num Paths              5
exploration/Average Returns     -328.257
evaluation/num steps total     28500
evaluation/num paths total       285
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.78465
evaluation/Rewards Std             1.81798
evaluation/Rewards Max            -0.211357
evaluation/Rewards Min            -9.84295
evaluation/Returns Mean         -278.465
evaluation/Returns Std           167.434
evaluation/Returns Max           -34.0727
evaluation/Returns Min          -641.438
evaluation/Actions Mean            0.00845561
evaluation/Actions Std             0.159235
evaluation/Actions Max             0.993993
evaluation/Actions Min            -0.988733
evaluation/Num Paths              15
evaluation/Average Returns      -278.465
time/data storing (s)              0.00323155
time/evaluation sampling (s)       0.326303
time/exploration sampling (s)      0.15259
time/logging (s)                   0.00470336
time/saving (s)                    0.00191655
time/training (s)                  1.94439
time/epoch (s)                     2.43313
time/total (s)                    46.3733
Epoch                             18
-----------------------------  --------------
2019-04-23 01:14:19.526129 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 19 finished
-----------------------------  --------------
replay_buffer/size             10200
trainer/QF1 Loss                 217.44
trainer/QF2 Loss                 216.628
trainer/Policy Loss               99.6988
trainer/Q1 Predictions Mean      -99.5754
trainer/Q1 Predictions Std        34.6402
trainer/Q1 Predictions Max       -24.1323
trainer/Q1 Predictions Min      -155.354
trainer/Q2 Predictions Mean      -99.6713
trainer/Q2 Predictions Std        34.5962
trainer/Q2 Predictions Max       -24.0363
trainer/Q2 Predictions Min      -156.125
trainer/Q Targets Mean           -98.7211
trainer/Q Targets Std             35.8391
trainer/Q Targets Max             -4.76906
trainer/Q Targets Min           -156.808
trainer/Log Pis Mean               1.18197
trainer/Log Pis Std                1.3444
trainer/Log Pis Max                4.68545
trainer/Log Pis Min               -2.70898
trainer/Policy mu Mean            -0.0301983
trainer/Policy mu Std              0.898335
trainer/Policy mu Max              2.89577
trainer/Policy mu Min             -2.80683
trainer/Policy log std Mean       -1.42047
trainer/Policy log std Std         0.377591
trainer/Policy log std Max        -0.339734
trainer/Policy log std Min        -2.18433
trainer/Alpha                      0.0831781
trainer/Alpha Loss                -2.03407
exploration/num steps total    10200
exploration/num paths total      102
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.54172
exploration/Rewards Std            2.19391
exploration/Rewards Max           -0.0167025
exploration/Rewards Min           -9.07204
exploration/Returns Mean        -254.172
exploration/Returns Std          203.254
exploration/Returns Max          -65.7695
exploration/Returns Min         -648.792
exploration/Actions Mean           0.0442107
exploration/Actions Std            0.288832
exploration/Actions Max            0.994909
exploration/Actions Min           -0.991902
exploration/Num Paths              5
exploration/Average Returns     -254.172
evaluation/num steps total     30000
evaluation/num paths total       300
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.26773
evaluation/Rewards Std             1.44884
evaluation/Rewards Max            -0.155135
evaluation/Rewards Min            -8.97562
evaluation/Returns Mean         -226.773
evaluation/Returns Std           130.217
evaluation/Returns Max           -27.3199
evaluation/Returns Min          -469.624
evaluation/Actions Mean            0.00380358
evaluation/Actions Std             0.166075
evaluation/Actions Max             0.993364
evaluation/Actions Min            -0.996622
evaluation/Num Paths              15
evaluation/Average Returns      -226.773
time/data storing (s)              0.00301958
time/evaluation sampling (s)       0.325134
time/exploration sampling (s)      0.141477
time/logging (s)                   0.00473416
time/saving (s)                    0.00192611
time/training (s)                  1.95148
time/epoch (s)                     2.42777
time/total (s)                    48.8046
Epoch                             19
-----------------------------  --------------
2019-04-23 01:14:21.948752 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 20 finished
-----------------------------  --------------
replay_buffer/size             10700
trainer/QF1 Loss                  57.9659
trainer/QF2 Loss                  57.7333
trainer/Policy Loss               99.0705
trainer/Q1 Predictions Mean      -98.9603
trainer/Q1 Predictions Std        37.51
trainer/Q1 Predictions Max       -24.0299
trainer/Q1 Predictions Min      -156.825
trainer/Q2 Predictions Mean      -98.9657
trainer/Q2 Predictions Std        37.5379
trainer/Q2 Predictions Max       -24.1778
trainer/Q2 Predictions Min      -157.417
trainer/Q Targets Mean           -99.369
trainer/Q Targets Std             39.7987
trainer/Q Targets Max             -1.9604
trainer/Q Targets Min           -159.258
trainer/Log Pis Mean               1.18095
trainer/Log Pis Std                1.51953
trainer/Log Pis Max                7.05366
trainer/Log Pis Min               -2.60892
trainer/Policy mu Mean            -0.0121315
trainer/Policy mu Std              0.759938
trainer/Policy mu Max              2.78752
trainer/Policy mu Min             -2.35336
trainer/Policy log std Mean       -1.56374
trainer/Policy log std Std         0.355192
trainer/Policy log std Max        -0.439714
trainer/Policy log std Min        -2.37068
trainer/Alpha                      0.0749801
trainer/Alpha Loss                -2.12158
exploration/num steps total    10700
exploration/num paths total      107
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.39451
exploration/Rewards Std            1.04981
exploration/Rewards Max           -0.56317
exploration/Rewards Min          -10.2924
exploration/Returns Mean        -239.451
exploration/Returns Std           53.0854
exploration/Returns Max         -156.6
exploration/Returns Min         -304.199
exploration/Actions Mean          -0.01144
exploration/Actions Std            0.271463
exploration/Actions Max            0.992523
exploration/Actions Min           -0.999917
exploration/Num Paths              5
exploration/Average Returns     -239.451
evaluation/num steps total     31500
evaluation/num paths total       315
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.61678
evaluation/Rewards Std             1.70355
evaluation/Rewards Max            -0.197652
evaluation/Rewards Min            -9.10298
evaluation/Returns Mean         -261.678
evaluation/Returns Std           153.859
evaluation/Returns Max           -28.757
evaluation/Returns Min          -525.939
evaluation/Actions Mean           -0.0020711
evaluation/Actions Std             0.166008
evaluation/Actions Max             0.974569
evaluation/Actions Min            -0.997883
evaluation/Num Paths              15
evaluation/Average Returns      -261.678
time/data storing (s)              0.0029557
time/evaluation sampling (s)       0.332996
time/exploration sampling (s)      0.132777
time/logging (s)                   0.00475539
time/saving (s)                    0.00166296
time/training (s)                  1.94236
time/epoch (s)                     2.4175
time/total (s)                    51.2263
Epoch                             20
-----------------------------  --------------
2019-04-23 01:14:24.359158 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 21 finished
-----------------------------  --------------
replay_buffer/size             11200
trainer/QF1 Loss                   2.60151
trainer/QF2 Loss                   2.79376
trainer/Policy Loss              100.111
trainer/Q1 Predictions Mean      -99.6764
trainer/Q1 Predictions Std        36.1599
trainer/Q1 Predictions Max       -22.1652
trainer/Q1 Predictions Min      -162.912
trainer/Q2 Predictions Mean      -99.6808
trainer/Q2 Predictions Std        36.1567
trainer/Q2 Predictions Max       -22.1711
trainer/Q2 Predictions Min      -162.692
trainer/Q Targets Mean          -100.802
trainer/Q Targets Std             36.754
trainer/Q Targets Max            -23.0008
trainer/Q Targets Min           -164.229
trainer/Log Pis Mean               1.40405
trainer/Log Pis Std                1.49416
trainer/Log Pis Max                6.14891
trainer/Log Pis Min               -5.12162
trainer/Policy mu Mean             0.0432418
trainer/Policy mu Std              0.814893
trainer/Policy mu Max              2.32557
trainer/Policy mu Min             -3.11346
trainer/Policy log std Mean       -1.68982
trainer/Policy log std Std         0.415686
trainer/Policy log std Max        -0.597455
trainer/Policy log std Min        -2.424
trainer/Alpha                      0.0687363
trainer/Alpha Loss                -1.59552
exploration/num steps total    11200
exploration/num paths total      112
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.66221
exploration/Rewards Std            0.889271
exploration/Rewards Max           -0.453533
exploration/Rewards Min           -7.98172
exploration/Returns Mean        -166.221
exploration/Returns Std           69.9581
exploration/Returns Max          -86.4129
exploration/Returns Min         -271.683
exploration/Actions Mean          -0.0100899
exploration/Actions Std            0.246482
exploration/Actions Max            0.999571
exploration/Actions Min           -0.99341
exploration/Num Paths              5
exploration/Average Returns     -166.221
evaluation/num steps total     33000
evaluation/num paths total       330
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.2929
evaluation/Rewards Std             1.5064
evaluation/Rewards Max            -0.295895
evaluation/Rewards Min            -9.61018
evaluation/Returns Mean         -229.29
evaluation/Returns Std           131.225
evaluation/Returns Max           -60.3625
evaluation/Returns Min          -537.705
evaluation/Actions Mean            0.0172734
evaluation/Actions Std             0.175064
evaluation/Actions Max             0.99366
evaluation/Actions Min            -0.994144
evaluation/Num Paths              15
evaluation/Average Returns      -229.29
time/data storing (s)              0.00286877
time/evaluation sampling (s)       0.333348
time/exploration sampling (s)      0.134842
time/logging (s)                   0.00473311
time/saving (s)                    0.00157409
time/training (s)                  1.92779
time/epoch (s)                     2.40516
time/total (s)                    53.6357
Epoch                             21
-----------------------------  --------------
2019-04-23 01:14:26.789810 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 22 finished
-----------------------------  --------------
replay_buffer/size             11700
trainer/QF1 Loss                 243.817
trainer/QF2 Loss                 243.548
trainer/Policy Loss              110.329
trainer/Q1 Predictions Mean     -109.538
trainer/Q1 Predictions Std        35.4171
trainer/Q1 Predictions Max       -24.5514
trainer/Q1 Predictions Min      -167.472
trainer/Q2 Predictions Mean     -109.622
trainer/Q2 Predictions Std        35.4323
trainer/Q2 Predictions Max       -24.2292
trainer/Q2 Predictions Min      -167.504
trainer/Q Targets Mean          -109.087
trainer/Q Targets Std             36.997
trainer/Q Targets Max             -5.20486
trainer/Q Targets Min           -169.113
trainer/Log Pis Mean               1.54662
trainer/Log Pis Std                1.6137
trainer/Log Pis Max                6.03572
trainer/Log Pis Min               -4.80072
trainer/Policy mu Mean            -0.0315089
trainer/Policy mu Std              0.804953
trainer/Policy mu Max              2.22085
trainer/Policy mu Min             -3.1147
trainer/Policy log std Mean       -1.7702
trainer/Policy log std Std         0.379849
trainer/Policy log std Max        -0.374103
trainer/Policy log std Min        -2.43494
trainer/Alpha                      0.064132
trainer/Alpha Loss                -1.24529
exploration/num steps total    11700
exploration/num paths total      117
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -3.62383
exploration/Rewards Std            2.14338
exploration/Rewards Max           -0.155966
exploration/Rewards Min          -10.0642
exploration/Returns Mean        -362.383
exploration/Returns Std          199.151
exploration/Returns Max         -111.549
exploration/Returns Min         -628.833
exploration/Actions Mean           0.0169371
exploration/Actions Std            0.26901
exploration/Actions Max            0.99738
exploration/Actions Min           -0.996614
exploration/Num Paths              5
exploration/Average Returns     -362.383
evaluation/num steps total     34500
evaluation/num paths total       345
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.57637
evaluation/Rewards Std             1.74643
evaluation/Rewards Max            -0.130221
evaluation/Rewards Min            -8.81724
evaluation/Returns Mean         -257.637
evaluation/Returns Std           168.631
evaluation/Returns Max           -21.9304
evaluation/Returns Min          -610.187
evaluation/Actions Mean            0.00417591
evaluation/Actions Std             0.146162
evaluation/Actions Max             0.995365
evaluation/Actions Min            -0.99783
evaluation/Num Paths              15
evaluation/Average Returns      -257.637
time/data storing (s)              0.00313809
time/evaluation sampling (s)       0.333957
time/exploration sampling (s)      0.138002
time/logging (s)                   0.00400278
time/saving (s)                    0.00192443
time/training (s)                  1.94363
time/epoch (s)                     2.42465
time/total (s)                    56.0646
Epoch                             22
-----------------------------  --------------
2019-04-23 01:14:29.217180 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 23 finished
-----------------------------  --------------
replay_buffer/size             12200
trainer/QF1 Loss                  82.6426
trainer/QF2 Loss                  82.5158
trainer/Policy Loss              110.138
trainer/Q1 Predictions Mean     -109.115
trainer/Q1 Predictions Std        38.4012
trainer/Q1 Predictions Max       -23.6947
trainer/Q1 Predictions Min      -169.987
trainer/Q2 Predictions Mean     -109.08
trainer/Q2 Predictions Std        38.4612
trainer/Q2 Predictions Max       -23.1427
trainer/Q2 Predictions Min      -170.247
trainer/Q Targets Mean          -110.195
trainer/Q Targets Std             40.608
trainer/Q Targets Max             -2.59419
trainer/Q Targets Min           -173.316
trainer/Log Pis Mean               1.91724
trainer/Log Pis Std                1.54394
trainer/Log Pis Max                6.09364
trainer/Log Pis Min               -3.07918
trainer/Policy mu Mean            -0.0599192
trainer/Policy mu Std              0.936784
trainer/Policy mu Max              2.90952
trainer/Policy mu Min             -3.08698
trainer/Policy log std Mean       -1.7104
trainer/Policy log std Std         0.477324
trainer/Policy log std Max        -0.238695
trainer/Policy log std Min        -2.48858
trainer/Alpha                      0.060409
trainer/Alpha Loss                -0.232269
exploration/num steps total    12200
exploration/num paths total      122
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.38086
exploration/Rewards Std            1.39998
exploration/Rewards Max           -0.379435
exploration/Rewards Min           -9.2059
exploration/Returns Mean        -238.086
exploration/Returns Std          123.048
exploration/Returns Max          -92.5639
exploration/Returns Min         -440.599
exploration/Actions Mean           0.0137661
exploration/Actions Std            0.227013
exploration/Actions Max            0.986759
exploration/Actions Min           -0.983293
exploration/Num Paths              5
exploration/Average Returns     -238.086
evaluation/num steps total     36000
evaluation/num paths total       360
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.55464
evaluation/Rewards Std             1.73668
evaluation/Rewards Max            -0.0928607
evaluation/Rewards Min            -8.02273
evaluation/Returns Mean         -255.464
evaluation/Returns Std           165.848
evaluation/Returns Max           -27.1252
evaluation/Returns Min          -628.084
evaluation/Actions Mean            0.00745686
evaluation/Actions Std             0.15041
evaluation/Actions Max             0.991089
evaluation/Actions Min            -0.990606
evaluation/Num Paths              15
evaluation/Average Returns      -255.464
time/data storing (s)              0.00280947
time/evaluation sampling (s)       0.325629
time/exploration sampling (s)      0.137146
time/logging (s)                   0.00455592
time/saving (s)                    0.00193441
time/training (s)                  1.95072
time/epoch (s)                     2.4228
time/total (s)                    58.4916
Epoch                             23
-----------------------------  --------------
2019-04-23 01:14:31.643186 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 24 finished
-----------------------------  --------------
replay_buffer/size             12700
trainer/QF1 Loss                   1.83248
trainer/QF2 Loss                   2.016
trainer/Policy Loss              112.993
trainer/Q1 Predictions Mean     -112.045
trainer/Q1 Predictions Std        40.0687
trainer/Q1 Predictions Max       -17.7024
trainer/Q1 Predictions Min      -177.349
trainer/Q2 Predictions Mean     -112.026
trainer/Q2 Predictions Std        40.0632
trainer/Q2 Predictions Max       -17.3683
trainer/Q2 Predictions Min      -176.462
trainer/Q Targets Mean          -113.004
trainer/Q Targets Std             40.4272
trainer/Q Targets Max            -18.3019
trainer/Q Targets Min           -178.492
trainer/Log Pis Mean               1.87354
trainer/Log Pis Std                1.73546
trainer/Log Pis Max                7.57389
trainer/Log Pis Min               -3.28486
trainer/Policy mu Mean            -0.0515216
trainer/Policy mu Std              0.928169
trainer/Policy mu Max              2.98824
trainer/Policy mu Min             -3.42104
trainer/Policy log std Mean       -1.81275
trainer/Policy log std Std         0.487201
trainer/Policy log std Max        -0.285113
trainer/Policy log std Min        -2.69324
trainer/Alpha                      0.0573873
trainer/Alpha Loss                -0.361389
exploration/num steps total    12700
exploration/num paths total      127
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -3.48769
exploration/Rewards Std            2.10133
exploration/Rewards Max           -0.0706592
exploration/Rewards Min           -7.91516
exploration/Returns Mean        -348.769
exploration/Returns Std          198.162
exploration/Returns Max         -117.513
exploration/Returns Min         -599.013
exploration/Actions Mean           0.0300954
exploration/Actions Std            0.231263
exploration/Actions Max            0.994587
exploration/Actions Min           -0.699333
exploration/Num Paths              5
exploration/Average Returns     -348.769
evaluation/num steps total     37500
evaluation/num paths total       375
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -3.07756
evaluation/Rewards Std             1.48395
evaluation/Rewards Max            -0.309023
evaluation/Rewards Min           -11.5367
evaluation/Returns Mean         -307.756
evaluation/Returns Std           129.73
evaluation/Returns Max           -93.2239
evaluation/Returns Min          -539.42
evaluation/Actions Mean            0.0101634
evaluation/Actions Std             0.186242
evaluation/Actions Max             0.991749
evaluation/Actions Min            -0.9977
evaluation/Num Paths              15
evaluation/Average Returns      -307.756
time/data storing (s)              0.00304925
time/evaluation sampling (s)       0.324834
time/exploration sampling (s)      0.142039
time/logging (s)                   0.00480083
time/saving (s)                    0.00194831
time/training (s)                  1.94478
time/epoch (s)                     2.42145
time/total (s)                    60.9171
Epoch                             24
-----------------------------  --------------
2019-04-23 01:14:34.062322 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 25 finished
-----------------------------  --------------
replay_buffer/size             13200
trainer/QF1 Loss                   1.29241
trainer/QF2 Loss                   1.39828
trainer/Policy Loss              113.703
trainer/Q1 Predictions Mean     -112.577
trainer/Q1 Predictions Std        44.5659
trainer/Q1 Predictions Max       -15.6863
trainer/Q1 Predictions Min      -180.901
trainer/Q2 Predictions Mean     -112.523
trainer/Q2 Predictions Std        44.5103
trainer/Q2 Predictions Max       -15.9139
trainer/Q2 Predictions Min      -181.217
trainer/Q Targets Mean          -113.214
trainer/Q Targets Std             45.0284
trainer/Q Targets Max            -16.396
trainer/Q Targets Min           -182.47
trainer/Log Pis Mean               1.83799
trainer/Log Pis Std                1.19989
trainer/Log Pis Max                5.81878
trainer/Log Pis Min               -0.997213
trainer/Policy mu Mean            -0.0609763
trainer/Policy mu Std              0.671033
trainer/Policy mu Max              1.94494
trainer/Policy mu Min             -3.21895
trainer/Policy log std Mean       -1.94297
trainer/Policy log std Std         0.39867
trainer/Policy log std Max        -0.337105
trainer/Policy log std Min        -2.71996
trainer/Alpha                      0.0558111
trainer/Alpha Loss                -0.467501
exploration/num steps total    13200
exploration/num paths total      132
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -3.03044
exploration/Rewards Std            1.21817
exploration/Rewards Max           -1.1938
exploration/Rewards Min          -11.6881
exploration/Returns Mean        -303.044
exploration/Returns Std           74.8841
exploration/Returns Max         -199.81
exploration/Returns Min         -417.784
exploration/Actions Mean          -0.00442329
exploration/Actions Std            0.261846
exploration/Actions Max            0.99682
exploration/Actions Min           -0.999668
exploration/Num Paths              5
exploration/Average Returns     -303.044
evaluation/num steps total     39000
evaluation/num paths total       390
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.20766
evaluation/Rewards Std             2.00262
evaluation/Rewards Max            -0.0424362
evaluation/Rewards Min            -9.97454
evaluation/Returns Mean         -220.766
evaluation/Returns Std           187.487
evaluation/Returns Max           -32.4983
evaluation/Returns Min          -609.523
evaluation/Actions Mean            0.00977961
evaluation/Actions Std             0.160757
evaluation/Actions Max             0.996794
evaluation/Actions Min            -0.991758
evaluation/Num Paths              15
evaluation/Average Returns      -220.766
time/data storing (s)              0.00295852
time/evaluation sampling (s)       0.335533
time/exploration sampling (s)      0.140836
time/logging (s)                   0.00474544
time/saving (s)                    0.0019493
time/training (s)                  1.92781
time/epoch (s)                     2.41384
time/total (s)                    63.3351
Epoch                             25
-----------------------------  --------------
2019-04-23 01:14:36.487155 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 26 finished
-----------------------------  --------------
replay_buffer/size             13700
trainer/QF1 Loss                   1.80176
trainer/QF2 Loss                   2.00718
trainer/Policy Loss              109.06
trainer/Q1 Predictions Mean     -107.879
trainer/Q1 Predictions Std        45.9633
trainer/Q1 Predictions Max       -14.6359
trainer/Q1 Predictions Min      -185.121
trainer/Q2 Predictions Mean     -107.847
trainer/Q2 Predictions Std        45.9659
trainer/Q2 Predictions Max       -14.3539
trainer/Q2 Predictions Min      -185.122
trainer/Q Targets Mean          -108.443
trainer/Q Targets Std             46.3278
trainer/Q Targets Max            -15.3857
trainer/Q Targets Min           -187.093
trainer/Log Pis Mean               2.05875
trainer/Log Pis Std                1.42185
trainer/Log Pis Max                8.32636
trainer/Log Pis Min               -2.2642
trainer/Policy mu Mean            -0.0518488
trainer/Policy mu Std              0.765661
trainer/Policy mu Max              2.63148
trainer/Policy mu Min             -3.40817
trainer/Policy log std Mean       -1.9754
trainer/Policy log std Std         0.44503
trainer/Policy log std Max        -0.258193
trainer/Policy log std Min        -2.81029
trainer/Alpha                      0.0549549
trainer/Alpha Loss                 0.170461
exploration/num steps total    13700
exploration/num paths total      137
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.01199
exploration/Rewards Std            1.19391
exploration/Rewards Max           -0.0310503
exploration/Rewards Min           -7.63445
exploration/Returns Mean        -201.199
exploration/Returns Std          100.694
exploration/Returns Max          -62.0121
exploration/Returns Min         -317.346
exploration/Actions Mean           0.0161235
exploration/Actions Std            0.197865
exploration/Actions Max            0.995799
exploration/Actions Min           -0.819224
exploration/Num Paths              5
exploration/Average Returns     -201.199
evaluation/num steps total     40500
evaluation/num paths total       405
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.73211
evaluation/Rewards Std             1.15531
evaluation/Rewards Max            -0.202419
evaluation/Rewards Min            -7.42976
evaluation/Returns Mean         -173.211
evaluation/Returns Std           100.343
evaluation/Returns Max           -50.2193
evaluation/Returns Min          -313.854
evaluation/Actions Mean           -0.00138083
evaluation/Actions Std             0.147485
evaluation/Actions Max             0.994684
evaluation/Actions Min            -0.998115
evaluation/Num Paths              15
evaluation/Average Returns      -173.211
time/data storing (s)              0.00299491
time/evaluation sampling (s)       0.33229
time/exploration sampling (s)      0.135663
time/logging (s)                   0.00348459
time/saving (s)                    0.00202618
time/training (s)                  1.94188
time/epoch (s)                     2.41834
time/total (s)                    65.7576
Epoch                             26
-----------------------------  --------------
2019-04-23 01:14:38.923611 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 27 finished
-----------------------------  --------------
replay_buffer/size             14200
trainer/QF1 Loss                 479.543
trainer/QF2 Loss                 480.891
trainer/Policy Loss              111.935
trainer/Q1 Predictions Mean     -110.581
trainer/Q1 Predictions Std        42.8554
trainer/Q1 Predictions Max       -16.1851
trainer/Q1 Predictions Min      -191.311
trainer/Q2 Predictions Mean     -110.635
trainer/Q2 Predictions Std        42.8838
trainer/Q2 Predictions Max       -16.1354
trainer/Q2 Predictions Min      -191.108
trainer/Q Targets Mean          -107.45
trainer/Q Targets Std             46.0412
trainer/Q Targets Max             -1.96055
trainer/Q Targets Min           -192.786
trainer/Log Pis Mean               2.22981
trainer/Log Pis Std                1.58495
trainer/Log Pis Max                7.51584
trainer/Log Pis Min               -2.18471
trainer/Policy mu Mean            -0.0255778
trainer/Policy mu Std              0.92617
trainer/Policy mu Max              3.05684
trainer/Policy mu Min             -3.17249
trainer/Policy log std Mean       -1.91914
trainer/Policy log std Std         0.502356
trainer/Policy log std Max        -0.336542
trainer/Policy log std Min        -2.80237
trainer/Alpha                      0.0567101
trainer/Alpha Loss                 0.659533
exploration/num steps total    14200
exploration/num paths total      142
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.52565
exploration/Rewards Std            1.87707
exploration/Rewards Max           -0.259181
exploration/Rewards Min          -10.208
exploration/Returns Mean        -252.565
exploration/Returns Std          170.793
exploration/Returns Max          -55.0314
exploration/Returns Min         -518.986
exploration/Actions Mean           0.00598519
exploration/Actions Std            0.210458
exploration/Actions Max            0.977464
exploration/Actions Min           -0.999853
exploration/Num Paths              5
exploration/Average Returns     -252.565
evaluation/num steps total     42000
evaluation/num paths total       420
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -3.15585
evaluation/Rewards Std             2.23053
evaluation/Rewards Max            -0.239197
evaluation/Rewards Min           -10.0671
evaluation/Returns Mean         -315.585
evaluation/Returns Std           209.594
evaluation/Returns Max           -59.3209
evaluation/Returns Min          -633.882
evaluation/Actions Mean            0.0272116
evaluation/Actions Std             0.187868
evaluation/Actions Max             0.998342
evaluation/Actions Min            -0.982723
evaluation/Num Paths              15
evaluation/Average Returns      -315.585
time/data storing (s)              0.00278776
time/evaluation sampling (s)       0.332223
time/exploration sampling (s)      0.135948
time/logging (s)                   0.00473912
time/saving (s)                    0.00185635
time/training (s)                  1.95538
time/epoch (s)                     2.43294
time/total (s)                    68.1946
Epoch                             27
-----------------------------  --------------
2019-04-23 01:14:41.394443 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 28 finished
-----------------------------  --------------
replay_buffer/size             14700
trainer/QF1 Loss                  97.5072
trainer/QF2 Loss                  97.1618
trainer/Policy Loss              111.541
trainer/Q1 Predictions Mean     -110.44
trainer/Q1 Predictions Std        45.7592
trainer/Q1 Predictions Max       -14.1482
trainer/Q1 Predictions Min      -197.06
trainer/Q2 Predictions Mean     -110.47
trainer/Q2 Predictions Std        45.8187
trainer/Q2 Predictions Max       -14.9334
trainer/Q2 Predictions Min      -197.391
trainer/Q Targets Mean          -110.141
trainer/Q Targets Std             47.3955
trainer/Q Targets Max             -6.51642
trainer/Q Targets Min           -198.658
trainer/Log Pis Mean               2.11276
trainer/Log Pis Std                1.55316
trainer/Log Pis Max                9.01189
trainer/Log Pis Min               -3.63457
trainer/Policy mu Mean            -0.0857725
trainer/Policy mu Std              0.781829
trainer/Policy mu Max              2.19457
trainer/Policy mu Min             -3.75088
trainer/Policy log std Mean       -1.96886
trainer/Policy log std Std         0.500622
trainer/Policy log std Max        -0.146931
trainer/Policy log std Min        -2.76233
trainer/Alpha                      0.0582697
trainer/Alpha Loss                 0.320532
exploration/num steps total    14700
exploration/num paths total      147
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.49695
exploration/Rewards Std            1.36524
exploration/Rewards Max           -0.813182
exploration/Rewards Min          -11.4715
exploration/Returns Mean        -249.695
exploration/Returns Std          123.607
exploration/Returns Max         -143.284
exploration/Returns Min         -481.361
exploration/Actions Mean          -0.0146222
exploration/Actions Std            0.220656
exploration/Actions Max            0.955364
exploration/Actions Min           -0.998842
exploration/Num Paths              5
exploration/Average Returns     -249.695
evaluation/num steps total     43500
evaluation/num paths total       435
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.42728
evaluation/Rewards Std             1.62722
evaluation/Rewards Max            -0.198761
evaluation/Rewards Min            -9.31782
evaluation/Returns Mean         -242.728
evaluation/Returns Std           143.885
evaluation/Returns Max           -27.6062
evaluation/Returns Min          -505.674
evaluation/Actions Mean            0.00557115
evaluation/Actions Std             0.166986
evaluation/Actions Max             0.995896
evaluation/Actions Min            -0.99599
evaluation/Num Paths              15
evaluation/Average Returns      -242.728
time/data storing (s)              0.00305155
time/evaluation sampling (s)       0.360307
time/exploration sampling (s)      0.143324
time/logging (s)                   0.00476376
time/saving (s)                    0.00189615
time/training (s)                  1.95219
time/epoch (s)                     2.46553
time/total (s)                    70.6643
Epoch                             28
-----------------------------  --------------
2019-04-23 01:14:43.855757 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 29 finished
-----------------------------  ---------------
replay_buffer/size             15200
trainer/QF1 Loss                 372.574
trainer/QF2 Loss                 376.579
trainer/Policy Loss              120.562
trainer/Q1 Predictions Mean     -119.572
trainer/Q1 Predictions Std        48.3929
trainer/Q1 Predictions Max       -29.1811
trainer/Q1 Predictions Min      -197.911
trainer/Q2 Predictions Mean     -119.55
trainer/Q2 Predictions Std        48.4914
trainer/Q2 Predictions Max       -29.4068
trainer/Q2 Predictions Min      -198.537
trainer/Q Targets Mean          -118.401
trainer/Q Targets Std             51.6202
trainer/Q Targets Max             -2.95681
trainer/Q Targets Min           -202.287
trainer/Log Pis Mean               1.7993
trainer/Log Pis Std                1.63044
trainer/Log Pis Max                7.98069
trainer/Log Pis Min               -4.62988
trainer/Policy mu Mean            -0.123712
trainer/Policy mu Std              0.813064
trainer/Policy mu Max              2.23606
trainer/Policy mu Min             -3.68106
trainer/Policy log std Mean       -1.856
trainer/Policy log std Std         0.458097
trainer/Policy log std Max        -0.0518779
trainer/Policy log std Min        -2.89212
trainer/Alpha                      0.0569932
trainer/Alpha Loss                -0.574919
exploration/num steps total    15200
exploration/num paths total      152
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.89396
exploration/Rewards Std            1.62533
exploration/Rewards Max           -0.307646
exploration/Rewards Min           -9.63905
exploration/Returns Mean        -289.396
exploration/Returns Std          141.534
exploration/Returns Max          -82.6797
exploration/Returns Min         -448.858
exploration/Actions Mean          -0.0182405
exploration/Actions Std            0.257435
exploration/Actions Max            0.993301
exploration/Actions Min           -0.999854
exploration/Num Paths              5
exploration/Average Returns     -289.396
evaluation/num steps total     45000
evaluation/num paths total       450
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.41432
evaluation/Rewards Std             2.10582
evaluation/Rewards Max            -0.316575
evaluation/Rewards Min            -8.95892
evaluation/Returns Mean         -241.432
evaluation/Returns Std           202.88
evaluation/Returns Max           -57.1033
evaluation/Returns Min          -638.435
evaluation/Actions Mean            0.000725878
evaluation/Actions Std             0.151047
evaluation/Actions Max             0.997532
evaluation/Actions Min            -0.998788
evaluation/Num Paths              15
evaluation/Average Returns      -241.432
time/data storing (s)              0.00379342
time/evaluation sampling (s)       0.329526
time/exploration sampling (s)      0.164757
time/logging (s)                   0.00431584
time/saving (s)                    0.00995615
time/training (s)                  1.94315
time/epoch (s)                     2.4555
time/total (s)                    73.1241
Epoch                             29
-----------------------------  ---------------
2019-04-23 01:14:46.266434 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 30 finished
-----------------------------  --------------
replay_buffer/size             15700
trainer/QF1 Loss                   3.18628
trainer/QF2 Loss                   3.03836
trainer/Policy Loss              116.27
trainer/Q1 Predictions Mean     -115.144
trainer/Q1 Predictions Std        53.1503
trainer/Q1 Predictions Max       -12.0781
trainer/Q1 Predictions Min      -202.632
trainer/Q2 Predictions Mean     -115.122
trainer/Q2 Predictions Std        53.2055
trainer/Q2 Predictions Max       -11.878
trainer/Q2 Predictions Min      -203.013
trainer/Q Targets Mean          -116.339
trainer/Q Targets Std             53.8426
trainer/Q Targets Max            -12.5114
trainer/Q Targets Min           -206.139
trainer/Log Pis Mean               1.8427
trainer/Log Pis Std                1.49659
trainer/Log Pis Max                5.62762
trainer/Log Pis Min               -4.93674
trainer/Policy mu Mean             0.0247544
trainer/Policy mu Std              0.684485
trainer/Policy mu Max              2.70438
trainer/Policy mu Min             -2.56595
trainer/Policy log std Mean       -2.02086
trainer/Policy log std Std         0.457336
trainer/Policy log std Max        -0.574096
trainer/Policy log std Min        -2.89521
trainer/Alpha                      0.0565329
trainer/Alpha Loss                -0.451918
exploration/num steps total    15700
exploration/num paths total      157
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.85199
exploration/Rewards Std            1.15762
exploration/Rewards Max           -1.22123
exploration/Rewards Min          -10.3949
exploration/Returns Mean        -285.199
exploration/Returns Std           91.0255
exploration/Returns Max         -187.336
exploration/Returns Min         -451.675
exploration/Actions Mean           0.0107171
exploration/Actions Std            0.217312
exploration/Actions Max            0.997978
exploration/Actions Min           -0.995027
exploration/Num Paths              5
exploration/Average Returns     -285.199
evaluation/num steps total     46500
evaluation/num paths total       465
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -3.07616
evaluation/Rewards Std             1.73604
evaluation/Rewards Max            -0.274206
evaluation/Rewards Min           -11.645
evaluation/Returns Mean         -307.616
evaluation/Returns Std           162.419
evaluation/Returns Max           -93.2453
evaluation/Returns Min          -614.753
evaluation/Actions Mean            0.00712739
evaluation/Actions Std             0.165303
evaluation/Actions Max             0.992954
evaluation/Actions Min            -0.998903
evaluation/Num Paths              15
evaluation/Average Returns      -307.616
time/data storing (s)              0.00294016
time/evaluation sampling (s)       0.327239
time/exploration sampling (s)      0.13596
time/logging (s)                   0.00479961
time/saving (s)                    0.00193516
time/training (s)                  1.93264
time/epoch (s)                     2.40552
time/total (s)                    75.5342
Epoch                             30
-----------------------------  --------------
2019-04-23 01:14:48.697612 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 31 finished
-----------------------------  --------------
replay_buffer/size             16200
trainer/QF1 Loss                 157.393
trainer/QF2 Loss                 156.514
trainer/Policy Loss              118.8
trainer/Q1 Predictions Mean     -117.968
trainer/Q1 Predictions Std        50.5137
trainer/Q1 Predictions Max       -11.8691
trainer/Q1 Predictions Min      -208.817
trainer/Q2 Predictions Mean     -117.959
trainer/Q2 Predictions Std        50.5276
trainer/Q2 Predictions Max       -11.7187
trainer/Q2 Predictions Min      -208.181
trainer/Q Targets Mean          -116.71
trainer/Q Targets Std             53.2897
trainer/Q Targets Max             -1.47462
trainer/Q Targets Min           -210.605
trainer/Log Pis Mean               1.98591
trainer/Log Pis Std                1.40068
trainer/Log Pis Max                7.02331
trainer/Log Pis Min               -3.66146
trainer/Policy mu Mean            -0.0527742
trainer/Policy mu Std              0.798863
trainer/Policy mu Max              2.41854
trainer/Policy mu Min             -3.77005
trainer/Policy log std Mean       -1.93469
trainer/Policy log std Std         0.514536
trainer/Policy log std Max         0.199079
trainer/Policy log std Min        -2.82723
trainer/Alpha                      0.0593342
trainer/Alpha Loss                -0.0398001
exploration/num steps total    16200
exploration/num paths total      162
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.57637
exploration/Rewards Std            1.28473
exploration/Rewards Max           -0.0481357
exploration/Rewards Min           -7.67754
exploration/Returns Mean        -157.637
exploration/Returns Std           90.585
exploration/Returns Max          -66.0127
exploration/Returns Min         -273.529
exploration/Actions Mean           0.0416654
exploration/Actions Std            0.231237
exploration/Actions Max            0.998514
exploration/Actions Min           -0.638388
exploration/Num Paths              5
exploration/Average Returns     -157.637
evaluation/num steps total     48000
evaluation/num paths total       480
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.07016
evaluation/Rewards Std             1.66771
evaluation/Rewards Max            -0.23262
evaluation/Rewards Min            -9.7651
evaluation/Returns Mean         -207.016
evaluation/Returns Std           146.385
evaluation/Returns Max           -39.7418
evaluation/Returns Min          -460.731
evaluation/Actions Mean            0.0089475
evaluation/Actions Std             0.162467
evaluation/Actions Max             0.998167
evaluation/Actions Min            -0.992047
evaluation/Num Paths              15
evaluation/Average Returns      -207.016
time/data storing (s)              0.0028849
time/evaluation sampling (s)       0.33333
time/exploration sampling (s)      0.139686
time/logging (s)                   0.00478811
time/saving (s)                    0.00194921
time/training (s)                  1.9431
time/epoch (s)                     2.42574
time/total (s)                    77.9642
Epoch                             31
-----------------------------  --------------
2019-04-23 01:14:51.121009 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 32 finished
-----------------------------  --------------
replay_buffer/size             16700
trainer/QF1 Loss                 326.873
trainer/QF2 Loss                 326.761
trainer/Policy Loss              115.991
trainer/Q1 Predictions Mean     -114.677
trainer/Q1 Predictions Std        50.0491
trainer/Q1 Predictions Max       -13.1805
trainer/Q1 Predictions Min      -211.75
trainer/Q2 Predictions Mean     -114.625
trainer/Q2 Predictions Std        50.0296
trainer/Q2 Predictions Max       -12.8351
trainer/Q2 Predictions Min      -211.653
trainer/Q Targets Mean          -114.983
trainer/Q Targets Std             51.2944
trainer/Q Targets Max             -5.20486
trainer/Q Targets Min           -214.457
trainer/Log Pis Mean               2.17786
trainer/Log Pis Std                1.26917
trainer/Log Pis Max                7.72843
trainer/Log Pis Min               -1.12535
trainer/Policy mu Mean            -0.101843
trainer/Policy mu Std              0.768983
trainer/Policy mu Max              2.04527
trainer/Policy mu Min             -3.87208
trainer/Policy log std Mean       -1.98462
trainer/Policy log std Std         0.462584
trainer/Policy log std Max        -0.0102979
trainer/Policy log std Min        -2.86092
trainer/Alpha                      0.0572045
trainer/Alpha Loss                 0.508865
exploration/num steps total    16700
exploration/num paths total      167
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -3.45322
exploration/Rewards Std            2.69192
exploration/Rewards Max           -0.202904
exploration/Rewards Min           -8.83779
exploration/Returns Mean        -345.322
exploration/Returns Std          261.361
exploration/Returns Max          -56.5112
exploration/Returns Min         -658.456
exploration/Actions Mean           0.00415498
exploration/Actions Std            0.225208
exploration/Actions Max            0.991728
exploration/Actions Min           -0.928763
exploration/Num Paths              5
exploration/Average Returns     -345.322
evaluation/num steps total     49500
evaluation/num paths total       495
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.59939
evaluation/Rewards Std             1.49452
evaluation/Rewards Max            -0.38018
evaluation/Rewards Min           -11.0669
evaluation/Returns Mean         -259.939
evaluation/Returns Std           123.03
evaluation/Returns Max           -71.7951
evaluation/Returns Min          -470.866
evaluation/Actions Mean            0.0170919
evaluation/Actions Std             0.173521
evaluation/Actions Max             0.999255
evaluation/Actions Min            -0.998486
evaluation/Num Paths              15
evaluation/Average Returns      -259.939
time/data storing (s)              0.0031003
time/evaluation sampling (s)       0.329367
time/exploration sampling (s)      0.141285
time/logging (s)                   0.00474558
time/saving (s)                    0.00189784
time/training (s)                  1.93726
time/epoch (s)                     2.41765
time/total (s)                    80.3865
Epoch                             32
-----------------------------  --------------
2019-04-23 01:14:53.558888 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 33 finished
-----------------------------  ---------------
replay_buffer/size             17200
trainer/QF1 Loss                 501.677
trainer/QF2 Loss                 503.329
trainer/Policy Loss              103.157
trainer/Q1 Predictions Mean     -101.989
trainer/Q1 Predictions Std        48.8635
trainer/Q1 Predictions Max       -10.6993
trainer/Q1 Predictions Min      -218.611
trainer/Q2 Predictions Mean     -102.076
trainer/Q2 Predictions Std        48.8048
trainer/Q2 Predictions Max       -10.715
trainer/Q2 Predictions Min      -218.91
trainer/Q Targets Mean           -99.8128
trainer/Q Targets Std             49.6451
trainer/Q Targets Max             -0.35583
trainer/Q Targets Min           -219.91
trainer/Log Pis Mean               1.80108
trainer/Log Pis Std                1.44562
trainer/Log Pis Max                6.95107
trainer/Log Pis Min               -2.81464
trainer/Policy mu Mean             0.0140886
trainer/Policy mu Std              0.705359
trainer/Policy mu Max              3.07897
trainer/Policy mu Min             -2.63601
trainer/Policy log std Mean       -2.03078
trainer/Policy log std Std         0.496941
trainer/Policy log std Max        -0.460045
trainer/Policy log std Min        -2.87119
trainer/Alpha                      0.0574839
trainer/Alpha Loss                -0.568152
exploration/num steps total    17200
exploration/num paths total      172
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.27151
exploration/Rewards Std            1.3919
exploration/Rewards Max           -0.80631
exploration/Rewards Min           -8.83959
exploration/Returns Mean        -227.151
exploration/Returns Std          116.005
exploration/Returns Max         -141.857
exploration/Returns Min         -447.774
exploration/Actions Mean          -0.000203468
exploration/Actions Std            0.247977
exploration/Actions Max            0.995295
exploration/Actions Min           -0.975564
exploration/Num Paths              5
exploration/Average Returns     -227.151
evaluation/num steps total     51000
evaluation/num paths total       510
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.17766
evaluation/Rewards Std             1.4597
evaluation/Rewards Max            -0.438923
evaluation/Rewards Min           -10.4467
evaluation/Returns Mean         -217.766
evaluation/Returns Std           136.053
evaluation/Returns Max           -51.4785
evaluation/Returns Min          -501.913
evaluation/Actions Mean            0.0183309
evaluation/Actions Std             0.146753
evaluation/Actions Max             0.996479
evaluation/Actions Min            -0.992546
evaluation/Num Paths              15
evaluation/Average Returns      -217.766
time/data storing (s)              0.00304363
time/evaluation sampling (s)       0.328985
time/exploration sampling (s)      0.140419
time/logging (s)                   0.0047352
time/saving (s)                    0.00155855
time/training (s)                  1.95343
time/epoch (s)                     2.43217
time/total (s)                    82.8232
Epoch                             33
-----------------------------  ---------------
2019-04-23 01:14:56.000832 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 34 finished
-----------------------------  --------------
replay_buffer/size             17700
trainer/QF1 Loss                  75.8416
trainer/QF2 Loss                  75.3238
trainer/Policy Loss              111.783
trainer/Q1 Predictions Mean     -110.509
trainer/Q1 Predictions Std        50.6674
trainer/Q1 Predictions Max       -11.3759
trainer/Q1 Predictions Min      -220.636
trainer/Q2 Predictions Mean     -110.435
trainer/Q2 Predictions Std        50.7013
trainer/Q2 Predictions Max       -11.1955
trainer/Q2 Predictions Min      -220.347
trainer/Q Targets Mean          -110.621
trainer/Q Targets Std             52.2121
trainer/Q Targets Max             -4.93169
trainer/Q Targets Min           -222.851
trainer/Log Pis Mean               2.22472
trainer/Log Pis Std                1.28352
trainer/Log Pis Max                6.55754
trainer/Log Pis Min               -1.31453
trainer/Policy mu Mean             0.0753874
trainer/Policy mu Std              0.818384
trainer/Policy mu Max              2.74117
trainer/Policy mu Min             -3.74473
trainer/Policy log std Mean       -2.02195
trainer/Policy log std Std         0.492121
trainer/Policy log std Max         0.00381659
trainer/Policy log std Min        -2.91267
trainer/Alpha                      0.0596378
trainer/Alpha Loss                 0.633654
exploration/num steps total    17700
exploration/num paths total      177
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.60225
exploration/Rewards Std            1.9102
exploration/Rewards Max           -0.179372
exploration/Rewards Min           -8.36117
exploration/Returns Mean        -260.225
exploration/Returns Std          179.829
exploration/Returns Max          -41.8796
exploration/Returns Min         -556.657
exploration/Actions Mean          -0.00999421
exploration/Actions Std            0.215673
exploration/Actions Max            0.997135
exploration/Actions Min           -0.986069
exploration/Num Paths              5
exploration/Average Returns     -260.225
evaluation/num steps total     52500
evaluation/num paths total       525
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.16488
evaluation/Rewards Std             2.07854
evaluation/Rewards Max            -0.246597
evaluation/Rewards Min            -9.64983
evaluation/Returns Mean         -216.488
evaluation/Returns Std           201.966
evaluation/Returns Max           -34.2177
evaluation/Returns Min          -629.459
evaluation/Actions Mean            0.0215646
evaluation/Actions Std             0.160444
evaluation/Actions Max             0.997237
evaluation/Actions Min            -0.991086
evaluation/Num Paths              15
evaluation/Average Returns      -216.488
time/data storing (s)              0.00297569
time/evaluation sampling (s)       0.3327
time/exploration sampling (s)      0.137804
time/logging (s)                   0.00479004
time/saving (s)                    0.00197345
time/training (s)                  1.95602
time/epoch (s)                     2.43627
time/total (s)                    85.264
Epoch                             34
-----------------------------  --------------
2019-04-23 01:14:58.434428 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 35 finished
-----------------------------  --------------
replay_buffer/size             18200
trainer/QF1 Loss                 256.551
trainer/QF2 Loss                 257.66
trainer/Policy Loss              107.672
trainer/Q1 Predictions Mean     -106.56
trainer/Q1 Predictions Std        60.9018
trainer/Q1 Predictions Max       -10.616
trainer/Q1 Predictions Min      -224.925
trainer/Q2 Predictions Mean     -106.528
trainer/Q2 Predictions Std        60.9078
trainer/Q2 Predictions Max       -10.5917
trainer/Q2 Predictions Min      -224.932
trainer/Q Targets Mean          -105.084
trainer/Q Targets Std             62.8496
trainer/Q Targets Max             -1.44661
trainer/Q Targets Min           -226.861
trainer/Log Pis Mean               1.81949
trainer/Log Pis Std                1.1028
trainer/Log Pis Max                5.13073
trainer/Log Pis Min               -1.4282
trainer/Policy mu Mean             0.122672
trainer/Policy mu Std              0.615563
trainer/Policy mu Max              2.44037
trainer/Policy mu Min             -2.82667
trainer/Policy log std Mean       -1.99119
trainer/Policy log std Std         0.418916
trainer/Policy log std Max        -0.317768
trainer/Policy log std Min        -2.84508
trainer/Alpha                      0.0609222
trainer/Alpha Loss                -0.505049
exploration/num steps total    18200
exploration/num paths total      182
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.87672
exploration/Rewards Std            1.37557
exploration/Rewards Max           -0.132796
exploration/Rewards Min          -10.8249
exploration/Returns Mean        -187.672
exploration/Returns Std           84.3651
exploration/Returns Max          -71.1872
exploration/Returns Min         -293.121
exploration/Actions Mean           0.0210108
exploration/Actions Std            0.256001
exploration/Actions Max            0.99929
exploration/Actions Min           -0.999671
exploration/Num Paths              5
exploration/Average Returns     -187.672
evaluation/num steps total     54000
evaluation/num paths total       540
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -3.18956
evaluation/Rewards Std             2.13045
evaluation/Rewards Max            -0.074692
evaluation/Rewards Min           -10.4354
evaluation/Returns Mean         -318.956
evaluation/Returns Std           205.294
evaluation/Returns Max           -43.8534
evaluation/Returns Min          -689.416
evaluation/Actions Mean            0.00295138
evaluation/Actions Std             0.152483
evaluation/Actions Max             0.998
evaluation/Actions Min            -0.998079
evaluation/Num Paths              15
evaluation/Average Returns      -318.956
time/data storing (s)              0.00309016
time/evaluation sampling (s)       0.329931
time/exploration sampling (s)      0.141456
time/logging (s)                   0.00479063
time/saving (s)                    0.0019506
time/training (s)                  1.94672
time/epoch (s)                     2.42794
time/total (s)                    87.6964
Epoch                             35
-----------------------------  --------------
2019-04-23 01:15:00.875436 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 36 finished
-----------------------------  --------------
replay_buffer/size             18700
trainer/QF1 Loss                 136.686
trainer/QF2 Loss                 136.504
trainer/Policy Loss              118.321
trainer/Q1 Predictions Mean     -117.167
trainer/Q1 Predictions Std        53.0393
trainer/Q1 Predictions Max       -26.0066
trainer/Q1 Predictions Min      -226.5
trainer/Q2 Predictions Mean     -117.163
trainer/Q2 Predictions Std        53.0574
trainer/Q2 Predictions Max       -24.8343
trainer/Q2 Predictions Min      -226.624
trainer/Q Targets Mean          -116.814
trainer/Q Targets Std             55.7503
trainer/Q Targets Max             -2.29016
trainer/Q Targets Min           -229.83
trainer/Log Pis Mean               1.90143
trainer/Log Pis Std                1.38768
trainer/Log Pis Max                6.89634
trainer/Log Pis Min               -1.8846
trainer/Policy mu Mean            -0.0649952
trainer/Policy mu Std              0.79566
trainer/Policy mu Max              2.93406
trainer/Policy mu Min             -3.19497
trainer/Policy log std Mean       -1.93151
trainer/Policy log std Std         0.508649
trainer/Policy log std Max        -0.183229
trainer/Policy log std Min        -2.73895
trainer/Alpha                      0.0605642
trainer/Alpha Loss                -0.276381
exploration/num steps total    18700
exploration/num paths total      187
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -3.09959
exploration/Rewards Std            2.60474
exploration/Rewards Max           -0.1102
exploration/Rewards Min           -8.55079
exploration/Returns Mean        -309.959
exploration/Returns Std          246.838
exploration/Returns Max          -73.6087
exploration/Returns Min         -702.318
exploration/Actions Mean           0.0144342
exploration/Actions Std            0.236271
exploration/Actions Max            0.999062
exploration/Actions Min           -0.929804
exploration/Num Paths              5
exploration/Average Returns     -309.959
evaluation/num steps total     55500
evaluation/num paths total       555
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.60023
evaluation/Rewards Std             2.13067
evaluation/Rewards Max            -0.0477857
evaluation/Rewards Min            -9.43994
evaluation/Returns Mean         -260.023
evaluation/Returns Std           203.353
evaluation/Returns Max            -7.34992
evaluation/Returns Min          -701.102
evaluation/Actions Mean            0.0123914
evaluation/Actions Std             0.148625
evaluation/Actions Max             0.998568
evaluation/Actions Min            -0.962191
evaluation/Num Paths              15
evaluation/Average Returns      -260.023
time/data storing (s)              0.00295953
time/evaluation sampling (s)       0.327955
time/exploration sampling (s)      0.137233
time/logging (s)                   0.00475918
time/saving (s)                    0.00194636
time/training (s)                  1.96062
time/epoch (s)                     2.43547
time/total (s)                    90.1362
Epoch                             36
-----------------------------  --------------
2019-04-23 01:15:03.310660 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 37 finished
-----------------------------  --------------
replay_buffer/size             19200
trainer/QF1 Loss                   3.2926
trainer/QF2 Loss                   2.67441
trainer/Policy Loss              117.838
trainer/Q1 Predictions Mean     -116.507
trainer/Q1 Predictions Std        61.5299
trainer/Q1 Predictions Max       -11.437
trainer/Q1 Predictions Min      -230.462
trainer/Q2 Predictions Mean     -116.681
trainer/Q2 Predictions Std        61.5331
trainer/Q2 Predictions Max       -11.6147
trainer/Q2 Predictions Min      -230.518
trainer/Q Targets Mean          -117.709
trainer/Q Targets Std             62.376
trainer/Q Targets Max            -11.4637
trainer/Q Targets Min           -232.847
trainer/Log Pis Mean               1.93842
trainer/Log Pis Std                1.32337
trainer/Log Pis Max                7.09935
trainer/Log Pis Min               -2.67704
trainer/Policy mu Mean            -0.00725023
trainer/Policy mu Std              0.677983
trainer/Policy mu Max              1.97308
trainer/Policy mu Min             -2.96477
trainer/Policy log std Mean       -2.00837
trainer/Policy log std Std         0.415329
trainer/Policy log std Max        -0.341844
trainer/Policy log std Min        -2.84244
trainer/Alpha                      0.0617291
trainer/Alpha Loss                -0.171514
exploration/num steps total    19200
exploration/num paths total      192
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -3.33253
exploration/Rewards Std            2.41399
exploration/Rewards Max           -0.0235269
exploration/Rewards Min          -10.8581
exploration/Returns Mean        -333.253
exploration/Returns Std          224.493
exploration/Returns Max          -41.1637
exploration/Returns Min         -521.308
exploration/Actions Mean           0.0289177
exploration/Actions Std            0.237937
exploration/Actions Max            0.99877
exploration/Actions Min           -0.999123
exploration/Num Paths              5
exploration/Average Returns     -333.253
evaluation/num steps total     57000
evaluation/num paths total       570
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -3.35848
evaluation/Rewards Std             2.1991
evaluation/Rewards Max            -0.688888
evaluation/Rewards Min            -8.71663
evaluation/Returns Mean         -335.848
evaluation/Returns Std           208.97
evaluation/Returns Max          -102.065
evaluation/Returns Min          -699.1
evaluation/Actions Mean            0.0128537
evaluation/Actions Std             0.183912
evaluation/Actions Max             0.998897
evaluation/Actions Min            -0.99568
evaluation/Num Paths              15
evaluation/Average Returns      -335.848
time/data storing (s)              0.00293709
time/evaluation sampling (s)       0.331755
time/exploration sampling (s)      0.140642
time/logging (s)                   0.00489693
time/saving (s)                    0.00193414
time/training (s)                  1.94742
time/epoch (s)                     2.42959
time/total (s)                    92.5704
Epoch                             37
-----------------------------  --------------
2019-04-23 01:15:05.743998 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 38 finished
-----------------------------  --------------
replay_buffer/size             19700
trainer/QF1 Loss                  52.3025
trainer/QF2 Loss                  52.6181
trainer/Policy Loss              121.256
trainer/Q1 Predictions Mean     -120.251
trainer/Q1 Predictions Std        57.9323
trainer/Q1 Predictions Max       -11.4252
trainer/Q1 Predictions Min      -232.512
trainer/Q2 Predictions Mean     -120.183
trainer/Q2 Predictions Std        57.966
trainer/Q2 Predictions Max       -11.6342
trainer/Q2 Predictions Min      -232.391
trainer/Q Targets Mean          -121.225
trainer/Q Targets Std             59.6055
trainer/Q Targets Max             -1.76637
trainer/Q Targets Min           -236.495
trainer/Log Pis Mean               1.86434
trainer/Log Pis Std                1.25962
trainer/Log Pis Max                5.21772
trainer/Log Pis Min               -0.894648
trainer/Policy mu Mean             0.163197
trainer/Policy mu Std              0.712657
trainer/Policy mu Max              2.46988
trainer/Policy mu Min             -3.58014
trainer/Policy log std Mean       -2.00836
trainer/Policy log std Std         0.469589
trainer/Policy log std Max        -0.428072
trainer/Policy log std Min        -2.88504
trainer/Alpha                      0.0614694
trainer/Alpha Loss                -0.378398
exploration/num steps total    19700
exploration/num paths total      197
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -3.38665
exploration/Rewards Std            1.78923
exploration/Rewards Max           -0.034525
exploration/Rewards Min           -7.9804
exploration/Returns Mean        -338.665
exploration/Returns Std          171.598
exploration/Returns Max          -43.3612
exploration/Returns Min         -542.528
exploration/Actions Mean          -0.00350265
exploration/Actions Std            0.221918
exploration/Actions Max            0.994087
exploration/Actions Min           -0.996206
exploration/Num Paths              5
exploration/Average Returns     -338.665
evaluation/num steps total     58500
evaluation/num paths total       585
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.68561
evaluation/Rewards Std             1.56322
evaluation/Rewards Max            -0.400412
evaluation/Rewards Min           -10.3408
evaluation/Returns Mean         -268.561
evaluation/Returns Std           142.806
evaluation/Returns Max           -61.8195
evaluation/Returns Min          -549.504
evaluation/Actions Mean            0.0149496
evaluation/Actions Std             0.162426
evaluation/Actions Max             0.997615
evaluation/Actions Min            -0.988906
evaluation/Num Paths              15
evaluation/Average Returns      -268.561
time/data storing (s)              0.00302852
time/evaluation sampling (s)       0.333092
time/exploration sampling (s)      0.139043
time/logging (s)                   0.00427356
time/saving (s)                    0.00195575
time/training (s)                  1.94564
time/epoch (s)                     2.42703
time/total (s)                    95.0018
Epoch                             38
-----------------------------  --------------
2019-04-23 01:15:08.176553 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 39 finished
-----------------------------  --------------
replay_buffer/size             20200
trainer/QF1 Loss                 111.677
trainer/QF2 Loss                 110.772
trainer/Policy Loss              124.476
trainer/Q1 Predictions Mean     -123.441
trainer/Q1 Predictions Std        65.8708
trainer/Q1 Predictions Max       -11.1471
trainer/Q1 Predictions Min      -238.007
trainer/Q2 Predictions Mean     -123.454
trainer/Q2 Predictions Std        65.9009
trainer/Q2 Predictions Max       -11.246
trainer/Q2 Predictions Min      -238.03
trainer/Q Targets Mean          -123.594
trainer/Q Targets Std             67.4351
trainer/Q Targets Max             -3.31101
trainer/Q Targets Min           -239.855
trainer/Log Pis Mean               1.90432
trainer/Log Pis Std                1.38859
trainer/Log Pis Max                7.90255
trainer/Log Pis Min               -1.63256
trainer/Policy mu Mean            -0.0361463
trainer/Policy mu Std              0.741753
trainer/Policy mu Max              2.74021
trainer/Policy mu Min             -3.60648
trainer/Policy log std Mean       -1.96239
trainer/Policy log std Std         0.449423
trainer/Policy log std Max        -0.279649
trainer/Policy log std Min        -2.92339
trainer/Alpha                      0.0613127
trainer/Alpha Loss                -0.267107
exploration/num steps total    20200
exploration/num paths total      202
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -3.64589
exploration/Rewards Std            2.64701
exploration/Rewards Max           -0.0651746
exploration/Rewards Min           -9.69039
exploration/Returns Mean        -364.589
exploration/Returns Std          245.943
exploration/Returns Max          -72.1504
exploration/Returns Min         -698.923
exploration/Actions Mean           0.0212776
exploration/Actions Std            0.233405
exploration/Actions Max            0.998687
exploration/Actions Min           -0.997441
exploration/Num Paths              5
exploration/Average Returns     -364.589
evaluation/num steps total     60000
evaluation/num paths total       600
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.80765
evaluation/Rewards Std             1.62293
evaluation/Rewards Max            -0.0448955
evaluation/Rewards Min            -9.05403
evaluation/Returns Mean         -180.765
evaluation/Returns Std           145.352
evaluation/Returns Max           -15.6641
evaluation/Returns Min          -484.034
evaluation/Actions Mean            0.0140975
evaluation/Actions Std             0.164437
evaluation/Actions Max             0.997188
evaluation/Actions Min            -0.99857
evaluation/Num Paths              15
evaluation/Average Returns      -180.765
time/data storing (s)              0.00311266
time/evaluation sampling (s)       0.329216
time/exploration sampling (s)      0.144033
time/logging (s)                   0.00475266
time/saving (s)                    0.00155925
time/training (s)                  1.94558
time/epoch (s)                     2.42825
time/total (s)                    97.434
Epoch                             39
-----------------------------  --------------
2019-04-23 01:15:10.611020 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 40 finished
-----------------------------  --------------
replay_buffer/size             20700
trainer/QF1 Loss                  61.4624
trainer/QF2 Loss                  60.538
trainer/Policy Loss              113.103
trainer/Q1 Predictions Mean     -112.056
trainer/Q1 Predictions Std        57.8226
trainer/Q1 Predictions Max       -11.8391
trainer/Q1 Predictions Min      -241.204
trainer/Q2 Predictions Mean     -111.996
trainer/Q2 Predictions Std        57.894
trainer/Q2 Predictions Max       -11.9408
trainer/Q2 Predictions Min      -241.292
trainer/Q Targets Mean          -111.876
trainer/Q Targets Std             59.0984
trainer/Q Targets Max             -4.72615
trainer/Q Targets Min           -243.073
trainer/Log Pis Mean               2.24508
trainer/Log Pis Std                1.56421
trainer/Log Pis Max                7.30764
trainer/Log Pis Min               -2.17826
trainer/Policy mu Mean            -0.0164671
trainer/Policy mu Std              0.905222
trainer/Policy mu Max              3.47806
trainer/Policy mu Min             -3.76217
trainer/Policy log std Mean       -1.97711
trainer/Policy log std Std         0.583085
trainer/Policy log std Max        -0.0708465
trainer/Policy log std Min        -2.90917
trainer/Alpha                      0.0608327
trainer/Alpha Loss                 0.686175
exploration/num steps total    20700
exploration/num paths total      207
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -4.50654
exploration/Rewards Std            1.91203
exploration/Rewards Max           -1.88697
exploration/Rewards Min           -9.75257
exploration/Returns Mean        -450.654
exploration/Returns Std          184.795
exploration/Returns Max         -223.719
exploration/Returns Min         -743.388
exploration/Actions Mean           0.00217142
exploration/Actions Std            0.225328
exploration/Actions Max            0.999878
exploration/Actions Min           -0.99623
exploration/Num Paths              5
exploration/Average Returns     -450.654
evaluation/num steps total     61500
evaluation/num paths total       615
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.8401
evaluation/Rewards Std             1.97501
evaluation/Rewards Max            -0.0285122
evaluation/Rewards Min           -10.3071
evaluation/Returns Mean         -284.01
evaluation/Returns Std           180.985
evaluation/Returns Max           -57.9035
evaluation/Returns Min          -512.689
evaluation/Actions Mean            0.00736369
evaluation/Actions Std             0.191435
evaluation/Actions Max             0.998808
evaluation/Actions Min            -0.989776
evaluation/Num Paths              15
evaluation/Average Returns      -284.01
time/data storing (s)              0.00296703
time/evaluation sampling (s)       0.328535
time/exploration sampling (s)      0.139536
time/logging (s)                   0.00475149
time/saving (s)                    0.00191717
time/training (s)                  1.95123
time/epoch (s)                     2.42893
time/total (s)                    99.8673
Epoch                             40
-----------------------------  --------------
2019-04-23 01:15:13.060971 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 41 finished
-----------------------------  --------------
replay_buffer/size             21200
trainer/QF1 Loss                   3.75988
trainer/QF2 Loss                   3.82253
trainer/Policy Loss              118.125
trainer/Q1 Predictions Mean     -116.923
trainer/Q1 Predictions Std        63.8392
trainer/Q1 Predictions Max       -12.2624
trainer/Q1 Predictions Min      -243.439
trainer/Q2 Predictions Mean     -116.906
trainer/Q2 Predictions Std        63.8342
trainer/Q2 Predictions Max       -12.1317
trainer/Q2 Predictions Min      -243.707
trainer/Q Targets Mean          -118.201
trainer/Q Targets Std             64.8223
trainer/Q Targets Max            -11.9135
trainer/Q Targets Min           -246.193
trainer/Log Pis Mean               1.88917
trainer/Log Pis Std                1.49528
trainer/Log Pis Max                5.86355
trainer/Log Pis Min               -2.63777
trainer/Policy mu Mean            -0.0793275
trainer/Policy mu Std              0.766504
trainer/Policy mu Max              3.04768
trainer/Policy mu Min             -3.02788
trainer/Policy log std Mean       -1.9465
trainer/Policy log std Std         0.500532
trainer/Policy log std Max        -0.421445
trainer/Policy log std Min        -2.84659
trainer/Alpha                      0.0581964
trainer/Alpha Loss                -0.315156
exploration/num steps total    21200
exploration/num paths total      212
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.65569
exploration/Rewards Std            1.86389
exploration/Rewards Max           -0.140989
exploration/Rewards Min           -7.87168
exploration/Returns Mean        -265.569
exploration/Returns Std          174.832
exploration/Returns Max          -74.0738
exploration/Returns Min         -494.941
exploration/Actions Mean           0.0143955
exploration/Actions Std            0.220942
exploration/Actions Max            0.999293
exploration/Actions Min           -0.988079
exploration/Num Paths              5
exploration/Average Returns     -265.569
evaluation/num steps total     63000
evaluation/num paths total       630
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -4.12511
evaluation/Rewards Std             1.93003
evaluation/Rewards Max            -0.451718
evaluation/Rewards Min           -10.1949
evaluation/Returns Mean         -412.511
evaluation/Returns Std           186.247
evaluation/Returns Max           -78.9068
evaluation/Returns Min          -695.074
evaluation/Actions Mean            0.00928568
evaluation/Actions Std             0.15595
evaluation/Actions Max             0.993966
evaluation/Actions Min            -0.999197
evaluation/Num Paths              15
evaluation/Average Returns      -412.511
time/data storing (s)              0.00301195
time/evaluation sampling (s)       0.333659
time/exploration sampling (s)      0.136256
time/logging (s)                   0.00479633
time/saving (s)                    0.00922204
time/training (s)                  1.95757
time/epoch (s)                     2.44451
time/total (s)                   102.316
Epoch                             41
-----------------------------  --------------
2019-04-23 01:15:15.506136 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 42 finished
-----------------------------  --------------
replay_buffer/size             21700
trainer/QF1 Loss                 710.428
trainer/QF2 Loss                 711.926
trainer/Policy Loss              116.993
trainer/Q1 Predictions Mean     -115.608
trainer/Q1 Predictions Std        63.6519
trainer/Q1 Predictions Max       -11.7899
trainer/Q1 Predictions Min      -246.189
trainer/Q2 Predictions Mean     -115.556
trainer/Q2 Predictions Std        63.7055
trainer/Q2 Predictions Max       -11.8904
trainer/Q2 Predictions Min      -246.132
trainer/Q Targets Mean          -113.917
trainer/Q Targets Std             65.9171
trainer/Q Targets Max             -1.72315
trainer/Q Targets Min           -250.705
trainer/Log Pis Mean               2.11108
trainer/Log Pis Std                1.40391
trainer/Log Pis Max                6.52322
trainer/Log Pis Min               -5.48916
trainer/Policy mu Mean             0.0388306
trainer/Policy mu Std              0.664374
trainer/Policy mu Max              3.2255
trainer/Policy mu Min             -2.91066
trainer/Policy log std Mean       -2.11505
trainer/Policy log std Std         0.444319
trainer/Policy log std Max        -0.463882
trainer/Policy log std Min        -2.91198
trainer/Alpha                      0.0582712
trainer/Alpha Loss                 0.315775
exploration/num steps total    21700
exploration/num paths total      217
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.0991
exploration/Rewards Std            1.00041
exploration/Rewards Max           -0.0805127
exploration/Rewards Min           -8.34864
exploration/Returns Mean        -109.91
exploration/Returns Std           46.8464
exploration/Returns Max          -65.9351
exploration/Returns Min         -188.703
exploration/Actions Mean           0.0119493
exploration/Actions Std            0.212667
exploration/Actions Max            0.997455
exploration/Actions Min           -0.999771
exploration/Num Paths              5
exploration/Average Returns     -109.91
evaluation/num steps total     64500
evaluation/num paths total       645
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.92065
evaluation/Rewards Std             1.86961
evaluation/Rewards Max            -0.244807
evaluation/Rewards Min           -10.7643
evaluation/Returns Mean         -292.065
evaluation/Returns Std           172.605
evaluation/Returns Max           -59.7115
evaluation/Returns Min          -678.898
evaluation/Actions Mean            0.0154637
evaluation/Actions Std             0.163015
evaluation/Actions Max             0.999063
evaluation/Actions Min            -0.991317
evaluation/Num Paths              15
evaluation/Average Returns      -292.065
time/data storing (s)              0.00295553
time/evaluation sampling (s)       0.32737
time/exploration sampling (s)      0.142853
time/logging (s)                   0.00477784
time/saving (s)                    0.00195669
time/training (s)                  1.95943
time/epoch (s)                     2.43934
time/total (s)                   104.76
Epoch                             42
-----------------------------  --------------
2019-04-23 01:15:17.944300 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 43 finished
-----------------------------  --------------
replay_buffer/size             22200
trainer/QF1 Loss                   4.86105
trainer/QF2 Loss                   4.78058
trainer/Policy Loss              120.805
trainer/Q1 Predictions Mean     -119.673
trainer/Q1 Predictions Std        62.0342
trainer/Q1 Predictions Max       -15.3105
trainer/Q1 Predictions Min      -249.182
trainer/Q2 Predictions Mean     -119.675
trainer/Q2 Predictions Std        62.0251
trainer/Q2 Predictions Max       -15.4757
trainer/Q2 Predictions Min      -249.257
trainer/Q Targets Mean          -121.415
trainer/Q Targets Std             63.0188
trainer/Q Targets Max            -16.2804
trainer/Q Targets Min           -254.287
trainer/Log Pis Mean               2.01563
trainer/Log Pis Std                1.32045
trainer/Log Pis Max                7.33615
trainer/Log Pis Min               -1.7249
trainer/Policy mu Mean            -0.0698388
trainer/Policy mu Std              0.797663
trainer/Policy mu Max              3.42078
trainer/Policy mu Min             -3.61063
trainer/Policy log std Mean       -1.97038
trainer/Policy log std Std         0.547476
trainer/Policy log std Max        -0.0764846
trainer/Policy log std Min        -2.79806
trainer/Alpha                      0.0628778
trainer/Alpha Loss                 0.043231
exploration/num steps total    22200
exploration/num paths total      222
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.51715
exploration/Rewards Std            1.07541
exploration/Rewards Max           -0.0487015
exploration/Rewards Min           -8.75949
exploration/Returns Mean        -151.715
exploration/Returns Std           95.7263
exploration/Returns Max          -45.1261
exploration/Returns Min         -285.954
exploration/Actions Mean           0.0134546
exploration/Actions Std            0.183528
exploration/Actions Max            0.99791
exploration/Actions Min           -0.911463
exploration/Num Paths              5
exploration/Average Returns     -151.715
evaluation/num steps total     66000
evaluation/num paths total       660
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.4859
evaluation/Rewards Std             2.17556
evaluation/Rewards Max            -0.0714011
evaluation/Rewards Min           -10.5969
evaluation/Returns Mean         -248.59
evaluation/Returns Std           200.684
evaluation/Returns Max           -50.7615
evaluation/Returns Min          -796.761
evaluation/Actions Mean            0.00793478
evaluation/Actions Std             0.169692
evaluation/Actions Max             0.998395
evaluation/Actions Min            -0.998571
evaluation/Num Paths              15
evaluation/Average Returns      -248.59
time/data storing (s)              0.00303154
time/evaluation sampling (s)       0.329898
time/exploration sampling (s)      0.139267
time/logging (s)                   0.00477229
time/saving (s)                    0.00195422
time/training (s)                  1.95343
time/epoch (s)                     2.43235
time/total (s)                   107.197
Epoch                             43
-----------------------------  --------------
2019-04-23 01:15:20.395073 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 44 finished
-----------------------------  --------------
replay_buffer/size             22700
trainer/QF1 Loss                 395.195
trainer/QF2 Loss                 396.614
trainer/Policy Loss              122.708
trainer/Q1 Predictions Mean     -121.507
trainer/Q1 Predictions Std        67.386
trainer/Q1 Predictions Max       -13.1709
trainer/Q1 Predictions Min      -252.73
trainer/Q2 Predictions Mean     -121.428
trainer/Q2 Predictions Std        67.3507
trainer/Q2 Predictions Max       -12.9426
trainer/Q2 Predictions Min      -253.001
trainer/Q Targets Mean          -119.969
trainer/Q Targets Std             69.1213
trainer/Q Targets Max             -0.077035
trainer/Q Targets Min           -256.574
trainer/Log Pis Mean               1.95936
trainer/Log Pis Std                1.44672
trainer/Log Pis Max                6.68884
trainer/Log Pis Min               -3.54341
trainer/Policy mu Mean             0.0317805
trainer/Policy mu Std              0.688426
trainer/Policy mu Max              2.92561
trainer/Policy mu Min             -3.48556
trainer/Policy log std Mean       -2.04135
trainer/Policy log std Std         0.573511
trainer/Policy log std Max        -0.325423
trainer/Policy log std Min        -2.98899
trainer/Alpha                      0.0590777
trainer/Alpha Loss                -0.11496
exploration/num steps total    22700
exploration/num paths total      227
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.90626
exploration/Rewards Std            1.22983
exploration/Rewards Max           -0.323625
exploration/Rewards Min           -9.6577
exploration/Returns Mean        -190.626
exploration/Returns Std           92.5848
exploration/Returns Max          -73.956
exploration/Returns Min         -303.555
exploration/Actions Mean           0.0248863
exploration/Actions Std            0.194102
exploration/Actions Max            0.999963
exploration/Actions Min           -0.6464
exploration/Num Paths              5
exploration/Average Returns     -190.626
evaluation/num steps total     67500
evaluation/num paths total       675
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.42352
evaluation/Rewards Std             1.65849
evaluation/Rewards Max            -0.285407
evaluation/Rewards Min           -10.558
evaluation/Returns Mean         -242.352
evaluation/Returns Std           144.668
evaluation/Returns Max           -53.8708
evaluation/Returns Min          -514.758
evaluation/Actions Mean            0.00613842
evaluation/Actions Std             0.184122
evaluation/Actions Max             0.998767
evaluation/Actions Min            -0.997605
evaluation/Num Paths              15
evaluation/Average Returns      -242.352
time/data storing (s)              0.00286057
time/evaluation sampling (s)       0.333164
time/exploration sampling (s)      0.137699
time/logging (s)                   0.00481639
time/saving (s)                    0.00195313
time/training (s)                  1.9645
time/epoch (s)                     2.44499
time/total (s)                   109.646
Epoch                             44
-----------------------------  --------------
2019-04-23 01:15:22.838125 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 45 finished
-----------------------------  --------------
replay_buffer/size             23200
trainer/QF1 Loss                 392.158
trainer/QF2 Loss                 392.534
trainer/Policy Loss              118.614
trainer/Q1 Predictions Mean     -117.232
trainer/Q1 Predictions Std        65.116
trainer/Q1 Predictions Max       -13.1427
trainer/Q1 Predictions Min      -259.118
trainer/Q2 Predictions Mean     -117.258
trainer/Q2 Predictions Std        65.1714
trainer/Q2 Predictions Max       -13.1679
trainer/Q2 Predictions Min      -259.212
trainer/Q Targets Mean          -116.122
trainer/Q Targets Std             65.9385
trainer/Q Targets Max             -4.72492
trainer/Q Targets Min           -260.414
trainer/Log Pis Mean               1.94738
trainer/Log Pis Std                1.11859
trainer/Log Pis Max                6.55483
trainer/Log Pis Min               -1.03703
trainer/Policy mu Mean            -0.236986
trainer/Policy mu Std              0.689859
trainer/Policy mu Max              1.97148
trainer/Policy mu Min             -3.51528
trainer/Policy log std Mean       -1.96824
trainer/Policy log std Std         0.499011
trainer/Policy log std Max        -0.0970574
trainer/Policy log std Min        -3.04475
trainer/Alpha                      0.0580713
trainer/Alpha Loss                -0.149736
exploration/num steps total    23200
exploration/num paths total      232
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.67382
exploration/Rewards Std            1.81551
exploration/Rewards Max           -0.0346076
exploration/Rewards Min           -7.08238
exploration/Returns Mean        -267.382
exploration/Returns Std          172.804
exploration/Returns Max         -105.903
exploration/Returns Min         -599.164
exploration/Actions Mean           0.0184599
exploration/Actions Std            0.234265
exploration/Actions Max            0.998359
exploration/Actions Min           -0.9694
exploration/Num Paths              5
exploration/Average Returns     -267.382
evaluation/num steps total     69000
evaluation/num paths total       690
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.61922
evaluation/Rewards Std             1.72558
evaluation/Rewards Max            -0.10216
evaluation/Rewards Min           -10.7403
evaluation/Returns Mean         -261.922
evaluation/Returns Std           157.01
evaluation/Returns Max           -88.1066
evaluation/Returns Min          -609.355
evaluation/Actions Mean            0.0031111
evaluation/Actions Std             0.175246
evaluation/Actions Max             0.996071
evaluation/Actions Min            -0.998272
evaluation/Num Paths              15
evaluation/Average Returns      -261.922
time/data storing (s)              0.00283007
time/evaluation sampling (s)       0.331635
time/exploration sampling (s)      0.140794
time/logging (s)                   0.00479882
time/saving (s)                    0.00195346
time/training (s)                  1.95555
time/epoch (s)                     2.43756
time/total (s)                   112.088
Epoch                             45
-----------------------------  --------------
2019-04-23 01:15:25.260709 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 46 finished
-----------------------------  --------------
replay_buffer/size             23700
trainer/QF1 Loss                 198.933
trainer/QF2 Loss                 198.019
trainer/Policy Loss              116.45
trainer/Q1 Predictions Mean     -115.261
trainer/Q1 Predictions Std        71.0554
trainer/Q1 Predictions Max       -13.4366
trainer/Q1 Predictions Min      -259.455
trainer/Q2 Predictions Mean     -115.28
trainer/Q2 Predictions Std        71.0284
trainer/Q2 Predictions Max       -13.4965
trainer/Q2 Predictions Min      -259.269
trainer/Q Targets Mean          -114.099
trainer/Q Targets Std             73.5013
trainer/Q Targets Max             -2.01118
trainer/Q Targets Min           -260.557
trainer/Log Pis Mean               2.01084
trainer/Log Pis Std                1.52793
trainer/Log Pis Max                7.72815
trainer/Log Pis Min               -4.10091
trainer/Policy mu Mean            -0.00243127
trainer/Policy mu Std              0.70043
trainer/Policy mu Max              2.96512
trainer/Policy mu Min             -2.73831
trainer/Policy log std Mean       -2.08604
trainer/Policy log std Std         0.485838
trainer/Policy log std Max        -0.469287
trainer/Policy log std Min        -3.02692
trainer/Alpha                      0.0602392
trainer/Alpha Loss                 0.0304593
exploration/num steps total    23700
exploration/num paths total      237
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.70683
exploration/Rewards Std            1.84276
exploration/Rewards Max           -0.137979
exploration/Rewards Min           -9.34384
exploration/Returns Mean        -270.683
exploration/Returns Std          169.469
exploration/Returns Max          -33.1018
exploration/Returns Min         -455.938
exploration/Actions Mean           0.00336723
exploration/Actions Std            0.20081
exploration/Actions Max            0.998568
exploration/Actions Min           -0.969438
exploration/Num Paths              5
exploration/Average Returns     -270.683
evaluation/num steps total     70500
evaluation/num paths total       705
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.50369
evaluation/Rewards Std             2.04119
evaluation/Rewards Max            -0.207389
evaluation/Rewards Min           -12.0991
evaluation/Returns Mean         -250.369
evaluation/Returns Std           191.291
evaluation/Returns Max           -33.2592
evaluation/Returns Min          -667.245
evaluation/Actions Mean            0.00887287
evaluation/Actions Std             0.180758
evaluation/Actions Max             0.999422
evaluation/Actions Min            -0.989718
evaluation/Num Paths              15
evaluation/Average Returns      -250.369
time/data storing (s)              0.00301438
time/evaluation sampling (s)       0.331488
time/exploration sampling (s)      0.140602
time/logging (s)                   0.00483053
time/saving (s)                    0.00195583
time/training (s)                  1.93488
time/epoch (s)                     2.41677
time/total (s)                   114.509
Epoch                             46
-----------------------------  --------------
2019-04-23 01:15:27.697376 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 47 finished
-----------------------------  --------------
replay_buffer/size             24200
trainer/QF1 Loss                1108.93
trainer/QF2 Loss                1106.71
trainer/Policy Loss              115.749
trainer/Q1 Predictions Mean     -114.262
trainer/Q1 Predictions Std        71.7196
trainer/Q1 Predictions Max       -13.9812
trainer/Q1 Predictions Min      -262.463
trainer/Q2 Predictions Mean     -114.174
trainer/Q2 Predictions Std        71.6681
trainer/Q2 Predictions Max       -14.0475
trainer/Q2 Predictions Min      -262.597
trainer/Q Targets Mean          -110.736
trainer/Q Targets Std             71.5249
trainer/Q Targets Max             -5.66909
trainer/Q Targets Min           -265.147
trainer/Log Pis Mean               2.0044
trainer/Log Pis Std                1.21703
trainer/Log Pis Max                6.0409
trainer/Log Pis Min               -2.1968
trainer/Policy mu Mean             0.0212633
trainer/Policy mu Std              0.645984
trainer/Policy mu Max              2.934
trainer/Policy mu Min             -2.70766
trainer/Policy log std Mean       -2.05391
trainer/Policy log std Std         0.520918
trainer/Policy log std Max        -0.256349
trainer/Policy log std Min        -3.0825
trainer/Alpha                      0.0618823
trainer/Alpha Loss                 0.0122356
exploration/num steps total    24200
exploration/num paths total      242
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.79762
exploration/Rewards Std            1.01245
exploration/Rewards Max           -0.432899
exploration/Rewards Min           -7.74451
exploration/Returns Mean        -179.762
exploration/Returns Std           73.6362
exploration/Returns Max          -98.7054
exploration/Returns Min         -272.86
exploration/Actions Mean           0.00261694
exploration/Actions Std            0.213013
exploration/Actions Max            0.995417
exploration/Actions Min           -0.999445
exploration/Num Paths              5
exploration/Average Returns     -179.762
evaluation/num steps total     72000
evaluation/num paths total       720
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -3.44541
evaluation/Rewards Std             1.9391
evaluation/Rewards Max            -0.283367
evaluation/Rewards Min            -8.89316
evaluation/Returns Mean         -344.541
evaluation/Returns Std           188.526
evaluation/Returns Max           -73.4502
evaluation/Returns Min          -633.208
evaluation/Actions Mean            0.0103432
evaluation/Actions Std             0.152148
evaluation/Actions Max             0.997529
evaluation/Actions Min            -0.993815
evaluation/Num Paths              15
evaluation/Average Returns      -344.541
time/data storing (s)              0.00293137
time/evaluation sampling (s)       0.332539
time/exploration sampling (s)      0.139595
time/logging (s)                   0.00431962
time/saving (s)                    0.00154701
time/training (s)                  1.94927
time/epoch (s)                     2.4302
time/total (s)                   116.944
Epoch                             47
-----------------------------  --------------
2019-04-23 01:15:30.133313 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 48 finished
-----------------------------  --------------
replay_buffer/size             24700
trainer/QF1 Loss                   4.15573
trainer/QF2 Loss                   4.43323
trainer/Policy Loss              132.142
trainer/Q1 Predictions Mean     -130.936
trainer/Q1 Predictions Std        72.2429
trainer/Q1 Predictions Max       -14.5828
trainer/Q1 Predictions Min      -264.091
trainer/Q2 Predictions Mean     -130.874
trainer/Q2 Predictions Std        72.2285
trainer/Q2 Predictions Max       -14.5722
trainer/Q2 Predictions Min      -264.157
trainer/Q Targets Mean          -132.54
trainer/Q Targets Std             73.188
trainer/Q Targets Max            -15.1307
trainer/Q Targets Min           -268.097
trainer/Log Pis Mean               1.81904
trainer/Log Pis Std                1.44869
trainer/Log Pis Max                4.71573
trainer/Log Pis Min               -2.81821
trainer/Policy mu Mean             0.0555546
trainer/Policy mu Std              0.643372
trainer/Policy mu Max              3.10059
trainer/Policy mu Min             -2.19001
trainer/Policy log std Mean       -1.99032
trainer/Policy log std Std         0.517022
trainer/Policy log std Max        -0.0870209
trainer/Policy log std Min        -3.03057
trainer/Alpha                      0.0640636
trainer/Alpha Loss                -0.497231
exploration/num steps total    24700
exploration/num paths total      247
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.93245
exploration/Rewards Std            1.68873
exploration/Rewards Max           -0.235948
exploration/Rewards Min           -8.60382
exploration/Returns Mean        -193.245
exploration/Returns Std          138.5
exploration/Returns Max          -85.6387
exploration/Returns Min         -462.372
exploration/Actions Mean           0.041253
exploration/Actions Std            0.228497
exploration/Actions Max            0.999157
exploration/Actions Min           -0.567126
exploration/Num Paths              5
exploration/Average Returns     -193.245
evaluation/num steps total     73500
evaluation/num paths total       735
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.2242
evaluation/Rewards Std             2.38623
evaluation/Rewards Max            -0.0951326
evaluation/Rewards Min           -11.019
evaluation/Returns Mean         -222.42
evaluation/Returns Std           221.6
evaluation/Returns Max           -51.9449
evaluation/Returns Min          -709.752
evaluation/Actions Mean           -0.00960918
evaluation/Actions Std             0.170945
evaluation/Actions Max             0.995382
evaluation/Actions Min            -0.999791
evaluation/Num Paths              15
evaluation/Average Returns      -222.42
time/data storing (s)              0.00308898
time/evaluation sampling (s)       0.327621
time/exploration sampling (s)      0.136907
time/logging (s)                   0.00475059
time/saving (s)                    0.00195265
time/training (s)                  1.95613
time/epoch (s)                     2.43045
time/total (s)                   119.379
Epoch                             48
-----------------------------  --------------
2019-04-23 01:15:32.568196 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 49 finished
-----------------------------  --------------
replay_buffer/size             25200
trainer/QF1 Loss                 261.784
trainer/QF2 Loss                 265.321
trainer/Policy Loss              120.577
trainer/Q1 Predictions Mean     -119.33
trainer/Q1 Predictions Std        75.7507
trainer/Q1 Predictions Max       -14.9376
trainer/Q1 Predictions Min      -268.842
trainer/Q2 Predictions Mean     -119.395
trainer/Q2 Predictions Std        75.7676
trainer/Q2 Predictions Max       -14.7522
trainer/Q2 Predictions Min      -269.074
trainer/Q Targets Mean          -117.8
trainer/Q Targets Std             77.3396
trainer/Q Targets Max             -0.928087
trainer/Q Targets Min           -270.546
trainer/Log Pis Mean               1.78705
trainer/Log Pis Std                1.48066
trainer/Log Pis Max                6.94477
trainer/Log Pis Min               -2.66724
trainer/Policy mu Mean            -0.019625
trainer/Policy mu Std              0.691434
trainer/Policy mu Max              2.39766
trainer/Policy mu Min             -3.46902
trainer/Policy log std Mean       -1.98995
trainer/Policy log std Std         0.506405
trainer/Policy log std Max        -0.429399
trainer/Policy log std Min        -2.98131
trainer/Alpha                      0.0674527
trainer/Alpha Loss                -0.574154
exploration/num steps total    25200
exploration/num paths total      252
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.46696
exploration/Rewards Std            1.53835
exploration/Rewards Max           -0.239916
exploration/Rewards Min           -8.89972
exploration/Returns Mean        -246.696
exploration/Returns Std          140.823
exploration/Returns Max          -54.9221
exploration/Returns Min         -490.102
exploration/Actions Mean           0.00912269
exploration/Actions Std            0.209856
exploration/Actions Max            0.999653
exploration/Actions Min           -0.998633
exploration/Num Paths              5
exploration/Average Returns     -246.696
evaluation/num steps total     75000
evaluation/num paths total       750
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.65256
evaluation/Rewards Std             1.55588
evaluation/Rewards Max            -0.0131044
evaluation/Rewards Min            -9.47248
evaluation/Returns Mean         -165.256
evaluation/Returns Std           139.851
evaluation/Returns Max           -39.8714
evaluation/Returns Min          -482.473
evaluation/Actions Mean            0.00103556
evaluation/Actions Std             0.157045
evaluation/Actions Max             0.995659
evaluation/Actions Min            -0.999443
evaluation/Num Paths              15
evaluation/Average Returns      -165.256
time/data storing (s)              0.00290061
time/evaluation sampling (s)       0.330552
time/exploration sampling (s)      0.137617
time/logging (s)                   0.00475286
time/saving (s)                    0.00192423
time/training (s)                  1.95122
time/epoch (s)                     2.42897
time/total (s)                   121.813
Epoch                             49
-----------------------------  --------------
2019-04-23 01:15:35.012855 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 50 finished
-----------------------------  --------------
replay_buffer/size             25700
trainer/QF1 Loss                  90.2665
trainer/QF2 Loss                  89.8798
trainer/Policy Loss              113.527
trainer/Q1 Predictions Mean     -112.113
trainer/Q1 Predictions Std        73.8708
trainer/Q1 Predictions Max       -15.0436
trainer/Q1 Predictions Min      -269.286
trainer/Q2 Predictions Mean     -112.097
trainer/Q2 Predictions Std        73.812
trainer/Q2 Predictions Max       -15.0162
trainer/Q2 Predictions Min      -269.101
trainer/Q Targets Mean          -112.291
trainer/Q Targets Std             75.2127
trainer/Q Targets Max             -2.3055
trainer/Q Targets Min           -271.147
trainer/Log Pis Mean               1.83649
trainer/Log Pis Std                1.18024
trainer/Log Pis Max                5.95318
trainer/Log Pis Min               -1.29322
trainer/Policy mu Mean            -0.036365
trainer/Policy mu Std              0.673842
trainer/Policy mu Max              3.35251
trainer/Policy mu Min             -3.3306
trainer/Policy log std Mean       -1.93652
trainer/Policy log std Std         0.512517
trainer/Policy log std Max        -0.17699
trainer/Policy log std Min        -3.0507
trainer/Alpha                      0.064479
trainer/Alpha Loss                -0.448223
exploration/num steps total    25700
exploration/num paths total      257
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -3.24716
exploration/Rewards Std            1.64309
exploration/Rewards Max           -0.779209
exploration/Rewards Min           -9.85033
exploration/Returns Mean        -324.716
exploration/Returns Std          146.822
exploration/Returns Max         -120.646
exploration/Returns Min         -507.225
exploration/Actions Mean           0.00522809
exploration/Actions Std            0.229558
exploration/Actions Max            0.997719
exploration/Actions Min           -0.998517
exploration/Num Paths              5
exploration/Average Returns     -324.716
evaluation/num steps total     76500
evaluation/num paths total       765
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -3.15176
evaluation/Rewards Std             2.50667
evaluation/Rewards Max            -0.230596
evaluation/Rewards Min            -9.07526
evaluation/Returns Mean         -315.176
evaluation/Returns Std           244.3
evaluation/Returns Max           -54.5511
evaluation/Returns Min          -767.058
evaluation/Actions Mean            0.0131591
evaluation/Actions Std             0.159498
evaluation/Actions Max             0.997908
evaluation/Actions Min            -0.988387
evaluation/Num Paths              15
evaluation/Average Returns      -315.176
time/data storing (s)              0.00306017
time/evaluation sampling (s)       0.333639
time/exploration sampling (s)      0.136868
time/logging (s)                   0.00474915
time/saving (s)                    0.00157214
time/training (s)                  1.95888
time/epoch (s)                     2.43877
time/total (s)                   124.256
Epoch                             50
-----------------------------  --------------
2019-04-23 01:15:37.460076 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 51 finished
-----------------------------  --------------
replay_buffer/size             26200
trainer/QF1 Loss                   3.82208
trainer/QF2 Loss                   3.6965
trainer/Policy Loss              113.864
trainer/Q1 Predictions Mean     -112.43
trainer/Q1 Predictions Std        70.2707
trainer/Q1 Predictions Max       -15.3704
trainer/Q1 Predictions Min      -274.191
trainer/Q2 Predictions Mean     -112.442
trainer/Q2 Predictions Std        70.2768
trainer/Q2 Predictions Max       -15.3419
trainer/Q2 Predictions Min      -273.686
trainer/Q Targets Mean          -113.113
trainer/Q Targets Std             70.8348
trainer/Q Targets Max             -0.794022
trainer/Q Targets Min           -274.807
trainer/Log Pis Mean               2.01254
trainer/Log Pis Std                1.21321
trainer/Log Pis Max                5.2885
trainer/Log Pis Min               -1.43681
trainer/Policy mu Mean             0.06875
trainer/Policy mu Std              0.709551
trainer/Policy mu Max              2.9382
trainer/Policy mu Min             -2.99323
trainer/Policy log std Mean       -2.06163
trainer/Policy log std Std         0.535975
trainer/Policy log std Max         0.0991949
trainer/Policy log std Min        -2.95328
trainer/Alpha                      0.0642933
trainer/Alpha Loss                 0.0344263
exploration/num steps total    26200
exploration/num paths total      262
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.69389
exploration/Rewards Std            2.6204
exploration/Rewards Max           -0.159659
exploration/Rewards Min           -9.23565
exploration/Returns Mean        -269.389
exploration/Returns Std          255.596
exploration/Returns Max          -66.2079
exploration/Returns Min         -747.533
exploration/Actions Mean           0.0150708
exploration/Actions Std            0.242596
exploration/Actions Max            0.998232
exploration/Actions Min           -0.988591
exploration/Num Paths              5
exploration/Average Returns     -269.389
evaluation/num steps total     78000
evaluation/num paths total       780
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.29475
evaluation/Rewards Std             2.29953
evaluation/Rewards Max            -0.384953
evaluation/Rewards Min            -9.72357
evaluation/Returns Mean         -229.475
evaluation/Returns Std           210.061
evaluation/Returns Max           -48.0677
evaluation/Returns Min          -748.525
evaluation/Actions Mean            0.00757061
evaluation/Actions Std             0.185967
evaluation/Actions Max             0.99914
evaluation/Actions Min            -0.999824
evaluation/Num Paths              15
evaluation/Average Returns      -229.475
time/data storing (s)              0.00306116
time/evaluation sampling (s)       0.334386
time/exploration sampling (s)      0.136563
time/logging (s)                   0.00481792
time/saving (s)                    0.00193909
time/training (s)                  1.96055
time/epoch (s)                     2.44132
time/total (s)                   126.702
Epoch                             51
-----------------------------  --------------
2019-04-23 01:15:39.898334 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 52 finished
-----------------------------  --------------
replay_buffer/size             26700
trainer/QF1 Loss                 499.039
trainer/QF2 Loss                 499.535
trainer/Policy Loss              119.91
trainer/Q1 Predictions Mean     -118.622
trainer/Q1 Predictions Std        71.037
trainer/Q1 Predictions Max       -16.0544
trainer/Q1 Predictions Min      -269.884
trainer/Q2 Predictions Mean     -118.609
trainer/Q2 Predictions Std        71.0233
trainer/Q2 Predictions Max       -16.1317
trainer/Q2 Predictions Min      -269.801
trainer/Q Targets Mean          -117.455
trainer/Q Targets Std             73.766
trainer/Q Targets Max             -0.464215
trainer/Q Targets Min           -275.446
trainer/Log Pis Mean               1.94
trainer/Log Pis Std                1.11664
trainer/Log Pis Max                4.02428
trainer/Log Pis Min               -1.22965
trainer/Policy mu Mean            -0.0738884
trainer/Policy mu Std              0.617496
trainer/Policy mu Max              1.93018
trainer/Policy mu Min             -3.48163
trainer/Policy log std Mean       -2.1063
trainer/Policy log std Std         0.494387
trainer/Policy log std Max        -0.12834
trainer/Policy log std Min        -3.04023
trainer/Alpha                      0.0622629
trainer/Alpha Loss                -0.166601
exploration/num steps total    26700
exploration/num paths total      267
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.80516
exploration/Rewards Std            1.72777
exploration/Rewards Max           -0.290154
exploration/Rewards Min           -7.09896
exploration/Returns Mean        -280.516
exploration/Returns Std          167.602
exploration/Returns Max          -66.0255
exploration/Returns Min         -488.85
exploration/Actions Mean           0.0116534
exploration/Actions Std            0.224673
exploration/Actions Max            0.999693
exploration/Actions Min           -0.990589
exploration/Num Paths              5
exploration/Average Returns     -280.516
evaluation/num steps total     79500
evaluation/num paths total       795
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.26691
evaluation/Rewards Std             2.19053
evaluation/Rewards Max            -0.342932
evaluation/Rewards Min           -10.9827
evaluation/Returns Mean         -226.691
evaluation/Returns Std           204.07
evaluation/Returns Max           -48.7712
evaluation/Returns Min          -640.265
evaluation/Actions Mean            0.0098394
evaluation/Actions Std             0.169419
evaluation/Actions Max             0.997762
evaluation/Actions Min            -0.994556
evaluation/Num Paths              15
evaluation/Average Returns      -226.691
time/data storing (s)              0.00284481
time/evaluation sampling (s)       0.33046
time/exploration sampling (s)      0.137903
time/logging (s)                   0.0047531
time/saving (s)                    0.00191537
time/training (s)                  1.95441
time/epoch (s)                     2.43228
time/total (s)                   129.139
Epoch                             52
-----------------------------  --------------
2019-04-23 01:15:42.365789 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 53 finished
-----------------------------  --------------
replay_buffer/size             27200
trainer/QF1 Loss                   6.63196
trainer/QF2 Loss                   6.84435
trainer/Policy Loss              128.365
trainer/Q1 Predictions Mean     -126.851
trainer/Q1 Predictions Std        70.9516
trainer/Q1 Predictions Max       -16.194
trainer/Q1 Predictions Min      -272.289
trainer/Q2 Predictions Mean     -126.799
trainer/Q2 Predictions Std        70.9424
trainer/Q2 Predictions Max       -16.0938
trainer/Q2 Predictions Min      -272.464
trainer/Q Targets Mean          -128.928
trainer/Q Targets Std             72.1064
trainer/Q Targets Max            -16.051
trainer/Q Targets Min           -276.799
trainer/Log Pis Mean               2.27386
trainer/Log Pis Std                1.58458
trainer/Log Pis Max                8.35596
trainer/Log Pis Min               -2.53163
trainer/Policy mu Mean            -0.0314082
trainer/Policy mu Std              0.813959
trainer/Policy mu Max              2.58703
trainer/Policy mu Min             -4.04294
trainer/Policy log std Mean       -2.11013
trainer/Policy log std Std         0.580687
trainer/Policy log std Max        -0.0552753
trainer/Policy log std Min        -3.04976
trainer/Alpha                      0.0621561
trainer/Alpha Loss                 0.760811
exploration/num steps total    27200
exploration/num paths total      272
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.85381
exploration/Rewards Std            1.33754
exploration/Rewards Max           -0.965345
exploration/Rewards Min           -7.82953
exploration/Returns Mean        -285.381
exploration/Returns Std          116.972
exploration/Returns Max         -161.392
exploration/Returns Min         -498.675
exploration/Actions Mean           0.0151102
exploration/Actions Std            0.196778
exploration/Actions Max            0.999003
exploration/Actions Min           -0.999262
exploration/Num Paths              5
exploration/Average Returns     -285.381
evaluation/num steps total     81000
evaluation/num paths total       810
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -3.09817
evaluation/Rewards Std             2.32211
evaluation/Rewards Max            -0.0530147
evaluation/Rewards Min            -9.64259
evaluation/Returns Mean         -309.817
evaluation/Returns Std           224.013
evaluation/Returns Max           -67.1188
evaluation/Returns Min          -662.046
evaluation/Actions Mean            0.0114907
evaluation/Actions Std             0.180195
evaluation/Actions Max             0.997807
evaluation/Actions Min            -0.996406
evaluation/Num Paths              15
evaluation/Average Returns      -309.817
time/data storing (s)              0.00311063
time/evaluation sampling (s)       0.334557
time/exploration sampling (s)      0.141865
time/logging (s)                   0.00479244
time/saving (s)                    0.00193814
time/training (s)                  1.97526
time/epoch (s)                     2.46153
time/total (s)                   131.605
Epoch                             53
-----------------------------  --------------
2019-04-23 01:15:44.798159 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 54 finished
-----------------------------  ---------------
replay_buffer/size             27700
trainer/QF1 Loss                   3.4605
trainer/QF2 Loss                   3.28119
trainer/Policy Loss              117.585
trainer/Q1 Predictions Mean     -116.226
trainer/Q1 Predictions Std        64.6302
trainer/Q1 Predictions Max       -16.7695
trainer/Q1 Predictions Min      -277.541
trainer/Q2 Predictions Mean     -116.318
trainer/Q2 Predictions Std        64.64
trainer/Q2 Predictions Max       -16.4038
trainer/Q2 Predictions Min      -277.807
trainer/Q Targets Mean          -117.546
trainer/Q Targets Std             65.5319
trainer/Q Targets Max            -16.453
trainer/Q Targets Min           -280.993
trainer/Log Pis Mean               1.87446
trainer/Log Pis Std                1.24219
trainer/Log Pis Max                4.96592
trainer/Log Pis Min               -2.51944
trainer/Policy mu Mean            -0.0356699
trainer/Policy mu Std              0.598253
trainer/Policy mu Max              2.51688
trainer/Policy mu Min             -2.64478
trainer/Policy log std Mean       -2.12081
trainer/Policy log std Std         0.475495
trainer/Policy log std Max        -0.266973
trainer/Policy log std Min        -2.9685
trainer/Alpha                      0.0636267
trainer/Alpha Loss                -0.345806
exploration/num steps total    27700
exploration/num paths total      277
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -3.39219
exploration/Rewards Std            1.45469
exploration/Rewards Max           -1.07066
exploration/Rewards Min           -7.01731
exploration/Returns Mean        -339.219
exploration/Returns Std          138.283
exploration/Returns Max         -149.926
exploration/Returns Min         -520.644
exploration/Actions Mean           0.0166043
exploration/Actions Std            0.201308
exploration/Actions Max            0.996376
exploration/Actions Min           -0.984879
exploration/Num Paths              5
exploration/Average Returns     -339.219
evaluation/num steps total     82500
evaluation/num paths total       825
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.12688
evaluation/Rewards Std             1.39949
evaluation/Rewards Max            -0.259171
evaluation/Rewards Min           -10.0064
evaluation/Returns Mean         -212.688
evaluation/Returns Std           124.681
evaluation/Returns Max           -73.1788
evaluation/Returns Min          -488.472
evaluation/Actions Mean           -0.000339363
evaluation/Actions Std             0.153963
evaluation/Actions Max             0.997983
evaluation/Actions Min            -0.994044
evaluation/Num Paths              15
evaluation/Average Returns      -212.688
time/data storing (s)              0.00301346
time/evaluation sampling (s)       0.32487
time/exploration sampling (s)      0.139718
time/logging (s)                   0.0036647
time/saving (s)                    0.00195014
time/training (s)                  1.95206
time/epoch (s)                     2.42528
time/total (s)                   134.035
Epoch                             54
-----------------------------  ---------------
2019-04-23 01:15:47.239926 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 55 finished
-----------------------------  --------------
replay_buffer/size             28200
trainer/QF1 Loss                 521.639
trainer/QF2 Loss                 524.827
trainer/Policy Loss              115.417
trainer/Q1 Predictions Mean     -114.326
trainer/Q1 Predictions Std        70.0777
trainer/Q1 Predictions Max       -17.1557
trainer/Q1 Predictions Min      -280.421
trainer/Q2 Predictions Mean     -114.309
trainer/Q2 Predictions Std        70.085
trainer/Q2 Predictions Max       -16.9937
trainer/Q2 Predictions Min      -280.655
trainer/Q Targets Mean          -112.56
trainer/Q Targets Std             71.7971
trainer/Q Targets Max             -5.00943
trainer/Q Targets Min           -283.795
trainer/Log Pis Mean               1.54852
trainer/Log Pis Std                1.41181
trainer/Log Pis Max                6.35028
trainer/Log Pis Min               -3.24677
trainer/Policy mu Mean            -0.0185674
trainer/Policy mu Std              0.743213
trainer/Policy mu Max              3.64593
trainer/Policy mu Min             -3.44343
trainer/Policy log std Mean       -1.81638
trainer/Policy log std Std         0.465023
trainer/Policy log std Max        -0.0628442
trainer/Policy log std Min        -2.85534
trainer/Alpha                      0.0635153
trainer/Alpha Loss                -1.24421
exploration/num steps total    28200
exploration/num paths total      282
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.01549
exploration/Rewards Std            1.72275
exploration/Rewards Max           -0.167079
exploration/Rewards Min           -6.53435
exploration/Returns Mean        -201.549
exploration/Returns Std          165.438
exploration/Returns Max          -45.8577
exploration/Returns Min         -492.578
exploration/Actions Mean           0.010209
exploration/Actions Std            0.22727
exploration/Actions Max            0.986892
exploration/Actions Min           -0.952712
exploration/Num Paths              5
exploration/Average Returns     -201.549
evaluation/num steps total     84000
evaluation/num paths total       840
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.15609
evaluation/Rewards Std             1.7002
evaluation/Rewards Max            -0.218853
evaluation/Rewards Min           -10.2401
evaluation/Returns Mean         -215.609
evaluation/Returns Std           150.811
evaluation/Returns Max           -70.4129
evaluation/Returns Min          -503.139
evaluation/Actions Mean            0.0102245
evaluation/Actions Std             0.164597
evaluation/Actions Max             0.998309
evaluation/Actions Min            -0.998909
evaluation/Num Paths              15
evaluation/Average Returns      -215.609
time/data storing (s)              0.00345583
time/evaluation sampling (s)       0.327588
time/exploration sampling (s)      0.138425
time/logging (s)                   0.00478914
time/saving (s)                    0.00175775
time/training (s)                  1.9607
time/epoch (s)                     2.43671
time/total (s)                   136.476
Epoch                             55
-----------------------------  --------------
2019-04-23 01:15:49.682030 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 56 finished
-----------------------------  --------------
replay_buffer/size             28700
trainer/QF1 Loss                 649.514
trainer/QF2 Loss                 646.98
trainer/Policy Loss              107.282
trainer/Q1 Predictions Mean     -106.115
trainer/Q1 Predictions Std        72.4996
trainer/Q1 Predictions Max       -17.589
trainer/Q1 Predictions Min      -279.273
trainer/Q2 Predictions Mean     -106.197
trainer/Q2 Predictions Std        72.5407
trainer/Q2 Predictions Max       -17.5529
trainer/Q2 Predictions Min      -279.328
trainer/Q Targets Mean          -103.877
trainer/Q Targets Std             73.9053
trainer/Q Targets Max             -2.76402
trainer/Q Targets Min           -283.147
trainer/Log Pis Mean               1.57664
trainer/Log Pis Std                1.54874
trainer/Log Pis Max                5.52418
trainer/Log Pis Min               -5.39154
trainer/Policy mu Mean            -0.0977751
trainer/Policy mu Std              0.605807
trainer/Policy mu Max              2.89649
trainer/Policy mu Min             -2.8149
trainer/Policy log std Mean       -1.95622
trainer/Policy log std Std         0.488227
trainer/Policy log std Max        -0.35001
trainer/Policy log std Min        -2.75225
trainer/Alpha                      0.062155
trainer/Alpha Loss                -1.176
exploration/num steps total    28700
exploration/num paths total      287
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.40713
exploration/Rewards Std            1.00895
exploration/Rewards Max           -0.287644
exploration/Rewards Min           -9.35796
exploration/Returns Mean        -140.713
exploration/Returns Std           59.6019
exploration/Returns Max          -60.9107
exploration/Returns Min         -231.21
exploration/Actions Mean           0.0101932
exploration/Actions Std            0.200621
exploration/Actions Max            0.996996
exploration/Actions Min           -0.999668
exploration/Num Paths              5
exploration/Average Returns     -140.713
evaluation/num steps total     85500
evaluation/num paths total       855
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -3.30233
evaluation/Rewards Std             2.32092
evaluation/Rewards Max            -0.313342
evaluation/Rewards Min            -8.53608
evaluation/Returns Mean         -330.233
evaluation/Returns Std           226.114
evaluation/Returns Max           -52.0148
evaluation/Returns Min          -623.342
evaluation/Actions Mean            0.014097
evaluation/Actions Std             0.155962
evaluation/Actions Max             0.998694
evaluation/Actions Min            -0.994521
evaluation/Num Paths              15
evaluation/Average Returns      -330.233
time/data storing (s)              0.00302437
time/evaluation sampling (s)       0.329254
time/exploration sampling (s)      0.138915
time/logging (s)                   0.00475075
time/saving (s)                    0.00153008
time/training (s)                  1.9586
time/epoch (s)                     2.43607
time/total (s)                   138.917
Epoch                             56
-----------------------------  --------------
2019-04-23 01:15:52.127362 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 57 finished
-----------------------------  --------------
replay_buffer/size             29200
trainer/QF1 Loss                   1.98918
trainer/QF2 Loss                   2.15563
trainer/Policy Loss              112.118
trainer/Q1 Predictions Mean     -110.563
trainer/Q1 Predictions Std        67.3388
trainer/Q1 Predictions Max       -17.4117
trainer/Q1 Predictions Min      -283.937
trainer/Q2 Predictions Mean     -110.55
trainer/Q2 Predictions Std        67.2937
trainer/Q2 Predictions Max       -17.8906
trainer/Q2 Predictions Min      -283.487
trainer/Q Targets Mean          -111.592
trainer/Q Targets Std             67.9356
trainer/Q Targets Max            -17.5932
trainer/Q Targets Min           -284.983
trainer/Log Pis Mean               2.10554
trainer/Log Pis Std                1.12831
trainer/Log Pis Max                4.83046
trainer/Log Pis Min               -1.87526
trainer/Policy mu Mean             0.0471379
trainer/Policy mu Std              0.667127
trainer/Policy mu Max              2.69074
trainer/Policy mu Min             -2.70289
trainer/Policy log std Mean       -2.13944
trainer/Policy log std Std         0.525045
trainer/Policy log std Max        -0.462585
trainer/Policy log std Min        -2.91487
trainer/Alpha                      0.062131
trainer/Alpha Loss                 0.293271
exploration/num steps total    29200
exploration/num paths total      292
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.22925
exploration/Rewards Std            0.570299
exploration/Rewards Max           -0.377858
exploration/Rewards Min           -7.85633
exploration/Returns Mean        -122.925
exploration/Returns Std           32.3254
exploration/Returns Max          -60.3458
exploration/Returns Min         -153.984
exploration/Actions Mean          -0.0126221
exploration/Actions Std            0.151705
exploration/Actions Max            0.946181
exploration/Actions Min           -0.98899
exploration/Num Paths              5
exploration/Average Returns     -122.925
evaluation/num steps total     87000
evaluation/num paths total       870
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.24806
evaluation/Rewards Std             1.76383
evaluation/Rewards Max            -0.332552
evaluation/Rewards Min           -11.1941
evaluation/Returns Mean         -224.806
evaluation/Returns Std           156.687
evaluation/Returns Max           -53.6075
evaluation/Returns Min          -506.98
evaluation/Actions Mean            0.0265462
evaluation/Actions Std             0.186106
evaluation/Actions Max             0.998279
evaluation/Actions Min            -0.973478
evaluation/Num Paths              15
evaluation/Average Returns      -224.806
time/data storing (s)              0.00377921
time/evaluation sampling (s)       0.332313
time/exploration sampling (s)      0.14713
time/logging (s)                   0.00415768
time/saving (s)                    0.00154289
time/training (s)                  1.94997
time/epoch (s)                     2.43889
time/total (s)                   141.36
Epoch                             57
-----------------------------  --------------
2019-04-23 01:15:54.579582 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 58 finished
-----------------------------  --------------
replay_buffer/size             29700
trainer/QF1 Loss                 491.508
trainer/QF2 Loss                 491.274
trainer/Policy Loss              119.754
trainer/Q1 Predictions Mean     -118.378
trainer/Q1 Predictions Std        72.3088
trainer/Q1 Predictions Max       -17.4115
trainer/Q1 Predictions Min      -281.831
trainer/Q2 Predictions Mean     -118.387
trainer/Q2 Predictions Std        72.2887
trainer/Q2 Predictions Max       -17.9089
trainer/Q2 Predictions Min      -281.715
trainer/Q Targets Mean          -117.765
trainer/Q Targets Std             73.644
trainer/Q Targets Max             -0.445058
trainer/Q Targets Min           -286.915
trainer/Log Pis Mean               2.00353
trainer/Log Pis Std                1.09394
trainer/Log Pis Max                5.97606
trainer/Log Pis Min               -1.60658
trainer/Policy mu Mean             0.0640113
trainer/Policy mu Std              0.593525
trainer/Policy mu Max              2.4202
trainer/Policy mu Min             -2.77972
trainer/Policy log std Mean       -2.07102
trainer/Policy log std Std         0.475551
trainer/Policy log std Max        -0.400162
trainer/Policy log std Min        -2.93869
trainer/Alpha                      0.0641257
trainer/Alpha Loss                 0.0096916
exploration/num steps total    29700
exploration/num paths total      297
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.63773
exploration/Rewards Std            2.12377
exploration/Rewards Max           -0.342224
exploration/Rewards Min           -7.41909
exploration/Returns Mean        -263.773
exploration/Returns Std          207.598
exploration/Returns Max          -51.9713
exploration/Returns Min         -526.881
exploration/Actions Mean           0.0118447
exploration/Actions Std            0.186139
exploration/Actions Max            0.993884
exploration/Actions Min           -0.963172
exploration/Num Paths              5
exploration/Average Returns     -263.773
evaluation/num steps total     88500
evaluation/num paths total       885
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -3.0138
evaluation/Rewards Std             2.12977
evaluation/Rewards Max            -0.47378
evaluation/Rewards Min           -10.5857
evaluation/Returns Mean         -301.38
evaluation/Returns Std           190.378
evaluation/Returns Max           -93.8635
evaluation/Returns Min          -710.316
evaluation/Actions Mean            0.0246922
evaluation/Actions Std             0.200582
evaluation/Actions Max             0.999362
evaluation/Actions Min            -0.998238
evaluation/Num Paths              15
evaluation/Average Returns      -301.38
time/data storing (s)              0.00300065
time/evaluation sampling (s)       0.336342
time/exploration sampling (s)      0.136984
time/logging (s)                   0.00472806
time/saving (s)                    0.00193146
time/training (s)                  1.96392
time/epoch (s)                     2.44691
time/total (s)                   143.811
Epoch                             58
-----------------------------  --------------
2019-04-23 01:15:57.032601 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 59 finished
-----------------------------  --------------
replay_buffer/size             30200
trainer/QF1 Loss                   6.05142
trainer/QF2 Loss                   6.25378
trainer/Policy Loss              116.988
trainer/Q1 Predictions Mean     -115.408
trainer/Q1 Predictions Std        74.8247
trainer/Q1 Predictions Max       -18.273
trainer/Q1 Predictions Min      -287.085
trainer/Q2 Predictions Mean     -115.4
trainer/Q2 Predictions Std        74.737
trainer/Q2 Predictions Max       -18.5844
trainer/Q2 Predictions Min      -287.92
trainer/Q Targets Mean          -116.399
trainer/Q Targets Std             76.0121
trainer/Q Targets Max             -0.764257
trainer/Q Targets Min           -290.966
trainer/Log Pis Mean               1.86988
trainer/Log Pis Std                1.2877
trainer/Log Pis Max                7.20017
trainer/Log Pis Min               -2.04764
trainer/Policy mu Mean             0.0554072
trainer/Policy mu Std              0.58294
trainer/Policy mu Max              3.41435
trainer/Policy mu Min             -2.62324
trainer/Policy log std Mean       -2.12239
trainer/Policy log std Std         0.482634
trainer/Policy log std Max        -0.224799
trainer/Policy log std Min        -2.93588
trainer/Alpha                      0.0675003
trainer/Alpha Loss                -0.350743
exploration/num steps total    30200
exploration/num paths total      302
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.7096
exploration/Rewards Std            1.67685
exploration/Rewards Max           -0.331736
exploration/Rewards Min          -11.2637
exploration/Returns Mean        -270.96
exploration/Returns Std          136.596
exploration/Returns Max          -99.6121
exploration/Returns Min         -507.513
exploration/Actions Mean           0.0131502
exploration/Actions Std            0.219987
exploration/Actions Max            0.999331
exploration/Actions Min           -0.9963
exploration/Num Paths              5
exploration/Average Returns     -270.96
evaluation/num steps total     90000
evaluation/num paths total       900
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.81328
evaluation/Rewards Std             2.28354
evaluation/Rewards Max            -0.256449
evaluation/Rewards Min            -8.36237
evaluation/Returns Mean         -281.328
evaluation/Returns Std           217.518
evaluation/Returns Max           -40.4149
evaluation/Returns Min          -698.746
evaluation/Actions Mean            0.0141477
evaluation/Actions Std             0.169439
evaluation/Actions Max             0.998565
evaluation/Actions Min            -0.987407
evaluation/Num Paths              15
evaluation/Average Returns      -281.328
time/data storing (s)              0.0030452
time/evaluation sampling (s)       0.325458
time/exploration sampling (s)      0.147632
time/logging (s)                   0.00475715
time/saving (s)                    0.00197217
time/training (s)                  1.96445
time/epoch (s)                     2.44731
time/total (s)                   146.263
Epoch                             59
-----------------------------  --------------
2019-04-23 01:15:59.494162 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 60 finished
-----------------------------  --------------
replay_buffer/size             30700
trainer/QF1 Loss                 145.902
trainer/QF2 Loss                 146.168
trainer/Policy Loss              124.324
trainer/Q1 Predictions Mean     -122.741
trainer/Q1 Predictions Std        72.4049
trainer/Q1 Predictions Max       -18.1985
trainer/Q1 Predictions Min      -283.466
trainer/Q2 Predictions Mean     -122.75
trainer/Q2 Predictions Std        72.3618
trainer/Q2 Predictions Max       -18.6973
trainer/Q2 Predictions Min      -283.476
trainer/Q Targets Mean          -123.991
trainer/Q Targets Std             74.452
trainer/Q Targets Max             -2.72473
trainer/Q Targets Min           -288.553
trainer/Log Pis Mean               1.9867
trainer/Log Pis Std                1.36916
trainer/Log Pis Max                5.27316
trainer/Log Pis Min               -4.17824
trainer/Policy mu Mean             0.052502
trainer/Policy mu Std              0.617637
trainer/Policy mu Max              2.70823
trainer/Policy mu Min             -2.63521
trainer/Policy log std Mean       -2.13766
trainer/Policy log std Std         0.507688
trainer/Policy log std Max        -0.44482
trainer/Policy log std Min        -2.94727
trainer/Alpha                      0.0646253
trainer/Alpha Loss                -0.0364351
exploration/num steps total    30700
exploration/num paths total      307
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -4.26616
exploration/Rewards Std            2.07024
exploration/Rewards Max           -0.124032
exploration/Rewards Min           -9.38555
exploration/Returns Mean        -426.616
exploration/Returns Std          204.954
exploration/Returns Max          -57.4634
exploration/Returns Min         -685.444
exploration/Actions Mean           0.0133746
exploration/Actions Std            0.233925
exploration/Actions Max            0.99954
exploration/Actions Min           -0.956785
exploration/Num Paths              5
exploration/Average Returns     -426.616
evaluation/num steps total     91500
evaluation/num paths total       915
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -3.07378
evaluation/Rewards Std             1.67076
evaluation/Rewards Max            -0.405878
evaluation/Rewards Min           -10.2692
evaluation/Returns Mean         -307.378
evaluation/Returns Std           154.296
evaluation/Returns Max           -57.4508
evaluation/Returns Min          -667.947
evaluation/Actions Mean            0.00640247
evaluation/Actions Std             0.173417
evaluation/Actions Max             0.994845
evaluation/Actions Min            -0.999431
evaluation/Num Paths              15
evaluation/Average Returns      -307.378
time/data storing (s)              0.00307611
time/evaluation sampling (s)       0.332386
time/exploration sampling (s)      0.141171
time/logging (s)                   0.00475381
time/saving (s)                    0.00193572
time/training (s)                  1.9732
time/epoch (s)                     2.45652
time/total (s)                   148.723
Epoch                             60
-----------------------------  --------------
2019-04-23 01:16:01.932371 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 61 finished
-----------------------------  --------------
replay_buffer/size             31200
trainer/QF1 Loss                1020.64
trainer/QF2 Loss                1023.71
trainer/Policy Loss              113.182
trainer/Q1 Predictions Mean     -111.422
trainer/Q1 Predictions Std        72.0933
trainer/Q1 Predictions Max       -18.715
trainer/Q1 Predictions Min      -286.598
trainer/Q2 Predictions Mean     -111.376
trainer/Q2 Predictions Std        72.0861
trainer/Q2 Predictions Max       -18.9619
trainer/Q2 Predictions Min      -286.416
trainer/Q Targets Mean          -108.151
trainer/Q Targets Std             73.2978
trainer/Q Targets Max             -3.31101
trainer/Q Targets Min           -290.484
trainer/Log Pis Mean               2.15012
trainer/Log Pis Std                1.40687
trainer/Log Pis Max                6.25876
trainer/Log Pis Min               -1.74877
trainer/Policy mu Mean             0.0220151
trainer/Policy mu Std              0.690406
trainer/Policy mu Max              3.01162
trainer/Policy mu Min             -3.13388
trainer/Policy log std Mean       -2.17406
trainer/Policy log std Std         0.550779
trainer/Policy log std Max        -0.562069
trainer/Policy log std Min        -2.98675
trainer/Alpha                      0.0628139
trainer/Alpha Loss                 0.415496
exploration/num steps total    31200
exploration/num paths total      312
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.13945
exploration/Rewards Std            1.15406
exploration/Rewards Max           -0.139655
exploration/Rewards Min           -8.0622
exploration/Returns Mean        -113.945
exploration/Returns Std           90.3867
exploration/Returns Max          -54.7544
exploration/Returns Min         -292.666
exploration/Actions Mean           0.0104751
exploration/Actions Std            0.193291
exploration/Actions Max            0.99915
exploration/Actions Min           -0.983605
exploration/Num Paths              5
exploration/Average Returns     -113.945
evaluation/num steps total     93000
evaluation/num paths total       930
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.20025
evaluation/Rewards Std             1.68979
evaluation/Rewards Max            -0.0887308
evaluation/Rewards Min           -11.8564
evaluation/Returns Mean         -220.025
evaluation/Returns Std           153.175
evaluation/Returns Max           -19.5383
evaluation/Returns Min          -472.114
evaluation/Actions Mean            0.0154166
evaluation/Actions Std             0.164669
evaluation/Actions Max             0.994919
evaluation/Actions Min            -0.996944
evaluation/Num Paths              15
evaluation/Average Returns      -220.025
time/data storing (s)              0.0030779
time/evaluation sampling (s)       0.327689
time/exploration sampling (s)      0.139521
time/logging (s)                   0.00477957
time/saving (s)                    0.00195125
time/training (s)                  1.95546
time/epoch (s)                     2.43248
time/total (s)                   151.16
Epoch                             61
-----------------------------  --------------
2019-04-23 01:16:04.368578 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 62 finished
-----------------------------  --------------
replay_buffer/size             31700
trainer/QF1 Loss                  12.0844
trainer/QF2 Loss                  11.9778
trainer/Policy Loss              109.013
trainer/Q1 Predictions Mean     -107.703
trainer/Q1 Predictions Std        79.3444
trainer/Q1 Predictions Max       -19.0518
trainer/Q1 Predictions Min      -289.036
trainer/Q2 Predictions Mean     -107.722
trainer/Q2 Predictions Std        79.3085
trainer/Q2 Predictions Max       -19.2491
trainer/Q2 Predictions Min      -288.504
trainer/Q Targets Mean          -108.758
trainer/Q Targets Std             80.4587
trainer/Q Targets Max             -0.419533
trainer/Q Targets Min           -291.457
trainer/Log Pis Mean               1.69539
trainer/Log Pis Std                1.49957
trainer/Log Pis Max                7.37442
trainer/Log Pis Min               -1.40273
trainer/Policy mu Mean            -0.13966
trainer/Policy mu Std              0.619711
trainer/Policy mu Max              2.93486
trainer/Policy mu Min             -2.91919
trainer/Policy log std Mean       -1.99381
trainer/Policy log std Std         0.552224
trainer/Policy log std Max        -0.262999
trainer/Policy log std Min        -2.95853
trainer/Alpha                      0.0614932
trainer/Alpha Loss                -0.849451
exploration/num steps total    31700
exploration/num paths total      317
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.18793
exploration/Rewards Std            0.996502
exploration/Rewards Max           -0.0464348
exploration/Rewards Min           -5.34957
exploration/Returns Mean        -118.793
exploration/Returns Std           94.3849
exploration/Returns Max          -43.7315
exploration/Returns Min         -289.551
exploration/Actions Mean          -0.00711303
exploration/Actions Std            0.162094
exploration/Actions Max            0.990772
exploration/Actions Min           -0.994141
exploration/Num Paths              5
exploration/Average Returns     -118.793
evaluation/num steps total     94500
evaluation/num paths total       945
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.45569
evaluation/Rewards Std             2.08285
evaluation/Rewards Max            -0.182887
evaluation/Rewards Min            -9.85489
evaluation/Returns Mean         -245.569
evaluation/Returns Std           190.014
evaluation/Returns Max           -49.969
evaluation/Returns Min          -622.127
evaluation/Actions Mean            0.0148036
evaluation/Actions Std             0.175301
evaluation/Actions Max             0.996467
evaluation/Actions Min            -0.999266
evaluation/Num Paths              15
evaluation/Average Returns      -245.569
time/data storing (s)              0.00294977
time/evaluation sampling (s)       0.32314
time/exploration sampling (s)      0.143207
time/logging (s)                   0.00491854
time/saving (s)                    0.0016497
time/training (s)                  1.95563
time/epoch (s)                     2.43149
time/total (s)                   153.595
Epoch                             62
-----------------------------  --------------
2019-04-23 01:16:06.809400 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 63 finished
-----------------------------  --------------
replay_buffer/size             32200
trainer/QF1 Loss                 243.698
trainer/QF2 Loss                 243.199
trainer/Policy Loss              126.406
trainer/Q1 Predictions Mean     -124.824
trainer/Q1 Predictions Std        75.4451
trainer/Q1 Predictions Max       -23.1409
trainer/Q1 Predictions Min      -290.436
trainer/Q2 Predictions Mean     -124.785
trainer/Q2 Predictions Std        75.455
trainer/Q2 Predictions Max       -22.5896
trainer/Q2 Predictions Min      -289.952
trainer/Q Targets Mean          -124.519
trainer/Q Targets Std             78.0461
trainer/Q Targets Max             -1.83578
trainer/Q Targets Min           -293.918
trainer/Log Pis Mean               2.05059
trainer/Log Pis Std                1.37109
trainer/Log Pis Max                7.52127
trainer/Log Pis Min               -2.03902
trainer/Policy mu Mean            -0.0688038
trainer/Policy mu Std              0.740711
trainer/Policy mu Max              2.8802
trainer/Policy mu Min             -3.48441
trainer/Policy log std Mean       -2.03164
trainer/Policy log std Std         0.587871
trainer/Policy log std Max        -0.279161
trainer/Policy log std Min        -2.96023
trainer/Alpha                      0.0595937
trainer/Alpha Loss                 0.142674
exploration/num steps total    32200
exploration/num paths total      322
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -3.26379
exploration/Rewards Std            1.21003
exploration/Rewards Max           -1.1359
exploration/Rewards Min           -7.10259
exploration/Returns Mean        -326.379
exploration/Returns Std          116.379
exploration/Returns Max         -134.998
exploration/Returns Min         -449.954
exploration/Actions Mean           0.00988001
exploration/Actions Std            0.223237
exploration/Actions Max            0.992634
exploration/Actions Min           -0.989546
exploration/Num Paths              5
exploration/Average Returns     -326.379
evaluation/num steps total     96000
evaluation/num paths total       960
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.76008
evaluation/Rewards Std             2.27465
evaluation/Rewards Max            -0.240059
evaluation/Rewards Min            -8.8194
evaluation/Returns Mean         -276.008
evaluation/Returns Std           220.876
evaluation/Returns Max           -49.4872
evaluation/Returns Min          -633.733
evaluation/Actions Mean           -0.00103179
evaluation/Actions Std             0.148111
evaluation/Actions Max             0.99516
evaluation/Actions Min            -0.99796
evaluation/Num Paths              15
evaluation/Average Returns      -276.008
time/data storing (s)              0.00306186
time/evaluation sampling (s)       0.328817
time/exploration sampling (s)      0.138066
time/logging (s)                   0.00472696
time/saving (s)                    0.00194779
time/training (s)                  1.9582
time/epoch (s)                     2.43482
time/total (s)                   156.034
Epoch                             63
-----------------------------  --------------
2019-04-23 01:16:09.274598 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 64 finished
-----------------------------  --------------
replay_buffer/size             32700
trainer/QF1 Loss                   3.07999
trainer/QF2 Loss                   3.05576
trainer/Policy Loss              117.678
trainer/Q1 Predictions Mean     -115.998
trainer/Q1 Predictions Std        82.6707
trainer/Q1 Predictions Max       -19.8672
trainer/Q1 Predictions Min      -292.636
trainer/Q2 Predictions Mean     -116.003
trainer/Q2 Predictions Std        82.6266
trainer/Q2 Predictions Max       -19.8156
trainer/Q2 Predictions Min      -292.557
trainer/Q Targets Mean          -117.369
trainer/Q Targets Std             83.0829
trainer/Q Targets Max            -19.9828
trainer/Q Targets Min           -294.619
trainer/Log Pis Mean               2.18982
trainer/Log Pis Std                1.36484
trainer/Log Pis Max                8.35583
trainer/Log Pis Min               -1.57927
trainer/Policy mu Mean             0.0169313
trainer/Policy mu Std              0.792135
trainer/Policy mu Max              2.62858
trainer/Policy mu Min             -3.50202
trainer/Policy log std Mean       -2.01548
trainer/Policy log std Std         0.587746
trainer/Policy log std Max        -0.143632
trainer/Policy log std Min        -2.89318
trainer/Alpha                      0.0620332
trainer/Alpha Loss                 0.527725
exploration/num steps total    32700
exploration/num paths total      327
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -3.48583
exploration/Rewards Std            2.5324
exploration/Rewards Max           -0.0923341
exploration/Rewards Min           -8.46566
exploration/Returns Mean        -348.583
exploration/Returns Std          241.518
exploration/Returns Max          -54.864
exploration/Returns Min         -682.09
exploration/Actions Mean           0.0138185
exploration/Actions Std            0.246542
exploration/Actions Max            0.999754
exploration/Actions Min           -0.987438
exploration/Num Paths              5
exploration/Average Returns     -348.583
evaluation/num steps total     97500
evaluation/num paths total       975
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.30234
evaluation/Rewards Std             1.34122
evaluation/Rewards Max            -0.0559476
evaluation/Rewards Min            -7.45379
evaluation/Returns Mean         -130.234
evaluation/Returns Std           122.96
evaluation/Returns Max           -30.2746
evaluation/Returns Min          -486.642
evaluation/Actions Mean           -0.00720914
evaluation/Actions Std             0.13824
evaluation/Actions Max             0.986995
evaluation/Actions Min            -0.998289
evaluation/Num Paths              15
evaluation/Average Returns      -130.234
time/data storing (s)              0.00298727
time/evaluation sampling (s)       0.339923
time/exploration sampling (s)      0.140434
time/logging (s)                   0.00478916
time/saving (s)                    0.00194017
time/training (s)                  1.96945
time/epoch (s)                     2.45953
time/total (s)                   158.498
Epoch                             64
-----------------------------  --------------
2019-04-23 01:16:11.755601 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 65 finished
-----------------------------  --------------
replay_buffer/size             33200
trainer/QF1 Loss                   3.07603
trainer/QF2 Loss                   3.38251
trainer/Policy Loss              123.624
trainer/Q1 Predictions Mean     -122.303
trainer/Q1 Predictions Std        78.4593
trainer/Q1 Predictions Max       -20.2864
trainer/Q1 Predictions Min      -295.264
trainer/Q2 Predictions Mean     -122.327
trainer/Q2 Predictions Std        78.406
trainer/Q2 Predictions Max       -20.3041
trainer/Q2 Predictions Min      -295.097
trainer/Q Targets Mean          -123.624
trainer/Q Targets Std             79.184
trainer/Q Targets Max            -20.4275
trainer/Q Targets Min           -297.74
trainer/Log Pis Mean               2.01102
trainer/Log Pis Std                1.49808
trainer/Log Pis Max                6.64271
trainer/Log Pis Min               -3.55996
trainer/Policy mu Mean            -0.0143128
trainer/Policy mu Std              0.730848
trainer/Policy mu Max              2.62631
trainer/Policy mu Min             -2.84402
trainer/Policy log std Mean       -2.02998
trainer/Policy log std Std         0.516851
trainer/Policy log std Max        -0.206813
trainer/Policy log std Min        -2.91245
trainer/Alpha                      0.0630904
trainer/Alpha Loss                 0.0304443
exploration/num steps total    33200
exploration/num paths total      332
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.64779
exploration/Rewards Std            1.96892
exploration/Rewards Max           -0.0202533
exploration/Rewards Min           -7.49114
exploration/Returns Mean        -264.779
exploration/Returns Std          193.93
exploration/Returns Max          -27.0132
exploration/Returns Min         -444.051
exploration/Actions Mean          -0.00638351
exploration/Actions Std            0.209048
exploration/Actions Max            0.992659
exploration/Actions Min           -0.998667
exploration/Num Paths              5
exploration/Average Returns     -264.779
evaluation/num steps total     99000
evaluation/num paths total       990
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.19915
evaluation/Rewards Std             1.82805
evaluation/Rewards Max            -0.0298385
evaluation/Rewards Min           -10.2051
evaluation/Returns Mean         -219.915
evaluation/Returns Std           171.027
evaluation/Returns Max           -38.6866
evaluation/Returns Min          -487.95
evaluation/Actions Mean            0.00202089
evaluation/Actions Std             0.148621
evaluation/Actions Max             0.999323
evaluation/Actions Min            -0.992932
evaluation/Num Paths              15
evaluation/Average Returns      -219.915
time/data storing (s)              0.00294723
time/evaluation sampling (s)       0.331432
time/exploration sampling (s)      0.140279
time/logging (s)                   0.00496206
time/saving (s)                    0.0222891
time/training (s)                  1.97341
time/epoch (s)                     2.47532
time/total (s)                   160.977
Epoch                             65
-----------------------------  --------------
2019-04-23 01:16:14.223593 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 66 finished
-----------------------------  ---------------
replay_buffer/size              33700
trainer/QF1 Loss                    1.98258
trainer/QF2 Loss                    2.04008
trainer/Policy Loss               114.086
trainer/Q1 Predictions Mean      -112.837
trainer/Q1 Predictions Std         80.2371
trainer/Q1 Predictions Max        -20.2589
trainer/Q1 Predictions Min       -295.788
trainer/Q2 Predictions Mean      -112.815
trainer/Q2 Predictions Std         80.1964
trainer/Q2 Predictions Max        -20.109
trainer/Q2 Predictions Min       -295.693
trainer/Q Targets Mean           -113.617
trainer/Q Targets Std              80.9333
trainer/Q Targets Max             -20.3026
trainer/Q Targets Min            -298.936
trainer/Log Pis Mean                2.05558
trainer/Log Pis Std                 1.42483
trainer/Log Pis Max                 7.05973
trainer/Log Pis Min                -3.02704
trainer/Policy mu Mean             -0.0340642
trainer/Policy mu Std               0.700813
trainer/Policy mu Max               2.61459
trainer/Policy mu Min              -3.57763
trainer/Policy log std Mean        -2.08243
trainer/Policy log std Std          0.569643
trainer/Policy log std Max         -0.271938
trainer/Policy log std Min         -2.92158
trainer/Alpha                       0.0624066
trainer/Alpha Loss                  0.154181
exploration/num steps total     33700
exploration/num paths total       337
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -3.24767
exploration/Rewards Std             2.1985
exploration/Rewards Max            -0.136508
exploration/Rewards Min            -8.64092
exploration/Returns Mean         -324.767
exploration/Returns Std           210.624
exploration/Returns Max           -49.001
exploration/Returns Min          -641.66
exploration/Actions Mean            0.0101122
exploration/Actions Std             0.235393
exploration/Actions Max             0.999509
exploration/Actions Min            -0.997596
exploration/Num Paths               5
exploration/Average Returns      -324.767
evaluation/num steps total     100500
evaluation/num paths total       1005
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -2.96747
evaluation/Rewards Std              2.28631
evaluation/Rewards Max             -0.00124899
evaluation/Rewards Min             -9.76118
evaluation/Returns Mean          -296.747
evaluation/Returns Std            219.547
evaluation/Returns Max            -29.387
evaluation/Returns Min           -647.15
evaluation/Actions Mean             0.00955241
evaluation/Actions Std              0.160094
evaluation/Actions Max              0.995373
evaluation/Actions Min             -0.998628
evaluation/Num Paths               15
evaluation/Average Returns       -296.747
time/data storing (s)               0.00303348
time/evaluation sampling (s)        0.337354
time/exploration sampling (s)       0.140675
time/logging (s)                    0.00479412
time/saving (s)                     0.00200217
time/training (s)                   1.97372
time/epoch (s)                      2.46158
time/total (s)                    163.443
Epoch                              66
-----------------------------  ---------------
2019-04-23 01:16:16.663895 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 67 finished
-----------------------------  ---------------
replay_buffer/size              34200
trainer/QF1 Loss                    1.67206
trainer/QF2 Loss                    1.58894
trainer/Policy Loss               114.201
trainer/Q1 Predictions Mean      -113.268
trainer/Q1 Predictions Std         76.9886
trainer/Q1 Predictions Max        -20.7797
trainer/Q1 Predictions Min       -298.378
trainer/Q2 Predictions Mean      -113.272
trainer/Q2 Predictions Std         77.0081
trainer/Q2 Predictions Max        -20.7327
trainer/Q2 Predictions Min       -298.364
trainer/Q Targets Mean           -113.856
trainer/Q Targets Std              77.5312
trainer/Q Targets Max             -20.6781
trainer/Q Targets Min            -300.231
trainer/Log Pis Mean                1.96508
trainer/Log Pis Std                 1.24676
trainer/Log Pis Max                 6.94529
trainer/Log Pis Min                -1.11911
trainer/Policy mu Mean             -0.0291296
trainer/Policy mu Std               0.643074
trainer/Policy mu Max               3.30738
trainer/Policy mu Min              -3.45678
trainer/Policy log std Mean        -2.14841
trainer/Policy log std Std          0.472465
trainer/Policy log std Max         -0.317953
trainer/Policy log std Min         -2.88883
trainer/Alpha                       0.062973
trainer/Alpha Loss                 -0.0965615
exploration/num steps total     34200
exploration/num paths total       342
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -3.0099
exploration/Rewards Std             1.66079
exploration/Rewards Max            -0.763249
exploration/Rewards Min            -8.12775
exploration/Returns Mean         -300.99
exploration/Returns Std           157.151
exploration/Returns Max           -99.1468
exploration/Returns Min          -487.773
exploration/Actions Mean           -0.00864986
exploration/Actions Std             0.190041
exploration/Actions Max             0.999442
exploration/Actions Min            -0.999345
exploration/Num Paths               5
exploration/Average Returns      -300.99
evaluation/num steps total     102000
evaluation/num paths total       1020
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -3.30836
evaluation/Rewards Std              2.21739
evaluation/Rewards Max             -0.0377167
evaluation/Rewards Min            -10.4592
evaluation/Returns Mean          -330.836
evaluation/Returns Std            209.037
evaluation/Returns Max            -61.3582
evaluation/Returns Min           -676.466
evaluation/Actions Mean             0.00987419
evaluation/Actions Std              0.159168
evaluation/Actions Max              0.998692
evaluation/Actions Min             -0.996584
evaluation/Num Paths               15
evaluation/Average Returns       -330.836
time/data storing (s)               0.00294689
time/evaluation sampling (s)        0.331488
time/exploration sampling (s)       0.141738
time/logging (s)                    0.00470216
time/saving (s)                     0.001921
time/training (s)                   1.95125
time/epoch (s)                      2.43404
time/total (s)                    165.882
Epoch                              67
-----------------------------  ---------------
2019-04-23 01:16:19.132327 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 68 finished
-----------------------------  ---------------
replay_buffer/size              34700
trainer/QF1 Loss                  447.282
trainer/QF2 Loss                  447.574
trainer/Policy Loss               131.973
trainer/Q1 Predictions Mean      -130.759
trainer/Q1 Predictions Std         82.8
trainer/Q1 Predictions Max        -20.8662
trainer/Q1 Predictions Min       -297.913
trainer/Q2 Predictions Mean      -130.752
trainer/Q2 Predictions Std         82.7393
trainer/Q2 Predictions Max        -20.6337
trainer/Q2 Predictions Min       -297.238
trainer/Q Targets Mean           -130.242
trainer/Q Targets Std              83.9982
trainer/Q Targets Max              -5.0379
trainer/Q Targets Min            -300.97
trainer/Log Pis Mean                1.78716
trainer/Log Pis Std                 1.56252
trainer/Log Pis Max                 7.04019
trainer/Log Pis Min                -3.6803
trainer/Policy mu Mean              0.0240966
trainer/Policy mu Std               0.640058
trainer/Policy mu Max               2.98649
trainer/Policy mu Min              -2.43011
trainer/Policy log std Mean        -2.11103
trainer/Policy log std Std          0.514843
trainer/Policy log std Max         -0.315667
trainer/Policy log std Min         -2.93676
trainer/Alpha                       0.0631223
trainer/Alpha Loss                 -0.588035
exploration/num steps total     34700
exploration/num paths total       347
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -2.00147
exploration/Rewards Std             1.52337
exploration/Rewards Max            -0.181313
exploration/Rewards Min           -10.5587
exploration/Returns Mean         -200.147
exploration/Returns Std           142.407
exploration/Returns Max           -59.4086
exploration/Returns Min          -466.602
exploration/Actions Mean            0.011501
exploration/Actions Std             0.192664
exploration/Actions Max             0.999685
exploration/Actions Min            -0.994985
exploration/Num Paths               5
exploration/Average Returns      -200.147
evaluation/num steps total     103500
evaluation/num paths total       1035
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.44483
evaluation/Rewards Std              1.28234
evaluation/Rewards Max             -0.183924
evaluation/Rewards Min             -7.33557
evaluation/Returns Mean          -144.483
evaluation/Returns Std            110.713
evaluation/Returns Max            -46.7874
evaluation/Returns Min           -480.624
evaluation/Actions Mean             0.00489867
evaluation/Actions Std              0.14852
evaluation/Actions Max              0.997093
evaluation/Actions Min             -0.998634
evaluation/Num Paths               15
evaluation/Average Returns       -144.483
time/data storing (s)               0.00295571
time/evaluation sampling (s)        0.338464
time/exploration sampling (s)       0.144369
time/logging (s)                    0.00448511
time/saving (s)                     0.00195421
time/training (s)                   1.96981
time/epoch (s)                      2.46204
time/total (s)                    168.349
Epoch                              68
-----------------------------  ---------------
2019-04-23 01:16:21.582816 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 69 finished
-----------------------------  ---------------
replay_buffer/size              35200
trainer/QF1 Loss                  170.462
trainer/QF2 Loss                  171.092
trainer/Policy Loss               126.719
trainer/Q1 Predictions Mean      -125.198
trainer/Q1 Predictions Std         83.6322
trainer/Q1 Predictions Max        -20.9603
trainer/Q1 Predictions Min       -299.121
trainer/Q2 Predictions Mean      -125.234
trainer/Q2 Predictions Std         83.6018
trainer/Q2 Predictions Max        -21.094
trainer/Q2 Predictions Min       -298.98
trainer/Q Targets Mean           -124.773
trainer/Q Targets Std              85.3095
trainer/Q Targets Max              -0.63793
trainer/Q Targets Min            -300.758
trainer/Log Pis Mean                2.06245
trainer/Log Pis Std                 1.5742
trainer/Log Pis Max                 8.51534
trainer/Log Pis Min                -3.50543
trainer/Policy mu Mean             -0.0170231
trainer/Policy mu Std               0.74897
trainer/Policy mu Max               2.53291
trainer/Policy mu Min              -4.14054
trainer/Policy log std Mean        -2.11226
trainer/Policy log std Std          0.54159
trainer/Policy log std Max         -0.304138
trainer/Policy log std Min         -3.0428
trainer/Alpha                       0.0629393
trainer/Alpha Loss                  0.172743
exploration/num steps total     35200
exploration/num paths total       352
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.35527
exploration/Rewards Std             1.29732
exploration/Rewards Max            -0.0357176
exploration/Rewards Min            -9.80672
exploration/Returns Mean         -135.527
exploration/Returns Std            94.133
exploration/Returns Max           -43.7113
exploration/Returns Min          -284.182
exploration/Actions Mean            0.014313
exploration/Actions Std             0.204361
exploration/Actions Max             0.999094
exploration/Actions Min            -0.999959
exploration/Num Paths               5
exploration/Average Returns      -135.527
evaluation/num steps total     105000
evaluation/num paths total       1050
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -3.99306
evaluation/Rewards Std              1.85635
evaluation/Rewards Max             -0.0203685
evaluation/Rewards Min            -10.2268
evaluation/Returns Mean          -399.306
evaluation/Returns Std            179.789
evaluation/Returns Max            -28.2491
evaluation/Returns Min           -646.336
evaluation/Actions Mean             0.0163473
evaluation/Actions Std              0.164265
evaluation/Actions Max              0.994646
evaluation/Actions Min             -0.997659
evaluation/Num Paths               15
evaluation/Average Returns       -399.306
time/data storing (s)               0.00293944
time/evaluation sampling (s)        0.323893
time/exploration sampling (s)       0.14261
time/logging (s)                    0.00380186
time/saving (s)                     0.00189172
time/training (s)                   1.9688
time/epoch (s)                      2.44393
time/total (s)                    170.797
Epoch                              69
-----------------------------  ---------------
2019-04-23 01:16:24.006497 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 70 finished
-----------------------------  ---------------
replay_buffer/size              35700
trainer/QF1 Loss                    0.897879
trainer/QF2 Loss                    0.731412
trainer/Policy Loss               123.521
trainer/Q1 Predictions Mean      -122.067
trainer/Q1 Predictions Std         82.8342
trainer/Q1 Predictions Max        -20.9116
trainer/Q1 Predictions Min       -302.184
trainer/Q2 Predictions Mean      -122.047
trainer/Q2 Predictions Std         82.8613
trainer/Q2 Predictions Max        -20.9378
trainer/Q2 Predictions Min       -302.375
trainer/Q Targets Mean           -122.397
trainer/Q Targets Std              83.0358
trainer/Q Targets Max             -21.1224
trainer/Q Targets Min            -303.997
trainer/Log Pis Mean                1.99563
trainer/Log Pis Std                 1.1383
trainer/Log Pis Max                 5.30495
trainer/Log Pis Min                -2.10646
trainer/Policy mu Mean              0.0560539
trainer/Policy mu Std               0.595196
trainer/Policy mu Max               2.41667
trainer/Policy mu Min              -2.89065
trainer/Policy log std Mean        -2.09292
trainer/Policy log std Std          0.521485
trainer/Policy log std Max         -0.302594
trainer/Policy log std Min         -2.86431
trainer/Alpha                       0.0658346
trainer/Alpha Loss                 -0.0118808
exploration/num steps total     35700
exploration/num paths total       357
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -3.0944
exploration/Rewards Std             2.4964
exploration/Rewards Max            -0.0823622
exploration/Rewards Min            -9.3006
exploration/Returns Mean         -309.44
exploration/Returns Std           236.308
exploration/Returns Max           -43.2183
exploration/Returns Min          -674.327
exploration/Actions Mean            0.0231695
exploration/Actions Std             0.256377
exploration/Actions Max             0.999946
exploration/Actions Min            -0.983311
exploration/Num Paths               5
exploration/Average Returns      -309.44
evaluation/num steps total     106500
evaluation/num paths total       1065
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -2.58621
evaluation/Rewards Std              1.92485
evaluation/Rewards Max             -0.0322262
evaluation/Rewards Min             -8.93231
evaluation/Returns Mean          -258.621
evaluation/Returns Std            180.25
evaluation/Returns Max            -50.0721
evaluation/Returns Min           -696.728
evaluation/Actions Mean             0.00830966
evaluation/Actions Std              0.174768
evaluation/Actions Max              0.997061
evaluation/Actions Min             -0.999357
evaluation/Num Paths               15
evaluation/Average Returns       -258.621
time/data storing (s)               0.00291546
time/evaluation sampling (s)        0.326909
time/exploration sampling (s)       0.136699
time/logging (s)                    0.00349042
time/saving (s)                     0.00203713
time/training (s)                   1.94519
time/epoch (s)                      2.41724
time/total (s)                    173.219
Epoch                              70
-----------------------------  ---------------
2019-04-23 01:16:26.460930 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 71 finished
-----------------------------  ---------------
replay_buffer/size              36200
trainer/QF1 Loss                   50.5103
trainer/QF2 Loss                   50.5315
trainer/Policy Loss               122.588
trainer/Q1 Predictions Mean      -121.422
trainer/Q1 Predictions Std         82.1394
trainer/Q1 Predictions Max        -21.5068
trainer/Q1 Predictions Min       -300.775
trainer/Q2 Predictions Mean      -121.382
trainer/Q2 Predictions Std         82.1923
trainer/Q2 Predictions Max        -21.4579
trainer/Q2 Predictions Min       -301.18
trainer/Q Targets Mean           -121.691
trainer/Q Targets Std              83.7498
trainer/Q Targets Max              -1.15827
trainer/Q Targets Min            -304.599
trainer/Log Pis Mean                1.72724
trainer/Log Pis Std                 1.4939
trainer/Log Pis Max                 6.34518
trainer/Log Pis Min                -2.88382
trainer/Policy mu Mean             -0.00757334
trainer/Policy mu Std               0.63651
trainer/Policy mu Max               2.89824
trainer/Policy mu Min              -3.31929
trainer/Policy log std Mean        -2.10569
trainer/Policy log std Std          0.513198
trainer/Policy log std Max         -0.301515
trainer/Policy log std Min         -2.98718
trainer/Alpha                       0.0635919
trainer/Alpha Loss                 -0.75151
exploration/num steps total     36200
exploration/num paths total       362
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -3.53099
exploration/Rewards Std             1.83755
exploration/Rewards Max            -0.843113
exploration/Rewards Min            -8.39658
exploration/Returns Mean         -353.099
exploration/Returns Std           170.943
exploration/Returns Max          -144.484
exploration/Returns Min          -608.937
exploration/Actions Mean            0.0170355
exploration/Actions Std             0.255615
exploration/Actions Max             0.999282
exploration/Actions Min            -0.981476
exploration/Num Paths               5
exploration/Average Returns      -353.099
evaluation/num steps total     108000
evaluation/num paths total       1080
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -2.68953
evaluation/Rewards Std              1.31319
evaluation/Rewards Max             -0.208953
evaluation/Rewards Min            -10.6996
evaluation/Returns Mean          -268.953
evaluation/Returns Std            119.303
evaluation/Returns Max            -22.7597
evaluation/Returns Min           -437.947
evaluation/Actions Mean             0.0134466
evaluation/Actions Std              0.157143
evaluation/Actions Max              0.998359
evaluation/Actions Min             -0.994293
evaluation/Num Paths               15
evaluation/Average Returns       -268.953
time/data storing (s)               0.00294938
time/evaluation sampling (s)        0.326745
time/exploration sampling (s)       0.141698
time/logging (s)                    0.00415608
time/saving (s)                     0.00195751
time/training (s)                   1.97213
time/epoch (s)                      2.44963
time/total (s)                    175.673
Epoch                              71
-----------------------------  ---------------
2019-04-23 01:16:28.905242 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 72 finished
-----------------------------  ---------------
replay_buffer/size              36700
trainer/QF1 Loss                   50.9096
trainer/QF2 Loss                   50.555
trainer/Policy Loss               118.796
trainer/Q1 Predictions Mean      -117.504
trainer/Q1 Predictions Std         80.6213
trainer/Q1 Predictions Max        -21.1814
trainer/Q1 Predictions Min       -305.808
trainer/Q2 Predictions Mean      -117.461
trainer/Q2 Predictions Std         80.6165
trainer/Q2 Predictions Max        -21.3652
trainer/Q2 Predictions Min       -305.671
trainer/Q Targets Mean           -117.211
trainer/Q Targets Std              81.5219
trainer/Q Targets Max              -0.845944
trainer/Q Targets Min            -306.396
trainer/Log Pis Mean                1.96556
trainer/Log Pis Std                 1.40728
trainer/Log Pis Max                 7.2632
trainer/Log Pis Min                -6.282
trainer/Policy mu Mean             -0.043564
trainer/Policy mu Std               0.601968
trainer/Policy mu Max               2.03074
trainer/Policy mu Min              -3.35564
trainer/Policy log std Mean        -2.10622
trainer/Policy log std Std          0.501801
trainer/Policy log std Max         -0.522922
trainer/Policy log std Min         -2.90986
trainer/Alpha                       0.0630906
trainer/Alpha Loss                 -0.0951557
exploration/num steps total     36700
exploration/num paths total       367
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -2.39037
exploration/Rewards Std             1.73737
exploration/Rewards Max            -0.495197
exploration/Rewards Min            -9.91631
exploration/Returns Mean         -239.037
exploration/Returns Std           151.582
exploration/Returns Max           -83.4803
exploration/Returns Min          -447.807
exploration/Actions Mean            0.0287953
exploration/Actions Std             0.241127
exploration/Actions Max             0.999143
exploration/Actions Min            -0.995812
exploration/Num Paths               5
exploration/Average Returns      -239.037
evaluation/num steps total     109500
evaluation/num paths total       1095
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -2.29466
evaluation/Rewards Std              1.92037
evaluation/Rewards Max             -0.308153
evaluation/Rewards Min             -8.36544
evaluation/Returns Mean          -229.466
evaluation/Returns Std            182.613
evaluation/Returns Max            -35.0028
evaluation/Returns Min           -625.418
evaluation/Actions Mean             0.0111394
evaluation/Actions Std              0.16557
evaluation/Actions Max              0.994387
evaluation/Actions Min             -0.997441
evaluation/Num Paths               15
evaluation/Average Returns       -229.466
time/data storing (s)               0.00300183
time/evaluation sampling (s)        0.325741
time/exploration sampling (s)       0.142366
time/logging (s)                    0.00474647
time/saving (s)                     0.00193041
time/training (s)                   1.96208
time/epoch (s)                      2.43986
time/total (s)                    178.116
Epoch                              72
-----------------------------  ---------------
2019-04-23 01:16:31.354911 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 73 finished
-----------------------------  ---------------
replay_buffer/size              37200
trainer/QF1 Loss                  165.796
trainer/QF2 Loss                  165.367
trainer/Policy Loss               112.753
trainer/Q1 Predictions Mean      -111.519
trainer/Q1 Predictions Std         75.9707
trainer/Q1 Predictions Max        -21.1751
trainer/Q1 Predictions Min       -303.314
trainer/Q2 Predictions Mean      -111.455
trainer/Q2 Predictions Std         76.0148
trainer/Q2 Predictions Max        -20.9971
trainer/Q2 Predictions Min       -304.198
trainer/Q Targets Mean           -111.927
trainer/Q Targets Std              77.907
trainer/Q Targets Max              -2.81991
trainer/Q Targets Min            -308.302
trainer/Log Pis Mean                1.92643
trainer/Log Pis Std                 1.65035
trainer/Log Pis Max                 8.23342
trainer/Log Pis Min                -3.97949
trainer/Policy mu Mean             -0.0897796
trainer/Policy mu Std               0.754976
trainer/Policy mu Max               2.99005
trainer/Policy mu Min              -4.00093
trainer/Policy log std Mean        -2.08352
trainer/Policy log std Std          0.558922
trainer/Policy log std Max         -0.04683
trainer/Policy log std Min         -2.89678
trainer/Alpha                       0.0657764
trainer/Alpha Loss                 -0.200227
exploration/num steps total     37200
exploration/num paths total       372
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.3138
exploration/Rewards Std             0.954752
exploration/Rewards Max            -0.073597
exploration/Rewards Min            -8.58568
exploration/Returns Mean         -131.38
exploration/Returns Std            58.2399
exploration/Returns Max           -42.1108
exploration/Returns Min          -208.42
exploration/Actions Mean            0.00184222
exploration/Actions Std             0.193753
exploration/Actions Max             0.994439
exploration/Actions Min            -0.997943
exploration/Num Paths               5
exploration/Average Returns      -131.38
evaluation/num steps total     111000
evaluation/num paths total       1110
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -2.34705
evaluation/Rewards Std              1.7302
evaluation/Rewards Max             -0.22849
evaluation/Rewards Min            -10.4264
evaluation/Returns Mean          -234.705
evaluation/Returns Std            160.509
evaluation/Returns Max            -24.6792
evaluation/Returns Min           -461.751
evaluation/Actions Mean            -0.00361865
evaluation/Actions Std              0.171317
evaluation/Actions Max              0.993558
evaluation/Actions Min             -0.999693
evaluation/Num Paths               15
evaluation/Average Returns       -234.705
time/data storing (s)               0.00306471
time/evaluation sampling (s)        0.328238
time/exploration sampling (s)       0.141702
time/logging (s)                    0.0047379
time/saving (s)                     0.00192741
time/training (s)                   1.96374
time/epoch (s)                      2.44341
time/total (s)                    180.564
Epoch                              73
-----------------------------  ---------------
2019-04-23 01:16:33.800026 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 74 finished
-----------------------------  ---------------
replay_buffer/size              37700
trainer/QF1 Loss                   59.3465
trainer/QF2 Loss                   58.7781
trainer/Policy Loss               123.38
trainer/Q1 Predictions Mean      -121.884
trainer/Q1 Predictions Std         91.8107
trainer/Q1 Predictions Max        -21.5175
trainer/Q1 Predictions Min       -307.498
trainer/Q2 Predictions Mean      -121.899
trainer/Q2 Predictions Std         91.7703
trainer/Q2 Predictions Max        -21.6625
trainer/Q2 Predictions Min       -307.703
trainer/Q Targets Mean           -121.404
trainer/Q Targets Std              93.3302
trainer/Q Targets Max              -1.52084
trainer/Q Targets Min            -309.308
trainer/Log Pis Mean                1.93247
trainer/Log Pis Std                 1.35333
trainer/Log Pis Max                 4.72422
trainer/Log Pis Min                -2.66257
trainer/Policy mu Mean              0.00956527
trainer/Policy mu Std               0.513976
trainer/Policy mu Max               2.44303
trainer/Policy mu Min              -1.83781
trainer/Policy log std Mean        -2.16723
trainer/Policy log std Std          0.45857
trainer/Policy log std Max         -0.881811
trainer/Policy log std Min         -2.93444
trainer/Alpha                       0.0665073
trainer/Alpha Loss                 -0.183034
exploration/num steps total     37700
exploration/num paths total       377
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -2.21322
exploration/Rewards Std             2.31456
exploration/Rewards Max            -0.0401748
exploration/Rewards Min            -9.73523
exploration/Returns Mean         -221.322
exploration/Returns Std           216.107
exploration/Returns Max           -31.0394
exploration/Returns Min          -634.855
exploration/Actions Mean            0.00217027
exploration/Actions Std             0.228536
exploration/Actions Max             0.999921
exploration/Actions Min            -0.985084
exploration/Num Paths               5
exploration/Average Returns      -221.322
evaluation/num steps total     112500
evaluation/num paths total       1125
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -2.54603
evaluation/Rewards Std              1.89331
evaluation/Rewards Max             -0.104698
evaluation/Rewards Min            -10.7413
evaluation/Returns Mean          -254.603
evaluation/Returns Std            170.363
evaluation/Returns Max            -24.436
evaluation/Returns Min           -642.894
evaluation/Actions Mean            -0.00175015
evaluation/Actions Std              0.187694
evaluation/Actions Max              0.999514
evaluation/Actions Min             -0.999755
evaluation/Num Paths               15
evaluation/Average Returns       -254.603
time/data storing (s)               0.00302237
time/evaluation sampling (s)        0.332681
time/exploration sampling (s)       0.137656
time/logging (s)                    0.00472479
time/saving (s)                     0.00199677
time/training (s)                   1.9588
time/epoch (s)                      2.43888
time/total (s)                    183.008
Epoch                              74
-----------------------------  ---------------
2019-04-23 01:16:36.261222 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 75 finished
-----------------------------  ---------------
replay_buffer/size              38200
trainer/QF1 Loss                  651.027
trainer/QF2 Loss                  652.358
trainer/Policy Loss               115.262
trainer/Q1 Predictions Mean      -113.758
trainer/Q1 Predictions Std         84.0147
trainer/Q1 Predictions Max        -21.2145
trainer/Q1 Predictions Min       -305.984
trainer/Q2 Predictions Mean      -113.742
trainer/Q2 Predictions Std         84.0387
trainer/Q2 Predictions Max        -21.322
trainer/Q2 Predictions Min       -306.497
trainer/Q Targets Mean           -111.022
trainer/Q Targets Std              85.6786
trainer/Q Targets Max              -0.96813
trainer/Q Targets Min            -309.75
trainer/Log Pis Mean                2.09251
trainer/Log Pis Std                 1.12815
trainer/Log Pis Max                 6.27356
trainer/Log Pis Min                -1.85591
trainer/Policy mu Mean             -0.0292462
trainer/Policy mu Std               0.628712
trainer/Policy mu Max               2.75583
trainer/Policy mu Min              -2.88543
trainer/Policy log std Mean        -2.12941
trainer/Policy log std Std          0.527844
trainer/Policy log std Max         -0.159257
trainer/Policy log std Min         -2.82414
trainer/Alpha                       0.0672386
trainer/Alpha Loss                  0.249723
exploration/num steps total     38200
exploration/num paths total       382
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -2.10135
exploration/Rewards Std             1.51422
exploration/Rewards Max            -0.615213
exploration/Rewards Min            -7.38517
exploration/Returns Mean         -210.135
exploration/Returns Std           134.967
exploration/Returns Max           -96.4905
exploration/Returns Min          -445.188
exploration/Actions Mean           -0.00415909
exploration/Actions Std             0.203557
exploration/Actions Max             0.991094
exploration/Actions Min            -0.995578
exploration/Num Paths               5
exploration/Average Returns      -210.135
evaluation/num steps total     114000
evaluation/num paths total       1140
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -2.35741
evaluation/Rewards Std              1.93287
evaluation/Rewards Max             -0.224566
evaluation/Rewards Min            -11.5764
evaluation/Returns Mean          -235.741
evaluation/Returns Std            175.589
evaluation/Returns Max            -51.5713
evaluation/Returns Min           -654.417
evaluation/Actions Mean             0.0129449
evaluation/Actions Std              0.172762
evaluation/Actions Max              0.999071
evaluation/Actions Min             -0.998049
evaluation/Num Paths               15
evaluation/Average Returns       -235.741
time/data storing (s)               0.00299922
time/evaluation sampling (s)        0.327931
time/exploration sampling (s)       0.138242
time/logging (s)                    0.0046048
time/saving (s)                     0.00194284
time/training (s)                   1.97893
time/epoch (s)                      2.45465
time/total (s)                    185.467
Epoch                              75
-----------------------------  ---------------
2019-04-23 01:16:38.690573 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 76 finished
-----------------------------  ---------------
replay_buffer/size              38700
trainer/QF1 Loss                  379.086
trainer/QF2 Loss                  379.738
trainer/Policy Loss               116.689
trainer/Q1 Predictions Mean      -115.438
trainer/Q1 Predictions Std         81.4008
trainer/Q1 Predictions Max        -21.8747
trainer/Q1 Predictions Min       -310.159
trainer/Q2 Predictions Mean      -115.371
trainer/Q2 Predictions Std         81.3558
trainer/Q2 Predictions Max        -21.7479
trainer/Q2 Predictions Min       -310.054
trainer/Q Targets Mean           -113.239
trainer/Q Targets Std              83.0975
trainer/Q Targets Max              -3.08276
trainer/Q Targets Min            -311.4
trainer/Log Pis Mean                2.03197
trainer/Log Pis Std                 1.36066
trainer/Log Pis Max                 6.05542
trainer/Log Pis Min                -1.89126
trainer/Policy mu Mean             -0.0828909
trainer/Policy mu Std               0.726545
trainer/Policy mu Max               2.10678
trainer/Policy mu Min              -3.1565
trainer/Policy log std Mean        -2.04081
trainer/Policy log std Std          0.53436
trainer/Policy log std Max         -0.488928
trainer/Policy log std Min         -2.92889
trainer/Alpha                       0.0677415
trainer/Alpha Loss                  0.0860572
exploration/num steps total     38700
exploration/num paths total       387
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -2.49948
exploration/Rewards Std             1.10192
exploration/Rewards Max            -0.683452
exploration/Rewards Min            -8.27432
exploration/Returns Mean         -249.948
exploration/Returns Std            99.2145
exploration/Returns Max           -87.0887
exploration/Returns Min          -393.265
exploration/Actions Mean            0.0062097
exploration/Actions Std             0.170775
exploration/Actions Max             0.999696
exploration/Actions Min            -0.987743
exploration/Num Paths               5
exploration/Average Returns      -249.948
evaluation/num steps total     115500
evaluation/num paths total       1155
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -3.08104
evaluation/Rewards Std              2.17545
evaluation/Rewards Max             -0.182997
evaluation/Rewards Min            -10.576
evaluation/Returns Mean          -308.104
evaluation/Returns Std            207.091
evaluation/Returns Max            -37.5505
evaluation/Returns Min           -640.22
evaluation/Actions Mean             0.0151436
evaluation/Actions Std              0.176018
evaluation/Actions Max              0.996595
evaluation/Actions Min             -0.997778
evaluation/Num Paths               15
evaluation/Average Returns       -308.104
time/data storing (s)               0.0029812
time/evaluation sampling (s)        0.327088
time/exploration sampling (s)       0.136051
time/logging (s)                    0.00468244
time/saving (s)                     0.00193991
time/training (s)                   1.95051
time/epoch (s)                      2.42325
time/total (s)                    187.895
Epoch                              76
-----------------------------  ---------------
2019-04-23 01:16:41.132519 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 77 finished
-----------------------------  ---------------
replay_buffer/size              39200
trainer/QF1 Loss                    4.79169
trainer/QF2 Loss                    4.4713
trainer/Policy Loss               126.322
trainer/Q1 Predictions Mean      -124.698
trainer/Q1 Predictions Std         83.2794
trainer/Q1 Predictions Max        -21.7955
trainer/Q1 Predictions Min       -308.164
trainer/Q2 Predictions Mean      -124.763
trainer/Q2 Predictions Std         83.3195
trainer/Q2 Predictions Max        -21.9167
trainer/Q2 Predictions Min       -308.545
trainer/Q Targets Mean           -126.219
trainer/Q Targets Std              84.6357
trainer/Q Targets Max             -21.6641
trainer/Q Targets Min            -312.648
trainer/Log Pis Mean                1.84473
trainer/Log Pis Std                 1.23228
trainer/Log Pis Max                 5.03526
trainer/Log Pis Min                -2.02521
trainer/Policy mu Mean             -0.0253732
trainer/Policy mu Std               0.57198
trainer/Policy mu Max               2.38743
trainer/Policy mu Min              -2.47611
trainer/Policy log std Mean        -2.06301
trainer/Policy log std Std          0.542309
trainer/Policy log std Max         -0.378779
trainer/Policy log std Min         -2.87643
trainer/Alpha                       0.0619359
trainer/Alpha Loss                 -0.431851
exploration/num steps total     39200
exploration/num paths total       392
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -3.39107
exploration/Rewards Std             1.11197
exploration/Rewards Max            -1.92968
exploration/Rewards Min            -9.69085
exploration/Returns Mean         -339.107
exploration/Returns Std            87.1083
exploration/Returns Max          -219.59
exploration/Returns Min          -489.996
exploration/Actions Mean            0.00347632
exploration/Actions Std             0.22691
exploration/Actions Max             0.996811
exploration/Actions Min            -0.996945
exploration/Num Paths               5
exploration/Average Returns      -339.107
evaluation/num steps total     117000
evaluation/num paths total       1170
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.25639
evaluation/Rewards Std              1.19642
evaluation/Rewards Max             -0.165195
evaluation/Rewards Min            -10.3907
evaluation/Returns Mean          -125.639
evaluation/Returns Std             95.2586
evaluation/Returns Max            -29.7046
evaluation/Returns Min           -350.178
evaluation/Actions Mean             0.00188169
evaluation/Actions Std              0.159672
evaluation/Actions Max              0.997576
evaluation/Actions Min             -0.998962
evaluation/Num Paths               15
evaluation/Average Returns       -125.639
time/data storing (s)               0.00305969
time/evaluation sampling (s)        0.327588
time/exploration sampling (s)       0.141411
time/logging (s)                    0.00483955
time/saving (s)                     0.00196795
time/training (s)                   1.9572
time/epoch (s)                      2.43606
time/total (s)                    190.335
Epoch                              77
-----------------------------  ---------------
2019-04-23 01:16:43.586636 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 78 finished
-----------------------------  ---------------
replay_buffer/size              39700
trainer/QF1 Loss                    1.97114
trainer/QF2 Loss                    1.96053
trainer/Policy Loss               132.92
trainer/Q1 Predictions Mean      -131.348
trainer/Q1 Predictions Std         85.496
trainer/Q1 Predictions Max        -21.6555
trainer/Q1 Predictions Min       -313.862
trainer/Q2 Predictions Mean      -131.34
trainer/Q2 Predictions Std         85.5018
trainer/Q2 Predictions Max        -21.6561
trainer/Q2 Predictions Min       -314.521
trainer/Q Targets Mean           -132.263
trainer/Q Targets Std              86.0768
trainer/Q Targets Max             -21.6783
trainer/Q Targets Min            -315.253
trainer/Log Pis Mean                1.99438
trainer/Log Pis Std                 1.32329
trainer/Log Pis Max                 5.21788
trainer/Log Pis Min                -2.21139
trainer/Policy mu Mean             -0.159967
trainer/Policy mu Std               0.678723
trainer/Policy mu Max               2.61002
trainer/Policy mu Min              -3.09287
trainer/Policy log std Mean        -1.99562
trainer/Policy log std Std          0.539565
trainer/Policy log std Max         -0.402863
trainer/Policy log std Min         -3.09087
trainer/Alpha                       0.061063
trainer/Alpha Loss                 -0.0156996
exploration/num steps total     39700
exploration/num paths total       397
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -3.26504
exploration/Rewards Std             2.36569
exploration/Rewards Max            -0.0288918
exploration/Rewards Min            -9.85764
exploration/Returns Mean         -326.504
exploration/Returns Std           220.645
exploration/Returns Max           -36.3361
exploration/Returns Min          -563.771
exploration/Actions Mean            0.0121369
exploration/Actions Std             0.285035
exploration/Actions Max             0.998698
exploration/Actions Min            -0.997005
exploration/Num Paths               5
exploration/Average Returns      -326.504
evaluation/num steps total     118500
evaluation/num paths total       1185
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -2.7479
evaluation/Rewards Std              2.11198
evaluation/Rewards Max             -0.108076
evaluation/Rewards Min            -10.7568
evaluation/Returns Mean          -274.79
evaluation/Returns Std            199.834
evaluation/Returns Max            -48.8045
evaluation/Returns Min           -568.066
evaluation/Actions Mean            -0.00915433
evaluation/Actions Std              0.175799
evaluation/Actions Max              0.997954
evaluation/Actions Min             -0.999373
evaluation/Num Paths               15
evaluation/Average Returns       -274.79
time/data storing (s)               0.0029605
time/evaluation sampling (s)        0.332732
time/exploration sampling (s)       0.141022
time/logging (s)                    0.00478377
time/saving (s)                     0.00197656
time/training (s)                   1.96455
time/epoch (s)                      2.44803
time/total (s)                    192.788
Epoch                              78
-----------------------------  ---------------
2019-04-23 01:16:46.028355 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 79 finished
-----------------------------  ----------------
replay_buffer/size              40200
trainer/QF1 Loss                    9.10285
trainer/QF2 Loss                    8.89172
trainer/Policy Loss               111.585
trainer/Q1 Predictions Mean      -110.124
trainer/Q1 Predictions Std         81.0212
trainer/Q1 Predictions Max        -21.4054
trainer/Q1 Predictions Min       -312.063
trainer/Q2 Predictions Mean      -110.121
trainer/Q2 Predictions Std         81.0074
trainer/Q2 Predictions Max        -21.2847
trainer/Q2 Predictions Min       -312.73
trainer/Q Targets Mean           -110.766
trainer/Q Targets Std              82.162
trainer/Q Targets Max              -0.42612
trainer/Q Targets Min            -314.754
trainer/Log Pis Mean                1.93412
trainer/Log Pis Std                 1.35119
trainer/Log Pis Max                 6.94675
trainer/Log Pis Min                -3.24071
trainer/Policy mu Mean             -0.0545974
trainer/Policy mu Std               0.670093
trainer/Policy mu Max               3.31692
trainer/Policy mu Min              -2.34756
trainer/Policy log std Mean        -2.07016
trainer/Policy log std Std          0.586478
trainer/Policy log std Max         -0.29927
trainer/Policy log std Min         -2.9481
trainer/Alpha                       0.0596548
trainer/Alpha Loss                 -0.185715
exploration/num steps total     40200
exploration/num paths total       402
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.04849
exploration/Rewards Std             0.77767
exploration/Rewards Max            -0.0644957
exploration/Rewards Min            -6.16972
exploration/Returns Mean         -104.849
exploration/Returns Std            56.9395
exploration/Returns Max           -39.0599
exploration/Returns Min          -187.58
exploration/Actions Mean            0.0184726
exploration/Actions Std             0.200927
exploration/Actions Max             0.999379
exploration/Actions Min            -0.958202
exploration/Num Paths               5
exploration/Average Returns      -104.849
evaluation/num steps total     120000
evaluation/num paths total       1200
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.42463
evaluation/Rewards Std              1.25524
evaluation/Rewards Max             -0.240917
evaluation/Rewards Min            -10.1819
evaluation/Returns Mean          -142.463
evaluation/Returns Std             96.1115
evaluation/Returns Max            -46.5707
evaluation/Returns Min           -341.614
evaluation/Actions Mean             0.000761009
evaluation/Actions Std              0.177584
evaluation/Actions Max              0.997862
evaluation/Actions Min             -0.998301
evaluation/Num Paths               15
evaluation/Average Returns       -142.463
time/data storing (s)               0.0029516
time/evaluation sampling (s)        0.332956
time/exploration sampling (s)       0.13992
time/logging (s)                    0.0046763
time/saving (s)                     0.0019554
time/training (s)                   1.95289
time/epoch (s)                      2.43535
time/total (s)                    195.227
Epoch                              79
-----------------------------  ----------------
2019-04-23 01:16:48.485539 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 80 finished
-----------------------------  ---------------
replay_buffer/size              40700
trainer/QF1 Loss                 1523.03
trainer/QF2 Loss                 1518.31
trainer/Policy Loss               134.223
trainer/Q1 Predictions Mean      -132.777
trainer/Q1 Predictions Std         86.2645
trainer/Q1 Predictions Max        -21.859
trainer/Q1 Predictions Min       -314.16
trainer/Q2 Predictions Mean      -132.701
trainer/Q2 Predictions Std         86.1761
trainer/Q2 Predictions Max        -21.7861
trainer/Q2 Predictions Min       -314.363
trainer/Q Targets Mean           -126.909
trainer/Q Targets Std              86.3845
trainer/Q Targets Max              -0.845944
trainer/Q Targets Min            -315.069
trainer/Log Pis Mean                1.88743
trainer/Log Pis Std                 1.18984
trainer/Log Pis Max                 4.97305
trainer/Log Pis Min                -1.65923
trainer/Policy mu Mean             -0.0555089
trainer/Policy mu Std               0.648145
trainer/Policy mu Max               3.17446
trainer/Policy mu Min              -2.87667
trainer/Policy log std Mean        -2.02894
trainer/Policy log std Std          0.519555
trainer/Policy log std Max         -0.194119
trainer/Policy log std Min         -2.91743
trainer/Alpha                       0.0596535
trainer/Alpha Loss                 -0.317358
exploration/num steps total     40700
exploration/num paths total       407
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.32794
exploration/Rewards Std             1.25648
exploration/Rewards Max            -0.0504901
exploration/Rewards Min            -9.54441
exploration/Returns Mean         -132.794
exploration/Returns Std            60.0822
exploration/Returns Max           -72.9902
exploration/Returns Min          -217.1
exploration/Actions Mean           -0.0145602
exploration/Actions Std             0.216632
exploration/Actions Max             0.99739
exploration/Actions Min            -0.999439
exploration/Num Paths               5
exploration/Average Returns      -132.794
evaluation/num steps total     121500
evaluation/num paths total       1215
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.83759
evaluation/Rewards Std              1.8083
evaluation/Rewards Max             -0.162003
evaluation/Rewards Min             -8.67374
evaluation/Returns Mean          -183.759
evaluation/Returns Std            166.488
evaluation/Returns Max            -17.6008
evaluation/Returns Min           -564.896
evaluation/Actions Mean             0.00277804
evaluation/Actions Std              0.170314
evaluation/Actions Max              0.996064
evaluation/Actions Min             -0.999369
evaluation/Num Paths               15
evaluation/Average Returns       -183.759
time/data storing (s)               0.00288515
time/evaluation sampling (s)        0.327417
time/exploration sampling (s)       0.139796
time/logging (s)                    0.00477773
time/saving (s)                     0.00207705
time/training (s)                   1.9742
time/epoch (s)                      2.45115
time/total (s)                    197.683
Epoch                              80
-----------------------------  ---------------
2019-04-23 01:16:50.932450 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 81 finished
-----------------------------  ---------------
replay_buffer/size              41200
trainer/QF1 Loss                    3.79868
trainer/QF2 Loss                    3.67059
trainer/Policy Loss               118.45
trainer/Q1 Predictions Mean      -116.756
trainer/Q1 Predictions Std         80.4972
trainer/Q1 Predictions Max        -21.1795
trainer/Q1 Predictions Min       -309.496
trainer/Q2 Predictions Mean      -116.775
trainer/Q2 Predictions Std         80.4546
trainer/Q2 Predictions Max        -21.3808
trainer/Q2 Predictions Min       -310.371
trainer/Q Targets Mean           -118.225
trainer/Q Targets Std              81.2117
trainer/Q Targets Max             -21.3096
trainer/Q Targets Min            -315.587
trainer/Log Pis Mean                2.26889
trainer/Log Pis Std                 1.39349
trainer/Log Pis Max                 6.28883
trainer/Log Pis Min                -1.96929
trainer/Policy mu Mean             -0.16059
trainer/Policy mu Std               0.83844
trainer/Policy mu Max               3.80074
trainer/Policy mu Min              -3.19629
trainer/Policy log std Mean        -2.07608
trainer/Policy log std Std          0.672864
trainer/Policy log std Max         -0.0149934
trainer/Policy log std Min         -3.11246
trainer/Alpha                       0.0619083
trainer/Alpha Loss                  0.748175
exploration/num steps total     41200
exploration/num paths total       412
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -4.24954
exploration/Rewards Std             1.16544
exploration/Rewards Max            -1.9134
exploration/Rewards Min            -9.59421
exploration/Returns Mean         -424.954
exploration/Returns Std           104.342
exploration/Returns Max          -304.374
exploration/Returns Min          -591.027
exploration/Actions Mean            0.0105348
exploration/Actions Std             0.261706
exploration/Actions Max             0.995666
exploration/Actions Min            -0.997909
exploration/Num Paths               5
exploration/Average Returns      -424.954
evaluation/num steps total     123000
evaluation/num paths total       1230
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -2.61498
evaluation/Rewards Std              1.9115
evaluation/Rewards Max             -0.0479388
evaluation/Rewards Min            -11.3255
evaluation/Returns Mean          -261.498
evaluation/Returns Std            171.136
evaluation/Returns Max            -19.58
evaluation/Returns Min           -593.322
evaluation/Actions Mean             0.00719932
evaluation/Actions Std              0.169898
evaluation/Actions Max              0.999002
evaluation/Actions Min             -0.998711
evaluation/Num Paths               15
evaluation/Average Returns       -261.498
time/data storing (s)               0.00279924
time/evaluation sampling (s)        0.328444
time/exploration sampling (s)       0.139551
time/logging (s)                    0.00475802
time/saving (s)                     0.00193687
time/training (s)                   1.96311
time/epoch (s)                      2.4406
time/total (s)                    200.128
Epoch                              81
-----------------------------  ---------------
2019-04-23 01:16:53.370615 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 82 finished
-----------------------------  ---------------
replay_buffer/size              41700
trainer/QF1 Loss                  215.631
trainer/QF2 Loss                  215.59
trainer/Policy Loss               142.096
trainer/Q1 Predictions Mean      -140.879
trainer/Q1 Predictions Std         95.8392
trainer/Q1 Predictions Max        -21.2803
trainer/Q1 Predictions Min       -310.27
trainer/Q2 Predictions Mean      -140.868
trainer/Q2 Predictions Std         95.9409
trainer/Q2 Predictions Max        -21.458
trainer/Q2 Predictions Min       -310.835
trainer/Q Targets Mean           -140.99
trainer/Q Targets Std              97.8697
trainer/Q Targets Max              -3.35731
trainer/Q Targets Min            -314.906
trainer/Log Pis Mean                1.59521
trainer/Log Pis Std                 1.33867
trainer/Log Pis Max                 5.4496
trainer/Log Pis Min                -3.01956
trainer/Policy mu Mean             -0.0924554
trainer/Policy mu Std               0.567118
trainer/Policy mu Max               2.8007
trainer/Policy mu Min              -1.74104
trainer/Policy log std Mean        -1.97504
trainer/Policy log std Std          0.564659
trainer/Policy log std Max         -0.514889
trainer/Policy log std Min         -2.89443
trainer/Alpha                       0.0612737
trainer/Alpha Loss                 -1.13021
exploration/num steps total     41700
exploration/num paths total       417
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -3.10061
exploration/Rewards Std             1.08476
exploration/Rewards Max            -0.990977
exploration/Rewards Min            -7.87719
exploration/Returns Mean         -310.061
exploration/Returns Std            97.4079
exploration/Returns Max          -125.852
exploration/Returns Min          -389.563
exploration/Actions Mean           -0.00919791
exploration/Actions Std             0.221937
exploration/Actions Max             0.996493
exploration/Actions Min            -0.995413
exploration/Num Paths               5
exploration/Average Returns      -310.061
evaluation/num steps total     124500
evaluation/num paths total       1245
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -2.02387
evaluation/Rewards Std              1.88064
evaluation/Rewards Max             -0.149789
evaluation/Rewards Min            -11.8474
evaluation/Returns Mean          -202.387
evaluation/Returns Std            172.328
evaluation/Returns Max            -16.2405
evaluation/Returns Min           -552.707
evaluation/Actions Mean             0.0108877
evaluation/Actions Std              0.169483
evaluation/Actions Max              0.998541
evaluation/Actions Min             -0.990048
evaluation/Num Paths               15
evaluation/Average Returns       -202.387
time/data storing (s)               0.00298426
time/evaluation sampling (s)        0.328543
time/exploration sampling (s)       0.141411
time/logging (s)                    0.00478735
time/saving (s)                     0.0019495
time/training (s)                   1.95222
time/epoch (s)                      2.4319
time/total (s)                    202.565
Epoch                              82
-----------------------------  ---------------
2019-04-23 01:16:55.825942 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 83 finished
-----------------------------  ---------------
replay_buffer/size              42200
trainer/QF1 Loss                  905.611
trainer/QF2 Loss                  903.181
trainer/Policy Loss               113.389
trainer/Q1 Predictions Mean      -111.957
trainer/Q1 Predictions Std         85.5661
trainer/Q1 Predictions Max        -21.3925
trainer/Q1 Predictions Min       -308.387
trainer/Q2 Predictions Mean      -111.968
trainer/Q2 Predictions Std         85.6026
trainer/Q2 Predictions Max        -21.398
trainer/Q2 Predictions Min       -308.425
trainer/Q Targets Mean           -109.605
trainer/Q Targets Std              84.7615
trainer/Q Targets Max              -6.39365
trainer/Q Targets Min            -312.33
trainer/Log Pis Mean                1.85651
trainer/Log Pis Std                 1.30943
trainer/Log Pis Max                 4.95873
trainer/Log Pis Min                -3.14374
trainer/Policy mu Mean             -0.142887
trainer/Policy mu Std               0.577846
trainer/Policy mu Max               2.30726
trainer/Policy mu Min              -2.55612
trainer/Policy log std Mean        -2.07933
trainer/Policy log std Std          0.573112
trainer/Policy log std Max         -0.541497
trainer/Policy log std Min         -3.10698
trainer/Alpha                       0.0607693
trainer/Alpha Loss                 -0.401885
exploration/num steps total     42200
exploration/num paths total       422
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -2.31822
exploration/Rewards Std             2.04475
exploration/Rewards Max            -0.0191447
exploration/Rewards Min           -10.1497
exploration/Returns Mean         -231.822
exploration/Returns Std           171.98
exploration/Returns Max           -60.9976
exploration/Returns Min          -523.945
exploration/Actions Mean            0.0321823
exploration/Actions Std             0.278317
exploration/Actions Max             0.998354
exploration/Actions Min            -0.999416
exploration/Num Paths               5
exploration/Average Returns      -231.822
evaluation/num steps total     126000
evaluation/num paths total       1260
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -2.6605
evaluation/Rewards Std              2.00497
evaluation/Rewards Max             -0.255381
evaluation/Rewards Min            -11.1857
evaluation/Returns Mean          -266.05
evaluation/Returns Std            176.973
evaluation/Returns Max            -29.1297
evaluation/Returns Min           -538.043
evaluation/Actions Mean            -0.00491345
evaluation/Actions Std              0.18488
evaluation/Actions Max              0.9958
evaluation/Actions Min             -0.998725
evaluation/Num Paths               15
evaluation/Average Returns       -266.05
time/data storing (s)               0.00303747
time/evaluation sampling (s)        0.32964
time/exploration sampling (s)       0.137839
time/logging (s)                    0.00476829
time/saving (s)                     0.00192477
time/training (s)                   1.97176
time/epoch (s)                      2.44896
time/total (s)                    205.018
Epoch                              83
-----------------------------  ---------------
2019-04-23 01:16:58.262006 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 84 finished
-----------------------------  ---------------
replay_buffer/size              42700
trainer/QF1 Loss                  221.024
trainer/QF2 Loss                  220.22
trainer/Policy Loss               132.178
trainer/Q1 Predictions Mean      -130.64
trainer/Q1 Predictions Std         79.4015
trainer/Q1 Predictions Max        -21.6553
trainer/Q1 Predictions Min       -307.394
trainer/Q2 Predictions Mean      -130.667
trainer/Q2 Predictions Std         79.3523
trainer/Q2 Predictions Max        -21.7646
trainer/Q2 Predictions Min       -307.728
trainer/Q Targets Mean           -130.537
trainer/Q Targets Std              81.4357
trainer/Q Targets Max              -2.8421
trainer/Q Targets Min            -311.218
trainer/Log Pis Mean                2.16853
trainer/Log Pis Std                 1.30425
trainer/Log Pis Max                 5.6476
trainer/Log Pis Min                -1.9639
trainer/Policy mu Mean              0.0211153
trainer/Policy mu Std               0.666405
trainer/Policy mu Max               3.35249
trainer/Policy mu Min              -3.36317
trainer/Policy log std Mean        -2.16741
trainer/Policy log std Std          0.527809
trainer/Policy log std Max         -0.400249
trainer/Policy log std Min         -3.09539
trainer/Alpha                       0.0615313
trainer/Alpha Loss                  0.469937
exploration/num steps total     42700
exploration/num paths total       427
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -2.94251
exploration/Rewards Std             1.53624
exploration/Rewards Max            -0.166557
exploration/Rewards Min            -8.2976
exploration/Returns Mean         -294.251
exploration/Returns Std           138.976
exploration/Returns Max           -71.4827
exploration/Returns Min          -456.634
exploration/Actions Mean            0.0219722
exploration/Actions Std             0.201034
exploration/Actions Max             0.998729
exploration/Actions Min            -0.981405
exploration/Num Paths               5
exploration/Average Returns      -294.251
evaluation/num steps total     127500
evaluation/num paths total       1275
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -2.96657
evaluation/Rewards Std              1.91227
evaluation/Rewards Max             -0.202819
evaluation/Rewards Min            -10.1559
evaluation/Returns Mean          -296.657
evaluation/Returns Std            177.621
evaluation/Returns Max            -27.6358
evaluation/Returns Min           -495.303
evaluation/Actions Mean             0.0080414
evaluation/Actions Std              0.15861
evaluation/Actions Max              0.999304
evaluation/Actions Min             -0.996363
evaluation/Num Paths               15
evaluation/Average Returns       -296.657
time/data storing (s)               0.00304936
time/evaluation sampling (s)        0.333803
time/exploration sampling (s)       0.136897
time/logging (s)                    0.00476488
time/saving (s)                     0.00194515
time/training (s)                   1.94981
time/epoch (s)                      2.43027
time/total (s)                    207.452
Epoch                              84
-----------------------------  ---------------
2019-04-23 01:17:00.766669 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 85 finished
-----------------------------  ---------------
replay_buffer/size              43200
trainer/QF1 Loss                  220.603
trainer/QF2 Loss                  220.296
trainer/Policy Loss               118.829
trainer/Q1 Predictions Mean      -117.068
trainer/Q1 Predictions Std         84.9168
trainer/Q1 Predictions Max        -21.259
trainer/Q1 Predictions Min       -305.575
trainer/Q2 Predictions Mean      -117.094
trainer/Q2 Predictions Std         84.8782
trainer/Q2 Predictions Max        -21.2713
trainer/Q2 Predictions Min       -305.394
trainer/Q Targets Mean           -117.172
trainer/Q Targets Std              87.7592
trainer/Q Targets Max              -1.37714
trainer/Q Targets Min            -312.455
trainer/Log Pis Mean                2.16944
trainer/Log Pis Std                 1.11218
trainer/Log Pis Max                 4.00117
trainer/Log Pis Min                -1.61011
trainer/Policy mu Mean             -0.0762306
trainer/Policy mu Std               0.541945
trainer/Policy mu Max               1.78236
trainer/Policy mu Min              -2.80173
trainer/Policy log std Mean        -2.24862
trainer/Policy log std Std          0.51435
trainer/Policy log std Max         -0.532109
trainer/Policy log std Min         -3.04625
trainer/Alpha                       0.0651401
trainer/Alpha Loss                  0.462791
exploration/num steps total     43200
exploration/num paths total       432
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.87921
exploration/Rewards Std             1.72746
exploration/Rewards Max            -0.030638
exploration/Rewards Min            -9.81844
exploration/Returns Mean         -187.921
exploration/Returns Std           128.556
exploration/Returns Max           -65.6571
exploration/Returns Min          -393.694
exploration/Actions Mean            0.0294009
exploration/Actions Std             0.237046
exploration/Actions Max             0.999566
exploration/Actions Min            -0.999987
exploration/Num Paths               5
exploration/Average Returns      -187.921
evaluation/num steps total     129000
evaluation/num paths total       1290
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -2.21281
evaluation/Rewards Std              1.87312
evaluation/Rewards Max             -0.0276232
evaluation/Rewards Min            -10.2843
evaluation/Returns Mean          -221.281
evaluation/Returns Std            174.972
evaluation/Returns Max            -14.0237
evaluation/Returns Min           -569.6
evaluation/Actions Mean             0.0170382
evaluation/Actions Std              0.168214
evaluation/Actions Max              0.993434
evaluation/Actions Min             -0.998556
evaluation/Num Paths               15
evaluation/Average Returns       -221.281
time/data storing (s)               0.00298471
time/evaluation sampling (s)        0.333529
time/exploration sampling (s)       0.138791
time/logging (s)                    0.00447553
time/saving (s)                     0.00159414
time/training (s)                   2.01665
time/epoch (s)                      2.49803
time/total (s)                    209.955
Epoch                              85
-----------------------------  ---------------
2019-04-23 01:17:03.253074 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 86 finished
-----------------------------  ----------------
replay_buffer/size              43700
trainer/QF1 Loss                    3.566
trainer/QF2 Loss                    3.97006
trainer/Policy Loss               126.716
trainer/Q1 Predictions Mean      -125.452
trainer/Q1 Predictions Std         86.0289
trainer/Q1 Predictions Max        -21.5424
trainer/Q1 Predictions Min       -308.152
trainer/Q2 Predictions Mean      -125.425
trainer/Q2 Predictions Std         85.9704
trainer/Q2 Predictions Max        -21.7642
trainer/Q2 Predictions Min       -308.436
trainer/Q Targets Mean           -126.622
trainer/Q Targets Std              86.9802
trainer/Q Targets Max             -21.6169
trainer/Q Targets Min            -310.916
trainer/Log Pis Mean                2.13086
trainer/Log Pis Std                 1.20589
trainer/Log Pis Max                 4.76965
trainer/Log Pis Min                -1.51795
trainer/Policy mu Mean             -0.394174
trainer/Policy mu Std               0.81486
trainer/Policy mu Max               2.62574
trainer/Policy mu Min              -3.54107
trainer/Policy log std Mean        -1.87834
trainer/Policy log std Std          0.67974
trainer/Policy log std Max          0.323692
trainer/Policy log std Min         -3.03646
trainer/Alpha                       0.0629045
trainer/Alpha Loss                  0.361995
exploration/num steps total     43700
exploration/num paths total       437
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -2.35437
exploration/Rewards Std             2.12547
exploration/Rewards Max            -0.124086
exploration/Rewards Min            -7.891
exploration/Returns Mean         -235.437
exploration/Returns Std           208.97
exploration/Returns Max           -58.9988
exploration/Returns Min          -629.336
exploration/Actions Mean            0.00136092
exploration/Actions Std             0.223337
exploration/Actions Max             0.971186
exploration/Actions Min            -0.997149
exploration/Num Paths               5
exploration/Average Returns      -235.437
evaluation/num steps total     130500
evaluation/num paths total       1305
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -2.00143
evaluation/Rewards Std              1.77437
evaluation/Rewards Max             -0.372522
evaluation/Rewards Min             -8.90655
evaluation/Returns Mean          -200.143
evaluation/Returns Std            165.348
evaluation/Returns Max            -54.8336
evaluation/Returns Min           -622.015
evaluation/Actions Mean             0.000536961
evaluation/Actions Std              0.158358
evaluation/Actions Max              0.996954
evaluation/Actions Min             -0.997195
evaluation/Num Paths               15
evaluation/Average Returns       -200.143
time/data storing (s)               0.00287216
time/evaluation sampling (s)        0.335782
time/exploration sampling (s)       0.137762
time/logging (s)                    0.004761
time/saving (s)                     0.00182146
time/training (s)                   1.99758
time/epoch (s)                      2.48058
time/total (s)                    212.44
Epoch                              86
-----------------------------  ----------------
2019-04-23 01:17:05.712820 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 87 finished
-----------------------------  ---------------
replay_buffer/size              44200
trainer/QF1 Loss                   55.2619
trainer/QF2 Loss                   55.4736
trainer/Policy Loss               120.673
trainer/Q1 Predictions Mean      -119.009
trainer/Q1 Predictions Std         80.4374
trainer/Q1 Predictions Max        -21.1649
trainer/Q1 Predictions Min       -305.64
trainer/Q2 Predictions Mean      -118.98
trainer/Q2 Predictions Std         80.3681
trainer/Q2 Predictions Max        -21.3853
trainer/Q2 Predictions Min       -305.433
trainer/Q Targets Mean           -119.507
trainer/Q Targets Std              82.6741
trainer/Q Targets Max              -0.42612
trainer/Q Targets Min            -310.643
trainer/Log Pis Mean                2.01613
trainer/Log Pis Std                 1.17115
trainer/Log Pis Max                 4.64623
trainer/Log Pis Min                -1.69378
trainer/Policy mu Mean              0.0191499
trainer/Policy mu Std               0.57486
trainer/Policy mu Max               2.80504
trainer/Policy mu Min              -2.21251
trainer/Policy log std Mean        -2.18123
trainer/Policy log std Std          0.591311
trainer/Policy log std Max         -0.379044
trainer/Policy log std Min         -3.10952
trainer/Alpha                       0.062166
trainer/Alpha Loss                  0.0448145
exploration/num steps total     44200
exploration/num paths total       442
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -2.87953
exploration/Rewards Std             1.88538
exploration/Rewards Max            -0.0825592
exploration/Rewards Min            -7.74551
exploration/Returns Mean         -287.953
exploration/Returns Std           178.074
exploration/Returns Max           -63.0354
exploration/Returns Min          -603.318
exploration/Actions Mean            0.0120203
exploration/Actions Std             0.239781
exploration/Actions Max             0.993564
exploration/Actions Min            -0.999016
exploration/Num Paths               5
exploration/Average Returns      -287.953
evaluation/num steps total     132000
evaluation/num paths total       1320
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.83136
evaluation/Rewards Std              2.07513
evaluation/Rewards Max             -0.163404
evaluation/Rewards Min            -10.5458
evaluation/Returns Mean          -183.136
evaluation/Returns Std            190.739
evaluation/Returns Max            -34.0854
evaluation/Returns Min           -605.925
evaluation/Actions Mean             0.00912116
evaluation/Actions Std              0.17793
evaluation/Actions Max              0.998959
evaluation/Actions Min             -0.992809
evaluation/Num Paths               15
evaluation/Average Returns       -183.136
time/data storing (s)               0.00297712
time/evaluation sampling (s)        0.328025
time/exploration sampling (s)       0.13887
time/logging (s)                    0.00477377
time/saving (s)                     0.00192514
time/training (s)                   1.97709
time/epoch (s)                      2.45366
time/total (s)                    214.898
Epoch                              87
-----------------------------  ---------------
2019-04-23 01:17:08.170480 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 88 finished
-----------------------------  ---------------
replay_buffer/size              44700
trainer/QF1 Loss                  913.014
trainer/QF2 Loss                  909.269
trainer/Policy Loss               126.79
trainer/Q1 Predictions Mean      -125.396
trainer/Q1 Predictions Std         82.6598
trainer/Q1 Predictions Max        -21.4659
trainer/Q1 Predictions Min       -309.006
trainer/Q2 Predictions Mean      -125.399
trainer/Q2 Predictions Std         82.6101
trainer/Q2 Predictions Max        -21.6332
trainer/Q2 Predictions Min       -308.873
trainer/Q Targets Mean           -123.072
trainer/Q Targets Std              81.8258
trainer/Q Targets Max              -5.28122
trainer/Q Targets Min            -310.631
trainer/Log Pis Mean                2.11559
trainer/Log Pis Std                 1.32543
trainer/Log Pis Max                 6.31662
trainer/Log Pis Min                -2.12365
trainer/Policy mu Mean             -0.105944
trainer/Policy mu Std               0.690768
trainer/Policy mu Max               2.198
trainer/Policy mu Min              -3.83149
trainer/Policy log std Mean        -2.16051
trainer/Policy log std Std          0.568285
trainer/Policy log std Max         -0.304559
trainer/Policy log std Min         -3.13635
trainer/Alpha                       0.0641524
trainer/Alpha Loss                  0.317496
exploration/num steps total     44700
exploration/num paths total       447
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -3.86215
exploration/Rewards Std             2.16337
exploration/Rewards Max            -0.692365
exploration/Rewards Min            -9.89215
exploration/Returns Mean         -386.215
exploration/Returns Std           198.054
exploration/Returns Max          -133.719
exploration/Returns Min          -556.288
exploration/Actions Mean            0.0336527
exploration/Actions Std             0.325405
exploration/Actions Max             0.99943
exploration/Actions Min            -0.998151
exploration/Num Paths               5
exploration/Average Returns      -386.215
evaluation/num steps total     133500
evaluation/num paths total       1335
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -2.34795
evaluation/Rewards Std              2.15939
evaluation/Rewards Max             -0.0365998
evaluation/Rewards Min            -10.5166
evaluation/Returns Mean          -234.795
evaluation/Returns Std            202.18
evaluation/Returns Max            -10.7442
evaluation/Returns Min           -539.43
evaluation/Actions Mean             0.00727715
evaluation/Actions Std              0.178837
evaluation/Actions Max              0.998323
evaluation/Actions Min             -0.994891
evaluation/Num Paths               15
evaluation/Average Returns       -234.795
time/data storing (s)               0.00279161
time/evaluation sampling (s)        0.32808
time/exploration sampling (s)       0.142483
time/logging (s)                    0.0043312
time/saving (s)                     0.00193671
time/training (s)                   1.9712
time/epoch (s)                      2.45082
time/total (s)                    217.353
Epoch                              88
-----------------------------  ---------------
2019-04-23 01:17:10.633555 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 89 finished
-----------------------------  ----------------
replay_buffer/size              45200
trainer/QF1 Loss                   91.8444
trainer/QF2 Loss                   91.1872
trainer/Policy Loss               144.21
trainer/Q1 Predictions Mean      -142.616
trainer/Q1 Predictions Std         91.4601
trainer/Q1 Predictions Max        -21.6796
trainer/Q1 Predictions Min       -308.082
trainer/Q2 Predictions Mean      -142.66
trainer/Q2 Predictions Std         91.4139
trainer/Q2 Predictions Max        -21.6832
trainer/Q2 Predictions Min       -308.676
trainer/Q Targets Mean           -142.69
trainer/Q Targets Std              93.1311
trainer/Q Targets Max              -2.26183
trainer/Q Targets Min            -311.018
trainer/Log Pis Mean                1.90644
trainer/Log Pis Std                 1.37806
trainer/Log Pis Max                 7.01145
trainer/Log Pis Min                -2.46679
trainer/Policy mu Mean             -0.0953873
trainer/Policy mu Std               0.713827
trainer/Policy mu Max               3.1164
trainer/Policy mu Min              -3.6961
trainer/Policy log std Mean        -1.95202
trainer/Policy log std Std          0.667848
trainer/Policy log std Max         -0.165464
trainer/Policy log std Min         -3.10827
trainer/Alpha                       0.0623631
trainer/Alpha Loss                 -0.259588
exploration/num steps total     45200
exploration/num paths total       452
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -2.99958
exploration/Rewards Std             1.33184
exploration/Rewards Max            -1.12857
exploration/Rewards Min           -10.4253
exploration/Returns Mean         -299.958
exploration/Returns Std           120.737
exploration/Returns Max          -142.935
exploration/Returns Min          -510.689
exploration/Actions Mean           -0.0024866
exploration/Actions Std             0.198649
exploration/Actions Max             0.996651
exploration/Actions Min            -0.999962
exploration/Num Paths               5
exploration/Average Returns      -299.958
evaluation/num steps total     135000
evaluation/num paths total       1350
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.90337
evaluation/Rewards Std              1.74228
evaluation/Rewards Max             -0.0584616
evaluation/Rewards Min            -10.4325
evaluation/Returns Mean          -190.337
evaluation/Returns Std            157.43
evaluation/Returns Max            -15.6046
evaluation/Returns Min           -498.758
evaluation/Actions Mean             0.000760599
evaluation/Actions Std              0.16916
evaluation/Actions Max              0.996562
evaluation/Actions Min             -0.998131
evaluation/Num Paths               15
evaluation/Average Returns       -190.337
time/data storing (s)               0.00304374
time/evaluation sampling (s)        0.330168
time/exploration sampling (s)       0.138583
time/logging (s)                    0.00474418
time/saving (s)                     0.00193724
time/training (s)                   1.97969
time/epoch (s)                      2.45816
time/total (s)                    219.815
Epoch                              89
-----------------------------  ----------------
2019-04-23 01:17:13.092237 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 90 finished
-----------------------------  ---------------
replay_buffer/size              45700
trainer/QF1 Loss                  647.769
trainer/QF2 Loss                  648.736
trainer/Policy Loss               118.707
trainer/Q1 Predictions Mean      -116.869
trainer/Q1 Predictions Std         92.5594
trainer/Q1 Predictions Max        -21.558
trainer/Q1 Predictions Min       -307.119
trainer/Q2 Predictions Mean      -116.88
trainer/Q2 Predictions Std         92.4784
trainer/Q2 Predictions Max        -21.6692
trainer/Q2 Predictions Min       -307.634
trainer/Q Targets Mean           -114.066
trainer/Q Targets Std              94.8981
trainer/Q Targets Max              -0.553988
trainer/Q Targets Min            -310.575
trainer/Log Pis Mean                2.30092
trainer/Log Pis Std                 1.06061
trainer/Log Pis Max                 6.23531
trainer/Log Pis Min                -0.502901
trainer/Policy mu Mean             -0.218008
trainer/Policy mu Std               0.717379
trainer/Policy mu Max               2.78289
trainer/Policy mu Min              -2.77788
trainer/Policy log std Mean        -2.01562
trainer/Policy log std Std          0.608808
trainer/Policy log std Max         -0.255264
trainer/Policy log std Min         -3.05406
trainer/Alpha                       0.0622597
trainer/Alpha Loss                  0.835585
exploration/num steps total     45700
exploration/num paths total       457
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.47452
exploration/Rewards Std             1.08503
exploration/Rewards Max            -0.0691246
exploration/Rewards Min            -8.54122
exploration/Returns Mean         -147.452
exploration/Returns Std            77.7972
exploration/Returns Max           -38.0687
exploration/Returns Min          -262.838
exploration/Actions Mean           -0.0126251
exploration/Actions Std             0.21322
exploration/Actions Max             0.995248
exploration/Actions Min            -0.999018
exploration/Num Paths               5
exploration/Average Returns      -147.452
evaluation/num steps total     136500
evaluation/num paths total       1365
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.52487
evaluation/Rewards Std              1.77274
evaluation/Rewards Max             -0.157496
evaluation/Rewards Min             -9.97493
evaluation/Returns Mean          -152.487
evaluation/Returns Std            155.615
evaluation/Returns Max            -27.0359
evaluation/Returns Min           -589.583
evaluation/Actions Mean             0.0249012
evaluation/Actions Std              0.16833
evaluation/Actions Max              0.99832
evaluation/Actions Min             -0.997069
evaluation/Num Paths               15
evaluation/Average Returns       -152.487
time/data storing (s)               0.00297761
time/evaluation sampling (s)        0.333332
time/exploration sampling (s)       0.142679
time/logging (s)                    0.0047722
time/saving (s)                     0.0100486
time/training (s)                   1.95877
time/epoch (s)                      2.45258
time/total (s)                    222.272
Epoch                              90
-----------------------------  ---------------
2019-04-23 01:17:15.540093 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 91 finished
-----------------------------  ---------------
replay_buffer/size              46200
trainer/QF1 Loss                    1.97478
trainer/QF2 Loss                    1.8519
trainer/Policy Loss               129.93
trainer/Q1 Predictions Mean      -128.478
trainer/Q1 Predictions Std         83.4275
trainer/Q1 Predictions Max        -21.0869
trainer/Q1 Predictions Min       -308.164
trainer/Q2 Predictions Mean      -128.497
trainer/Q2 Predictions Std         83.4405
trainer/Q2 Predictions Max        -21.1585
trainer/Q2 Predictions Min       -308.506
trainer/Q Targets Mean           -129.512
trainer/Q Targets Std              84.083
trainer/Q Targets Max             -21.285
trainer/Q Targets Min            -310.208
trainer/Log Pis Mean                1.95604
trainer/Log Pis Std                 1.1845
trainer/Log Pis Max                 5.85062
trainer/Log Pis Min                -1.9754
trainer/Policy mu Mean             -0.127294
trainer/Policy mu Std               0.638612
trainer/Policy mu Max               2.27985
trainer/Policy mu Min              -3.20497
trainer/Policy log std Mean        -2.04072
trainer/Policy log std Std          0.555303
trainer/Policy log std Max         -0.363309
trainer/Policy log std Min         -3.03325
trainer/Alpha                       0.0618077
trainer/Alpha Loss                 -0.122365
exploration/num steps total     46200
exploration/num paths total       462
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.74115
exploration/Rewards Std             1.14162
exploration/Rewards Max            -0.079279
exploration/Rewards Min            -5.50578
exploration/Returns Mean         -174.115
exploration/Returns Std           107.247
exploration/Returns Max           -44.1718
exploration/Returns Min          -369.52
exploration/Actions Mean            0.00360701
exploration/Actions Std             0.17267
exploration/Actions Max             0.953182
exploration/Actions Min            -0.978466
exploration/Num Paths               5
exploration/Average Returns      -174.115
evaluation/num steps total     138000
evaluation/num paths total       1380
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -2.0495
evaluation/Rewards Std              1.40971
evaluation/Rewards Max             -0.149938
evaluation/Rewards Min            -10.4667
evaluation/Returns Mean          -204.95
evaluation/Returns Std            120.295
evaluation/Returns Max            -24.763
evaluation/Returns Min           -465.566
evaluation/Actions Mean             0.00399655
evaluation/Actions Std              0.159572
evaluation/Actions Max              0.995829
evaluation/Actions Min             -0.999719
evaluation/Num Paths               15
evaluation/Average Returns       -204.95
time/data storing (s)               0.0027834
time/evaluation sampling (s)        0.329119
time/exploration sampling (s)       0.139368
time/logging (s)                    0.00475203
time/saving (s)                     0.00199684
time/training (s)                   1.96361
time/epoch (s)                      2.44162
time/total (s)                    224.718
Epoch                              91
-----------------------------  ---------------
2019-04-23 01:17:17.983685 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 92 finished
-----------------------------  ---------------
replay_buffer/size              46700
trainer/QF1 Loss                    9.34817
trainer/QF2 Loss                    9.51797
trainer/Policy Loss               121.599
trainer/Q1 Predictions Mean      -120.192
trainer/Q1 Predictions Std         86.8765
trainer/Q1 Predictions Max        -21.3661
trainer/Q1 Predictions Min       -307.998
trainer/Q2 Predictions Mean      -120.229
trainer/Q2 Predictions Std         86.7705
trainer/Q2 Predictions Max        -21.569
trainer/Q2 Predictions Min       -308.229
trainer/Q Targets Mean           -121.061
trainer/Q Targets Std              87.8946
trainer/Q Targets Max              -0.410865
trainer/Q Targets Min            -310.434
trainer/Log Pis Mean                2.0498
trainer/Log Pis Std                 1.54549
trainer/Log Pis Max                 6.91447
trainer/Log Pis Min                -4.07805
trainer/Policy mu Mean             -0.285671
trainer/Policy mu Std               1.00473
trainer/Policy mu Max               3.24875
trainer/Policy mu Min              -4.846
trainer/Policy log std Mean        -1.75465
trainer/Policy log std Std          0.713906
trainer/Policy log std Max          1.16802
trainer/Policy log std Min         -2.90573
trainer/Alpha                       0.0624469
trainer/Alpha Loss                  0.138129
exploration/num steps total     46700
exploration/num paths total       467
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.68099
exploration/Rewards Std             1.11177
exploration/Rewards Max            -0.0560396
exploration/Rewards Min            -8.43974
exploration/Returns Mean         -168.099
exploration/Returns Std            93.1511
exploration/Returns Max           -51.3143
exploration/Returns Min          -305.286
exploration/Actions Mean            0.00516172
exploration/Actions Std             0.23012
exploration/Actions Max             0.998214
exploration/Actions Min            -0.999886
exploration/Num Paths               5
exploration/Average Returns      -168.099
evaluation/num steps total     139500
evaluation/num paths total       1395
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -2.24202
evaluation/Rewards Std              1.63686
evaluation/Rewards Max             -0.127124
evaluation/Rewards Min            -10.3169
evaluation/Returns Mean          -224.202
evaluation/Returns Std            144.49
evaluation/Returns Max            -37.5658
evaluation/Returns Min           -427.088
evaluation/Actions Mean            -0.0072234
evaluation/Actions Std              0.176554
evaluation/Actions Max              0.99878
evaluation/Actions Min             -0.999891
evaluation/Num Paths               15
evaluation/Average Returns       -224.202
time/data storing (s)               0.00309033
time/evaluation sampling (s)        0.33045
time/exploration sampling (s)       0.138618
time/logging (s)                    0.00477581
time/saving (s)                     0.00193821
time/training (s)                   1.95795
time/epoch (s)                      2.43682
time/total (s)                    227.16
Epoch                              92
-----------------------------  ---------------
2019-04-23 01:17:20.441488 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 93 finished
-----------------------------  ---------------
replay_buffer/size              47200
trainer/QF1 Loss                  647.028
trainer/QF2 Loss                  644.928
trainer/Policy Loss               128.855
trainer/Q1 Predictions Mean      -127.462
trainer/Q1 Predictions Std         93.1981
trainer/Q1 Predictions Max        -21.4037
trainer/Q1 Predictions Min       -307.318
trainer/Q2 Predictions Mean      -127.551
trainer/Q2 Predictions Std         93.2822
trainer/Q2 Predictions Max        -21.4594
trainer/Q2 Predictions Min       -308.467
trainer/Q Targets Mean           -125.494
trainer/Q Targets Std              95.3302
trainer/Q Targets Max              -2.85422
trainer/Q Targets Min            -313.629
trainer/Log Pis Mean                1.92961
trainer/Log Pis Std                 1.38739
trainer/Log Pis Max                 7.33219
trainer/Log Pis Min                -3.46421
trainer/Policy mu Mean             -0.167525
trainer/Policy mu Std               0.710514
trainer/Policy mu Max               3.16022
trainer/Policy mu Min              -3.1048
trainer/Policy log std Mean        -1.99749
trainer/Policy log std Std          0.61973
trainer/Policy log std Max         -0.253473
trainer/Policy log std Min         -3.07537
trainer/Alpha                       0.0635367
trainer/Alpha Loss                 -0.194015
exploration/num steps total     47200
exploration/num paths total       472
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -2.31758
exploration/Rewards Std             1.71877
exploration/Rewards Max            -0.191292
exploration/Rewards Min            -5.79434
exploration/Returns Mean         -231.758
exploration/Returns Std           168.533
exploration/Returns Max           -88.7052
exploration/Returns Min          -479.35
exploration/Actions Mean            0.0145291
exploration/Actions Std             0.159662
exploration/Actions Max             0.959847
exploration/Actions Min            -0.931835
exploration/Num Paths               5
exploration/Average Returns      -231.758
evaluation/num steps total     141000
evaluation/num paths total       1410
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -2.62205
evaluation/Rewards Std              2.14431
evaluation/Rewards Max             -0.284145
evaluation/Rewards Min             -9.33795
evaluation/Returns Mean          -262.205
evaluation/Returns Std            203.303
evaluation/Returns Max            -36.0981
evaluation/Returns Min           -569.755
evaluation/Actions Mean             0.00161889
evaluation/Actions Std              0.148934
evaluation/Actions Max              0.994372
evaluation/Actions Min             -0.998669
evaluation/Num Paths               15
evaluation/Average Returns       -262.205
time/data storing (s)               0.00300959
time/evaluation sampling (s)        0.333272
time/exploration sampling (s)       0.137105
time/logging (s)                    0.00472377
time/saving (s)                     0.00152832
time/training (s)                   1.97159
time/epoch (s)                      2.45123
time/total (s)                    229.616
Epoch                              93
-----------------------------  ---------------
2019-04-23 01:17:22.887738 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 94 finished
-----------------------------  ---------------
replay_buffer/size              47700
trainer/QF1 Loss                    8.84845
trainer/QF2 Loss                    8.72719
trainer/Policy Loss               120.777
trainer/Q1 Predictions Mean      -119.302
trainer/Q1 Predictions Std         84.639
trainer/Q1 Predictions Max        -21.5222
trainer/Q1 Predictions Min       -307.435
trainer/Q2 Predictions Mean      -119.344
trainer/Q2 Predictions Std         84.6612
trainer/Q2 Predictions Max        -21.5363
trainer/Q2 Predictions Min       -308.857
trainer/Q Targets Mean           -120.464
trainer/Q Targets Std              85.9043
trainer/Q Targets Max              -0.55093
trainer/Q Targets Min            -312.229
trainer/Log Pis Mean                1.79828
trainer/Log Pis Std                 1.24544
trainer/Log Pis Max                 4.80272
trainer/Log Pis Min                -1.8044
trainer/Policy mu Mean              0.0968383
trainer/Policy mu Std               0.594324
trainer/Policy mu Max               2.69274
trainer/Policy mu Min              -2.6264
trainer/Policy log std Mean        -2.10529
trainer/Policy log std Std          0.56519
trainer/Policy log std Max         -0.373493
trainer/Policy log std Min         -3.21312
trainer/Alpha                       0.0635958
trainer/Alpha Loss                 -0.555799
exploration/num steps total     47700
exploration/num paths total       477
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.58414
exploration/Rewards Std             2.07014
exploration/Rewards Max            -0.0966645
exploration/Rewards Min           -10.2253
exploration/Returns Mean         -158.414
exploration/Returns Std           177.696
exploration/Returns Max           -37.1351
exploration/Returns Min          -510.687
exploration/Actions Mean            0.0370292
exploration/Actions Std             0.237399
exploration/Actions Max             0.999679
exploration/Actions Min            -0.936267
exploration/Num Paths               5
exploration/Average Returns      -158.414
evaluation/num steps total     142500
evaluation/num paths total       1425
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -3.08888
evaluation/Rewards Std              1.70515
evaluation/Rewards Max             -0.110959
evaluation/Rewards Min            -10.4887
evaluation/Returns Mean          -308.888
evaluation/Returns Std            157.205
evaluation/Returns Max            -22.2816
evaluation/Returns Min           -552.48
evaluation/Actions Mean             0.0156329
evaluation/Actions Std              0.164835
evaluation/Actions Max              0.998834
evaluation/Actions Min             -0.99147
evaluation/Num Paths               15
evaluation/Average Returns       -308.888
time/data storing (s)               0.00274725
time/evaluation sampling (s)        0.331116
time/exploration sampling (s)       0.136329
time/logging (s)                    0.00472902
time/saving (s)                     0.0019691
time/training (s)                   1.96311
time/epoch (s)                      2.44
time/total (s)                    232.06
Epoch                              94
-----------------------------  ---------------
2019-04-23 01:17:25.321230 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 95 finished
-----------------------------  ---------------
replay_buffer/size              48200
trainer/QF1 Loss                  492.435
trainer/QF2 Loss                  494.326
trainer/Policy Loss               132.842
trainer/Q1 Predictions Mean      -131.408
trainer/Q1 Predictions Std         88.6968
trainer/Q1 Predictions Max        -23.7187
trainer/Q1 Predictions Min       -306.836
trainer/Q2 Predictions Mean      -131.378
trainer/Q2 Predictions Std         88.7608
trainer/Q2 Predictions Max        -23.6179
trainer/Q2 Predictions Min       -307.07
trainer/Q Targets Mean           -130.012
trainer/Q Targets Std              89.8279
trainer/Q Targets Max              -6.75106
trainer/Q Targets Min            -310.294
trainer/Log Pis Mean                2.19542
trainer/Log Pis Std                 1.34891
trainer/Log Pis Max                 8.37485
trainer/Log Pis Min                -2.25712
trainer/Policy mu Mean             -0.299638
trainer/Policy mu Std               0.739875
trainer/Policy mu Max               2.07701
trainer/Policy mu Min              -4.33275
trainer/Policy log std Mean        -1.92953
trainer/Policy log std Std          0.611751
trainer/Policy log std Max         -0.143574
trainer/Policy log std Min         -3.0591
trainer/Alpha                       0.064888
trainer/Alpha Loss                  0.534523
exploration/num steps total     48200
exploration/num paths total       482
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.920408
exploration/Rewards Std             0.545889
exploration/Rewards Max            -0.441401
exploration/Rewards Min            -6.01852
exploration/Returns Mean          -92.0408
exploration/Returns Std            19.7796
exploration/Returns Max           -74.4645
exploration/Returns Min          -129.283
exploration/Actions Mean           -0.00552227
exploration/Actions Std             0.151309
exploration/Actions Max             0.848587
exploration/Actions Min            -0.998987
exploration/Num Paths               5
exploration/Average Returns       -92.0408
evaluation/num steps total     144000
evaluation/num paths total       1440
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -2.67975
evaluation/Rewards Std              2.25851
evaluation/Rewards Max             -0.307432
evaluation/Rewards Min            -10.0376
evaluation/Returns Mean          -267.975
evaluation/Returns Std            213.83
evaluation/Returns Max            -50.3321
evaluation/Returns Min           -606.782
evaluation/Actions Mean            -0.00686746
evaluation/Actions Std              0.18217
evaluation/Actions Max              0.995853
evaluation/Actions Min             -0.998223
evaluation/Num Paths               15
evaluation/Average Returns       -267.975
time/data storing (s)               0.00300898
time/evaluation sampling (s)        0.33087
time/exploration sampling (s)       0.137719
time/logging (s)                    0.0047668
time/saving (s)                     0.00193554
time/training (s)                   1.94882
time/epoch (s)                      2.42712
time/total (s)                    234.492
Epoch                              95
-----------------------------  ---------------
2019-04-23 01:17:27.778285 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 96 finished
-----------------------------  ----------------
replay_buffer/size              48700
trainer/QF1 Loss                    3.72559
trainer/QF2 Loss                    3.57052
trainer/Policy Loss               126.323
trainer/Q1 Predictions Mean      -124.703
trainer/Q1 Predictions Std         82.8326
trainer/Q1 Predictions Max        -21.6953
trainer/Q1 Predictions Min       -303.107
trainer/Q2 Predictions Mean      -124.702
trainer/Q2 Predictions Std         82.8678
trainer/Q2 Predictions Max        -21.4293
trainer/Q2 Predictions Min       -303.817
trainer/Q Targets Mean           -126.082
trainer/Q Targets Std              83.7906
trainer/Q Targets Max             -22.1597
trainer/Q Targets Min            -307.559
trainer/Log Pis Mean                2.04382
trainer/Log Pis Std                 1.1822
trainer/Log Pis Max                 4.29801
trainer/Log Pis Min                -2.44421
trainer/Policy mu Mean             -0.202804
trainer/Policy mu Std               0.663391
trainer/Policy mu Max               2.3765
trainer/Policy mu Min              -2.81269
trainer/Policy log std Mean        -2.07059
trainer/Policy log std Std          0.608799
trainer/Policy log std Max         -0.340181
trainer/Policy log std Min         -3.12857
trainer/Alpha                       0.0667594
trainer/Alpha Loss                  0.118602
exploration/num steps total     48700
exploration/num paths total       487
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -2.53321
exploration/Rewards Std             2.42106
exploration/Rewards Max            -0.00907769
exploration/Rewards Min            -9.02161
exploration/Returns Mean         -253.321
exploration/Returns Std           221.448
exploration/Returns Max           -47.3156
exploration/Returns Min          -594.07
exploration/Actions Mean            0.000463498
exploration/Actions Std             0.29702
exploration/Actions Max             0.998801
exploration/Actions Min            -0.999166
exploration/Num Paths               5
exploration/Average Returns      -253.321
evaluation/num steps total     145500
evaluation/num paths total       1455
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -2.21647
evaluation/Rewards Std              1.92185
evaluation/Rewards Max             -0.115425
evaluation/Rewards Min            -10.4895
evaluation/Returns Mean          -221.647
evaluation/Returns Std            182.607
evaluation/Returns Max            -20.6789
evaluation/Returns Min           -614.827
evaluation/Actions Mean            -0.00149836
evaluation/Actions Std              0.253525
evaluation/Actions Max              0.994671
evaluation/Actions Min             -0.998605
evaluation/Num Paths               15
evaluation/Average Returns       -221.647
time/data storing (s)               0.0028859
time/evaluation sampling (s)        0.332807
time/exploration sampling (s)       0.141532
time/logging (s)                    0.00480408
time/saving (s)                     0.00187014
time/training (s)                   1.96696
time/epoch (s)                      2.45086
time/total (s)                    236.947
Epoch                              96
-----------------------------  ----------------
2019-04-23 01:17:30.231095 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 97 finished
-----------------------------  ---------------
replay_buffer/size              49200
trainer/QF1 Loss                  182.125
trainer/QF2 Loss                  181.584
trainer/Policy Loss               135.566
trainer/Q1 Predictions Mean      -134.044
trainer/Q1 Predictions Std         90.6523
trainer/Q1 Predictions Max        -21.824
trainer/Q1 Predictions Min       -302.397
trainer/Q2 Predictions Mean      -134.02
trainer/Q2 Predictions Std         90.6086
trainer/Q2 Predictions Max        -21.8234
trainer/Q2 Predictions Min       -302.978
trainer/Q Targets Mean           -132.467
trainer/Q Targets Std              92.3044
trainer/Q Targets Max              -1.07169
trainer/Q Targets Min            -303.14
trainer/Log Pis Mean                1.98511
trainer/Log Pis Std                 1.29087
trainer/Log Pis Max                 4.30439
trainer/Log Pis Min                -2.26462
trainer/Policy mu Mean             -0.245224
trainer/Policy mu Std               0.749825
trainer/Policy mu Max               2.23906
trainer/Policy mu Min              -2.54259
trainer/Policy log std Mean        -1.94766
trainer/Policy log std Std          0.684574
trainer/Policy log std Max         -0.387111
trainer/Policy log std Min         -3.06268
trainer/Alpha                       0.0657226
trainer/Alpha Loss                 -0.0405322
exploration/num steps total     49200
exploration/num paths total       492
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.60884
exploration/Rewards Std             1.82177
exploration/Rewards Max            -0.0381931
exploration/Rewards Min            -9.24242
exploration/Returns Mean         -160.884
exploration/Returns Std           165.258
exploration/Returns Max           -37.7552
exploration/Returns Min          -487.563
exploration/Actions Mean            0.00307606
exploration/Actions Std             0.207551
exploration/Actions Max             0.99904
exploration/Actions Min            -0.998413
exploration/Num Paths               5
exploration/Average Returns      -160.884
evaluation/num steps total     147000
evaluation/num paths total       1470
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.92224
evaluation/Rewards Std              1.61817
evaluation/Rewards Max             -0.167161
evaluation/Rewards Min             -9.85739
evaluation/Returns Mean          -192.224
evaluation/Returns Std            149.624
evaluation/Returns Max            -24.4571
evaluation/Returns Min           -596.201
evaluation/Actions Mean            -0.0102245
evaluation/Actions Std              0.175249
evaluation/Actions Max              0.989779
evaluation/Actions Min             -0.99243
evaluation/Num Paths               15
evaluation/Average Returns       -192.224
time/data storing (s)               0.00302596
time/evaluation sampling (s)        0.334844
time/exploration sampling (s)       0.140643
time/logging (s)                    0.00377786
time/saving (s)                     0.00194842
time/training (s)                   1.96145
time/epoch (s)                      2.44569
time/total (s)                    239.397
Epoch                              97
-----------------------------  ---------------
2019-04-23 01:17:32.663309 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 98 finished
-----------------------------  ---------------
replay_buffer/size              49700
trainer/QF1 Loss                   13.509
trainer/QF2 Loss                   13.2104
trainer/Policy Loss               134.418
trainer/Q1 Predictions Mean      -133.104
trainer/Q1 Predictions Std         90.9297
trainer/Q1 Predictions Max        -20.8808
trainer/Q1 Predictions Min       -303.429
trainer/Q2 Predictions Mean      -133.137
trainer/Q2 Predictions Std         90.9503
trainer/Q2 Predictions Max        -20.9526
trainer/Q2 Predictions Min       -304.48
trainer/Q Targets Mean           -134.796
trainer/Q Targets Std              92.3786
trainer/Q Targets Max              -0.745514
trainer/Q Targets Min            -306.032
trainer/Log Pis Mean                1.68559
trainer/Log Pis Std                 1.401
trainer/Log Pis Max                 5.85603
trainer/Log Pis Min                -2.94439
trainer/Policy mu Mean             -0.0661138
trainer/Policy mu Std               0.50474
trainer/Policy mu Max               2.06918
trainer/Policy mu Min              -2.25516
trainer/Policy log std Mean        -2.07213
trainer/Policy log std Std          0.489087
trainer/Policy log std Max         -0.443857
trainer/Policy log std Min         -2.99561
trainer/Alpha                       0.0652667
trainer/Alpha Loss                 -0.858059
exploration/num steps total     49700
exploration/num paths total       497
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.3267
exploration/Rewards Std             1.22383
exploration/Rewards Max            -0.0358649
exploration/Rewards Min            -9.63595
exploration/Returns Mean         -132.67
exploration/Returns Std            59.3757
exploration/Returns Max           -76.5941
exploration/Returns Min          -215.761
exploration/Actions Mean            0.0147872
exploration/Actions Std             0.206298
exploration/Actions Max             0.999471
exploration/Actions Min            -0.984649
exploration/Num Paths               5
exploration/Average Returns      -132.67
evaluation/num steps total     148500
evaluation/num paths total       1485
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -2.53043
evaluation/Rewards Std              2.15064
evaluation/Rewards Max             -0.440576
evaluation/Rewards Min             -9.31353
evaluation/Returns Mean          -253.043
evaluation/Returns Std            204.112
evaluation/Returns Max            -56.5159
evaluation/Returns Min           -624.367
evaluation/Actions Mean             0.0169492
evaluation/Actions Std              0.154988
evaluation/Actions Max              0.998709
evaluation/Actions Min             -0.999029
evaluation/Num Paths               15
evaluation/Average Returns       -253.043
time/data storing (s)               0.00300077
time/evaluation sampling (s)        0.328671
time/exploration sampling (s)       0.138039
time/logging (s)                    0.00365167
time/saving (s)                     0.00183215
time/training (s)                   1.95125
time/epoch (s)                      2.42644
time/total (s)                    241.828
Epoch                              98
-----------------------------  ---------------
2019-04-23 01:17:35.100795 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 99 finished
-----------------------------  ---------------
replay_buffer/size              50200
trainer/QF1 Loss                    7.01252
trainer/QF2 Loss                    6.71289
trainer/Policy Loss               118.187
trainer/Q1 Predictions Mean      -116.57
trainer/Q1 Predictions Std         85.7794
trainer/Q1 Predictions Max        -21.2371
trainer/Q1 Predictions Min       -299.709
trainer/Q2 Predictions Mean      -116.615
trainer/Q2 Predictions Std         85.7391
trainer/Q2 Predictions Max        -21.4217
trainer/Q2 Predictions Min       -300.619
trainer/Q Targets Mean           -117.346
trainer/Q Targets Std              86.9484
trainer/Q Targets Max              -0.764257
trainer/Q Targets Min            -304.023
trainer/Log Pis Mean                2.0956
trainer/Log Pis Std                 1.07165
trainer/Log Pis Max                 5.34793
trainer/Log Pis Min                -1.30391
trainer/Policy mu Mean              0.0602195
trainer/Policy mu Std               0.635836
trainer/Policy mu Max               2.66335
trainer/Policy mu Min              -2.68462
trainer/Policy log std Mean        -2.07212
trainer/Policy log std Std          0.531258
trainer/Policy log std Max         -0.617414
trainer/Policy log std Min         -3.21422
trainer/Alpha                       0.0626824
trainer/Alpha Loss                  0.264806
exploration/num steps total     50200
exploration/num paths total       502
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -4.23019
exploration/Rewards Std             1.16389
exploration/Rewards Max            -2.58407
exploration/Rewards Min            -9.64534
exploration/Returns Mean         -423.019
exploration/Returns Std            95.2757
exploration/Returns Max          -304.811
exploration/Returns Min          -596.359
exploration/Actions Mean            0.00387447
exploration/Actions Std             0.258697
exploration/Actions Max             0.998052
exploration/Actions Min            -0.998181
exploration/Num Paths               5
exploration/Average Returns      -423.019
evaluation/num steps total     150000
evaluation/num paths total       1500
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -2.17314
evaluation/Rewards Std              1.60737
evaluation/Rewards Max             -0.104583
evaluation/Rewards Min             -8.62156
evaluation/Returns Mean          -217.314
evaluation/Returns Std            147.765
evaluation/Returns Max            -27.003
evaluation/Returns Min           -505.619
evaluation/Actions Mean             0.00704607
evaluation/Actions Std              0.165187
evaluation/Actions Max              0.996915
evaluation/Actions Min             -0.996364
evaluation/Num Paths               15
evaluation/Average Returns       -217.314
time/data storing (s)               0.00305442
time/evaluation sampling (s)        0.322937
time/exploration sampling (s)       0.141697
time/logging (s)                    0.00492256
time/saving (s)                     0.00196673
time/training (s)                   1.95796
time/epoch (s)                      2.43254
time/total (s)                    244.264
Epoch                              99
-----------------------------  ---------------
2019-04-23 01:17:37.539112 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 100 finished
-----------------------------  ---------------
replay_buffer/size              50700
trainer/QF1 Loss                  181.451
trainer/QF2 Loss                  181.6
trainer/Policy Loss               110.994
trainer/Q1 Predictions Mean      -109.225
trainer/Q1 Predictions Std         84.0621
trainer/Q1 Predictions Max        -21.3403
trainer/Q1 Predictions Min       -300.219
trainer/Q2 Predictions Mean      -109.227
trainer/Q2 Predictions Std         84.0585
trainer/Q2 Predictions Max        -21.2141
trainer/Q2 Predictions Min       -301.395
trainer/Q Targets Mean           -108.727
trainer/Q Targets Std              85.3772
trainer/Q Targets Max              -3.31101
trainer/Q Targets Min            -306.137
trainer/Log Pis Mean                2.30515
trainer/Log Pis Std                 1.47351
trainer/Log Pis Max                 7.05646
trainer/Log Pis Min                -3.5497
trainer/Policy mu Mean             -0.156688
trainer/Policy mu Std               0.80725
trainer/Policy mu Max               2.04059
trainer/Policy mu Min              -3.73306
trainer/Policy log std Mean        -2.07193
trainer/Policy log std Std          0.669009
trainer/Policy log std Max         -0.121551
trainer/Policy log std Min         -3.20477
trainer/Alpha                       0.0612274
trainer/Alpha Loss                  0.852351
exploration/num steps total     50700
exploration/num paths total       507
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.36349
exploration/Rewards Std             1.27557
exploration/Rewards Max            -0.0553354
exploration/Rewards Min            -6.05219
exploration/Returns Mean         -136.349
exploration/Returns Std           120.969
exploration/Returns Max           -29.5595
exploration/Returns Min          -284.546
exploration/Actions Mean           -0.00016974
exploration/Actions Std             0.171915
exploration/Actions Max             0.993125
exploration/Actions Min            -0.987708
exploration/Num Paths               5
exploration/Average Returns      -136.349
evaluation/num steps total     151500
evaluation/num paths total       1515
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.89498
evaluation/Rewards Std              1.79412
evaluation/Rewards Max             -0.117187
evaluation/Rewards Min             -9.2417
evaluation/Returns Mean          -189.498
evaluation/Returns Std            160.773
evaluation/Returns Max            -39.5871
evaluation/Returns Min           -452.759
evaluation/Actions Mean             0.0181087
evaluation/Actions Std              0.238628
evaluation/Actions Max              0.994051
evaluation/Actions Min             -0.997971
evaluation/Num Paths               15
evaluation/Average Returns       -189.498
time/data storing (s)               0.0029995
time/evaluation sampling (s)        0.332617
time/exploration sampling (s)       0.137443
time/logging (s)                    0.00473942
time/saving (s)                     0.00192911
time/training (s)                   1.95205
time/epoch (s)                      2.43178
time/total (s)                    246.7
Epoch                             100
-----------------------------  ---------------
2019-04-23 01:17:39.997156 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 101 finished
-----------------------------  ---------------
replay_buffer/size              51200
trainer/QF1 Loss                    6.36131
trainer/QF2 Loss                    6.34308
trainer/Policy Loss               106.007
trainer/Q1 Predictions Mean      -104.327
trainer/Q1 Predictions Std         84.7461
trainer/Q1 Predictions Max        -21.3178
trainer/Q1 Predictions Min       -300.917
trainer/Q2 Predictions Mean      -104.38
trainer/Q2 Predictions Std         84.7869
trainer/Q2 Predictions Max        -21.4469
trainer/Q2 Predictions Min       -301.214
trainer/Q Targets Mean           -104.581
trainer/Q Targets Std              85.5257
trainer/Q Targets Max              -0.422088
trainer/Q Targets Min            -302.508
trainer/Log Pis Mean                1.93673
trainer/Log Pis Std                 1.39435
trainer/Log Pis Max                 4.97014
trainer/Log Pis Min                -3.69118
trainer/Policy mu Mean             -0.0893162
trainer/Policy mu Std               0.662344
trainer/Policy mu Max               2.43217
trainer/Policy mu Min              -3.28281
trainer/Policy log std Mean        -2.10983
trainer/Policy log std Std          0.6398
trainer/Policy log std Max         -0.339579
trainer/Policy log std Min         -3.21754
trainer/Alpha                       0.0633439
trainer/Alpha Loss                 -0.174561
exploration/num steps total     51200
exploration/num paths total       512
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -2.49199
exploration/Rewards Std             2.03325
exploration/Rewards Max            -0.0321238
exploration/Rewards Min            -9.01629
exploration/Returns Mean         -249.199
exploration/Returns Std           187.844
exploration/Returns Max           -39.4683
exploration/Returns Min          -593.485
exploration/Actions Mean           -0.0468542
exploration/Actions Std             0.279244
exploration/Actions Max             0.990398
exploration/Actions Min            -0.996938
exploration/Num Paths               5
exploration/Average Returns      -249.199
evaluation/num steps total     153000
evaluation/num paths total       1530
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -2.37216
evaluation/Rewards Std              2.12887
evaluation/Rewards Max             -0.0373045
evaluation/Rewards Min             -9.475
evaluation/Returns Mean          -237.216
evaluation/Returns Std            204.009
evaluation/Returns Max            -16.2408
evaluation/Returns Min           -613.175
evaluation/Actions Mean            -0.0682838
evaluation/Actions Std              0.222685
evaluation/Actions Max              0.988502
evaluation/Actions Min             -0.999336
evaluation/Num Paths               15
evaluation/Average Returns       -237.216
time/data storing (s)               0.00298103
time/evaluation sampling (s)        0.336854
time/exploration sampling (s)       0.137745
time/logging (s)                    0.00477362
time/saving (s)                     0.00153266
time/training (s)                   1.96788
time/epoch (s)                      2.45176
time/total (s)                    249.157
Epoch                             101
-----------------------------  ---------------
2019-04-23 01:17:42.467073 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 102 finished
-----------------------------  ---------------
replay_buffer/size              51700
trainer/QF1 Loss                  138.247
trainer/QF2 Loss                  139.031
trainer/Policy Loss               125.031
trainer/Q1 Predictions Mean      -123.664
trainer/Q1 Predictions Std         86.5067
trainer/Q1 Predictions Max        -21.2167
trainer/Q1 Predictions Min       -302.552
trainer/Q2 Predictions Mean      -123.632
trainer/Q2 Predictions Std         86.5096
trainer/Q2 Predictions Max        -21.3428
trainer/Q2 Predictions Min       -303.261
trainer/Q Targets Mean           -122.92
trainer/Q Targets Std              87.4957
trainer/Q Targets Max              -3.08276
trainer/Q Targets Min            -304.006
trainer/Log Pis Mean                1.83895
trainer/Log Pis Std                 1.14734
trainer/Log Pis Max                 4.40744
trainer/Log Pis Min                -1.63944
trainer/Policy mu Mean             -0.231296
trainer/Policy mu Std               0.664772
trainer/Policy mu Max               2.28181
trainer/Policy mu Min              -2.37397
trainer/Policy log std Mean        -1.96686
trainer/Policy log std Std          0.591539
trainer/Policy log std Max         -0.388289
trainer/Policy log std Min         -3.19638
trainer/Alpha                       0.0640438
trainer/Alpha Loss                 -0.442612
exploration/num steps total     51700
exploration/num paths total       517
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -2.23739
exploration/Rewards Std             1.5612
exploration/Rewards Max            -0.0159101
exploration/Rewards Min            -4.45084
exploration/Returns Mean         -223.739
exploration/Returns Std           154.603
exploration/Returns Max           -20.7991
exploration/Returns Min          -417.826
exploration/Actions Mean           -0.00650764
exploration/Actions Std             0.189051
exploration/Actions Max             0.989929
exploration/Actions Min            -0.75856
exploration/Num Paths               5
exploration/Average Returns      -223.739
evaluation/num steps total     154500
evaluation/num paths total       1545
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.80324
evaluation/Rewards Std              1.35897
evaluation/Rewards Max             -0.0460674
evaluation/Rewards Min            -10.1718
evaluation/Returns Mean          -180.324
evaluation/Returns Std            104.143
evaluation/Returns Max            -20.4144
evaluation/Returns Min           -372.65
evaluation/Actions Mean            -0.0597793
evaluation/Actions Std              0.23646
evaluation/Actions Max              0.997921
evaluation/Actions Min             -0.999441
evaluation/Num Paths               15
evaluation/Average Returns       -180.324
time/data storing (s)               0.00293414
time/evaluation sampling (s)        0.329658
time/exploration sampling (s)       0.142483
time/logging (s)                    0.00478776
time/saving (s)                     0.00196913
time/training (s)                   1.98183
time/epoch (s)                      2.46366
time/total (s)                    251.624
Epoch                             102
-----------------------------  ---------------
2019-04-23 01:17:44.921594 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 103 finished
-----------------------------  ---------------
replay_buffer/size              52200
trainer/QF1 Loss                   86.1218
trainer/QF2 Loss                   86.0086
trainer/Policy Loss               111.639
trainer/Q1 Predictions Mean      -110.153
trainer/Q1 Predictions Std         83.5987
trainer/Q1 Predictions Max        -20.9092
trainer/Q1 Predictions Min       -299.742
trainer/Q2 Predictions Mean      -110.119
trainer/Q2 Predictions Std         83.5314
trainer/Q2 Predictions Max        -21.0203
trainer/Q2 Predictions Min       -300.306
trainer/Q Targets Mean           -109.861
trainer/Q Targets Std              84.7997
trainer/Q Targets Max              -2.08056
trainer/Q Targets Min            -302.436
trainer/Log Pis Mean                2.27549
trainer/Log Pis Std                 1.62219
trainer/Log Pis Max                 8.83782
trainer/Log Pis Min                -2.28437
trainer/Policy mu Mean             -0.22366
trainer/Policy mu Std               0.877121
trainer/Policy mu Max               2.45183
trainer/Policy mu Min              -4.45668
trainer/Policy log std Mean        -2.01336
trainer/Policy log std Std          0.67181
trainer/Policy log std Max          0.315367
trainer/Policy log std Min         -3.08088
trainer/Alpha                       0.0644089
trainer/Alpha Loss                  0.75552
exploration/num steps total     52200
exploration/num paths total       522
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -2.0537
exploration/Rewards Std             1.6467
exploration/Rewards Max            -0.0298913
exploration/Rewards Min            -9.03691
exploration/Returns Mean         -205.37
exploration/Returns Std           148.804
exploration/Returns Max           -28.6085
exploration/Returns Min          -439.489
exploration/Actions Mean           -0.0396171
exploration/Actions Std             0.250955
exploration/Actions Max             0.991219
exploration/Actions Min            -0.998538
exploration/Num Paths               5
exploration/Average Returns      -205.37
evaluation/num steps total     156000
evaluation/num paths total       1560
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -2.11037
evaluation/Rewards Std              1.49531
evaluation/Rewards Max             -0.167503
evaluation/Rewards Min             -8.99602
evaluation/Returns Mean          -211.037
evaluation/Returns Std            136.831
evaluation/Returns Max            -23.9482
evaluation/Returns Min           -462.767
evaluation/Actions Mean            -0.031838
evaluation/Actions Std              0.184295
evaluation/Actions Max              0.996995
evaluation/Actions Min             -0.997805
evaluation/Num Paths               15
evaluation/Average Returns       -211.037
time/data storing (s)               0.00299156
time/evaluation sampling (s)        0.340868
time/exploration sampling (s)       0.139707
time/logging (s)                    0.00474581
time/saving (s)                     0.00194307
time/training (s)                   1.95761
time/epoch (s)                      2.44787
time/total (s)                    254.077
Epoch                             103
-----------------------------  ---------------
2019-04-23 01:17:47.382475 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 104 finished
-----------------------------  ---------------
replay_buffer/size              52700
trainer/QF1 Loss                  491.339
trainer/QF2 Loss                  490.894
trainer/Policy Loss               106.422
trainer/Q1 Predictions Mean      -104.806
trainer/Q1 Predictions Std         77.8005
trainer/Q1 Predictions Max        -20.9372
trainer/Q1 Predictions Min       -299.924
trainer/Q2 Predictions Mean      -104.779
trainer/Q2 Predictions Std         77.7599
trainer/Q2 Predictions Max        -21.0044
trainer/Q2 Predictions Min       -299.326
trainer/Q Targets Mean           -103.739
trainer/Q Targets Std              78.7631
trainer/Q Targets Max              -0.385919
trainer/Q Targets Min            -300.035
trainer/Log Pis Mean                2.00676
trainer/Log Pis Std                 1.40231
trainer/Log Pis Max                 8.53941
trainer/Log Pis Min                -1.07797
trainer/Policy mu Mean             -0.0490209
trainer/Policy mu Std               0.7169
trainer/Policy mu Max               3.51133
trainer/Policy mu Min              -2.85874
trainer/Policy log std Mean        -2.04443
trainer/Policy log std Std          0.584471
trainer/Policy log std Max         -0.20339
trainer/Policy log std Min         -3.09246
trainer/Alpha                       0.0642151
trainer/Alpha Loss                  0.0185678
exploration/num steps total     52700
exploration/num paths total       527
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -2.41481
exploration/Rewards Std             1.25592
exploration/Rewards Max            -0.760075
exploration/Rewards Min            -9.41506
exploration/Returns Mean         -241.481
exploration/Returns Std           109.239
exploration/Returns Max          -103.562
exploration/Returns Min          -348.414
exploration/Actions Mean            0.0172134
exploration/Actions Std             0.195455
exploration/Actions Max             0.997236
exploration/Actions Min            -0.981091
exploration/Num Paths               5
exploration/Average Returns      -241.481
evaluation/num steps total     157500
evaluation/num paths total       1575
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -2.7163
evaluation/Rewards Std              1.82494
evaluation/Rewards Max             -0.168465
evaluation/Rewards Min            -10.5867
evaluation/Returns Mean          -271.63
evaluation/Returns Std            168.329
evaluation/Returns Max            -26.1268
evaluation/Returns Min           -491.254
evaluation/Actions Mean             0.0126421
evaluation/Actions Std              0.17702
evaluation/Actions Max              0.998719
evaluation/Actions Min             -0.999019
evaluation/Num Paths               15
evaluation/Average Returns       -271.63
time/data storing (s)               0.00306483
time/evaluation sampling (s)        0.330367
time/exploration sampling (s)       0.136143
time/logging (s)                    0.0050175
time/saving (s)                     0.00167481
time/training (s)                   1.97809
time/epoch (s)                      2.45436
time/total (s)                    256.536
Epoch                             104
-----------------------------  ---------------
2019-04-23 01:17:49.856700 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 105 finished
-----------------------------  ---------------
replay_buffer/size              53200
trainer/QF1 Loss                    6.29235
trainer/QF2 Loss                    6.06581
trainer/Policy Loss               118.078
trainer/Q1 Predictions Mean      -116.419
trainer/Q1 Predictions Std         80.8581
trainer/Q1 Predictions Max        -22.702
trainer/Q1 Predictions Min       -294.081
trainer/Q2 Predictions Mean      -116.427
trainer/Q2 Predictions Std         80.9271
trainer/Q2 Predictions Max        -23.1903
trainer/Q2 Predictions Min       -294.616
trainer/Q Targets Mean           -118.32
trainer/Q Targets Std              82.2043
trainer/Q Targets Max             -23.0835
trainer/Q Targets Min            -298.848
trainer/Log Pis Mean                2.05448
trainer/Log Pis Std                 1.24076
trainer/Log Pis Max                 4.49246
trainer/Log Pis Min                -4.39996
trainer/Policy mu Mean             -0.161204
trainer/Policy mu Std               0.640553
trainer/Policy mu Max               2.41922
trainer/Policy mu Min              -2.34422
trainer/Policy log std Mean        -2.0812
trainer/Policy log std Std          0.538298
trainer/Policy log std Max         -0.590412
trainer/Policy log std Min         -3.07515
trainer/Alpha                       0.0620826
trainer/Alpha Loss                  0.151406
exploration/num steps total     53200
exploration/num paths total       532
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.31261
exploration/Rewards Std             0.805307
exploration/Rewards Max            -0.0610471
exploration/Rewards Min            -5.50122
exploration/Returns Mean         -131.261
exploration/Returns Std            59.5459
exploration/Returns Max           -50.1028
exploration/Returns Min          -195.161
exploration/Actions Mean           -0.0408989
exploration/Actions Std             0.217509
exploration/Actions Max             0.998705
exploration/Actions Min            -0.997101
exploration/Num Paths               5
exploration/Average Returns      -131.261
evaluation/num steps total     159000
evaluation/num paths total       1590
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -2.84922
evaluation/Rewards Std              2.00009
evaluation/Rewards Max             -0.218701
evaluation/Rewards Min             -8.91813
evaluation/Returns Mean          -284.922
evaluation/Returns Std            186.463
evaluation/Returns Max            -64.1565
evaluation/Returns Min           -629.314
evaluation/Actions Mean            -0.0444513
evaluation/Actions Std              0.251771
evaluation/Actions Max              0.997999
evaluation/Actions Min             -0.99014
evaluation/Num Paths               15
evaluation/Average Returns       -284.922
time/data storing (s)               0.00289362
time/evaluation sampling (s)        0.342173
time/exploration sampling (s)       0.138259
time/logging (s)                    0.00478671
time/saving (s)                     0.0019323
time/training (s)                   1.97765
time/epoch (s)                      2.46769
time/total (s)                    259.008
Epoch                             105
-----------------------------  ---------------
2019-04-23 01:17:52.321451 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 106 finished
-----------------------------  ---------------
replay_buffer/size              53700
trainer/QF1 Loss                   31.5669
trainer/QF2 Loss                   31.2979
trainer/Policy Loss               126.336
trainer/Q1 Predictions Mean      -124.847
trainer/Q1 Predictions Std         89.273
trainer/Q1 Predictions Max        -21.9182
trainer/Q1 Predictions Min       -293.715
trainer/Q2 Predictions Mean      -124.905
trainer/Q2 Predictions Std         89.275
trainer/Q2 Predictions Max        -21.9732
trainer/Q2 Predictions Min       -294.447
trainer/Q Targets Mean           -125.133
trainer/Q Targets Std              90.567
trainer/Q Targets Max              -0.920589
trainer/Q Targets Min            -296.591
trainer/Log Pis Mean                1.94078
trainer/Log Pis Std                 1.33575
trainer/Log Pis Max                 5.05341
trainer/Log Pis Min                -3.93581
trainer/Policy mu Mean             -0.265497
trainer/Policy mu Std               0.672078
trainer/Policy mu Max               2.23365
trainer/Policy mu Min              -2.94284
trainer/Policy log std Mean        -1.99413
trainer/Policy log std Std          0.623071
trainer/Policy log std Max         -0.335146
trainer/Policy log std Min         -3.1717
trainer/Alpha                       0.0598767
trainer/Alpha Loss                 -0.16671
exploration/num steps total     53700
exploration/num paths total       537
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -2.05318
exploration/Rewards Std             1.52882
exploration/Rewards Max            -0.0674608
exploration/Rewards Min            -7.12153
exploration/Returns Mean         -205.318
exploration/Returns Std           134.501
exploration/Returns Max           -47.851
exploration/Returns Min          -371.859
exploration/Actions Mean           -0.0452172
exploration/Actions Std             0.270036
exploration/Actions Max             0.974421
exploration/Actions Min            -0.999151
exploration/Num Paths               5
exploration/Average Returns      -205.318
evaluation/num steps total     160500
evaluation/num paths total       1605
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -2.11154
evaluation/Rewards Std              1.94819
evaluation/Rewards Max             -0.082229
evaluation/Rewards Min            -10.8488
evaluation/Returns Mean          -211.154
evaluation/Returns Std            177.806
evaluation/Returns Max             -8.42232
evaluation/Returns Min           -584.361
evaluation/Actions Mean            -0.0954996
evaluation/Actions Std              0.268586
evaluation/Actions Max              0.99679
evaluation/Actions Min             -0.998825
evaluation/Num Paths               15
evaluation/Average Returns       -211.154
time/data storing (s)               0.00298148
time/evaluation sampling (s)        0.340495
time/exploration sampling (s)       0.139252
time/logging (s)                    0.00486176
time/saving (s)                     0.00191859
time/training (s)                   1.96896
time/epoch (s)                      2.45847
time/total (s)                    261.471
Epoch                             106
-----------------------------  ---------------
2019-04-23 01:17:54.759243 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 107 finished
-----------------------------  ---------------
replay_buffer/size              54200
trainer/QF1 Loss                  594.686
trainer/QF2 Loss                  595.416
trainer/Policy Loss               123.39
trainer/Q1 Predictions Mean      -121.696
trainer/Q1 Predictions Std         78.1696
trainer/Q1 Predictions Max        -21.3631
trainer/Q1 Predictions Min       -291.238
trainer/Q2 Predictions Mean      -121.697
trainer/Q2 Predictions Std         78.1484
trainer/Q2 Predictions Max        -21.3668
trainer/Q2 Predictions Min       -292.044
trainer/Q Targets Mean           -119.636
trainer/Q Targets Std              79.9306
trainer/Q Targets Max              -3.13778
trainer/Q Targets Min            -294.227
trainer/Log Pis Mean                2.12183
trainer/Log Pis Std                 1.20379
trainer/Log Pis Max                 5.39561
trainer/Log Pis Min                -2.45541
trainer/Policy mu Mean             -0.301259
trainer/Policy mu Std               0.720743
trainer/Policy mu Max               2.88218
trainer/Policy mu Min              -2.88717
trainer/Policy log std Mean        -1.97946
trainer/Policy log std Std          0.62052
trainer/Policy log std Max         -0.156979
trainer/Policy log std Min         -3.02907
trainer/Alpha                       0.0597664
trainer/Alpha Loss                  0.343219
exploration/num steps total     54200
exploration/num paths total       542
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -2.48208
exploration/Rewards Std             2.03836
exploration/Rewards Max            -0.113945
exploration/Rewards Min            -8.44374
exploration/Returns Mean         -248.208
exploration/Returns Std           193.039
exploration/Returns Max           -39.3735
exploration/Returns Min          -567.127
exploration/Actions Mean           -0.10961
exploration/Actions Std             0.354763
exploration/Actions Max             0.974659
exploration/Actions Min            -0.999337
exploration/Num Paths               5
exploration/Average Returns      -248.208
evaluation/num steps total     162000
evaluation/num paths total       1620
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.84024
evaluation/Rewards Std              1.79295
evaluation/Rewards Max             -0.305383
evaluation/Rewards Min             -9.70017
evaluation/Returns Mean          -184.024
evaluation/Returns Std            161.564
evaluation/Returns Max            -35.8053
evaluation/Returns Min           -598.871
evaluation/Actions Mean             0.00441114
evaluation/Actions Std              0.271888
evaluation/Actions Max              0.997154
evaluation/Actions Min             -0.999805
evaluation/Num Paths               15
evaluation/Average Returns       -184.024
time/data storing (s)               0.00299448
time/evaluation sampling (s)        0.334391
time/exploration sampling (s)       0.139361
time/logging (s)                    0.00479349
time/saving (s)                     0.00204783
time/training (s)                   1.94746
time/epoch (s)                      2.43105
time/total (s)                    263.906
Epoch                             107
-----------------------------  ---------------
2019-04-23 01:17:57.220426 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 108 finished
-----------------------------  ---------------
replay_buffer/size              54700
trainer/QF1 Loss                  206.411
trainer/QF2 Loss                  206.57
trainer/Policy Loss               118.518
trainer/Q1 Predictions Mean      -116.878
trainer/Q1 Predictions Std         89.0815
trainer/Q1 Predictions Max        -20.6561
trainer/Q1 Predictions Min       -287.279
trainer/Q2 Predictions Mean      -116.86
trainer/Q2 Predictions Std         89.0222
trainer/Q2 Predictions Max        -20.6845
trainer/Q2 Predictions Min       -287.348
trainer/Q Targets Mean           -117.998
trainer/Q Targets Std              91.3569
trainer/Q Targets Max              -2.88435
trainer/Q Targets Min            -293.541
trainer/Log Pis Mean                2.15475
trainer/Log Pis Std                 1.51122
trainer/Log Pis Max                10.6438
trainer/Log Pis Min                -3.54971
trainer/Policy mu Mean             -0.212581
trainer/Policy mu Std               0.730592
trainer/Policy mu Max               2.99101
trainer/Policy mu Min              -4.75949
trainer/Policy log std Mean        -2.08822
trainer/Policy log std Std          0.600353
trainer/Policy log std Max         -0.192524
trainer/Policy log std Min         -3.15821
trainer/Alpha                       0.0605618
trainer/Alpha Loss                  0.433963
exploration/num steps total     54700
exploration/num paths total       547
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -2.00607
exploration/Rewards Std             2.08133
exploration/Rewards Max            -0.0304215
exploration/Rewards Min            -8.46942
exploration/Returns Mean         -200.607
exploration/Returns Std           197.257
exploration/Returns Max           -58.9101
exploration/Returns Min          -587.17
exploration/Actions Mean           -0.125146
exploration/Actions Std             0.324692
exploration/Actions Max             0.993039
exploration/Actions Min            -0.988502
exploration/Num Paths               5
exploration/Average Returns      -200.607
evaluation/num steps total     163500
evaluation/num paths total       1635
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -2.08262
evaluation/Rewards Std              1.66841
evaluation/Rewards Max             -0.0911664
evaluation/Rewards Min            -10.1202
evaluation/Returns Mean          -208.262
evaluation/Returns Std            148.741
evaluation/Returns Max            -47.7182
evaluation/Returns Min           -466.258
evaluation/Actions Mean            -0.0324664
evaluation/Actions Std              0.1994
evaluation/Actions Max              0.993903
evaluation/Actions Min             -0.998299
evaluation/Num Paths               15
evaluation/Average Returns       -208.262
time/data storing (s)               0.00285342
time/evaluation sampling (s)        0.335673
time/exploration sampling (s)       0.144064
time/logging (s)                    0.00479396
time/saving (s)                     0.00194896
time/training (s)                   1.96645
time/epoch (s)                      2.45578
time/total (s)                    266.366
Epoch                             108
-----------------------------  ---------------
2019-04-23 01:17:59.673111 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 109 finished
-----------------------------  ---------------
replay_buffer/size              55200
trainer/QF1 Loss                  189.916
trainer/QF2 Loss                  190.398
trainer/Policy Loss               109.594
trainer/Q1 Predictions Mean      -107.681
trainer/Q1 Predictions Std         78.3466
trainer/Q1 Predictions Max        -21.0261
trainer/Q1 Predictions Min       -287.438
trainer/Q2 Predictions Mean      -107.715
trainer/Q2 Predictions Std         78.3462
trainer/Q2 Predictions Max        -20.9982
trainer/Q2 Predictions Min       -286.924
trainer/Q Targets Mean           -107.57
trainer/Q Targets Std              80.1701
trainer/Q Targets Max              -0.969805
trainer/Q Targets Min            -290.183
trainer/Log Pis Mean                2.11967
trainer/Log Pis Std                 1.22562
trainer/Log Pis Max                 7.5541
trainer/Log Pis Min                -1.69691
trainer/Policy mu Mean             -0.00553881
trainer/Policy mu Std               0.634786
trainer/Policy mu Max               3.53151
trainer/Policy mu Min              -2.93092
trainer/Policy log std Mean        -2.13388
trainer/Policy log std Std          0.570622
trainer/Policy log std Max         -0.311637
trainer/Policy log std Min         -3.08111
trainer/Alpha                       0.0627408
trainer/Alpha Loss                  0.331346
exploration/num steps total     55200
exploration/num paths total       552
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.95785
exploration/Rewards Std             1.27502
exploration/Rewards Max            -0.0315328
exploration/Rewards Min            -7.74741
exploration/Returns Mean         -195.785
exploration/Returns Std           110.08
exploration/Returns Max           -49.0426
exploration/Returns Min          -314.467
exploration/Actions Mean            0.0215335
exploration/Actions Std             0.208457
exploration/Actions Max             0.999564
exploration/Actions Min            -0.985294
exploration/Num Paths               5
exploration/Average Returns      -195.785
evaluation/num steps total     165000
evaluation/num paths total       1650
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.01629
evaluation/Rewards Std              1.16112
evaluation/Rewards Max             -0.0696398
evaluation/Rewards Min             -9.26941
evaluation/Returns Mean          -101.629
evaluation/Returns Std             77.8136
evaluation/Returns Max            -27.2854
evaluation/Returns Min           -302.546
evaluation/Actions Mean             0.0208667
evaluation/Actions Std              0.168342
evaluation/Actions Max              0.997739
evaluation/Actions Min             -0.998105
evaluation/Num Paths               15
evaluation/Average Returns       -101.629
time/data storing (s)               0.00291715
time/evaluation sampling (s)        0.328954
time/exploration sampling (s)       0.141446
time/logging (s)                    0.00483324
time/saving (s)                     0.00198593
time/training (s)                   1.96583
time/epoch (s)                      2.44597
time/total (s)                    268.816
Epoch                             109
-----------------------------  ---------------
2019-04-23 01:18:02.155192 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 110 finished
-----------------------------  ---------------
replay_buffer/size              55700
trainer/QF1 Loss                   19.4455
trainer/QF2 Loss                   19.2466
trainer/Policy Loss               110.039
trainer/Q1 Predictions Mean      -108.841
trainer/Q1 Predictions Std         78.2826
trainer/Q1 Predictions Max        -21.1134
trainer/Q1 Predictions Min       -293.791
trainer/Q2 Predictions Mean      -108.784
trainer/Q2 Predictions Std         78.1891
trainer/Q2 Predictions Max        -21.2639
trainer/Q2 Predictions Min       -291.823
trainer/Q Targets Mean           -108.618
trainer/Q Targets Std              79.3891
trainer/Q Targets Max              -0.315203
trainer/Q Targets Min            -292.676
trainer/Log Pis Mean                1.78205
trainer/Log Pis Std                 1.43685
trainer/Log Pis Max                 6.25178
trainer/Log Pis Min                -3.77412
trainer/Policy mu Mean             -0.128105
trainer/Policy mu Std               0.65377
trainer/Policy mu Max               2.60109
trainer/Policy mu Min              -2.05659
trainer/Policy log std Mean        -2.02382
trainer/Policy log std Std          0.544797
trainer/Policy log std Max         -0.207245
trainer/Policy log std Min         -3.02158
trainer/Alpha                       0.061885
trainer/Alpha Loss                 -0.606456
exploration/num steps total     55700
exploration/num paths total       557
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.18188
exploration/Rewards Std             0.977558
exploration/Rewards Max            -0.067609
exploration/Rewards Min            -7.65333
exploration/Returns Mean         -118.188
exploration/Returns Std            70.6881
exploration/Returns Max           -49.6111
exploration/Returns Min          -253.211
exploration/Actions Mean            0.00953919
exploration/Actions Std             0.166442
exploration/Actions Max             0.974057
exploration/Actions Min            -0.932917
exploration/Num Paths               5
exploration/Average Returns      -118.188
evaluation/num steps total     166500
evaluation/num paths total       1665
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.93069
evaluation/Rewards Std              2.19494
evaluation/Rewards Max             -0.181833
evaluation/Rewards Min            -11.1329
evaluation/Returns Mean          -193.069
evaluation/Returns Std            197.027
evaluation/Returns Max            -38.757
evaluation/Returns Min           -638.532
evaluation/Actions Mean            -0.113368
evaluation/Actions Std              0.304656
evaluation/Actions Max              0.995377
evaluation/Actions Min             -0.997442
evaluation/Num Paths               15
evaluation/Average Returns       -193.069
time/data storing (s)               0.00299464
time/evaluation sampling (s)        0.33341
time/exploration sampling (s)       0.144744
time/logging (s)                    0.00477446
time/saving (s)                     0.0019388
time/training (s)                   1.98727
time/epoch (s)                      2.47513
time/total (s)                    271.296
Epoch                             110
-----------------------------  ---------------
2019-04-23 01:18:04.633965 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 111 finished
-----------------------------  ---------------
replay_buffer/size              56200
trainer/QF1 Loss                    4.0883
trainer/QF2 Loss                    4.04923
trainer/Policy Loss               117.193
trainer/Q1 Predictions Mean      -115.997
trainer/Q1 Predictions Std         79.9288
trainer/Q1 Predictions Max        -21.2348
trainer/Q1 Predictions Min       -285.478
trainer/Q2 Predictions Mean      -116.033
trainer/Q2 Predictions Std         79.8735
trainer/Q2 Predictions Max        -21.3351
trainer/Q2 Predictions Min       -284.878
trainer/Q Targets Mean           -117.524
trainer/Q Targets Std              80.8449
trainer/Q Targets Max             -21.1778
trainer/Q Targets Min            -288.539
trainer/Log Pis Mean                1.71649
trainer/Log Pis Std                 1.37811
trainer/Log Pis Max                 5.80431
trainer/Log Pis Min                -2.70352
trainer/Policy mu Mean             -0.323342
trainer/Policy mu Std               0.721114
trainer/Policy mu Max               2.17019
trainer/Policy mu Min              -2.97785
trainer/Policy log std Mean        -1.82659
trainer/Policy log std Std          0.578108
trainer/Policy log std Max         -0.274549
trainer/Policy log std Min         -3.05564
trainer/Alpha                       0.0653152
trainer/Alpha Loss                 -0.77357
exploration/num steps total     56200
exploration/num paths total       562
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -2.50943
exploration/Rewards Std             2.94025
exploration/Rewards Max            -0.0159599
exploration/Rewards Min            -9.71652
exploration/Returns Mean         -250.943
exploration/Returns Std           277.385
exploration/Returns Max           -24.2026
exploration/Returns Min          -734.275
exploration/Actions Mean           -0.0170859
exploration/Actions Std             0.255325
exploration/Actions Max             0.994687
exploration/Actions Min            -0.999471
exploration/Num Paths               5
exploration/Average Returns      -250.943
evaluation/num steps total     168000
evaluation/num paths total       1680
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -2.99408
evaluation/Rewards Std              2.17656
evaluation/Rewards Max             -0.149533
evaluation/Rewards Min             -9.18997
evaluation/Returns Mean          -299.408
evaluation/Returns Std            210.177
evaluation/Returns Max            -19.6282
evaluation/Returns Min           -900.793
evaluation/Actions Mean            -0.326767
evaluation/Actions Std              0.338315
evaluation/Actions Max              0.944689
evaluation/Actions Min             -0.999691
evaluation/Num Paths               15
evaluation/Average Returns       -299.408
time/data storing (s)               0.0031664
time/evaluation sampling (s)        0.346946
time/exploration sampling (s)       0.141191
time/logging (s)                    0.00476914
time/saving (s)                     0.00191827
time/training (s)                   1.97406
time/epoch (s)                      2.47205
time/total (s)                    273.773
Epoch                             111
-----------------------------  ---------------
2019-04-23 01:18:07.087650 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 112 finished
-----------------------------  ---------------
replay_buffer/size              56700
trainer/QF1 Loss                    3.56998
trainer/QF2 Loss                    3.65031
trainer/Policy Loss               125.91
trainer/Q1 Predictions Mean      -124.461
trainer/Q1 Predictions Std         86.2616
trainer/Q1 Predictions Max        -20.7304
trainer/Q1 Predictions Min       -288.083
trainer/Q2 Predictions Mean      -124.417
trainer/Q2 Predictions Std         86.2889
trainer/Q2 Predictions Max        -20.8133
trainer/Q2 Predictions Min       -288.731
trainer/Q Targets Mean           -126.061
trainer/Q Targets Std              87.0835
trainer/Q Targets Max             -21.284
trainer/Q Targets Min            -291.672
trainer/Log Pis Mean                1.98968
trainer/Log Pis Std                 1.15098
trainer/Log Pis Max                 8.22577
trainer/Log Pis Min                -1.66555
trainer/Policy mu Mean             -0.0852996
trainer/Policy mu Std               0.64999
trainer/Policy mu Max               2.8331
trainer/Policy mu Min              -2.43095
trainer/Policy log std Mean        -1.99613
trainer/Policy log std Std          0.593511
trainer/Policy log std Max         -0.430421
trainer/Policy log std Min         -2.93178
trainer/Alpha                       0.0633364
trainer/Alpha Loss                 -0.0284865
exploration/num steps total     56700
exploration/num paths total       567
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.39534
exploration/Rewards Std             0.848327
exploration/Rewards Max            -0.247366
exploration/Rewards Min            -9.45964
exploration/Returns Mean         -139.534
exploration/Returns Std            51.119
exploration/Returns Max           -60.4189
exploration/Returns Min          -187.238
exploration/Actions Mean           -0.0177968
exploration/Actions Std             0.210958
exploration/Actions Max             0.996496
exploration/Actions Min            -0.999453
exploration/Num Paths               5
exploration/Average Returns      -139.534
evaluation/num steps total     169500
evaluation/num paths total       1695
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.6592
evaluation/Rewards Std              1.65001
evaluation/Rewards Max             -0.220363
evaluation/Rewards Min             -9.86061
evaluation/Returns Mean          -165.92
evaluation/Returns Std            146.579
evaluation/Returns Max            -40.327
evaluation/Returns Min           -501.348
evaluation/Actions Mean             0.00226467
evaluation/Actions Std              0.171253
evaluation/Actions Max              0.997499
evaluation/Actions Min             -0.996716
evaluation/Num Paths               15
evaluation/Average Returns       -165.92
time/data storing (s)               0.00362449
time/evaluation sampling (s)        0.329232
time/exploration sampling (s)       0.146233
time/logging (s)                    0.00474233
time/saving (s)                     0.00192503
time/training (s)                   1.9612
time/epoch (s)                      2.44696
time/total (s)                    276.224
Epoch                             112
-----------------------------  ---------------
2019-04-23 01:18:09.538858 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 113 finished
-----------------------------  ---------------
replay_buffer/size              57200
trainer/QF1 Loss                  928.617
trainer/QF2 Loss                  925.112
trainer/Policy Loss               115.289
trainer/Q1 Predictions Mean      -113.77
trainer/Q1 Predictions Std         83.7448
trainer/Q1 Predictions Max        -21.0856
trainer/Q1 Predictions Min       -290.817
trainer/Q2 Predictions Mean      -113.795
trainer/Q2 Predictions Std         83.7281
trainer/Q2 Predictions Max        -21.1698
trainer/Q2 Predictions Min       -291.264
trainer/Q Targets Mean           -110.379
trainer/Q Targets Std              84.1045
trainer/Q Targets Max              -4.43376
trainer/Q Targets Min            -293.308
trainer/Log Pis Mean                1.97537
trainer/Log Pis Std                 1.31432
trainer/Log Pis Max                 4.62331
trainer/Log Pis Min                -2.5372
trainer/Policy mu Mean             -0.0790559
trainer/Policy mu Std               0.77276
trainer/Policy mu Max               2.71947
trainer/Policy mu Min              -2.8761
trainer/Policy log std Mean        -1.95208
trainer/Policy log std Std          0.661425
trainer/Policy log std Max         -0.245978
trainer/Policy log std Min         -3.19462
trainer/Alpha                       0.0618146
trainer/Alpha Loss                 -0.0685589
exploration/num steps total     57200
exploration/num paths total       572
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.78295
exploration/Rewards Std             0.918867
exploration/Rewards Max            -0.51927
exploration/Rewards Min            -7.28661
exploration/Returns Mean         -178.295
exploration/Returns Std            75.163
exploration/Returns Max           -95.9586
exploration/Returns Min          -307.752
exploration/Actions Mean           -0.00662573
exploration/Actions Std             0.241446
exploration/Actions Max             0.992345
exploration/Actions Min            -0.999101
exploration/Num Paths               5
exploration/Average Returns      -178.295
evaluation/num steps total     171000
evaluation/num paths total       1710
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.70267
evaluation/Rewards Std              2.09184
evaluation/Rewards Max             -0.0252613
evaluation/Rewards Min             -9.6738
evaluation/Returns Mean          -170.267
evaluation/Returns Std            192.337
evaluation/Returns Max            -11.2898
evaluation/Returns Min           -610.914
evaluation/Actions Mean            -0.0289606
evaluation/Actions Std              0.201724
evaluation/Actions Max              0.996875
evaluation/Actions Min             -0.998403
evaluation/Num Paths               15
evaluation/Average Returns       -170.267
time/data storing (s)               0.00299185
time/evaluation sampling (s)        0.322226
time/exploration sampling (s)       0.138947
time/logging (s)                    0.0047707
time/saving (s)                     0.00197163
time/training (s)                   1.97362
time/epoch (s)                      2.44453
time/total (s)                    278.673
Epoch                             113
-----------------------------  ---------------
2019-04-23 01:18:12.004365 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 114 finished
-----------------------------  ---------------
replay_buffer/size              57700
trainer/QF1 Loss                   31.473
trainer/QF2 Loss                   31.2348
trainer/Policy Loss               108.005
trainer/Q1 Predictions Mean      -106.496
trainer/Q1 Predictions Std         80.1883
trainer/Q1 Predictions Max        -20.879
trainer/Q1 Predictions Min       -285.9
trainer/Q2 Predictions Mean      -106.495
trainer/Q2 Predictions Std         80.235
trainer/Q2 Predictions Max        -21.1313
trainer/Q2 Predictions Min       -286.329
trainer/Q Targets Mean           -107.521
trainer/Q Targets Std              81.8731
trainer/Q Targets Max              -0.834648
trainer/Q Targets Min            -291.317
trainer/Log Pis Mean                2.06676
trainer/Log Pis Std                 1.13
trainer/Log Pis Max                 4.61336
trainer/Log Pis Min                -1.46823
trainer/Policy mu Mean             -0.15628
trainer/Policy mu Std               0.569317
trainer/Policy mu Max               2.58898
trainer/Policy mu Min              -2.49962
trainer/Policy log std Mean        -2.12053
trainer/Policy log std Std          0.576297
trainer/Policy log std Max         -0.294538
trainer/Policy log std Min         -3.13697
trainer/Alpha                       0.0628656
trainer/Alpha Loss                  0.184722
exploration/num steps total     57700
exploration/num paths total       577
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.91711
exploration/Rewards Std             1.9321
exploration/Rewards Max            -0.0292224
exploration/Rewards Min           -11.5256
exploration/Returns Mean         -191.711
exploration/Returns Std           164.43
exploration/Returns Max           -25.4293
exploration/Returns Min          -472.933
exploration/Actions Mean           -0.0208685
exploration/Actions Std             0.217456
exploration/Actions Max             0.983956
exploration/Actions Min            -0.999686
exploration/Num Paths               5
exploration/Average Returns      -191.711
evaluation/num steps total     172500
evaluation/num paths total       1725
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.88905
evaluation/Rewards Std              2.0446
evaluation/Rewards Max             -0.0403569
evaluation/Rewards Min             -9.32093
evaluation/Returns Mean          -188.905
evaluation/Returns Std            189.712
evaluation/Returns Max            -21.9903
evaluation/Returns Min           -614.533
evaluation/Actions Mean            -0.0976238
evaluation/Actions Std              0.309558
evaluation/Actions Max              0.993432
evaluation/Actions Min             -0.998481
evaluation/Num Paths               15
evaluation/Average Returns       -188.905
time/data storing (s)               0.0028734
time/evaluation sampling (s)        0.342073
time/exploration sampling (s)       0.141444
time/logging (s)                    0.00483365
time/saving (s)                     0.00612216
time/training (s)                   1.9618
time/epoch (s)                      2.45914
time/total (s)                    281.137
Epoch                             114
-----------------------------  ---------------
2019-04-23 01:18:14.457055 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 115 finished
-----------------------------  ---------------
replay_buffer/size              58200
trainer/QF1 Loss                   13.3127
trainer/QF2 Loss                   13.6767
trainer/Policy Loss               109.312
trainer/Q1 Predictions Mean      -107.963
trainer/Q1 Predictions Std         79.3755
trainer/Q1 Predictions Max        -20.7977
trainer/Q1 Predictions Min       -283.048
trainer/Q2 Predictions Mean      -107.963
trainer/Q2 Predictions Std         79.2917
trainer/Q2 Predictions Max        -20.8539
trainer/Q2 Predictions Min       -282.892
trainer/Q Targets Mean           -108.722
trainer/Q Targets Std              80.9763
trainer/Q Targets Max              -0.448487
trainer/Q Targets Min            -288.833
trainer/Log Pis Mean                1.95202
trainer/Log Pis Std                 1.50801
trainer/Log Pis Max                 6.26817
trainer/Log Pis Min                -1.60364
trainer/Policy mu Mean             -0.299075
trainer/Policy mu Std               0.790982
trainer/Policy mu Max               3.22571
trainer/Policy mu Min              -2.96396
trainer/Policy log std Mean        -1.9201
trainer/Policy log std Std          0.668607
trainer/Policy log std Max         -0.123925
trainer/Policy log std Min         -3.17889
trainer/Alpha                       0.0632657
trainer/Alpha Loss                 -0.13244
exploration/num steps total     58200
exploration/num paths total       582
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -3.36236
exploration/Rewards Std             2.25825
exploration/Rewards Max            -0.00341356
exploration/Rewards Min            -8.76829
exploration/Returns Mean         -336.236
exploration/Returns Std           205.41
exploration/Returns Max           -56.4924
exploration/Returns Min          -545.434
exploration/Actions Mean           -0.0711804
exploration/Actions Std             0.356302
exploration/Actions Max             0.999845
exploration/Actions Min            -0.990484
exploration/Num Paths               5
exploration/Average Returns      -336.236
evaluation/num steps total     174000
evaluation/num paths total       1740
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -2.65562
evaluation/Rewards Std              2.41217
evaluation/Rewards Max             -0.0836996
evaluation/Rewards Min             -9.2734
evaluation/Returns Mean          -265.562
evaluation/Returns Std            226.189
evaluation/Returns Max            -20.0192
evaluation/Returns Min           -846.406
evaluation/Actions Mean            -0.266468
evaluation/Actions Std              0.362499
evaluation/Actions Max              0.981483
evaluation/Actions Min             -0.999114
evaluation/Num Paths               15
evaluation/Average Returns       -265.562
time/data storing (s)               0.00297699
time/evaluation sampling (s)        0.343381
time/exploration sampling (s)       0.14076
time/logging (s)                    0.00378218
time/saving (s)                     0.00164612
time/training (s)                   1.95214
time/epoch (s)                      2.44469
time/total (s)                    283.586
Epoch                             115
-----------------------------  ---------------
2019-04-23 01:18:16.875643 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 116 finished
-----------------------------  ---------------
replay_buffer/size              58700
trainer/QF1 Loss                  518.315
trainer/QF2 Loss                  518.977
trainer/Policy Loss               113.438
trainer/Q1 Predictions Mean      -111.784
trainer/Q1 Predictions Std         82.8525
trainer/Q1 Predictions Max        -20.1104
trainer/Q1 Predictions Min       -282.367
trainer/Q2 Predictions Mean      -111.774
trainer/Q2 Predictions Std         82.8246
trainer/Q2 Predictions Max        -20.4276
trainer/Q2 Predictions Min       -283.002
trainer/Q Targets Mean           -110.547
trainer/Q Targets Std              85.0334
trainer/Q Targets Max              -0.315203
trainer/Q Targets Min            -288.295
trainer/Log Pis Mean                2.08049
trainer/Log Pis Std                 1.41006
trainer/Log Pis Max                 6.50257
trainer/Log Pis Min                -1.95687
trainer/Policy mu Mean              0.0779936
trainer/Policy mu Std               0.682245
trainer/Policy mu Max               3.33595
trainer/Policy mu Min              -3.43375
trainer/Policy log std Mean        -2.08968
trainer/Policy log std Std          0.522066
trainer/Policy log std Max         -0.373802
trainer/Policy log std Min         -3.04587
trainer/Alpha                       0.0617113
trainer/Alpha Loss                  0.224178
exploration/num steps total     58700
exploration/num paths total       587
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -2.20435
exploration/Rewards Std             1.85692
exploration/Rewards Max            -0.0652802
exploration/Rewards Min           -10.4043
exploration/Returns Mean         -220.435
exploration/Returns Std           169.656
exploration/Returns Max           -32.2348
exploration/Returns Min          -431.051
exploration/Actions Mean            0.0149163
exploration/Actions Std             0.224062
exploration/Actions Max             0.999064
exploration/Actions Min            -0.998655
exploration/Num Paths               5
exploration/Average Returns      -220.435
evaluation/num steps total     175500
evaluation/num paths total       1755
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -2.24302
evaluation/Rewards Std              1.92391
evaluation/Rewards Max             -0.17662
evaluation/Rewards Min            -10.1048
evaluation/Returns Mean          -224.302
evaluation/Returns Std            179.465
evaluation/Returns Max            -42.5627
evaluation/Returns Min           -600.18
evaluation/Actions Mean            -0.00465878
evaluation/Actions Std              0.154291
evaluation/Actions Max              0.997415
evaluation/Actions Min             -0.99404
evaluation/Num Paths               15
evaluation/Average Returns       -224.302
time/data storing (s)               0.00291953
time/evaluation sampling (s)        0.334519
time/exploration sampling (s)       0.142243
time/logging (s)                    0.00478886
time/saving (s)                     0.00153042
time/training (s)                   1.92753
time/epoch (s)                      2.41354
time/total (s)                    286.004
Epoch                             116
-----------------------------  ---------------
2019-04-23 01:18:19.311886 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 117 finished
-----------------------------  ---------------
replay_buffer/size              59200
trainer/QF1 Loss                    4.18207
trainer/QF2 Loss                    3.78725
trainer/Policy Loss               116.108
trainer/Q1 Predictions Mean      -114.706
trainer/Q1 Predictions Std         84.2825
trainer/Q1 Predictions Max        -20.652
trainer/Q1 Predictions Min       -287.118
trainer/Q2 Predictions Mean      -114.754
trainer/Q2 Predictions Std         84.3797
trainer/Q2 Predictions Max        -20.6921
trainer/Q2 Predictions Min       -287.631
trainer/Q Targets Mean           -116.136
trainer/Q Targets Std              85.4357
trainer/Q Targets Max             -20.7892
trainer/Q Targets Min            -289.501
trainer/Log Pis Mean                1.81458
trainer/Log Pis Std                 1.44125
trainer/Log Pis Max                 5.7873
trainer/Log Pis Min                -4.8843
trainer/Policy mu Mean             -0.136859
trainer/Policy mu Std               0.701067
trainer/Policy mu Max               3.37262
trainer/Policy mu Min              -3.2646
trainer/Policy log std Mean        -2.00864
trainer/Policy log std Std          0.670042
trainer/Policy log std Max          0.296303
trainer/Policy log std Min         -3.08455
trainer/Alpha                       0.0613041
trainer/Alpha Loss                 -0.51769
exploration/num steps total     59200
exploration/num paths total       592
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.63534
exploration/Rewards Std             2.04398
exploration/Rewards Max            -0.0393825
exploration/Rewards Min            -6.55774
exploration/Returns Mean         -163.534
exploration/Returns Std           192.14
exploration/Returns Max           -27.3502
exploration/Returns Min          -541.619
exploration/Actions Mean           -0.0423674
exploration/Actions Std             0.307579
exploration/Actions Max             0.997151
exploration/Actions Min            -0.997315
exploration/Num Paths               5
exploration/Average Returns      -163.534
evaluation/num steps total     177000
evaluation/num paths total       1770
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.49447
evaluation/Rewards Std              1.42009
evaluation/Rewards Max             -0.0372208
evaluation/Rewards Min            -10.3038
evaluation/Returns Mean          -149.447
evaluation/Returns Std            113.934
evaluation/Returns Max            -22.9415
evaluation/Returns Min           -355.356
evaluation/Actions Mean             0.0168455
evaluation/Actions Std              0.168974
evaluation/Actions Max              0.999339
evaluation/Actions Min             -0.998918
evaluation/Num Paths               15
evaluation/Average Returns       -149.447
time/data storing (s)               0.00310313
time/evaluation sampling (s)        0.327454
time/exploration sampling (s)       0.139725
time/logging (s)                    0.00477059
time/saving (s)                     0.00198455
time/training (s)                   1.95265
time/epoch (s)                      2.42969
time/total (s)                    288.438
Epoch                             117
-----------------------------  ---------------
2019-04-23 01:18:21.775231 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 118 finished
-----------------------------  ---------------
replay_buffer/size              59700
trainer/QF1 Loss                    3.04408
trainer/QF2 Loss                    3.028
trainer/Policy Loss               110.386
trainer/Q1 Predictions Mean      -109.075
trainer/Q1 Predictions Std         79.8234
trainer/Q1 Predictions Max        -20.6997
trainer/Q1 Predictions Min       -284.399
trainer/Q2 Predictions Mean      -109.106
trainer/Q2 Predictions Std         79.7874
trainer/Q2 Predictions Max        -21.057
trainer/Q2 Predictions Min       -284.442
trainer/Q Targets Mean           -110.381
trainer/Q Targets Std              80.5567
trainer/Q Targets Max             -21.07
trainer/Q Targets Min            -286.885
trainer/Log Pis Mean                1.96923
trainer/Log Pis Std                 1.04492
trainer/Log Pis Max                 6.3129
trainer/Log Pis Min                -2.28935
trainer/Policy mu Mean             -0.119942
trainer/Policy mu Std               0.649559
trainer/Policy mu Max               1.62522
trainer/Policy mu Min              -4.21938
trainer/Policy log std Mean        -2.02834
trainer/Policy log std Std          0.551538
trainer/Policy log std Max         -0.180945
trainer/Policy log std Min         -3.10738
trainer/Alpha                       0.0631125
trainer/Alpha Loss                 -0.0850175
exploration/num steps total     59700
exploration/num paths total       597
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.44662
exploration/Rewards Std             1.14543
exploration/Rewards Max            -0.088392
exploration/Rewards Min            -7.85303
exploration/Returns Mean         -144.662
exploration/Returns Std            84.6249
exploration/Returns Max           -52.9048
exploration/Returns Min          -296.724
exploration/Actions Mean           -0.0478331
exploration/Actions Std             0.213038
exploration/Actions Max             0.854961
exploration/Actions Min            -0.996546
exploration/Num Paths               5
exploration/Average Returns      -144.662
evaluation/num steps total     178500
evaluation/num paths total       1785
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -2.3483
evaluation/Rewards Std              1.59374
evaluation/Rewards Max             -0.006503
evaluation/Rewards Min             -9.46422
evaluation/Returns Mean          -234.83
evaluation/Returns Std            140.207
evaluation/Returns Max            -26.375
evaluation/Returns Min           -482.646
evaluation/Actions Mean             0.00338163
evaluation/Actions Std              0.183352
evaluation/Actions Max              0.995695
evaluation/Actions Min             -0.99654
evaluation/Num Paths               15
evaluation/Average Returns       -234.83
time/data storing (s)               0.00288427
time/evaluation sampling (s)        0.327934
time/exploration sampling (s)       0.141217
time/logging (s)                    0.00486098
time/saving (s)                     0.00194517
time/training (s)                   1.97776
time/epoch (s)                      2.4566
time/total (s)                    290.899
Epoch                             118
-----------------------------  ---------------
2019-04-23 01:18:24.209394 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 119 finished
-----------------------------  ----------------
replay_buffer/size              60200
trainer/QF1 Loss                  124.307
trainer/QF2 Loss                  123.542
trainer/Policy Loss               107.425
trainer/Q1 Predictions Mean      -105.969
trainer/Q1 Predictions Std         81.8056
trainer/Q1 Predictions Max        -19.6295
trainer/Q1 Predictions Min       -283.002
trainer/Q2 Predictions Mean      -105.967
trainer/Q2 Predictions Std         81.8011
trainer/Q2 Predictions Max        -19.6267
trainer/Q2 Predictions Min       -283.483
trainer/Q Targets Mean           -105.921
trainer/Q Targets Std              83.5717
trainer/Q Targets Max              -0.745514
trainer/Q Targets Min            -287.411
trainer/Log Pis Mean                2.00035
trainer/Log Pis Std                 1.26458
trainer/Log Pis Max                 7.68989
trainer/Log Pis Min                -1.30092
trainer/Policy mu Mean             -0.216433
trainer/Policy mu Std               0.688475
trainer/Policy mu Max               2.70068
trainer/Policy mu Min              -4.31674
trainer/Policy log std Mean        -2.04554
trainer/Policy log std Std          0.56553
trainer/Policy log std Max         -0.302533
trainer/Policy log std Min         -2.90446
trainer/Alpha                       0.0638285
trainer/Alpha Loss                  0.000965226
exploration/num steps total     60200
exploration/num paths total       602
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.889595
exploration/Rewards Std             1.07014
exploration/Rewards Max            -0.0196092
exploration/Rewards Min            -7.25431
exploration/Returns Mean          -88.9595
exploration/Returns Std            91.5243
exploration/Returns Max           -24.2108
exploration/Returns Min          -268.3
exploration/Actions Mean            0.00143298
exploration/Actions Std             0.154114
exploration/Actions Max             0.988164
exploration/Actions Min            -0.909218
exploration/Num Paths               5
exploration/Average Returns       -88.9595
evaluation/num steps total     180000
evaluation/num paths total       1800
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -2.13481
evaluation/Rewards Std              3.06949
evaluation/Rewards Max             -0.0422512
evaluation/Rewards Min            -10.9157
evaluation/Returns Mean          -213.481
evaluation/Returns Std            284.491
evaluation/Returns Max            -19.605
evaluation/Returns Min           -860.203
evaluation/Actions Mean            -0.0906692
evaluation/Actions Std              0.276694
evaluation/Actions Max              0.996351
evaluation/Actions Min             -0.999423
evaluation/Num Paths               15
evaluation/Average Returns       -213.481
time/data storing (s)               0.00296549
time/evaluation sampling (s)        0.337284
time/exploration sampling (s)       0.139561
time/logging (s)                    0.00484057
time/saving (s)                     0.00196048
time/training (s)                   1.94066
time/epoch (s)                      2.42727
time/total (s)                    293.331
Epoch                             119
-----------------------------  ----------------
2019-04-23 01:18:26.675594 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 120 finished
-----------------------------  ---------------
replay_buffer/size              60700
trainer/QF1 Loss                    1.87003
trainer/QF2 Loss                    2.41532
trainer/Policy Loss               106.856
trainer/Q1 Predictions Mean      -105.498
trainer/Q1 Predictions Std         76.4662
trainer/Q1 Predictions Max        -20.2522
trainer/Q1 Predictions Min       -283.37
trainer/Q2 Predictions Mean      -105.46
trainer/Q2 Predictions Std         76.419
trainer/Q2 Predictions Max        -20.2233
trainer/Q2 Predictions Min       -283.972
trainer/Q Targets Mean           -106.202
trainer/Q Targets Std              77.1524
trainer/Q Targets Max             -20.4863
trainer/Q Targets Min            -286.015
trainer/Log Pis Mean                2.0231
trainer/Log Pis Std                 1.51425
trainer/Log Pis Max                 6.75207
trainer/Log Pis Min                -3.41389
trainer/Policy mu Mean             -0.258673
trainer/Policy mu Std               0.743116
trainer/Policy mu Max               2.29243
trainer/Policy mu Min              -3.86168
trainer/Policy log std Mean        -2.0217
trainer/Policy log std Std          0.612443
trainer/Policy log std Max         -0.40037
trainer/Policy log std Min         -2.9997
trainer/Alpha                       0.0633232
trainer/Alpha Loss                  0.0637565
exploration/num steps total     60700
exploration/num paths total       607
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -2.72772
exploration/Rewards Std             3.1814
exploration/Rewards Max            -0.028785
exploration/Rewards Min            -9.2119
exploration/Returns Mean         -272.772
exploration/Returns Std           288.432
exploration/Returns Max           -45.3514
exploration/Returns Min          -770.621
exploration/Actions Mean           -0.0655119
exploration/Actions Std             0.282989
exploration/Actions Max             0.995469
exploration/Actions Min            -0.99957
exploration/Num Paths               5
exploration/Average Returns      -272.772
evaluation/num steps total     181500
evaluation/num paths total       1815
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -2.17412
evaluation/Rewards Std              2.12264
evaluation/Rewards Max             -0.0744823
evaluation/Rewards Min             -8.17962
evaluation/Returns Mean          -217.412
evaluation/Returns Std            201.408
evaluation/Returns Max            -20.1255
evaluation/Returns Min           -570.141
evaluation/Actions Mean            -0.0422538
evaluation/Actions Std              0.338102
evaluation/Actions Max              0.995449
evaluation/Actions Min             -0.998911
evaluation/Num Paths               15
evaluation/Average Returns       -217.412
time/data storing (s)               0.00291904
time/evaluation sampling (s)        0.334762
time/exploration sampling (s)       0.139149
time/logging (s)                    0.00477557
time/saving (s)                     0.00193373
time/training (s)                   1.97564
time/epoch (s)                      2.45918
time/total (s)                    295.795
Epoch                             120
-----------------------------  ---------------
2019-04-23 01:18:29.125404 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 121 finished
-----------------------------  ---------------
replay_buffer/size              61200
trainer/QF1 Loss                   94.4883
trainer/QF2 Loss                   94.1573
trainer/Policy Loss               107.782
trainer/Q1 Predictions Mean      -106.436
trainer/Q1 Predictions Std         78.9339
trainer/Q1 Predictions Max        -19.9202
trainer/Q1 Predictions Min       -280.158
trainer/Q2 Predictions Mean      -106.462
trainer/Q2 Predictions Std         78.9323
trainer/Q2 Predictions Max        -19.7234
trainer/Q2 Predictions Min       -279.66
trainer/Q Targets Mean           -106.975
trainer/Q Targets Std              80.9035
trainer/Q Targets Max              -2.08056
trainer/Q Targets Min            -283.76
trainer/Log Pis Mean                2.09291
trainer/Log Pis Std                 1.3559
trainer/Log Pis Max                 8.74569
trainer/Log Pis Min                -1.73107
trainer/Policy mu Mean             -0.27731
trainer/Policy mu Std               0.703974
trainer/Policy mu Max               1.82278
trainer/Policy mu Min              -3.39286
trainer/Policy log std Mean        -1.97908
trainer/Policy log std Std          0.609107
trainer/Policy log std Max         -0.0293115
trainer/Policy log std Min         -3.04239
trainer/Alpha                       0.0637287
trainer/Alpha Loss                  0.255787
exploration/num steps total     61200
exploration/num paths total       612
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -3.7842
exploration/Rewards Std             3.8089
exploration/Rewards Max            -0.0273659
exploration/Rewards Min           -10.3676
exploration/Returns Mean         -378.42
exploration/Returns Std           353.968
exploration/Returns Max           -40.0486
exploration/Returns Min          -855.17
exploration/Actions Mean           -0.0832255
exploration/Actions Std             0.326582
exploration/Actions Max             0.998645
exploration/Actions Min            -0.992289
exploration/Num Paths               5
exploration/Average Returns      -378.42
evaluation/num steps total     183000
evaluation/num paths total       1830
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -2.8846
evaluation/Rewards Std              2.7735
evaluation/Rewards Max             -0.021952
evaluation/Rewards Min             -9.54713
evaluation/Returns Mean          -288.46
evaluation/Returns Std            268.068
evaluation/Returns Max             -3.72318
evaluation/Returns Min           -771.707
evaluation/Actions Mean            -0.106088
evaluation/Actions Std              0.253597
evaluation/Actions Max              0.992504
evaluation/Actions Min             -0.997181
evaluation/Num Paths               15
evaluation/Average Returns       -288.46
time/data storing (s)               0.0030162
time/evaluation sampling (s)        0.342294
time/exploration sampling (s)       0.142911
time/logging (s)                    0.00484999
time/saving (s)                     0.00192985
time/training (s)                   1.94925
time/epoch (s)                      2.44425
time/total (s)                    298.243
Epoch                             121
-----------------------------  ---------------
2019-04-23 01:18:31.586528 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 122 finished
-----------------------------  ---------------
replay_buffer/size              61700
trainer/QF1 Loss                    2.46143
trainer/QF2 Loss                    2.25354
trainer/Policy Loss               106.762
trainer/Q1 Predictions Mean      -105.127
trainer/Q1 Predictions Std         78.4499
trainer/Q1 Predictions Max        -19.7314
trainer/Q1 Predictions Min       -280.687
trainer/Q2 Predictions Mean      -105.192
trainer/Q2 Predictions Std         78.439
trainer/Q2 Predictions Max        -19.7638
trainer/Q2 Predictions Min       -280.844
trainer/Q Targets Mean           -106.138
trainer/Q Targets Std              79.2781
trainer/Q Targets Max             -19.8546
trainer/Q Targets Min            -284.552
trainer/Log Pis Mean                1.98059
trainer/Log Pis Std                 1.20349
trainer/Log Pis Max                 6.09146
trainer/Log Pis Min                -2.36978
trainer/Policy mu Mean             -0.199131
trainer/Policy mu Std               0.602973
trainer/Policy mu Max               1.96738
trainer/Policy mu Min              -3.13256
trainer/Policy log std Mean        -2.07599
trainer/Policy log std Std          0.592444
trainer/Policy log std Max         -0.343058
trainer/Policy log std Min         -2.8809
trainer/Alpha                       0.0616109
trainer/Alpha Loss                 -0.0541035
exploration/num steps total     61700
exploration/num paths total       617
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.48394
exploration/Rewards Std             1.09431
exploration/Rewards Max            -0.166219
exploration/Rewards Min            -7.36926
exploration/Returns Mean         -148.394
exploration/Returns Std            86.3327
exploration/Returns Max           -42.8658
exploration/Returns Min          -295.039
exploration/Actions Mean           -0.0573323
exploration/Actions Std             0.249911
exploration/Actions Max             0.997898
exploration/Actions Min            -0.993985
exploration/Num Paths               5
exploration/Average Returns      -148.394
evaluation/num steps total     184500
evaluation/num paths total       1845
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -2.24501
evaluation/Rewards Std              1.66256
evaluation/Rewards Max             -0.265783
evaluation/Rewards Min             -9.20731
evaluation/Returns Mean          -224.501
evaluation/Returns Std            156.032
evaluation/Returns Max            -37.1321
evaluation/Returns Min           -584.848
evaluation/Actions Mean            -0.0653236
evaluation/Actions Std              0.235717
evaluation/Actions Max              0.981859
evaluation/Actions Min             -0.998079
evaluation/Num Paths               15
evaluation/Average Returns       -224.501
time/data storing (s)               0.00296261
time/evaluation sampling (s)        0.334917
time/exploration sampling (s)       0.137475
time/logging (s)                    0.00372407
time/saving (s)                     0.00192189
time/training (s)                   1.97191
time/epoch (s)                      2.45291
time/total (s)                    300.7
Epoch                             122
-----------------------------  ---------------
2019-04-23 01:18:34.042886 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 123 finished
-----------------------------  ---------------
replay_buffer/size              62200
trainer/QF1 Loss                    7.14895
trainer/QF2 Loss                    7.10334
trainer/Policy Loss               114.709
trainer/Q1 Predictions Mean      -113.118
trainer/Q1 Predictions Std         81.0143
trainer/Q1 Predictions Max        -20.3683
trainer/Q1 Predictions Min       -279.384
trainer/Q2 Predictions Mean      -113.106
trainer/Q2 Predictions Std         81.0435
trainer/Q2 Predictions Max        -20.2549
trainer/Q2 Predictions Min       -279.84
trainer/Q Targets Mean           -114.055
trainer/Q Targets Std              82.0494
trainer/Q Targets Max              -0.129288
trainer/Q Targets Min            -281.936
trainer/Log Pis Mean                1.86346
trainer/Log Pis Std                 1.10287
trainer/Log Pis Max                 3.90781
trainer/Log Pis Min                -1.01397
trainer/Policy mu Mean              0.0212171
trainer/Policy mu Std               0.50281
trainer/Policy mu Max               1.8949
trainer/Policy mu Min              -2.23921
trainer/Policy log std Mean        -2.08596
trainer/Policy log std Std          0.608803
trainer/Policy log std Max          0.0682183
trainer/Policy log std Min         -2.91621
trainer/Alpha                       0.0608609
trainer/Alpha Loss                 -0.382183
exploration/num steps total     62200
exploration/num paths total       622
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.08402
exploration/Rewards Std             0.885838
exploration/Rewards Max            -0.0132409
exploration/Rewards Min            -8.0922
exploration/Returns Mean         -108.402
exploration/Returns Std            52.9873
exploration/Returns Max           -47.8391
exploration/Returns Min          -180.531
exploration/Actions Mean            0.0174326
exploration/Actions Std             0.196144
exploration/Actions Max             0.999208
exploration/Actions Min            -0.946536
exploration/Num Paths               5
exploration/Average Returns      -108.402
evaluation/num steps total     186000
evaluation/num paths total       1860
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.76616
evaluation/Rewards Std              1.83633
evaluation/Rewards Max             -0.0350455
evaluation/Rewards Min             -8.81485
evaluation/Returns Mean          -176.616
evaluation/Returns Std            174.172
evaluation/Returns Max            -19.1816
evaluation/Returns Min           -531.59
evaluation/Actions Mean             0.0173081
evaluation/Actions Std              0.160711
evaluation/Actions Max              0.995457
evaluation/Actions Min             -0.982461
evaluation/Num Paths               15
evaluation/Average Returns       -176.616
time/data storing (s)               0.00282077
time/evaluation sampling (s)        0.330161
time/exploration sampling (s)       0.137515
time/logging (s)                    0.00480919
time/saving (s)                     0.00196251
time/training (s)                   1.97392
time/epoch (s)                      2.45118
time/total (s)                    303.156
Epoch                             123
-----------------------------  ---------------
2019-04-23 01:18:36.494900 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 124 finished
-----------------------------  ---------------
replay_buffer/size              62700
trainer/QF1 Loss                    1.94378
trainer/QF2 Loss                    1.70595
trainer/Policy Loss                95.7474
trainer/Q1 Predictions Mean       -94.2227
trainer/Q1 Predictions Std         73.167
trainer/Q1 Predictions Max        -19.9203
trainer/Q1 Predictions Min       -280.678
trainer/Q2 Predictions Mean       -94.2921
trainer/Q2 Predictions Std         73.2639
trainer/Q2 Predictions Max        -19.8794
trainer/Q2 Predictions Min       -281.425
trainer/Q Targets Mean            -95.0778
trainer/Q Targets Std              73.9705
trainer/Q Targets Max             -19.6248
trainer/Q Targets Min            -283.607
trainer/Log Pis Mean                2.11298
trainer/Log Pis Std                 1.91309
trainer/Log Pis Max                 7.41922
trainer/Log Pis Min               -11.1278
trainer/Policy mu Mean              0.00897739
trainer/Policy mu Std               0.720597
trainer/Policy mu Max               3.52081
trainer/Policy mu Min              -2.91582
trainer/Policy log std Mean        -2.16167
trainer/Policy log std Std          0.587952
trainer/Policy log std Max         -0.216938
trainer/Policy log std Min         -2.99261
trainer/Alpha                       0.0624276
trainer/Alpha Loss                  0.313398
exploration/num steps total     62700
exploration/num paths total       627
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.503
exploration/Rewards Std             2.10835
exploration/Rewards Max            -0.0296296
exploration/Rewards Min           -10.3568
exploration/Returns Mean         -150.3
exploration/Returns Std           191.868
exploration/Returns Max           -43.318
exploration/Returns Min          -533.067
exploration/Actions Mean            0.00951688
exploration/Actions Std             0.228075
exploration/Actions Max             0.997521
exploration/Actions Min            -0.985866
exploration/Num Paths               5
exploration/Average Returns      -150.3
evaluation/num steps total     187500
evaluation/num paths total       1875
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.28785
evaluation/Rewards Std              1.48149
evaluation/Rewards Max             -0.0695361
evaluation/Rewards Min            -10.0092
evaluation/Returns Mean          -128.785
evaluation/Returns Std            123.086
evaluation/Returns Max            -30.9218
evaluation/Returns Min           -487.889
evaluation/Actions Mean             0.013328
evaluation/Actions Std              0.167356
evaluation/Actions Max              0.998615
evaluation/Actions Min             -0.996795
evaluation/Num Paths               15
evaluation/Average Returns       -128.785
time/data storing (s)               0.00281982
time/evaluation sampling (s)        0.326201
time/exploration sampling (s)       0.137474
time/logging (s)                    0.00481594
time/saving (s)                     0.00195844
time/training (s)                   1.97149
time/epoch (s)                      2.44476
time/total (s)                    305.606
Epoch                             124
-----------------------------  ---------------
2019-04-23 01:18:38.954014 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 125 finished
-----------------------------  ---------------
replay_buffer/size              63200
trainer/QF1 Loss                    3.05032
trainer/QF2 Loss                    3.25869
trainer/Policy Loss               113.315
trainer/Q1 Predictions Mean      -112.041
trainer/Q1 Predictions Std         85.0531
trainer/Q1 Predictions Max        -19.7905
trainer/Q1 Predictions Min       -283.375
trainer/Q2 Predictions Mean      -112
trainer/Q2 Predictions Std         85.0424
trainer/Q2 Predictions Max        -19.7103
trainer/Q2 Predictions Min       -283.458
trainer/Q Targets Mean           -113.201
trainer/Q Targets Std              85.7838
trainer/Q Targets Max             -19.882
trainer/Q Targets Min            -284.553
trainer/Log Pis Mean                2.04699
trainer/Log Pis Std                 1.55637
trainer/Log Pis Max                 6.46236
trainer/Log Pis Min                -4.04723
trainer/Policy mu Mean             -0.279052
trainer/Policy mu Std               0.78999
trainer/Policy mu Max               2.40793
trainer/Policy mu Min              -3.41298
trainer/Policy log std Mean        -2.00371
trainer/Policy log std Std          0.72463
trainer/Policy log std Max         -0.0796602
trainer/Policy log std Min         -3.05585
trainer/Alpha                       0.0643703
trainer/Alpha Loss                  0.128905
exploration/num steps total     63200
exploration/num paths total       632
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -2.16082
exploration/Rewards Std             1.39634
exploration/Rewards Max            -0.138647
exploration/Rewards Min           -10.6347
exploration/Returns Mean         -216.082
exploration/Returns Std            79.5813
exploration/Returns Max           -96.4316
exploration/Returns Min          -345.568
exploration/Actions Mean           -0.0451515
exploration/Actions Std             0.291801
exploration/Actions Max             0.998161
exploration/Actions Min            -0.999609
exploration/Num Paths               5
exploration/Average Returns      -216.082
evaluation/num steps total     189000
evaluation/num paths total       1890
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -2.07043
evaluation/Rewards Std              1.67079
evaluation/Rewards Max             -0.326999
evaluation/Rewards Min             -9.63414
evaluation/Returns Mean          -207.043
evaluation/Returns Std            147.669
evaluation/Returns Max            -37.7558
evaluation/Returns Min           -468.646
evaluation/Actions Mean            -0.0117275
evaluation/Actions Std              0.177415
evaluation/Actions Max              0.996183
evaluation/Actions Min             -0.999462
evaluation/Num Paths               15
evaluation/Average Returns       -207.043
time/data storing (s)               0.00281317
time/evaluation sampling (s)        0.326872
time/exploration sampling (s)       0.143063
time/logging (s)                    0.00478284
time/saving (s)                     0.00192564
time/training (s)                   1.97277
time/epoch (s)                      2.45222
time/total (s)                    308.062
Epoch                             125
-----------------------------  ---------------
2019-04-23 01:18:41.398975 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 126 finished
-----------------------------  ---------------
replay_buffer/size              63700
trainer/QF1 Loss                  230.577
trainer/QF2 Loss                  230.599
trainer/Policy Loss               104.804
trainer/Q1 Predictions Mean      -103.497
trainer/Q1 Predictions Std         77.685
trainer/Q1 Predictions Max        -19.2876
trainer/Q1 Predictions Min       -278.852
trainer/Q2 Predictions Mean      -103.442
trainer/Q2 Predictions Std         77.5888
trainer/Q2 Predictions Max        -19.3575
trainer/Q2 Predictions Min       -278.627
trainer/Q Targets Mean           -103.819
trainer/Q Targets Std              80.4502
trainer/Q Targets Max              -1.32537
trainer/Q Targets Min            -284.727
trainer/Log Pis Mean                1.73323
trainer/Log Pis Std                 1.33572
trainer/Log Pis Max                 6.07288
trainer/Log Pis Min                -2.64233
trainer/Policy mu Mean             -0.0667749
trainer/Policy mu Std               0.627195
trainer/Policy mu Max               3.23834
trainer/Policy mu Min              -2.14843
trainer/Policy log std Mean        -2.02438
trainer/Policy log std Std          0.535626
trainer/Policy log std Max         -0.238326
trainer/Policy log std Min         -2.89023
trainer/Alpha                       0.0662811
trainer/Alpha Loss                 -0.723949
exploration/num steps total     63700
exploration/num paths total       637
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -2.0144
exploration/Rewards Std             1.40655
exploration/Rewards Max            -0.050022
exploration/Rewards Min            -9.0387
exploration/Returns Mean         -201.44
exploration/Returns Std           110.922
exploration/Returns Max           -68.4138
exploration/Returns Min          -360.399
exploration/Actions Mean           -0.0140251
exploration/Actions Std             0.228053
exploration/Actions Max             0.992468
exploration/Actions Min            -0.999273
exploration/Num Paths               5
exploration/Average Returns      -201.44
evaluation/num steps total     190500
evaluation/num paths total       1905
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.98959
evaluation/Rewards Std              2.02037
evaluation/Rewards Max             -0.0295028
evaluation/Rewards Min             -9.6602
evaluation/Returns Mean          -198.959
evaluation/Returns Std            190.443
evaluation/Returns Max            -19.5223
evaluation/Returns Min           -615.684
evaluation/Actions Mean            -0.00820915
evaluation/Actions Std              0.143614
evaluation/Actions Max              0.988499
evaluation/Actions Min             -0.999463
evaluation/Num Paths               15
evaluation/Average Returns       -198.959
time/data storing (s)               0.00277997
time/evaluation sampling (s)        0.333237
time/exploration sampling (s)       0.138757
time/logging (s)                    0.00464963
time/saving (s)                     0.00195825
time/training (s)                   1.95654
time/epoch (s)                      2.43792
time/total (s)                    310.505
Epoch                             126
-----------------------------  ---------------
2019-04-23 01:18:43.873034 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 127 finished
-----------------------------  ---------------
replay_buffer/size              64200
trainer/QF1 Loss                    9.72563
trainer/QF2 Loss                   10.1958
trainer/Policy Loss               102
trainer/Q1 Predictions Mean      -100.582
trainer/Q1 Predictions Std         82.5858
trainer/Q1 Predictions Max        -19.4536
trainer/Q1 Predictions Min       -279.79
trainer/Q2 Predictions Mean      -100.541
trainer/Q2 Predictions Std         82.5205
trainer/Q2 Predictions Max        -19.5373
trainer/Q2 Predictions Min       -279.423
trainer/Q Targets Mean           -102.118
trainer/Q Targets Std              84.2336
trainer/Q Targets Max              -0.734801
trainer/Q Targets Min            -284.894
trainer/Log Pis Mean                1.71469
trainer/Log Pis Std                 1.25687
trainer/Log Pis Max                 4.86899
trainer/Log Pis Min                -2.81048
trainer/Policy mu Mean              0.0451894
trainer/Policy mu Std               0.640552
trainer/Policy mu Max               4.79006
trainer/Policy mu Min              -1.72557
trainer/Policy log std Mean        -2.08054
trainer/Policy log std Std          0.553559
trainer/Policy log std Max         -0.193922
trainer/Policy log std Min         -2.99742
trainer/Alpha                       0.0643297
trainer/Alpha Loss                 -0.782818
exploration/num steps total     64200
exploration/num paths total       642
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.26544
exploration/Rewards Std             1.54007
exploration/Rewards Max            -0.0444767
exploration/Rewards Min            -8.90792
exploration/Returns Mean         -126.544
exploration/Returns Std           133.124
exploration/Returns Max           -33.0091
exploration/Returns Min          -390.629
exploration/Actions Mean            0.0308793
exploration/Actions Std             0.209761
exploration/Actions Max             0.999211
exploration/Actions Min            -0.997414
exploration/Num Paths               5
exploration/Average Returns      -126.544
evaluation/num steps total     192000
evaluation/num paths total       1920
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -2.17729
evaluation/Rewards Std              1.78194
evaluation/Rewards Max             -0.267793
evaluation/Rewards Min            -11.6712
evaluation/Returns Mean          -217.729
evaluation/Returns Std            155.181
evaluation/Returns Max            -36.5654
evaluation/Returns Min           -563.007
evaluation/Actions Mean            -0.00549838
evaluation/Actions Std              0.175789
evaluation/Actions Max              0.998628
evaluation/Actions Min             -0.998722
evaluation/Num Paths               15
evaluation/Average Returns       -217.729
time/data storing (s)               0.00380218
time/evaluation sampling (s)        0.331161
time/exploration sampling (s)       0.180893
time/logging (s)                    0.00478844
time/saving (s)                     0.00996407
time/training (s)                   1.9369
time/epoch (s)                      2.46751
time/total (s)                    312.977
Epoch                             127
-----------------------------  ---------------
2019-04-23 01:18:46.322855 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 128 finished
-----------------------------  ---------------
replay_buffer/size              64700
trainer/QF1 Loss                   24.7592
trainer/QF2 Loss                   25.1073
trainer/Policy Loss               109.203
trainer/Q1 Predictions Mean      -107.847
trainer/Q1 Predictions Std         78.1484
trainer/Q1 Predictions Max        -19.3395
trainer/Q1 Predictions Min       -279.416
trainer/Q2 Predictions Mean      -107.809
trainer/Q2 Predictions Std         78.1331
trainer/Q2 Predictions Max        -19.533
trainer/Q2 Predictions Min       -279.773
trainer/Q Targets Mean           -109.03
trainer/Q Targets Std              79.7366
trainer/Q Targets Max              -0.432532
trainer/Q Targets Min            -283.601
trainer/Log Pis Mean                1.9451
trainer/Log Pis Std                 1.30585
trainer/Log Pis Max                 7.66883
trainer/Log Pis Min                -2.96849
trainer/Policy mu Mean             -0.256274
trainer/Policy mu Std               0.679076
trainer/Policy mu Max               2.37731
trainer/Policy mu Min              -3.68119
trainer/Policy log std Mean        -2.03369
trainer/Policy log std Std          0.596196
trainer/Policy log std Max         -0.259574
trainer/Policy log std Min         -3.03664
trainer/Alpha                       0.0642573
trainer/Alpha Loss                 -0.150694
exploration/num steps total     64700
exploration/num paths total       647
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -2.23705
exploration/Rewards Std             1.13006
exploration/Rewards Max            -0.0662155
exploration/Rewards Min            -9.59575
exploration/Returns Mean         -223.705
exploration/Returns Std            87.7935
exploration/Returns Max           -64.1656
exploration/Returns Min          -325.727
exploration/Actions Mean           -0.0236095
exploration/Actions Std             0.21363
exploration/Actions Max             0.99987
exploration/Actions Min            -0.998628
exploration/Num Paths               5
exploration/Average Returns      -223.705
evaluation/num steps total     193500
evaluation/num paths total       1935
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -2.37773
evaluation/Rewards Std              1.98846
evaluation/Rewards Max             -0.340152
evaluation/Rewards Min            -10.7826
evaluation/Returns Mean          -237.773
evaluation/Returns Std            186.766
evaluation/Returns Max            -53.6806
evaluation/Returns Min           -573.572
evaluation/Actions Mean            -0.0697446
evaluation/Actions Std              0.234973
evaluation/Actions Max              0.998095
evaluation/Actions Min             -0.999784
evaluation/Num Paths               15
evaluation/Average Returns       -237.773
time/data storing (s)               0.00298713
time/evaluation sampling (s)        0.335897
time/exploration sampling (s)       0.141049
time/logging (s)                    0.0048302
time/saving (s)                     0.00199953
time/training (s)                   1.95607
time/epoch (s)                      2.44283
time/total (s)                    315.424
Epoch                             128
-----------------------------  ---------------
2019-04-23 01:18:48.757137 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 129 finished
-----------------------------  ---------------
replay_buffer/size              65200
trainer/QF1 Loss                   43.3134
trainer/QF2 Loss                   43.4933
trainer/Policy Loss               101.972
trainer/Q1 Predictions Mean      -100.507
trainer/Q1 Predictions Std         71.5282
trainer/Q1 Predictions Max        -19.3638
trainer/Q1 Predictions Min       -279.085
trainer/Q2 Predictions Mean      -100.467
trainer/Q2 Predictions Std         71.5171
trainer/Q2 Predictions Max        -19.324
trainer/Q2 Predictions Min       -279.066
trainer/Q Targets Mean           -101.058
trainer/Q Targets Std              72.9919
trainer/Q Targets Max              -1.24731
trainer/Q Targets Min            -282.277
trainer/Log Pis Mean                2.06727
trainer/Log Pis Std                 1.14801
trainer/Log Pis Max                 5.2293
trainer/Log Pis Min                -1.3481
trainer/Policy mu Mean             -0.213646
trainer/Policy mu Std               0.674904
trainer/Policy mu Max               2.74736
trainer/Policy mu Min              -2.63176
trainer/Policy log std Mean        -2.0695
trainer/Policy log std Std          0.600349
trainer/Policy log std Max         -0.401745
trainer/Policy log std Min         -3.00947
trainer/Alpha                       0.0641842
trainer/Alpha Loss                  0.184731
exploration/num steps total     65200
exploration/num paths total       652
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.84824
exploration/Rewards Std             1.77858
exploration/Rewards Max            -0.319197
exploration/Rewards Min            -9.64288
exploration/Returns Mean         -184.824
exploration/Returns Std           158.109
exploration/Returns Max           -59.8272
exploration/Returns Min          -486.158
exploration/Actions Mean           -0.0309546
exploration/Actions Std             0.211776
exploration/Actions Max             0.992176
exploration/Actions Min            -0.998783
exploration/Num Paths               5
exploration/Average Returns      -184.824
evaluation/num steps total     195000
evaluation/num paths total       1950
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -2.04846
evaluation/Rewards Std              1.78845
evaluation/Rewards Max             -0.0323575
evaluation/Rewards Min             -9.00469
evaluation/Returns Mean          -204.846
evaluation/Returns Std            164.058
evaluation/Returns Max            -12.9631
evaluation/Returns Min           -586.998
evaluation/Actions Mean            -0.0289613
evaluation/Actions Std              0.210649
evaluation/Actions Max              0.997003
evaluation/Actions Min             -0.998522
evaluation/Num Paths               15
evaluation/Average Returns       -204.846
time/data storing (s)               0.00300278
time/evaluation sampling (s)        0.338136
time/exploration sampling (s)       0.137508
time/logging (s)                    0.00374136
time/saving (s)                     0.00195318
time/training (s)                   1.94196
time/epoch (s)                      2.42631
time/total (s)                    317.855
Epoch                             129
-----------------------------  ---------------
2019-04-23 01:18:51.213323 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 130 finished
-----------------------------  ---------------
replay_buffer/size              65700
trainer/QF1 Loss                  194.056
trainer/QF2 Loss                  193.582
trainer/Policy Loss               112.457
trainer/Q1 Predictions Mean      -111.018
trainer/Q1 Predictions Std         78.4994
trainer/Q1 Predictions Max        -19.898
trainer/Q1 Predictions Min       -282.192
trainer/Q2 Predictions Mean      -111.037
trainer/Q2 Predictions Std         78.5242
trainer/Q2 Predictions Max        -19.9339
trainer/Q2 Predictions Min       -282.709
trainer/Q Targets Mean           -110.204
trainer/Q Targets Std              79.6849
trainer/Q Targets Max              -3.60158
trainer/Q Targets Min            -283.653
trainer/Log Pis Mean                1.96582
trainer/Log Pis Std                 1.25715
trainer/Log Pis Max                 6.80313
trainer/Log Pis Min                -1.53822
trainer/Policy mu Mean             -0.0672212
trainer/Policy mu Std               0.68586
trainer/Policy mu Max               3.09046
trainer/Policy mu Min              -3.28901
trainer/Policy log std Mean        -2.01982
trainer/Policy log std Std          0.523235
trainer/Policy log std Max         -0.407449
trainer/Policy log std Min         -2.93678
trainer/Alpha                       0.0628851
trainer/Alpha Loss                 -0.0945452
exploration/num steps total     65700
exploration/num paths total       657
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.40782
exploration/Rewards Std             1.14479
exploration/Rewards Max            -0.0619863
exploration/Rewards Min            -8.98456
exploration/Returns Mean         -140.782
exploration/Returns Std            86.1392
exploration/Returns Max           -59.7988
exploration/Returns Min          -265.901
exploration/Actions Mean            0.00274447
exploration/Actions Std             0.238475
exploration/Actions Max             0.996981
exploration/Actions Min            -0.863741
exploration/Num Paths               5
exploration/Average Returns      -140.782
evaluation/num steps total     196500
evaluation/num paths total       1965
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -2.1008
evaluation/Rewards Std              1.89632
evaluation/Rewards Max             -0.254117
evaluation/Rewards Min            -11.5456
evaluation/Returns Mean          -210.08
evaluation/Returns Std            172.646
evaluation/Returns Max            -53.2555
evaluation/Returns Min           -654.138
evaluation/Actions Mean            -0.0235973
evaluation/Actions Std              0.180761
evaluation/Actions Max              0.999173
evaluation/Actions Min             -0.998772
evaluation/Num Paths               15
evaluation/Average Returns       -210.08
time/data storing (s)               0.00297706
time/evaluation sampling (s)        0.333038
time/exploration sampling (s)       0.137631
time/logging (s)                    0.00477998
time/saving (s)                     0.00157722
time/training (s)                   1.97109
time/epoch (s)                      2.45109
time/total (s)                    320.31
Epoch                             130
-----------------------------  ---------------
2019-04-23 01:18:53.652258 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 131 finished
-----------------------------  ----------------
replay_buffer/size              66200
trainer/QF1 Loss                    2.83723
trainer/QF2 Loss                    2.73737
trainer/Policy Loss               115.474
trainer/Q1 Predictions Mean      -114.155
trainer/Q1 Predictions Std         79.6177
trainer/Q1 Predictions Max        -19.4344
trainer/Q1 Predictions Min       -281.04
trainer/Q2 Predictions Mean      -114.191
trainer/Q2 Predictions Std         79.6228
trainer/Q2 Predictions Max        -19.4041
trainer/Q2 Predictions Min       -281.507
trainer/Q Targets Mean           -115.417
trainer/Q Targets Std              80.4578
trainer/Q Targets Max             -19.5431
trainer/Q Targets Min            -283.796
trainer/Log Pis Mean                1.91934
trainer/Log Pis Std                 1.27017
trainer/Log Pis Max                 4.26403
trainer/Log Pis Min                -3.61086
trainer/Policy mu Mean             -0.159442
trainer/Policy mu Std               0.666865
trainer/Policy mu Max               1.86942
trainer/Policy mu Min              -2.91764
trainer/Policy log std Mean        -1.97495
trainer/Policy log std Std          0.636107
trainer/Policy log std Max         -0.270869
trainer/Policy log std Min         -3.0193
trainer/Alpha                       0.0635271
trainer/Alpha Loss                 -0.222322
exploration/num steps total     66200
exploration/num paths total       662
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -2.19442
exploration/Rewards Std             1.7464
exploration/Rewards Max            -0.0581284
exploration/Rewards Min            -9.85704
exploration/Returns Mean         -219.442
exploration/Returns Std           139.814
exploration/Returns Max           -85.2293
exploration/Returns Min          -435.309
exploration/Actions Mean            0.000156462
exploration/Actions Std             0.275505
exploration/Actions Max             0.999133
exploration/Actions Min            -0.999175
exploration/Num Paths               5
exploration/Average Returns      -219.442
evaluation/num steps total     198000
evaluation/num paths total       1980
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -2.13464
evaluation/Rewards Std              1.45133
evaluation/Rewards Max             -0.327092
evaluation/Rewards Min            -10.3702
evaluation/Returns Mean          -213.464
evaluation/Returns Std            125.582
evaluation/Returns Max            -61.8174
evaluation/Returns Min           -496.285
evaluation/Actions Mean             0.00719311
evaluation/Actions Std              0.171784
evaluation/Actions Max              0.991241
evaluation/Actions Min             -0.99987
evaluation/Num Paths               15
evaluation/Average Returns       -213.464
time/data storing (s)               0.00299921
time/evaluation sampling (s)        0.328483
time/exploration sampling (s)       0.136832
time/logging (s)                    0.00476944
time/saving (s)                     0.00195206
time/training (s)                   1.95741
time/epoch (s)                      2.43245
time/total (s)                    322.747
Epoch                             131
-----------------------------  ----------------
2019-04-23 01:18:56.096486 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 132 finished
-----------------------------  ---------------
replay_buffer/size              66700
trainer/QF1 Loss                    1.66209
trainer/QF2 Loss                    1.82499
trainer/Policy Loss               105.448
trainer/Q1 Predictions Mean      -104.136
trainer/Q1 Predictions Std         73.7107
trainer/Q1 Predictions Max        -19.1119
trainer/Q1 Predictions Min       -277.412
trainer/Q2 Predictions Mean      -104.045
trainer/Q2 Predictions Std         73.6416
trainer/Q2 Predictions Max        -18.9826
trainer/Q2 Predictions Min       -277.446
trainer/Q Targets Mean           -104.602
trainer/Q Targets Std              74.1427
trainer/Q Targets Max             -19.4558
trainer/Q Targets Min            -279.821
trainer/Log Pis Mean                2.1852
trainer/Log Pis Std                 1.18833
trainer/Log Pis Max                 6.72117
trainer/Log Pis Min                -0.574665
trainer/Policy mu Mean             -0.250587
trainer/Policy mu Std               0.7608
trainer/Policy mu Max               2.62743
trainer/Policy mu Min              -2.81243
trainer/Policy log std Mean        -1.98084
trainer/Policy log std Std          0.596274
trainer/Policy log std Max         -0.5009
trainer/Policy log std Min         -2.87863
trainer/Alpha                       0.0646163
trainer/Alpha Loss                  0.50731
exploration/num steps total     66700
exploration/num paths total       667
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.95457
exploration/Rewards Std             1.56734
exploration/Rewards Max            -0.0133583
exploration/Rewards Min           -10.4452
exploration/Returns Mean         -195.457
exploration/Returns Std           125.512
exploration/Returns Max           -28.4687
exploration/Returns Min          -374.163
exploration/Actions Mean           -0.077264
exploration/Actions Std             0.274325
exploration/Actions Max             0.954221
exploration/Actions Min            -0.999373
exploration/Num Paths               5
exploration/Average Returns      -195.457
evaluation/num steps total     199500
evaluation/num paths total       1995
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.4427
evaluation/Rewards Std              1.59831
evaluation/Rewards Max             -0.0816523
evaluation/Rewards Min             -9.96815
evaluation/Returns Mean          -144.27
evaluation/Returns Std            148.071
evaluation/Returns Max            -25.5902
evaluation/Returns Min           -602.443
evaluation/Actions Mean            -0.0484737
evaluation/Actions Std              0.196108
evaluation/Actions Max              0.998215
evaluation/Actions Min             -0.995289
evaluation/Num Paths               15
evaluation/Average Returns       -144.27
time/data storing (s)               0.00290183
time/evaluation sampling (s)        0.333444
time/exploration sampling (s)       0.1367
time/logging (s)                    0.004208
time/saving (s)                     0.00198546
time/training (s)                   1.95766
time/epoch (s)                      2.4369
time/total (s)                    325.188
Epoch                             132
-----------------------------  ---------------
2019-04-23 01:18:58.534272 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 133 finished
-----------------------------  ---------------
replay_buffer/size              67200
trainer/QF1 Loss                  290.651
trainer/QF2 Loss                  289.27
trainer/Policy Loss               101.499
trainer/Q1 Predictions Mean      -100.183
trainer/Q1 Predictions Std         72.6649
trainer/Q1 Predictions Max        -19.1782
trainer/Q1 Predictions Min       -278.73
trainer/Q2 Predictions Mean      -100.197
trainer/Q2 Predictions Std         72.6313
trainer/Q2 Predictions Max        -19.2341
trainer/Q2 Predictions Min       -278.286
trainer/Q Targets Mean            -98.3622
trainer/Q Targets Std              74.6218
trainer/Q Targets Max              -1.00986
trainer/Q Targets Min            -279.314
trainer/Log Pis Mean                1.96609
trainer/Log Pis Std                 1.29815
trainer/Log Pis Max                 7.2467
trainer/Log Pis Min                -2.72711
trainer/Policy mu Mean             -0.177464
trainer/Policy mu Std               0.654286
trainer/Policy mu Max               2.14279
trainer/Policy mu Min              -3.82152
trainer/Policy log std Mean        -2.08925
trainer/Policy log std Std          0.548931
trainer/Policy log std Max         -0.271158
trainer/Policy log std Min         -3.03166
trainer/Alpha                       0.0650829
trainer/Alpha Loss                 -0.0926474
exploration/num steps total     67200
exploration/num paths total       672
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.17985
exploration/Rewards Std             1.74698
exploration/Rewards Max            -0.0262908
exploration/Rewards Min           -11.6526
exploration/Returns Mean         -117.985
exploration/Returns Std           121.813
exploration/Returns Max           -37.8112
exploration/Returns Min          -358.462
exploration/Actions Mean            0.0117525
exploration/Actions Std             0.223842
exploration/Actions Max             0.997015
exploration/Actions Min            -0.993793
exploration/Num Paths               5
exploration/Average Returns      -117.985
evaluation/num steps total     201000
evaluation/num paths total       2010
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -2.12894
evaluation/Rewards Std              2.08075
evaluation/Rewards Max             -0.277424
evaluation/Rewards Min            -11.2093
evaluation/Returns Mean          -212.894
evaluation/Returns Std            183.23
evaluation/Returns Max            -45.3167
evaluation/Returns Min           -581.614
evaluation/Actions Mean            -0.0422473
evaluation/Actions Std              0.231612
evaluation/Actions Max              0.99911
evaluation/Actions Min             -0.997195
evaluation/Num Paths               15
evaluation/Average Returns       -212.894
time/data storing (s)               0.00289679
time/evaluation sampling (s)        0.337194
time/exploration sampling (s)       0.135357
time/logging (s)                    0.00478818
time/saving (s)                     0.00191114
time/training (s)                   1.94959
time/epoch (s)                      2.43174
time/total (s)                    327.624
Epoch                             133
-----------------------------  ---------------
2019-04-23 01:19:00.984719 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 134 finished
-----------------------------  ---------------
replay_buffer/size              67700
trainer/QF1 Loss                    4.10442
trainer/QF2 Loss                    4.20346
trainer/Policy Loss               101.878
trainer/Q1 Predictions Mean      -100.322
trainer/Q1 Predictions Std         76.4285
trainer/Q1 Predictions Max        -18.8421
trainer/Q1 Predictions Min       -275.315
trainer/Q2 Predictions Mean      -100.311
trainer/Q2 Predictions Std         76.401
trainer/Q2 Predictions Max        -18.9436
trainer/Q2 Predictions Min       -275.314
trainer/Q Targets Mean           -101.767
trainer/Q Targets Std              77.4759
trainer/Q Targets Max             -18.8999
trainer/Q Targets Min            -278.893
trainer/Log Pis Mean                2.06694
trainer/Log Pis Std                 1.57167
trainer/Log Pis Max                 7.61545
trainer/Log Pis Min                -2.90693
trainer/Policy mu Mean             -0.0912678
trainer/Policy mu Std               0.803141
trainer/Policy mu Max               3.27229
trainer/Policy mu Min              -3.4568
trainer/Policy log std Mean        -2.03024
trainer/Policy log std Std          0.657759
trainer/Policy log std Max         -0.224878
trainer/Policy log std Min         -3.03515
trainer/Alpha                       0.0632851
trainer/Alpha Loss                  0.184761
exploration/num steps total     67700
exploration/num paths total       677
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.705801
exploration/Rewards Std             0.936658
exploration/Rewards Max            -0.0875534
exploration/Rewards Min           -11.476
exploration/Returns Mean          -70.5801
exploration/Returns Std            24.9641
exploration/Returns Max           -47.737
exploration/Returns Min          -119.009
exploration/Actions Mean            0.00383101
exploration/Actions Std             0.165559
exploration/Actions Max             0.991892
exploration/Actions Min            -0.961337
exploration/Num Paths               5
exploration/Average Returns       -70.5801
evaluation/num steps total     202500
evaluation/num paths total       2025
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.16025
evaluation/Rewards Std              1.2596
evaluation/Rewards Max             -0.0961597
evaluation/Rewards Min             -9.95952
evaluation/Returns Mean          -116.025
evaluation/Returns Std             91.6907
evaluation/Returns Max            -20.2727
evaluation/Returns Min           -296.257
evaluation/Actions Mean             0.00429486
evaluation/Actions Std              0.179325
evaluation/Actions Max              0.997937
evaluation/Actions Min             -0.999636
evaluation/Num Paths               15
evaluation/Average Returns       -116.025
time/data storing (s)               0.0028785
time/evaluation sampling (s)        0.322465
time/exploration sampling (s)       0.139365
time/logging (s)                    0.00475151
time/saving (s)                     0.00193274
time/training (s)                   1.97243
time/epoch (s)                      2.44382
time/total (s)                    330.072
Epoch                             134
-----------------------------  ---------------
2019-04-23 01:19:03.427975 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 135 finished
-----------------------------  ---------------
replay_buffer/size              68200
trainer/QF1 Loss                  404.932
trainer/QF2 Loss                  407.277
trainer/Policy Loss               114.86
trainer/Q1 Predictions Mean      -113.308
trainer/Q1 Predictions Std         76.7749
trainer/Q1 Predictions Max        -18.972
trainer/Q1 Predictions Min       -277.293
trainer/Q2 Predictions Mean      -113.294
trainer/Q2 Predictions Std         76.7546
trainer/Q2 Predictions Max        -19.0155
trainer/Q2 Predictions Min       -277.27
trainer/Q Targets Mean           -111.578
trainer/Q Targets Std              77.3111
trainer/Q Targets Max              -4.18364
trainer/Q Targets Min            -278.697
trainer/Log Pis Mean                2.17416
trainer/Log Pis Std                 1.24105
trainer/Log Pis Max                 6.41244
trainer/Log Pis Min                -0.719951
trainer/Policy mu Mean             -0.126479
trainer/Policy mu Std               0.760275
trainer/Policy mu Max               2.78109
trainer/Policy mu Min              -2.46927
trainer/Policy log std Mean        -2.02895
trainer/Policy log std Std          0.626885
trainer/Policy log std Max         -0.526252
trainer/Policy log std Min         -3.09252
trainer/Alpha                       0.0643967
trainer/Alpha Loss                  0.477673
exploration/num steps total     68200
exploration/num paths total       682
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -2.49054
exploration/Rewards Std             2.25788
exploration/Rewards Max            -0.0146046
exploration/Rewards Min            -6.52469
exploration/Returns Mean         -249.054
exploration/Returns Std           213.658
exploration/Returns Max           -36.9222
exploration/Returns Min          -519.815
exploration/Actions Mean            0.0222923
exploration/Actions Std             0.27393
exploration/Actions Max             0.993984
exploration/Actions Min            -0.998708
exploration/Num Paths               5
exploration/Average Returns      -249.054
evaluation/num steps total     204000
evaluation/num paths total       2040
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.28507
evaluation/Rewards Std              1.59646
evaluation/Rewards Max             -0.0859456
evaluation/Rewards Min            -10.8851
evaluation/Returns Mean          -128.507
evaluation/Returns Std            121.705
evaluation/Returns Max            -17.66
evaluation/Returns Min           -473.225
evaluation/Actions Mean             0.0110487
evaluation/Actions Std              0.186517
evaluation/Actions Max              0.999561
evaluation/Actions Min             -0.998651
evaluation/Num Paths               15
evaluation/Average Returns       -128.507
time/data storing (s)               0.00343085
time/evaluation sampling (s)        0.329356
time/exploration sampling (s)       0.140223
time/logging (s)                    0.00466487
time/saving (s)                     0.00190615
time/training (s)                   1.95725
time/epoch (s)                      2.43683
time/total (s)                    332.513
Epoch                             135
-----------------------------  ---------------
2019-04-23 01:19:05.870870 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 136 finished
-----------------------------  ---------------
replay_buffer/size              68700
trainer/QF1 Loss                   25.9773
trainer/QF2 Loss                   25.7775
trainer/Policy Loss               100.334
trainer/Q1 Predictions Mean       -98.747
trainer/Q1 Predictions Std         77.414
trainer/Q1 Predictions Max        -18.5299
trainer/Q1 Predictions Min       -279.9
trainer/Q2 Predictions Mean       -98.6954
trainer/Q2 Predictions Std         77.3795
trainer/Q2 Predictions Max        -18.4735
trainer/Q2 Predictions Min       -280.058
trainer/Q Targets Mean            -98.7058
trainer/Q Targets Std              78.655
trainer/Q Targets Max              -0.323037
trainer/Q Targets Min            -281.697
trainer/Log Pis Mean                2.1193
trainer/Log Pis Std                 1.15264
trainer/Log Pis Max                 8.03655
trainer/Log Pis Min                -2.66142
trainer/Policy mu Mean             -0.025259
trainer/Policy mu Std               0.744806
trainer/Policy mu Max               3.55293
trainer/Policy mu Min              -3.66142
trainer/Policy log std Mean        -2.04844
trainer/Policy log std Std          0.577515
trainer/Policy log std Max         -0.131523
trainer/Policy log std Min         -3.02721
trainer/Alpha                       0.0636134
trainer/Alpha Loss                  0.328664
exploration/num steps total     68700
exploration/num paths total       687
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.37027
exploration/Rewards Std             1.42254
exploration/Rewards Max            -0.0421432
exploration/Rewards Min           -10.4828
exploration/Returns Mean         -137.027
exploration/Returns Std            91.8957
exploration/Returns Max           -35.7513
exploration/Returns Min          -273.638
exploration/Actions Mean            0.00964768
exploration/Actions Std             0.210827
exploration/Actions Max             0.99988
exploration/Actions Min            -0.937024
exploration/Num Paths               5
exploration/Average Returns      -137.027
evaluation/num steps total     205500
evaluation/num paths total       2055
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.7598
evaluation/Rewards Std              1.70424
evaluation/Rewards Max             -0.124817
evaluation/Rewards Min            -10.1688
evaluation/Returns Mean          -175.98
evaluation/Returns Std            155.134
evaluation/Returns Max            -22.5025
evaluation/Returns Min           -540.107
evaluation/Actions Mean            -0.00570173
evaluation/Actions Std              0.159646
evaluation/Actions Max              0.992454
evaluation/Actions Min             -0.999241
evaluation/Num Paths               15
evaluation/Average Returns       -175.98
time/data storing (s)               0.00294133
time/evaluation sampling (s)        0.330116
time/exploration sampling (s)       0.136911
time/logging (s)                    0.00473998
time/saving (s)                     0.00153286
time/training (s)                   1.96006
time/epoch (s)                      2.4363
time/total (s)                    334.954
Epoch                             136
-----------------------------  ---------------
2019-04-23 01:19:08.322599 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 137 finished
-----------------------------  ---------------
replay_buffer/size              69200
trainer/QF1 Loss                  693.267
trainer/QF2 Loss                  690.582
trainer/Policy Loss                99.2636
trainer/Q1 Predictions Mean       -97.6173
trainer/Q1 Predictions Std         76.0416
trainer/Q1 Predictions Max        -18.8352
trainer/Q1 Predictions Min       -280.171
trainer/Q2 Predictions Mean       -97.5783
trainer/Q2 Predictions Std         76.0951
trainer/Q2 Predictions Max        -18.9138
trainer/Q2 Predictions Min       -280.378
trainer/Q Targets Mean            -94.1817
trainer/Q Targets Std              77.3346
trainer/Q Targets Max              -0.117455
trainer/Q Targets Min            -280.967
trainer/Log Pis Mean                2.20886
trainer/Log Pis Std                 1.26666
trainer/Log Pis Max                 7.32472
trainer/Log Pis Min                -2.37412
trainer/Policy mu Mean              0.00474893
trainer/Policy mu Std               0.728932
trainer/Policy mu Max               3.19628
trainer/Policy mu Min              -2.58952
trainer/Policy log std Mean        -2.03821
trainer/Policy log std Std          0.617256
trainer/Policy log std Max         -0.18008
trainer/Policy log std Min         -3.00556
trainer/Alpha                       0.0630186
trainer/Alpha Loss                  0.57739
exploration/num steps total     69200
exploration/num paths total       692
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -2.5627
exploration/Rewards Std             2.19978
exploration/Rewards Max            -0.034986
exploration/Rewards Min            -9.87032
exploration/Returns Mean         -256.27
exploration/Returns Std           214.903
exploration/Returns Max           -42.12
exploration/Returns Min          -526.504
exploration/Actions Mean           -0.0079968
exploration/Actions Std             0.182056
exploration/Actions Max             0.998727
exploration/Actions Min            -0.995237
exploration/Num Paths               5
exploration/Average Returns      -256.27
evaluation/num steps total     207000
evaluation/num paths total       2070
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.47285
evaluation/Rewards Std              1.56266
evaluation/Rewards Max             -0.0877769
evaluation/Rewards Min             -8.54675
evaluation/Returns Mean          -147.285
evaluation/Returns Std            139.815
evaluation/Returns Max            -19.5913
evaluation/Returns Min           -552.293
evaluation/Actions Mean             0.00216238
evaluation/Actions Std              0.16322
evaluation/Actions Max              0.999487
evaluation/Actions Min             -0.996273
evaluation/Num Paths               15
evaluation/Average Returns       -147.285
time/data storing (s)               0.00292629
time/evaluation sampling (s)        0.331444
time/exploration sampling (s)       0.137484
time/logging (s)                    0.00475757
time/saving (s)                     0.00192889
time/training (s)                   1.96645
time/epoch (s)                      2.445
time/total (s)                    337.403
Epoch                             137
-----------------------------  ---------------
2019-04-23 01:19:10.750658 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 138 finished
-----------------------------  ---------------
replay_buffer/size              69700
trainer/QF1 Loss                    4.1301
trainer/QF2 Loss                    4.10853
trainer/Policy Loss                98.6647
trainer/Q1 Predictions Mean       -97.1425
trainer/Q1 Predictions Std         72.8533
trainer/Q1 Predictions Max        -18.2429
trainer/Q1 Predictions Min       -278.683
trainer/Q2 Predictions Mean       -97.1608
trainer/Q2 Predictions Std         72.8206
trainer/Q2 Predictions Max        -18.3066
trainer/Q2 Predictions Min       -279.122
trainer/Q Targets Mean            -97.5751
trainer/Q Targets Std              73.1777
trainer/Q Targets Max              -0.333417
trainer/Q Targets Min            -280.187
trainer/Log Pis Mean                1.95124
trainer/Log Pis Std                 1.39844
trainer/Log Pis Max                 8.06412
trainer/Log Pis Min                -4.66433
trainer/Policy mu Mean             -0.0649017
trainer/Policy mu Std               0.688648
trainer/Policy mu Max               3.18442
trainer/Policy mu Min              -2.92011
trainer/Policy log std Mean        -2.06343
trainer/Policy log std Std          0.591681
trainer/Policy log std Max         -0.105555
trainer/Policy log std Min         -2.96817
trainer/Alpha                       0.0660987
trainer/Alpha Loss                 -0.132454
exploration/num steps total     69700
exploration/num paths total       697
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.890285
exploration/Rewards Std             0.855081
exploration/Rewards Max            -0.0101493
exploration/Rewards Min            -5.94637
exploration/Returns Mean          -89.0285
exploration/Returns Std            64.7072
exploration/Returns Max           -18.7889
exploration/Returns Min          -177.561
exploration/Actions Mean            0.0128917
exploration/Actions Std             0.197119
exploration/Actions Max             0.990553
exploration/Actions Min            -0.998759
exploration/Num Paths               5
exploration/Average Returns       -89.0285
evaluation/num steps total     208500
evaluation/num paths total       2085
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -2.5877
evaluation/Rewards Std              1.92097
evaluation/Rewards Max             -0.134957
evaluation/Rewards Min             -9.38895
evaluation/Returns Mean          -258.77
evaluation/Returns Std            181.513
evaluation/Returns Max            -51.5643
evaluation/Returns Min           -508.441
evaluation/Actions Mean             0.0011511
evaluation/Actions Std              0.169848
evaluation/Actions Max              0.998943
evaluation/Actions Min             -0.995324
evaluation/Num Paths               15
evaluation/Average Returns       -258.77
time/data storing (s)               0.00291117
time/evaluation sampling (s)        0.330614
time/exploration sampling (s)       0.137419
time/logging (s)                    0.00471882
time/saving (s)                     0.00194756
time/training (s)                   1.94361
time/epoch (s)                      2.42122
time/total (s)                    339.828
Epoch                             138
-----------------------------  ---------------
2019-04-23 01:19:13.226608 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 139 finished
-----------------------------  ---------------
replay_buffer/size              70200
trainer/QF1 Loss                  578.41
trainer/QF2 Loss                  580.738
trainer/Policy Loss                97.0141
trainer/Q1 Predictions Mean       -95.6799
trainer/Q1 Predictions Std         71.4753
trainer/Q1 Predictions Max        -18.6334
trainer/Q1 Predictions Min       -276.034
trainer/Q2 Predictions Mean       -95.7285
trainer/Q2 Predictions Std         71.4496
trainer/Q2 Predictions Max        -18.7288
trainer/Q2 Predictions Min       -276.079
trainer/Q Targets Mean            -92.318
trainer/Q Targets Std              72.9255
trainer/Q Targets Max              -3.08969
trainer/Q Targets Min            -278.706
trainer/Log Pis Mean                1.86677
trainer/Log Pis Std                 1.28881
trainer/Log Pis Max                 5.58025
trainer/Log Pis Min                -2.86999
trainer/Policy mu Mean              0.0224298
trainer/Policy mu Std               0.667762
trainer/Policy mu Max               2.99185
trainer/Policy mu Min              -2.04347
trainer/Policy log std Mean        -2.06452
trainer/Policy log std Std          0.510408
trainer/Policy log std Max         -0.444625
trainer/Policy log std Min         -2.91335
trainer/Alpha                       0.0642056
trainer/Alpha Loss                 -0.365827
exploration/num steps total     70200
exploration/num paths total       702
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -2.14248
exploration/Rewards Std             1.68858
exploration/Rewards Max            -0.0351145
exploration/Rewards Min           -10.3576
exploration/Returns Mean         -214.248
exploration/Returns Std           146.343
exploration/Returns Max           -55.4888
exploration/Returns Min          -391.665
exploration/Actions Mean           -0.0130677
exploration/Actions Std             0.1975
exploration/Actions Max             0.99395
exploration/Actions Min            -0.998684
exploration/Num Paths               5
exploration/Average Returns      -214.248
evaluation/num steps total     210000
evaluation/num paths total       2100
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.63632
evaluation/Rewards Std              1.7494
evaluation/Rewards Max             -0.222698
evaluation/Rewards Min             -9.49927
evaluation/Returns Mean          -163.632
evaluation/Returns Std            159.731
evaluation/Returns Max            -23.3304
evaluation/Returns Min           -571.365
evaluation/Actions Mean             0.0113196
evaluation/Actions Std              0.159986
evaluation/Actions Max              0.999845
evaluation/Actions Min             -0.996372
evaluation/Num Paths               15
evaluation/Average Returns       -163.632
time/data storing (s)               0.00293328
time/evaluation sampling (s)        0.330079
time/exploration sampling (s)       0.141054
time/logging (s)                    0.00476709
time/saving (s)                     0.00979561
time/training (s)                   1.9806
time/epoch (s)                      2.46923
time/total (s)                    342.302
Epoch                             139
-----------------------------  ---------------
2019-04-23 01:19:15.695204 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 140 finished
-----------------------------  ---------------
replay_buffer/size              70700
trainer/QF1 Loss                    1.29974
trainer/QF2 Loss                    1.65918
trainer/Policy Loss               103.016
trainer/Q1 Predictions Mean      -101.693
trainer/Q1 Predictions Std         74.4436
trainer/Q1 Predictions Max        -18.4282
trainer/Q1 Predictions Min       -277.188
trainer/Q2 Predictions Mean      -101.619
trainer/Q2 Predictions Std         74.3338
trainer/Q2 Predictions Max        -18.5276
trainer/Q2 Predictions Min       -276.24
trainer/Q Targets Mean           -102.083
trainer/Q Targets Std              75.0666
trainer/Q Targets Max             -18.4581
trainer/Q Targets Min            -280.401
trainer/Log Pis Mean                1.94327
trainer/Log Pis Std                 0.983368
trainer/Log Pis Max                 5.48851
trainer/Log Pis Min                -1.5488
trainer/Policy mu Mean              0.00786247
trainer/Policy mu Std               0.653796
trainer/Policy mu Max               2.87847
trainer/Policy mu Min              -2.13604
trainer/Policy log std Mean        -2.04481
trainer/Policy log std Std          0.490732
trainer/Policy log std Max         -0.344787
trainer/Policy log std Min         -2.72553
trainer/Alpha                       0.0661722
trainer/Alpha Loss                 -0.154069
exploration/num steps total     70700
exploration/num paths total       707
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.48188
exploration/Rewards Std             0.998129
exploration/Rewards Max            -0.0604422
exploration/Rewards Min            -7.26835
exploration/Returns Mean         -148.188
exploration/Returns Std            81.4057
exploration/Returns Max           -46.8177
exploration/Returns Min          -271.183
exploration/Actions Mean            0.00832024
exploration/Actions Std             0.199038
exploration/Actions Max             0.997107
exploration/Actions Min            -0.984891
exploration/Num Paths               5
exploration/Average Returns      -148.188
evaluation/num steps total     211500
evaluation/num paths total       2115
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -2.27298
evaluation/Rewards Std              1.87978
evaluation/Rewards Max             -0.0972408
evaluation/Rewards Min             -9.63947
evaluation/Returns Mean          -227.298
evaluation/Returns Std            171.891
evaluation/Returns Max            -36.2548
evaluation/Returns Min           -526.539
evaluation/Actions Mean             0.0174954
evaluation/Actions Std              0.171221
evaluation/Actions Max              0.999189
evaluation/Actions Min             -0.997069
evaluation/Num Paths               15
evaluation/Average Returns       -227.298
time/data storing (s)               0.00304676
time/evaluation sampling (s)        0.32855
time/exploration sampling (s)       0.139545
time/logging (s)                    0.00475187
time/saving (s)                     0.0019334
time/training (s)                   1.98367
time/epoch (s)                      2.46149
time/total (s)                    344.768
Epoch                             140
-----------------------------  ---------------
2019-04-23 01:19:18.150159 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 141 finished
-----------------------------  ---------------
replay_buffer/size              71200
trainer/QF1 Loss                   90.8786
trainer/QF2 Loss                   90.6121
trainer/Policy Loss               100.903
trainer/Q1 Predictions Mean       -99.234
trainer/Q1 Predictions Std         75.701
trainer/Q1 Predictions Max        -18.6415
trainer/Q1 Predictions Min       -277.944
trainer/Q2 Predictions Mean       -99.2192
trainer/Q2 Predictions Std         75.6606
trainer/Q2 Predictions Max        -18.4522
trainer/Q2 Predictions Min       -277.368
trainer/Q Targets Mean            -99.0025
trainer/Q Targets Std              77.2524
trainer/Q Targets Max              -2.62513
trainer/Q Targets Min            -280.079
trainer/Log Pis Mean                2.06022
trainer/Log Pis Std                 1.45167
trainer/Log Pis Max                 6.39821
trainer/Log Pis Min                -2.94432
trainer/Policy mu Mean             -0.132738
trainer/Policy mu Std               0.72765
trainer/Policy mu Max               3.88018
trainer/Policy mu Min              -3.34846
trainer/Policy log std Mean        -2.09776
trainer/Policy log std Std          0.592528
trainer/Policy log std Max         -0.243352
trainer/Policy log std Min         -2.99748
trainer/Alpha                       0.0680255
trainer/Alpha Loss                  0.161876
exploration/num steps total     71200
exploration/num paths total       712
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.80391
exploration/Rewards Std             1.91625
exploration/Rewards Max            -0.0350019
exploration/Rewards Min           -10.3504
exploration/Returns Mean         -180.391
exploration/Returns Std           174.659
exploration/Returns Max           -24.9977
exploration/Returns Min          -510.927
exploration/Actions Mean           -0.0352223
exploration/Actions Std             0.205361
exploration/Actions Max             0.998512
exploration/Actions Min            -0.998432
exploration/Num Paths               5
exploration/Average Returns      -180.391
evaluation/num steps total     213000
evaluation/num paths total       2130
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -2.08159
evaluation/Rewards Std              2.02077
evaluation/Rewards Max             -0.0773472
evaluation/Rewards Min            -11.507
evaluation/Returns Mean          -208.159
evaluation/Returns Std            184.173
evaluation/Returns Max            -12.1655
evaluation/Returns Min           -533.154
evaluation/Actions Mean             0.00521601
evaluation/Actions Std              0.180838
evaluation/Actions Max              0.995774
evaluation/Actions Min             -0.999576
evaluation/Num Paths               15
evaluation/Average Returns       -208.159
time/data storing (s)               0.00283339
time/evaluation sampling (s)        0.329166
time/exploration sampling (s)       0.14103
time/logging (s)                    0.00433543
time/saving (s)                     0.00193616
time/training (s)                   1.96894
time/epoch (s)                      2.44824
time/total (s)                    347.22
Epoch                             141
-----------------------------  ---------------
2019-04-23 01:19:20.613747 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 142 finished
-----------------------------  ---------------
replay_buffer/size              71700
trainer/QF1 Loss                    6.09953
trainer/QF2 Loss                    6.11802
trainer/Policy Loss               108.073
trainer/Q1 Predictions Mean      -106.603
trainer/Q1 Predictions Std         80.3739
trainer/Q1 Predictions Max        -18.6042
trainer/Q1 Predictions Min       -282.984
trainer/Q2 Predictions Mean      -106.64
trainer/Q2 Predictions Std         80.3293
trainer/Q2 Predictions Max        -18.8392
trainer/Q2 Predictions Min       -283.467
trainer/Q Targets Mean           -107.285
trainer/Q Targets Std              81.2551
trainer/Q Targets Max              -0.928087
trainer/Q Targets Min            -285.041
trainer/Log Pis Mean                1.97505
trainer/Log Pis Std                 1.19236
trainer/Log Pis Max                 4.71526
trainer/Log Pis Min                -2.39803
trainer/Policy mu Mean              0.0244764
trainer/Policy mu Std               0.702894
trainer/Policy mu Max               2.165
trainer/Policy mu Min              -2.4997
trainer/Policy log std Mean        -2.02201
trainer/Policy log std Std          0.566678
trainer/Policy log std Max         -0.403265
trainer/Policy log std Min         -3.05982
trainer/Alpha                       0.0695494
trainer/Alpha Loss                 -0.0665135
exploration/num steps total     71700
exploration/num paths total       717
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.88841
exploration/Rewards Std             1.85947
exploration/Rewards Max            -0.0104357
exploration/Rewards Min            -7.71047
exploration/Returns Mean         -188.841
exploration/Returns Std           168.347
exploration/Returns Max           -57.1259
exploration/Returns Min          -484.617
exploration/Actions Mean            0.0102927
exploration/Actions Std             0.202477
exploration/Actions Max             0.999977
exploration/Actions Min            -0.989978
exploration/Num Paths               5
exploration/Average Returns      -188.841
evaluation/num steps total     214500
evaluation/num paths total       2145
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -2.78942
evaluation/Rewards Std              2.25464
evaluation/Rewards Max             -0.107573
evaluation/Rewards Min             -7.97315
evaluation/Returns Mean          -278.942
evaluation/Returns Std            217.373
evaluation/Returns Max            -13.1487
evaluation/Returns Min           -579.694
evaluation/Actions Mean             0.0151408
evaluation/Actions Std              0.151424
evaluation/Actions Max              0.99736
evaluation/Actions Min             -0.992371
evaluation/Num Paths               15
evaluation/Average Returns       -278.942
time/data storing (s)               0.00281299
time/evaluation sampling (s)        0.332814
time/exploration sampling (s)       0.141851
time/logging (s)                    0.00475646
time/saving (s)                     0.00193385
time/training (s)                   1.97385
time/epoch (s)                      2.45802
time/total (s)                    349.683
Epoch                             142
-----------------------------  ---------------
2019-04-23 01:19:23.047250 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 143 finished
-----------------------------  ---------------
replay_buffer/size              72200
trainer/QF1 Loss                    3.92034
trainer/QF2 Loss                    3.6105
trainer/Policy Loss                89.9871
trainer/Q1 Predictions Mean       -88.0791
trainer/Q1 Predictions Std         69.3153
trainer/Q1 Predictions Max        -18.2499
trainer/Q1 Predictions Min       -277.229
trainer/Q2 Predictions Mean       -88.1334
trainer/Q2 Predictions Std         69.3485
trainer/Q2 Predictions Max        -18.4643
trainer/Q2 Predictions Min       -276.925
trainer/Q Targets Mean            -89.3939
trainer/Q Targets Std              70.2167
trainer/Q Targets Max             -18.5556
trainer/Q Targets Min            -282.403
trainer/Log Pis Mean                2.18633
trainer/Log Pis Std                 1.24145
trainer/Log Pis Max                 5.62355
trainer/Log Pis Min                -5.15975
trainer/Policy mu Mean             -0.0654018
trainer/Policy mu Std               0.510917
trainer/Policy mu Max               1.85699
trainer/Policy mu Min              -3.14544
trainer/Policy log std Mean        -2.24479
trainer/Policy log std Std          0.491159
trainer/Policy log std Max         -0.378182
trainer/Policy log std Min         -2.97993
trainer/Alpha                       0.0687964
trainer/Alpha Loss                  0.498741
exploration/num steps total     72200
exploration/num paths total       722
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.933474
exploration/Rewards Std             1.25719
exploration/Rewards Max            -0.0311335
exploration/Rewards Min            -9.46954
exploration/Returns Mean          -93.3474
exploration/Returns Std            75.4035
exploration/Returns Max           -38.2007
exploration/Returns Min          -240.112
exploration/Actions Mean            0.0190266
exploration/Actions Std             0.212252
exploration/Actions Max             0.99683
exploration/Actions Min            -0.974483
exploration/Num Paths               5
exploration/Average Returns       -93.3474
evaluation/num steps total     216000
evaluation/num paths total       2160
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.45608
evaluation/Rewards Std              1.8113
evaluation/Rewards Max             -0.0557264
evaluation/Rewards Min            -10.5761
evaluation/Returns Mean          -145.608
evaluation/Returns Std            154.302
evaluation/Returns Max            -27.8197
evaluation/Returns Min           -510.227
evaluation/Actions Mean             0.0123315
evaluation/Actions Std              0.177993
evaluation/Actions Max              0.999902
evaluation/Actions Min             -0.999924
evaluation/Num Paths               15
evaluation/Average Returns       -145.608
time/data storing (s)               0.0030379
time/evaluation sampling (s)        0.325411
time/exploration sampling (s)       0.140532
time/logging (s)                    0.0050984
time/saving (s)                     0.00191333
time/training (s)                   1.9507
time/epoch (s)                      2.4267
time/total (s)                    352.114
Epoch                             143
-----------------------------  ---------------
2019-04-23 01:19:25.524120 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 144 finished
-----------------------------  ---------------
replay_buffer/size              72700
trainer/QF1 Loss                    1.34032
trainer/QF2 Loss                    1.28882
trainer/Policy Loss               113.714
trainer/Q1 Predictions Mean      -112.203
trainer/Q1 Predictions Std         79.5356
trainer/Q1 Predictions Max        -18.2379
trainer/Q1 Predictions Min       -280.338
trainer/Q2 Predictions Mean      -112.165
trainer/Q2 Predictions Std         79.4759
trainer/Q2 Predictions Max        -18.0434
trainer/Q2 Predictions Min       -280.453
trainer/Q Targets Mean           -112.627
trainer/Q Targets Std              80.1479
trainer/Q Targets Max             -18.352
trainer/Q Targets Min            -283.154
trainer/Log Pis Mean                1.96742
trainer/Log Pis Std                 1.24888
trainer/Log Pis Max                 6.06168
trainer/Log Pis Min                -2.76346
trainer/Policy mu Mean             -0.099018
trainer/Policy mu Std               0.708021
trainer/Policy mu Max               2.2615
trainer/Policy mu Min              -2.98711
trainer/Policy log std Mean        -2.02845
trainer/Policy log std Std          0.562152
trainer/Policy log std Max         -0.193819
trainer/Policy log std Min         -2.88925
trainer/Alpha                       0.0700093
trainer/Alpha Loss                 -0.0866278
exploration/num steps total     72700
exploration/num paths total       727
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.4728
exploration/Rewards Std             2.15611
exploration/Rewards Max            -0.00711351
exploration/Rewards Min            -9.92024
exploration/Returns Mean         -147.28
exploration/Returns Std           200.874
exploration/Returns Max           -26.0105
exploration/Returns Min          -547.926
exploration/Actions Mean            0.0109597
exploration/Actions Std             0.238562
exploration/Actions Max             0.996738
exploration/Actions Min            -0.989416
exploration/Num Paths               5
exploration/Average Returns      -147.28
evaluation/num steps total     217500
evaluation/num paths total       2175
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.76975
evaluation/Rewards Std              1.85744
evaluation/Rewards Max             -0.0956218
evaluation/Rewards Min            -10.3487
evaluation/Returns Mean          -176.975
evaluation/Returns Std            159.608
evaluation/Returns Max            -14.0003
evaluation/Returns Min           -485.191
evaluation/Actions Mean             0.0186825
evaluation/Actions Std              0.178371
evaluation/Actions Max              0.998019
evaluation/Actions Min             -0.99795
evaluation/Num Paths               15
evaluation/Average Returns       -176.975
time/data storing (s)               0.00297795
time/evaluation sampling (s)        0.328014
time/exploration sampling (s)       0.136741
time/logging (s)                    0.00481022
time/saving (s)                     0.00194629
time/training (s)                   1.99487
time/epoch (s)                      2.46936
time/total (s)                    354.588
Epoch                             144
-----------------------------  ---------------
2019-04-23 01:19:27.982475 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 145 finished
-----------------------------  ---------------
replay_buffer/size              73200
trainer/QF1 Loss                   32.7654
trainer/QF2 Loss                   33.1627
trainer/Policy Loss               104.876
trainer/Q1 Predictions Mean      -103.376
trainer/Q1 Predictions Std         75.6387
trainer/Q1 Predictions Max        -18.1369
trainer/Q1 Predictions Min       -280.707
trainer/Q2 Predictions Mean      -103.379
trainer/Q2 Predictions Std         75.5698
trainer/Q2 Predictions Max        -18.262
trainer/Q2 Predictions Min       -281.265
trainer/Q Targets Mean           -103.435
trainer/Q Targets Std              76.8871
trainer/Q Targets Max              -0.717358
trainer/Q Targets Min            -282.843
trainer/Log Pis Mean                1.98955
trainer/Log Pis Std                 1.33781
trainer/Log Pis Max                 7.72046
trainer/Log Pis Min                -2.45065
trainer/Policy mu Mean             -0.139743
trainer/Policy mu Std               0.65189
trainer/Policy mu Max               3.59655
trainer/Policy mu Min              -2.69899
trainer/Policy log std Mean        -2.03386
trainer/Policy log std Std          0.577053
trainer/Policy log std Max         -0.346035
trainer/Policy log std Min         -2.96305
trainer/Alpha                       0.0705747
trainer/Alpha Loss                 -0.0277043
exploration/num steps total     73200
exploration/num paths total       732
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.67416
exploration/Rewards Std             1.00127
exploration/Rewards Max            -0.0629873
exploration/Rewards Min            -5.38279
exploration/Returns Mean         -167.416
exploration/Returns Std            90.9555
exploration/Returns Max           -64.2918
exploration/Returns Min          -278.043
exploration/Actions Mean           -0.0235256
exploration/Actions Std             0.172552
exploration/Actions Max             0.692157
exploration/Actions Min            -0.994394
exploration/Num Paths               5
exploration/Average Returns      -167.416
evaluation/num steps total     219000
evaluation/num paths total       2190
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.15179
evaluation/Rewards Std              1.45629
evaluation/Rewards Max             -0.109029
evaluation/Rewards Min            -11.8703
evaluation/Returns Mean          -115.179
evaluation/Returns Std            121.608
evaluation/Returns Max            -21.7818
evaluation/Returns Min           -501.665
evaluation/Actions Mean            -0.0172231
evaluation/Actions Std              0.169637
evaluation/Actions Max              0.996598
evaluation/Actions Min             -0.999724
evaluation/Num Paths               15
evaluation/Average Returns       -115.179
time/data storing (s)               0.00303263
time/evaluation sampling (s)        0.328647
time/exploration sampling (s)       0.137028
time/logging (s)                    0.0047415
time/saving (s)                     0.00194533
time/training (s)                   1.97557
time/epoch (s)                      2.45096
time/total (s)                    357.044
Epoch                             145
-----------------------------  ---------------
2019-04-23 01:19:30.417296 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 146 finished
-----------------------------  ---------------
replay_buffer/size              73700
trainer/QF1 Loss                   38.1404
trainer/QF2 Loss                   38.2541
trainer/Policy Loss               106.396
trainer/Q1 Predictions Mean      -104.825
trainer/Q1 Predictions Std         73.1001
trainer/Q1 Predictions Max        -18.1408
trainer/Q1 Predictions Min       -274.999
trainer/Q2 Predictions Mean      -104.738
trainer/Q2 Predictions Std         73.0266
trainer/Q2 Predictions Max        -18.3426
trainer/Q2 Predictions Min       -275.742
trainer/Q Targets Mean           -105.745
trainer/Q Targets Std              75.1718
trainer/Q Targets Max              -1.72315
trainer/Q Targets Min            -284.338
trainer/Log Pis Mean                2.00658
trainer/Log Pis Std                 1.13301
trainer/Log Pis Max                 5.95955
trainer/Log Pis Min                -1.99739
trainer/Policy mu Mean             -0.118734
trainer/Policy mu Std               0.645185
trainer/Policy mu Max               2.17245
trainer/Policy mu Min              -3.40815
trainer/Policy log std Mean        -2.05427
trainer/Policy log std Std          0.524471
trainer/Policy log std Max         -0.216814
trainer/Policy log std Min         -3.00536
trainer/Alpha                       0.0699091
trainer/Alpha Loss                  0.0175018
exploration/num steps total     73700
exploration/num paths total       737
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.58136
exploration/Rewards Std             1.93297
exploration/Rewards Max            -0.00922087
exploration/Rewards Min            -9.23061
exploration/Returns Mean         -158.136
exploration/Returns Std           175.363
exploration/Returns Max           -27.3451
exploration/Returns Min          -492.867
exploration/Actions Mean            0.00278826
exploration/Actions Std             0.193634
exploration/Actions Max             0.99649
exploration/Actions Min            -0.989532
exploration/Num Paths               5
exploration/Average Returns      -158.136
evaluation/num steps total     220500
evaluation/num paths total       2205
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -2.38048
evaluation/Rewards Std              1.61216
evaluation/Rewards Max             -0.180253
evaluation/Rewards Min             -9.60074
evaluation/Returns Mean          -238.048
evaluation/Returns Std            146.729
evaluation/Returns Max            -42.4978
evaluation/Returns Min           -478.652
evaluation/Actions Mean             0.00846114
evaluation/Actions Std              0.158159
evaluation/Actions Max              0.995645
evaluation/Actions Min             -0.999399
evaluation/Num Paths               15
evaluation/Average Returns       -238.048
time/data storing (s)               0.00285934
time/evaluation sampling (s)        0.331909
time/exploration sampling (s)       0.137881
time/logging (s)                    0.00474611
time/saving (s)                     0.00194306
time/training (s)                   1.94833
time/epoch (s)                      2.42767
time/total (s)                    359.476
Epoch                             146
-----------------------------  ---------------
2019-04-23 01:19:32.871502 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 147 finished
-----------------------------  ---------------
replay_buffer/size              74200
trainer/QF1 Loss                  192.79
trainer/QF2 Loss                  193.519
trainer/Policy Loss                95.5915
trainer/Q1 Predictions Mean       -94.1739
trainer/Q1 Predictions Std         70.0419
trainer/Q1 Predictions Max        -17.987
trainer/Q1 Predictions Min       -288.322
trainer/Q2 Predictions Mean       -94.13
trainer/Q2 Predictions Std         69.9787
trainer/Q2 Predictions Max        -18.0028
trainer/Q2 Predictions Min       -288.47
trainer/Q Targets Mean            -93.1785
trainer/Q Targets Std              70.7839
trainer/Q Targets Max              -2.59703
trainer/Q Targets Min            -285.672
trainer/Log Pis Mean                2.10679
trainer/Log Pis Std                 1.18124
trainer/Log Pis Max                 6.08483
trainer/Log Pis Min                -1.98526
trainer/Policy mu Mean             -0.191523
trainer/Policy mu Std               0.80867
trainer/Policy mu Max               3.29808
trainer/Policy mu Min              -3.8611
trainer/Policy log std Mean        -1.95595
trainer/Policy log std Std          0.595183
trainer/Policy log std Max          0.241311
trainer/Policy log std Min         -2.90368
trainer/Alpha                       0.0680053
trainer/Alpha Loss                  0.287065
exploration/num steps total     74200
exploration/num paths total       742
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.92717
exploration/Rewards Std             1.3837
exploration/Rewards Max            -0.00865099
exploration/Rewards Min            -9.53074
exploration/Returns Mean         -192.717
exploration/Returns Std           105.684
exploration/Returns Max           -47.8366
exploration/Returns Min          -306.722
exploration/Actions Mean            0.0182386
exploration/Actions Std             0.211795
exploration/Actions Max             0.99406
exploration/Actions Min            -0.988414
exploration/Num Paths               5
exploration/Average Returns      -192.717
evaluation/num steps total     222000
evaluation/num paths total       2220
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -2.08815
evaluation/Rewards Std              1.78459
evaluation/Rewards Max             -0.0432719
evaluation/Rewards Min             -9.23782
evaluation/Returns Mean          -208.815
evaluation/Returns Std            166.207
evaluation/Returns Max            -18.6446
evaluation/Returns Min           -560.957
evaluation/Actions Mean            -0.0192176
evaluation/Actions Std              0.179822
evaluation/Actions Max              0.989843
evaluation/Actions Min             -0.999087
evaluation/Num Paths               15
evaluation/Average Returns       -208.815
time/data storing (s)               0.00314272
time/evaluation sampling (s)        0.327302
time/exploration sampling (s)       0.138653
time/logging (s)                    0.00483782
time/saving (s)                     0.00194847
time/training (s)                   1.97122
time/epoch (s)                      2.44711
time/total (s)                    361.927
Epoch                             147
-----------------------------  ---------------
2019-04-23 01:19:35.332710 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 148 finished
-----------------------------  ---------------
replay_buffer/size              74700
trainer/QF1 Loss                    2.11997
trainer/QF2 Loss                    2.12827
trainer/Policy Loss               106.678
trainer/Q1 Predictions Mean      -105.535
trainer/Q1 Predictions Std         77.3635
trainer/Q1 Predictions Max        -17.6877
trainer/Q1 Predictions Min       -283.527
trainer/Q2 Predictions Mean      -105.532
trainer/Q2 Predictions Std         77.4049
trainer/Q2 Predictions Max        -17.7759
trainer/Q2 Predictions Min       -283.659
trainer/Q Targets Mean           -106.544
trainer/Q Targets Std              78.0842
trainer/Q Targets Max             -17.5807
trainer/Q Targets Min            -284.396
trainer/Log Pis Mean                1.88271
trainer/Log Pis Std                 1.24808
trainer/Log Pis Max                 4.59922
trainer/Log Pis Min                -2.03502
trainer/Policy mu Mean             -0.257053
trainer/Policy mu Std               0.761882
trainer/Policy mu Max               3.01077
trainer/Policy mu Min              -3.80059
trainer/Policy log std Mean        -1.95485
trainer/Policy log std Std          0.618785
trainer/Policy log std Max         -0.338999
trainer/Policy log std Min         -2.95197
trainer/Alpha                       0.0705884
trainer/Alpha Loss                 -0.310928
exploration/num steps total     74700
exploration/num paths total       747
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.79717
exploration/Rewards Std             1.76121
exploration/Rewards Max            -0.0287732
exploration/Rewards Min            -9.99406
exploration/Returns Mean         -179.717
exploration/Returns Std           157.6
exploration/Returns Max           -31.299
exploration/Returns Min          -480.383
exploration/Actions Mean           -0.0575103
exploration/Actions Std             0.231553
exploration/Actions Max             0.991047
exploration/Actions Min            -0.991138
exploration/Num Paths               5
exploration/Average Returns      -179.717
evaluation/num steps total     223500
evaluation/num paths total       2235
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.68088
evaluation/Rewards Std              1.94744
evaluation/Rewards Max             -0.0635003
evaluation/Rewards Min             -9.05237
evaluation/Returns Mean          -168.088
evaluation/Returns Std            179.607
evaluation/Returns Max             -9.87321
evaluation/Returns Min           -656.944
evaluation/Actions Mean            -0.0257665
evaluation/Actions Std              0.206017
evaluation/Actions Max              0.99896
evaluation/Actions Min             -0.999819
evaluation/Num Paths               15
evaluation/Average Returns       -168.088
time/data storing (s)               0.00302065
time/evaluation sampling (s)        0.331626
time/exploration sampling (s)       0.138699
time/logging (s)                    0.00473699
time/saving (s)                     0.00193557
time/training (s)                   1.97399
time/epoch (s)                      2.45401
time/total (s)                    364.386
Epoch                             148
-----------------------------  ---------------
2019-04-23 01:19:37.777007 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 149 finished
-----------------------------  ---------------
replay_buffer/size              75200
trainer/QF1 Loss                    6.45332
trainer/QF2 Loss                    7.0188
trainer/Policy Loss                99.7266
trainer/Q1 Predictions Mean       -98.4534
trainer/Q1 Predictions Std         74.8661
trainer/Q1 Predictions Max        -16.9916
trainer/Q1 Predictions Min       -274.576
trainer/Q2 Predictions Mean       -98.3929
trainer/Q2 Predictions Std         74.8672
trainer/Q2 Predictions Max        -17.0071
trainer/Q2 Predictions Min       -274.602
trainer/Q Targets Mean           -100.206
trainer/Q Targets Std              76.3651
trainer/Q Targets Max             -17.5377
trainer/Q Targets Min            -280.689
trainer/Log Pis Mean                1.94764
trainer/Log Pis Std                 1.24597
trainer/Log Pis Max                 7.68932
trainer/Log Pis Min                -2.16464
trainer/Policy mu Mean              0.0331316
trainer/Policy mu Std               0.670303
trainer/Policy mu Max               1.53446
trainer/Policy mu Min              -3.85475
trainer/Policy log std Mean        -2.04711
trainer/Policy log std Std          0.519065
trainer/Policy log std Max         -0.384313
trainer/Policy log std Min         -2.86734
trainer/Alpha                       0.0679831
trainer/Alpha Loss                 -0.140777
exploration/num steps total     75200
exploration/num paths total       752
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.711494
exploration/Rewards Std             1.09975
exploration/Rewards Max            -0.0138257
exploration/Rewards Min           -10.8281
exploration/Returns Mean          -71.1494
exploration/Returns Std            45.897
exploration/Returns Max           -33.9788
exploration/Returns Min          -154.145
exploration/Actions Mean            0.00948914
exploration/Actions Std             0.203048
exploration/Actions Max             0.999757
exploration/Actions Min            -0.962486
exploration/Num Paths               5
exploration/Average Returns       -71.1494
evaluation/num steps total     225000
evaluation/num paths total       2250
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.26443
evaluation/Rewards Std              1.19557
evaluation/Rewards Max             -0.0656805
evaluation/Rewards Min            -11.6226
evaluation/Returns Mean          -126.443
evaluation/Returns Std             72.1306
evaluation/Returns Max            -24.6328
evaluation/Returns Min           -308.751
evaluation/Actions Mean             0.00752318
evaluation/Actions Std              0.182635
evaluation/Actions Max              0.999797
evaluation/Actions Min             -0.99648
evaluation/Num Paths               15
evaluation/Average Returns       -126.443
time/data storing (s)               0.00301455
time/evaluation sampling (s)        0.330907
time/exploration sampling (s)       0.137803
time/logging (s)                    0.00484323
time/saving (s)                     0.00192408
time/training (s)                   1.95915
time/epoch (s)                      2.43765
time/total (s)                    366.828
Epoch                             149
-----------------------------  ---------------
2019-04-23 01:19:40.214053 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 150 finished
-----------------------------  ---------------
replay_buffer/size              75700
trainer/QF1 Loss                    3.36662
trainer/QF2 Loss                    3.42442
trainer/Policy Loss               100.073
trainer/Q1 Predictions Mean       -98.5117
trainer/Q1 Predictions Std         72.195
trainer/Q1 Predictions Max        -16.9341
trainer/Q1 Predictions Min       -286.042
trainer/Q2 Predictions Mean       -98.5913
trainer/Q2 Predictions Std         72.2461
trainer/Q2 Predictions Max        -16.9967
trainer/Q2 Predictions Min       -286.744
trainer/Q Targets Mean            -98.6083
trainer/Q Targets Std              72.5986
trainer/Q Targets Max              -0.243031
trainer/Q Targets Min            -286.821
trainer/Log Pis Mean                1.91766
trainer/Log Pis Std                 1.22767
trainer/Log Pis Max                 5.12902
trainer/Log Pis Min                -2.44333
trainer/Policy mu Mean             -0.00818293
trainer/Policy mu Std               0.574402
trainer/Policy mu Max               2.63129
trainer/Policy mu Min              -1.73197
trainer/Policy log std Mean        -2.11407
trainer/Policy log std Std          0.518723
trainer/Policy log std Max         -0.345513
trainer/Policy log std Min         -2.99892
trainer/Alpha                       0.0671511
trainer/Alpha Loss                 -0.222373
exploration/num steps total     75700
exploration/num paths total       757
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.8255
exploration/Rewards Std             1.99115
exploration/Rewards Max            -0.0067527
exploration/Rewards Min           -10.8011
exploration/Returns Mean         -182.55
exploration/Returns Std           189.324
exploration/Returns Max           -18.3595
exploration/Returns Min          -535.33
exploration/Actions Mean           -0.00500353
exploration/Actions Std             0.250322
exploration/Actions Max             0.996558
exploration/Actions Min            -0.986599
exploration/Num Paths               5
exploration/Average Returns      -182.55
evaluation/num steps total     226500
evaluation/num paths total       2265
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -2.20885
evaluation/Rewards Std              1.90907
evaluation/Rewards Max             -0.173728
evaluation/Rewards Min            -10.9053
evaluation/Returns Mean          -220.885
evaluation/Returns Std            169.855
evaluation/Returns Max            -29.743
evaluation/Returns Min           -517.331
evaluation/Actions Mean             0.00146659
evaluation/Actions Std              0.189116
evaluation/Actions Max              0.997795
evaluation/Actions Min             -0.999091
evaluation/Num Paths               15
evaluation/Average Returns       -220.885
time/data storing (s)               0.00279189
time/evaluation sampling (s)        0.331417
time/exploration sampling (s)       0.136653
time/logging (s)                    0.00473558
time/saving (s)                     0.00192792
time/training (s)                   1.95312
time/epoch (s)                      2.43065
time/total (s)                    369.262
Epoch                             150
-----------------------------  ---------------
2019-04-23 01:19:42.760011 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 151 finished
-----------------------------  ---------------
replay_buffer/size              76200
trainer/QF1 Loss                    5.5251
trainer/QF2 Loss                    5.48751
trainer/Policy Loss                94.0122
trainer/Q1 Predictions Mean       -92.5495
trainer/Q1 Predictions Std         74.7543
trainer/Q1 Predictions Max        -17.1396
trainer/Q1 Predictions Min       -280.613
trainer/Q2 Predictions Mean       -92.5912
trainer/Q2 Predictions Std         74.7465
trainer/Q2 Predictions Max        -17.3185
trainer/Q2 Predictions Min       -281.086
trainer/Q Targets Mean            -92.8552
trainer/Q Targets Std              75.6152
trainer/Q Targets Max              -1.32173
trainer/Q Targets Min            -283.902
trainer/Log Pis Mean                1.94863
trainer/Log Pis Std                 1.00959
trainer/Log Pis Max                 3.9497
trainer/Log Pis Min                -1.22921
trainer/Policy mu Mean             -0.0570353
trainer/Policy mu Std               0.602968
trainer/Policy mu Max               2.07949
trainer/Policy mu Min              -2.21621
trainer/Policy log std Mean        -2.02455
trainer/Policy log std Std          0.464223
trainer/Policy log std Max         -0.600653
trainer/Policy log std Min         -2.77673
trainer/Alpha                       0.0680037
trainer/Alpha Loss                 -0.138095
exploration/num steps total     76200
exploration/num paths total       762
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -2.35881
exploration/Rewards Std             2.47641
exploration/Rewards Max            -0.0386988
exploration/Rewards Min           -10.5841
exploration/Returns Mean         -235.881
exploration/Returns Std           227.994
exploration/Returns Max           -51.5972
exploration/Returns Min          -618.608
exploration/Actions Mean            0.0160122
exploration/Actions Std             0.264177
exploration/Actions Max             0.996351
exploration/Actions Min            -0.998686
exploration/Num Paths               5
exploration/Average Returns      -235.881
evaluation/num steps total     228000
evaluation/num paths total       2280
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -2.00875
evaluation/Rewards Std              2.08932
evaluation/Rewards Max             -0.127067
evaluation/Rewards Min            -10.9951
evaluation/Returns Mean          -200.875
evaluation/Returns Std            186.054
evaluation/Returns Max            -14.5188
evaluation/Returns Min           -624.14
evaluation/Actions Mean            -0.0135153
evaluation/Actions Std              0.185592
evaluation/Actions Max              0.998691
evaluation/Actions Min             -0.999621
evaluation/Num Paths               15
evaluation/Average Returns       -200.875
time/data storing (s)               0.00308826
time/evaluation sampling (s)        0.331607
time/exploration sampling (s)       0.139421
time/logging (s)                    0.00482572
time/saving (s)                     0.00994834
time/training (s)                   2.05028
time/epoch (s)                      2.53917
time/total (s)                    371.806
Epoch                             151
-----------------------------  ---------------
2019-04-23 01:19:45.291030 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 152 finished
-----------------------------  ---------------
replay_buffer/size              76700
trainer/QF1 Loss                  881.523
trainer/QF2 Loss                  881.24
trainer/Policy Loss               116.036
trainer/Q1 Predictions Mean      -114.868
trainer/Q1 Predictions Std         80.3704
trainer/Q1 Predictions Max        -16.7229
trainer/Q1 Predictions Min       -282.714
trainer/Q2 Predictions Mean      -114.799
trainer/Q2 Predictions Std         80.3804
trainer/Q2 Predictions Max        -16.7843
trainer/Q2 Predictions Min       -282.894
trainer/Q Targets Mean           -112.153
trainer/Q Targets Std              82.2453
trainer/Q Targets Max              -0.560049
trainer/Q Targets Min            -286.345
trainer/Log Pis Mean                1.8342
trainer/Log Pis Std                 1.24931
trainer/Log Pis Max                 5.10175
trainer/Log Pis Min                -2.70146
trainer/Policy mu Mean             -0.0945632
trainer/Policy mu Std               0.776712
trainer/Policy mu Max               2.47375
trainer/Policy mu Min              -3.9082
trainer/Policy log std Mean        -1.97087
trainer/Policy log std Std          0.623933
trainer/Policy log std Max         -0.130643
trainer/Policy log std Min         -3.02089
trainer/Alpha                       0.067961
trainer/Alpha Loss                 -0.445821
exploration/num steps total     76700
exploration/num paths total       767
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.82582
exploration/Rewards Std             1.80412
exploration/Rewards Max            -0.361653
exploration/Rewards Min            -9.46108
exploration/Returns Mean         -182.582
exploration/Returns Std           155.865
exploration/Returns Max           -74.2223
exploration/Returns Min          -491.818
exploration/Actions Mean            0.0144992
exploration/Actions Std             0.222243
exploration/Actions Max             0.998803
exploration/Actions Min            -0.996897
exploration/Num Paths               5
exploration/Average Returns      -182.582
evaluation/num steps total     229500
evaluation/num paths total       2295
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -2.03971
evaluation/Rewards Std              1.95163
evaluation/Rewards Max             -0.112148
evaluation/Rewards Min             -9.10028
evaluation/Returns Mean          -203.971
evaluation/Returns Std            182.785
evaluation/Returns Max            -21.2076
evaluation/Returns Min           -499.645
evaluation/Actions Mean             0.0022928
evaluation/Actions Std              0.176294
evaluation/Actions Max              0.994932
evaluation/Actions Min             -0.999453
evaluation/Num Paths               15
evaluation/Average Returns       -203.971
time/data storing (s)               0.00306273
time/evaluation sampling (s)        0.3267
time/exploration sampling (s)       0.143131
time/logging (s)                    0.00477497
time/saving (s)                     0.00152683
time/training (s)                   2.0448
time/epoch (s)                      2.52399
time/total (s)                    374.334
Epoch                             152
-----------------------------  ---------------
2019-04-23 01:19:47.763970 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 153 finished
-----------------------------  ----------------
replay_buffer/size              77200
trainer/QF1 Loss                  137.571
trainer/QF2 Loss                  138.892
trainer/Policy Loss                83.12
trainer/Q1 Predictions Mean       -81.7854
trainer/Q1 Predictions Std         63.3407
trainer/Q1 Predictions Max        -16.8223
trainer/Q1 Predictions Min       -275.381
trainer/Q2 Predictions Mean       -81.7807
trainer/Q2 Predictions Std         63.3611
trainer/Q2 Predictions Max        -16.8329
trainer/Q2 Predictions Min       -275.486
trainer/Q Targets Mean            -81.5271
trainer/Q Targets Std              64.2972
trainer/Q Targets Max              -5.15723
trainer/Q Targets Min            -279.515
trainer/Log Pis Mean                1.95179
trainer/Log Pis Std                 1.26811
trainer/Log Pis Max                 5.01675
trainer/Log Pis Min                -2.54306
trainer/Policy mu Mean             -0.247703
trainer/Policy mu Std               0.660902
trainer/Policy mu Max               2.39357
trainer/Policy mu Min              -2.78021
trainer/Policy log std Mean        -2.08877
trainer/Policy log std Std          0.566654
trainer/Policy log std Max         -0.478745
trainer/Policy log std Min         -3.05016
trainer/Alpha                       0.0685454
trainer/Alpha Loss                 -0.129221
exploration/num steps total     77200
exploration/num paths total       772
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -2.64674
exploration/Rewards Std             1.9907
exploration/Rewards Max            -0.0196879
exploration/Rewards Min            -9.96892
exploration/Returns Mean         -264.674
exploration/Returns Std           182.814
exploration/Returns Max           -32.694
exploration/Returns Min          -455.607
exploration/Actions Mean           -0.00682995
exploration/Actions Std             0.214105
exploration/Actions Max             0.99958
exploration/Actions Min            -0.966357
exploration/Num Paths               5
exploration/Average Returns      -264.674
evaluation/num steps total     231000
evaluation/num paths total       2310
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -2.10874
evaluation/Rewards Std              1.70219
evaluation/Rewards Max             -0.0123283
evaluation/Rewards Min             -9.28511
evaluation/Returns Mean          -210.874
evaluation/Returns Std            148.739
evaluation/Returns Max            -26.2164
evaluation/Returns Min           -460.816
evaluation/Actions Mean            -0.000250003
evaluation/Actions Std              0.179408
evaluation/Actions Max              0.994902
evaluation/Actions Min             -0.999828
evaluation/Num Paths               15
evaluation/Average Returns       -210.874
time/data storing (s)               0.00313246
time/evaluation sampling (s)        0.333978
time/exploration sampling (s)       0.137603
time/logging (s)                    0.00480179
time/saving (s)                     0.00194166
time/training (s)                   1.984
time/epoch (s)                      2.46546
time/total (s)                    376.805
Epoch                             153
-----------------------------  ----------------
2019-04-23 01:19:50.265051 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 154 finished
-----------------------------  ---------------
replay_buffer/size              77700
trainer/QF1 Loss                    1.40512
trainer/QF2 Loss                    1.68074
trainer/Policy Loss               100.454
trainer/Q1 Predictions Mean       -99.1242
trainer/Q1 Predictions Std         72.375
trainer/Q1 Predictions Max        -16.8196
trainer/Q1 Predictions Min       -276.794
trainer/Q2 Predictions Mean       -99.0896
trainer/Q2 Predictions Std         72.3309
trainer/Q2 Predictions Max        -17.0634
trainer/Q2 Predictions Min       -277.659
trainer/Q Targets Mean            -99.7081
trainer/Q Targets Std              72.9266
trainer/Q Targets Max             -16.9447
trainer/Q Targets Min            -277.888
trainer/Log Pis Mean                2.03255
trainer/Log Pis Std                 1.64592
trainer/Log Pis Max                11.5549
trainer/Log Pis Min                -2.17395
trainer/Policy mu Mean             -0.342227
trainer/Policy mu Std               0.790658
trainer/Policy mu Max               1.63354
trainer/Policy mu Min              -4.52463
trainer/Policy log std Mean        -1.96269
trainer/Policy log std Std          0.657793
trainer/Policy log std Max          0.36497
trainer/Policy log std Min         -3.00064
trainer/Alpha                       0.068131
trainer/Alpha Loss                  0.0874285
exploration/num steps total     77700
exploration/num paths total       777
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -3.34177
exploration/Rewards Std             2.28296
exploration/Rewards Max            -0.0200134
exploration/Rewards Min           -10.6648
exploration/Returns Mean         -334.177
exploration/Returns Std           209.693
exploration/Returns Max           -74.9345
exploration/Returns Min          -583.95
exploration/Actions Mean           -0.111079
exploration/Actions Std             0.437506
exploration/Actions Max             0.995554
exploration/Actions Min            -0.995191
exploration/Num Paths               5
exploration/Average Returns      -334.177
evaluation/num steps total     232500
evaluation/num paths total       2325
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -2.47565
evaluation/Rewards Std              1.93706
evaluation/Rewards Max             -0.0593138
evaluation/Rewards Min            -10.9446
evaluation/Returns Mean          -247.565
evaluation/Returns Std            179.18
evaluation/Returns Max            -41.4685
evaluation/Returns Min           -597.942
evaluation/Actions Mean            -0.0279274
evaluation/Actions Std              0.217771
evaluation/Actions Max              0.978531
evaluation/Actions Min             -0.999432
evaluation/Num Paths               15
evaluation/Average Returns       -247.565
time/data storing (s)               0.00284326
time/evaluation sampling (s)        0.330828
time/exploration sampling (s)       0.145121
time/logging (s)                    0.0047756
time/saving (s)                     0.0019339
time/training (s)                   2.00835
time/epoch (s)                      2.49386
time/total (s)                    379.303
Epoch                             154
-----------------------------  ---------------
2019-04-23 01:19:52.765039 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 155 finished
-----------------------------  ---------------
replay_buffer/size              78200
trainer/QF1 Loss                    3.60032
trainer/QF2 Loss                    3.39712
trainer/Policy Loss                96.5989
trainer/Q1 Predictions Mean       -95.363
trainer/Q1 Predictions Std         75.9894
trainer/Q1 Predictions Max        -16.3401
trainer/Q1 Predictions Min       -279.648
trainer/Q2 Predictions Mean       -95.3574
trainer/Q2 Predictions Std         75.9425
trainer/Q2 Predictions Max        -16.3405
trainer/Q2 Predictions Min       -277.314
trainer/Q Targets Mean            -96.773
trainer/Q Targets Std              76.6377
trainer/Q Targets Max             -16.6947
trainer/Q Targets Min            -281.112
trainer/Log Pis Mean                2.01174
trainer/Log Pis Std                 1.34765
trainer/Log Pis Max                 6.05069
trainer/Log Pis Min                -2.62101
trainer/Policy mu Mean             -0.25287
trainer/Policy mu Std               0.824408
trainer/Policy mu Max               1.86808
trainer/Policy mu Min              -3.5014
trainer/Policy log std Mean        -1.91648
trainer/Policy log std Std          0.550749
trainer/Policy log std Max         -0.502993
trainer/Policy log std Min         -2.69061
trainer/Alpha                       0.0682448
trainer/Alpha Loss                  0.0315267
exploration/num steps total     78200
exploration/num paths total       782
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -2.90173
exploration/Rewards Std             1.25612
exploration/Rewards Max            -0.540997
exploration/Rewards Min            -7.95552
exploration/Returns Mean         -290.173
exploration/Returns Std           106.974
exploration/Returns Max          -170.75
exploration/Returns Min          -467.964
exploration/Actions Mean           -0.0241413
exploration/Actions Std             0.27502
exploration/Actions Max             0.973463
exploration/Actions Min            -0.994671
exploration/Num Paths               5
exploration/Average Returns      -290.173
evaluation/num steps total     234000
evaluation/num paths total       2340
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -2.26813
evaluation/Rewards Std              1.35875
evaluation/Rewards Max             -0.0312759
evaluation/Rewards Min            -10.6388
evaluation/Returns Mean          -226.813
evaluation/Returns Std            110.534
evaluation/Returns Max            -10.2711
evaluation/Returns Min           -463.218
evaluation/Actions Mean            -0.0138606
evaluation/Actions Std              0.178267
evaluation/Actions Max              0.995886
evaluation/Actions Min             -0.999343
evaluation/Num Paths               15
evaluation/Average Returns       -226.813
time/data storing (s)               0.00289923
time/evaluation sampling (s)        0.330206
time/exploration sampling (s)       0.144155
time/logging (s)                    0.00474996
time/saving (s)                     0.00191365
time/training (s)                   2.00881
time/epoch (s)                      2.49273
time/total (s)                    381.8
Epoch                             155
-----------------------------  ---------------
2019-04-23 01:19:55.272235 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 156 finished
-----------------------------  ----------------
replay_buffer/size              78700
trainer/QF1 Loss                    1.61658
trainer/QF2 Loss                    1.73385
trainer/Policy Loss               100.629
trainer/Q1 Predictions Mean       -98.7648
trainer/Q1 Predictions Std         73.6198
trainer/Q1 Predictions Max        -16.7499
trainer/Q1 Predictions Min       -272.859
trainer/Q2 Predictions Mean       -98.7432
trainer/Q2 Predictions Std         73.6397
trainer/Q2 Predictions Max        -16.8808
trainer/Q2 Predictions Min       -273.033
trainer/Q Targets Mean            -99.4153
trainer/Q Targets Std              74.3196
trainer/Q Targets Max             -16.725
trainer/Q Targets Min            -276.156
trainer/Log Pis Mean                2.15044
trainer/Log Pis Std                 1.14071
trainer/Log Pis Max                 5.90668
trainer/Log Pis Min                -0.706983
trainer/Policy mu Mean             -0.141582
trainer/Policy mu Std               0.685029
trainer/Policy mu Max               2.05197
trainer/Policy mu Min              -3.01912
trainer/Policy log std Mean        -2.05668
trainer/Policy log std Std          0.597946
trainer/Policy log std Max         -0.567108
trainer/Policy log std Min         -2.85879
trainer/Alpha                       0.0666864
trainer/Alpha Loss                  0.407341
exploration/num steps total     78700
exploration/num paths total       787
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.55195
exploration/Rewards Std             2.38178
exploration/Rewards Max            -0.00705912
exploration/Rewards Min            -9.00968
exploration/Returns Mean         -155.195
exploration/Returns Std           211.96
exploration/Returns Max           -41.062
exploration/Returns Min          -578.897
exploration/Actions Mean            0.0237528
exploration/Actions Std             0.288789
exploration/Actions Max             0.99848
exploration/Actions Min            -0.992813
exploration/Num Paths               5
exploration/Average Returns      -155.195
evaluation/num steps total     235500
evaluation/num paths total       2355
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.43446
evaluation/Rewards Std              1.31309
evaluation/Rewards Max             -0.0156487
evaluation/Rewards Min            -10.2699
evaluation/Returns Mean          -143.446
evaluation/Returns Std            100.934
evaluation/Returns Max             -7.88276
evaluation/Returns Min           -325.062
evaluation/Actions Mean             0.000561797
evaluation/Actions Std              0.171718
evaluation/Actions Max              0.999
evaluation/Actions Min             -0.996067
evaluation/Num Paths               15
evaluation/Average Returns       -143.446
time/data storing (s)               0.00308077
time/evaluation sampling (s)        0.330173
time/exploration sampling (s)       0.143195
time/logging (s)                    0.00476198
time/saving (s)                     0.00193782
time/training (s)                   2.01684
time/epoch (s)                      2.49999
time/total (s)                    384.305
Epoch                             156
-----------------------------  ----------------
2019-04-23 01:19:57.758815 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 157 finished
-----------------------------  ---------------
replay_buffer/size              79200
trainer/QF1 Loss                    9.55506
trainer/QF2 Loss                    9.61443
trainer/Policy Loss                98.2831
trainer/Q1 Predictions Mean       -96.9289
trainer/Q1 Predictions Std         82.8128
trainer/Q1 Predictions Max        -16.5349
trainer/Q1 Predictions Min       -276.813
trainer/Q2 Predictions Mean       -96.8673
trainer/Q2 Predictions Std         82.8552
trainer/Q2 Predictions Max        -16.4658
trainer/Q2 Predictions Min       -276.606
trainer/Q Targets Mean            -97.7136
trainer/Q Targets Std              84.2779
trainer/Q Targets Max              -0.219629
trainer/Q Targets Min            -280.371
trainer/Log Pis Mean                1.99195
trainer/Log Pis Std                 1.49007
trainer/Log Pis Max                 7.92684
trainer/Log Pis Min                -2.82274
trainer/Policy mu Mean             -0.0649795
trainer/Policy mu Std               0.844297
trainer/Policy mu Max               2.95703
trainer/Policy mu Min              -3.46438
trainer/Policy log std Mean        -1.94808
trainer/Policy log std Std          0.635619
trainer/Policy log std Max         -0.108961
trainer/Policy log std Min         -2.75709
trainer/Alpha                       0.0669982
trainer/Alpha Loss                 -0.0217512
exploration/num steps total     79200
exploration/num paths total       792
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -2.87428
exploration/Rewards Std             1.82882
exploration/Rewards Max            -0.00300719
exploration/Rewards Min            -6.59949
exploration/Returns Mean         -287.428
exploration/Returns Std           179.549
exploration/Returns Max           -30.2888
exploration/Returns Min          -481.403
exploration/Actions Mean           -0.0129867
exploration/Actions Std             0.208058
exploration/Actions Max             0.802628
exploration/Actions Min            -0.986601
exploration/Num Paths               5
exploration/Average Returns      -287.428
evaluation/num steps total     237000
evaluation/num paths total       2370
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.70987
evaluation/Rewards Std              1.7017
evaluation/Rewards Max             -0.0192533
evaluation/Rewards Min            -10.0515
evaluation/Returns Mean          -170.987
evaluation/Returns Std            153.756
evaluation/Returns Max            -18.2633
evaluation/Returns Min           -486.912
evaluation/Actions Mean            -0.0093663
evaluation/Actions Std              0.166315
evaluation/Actions Max              0.999534
evaluation/Actions Min             -0.999216
evaluation/Num Paths               15
evaluation/Average Returns       -170.987
time/data storing (s)               0.00291909
time/evaluation sampling (s)        0.330086
time/exploration sampling (s)       0.14155
time/logging (s)                    0.0047605
time/saving (s)                     0.00157521
time/training (s)                   1.99845
time/epoch (s)                      2.47934
time/total (s)                    386.788
Epoch                             157
-----------------------------  ---------------
2019-04-23 01:20:00.246763 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 158 finished
-----------------------------  ---------------
replay_buffer/size              79700
trainer/QF1 Loss                  453.608
trainer/QF2 Loss                  454.686
trainer/Policy Loss                82.9181
trainer/Q1 Predictions Mean       -81.4242
trainer/Q1 Predictions Std         66.4377
trainer/Q1 Predictions Max        -15.7126
trainer/Q1 Predictions Min       -276.859
trainer/Q2 Predictions Mean       -81.497
trainer/Q2 Predictions Std         66.5225
trainer/Q2 Predictions Max        -15.7152
trainer/Q2 Predictions Min       -278.992
trainer/Q Targets Mean            -79.7365
trainer/Q Targets Std              65.8163
trainer/Q Targets Max              -4.83318
trainer/Q Targets Min            -281.113
trainer/Log Pis Mean                1.99888
trainer/Log Pis Std                 1.26599
trainer/Log Pis Max                 6.1317
trainer/Log Pis Min                -2.36818
trainer/Policy mu Mean             -0.0881482
trainer/Policy mu Std               0.697164
trainer/Policy mu Max               3.2335
trainer/Policy mu Min              -2.02497
trainer/Policy log std Mean        -2.15143
trainer/Policy log std Std          0.57031
trainer/Policy log std Max         -0.43727
trainer/Policy log std Min         -2.92665
trainer/Alpha                       0.0699679
trainer/Alpha Loss                 -0.00297139
exploration/num steps total     79700
exploration/num paths total       797
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.18742
exploration/Rewards Std             1.60241
exploration/Rewards Max            -0.0180893
exploration/Rewards Min            -8.89591
exploration/Returns Mean         -118.742
exploration/Returns Std           111.793
exploration/Returns Max           -55.2655
exploration/Returns Min          -341.789
exploration/Actions Mean            0.0186026
exploration/Actions Std             0.224864
exploration/Actions Max             0.999493
exploration/Actions Min            -0.996836
exploration/Num Paths               5
exploration/Average Returns      -118.742
evaluation/num steps total     238500
evaluation/num paths total       2385
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -2.67356
evaluation/Rewards Std              2.0973
evaluation/Rewards Max             -0.037006
evaluation/Rewards Min             -9.78848
evaluation/Returns Mean          -267.356
evaluation/Returns Std            196.961
evaluation/Returns Max            -16.7154
evaluation/Returns Min           -511.015
evaluation/Actions Mean             0.0152678
evaluation/Actions Std              0.181813
evaluation/Actions Max              0.997034
evaluation/Actions Min             -0.998449
evaluation/Num Paths               15
evaluation/Average Returns       -267.356
time/data storing (s)               0.00292846
time/evaluation sampling (s)        0.333684
time/exploration sampling (s)       0.139507
time/logging (s)                    0.00484562
time/saving (s)                     0.00190509
time/training (s)                   1.99849
time/epoch (s)                      2.48136
time/total (s)                    389.274
Epoch                             158
-----------------------------  ---------------
2019-04-23 01:20:02.717237 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 159 finished
-----------------------------  ---------------
replay_buffer/size              80200
trainer/QF1 Loss                    1.84617
trainer/QF2 Loss                    1.8492
trainer/Policy Loss                95.2438
trainer/Q1 Predictions Mean       -93.6466
trainer/Q1 Predictions Std         68.4044
trainer/Q1 Predictions Max        -16.6518
trainer/Q1 Predictions Min       -274.994
trainer/Q2 Predictions Mean       -93.6238
trainer/Q2 Predictions Std         68.4748
trainer/Q2 Predictions Max        -16.7038
trainer/Q2 Predictions Min       -275.297
trainer/Q Targets Mean            -94.1236
trainer/Q Targets Std              69.1859
trainer/Q Targets Max             -15.9997
trainer/Q Targets Min            -279.157
trainer/Log Pis Mean                2.07332
trainer/Log Pis Std                 1.35985
trainer/Log Pis Max                 8.18375
trainer/Log Pis Min                -2.58622
trainer/Policy mu Mean             -0.170952
trainer/Policy mu Std               0.670987
trainer/Policy mu Max               3.38427
trainer/Policy mu Min              -3.26891
trainer/Policy log std Mean        -2.06529
trainer/Policy log std Std          0.51479
trainer/Policy log std Max         -0.398378
trainer/Policy log std Min         -2.93671
trainer/Alpha                       0.0705514
trainer/Alpha Loss                  0.194407
exploration/num steps total     80200
exploration/num paths total       802
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.872831
exploration/Rewards Std             1.06398
exploration/Rewards Max            -0.0148527
exploration/Rewards Min            -9.28029
exploration/Returns Mean          -87.2831
exploration/Returns Std            37.3922
exploration/Returns Max           -53.178
exploration/Returns Min          -157.687
exploration/Actions Mean            0.027089
exploration/Actions Std             0.18874
exploration/Actions Max             0.999201
exploration/Actions Min            -0.960822
exploration/Num Paths               5
exploration/Average Returns       -87.2831
evaluation/num steps total     240000
evaluation/num paths total       2400
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -2.18288
evaluation/Rewards Std              1.93507
evaluation/Rewards Max             -0.0876072
evaluation/Rewards Min            -11.5731
evaluation/Returns Mean          -218.288
evaluation/Returns Std            169.342
evaluation/Returns Max            -10.8218
evaluation/Returns Min           -660.977
evaluation/Actions Mean            -0.0242071
evaluation/Actions Std              0.244158
evaluation/Actions Max              0.99661
evaluation/Actions Min             -0.998187
evaluation/Num Paths               15
evaluation/Average Returns       -218.288
time/data storing (s)               0.00308096
time/evaluation sampling (s)        0.334424
time/exploration sampling (s)       0.138607
time/logging (s)                    0.00479666
time/saving (s)                     0.00195995
time/training (s)                   1.98026
time/epoch (s)                      2.46312
time/total (s)                    391.742
Epoch                             159
-----------------------------  ---------------
2019-04-23 01:20:05.204675 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 160 finished
-----------------------------  ---------------
replay_buffer/size              80700
trainer/QF1 Loss                   70.1145
trainer/QF2 Loss                   70.3948
trainer/Policy Loss                98.5363
trainer/Q1 Predictions Mean       -97.0808
trainer/Q1 Predictions Std         79.6485
trainer/Q1 Predictions Max        -15.9074
trainer/Q1 Predictions Min       -276.817
trainer/Q2 Predictions Mean       -97.0965
trainer/Q2 Predictions Std         79.7163
trainer/Q2 Predictions Max        -15.9807
trainer/Q2 Predictions Min       -277.913
trainer/Q Targets Mean            -96.9382
trainer/Q Targets Std              81.0276
trainer/Q Targets Max              -1.86557
trainer/Q Targets Min            -280.493
trainer/Log Pis Mean                1.74378
trainer/Log Pis Std                 1.17953
trainer/Log Pis Max                 3.96178
trainer/Log Pis Min                -3.62347
trainer/Policy mu Mean             -0.0321127
trainer/Policy mu Std               0.59596
trainer/Policy mu Max               2.93005
trainer/Policy mu Min              -2.70729
trainer/Policy log std Mean        -2.00943
trainer/Policy log std Std          0.575353
trainer/Policy log std Max         -0.0423023
trainer/Policy log std Min         -2.94017
trainer/Alpha                       0.0730176
trainer/Alpha Loss                 -0.670477
exploration/num steps total     80700
exploration/num paths total       807
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -2.05013
exploration/Rewards Std             1.97796
exploration/Rewards Max            -0.00617529
exploration/Rewards Min            -8.73803
exploration/Returns Mean         -205.013
exploration/Returns Std           181.607
exploration/Returns Max           -17.7052
exploration/Returns Min          -497.199
exploration/Actions Mean            0.00755438
exploration/Actions Std             0.21616
exploration/Actions Max             0.9812
exploration/Actions Min            -0.999997
exploration/Num Paths               5
exploration/Average Returns      -205.013
evaluation/num steps total     241500
evaluation/num paths total       2415
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -2.29796
evaluation/Rewards Std              1.81706
evaluation/Rewards Max             -0.229001
evaluation/Rewards Min             -9.79885
evaluation/Returns Mean          -229.796
evaluation/Returns Std            169.531
evaluation/Returns Max            -42.9037
evaluation/Returns Min           -525.84
evaluation/Actions Mean            -0.0115443
evaluation/Actions Std              0.165285
evaluation/Actions Max              0.999072
evaluation/Actions Min             -0.995606
evaluation/Num Paths               15
evaluation/Average Returns       -229.796
time/data storing (s)               0.00300498
time/evaluation sampling (s)        0.335806
time/exploration sampling (s)       0.140048
time/logging (s)                    0.00478848
time/saving (s)                     0.00193166
time/training (s)                   1.99475
time/epoch (s)                      2.48032
time/total (s)                    394.227
Epoch                             160
-----------------------------  ---------------
2019-04-23 01:20:07.662797 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 161 finished
-----------------------------  ---------------
replay_buffer/size              81200
trainer/QF1 Loss                   13.4409
trainer/QF2 Loss                   13.4353
trainer/Policy Loss                87.5277
trainer/Q1 Predictions Mean       -85.8474
trainer/Q1 Predictions Std         74.2193
trainer/Q1 Predictions Max        -15.9201
trainer/Q1 Predictions Min       -270.1
trainer/Q2 Predictions Mean       -85.8725
trainer/Q2 Predictions Std         74.1867
trainer/Q2 Predictions Max        -15.957
trainer/Q2 Predictions Min       -270.246
trainer/Q Targets Mean            -86.2061
trainer/Q Targets Std              75.099
trainer/Q Targets Max              -0.205661
trainer/Q Targets Min            -272.378
trainer/Log Pis Mean                2.022
trainer/Log Pis Std                 1.16423
trainer/Log Pis Max                 4.60519
trainer/Log Pis Min                -3.59551
trainer/Policy mu Mean             -0.0836504
trainer/Policy mu Std               0.62966
trainer/Policy mu Max               2.54009
trainer/Policy mu Min              -2.46524
trainer/Policy log std Mean        -2.0802
trainer/Policy log std Std          0.513275
trainer/Policy log std Max         -0.481276
trainer/Policy log std Min         -2.84304
trainer/Alpha                       0.0697832
trainer/Alpha Loss                  0.0585656
exploration/num steps total     81200
exploration/num paths total       812
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.979188
exploration/Rewards Std             1.44357
exploration/Rewards Max            -0.0042614
exploration/Rewards Min           -10.4371
exploration/Returns Mean          -97.9188
exploration/Returns Std            98.8523
exploration/Returns Max           -32.9246
exploration/Returns Min          -291.613
exploration/Actions Mean           -0.0056559
exploration/Actions Std             0.195955
exploration/Actions Max             0.998957
exploration/Actions Min            -0.99928
exploration/Num Paths               5
exploration/Average Returns       -97.9188
evaluation/num steps total     243000
evaluation/num paths total       2430
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.40549
evaluation/Rewards Std              1.79486
evaluation/Rewards Max             -0.0484358
evaluation/Rewards Min            -10.9434
evaluation/Returns Mean          -140.549
evaluation/Returns Std            156.97
evaluation/Returns Max            -15.4686
evaluation/Returns Min           -489.174
evaluation/Actions Mean             0.00581739
evaluation/Actions Std              0.174063
evaluation/Actions Max              0.998608
evaluation/Actions Min             -0.99922
evaluation/Num Paths               15
evaluation/Average Returns       -140.549
time/data storing (s)               0.00302358
time/evaluation sampling (s)        0.333363
time/exploration sampling (s)       0.136207
time/logging (s)                    0.00474027
time/saving (s)                     0.00194038
time/training (s)                   1.97149
time/epoch (s)                      2.45077
time/total (s)                    396.682
Epoch                             161
-----------------------------  ---------------
2019-04-23 01:20:10.098595 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 162 finished
-----------------------------  ---------------
replay_buffer/size              81700
trainer/QF1 Loss                    2.43074
trainer/QF2 Loss                    2.66613
trainer/Policy Loss               100.926
trainer/Q1 Predictions Mean       -99.7196
trainer/Q1 Predictions Std         77.1359
trainer/Q1 Predictions Max        -15.2681
trainer/Q1 Predictions Min       -268.135
trainer/Q2 Predictions Mean       -99.6734
trainer/Q2 Predictions Std         77.0657
trainer/Q2 Predictions Max        -15.3393
trainer/Q2 Predictions Min       -268.502
trainer/Q Targets Mean           -100.781
trainer/Q Targets Std              78.0216
trainer/Q Targets Max             -15.8341
trainer/Q Targets Min            -271.628
trainer/Log Pis Mean                1.90283
trainer/Log Pis Std                 1.25733
trainer/Log Pis Max                 6.00885
trainer/Log Pis Min                -1.77038
trainer/Policy mu Mean             -0.132771
trainer/Policy mu Std               0.727996
trainer/Policy mu Max               2.63021
trainer/Policy mu Min              -3.06739
trainer/Policy log std Mean        -2.00472
trainer/Policy log std Std          0.584812
trainer/Policy log std Max         -0.418466
trainer/Policy log std Min         -2.94071
trainer/Alpha                       0.0693846
trainer/Alpha Loss                 -0.259278
exploration/num steps total     81700
exploration/num paths total       817
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.74726
exploration/Rewards Std             1.15119
exploration/Rewards Max            -0.0179546
exploration/Rewards Min            -7.32993
exploration/Returns Mean         -174.726
exploration/Returns Std           100.742
exploration/Returns Max           -36.0045
exploration/Returns Min          -293.987
exploration/Actions Mean           -0.00676982
exploration/Actions Std             0.16782
exploration/Actions Max             0.921273
exploration/Actions Min            -0.992896
exploration/Num Paths               5
exploration/Average Returns      -174.726
evaluation/num steps total     244500
evaluation/num paths total       2445
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.15731
evaluation/Rewards Std              1.31435
evaluation/Rewards Max             -0.025948
evaluation/Rewards Min             -8.63699
evaluation/Returns Mean          -115.731
evaluation/Returns Std            108.766
evaluation/Returns Max             -6.2925
evaluation/Returns Min           -320.297
evaluation/Actions Mean             0.0134461
evaluation/Actions Std              0.166329
evaluation/Actions Max              0.999262
evaluation/Actions Min             -0.994703
evaluation/Num Paths               15
evaluation/Average Returns       -115.731
time/data storing (s)               0.00288913
time/evaluation sampling (s)        0.328964
time/exploration sampling (s)       0.137477
time/logging (s)                    0.00476901
time/saving (s)                     0.00193391
time/training (s)                   1.95242
time/epoch (s)                      2.42846
time/total (s)                    399.115
Epoch                             162
-----------------------------  ---------------
2019-04-23 01:20:12.538293 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 163 finished
-----------------------------  ---------------
replay_buffer/size              82200
trainer/QF1 Loss                    2.13362
trainer/QF2 Loss                    1.95257
trainer/Policy Loss                90.5632
trainer/Q1 Predictions Mean       -89.1504
trainer/Q1 Predictions Std         68.2548
trainer/Q1 Predictions Max        -15.5663
trainer/Q1 Predictions Min       -277.5
trainer/Q2 Predictions Mean       -89.2182
trainer/Q2 Predictions Std         68.2641
trainer/Q2 Predictions Max        -15.6129
trainer/Q2 Predictions Min       -277.295
trainer/Q Targets Mean            -90.1575
trainer/Q Targets Std              68.9273
trainer/Q Targets Max             -15.8462
trainer/Q Targets Min            -278.46
trainer/Log Pis Mean                1.91623
trainer/Log Pis Std                 1.3201
trainer/Log Pis Max                 7.92291
trainer/Log Pis Min                -1.45507
trainer/Policy mu Mean              0.0535971
trainer/Policy mu Std               0.661119
trainer/Policy mu Max               3.71308
trainer/Policy mu Min              -2.75561
trainer/Policy log std Mean        -2.09635
trainer/Policy log std Std          0.509858
trainer/Policy log std Max         -0.168344
trainer/Policy log std Min         -2.93573
trainer/Alpha                       0.0693502
trainer/Alpha Loss                 -0.223558
exploration/num steps total     82200
exploration/num paths total       822
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.28365
exploration/Rewards Std             1.2636
exploration/Rewards Max            -0.0224719
exploration/Rewards Min            -6.74306
exploration/Returns Mean         -128.365
exploration/Returns Std           116.266
exploration/Returns Max           -26.4435
exploration/Returns Min          -330.349
exploration/Actions Mean            0.00145925
exploration/Actions Std             0.197082
exploration/Actions Max             0.99702
exploration/Actions Min            -0.983071
exploration/Num Paths               5
exploration/Average Returns      -128.365
evaluation/num steps total     246000
evaluation/num paths total       2460
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.4993
evaluation/Rewards Std              1.81207
evaluation/Rewards Max             -0.0415348
evaluation/Rewards Min            -10.7453
evaluation/Returns Mean          -149.93
evaluation/Returns Std            163.154
evaluation/Returns Max             -6.54382
evaluation/Returns Min           -577.361
evaluation/Actions Mean             0.00124651
evaluation/Actions Std              0.16317
evaluation/Actions Max              0.999583
evaluation/Actions Min             -0.997204
evaluation/Num Paths               15
evaluation/Average Returns       -149.93
time/data storing (s)               0.00278627
time/evaluation sampling (s)        0.328857
time/exploration sampling (s)       0.135381
time/logging (s)                    0.00481846
time/saving (s)                     0.0105233
time/training (s)                   1.95002
time/epoch (s)                      2.43239
time/total (s)                    401.552
Epoch                             163
-----------------------------  ---------------
2019-04-23 01:20:14.986494 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 164 finished
-----------------------------  ---------------
replay_buffer/size              82700
trainer/QF1 Loss                   67.5105
trainer/QF2 Loss                   67.9983
trainer/Policy Loss               105.846
trainer/Q1 Predictions Mean      -104.327
trainer/Q1 Predictions Std         76.3909
trainer/Q1 Predictions Max        -15.5433
trainer/Q1 Predictions Min       -275.532
trainer/Q2 Predictions Mean      -104.358
trainer/Q2 Predictions Std         76.371
trainer/Q2 Predictions Max        -15.6335
trainer/Q2 Predictions Min       -276.399
trainer/Q Targets Mean           -104.559
trainer/Q Targets Std              77.6774
trainer/Q Targets Max              -2.24645
trainer/Q Targets Min            -277.238
trainer/Log Pis Mean                2.0832
trainer/Log Pis Std                 1.36243
trainer/Log Pis Max                 7.90003
trainer/Log Pis Min                -3.07678
trainer/Policy mu Mean             -0.128997
trainer/Policy mu Std               0.769923
trainer/Policy mu Max               3.38225
trainer/Policy mu Min              -2.38017
trainer/Policy log std Mean        -2.03501
trainer/Policy log std Std          0.641584
trainer/Policy log std Max         -0.0297885
trainer/Policy log std Min         -2.93165
trainer/Alpha                       0.0705938
trainer/Alpha Loss                  0.220553
exploration/num steps total     82700
exploration/num paths total       827
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -2.72398
exploration/Rewards Std             2.0429
exploration/Rewards Max            -0.297983
exploration/Rewards Min            -9.68138
exploration/Returns Mean         -272.398
exploration/Returns Std           188.171
exploration/Returns Max           -93.7836
exploration/Returns Min          -517.952
exploration/Actions Mean            0.0136978
exploration/Actions Std             0.228196
exploration/Actions Max             0.99935
exploration/Actions Min            -0.959729
exploration/Num Paths               5
exploration/Average Returns      -272.398
evaluation/num steps total     247500
evaluation/num paths total       2475
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.58023
evaluation/Rewards Std              1.47992
evaluation/Rewards Max             -0.18783
evaluation/Rewards Min             -9.37186
evaluation/Returns Mean          -158.023
evaluation/Returns Std            113.511
evaluation/Returns Max            -57.6562
evaluation/Returns Min           -487.806
evaluation/Actions Mean            -0.00583003
evaluation/Actions Std              0.186474
evaluation/Actions Max              0.999417
evaluation/Actions Min             -0.998675
evaluation/Num Paths               15
evaluation/Average Returns       -158.023
time/data storing (s)               0.00291093
time/evaluation sampling (s)        0.32341
time/exploration sampling (s)       0.13495
time/logging (s)                    0.00475605
time/saving (s)                     0.00194379
time/training (s)                   1.97287
time/epoch (s)                      2.44084
time/total (s)                    403.997
Epoch                             164
-----------------------------  ---------------
2019-04-23 01:20:17.444141 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 165 finished
-----------------------------  ---------------
replay_buffer/size              83200
trainer/QF1 Loss                   63.8419
trainer/QF2 Loss                   64.4739
trainer/Policy Loss                95.5014
trainer/Q1 Predictions Mean       -94.4091
trainer/Q1 Predictions Std         78.1045
trainer/Q1 Predictions Max        -15.641
trainer/Q1 Predictions Min       -277.913
trainer/Q2 Predictions Mean       -94.3851
trainer/Q2 Predictions Std         78.0343
trainer/Q2 Predictions Max        -15.7014
trainer/Q2 Predictions Min       -278.051
trainer/Q Targets Mean            -93.7777
trainer/Q Targets Std              79.1618
trainer/Q Targets Max              -1.60027
trainer/Q Targets Min            -278.542
trainer/Log Pis Mean                1.68559
trainer/Log Pis Std                 1.38556
trainer/Log Pis Max                 4.32783
trainer/Log Pis Min                -4.81008
trainer/Policy mu Mean             -0.168782
trainer/Policy mu Std               0.709879
trainer/Policy mu Max               2.16109
trainer/Policy mu Min              -2.68997
trainer/Policy log std Mean        -1.92126
trainer/Policy log std Std          0.62115
trainer/Policy log std Max         -0.0690604
trainer/Policy log std Min         -2.90534
trainer/Alpha                       0.0705296
trainer/Alpha Loss                 -0.833692
exploration/num steps total     83200
exploration/num paths total       832
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.50585
exploration/Rewards Std             1.47162
exploration/Rewards Max            -0.0239999
exploration/Rewards Min           -10.263
exploration/Returns Mean         -150.585
exploration/Returns Std           113.107
exploration/Returns Max           -39.0839
exploration/Returns Min          -291.466
exploration/Actions Mean            0.00821576
exploration/Actions Std             0.200045
exploration/Actions Max             0.990394
exploration/Actions Min            -0.999591
exploration/Num Paths               5
exploration/Average Returns      -150.585
evaluation/num steps total     249000
evaluation/num paths total       2490
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.99829
evaluation/Rewards Std              1.65085
evaluation/Rewards Max             -0.0133736
evaluation/Rewards Min             -8.63678
evaluation/Returns Mean          -199.829
evaluation/Returns Std            149.393
evaluation/Returns Max            -10.0234
evaluation/Returns Min           -475.245
evaluation/Actions Mean             0.0182831
evaluation/Actions Std              0.172897
evaluation/Actions Max              0.995432
evaluation/Actions Min             -0.999069
evaluation/Num Paths               15
evaluation/Average Returns       -199.829
time/data storing (s)               0.00279829
time/evaluation sampling (s)        0.326193
time/exploration sampling (s)       0.134853
time/logging (s)                    0.00475814
time/saving (s)                     0.00194108
time/training (s)                   1.97973
time/epoch (s)                      2.45027
time/total (s)                    406.452
Epoch                             165
-----------------------------  ---------------
2019-04-23 01:20:19.890842 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 166 finished
-----------------------------  ---------------
replay_buffer/size              83700
trainer/QF1 Loss                   14.043
trainer/QF2 Loss                   13.8414
trainer/Policy Loss               110.573
trainer/Q1 Predictions Mean      -108.986
trainer/Q1 Predictions Std         83.7225
trainer/Q1 Predictions Max        -15.2311
trainer/Q1 Predictions Min       -275.605
trainer/Q2 Predictions Mean      -109.044
trainer/Q2 Predictions Std         83.7652
trainer/Q2 Predictions Max        -15.2439
trainer/Q2 Predictions Min       -276.376
trainer/Q Targets Mean           -109.992
trainer/Q Targets Std              85.2606
trainer/Q Targets Max              -1.07169
trainer/Q Targets Min            -278.292
trainer/Log Pis Mean                2.05789
trainer/Log Pis Std                 1.21825
trainer/Log Pis Max                 3.8014
trainer/Log Pis Min                -5.36592
trainer/Policy mu Mean             -0.0700647
trainer/Policy mu Std               0.644762
trainer/Policy mu Max               1.81755
trainer/Policy mu Min              -2.86087
trainer/Policy log std Mean        -2.06397
trainer/Policy log std Std          0.598227
trainer/Policy log std Max         -0.311044
trainer/Policy log std Min         -2.81532
trainer/Alpha                       0.070514
trainer/Alpha Loss                  0.153509
exploration/num steps total     83700
exploration/num paths total       837
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.948662
exploration/Rewards Std             0.939541
exploration/Rewards Max            -0.0398129
exploration/Rewards Min            -9.69779
exploration/Returns Mean          -94.8662
exploration/Returns Std            67.5414
exploration/Returns Max           -28.7642
exploration/Returns Min          -194.56
exploration/Actions Mean            0.0167427
exploration/Actions Std             0.165518
exploration/Actions Max             0.999846
exploration/Actions Min            -0.584631
exploration/Num Paths               5
exploration/Average Returns       -94.8662
evaluation/num steps total     250500
evaluation/num paths total       2505
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.7795
evaluation/Rewards Std              1.74109
evaluation/Rewards Max             -0.173917
evaluation/Rewards Min             -9.22693
evaluation/Returns Mean          -177.95
evaluation/Returns Std            154.569
evaluation/Returns Max            -24.9227
evaluation/Returns Min           -525.746
evaluation/Actions Mean            -0.0126424
evaluation/Actions Std              0.186446
evaluation/Actions Max              0.996856
evaluation/Actions Min             -0.999576
evaluation/Num Paths               15
evaluation/Average Returns       -177.95
time/data storing (s)               0.00297227
time/evaluation sampling (s)        0.319576
time/exploration sampling (s)       0.138234
time/logging (s)                    0.00352643
time/saving (s)                     0.00158074
time/training (s)                   1.97219
time/epoch (s)                      2.43808
time/total (s)                    408.895
Epoch                             166
-----------------------------  ---------------
2019-04-23 01:20:22.349774 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 167 finished
-----------------------------  ---------------
replay_buffer/size              84200
trainer/QF1 Loss                  188.268
trainer/QF2 Loss                  187.287
trainer/Policy Loss               108.249
trainer/Q1 Predictions Mean      -106.789
trainer/Q1 Predictions Std         80.2467
trainer/Q1 Predictions Max        -15.3311
trainer/Q1 Predictions Min       -274.365
trainer/Q2 Predictions Mean      -106.831
trainer/Q2 Predictions Std         80.2885
trainer/Q2 Predictions Max        -15.6303
trainer/Q2 Predictions Min       -275.012
trainer/Q Targets Mean           -105.736
trainer/Q Targets Std              81.1613
trainer/Q Targets Max              -2.68536
trainer/Q Targets Min            -276.578
trainer/Log Pis Mean                2.17583
trainer/Log Pis Std                 1.50942
trainer/Log Pis Max                 8.27766
trainer/Log Pis Min                -4.51372
trainer/Policy mu Mean             -0.0422441
trainer/Policy mu Std               0.898095
trainer/Policy mu Max               3.23998
trainer/Policy mu Min              -3.75381
trainer/Policy log std Mean        -1.95563
trainer/Policy log std Std          0.659235
trainer/Policy log std Max         -0.40148
trainer/Policy log std Min         -2.81846
trainer/Alpha                       0.0719638
trainer/Alpha Loss                  0.462715
exploration/num steps total     84200
exploration/num paths total       842
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.907085
exploration/Rewards Std             1.20353
exploration/Rewards Max            -0.0140626
exploration/Rewards Min            -7.44713
exploration/Returns Mean          -90.7085
exploration/Returns Std            97.1472
exploration/Returns Max           -20.1416
exploration/Returns Min          -282.291
exploration/Actions Mean            0.00759187
exploration/Actions Std             0.185775
exploration/Actions Max             0.999527
exploration/Actions Min            -0.96182
exploration/Num Paths               5
exploration/Average Returns       -90.7085
evaluation/num steps total     252000
evaluation/num paths total       2520
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.86525
evaluation/Rewards Std              1.88402
evaluation/Rewards Max             -0.0813242
evaluation/Rewards Min             -8.29421
evaluation/Returns Mean          -186.525
evaluation/Returns Std            175.127
evaluation/Returns Max            -24.382
evaluation/Returns Min           -510.447
evaluation/Actions Mean             0.0142783
evaluation/Actions Std              0.163743
evaluation/Actions Max              0.999508
evaluation/Actions Min             -0.999187
evaluation/Num Paths               15
evaluation/Average Returns       -186.525
time/data storing (s)               0.00310757
time/evaluation sampling (s)        0.331294
time/exploration sampling (s)       0.13981
time/logging (s)                    0.00472742
time/saving (s)                     0.00192058
time/training (s)                   1.97246
time/epoch (s)                      2.45332
time/total (s)                    411.353
Epoch                             167
-----------------------------  ---------------
2019-04-23 01:20:24.777535 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 168 finished
-----------------------------  ---------------
replay_buffer/size              84700
trainer/QF1 Loss                   52.8648
trainer/QF2 Loss                   53.2332
trainer/Policy Loss                99.8065
trainer/Q1 Predictions Mean       -98.4699
trainer/Q1 Predictions Std         79.694
trainer/Q1 Predictions Max        -14.9161
trainer/Q1 Predictions Min       -272.452
trainer/Q2 Predictions Mean       -98.3831
trainer/Q2 Predictions Std         79.682
trainer/Q2 Predictions Max        -15.0847
trainer/Q2 Predictions Min       -273.388
trainer/Q Targets Mean            -97.618
trainer/Q Targets Std              80.3341
trainer/Q Targets Max              -0.13891
trainer/Q Targets Min            -274.64
trainer/Log Pis Mean                2.14266
trainer/Log Pis Std                 1.15463
trainer/Log Pis Max                 5.20193
trainer/Log Pis Min                -1.66532
trainer/Policy mu Mean             -0.208404
trainer/Policy mu Std               0.706733
trainer/Policy mu Max               2.11273
trainer/Policy mu Min              -2.93215
trainer/Policy log std Mean        -2.00176
trainer/Policy log std Std          0.58742
trainer/Policy log std Max         -0.423335
trainer/Policy log std Min         -3.01556
trainer/Alpha                       0.0752857
trainer/Alpha Loss                  0.36898
exploration/num steps total     84700
exploration/num paths total       847
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.28088
exploration/Rewards Std             1.53011
exploration/Rewards Max            -0.00603882
exploration/Rewards Min            -9.12056
exploration/Returns Mean         -128.088
exploration/Returns Std           126.548
exploration/Returns Max           -34.1985
exploration/Returns Min          -375.73
exploration/Actions Mean           -0.013837
exploration/Actions Std             0.239361
exploration/Actions Max             0.997171
exploration/Actions Min            -0.999028
exploration/Num Paths               5
exploration/Average Returns      -128.088
evaluation/num steps total     253500
evaluation/num paths total       2535
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.08144
evaluation/Rewards Std              1.39401
evaluation/Rewards Max             -0.0852735
evaluation/Rewards Min            -10.2106
evaluation/Returns Mean          -108.144
evaluation/Returns Std            112.377
evaluation/Returns Max            -21.0145
evaluation/Returns Min           -440.998
evaluation/Actions Mean            -0.0048189
evaluation/Actions Std              0.17699
evaluation/Actions Max              0.998411
evaluation/Actions Min             -0.999641
evaluation/Num Paths               15
evaluation/Average Returns       -108.144
time/data storing (s)               0.00324205
time/evaluation sampling (s)        0.326956
time/exploration sampling (s)       0.137711
time/logging (s)                    0.00471385
time/saving (s)                     0.0019202
time/training (s)                   1.94581
time/epoch (s)                      2.42035
time/total (s)                    413.777
Epoch                             168
-----------------------------  ---------------
2019-04-23 01:20:27.213673 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 169 finished
-----------------------------  ----------------
replay_buffer/size              85200
trainer/QF1 Loss                    2.95405
trainer/QF2 Loss                    2.70062
trainer/Policy Loss                94.3852
trainer/Q1 Predictions Mean       -92.8001
trainer/Q1 Predictions Std         77.1832
trainer/Q1 Predictions Max        -14.7672
trainer/Q1 Predictions Min       -273.389
trainer/Q2 Predictions Mean       -92.8461
trainer/Q2 Predictions Std         77.2506
trainer/Q2 Predictions Max        -15.0403
trainer/Q2 Predictions Min       -274.168
trainer/Q Targets Mean            -94.0435
trainer/Q Targets Std              77.9278
trainer/Q Targets Max             -15.3923
trainer/Q Targets Min            -275.034
trainer/Log Pis Mean                2.07519
trainer/Log Pis Std                 1.02327
trainer/Log Pis Max                 4.13696
trainer/Log Pis Min                -2.82047
trainer/Policy mu Mean             -0.0482945
trainer/Policy mu Std               0.665129
trainer/Policy mu Max               2.51501
trainer/Policy mu Min              -2.55083
trainer/Policy log std Mean        -2.10584
trainer/Policy log std Std          0.606605
trainer/Policy log std Max         -0.381743
trainer/Policy log std Min         -2.96312
trainer/Alpha                       0.0756515
trainer/Alpha Loss                  0.194111
exploration/num steps total     85200
exploration/num paths total       852
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.43098
exploration/Rewards Std             2.10334
exploration/Rewards Max            -0.014145
exploration/Rewards Min            -9.42783
exploration/Returns Mean         -143.098
exploration/Returns Std           175.41
exploration/Returns Max           -36.3927
exploration/Returns Min          -492.605
exploration/Actions Mean           -0.000730179
exploration/Actions Std             0.241751
exploration/Actions Max             0.999885
exploration/Actions Min            -0.999994
exploration/Num Paths               5
exploration/Average Returns      -143.098
evaluation/num steps total     255000
evaluation/num paths total       2550
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.34327
evaluation/Rewards Std              1.65604
evaluation/Rewards Max             -0.0354863
evaluation/Rewards Min             -9.78352
evaluation/Returns Mean          -134.327
evaluation/Returns Std            154.643
evaluation/Returns Max            -12.1252
evaluation/Returns Min           -503.947
evaluation/Actions Mean            -0.00657605
evaluation/Actions Std              0.152547
evaluation/Actions Max              0.994743
evaluation/Actions Min             -0.998747
evaluation/Num Paths               15
evaluation/Average Returns       -134.327
time/data storing (s)               0.0029173
time/evaluation sampling (s)        0.330084
time/exploration sampling (s)       0.135656
time/logging (s)                    0.00477213
time/saving (s)                     0.00192534
time/training (s)                   1.95375
time/epoch (s)                      2.4291
time/total (s)                    416.211
Epoch                             169
-----------------------------  ----------------
2019-04-23 01:20:29.653627 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 170 finished
-----------------------------  ---------------
replay_buffer/size              85700
trainer/QF1 Loss                  280.74
trainer/QF2 Loss                  280.232
trainer/Policy Loss                88.9374
trainer/Q1 Predictions Mean       -87.7401
trainer/Q1 Predictions Std         80.691
trainer/Q1 Predictions Max        -14.8051
trainer/Q1 Predictions Min       -272.736
trainer/Q2 Predictions Mean       -87.7761
trainer/Q2 Predictions Std         80.7049
trainer/Q2 Predictions Max        -14.8234
trainer/Q2 Predictions Min       -274.191
trainer/Q Targets Mean            -85.4909
trainer/Q Targets Std              81.8984
trainer/Q Targets Max              -1.7363
trainer/Q Targets Min            -275.155
trainer/Log Pis Mean                1.91122
trainer/Log Pis Std                 1.5391
trainer/Log Pis Max                 5.4763
trainer/Log Pis Min                -6.3742
trainer/Policy mu Mean             -0.19341
trainer/Policy mu Std               0.810483
trainer/Policy mu Max               3.17549
trainer/Policy mu Min              -2.83528
trainer/Policy log std Mean        -1.95042
trainer/Policy log std Std          0.653206
trainer/Policy log std Max         -0.332875
trainer/Policy log std Min         -2.88484
trainer/Alpha                       0.0749202
trainer/Alpha Loss                 -0.23006
exploration/num steps total     85700
exploration/num paths total       857
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.49002
exploration/Rewards Std             0.61245
exploration/Rewards Max            -0.0395846
exploration/Rewards Min            -7.13104
exploration/Returns Mean          -49.002
exploration/Returns Std            17.946
exploration/Returns Max           -27.9955
exploration/Returns Min           -76.6418
exploration/Actions Mean            0.0125317
exploration/Actions Std             0.175823
exploration/Actions Max             0.999434
exploration/Actions Min            -0.980189
exploration/Num Paths               5
exploration/Average Returns       -49.002
evaluation/num steps total     256500
evaluation/num paths total       2565
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.4622
evaluation/Rewards Std              1.85102
evaluation/Rewards Max             -0.211294
evaluation/Rewards Min            -10.8031
evaluation/Returns Mean          -146.22
evaluation/Returns Std            154.644
evaluation/Returns Max            -26.8489
evaluation/Returns Min           -560.789
evaluation/Actions Mean            -0.00274649
evaluation/Actions Std              0.201644
evaluation/Actions Max              0.999067
evaluation/Actions Min             -0.999105
evaluation/Num Paths               15
evaluation/Average Returns       -146.22
time/data storing (s)               0.00307158
time/evaluation sampling (s)        0.331897
time/exploration sampling (s)       0.145865
time/logging (s)                    0.0047405
time/saving (s)                     0.00191913
time/training (s)                   1.94522
time/epoch (s)                      2.43271
time/total (s)                    418.648
Epoch                             170
-----------------------------  ---------------
2019-04-23 01:20:32.098708 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 171 finished
-----------------------------  ---------------
replay_buffer/size              86200
trainer/QF1 Loss                  168.233
trainer/QF2 Loss                  169.558
trainer/Policy Loss                91.4153
trainer/Q1 Predictions Mean       -90.1345
trainer/Q1 Predictions Std         78.4207
trainer/Q1 Predictions Max        -14.8515
trainer/Q1 Predictions Min       -270.69
trainer/Q2 Predictions Mean       -90.0933
trainer/Q2 Predictions Std         78.3368
trainer/Q2 Predictions Max        -14.9821
trainer/Q2 Predictions Min       -271.23
trainer/Q Targets Mean            -90.2646
trainer/Q Targets Std              80.2778
trainer/Q Targets Max              -3.07107
trainer/Q Targets Min            -274.769
trainer/Log Pis Mean                1.87613
trainer/Log Pis Std                 1.27928
trainer/Log Pis Max                 5.86358
trainer/Log Pis Min                -2.00043
trainer/Policy mu Mean             -0.0333758
trainer/Policy mu Std               0.686281
trainer/Policy mu Max               2.71753
trainer/Policy mu Min              -2.63089
trainer/Policy log std Mean        -2.04913
trainer/Policy log std Std          0.5727
trainer/Policy log std Max         -0.478774
trainer/Policy log std Min         -2.9592
trainer/Alpha                       0.0742479
trainer/Alpha Loss                 -0.322111
exploration/num steps total     86200
exploration/num paths total       862
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.938114
exploration/Rewards Std             1.10779
exploration/Rewards Max            -0.0168744
exploration/Rewards Min            -5.93494
exploration/Returns Mean          -93.8114
exploration/Returns Std            97.1781
exploration/Returns Max           -28.1362
exploration/Returns Min          -284.49
exploration/Actions Mean            0.0144628
exploration/Actions Std             0.182315
exploration/Actions Max             0.997817
exploration/Actions Min            -0.991524
exploration/Num Paths               5
exploration/Average Returns       -93.8114
evaluation/num steps total     258000
evaluation/num paths total       2580
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.61808
evaluation/Rewards Std              1.4578
evaluation/Rewards Max             -0.0310247
evaluation/Rewards Min            -10.1395
evaluation/Returns Mean          -161.808
evaluation/Returns Std            124.993
evaluation/Returns Max            -24.3527
evaluation/Returns Min           -467.171
evaluation/Actions Mean             0.0173713
evaluation/Actions Std              0.165082
evaluation/Actions Max              0.999227
evaluation/Actions Min             -0.996803
evaluation/Num Paths               15
evaluation/Average Returns       -161.808
time/data storing (s)               0.00317395
time/evaluation sampling (s)        0.329743
time/exploration sampling (s)       0.138108
time/logging (s)                    0.00474446
time/saving (s)                     0.0019561
time/training (s)                   1.96045
time/epoch (s)                      2.43817
time/total (s)                    421.09
Epoch                             171
-----------------------------  ---------------
2019-04-23 01:20:34.540107 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 172 finished
-----------------------------  ---------------
replay_buffer/size              86700
trainer/QF1 Loss                    7.86119
trainer/QF2 Loss                    7.60327
trainer/Policy Loss                94.1101
trainer/Q1 Predictions Mean       -92.6955
trainer/Q1 Predictions Std         76.7147
trainer/Q1 Predictions Max        -14.5018
trainer/Q1 Predictions Min       -270.377
trainer/Q2 Predictions Mean       -92.7297
trainer/Q2 Predictions Std         76.7327
trainer/Q2 Predictions Max        -14.8071
trainer/Q2 Predictions Min       -271.208
trainer/Q Targets Mean            -93.809
trainer/Q Targets Std              78.3265
trainer/Q Targets Max              -0.193898
trainer/Q Targets Min            -274.614
trainer/Log Pis Mean                1.8695
trainer/Log Pis Std                 1.25246
trainer/Log Pis Max                 5.10997
trainer/Log Pis Min                -1.4365
trainer/Policy mu Mean             -0.121029
trainer/Policy mu Std               0.751548
trainer/Policy mu Max               3.07682
trainer/Policy mu Min              -2.64104
trainer/Policy log std Mean        -1.90945
trainer/Policy log std Std          0.650881
trainer/Policy log std Max         -0.312621
trainer/Policy log std Min         -2.83311
trainer/Alpha                       0.0742858
trainer/Alpha Loss                 -0.339256
exploration/num steps total     86700
exploration/num paths total       867
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.9259
exploration/Rewards Std             2.07254
exploration/Rewards Max            -0.0700679
exploration/Rewards Min           -10.4055
exploration/Returns Mean         -192.59
exploration/Returns Std           176.047
exploration/Returns Max           -41.665
exploration/Returns Min          -527.357
exploration/Actions Mean            0.00719046
exploration/Actions Std             0.266011
exploration/Actions Max             0.999861
exploration/Actions Min            -0.988099
exploration/Num Paths               5
exploration/Average Returns      -192.59
evaluation/num steps total     259500
evaluation/num paths total       2595
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -2.47004
evaluation/Rewards Std              1.65129
evaluation/Rewards Max             -0.0360251
evaluation/Rewards Min             -8.59415
evaluation/Returns Mean          -247.004
evaluation/Returns Std            157.911
evaluation/Returns Max            -11.95
evaluation/Returns Min           -526.531
evaluation/Actions Mean            -0.00118472
evaluation/Actions Std              0.156412
evaluation/Actions Max              0.986858
evaluation/Actions Min             -0.993865
evaluation/Num Paths               15
evaluation/Average Returns       -247.004
time/data storing (s)               0.00287548
time/evaluation sampling (s)        0.329826
time/exploration sampling (s)       0.135639
time/logging (s)                    0.00478661
time/saving (s)                     0.00194986
time/training (s)                   1.95979
time/epoch (s)                      2.43487
time/total (s)                    423.529
Epoch                             172
-----------------------------  ---------------
2019-04-23 01:20:36.991518 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 173 finished
-----------------------------  ---------------
replay_buffer/size              87200
trainer/QF1 Loss                  112.376
trainer/QF2 Loss                  111.842
trainer/Policy Loss                99.5979
trainer/Q1 Predictions Mean       -97.833
trainer/Q1 Predictions Std         77.0514
trainer/Q1 Predictions Max        -15.0762
trainer/Q1 Predictions Min       -269.811
trainer/Q2 Predictions Mean       -97.7957
trainer/Q2 Predictions Std         77.0445
trainer/Q2 Predictions Max        -14.9632
trainer/Q2 Predictions Min       -269.66
trainer/Q Targets Mean            -96.8188
trainer/Q Targets Std              78.379
trainer/Q Targets Max              -0.760197
trainer/Q Targets Min            -270.607
trainer/Log Pis Mean                2.39416
trainer/Log Pis Std                 1.10929
trainer/Log Pis Max                 6.06082
trainer/Log Pis Min                -0.92666
trainer/Policy mu Mean             -0.121672
trainer/Policy mu Std               0.770691
trainer/Policy mu Max               2.61687
trainer/Policy mu Min              -2.90067
trainer/Policy log std Mean        -2.04981
trainer/Policy log std Std          0.559883
trainer/Policy log std Max         -0.560306
trainer/Policy log std Min         -3.04929
trainer/Alpha                       0.0755259
trainer/Alpha Loss                  1.0183
exploration/num steps total     87200
exploration/num paths total       872
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.69744
exploration/Rewards Std             1.39577
exploration/Rewards Max            -0.0929432
exploration/Rewards Min            -9.39072
exploration/Returns Mean         -169.744
exploration/Returns Std           116.813
exploration/Returns Max           -29.1422
exploration/Returns Min          -303.508
exploration/Actions Mean            0.00319443
exploration/Actions Std             0.200263
exploration/Actions Max             0.990365
exploration/Actions Min            -0.998962
exploration/Num Paths               5
exploration/Average Returns      -169.744
evaluation/num steps total     261000
evaluation/num paths total       2610
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -2.06268
evaluation/Rewards Std              1.70011
evaluation/Rewards Max             -0.242583
evaluation/Rewards Min            -10.5223
evaluation/Returns Mean          -206.268
evaluation/Returns Std            153.2
evaluation/Returns Max            -38.4609
evaluation/Returns Min           -511.302
evaluation/Actions Mean             0.0137444
evaluation/Actions Std              0.167133
evaluation/Actions Max              0.997751
evaluation/Actions Min             -0.994192
evaluation/Num Paths               15
evaluation/Average Returns       -206.268
time/data storing (s)               0.00305424
time/evaluation sampling (s)        0.332105
time/exploration sampling (s)       0.139084
time/logging (s)                    0.00404989
time/saving (s)                     0.00193516
time/training (s)                   1.96323
time/epoch (s)                      2.44346
time/total (s)                    425.976
Epoch                             173
-----------------------------  ---------------
2019-04-23 01:20:39.437165 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 174 finished
-----------------------------  ---------------
replay_buffer/size              87700
trainer/QF1 Loss                   64.5209
trainer/QF2 Loss                   64.3895
trainer/Policy Loss                89.1864
trainer/Q1 Predictions Mean       -87.7198
trainer/Q1 Predictions Std         79.5493
trainer/Q1 Predictions Max        -14.6711
trainer/Q1 Predictions Min       -267.822
trainer/Q2 Predictions Mean       -87.7291
trainer/Q2 Predictions Std         79.5812
trainer/Q2 Predictions Max        -14.633
trainer/Q2 Predictions Min       -268.101
trainer/Q Targets Mean            -87.8387
trainer/Q Targets Std              81.0594
trainer/Q Targets Max              -0.464176
trainer/Q Targets Min            -270.374
trainer/Log Pis Mean                2.02315
trainer/Log Pis Std                 1.09458
trainer/Log Pis Max                 4.35858
trainer/Log Pis Min                -1.62947
trainer/Policy mu Mean             -0.0902356
trainer/Policy mu Std               0.664238
trainer/Policy mu Max               2.37324
trainer/Policy mu Min              -2.16313
trainer/Policy log std Mean        -2.01325
trainer/Policy log std Std          0.601804
trainer/Policy log std Max         -0.486262
trainer/Policy log std Min         -2.99806
trainer/Alpha                       0.0757177
trainer/Alpha Loss                  0.059737
exploration/num steps total     87700
exploration/num paths total       877
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.25234
exploration/Rewards Std             1.17048
exploration/Rewards Max            -0.00894779
exploration/Rewards Min            -9.67274
exploration/Returns Mean         -125.234
exploration/Returns Std            81.1416
exploration/Returns Max           -32.7935
exploration/Returns Min          -224.732
exploration/Actions Mean            0.0147263
exploration/Actions Std             0.201316
exploration/Actions Max             0.997901
exploration/Actions Min            -0.97936
exploration/Num Paths               5
exploration/Average Returns      -125.234
evaluation/num steps total     262500
evaluation/num paths total       2625
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.5006
evaluation/Rewards Std              1.25538
evaluation/Rewards Max             -0.158209
evaluation/Rewards Min             -9.71969
evaluation/Returns Mean          -150.06
evaluation/Returns Std             98.5062
evaluation/Returns Max            -29.6123
evaluation/Returns Min           -281.127
evaluation/Actions Mean             0.00949533
evaluation/Actions Std              0.166071
evaluation/Actions Max              0.99934
evaluation/Actions Min             -0.999222
evaluation/Num Paths               15
evaluation/Average Returns       -150.06
time/data storing (s)               0.00298609
time/evaluation sampling (s)        0.327247
time/exploration sampling (s)       0.141086
time/logging (s)                    0.00479927
time/saving (s)                     0.00192609
time/training (s)                   1.96239
time/epoch (s)                      2.44044
time/total (s)                    428.42
Epoch                             174
-----------------------------  ---------------
2019-04-23 01:20:41.880661 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 175 finished
-----------------------------  ---------------
replay_buffer/size              88200
trainer/QF1 Loss                  166.822
trainer/QF2 Loss                  166.14
trainer/Policy Loss                79.7774
trainer/Q1 Predictions Mean       -78.5769
trainer/Q1 Predictions Std         68.1233
trainer/Q1 Predictions Max        -14.8116
trainer/Q1 Predictions Min       -264.764
trainer/Q2 Predictions Mean       -78.6095
trainer/Q2 Predictions Std         68.1942
trainer/Q2 Predictions Max        -14.7958
trainer/Q2 Predictions Min       -265.712
trainer/Q Targets Mean            -77.2174
trainer/Q Targets Std              69.7355
trainer/Q Targets Max              -0.525621
trainer/Q Targets Min            -269.133
trainer/Log Pis Mean                2.14841
trainer/Log Pis Std                 1.35998
trainer/Log Pis Max                 7.22957
trainer/Log Pis Min                -1.53829
trainer/Policy mu Mean             -0.199754
trainer/Policy mu Std               0.842881
trainer/Policy mu Max               3.55242
trainer/Policy mu Min              -3.76188
trainer/Policy log std Mean        -1.9647
trainer/Policy log std Std          0.665129
trainer/Policy log std Max         -0.164025
trainer/Policy log std Min         -2.94985
trainer/Alpha                       0.0735041
trainer/Alpha Loss                  0.387403
exploration/num steps total     88200
exploration/num paths total       882
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.03883
exploration/Rewards Std             1.02049
exploration/Rewards Max            -0.0389487
exploration/Rewards Min            -9.70988
exploration/Returns Mean         -103.883
exploration/Returns Std            64.6506
exploration/Returns Max           -25.147
exploration/Returns Min          -186.647
exploration/Actions Mean            0.0097436
exploration/Actions Std             0.174777
exploration/Actions Max             0.998343
exploration/Actions Min            -0.982219
exploration/Num Paths               5
exploration/Average Returns      -103.883
evaluation/num steps total     264000
evaluation/num paths total       2640
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.47422
evaluation/Rewards Std              1.37275
evaluation/Rewards Max             -0.116976
evaluation/Rewards Min            -10.7659
evaluation/Returns Mean          -147.422
evaluation/Returns Std            112.396
evaluation/Returns Max            -22.006
evaluation/Returns Min           -451.58
evaluation/Actions Mean            -0.00195746
evaluation/Actions Std              0.169812
evaluation/Actions Max              0.993488
evaluation/Actions Min             -0.99903
evaluation/Num Paths               15
evaluation/Average Returns       -147.422
time/data storing (s)               0.00286792
time/evaluation sampling (s)        0.323306
time/exploration sampling (s)       0.137348
time/logging (s)                    0.00489195
time/saving (s)                     0.00205533
time/training (s)                   1.96627
time/epoch (s)                      2.43674
time/total (s)                    430.861
Epoch                             175
-----------------------------  ---------------
2019-04-23 01:20:44.360433 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 176 finished
-----------------------------  ---------------
replay_buffer/size              88700
trainer/QF1 Loss                    2.34806
trainer/QF2 Loss                    2.13635
trainer/Policy Loss                85.1681
trainer/Q1 Predictions Mean       -83.3879
trainer/Q1 Predictions Std         69.9755
trainer/Q1 Predictions Max        -15.0177
trainer/Q1 Predictions Min       -261.871
trainer/Q2 Predictions Mean       -83.477
trainer/Q2 Predictions Std         70.0012
trainer/Q2 Predictions Max        -15.1181
trainer/Q2 Predictions Min       -262.426
trainer/Q Targets Mean            -84.141
trainer/Q Targets Std              70.8794
trainer/Q Targets Max             -14.5853
trainer/Q Targets Min            -267.323
trainer/Log Pis Mean                2.17458
trainer/Log Pis Std                 1.36595
trainer/Log Pis Max                 5.58123
trainer/Log Pis Min                -4.19192
trainer/Policy mu Mean             -0.172312
trainer/Policy mu Std               0.80534
trainer/Policy mu Max               2.23292
trainer/Policy mu Min              -3.2853
trainer/Policy log std Mean        -1.99256
trainer/Policy log std Std          0.651505
trainer/Policy log std Max         -0.43006
trainer/Policy log std Min         -3.07019
trainer/Alpha                       0.0737025
trainer/Alpha Loss                  0.455284
exploration/num steps total     88700
exploration/num paths total       887
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -2.02768
exploration/Rewards Std             2.23249
exploration/Rewards Max            -0.0139952
exploration/Rewards Min            -6.91806
exploration/Returns Mean         -202.768
exploration/Returns Std           218.656
exploration/Returns Max           -16.9292
exploration/Returns Min          -474.442
exploration/Actions Mean            0.00509332
exploration/Actions Std             0.179397
exploration/Actions Max             0.998208
exploration/Actions Min            -0.994108
exploration/Num Paths               5
exploration/Average Returns      -202.768
evaluation/num steps total     265500
evaluation/num paths total       2655
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.37598
evaluation/Rewards Std              1.80043
evaluation/Rewards Max             -0.0481415
evaluation/Rewards Min             -9.24529
evaluation/Returns Mean          -137.598
evaluation/Returns Std            159.308
evaluation/Returns Max             -7.83162
evaluation/Returns Min           -487.02
evaluation/Actions Mean             0.00322267
evaluation/Actions Std              0.17376
evaluation/Actions Max              0.997647
evaluation/Actions Min             -0.999448
evaluation/Num Paths               15
evaluation/Average Returns       -137.598
time/data storing (s)               0.00310337
time/evaluation sampling (s)        0.331007
time/exploration sampling (s)       0.135249
time/logging (s)                    0.00476925
time/saving (s)                     0.0104265
time/training (s)                   1.98722
time/epoch (s)                      2.47177
time/total (s)                    433.338
Epoch                             176
-----------------------------  ---------------
2019-04-23 01:20:46.803326 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 177 finished
-----------------------------  ---------------
replay_buffer/size              89200
trainer/QF1 Loss                  464.39
trainer/QF2 Loss                  463.389
trainer/Policy Loss                93.5536
trainer/Q1 Predictions Mean       -92.3627
trainer/Q1 Predictions Std         78.8476
trainer/Q1 Predictions Max        -14.915
trainer/Q1 Predictions Min       -259.433
trainer/Q2 Predictions Mean       -92.3388
trainer/Q2 Predictions Std         78.8708
trainer/Q2 Predictions Max        -15.1151
trainer/Q2 Predictions Min       -260.24
trainer/Q Targets Mean            -90.0075
trainer/Q Targets Std              80.9243
trainer/Q Targets Max              -2.78809
trainer/Q Targets Min            -266.321
trainer/Log Pis Mean                2.23155
trainer/Log Pis Std                 1.50281
trainer/Log Pis Max                 8.1648
trainer/Log Pis Min                -1.3522
trainer/Policy mu Mean             -0.169864
trainer/Policy mu Std               0.929913
trainer/Policy mu Max               3.97311
trainer/Policy mu Min              -3.04703
trainer/Policy log std Mean        -1.8548
trainer/Policy log std Std          0.635452
trainer/Policy log std Max         -0.215205
trainer/Policy log std Min         -2.76629
trainer/Alpha                       0.0745095
trainer/Alpha Loss                  0.6013
exploration/num steps total     89200
exploration/num paths total       892
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.93164
exploration/Rewards Std             1.89813
exploration/Rewards Max            -0.0123626
exploration/Rewards Min           -10.5942
exploration/Returns Mean         -193.164
exploration/Returns Std           167.061
exploration/Returns Max           -30.0401
exploration/Returns Min          -443.364
exploration/Actions Mean            0.0165323
exploration/Actions Std             0.259029
exploration/Actions Max             0.999373
exploration/Actions Min            -0.987148
exploration/Num Paths               5
exploration/Average Returns      -193.164
evaluation/num steps total     267000
evaluation/num paths total       2670
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.64269
evaluation/Rewards Std              1.4896
evaluation/Rewards Max             -0.20975
evaluation/Rewards Min            -10.057
evaluation/Returns Mean          -164.269
evaluation/Returns Std            136.816
evaluation/Returns Max            -41.169
evaluation/Returns Min           -464.203
evaluation/Actions Mean             0.0125247
evaluation/Actions Std              0.14345
evaluation/Actions Max              0.997901
evaluation/Actions Min             -0.999148
evaluation/Num Paths               15
evaluation/Average Returns       -164.269
time/data storing (s)               0.0027922
time/evaluation sampling (s)        0.32756
time/exploration sampling (s)       0.13635
time/logging (s)                    0.00474784
time/saving (s)                     0.00156374
time/training (s)                   1.96232
time/epoch (s)                      2.43533
time/total (s)                    435.778
Epoch                             177
-----------------------------  ---------------
2019-04-23 01:20:49.235322 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 178 finished
-----------------------------  ---------------
replay_buffer/size              89700
trainer/QF1 Loss                   11.173
trainer/QF2 Loss                   11.1465
trainer/Policy Loss                97.1173
trainer/Q1 Predictions Mean       -95.7833
trainer/Q1 Predictions Std         76.7412
trainer/Q1 Predictions Max        -14.1327
trainer/Q1 Predictions Min       -254.484
trainer/Q2 Predictions Mean       -95.7598
trainer/Q2 Predictions Std         76.7597
trainer/Q2 Predictions Max        -14.1276
trainer/Q2 Predictions Min       -255.054
trainer/Q Targets Mean            -96.8452
trainer/Q Targets Std              78.5194
trainer/Q Targets Max              -0.204941
trainer/Q Targets Min            -262.035
trainer/Log Pis Mean                2.07493
trainer/Log Pis Std                 1.42071
trainer/Log Pis Max                 6.56952
trainer/Log Pis Min                -3.31111
trainer/Policy mu Mean             -0.107852
trainer/Policy mu Std               0.930482
trainer/Policy mu Max               2.65866
trainer/Policy mu Min              -3.61553
trainer/Policy log std Mean        -1.85584
trainer/Policy log std Std          0.639927
trainer/Policy log std Max         -0.436393
trainer/Policy log std Min         -2.74869
trainer/Alpha                       0.0741328
trainer/Alpha Loss                  0.194983
exploration/num steps total     89700
exploration/num paths total       897
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -2.21938
exploration/Rewards Std             1.65158
exploration/Rewards Max            -0.0490604
exploration/Rewards Min            -9.24272
exploration/Returns Mean         -221.938
exploration/Returns Std           150.468
exploration/Returns Max           -41.2513
exploration/Returns Min          -442.875
exploration/Actions Mean           -0.00013152
exploration/Actions Std             0.23032
exploration/Actions Max             0.991888
exploration/Actions Min            -0.998372
exploration/Num Paths               5
exploration/Average Returns      -221.938
evaluation/num steps total     268500
evaluation/num paths total       2685
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.29316
evaluation/Rewards Std              1.26479
evaluation/Rewards Max             -0.0285444
evaluation/Rewards Min             -9.00275
evaluation/Returns Mean          -129.316
evaluation/Returns Std             98.9439
evaluation/Returns Max            -13.7559
evaluation/Returns Min           -314.337
evaluation/Actions Mean            -0.00475505
evaluation/Actions Std              0.181145
evaluation/Actions Max              0.993323
evaluation/Actions Min             -0.998754
evaluation/Num Paths               15
evaluation/Average Returns       -129.316
time/data storing (s)               0.00287732
time/evaluation sampling (s)        0.329646
time/exploration sampling (s)       0.135757
time/logging (s)                    0.00474472
time/saving (s)                     0.0019616
time/training (s)                   1.94949
time/epoch (s)                      2.42448
time/total (s)                    438.207
Epoch                             178
-----------------------------  ---------------
2019-04-23 01:20:51.701600 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 179 finished
-----------------------------  ---------------
replay_buffer/size              90200
trainer/QF1 Loss                  306
trainer/QF2 Loss                  305.266
trainer/Policy Loss                93.2611
trainer/Q1 Predictions Mean       -92.1682
trainer/Q1 Predictions Std         78.2578
trainer/Q1 Predictions Max        -13.5635
trainer/Q1 Predictions Min       -257.335
trainer/Q2 Predictions Mean       -92.1432
trainer/Q2 Predictions Std         78.2621
trainer/Q2 Predictions Max        -13.6577
trainer/Q2 Predictions Min       -257.297
trainer/Q Targets Mean            -91.4641
trainer/Q Targets Std              78.9121
trainer/Q Targets Max              -1.96005
trainer/Q Targets Min            -258.764
trainer/Log Pis Mean                1.97721
trainer/Log Pis Std                 1.01756
trainer/Log Pis Max                 4.19019
trainer/Log Pis Min                -2.18549
trainer/Policy mu Mean             -0.112653
trainer/Policy mu Std               0.772893
trainer/Policy mu Max               2.53546
trainer/Policy mu Min              -2.11305
trainer/Policy log std Mean        -1.88792
trainer/Policy log std Std          0.573638
trainer/Policy log std Max         -0.487284
trainer/Policy log std Min         -2.92746
trainer/Alpha                       0.073855
trainer/Alpha Loss                 -0.0593708
exploration/num steps total     90200
exploration/num paths total       902
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.43678
exploration/Rewards Std             1.36157
exploration/Rewards Max            -0.0216764
exploration/Rewards Min            -9.89861
exploration/Returns Mean         -143.678
exploration/Returns Std            75.0112
exploration/Returns Max           -39.9961
exploration/Returns Min          -262.824
exploration/Actions Mean           -0.0261559
exploration/Actions Std             0.247744
exploration/Actions Max             0.997989
exploration/Actions Min            -0.999732
exploration/Num Paths               5
exploration/Average Returns      -143.678
evaluation/num steps total     270000
evaluation/num paths total       2700
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.8502
evaluation/Rewards Std              1.79131
evaluation/Rewards Max             -0.0824319
evaluation/Rewards Min            -10.7407
evaluation/Returns Mean          -185.02
evaluation/Returns Std            164.75
evaluation/Returns Max            -17.134
evaluation/Returns Min           -475.696
evaluation/Actions Mean             0.0103654
evaluation/Actions Std              0.15607
evaluation/Actions Max              0.991135
evaluation/Actions Min             -0.998258
evaluation/Num Paths               15
evaluation/Average Returns       -185.02
time/data storing (s)               0.00302144
time/evaluation sampling (s)        0.325028
time/exploration sampling (s)       0.140034
time/logging (s)                    0.00462172
time/saving (s)                     0.0019056
time/training (s)                   1.98398
time/epoch (s)                      2.45859
time/total (s)                    440.67
Epoch                             179
-----------------------------  ---------------
2019-04-23 01:20:54.149650 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 180 finished
-----------------------------  ---------------
replay_buffer/size              90700
trainer/QF1 Loss                  244.714
trainer/QF2 Loss                  243.783
trainer/Policy Loss               100.382
trainer/Q1 Predictions Mean       -98.7696
trainer/Q1 Predictions Std         76.2572
trainer/Q1 Predictions Max        -13.6289
trainer/Q1 Predictions Min       -255.472
trainer/Q2 Predictions Mean       -98.6794
trainer/Q2 Predictions Std         76.3079
trainer/Q2 Predictions Max        -13.7212
trainer/Q2 Predictions Min       -257.436
trainer/Q Targets Mean            -98.1989
trainer/Q Targets Std              78.4863
trainer/Q Targets Max              -1.50841
trainer/Q Targets Min            -261.031
trainer/Log Pis Mean                2.16892
trainer/Log Pis Std                 1.23144
trainer/Log Pis Max                 6.01765
trainer/Log Pis Min                -4.48491
trainer/Policy mu Mean             -0.154966
trainer/Policy mu Std               0.666061
trainer/Policy mu Max               2.85378
trainer/Policy mu Min              -3.18302
trainer/Policy log std Mean        -2.07865
trainer/Policy log std Std          0.616014
trainer/Policy log std Max         -0.324694
trainer/Policy log std Min         -3.0022
trainer/Alpha                       0.0733636
trainer/Alpha Loss                  0.44126
exploration/num steps total     90700
exploration/num paths total       907
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.02211
exploration/Rewards Std             1.27516
exploration/Rewards Max            -0.0271345
exploration/Rewards Min            -8.9765
exploration/Returns Mean         -102.211
exploration/Returns Std            62.9804
exploration/Returns Max           -25.1466
exploration/Returns Min          -183.18
exploration/Actions Mean           -0.0182225
exploration/Actions Std             0.24499
exploration/Actions Max             0.998875
exploration/Actions Min            -0.999973
exploration/Num Paths               5
exploration/Average Returns      -102.211
evaluation/num steps total     271500
evaluation/num paths total       2715
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.05751
evaluation/Rewards Std              1.34133
evaluation/Rewards Max             -0.0517223
evaluation/Rewards Min            -10.3953
evaluation/Returns Mean          -105.751
evaluation/Returns Std            111.146
evaluation/Returns Max            -12.8578
evaluation/Returns Min           -433.412
evaluation/Actions Mean             0.00457895
evaluation/Actions Std              0.166995
evaluation/Actions Max              0.996251
evaluation/Actions Min             -0.999609
evaluation/Num Paths               15
evaluation/Average Returns       -105.751
time/data storing (s)               0.00295292
time/evaluation sampling (s)        0.332206
time/exploration sampling (s)       0.141808
time/logging (s)                    0.00476044
time/saving (s)                     0.00195248
time/training (s)                   1.95692
time/epoch (s)                      2.4406
time/total (s)                    443.115
Epoch                             180
-----------------------------  ---------------
2019-04-23 01:20:56.593728 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 181 finished
-----------------------------  ---------------
replay_buffer/size              91200
trainer/QF1 Loss                  617.87
trainer/QF2 Loss                  617.089
trainer/Policy Loss                71.5487
trainer/Q1 Predictions Mean       -70.0362
trainer/Q1 Predictions Std         64.8324
trainer/Q1 Predictions Max        -13.5513
trainer/Q1 Predictions Min       -255.676
trainer/Q2 Predictions Mean       -70.0658
trainer/Q2 Predictions Std         64.7645
trainer/Q2 Predictions Max        -13.5773
trainer/Q2 Predictions Min       -256.267
trainer/Q Targets Mean            -68.328
trainer/Q Targets Std              62.9917
trainer/Q Targets Max              -5.28122
trainer/Q Targets Min            -258.06
trainer/Log Pis Mean                2.08868
trainer/Log Pis Std                 1.07789
trainer/Log Pis Max                 5.15049
trainer/Log Pis Min                -1.38892
trainer/Policy mu Mean             -0.11786
trainer/Policy mu Std               0.721195
trainer/Policy mu Max               2.67483
trainer/Policy mu Min              -2.49883
trainer/Policy log std Mean        -2.03296
trainer/Policy log std Std          0.554373
trainer/Policy log std Max         -0.498541
trainer/Policy log std Min         -2.8667
trainer/Alpha                       0.0746408
trainer/Alpha Loss                  0.230126
exploration/num steps total     91200
exploration/num paths total       912
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -2.16885
exploration/Rewards Std             2.18326
exploration/Rewards Max            -0.0177082
exploration/Rewards Min            -8.83947
exploration/Returns Mean         -216.885
exploration/Returns Std           203.133
exploration/Returns Max           -37.6135
exploration/Returns Min          -480.381
exploration/Actions Mean            0.00742097
exploration/Actions Std             0.206898
exploration/Actions Max             0.999723
exploration/Actions Min            -0.843619
exploration/Num Paths               5
exploration/Average Returns      -216.885
evaluation/num steps total     273000
evaluation/num paths total       2730
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.56443
evaluation/Rewards Std              1.74153
evaluation/Rewards Max             -0.0285762
evaluation/Rewards Min             -9.51627
evaluation/Returns Mean          -156.443
evaluation/Returns Std            146.188
evaluation/Returns Max            -27.828
evaluation/Returns Min           -475.765
evaluation/Actions Mean            -0.0171185
evaluation/Actions Std              0.178046
evaluation/Actions Max              0.998597
evaluation/Actions Min             -0.999075
evaluation/Num Paths               15
evaluation/Average Returns       -156.443
time/data storing (s)               0.00279441
time/evaluation sampling (s)        0.328194
time/exploration sampling (s)       0.138117
time/logging (s)                    0.00456211
time/saving (s)                     0.00193899
time/training (s)                   1.96071
time/epoch (s)                      2.43632
time/total (s)                    445.556
Epoch                             181
-----------------------------  ---------------
2019-04-23 01:20:59.042269 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 182 finished
-----------------------------  ---------------
replay_buffer/size              91700
trainer/QF1 Loss                   70.2298
trainer/QF2 Loss                   69.7347
trainer/Policy Loss                88.7053
trainer/Q1 Predictions Mean       -87.2326
trainer/Q1 Predictions Std         73.4173
trainer/Q1 Predictions Max        -13.509
trainer/Q1 Predictions Min       -250.781
trainer/Q2 Predictions Mean       -87.2534
trainer/Q2 Predictions Std         73.2919
trainer/Q2 Predictions Max        -13.6029
trainer/Q2 Predictions Min       -251.005
trainer/Q Targets Mean            -87.7567
trainer/Q Targets Std              74.9645
trainer/Q Targets Max              -1.10152
trainer/Q Targets Min            -255.063
trainer/Log Pis Mean                1.98977
trainer/Log Pis Std                 1.19576
trainer/Log Pis Max                 5.21155
trainer/Log Pis Min                -2.77746
trainer/Policy mu Mean              0.0142074
trainer/Policy mu Std               0.675841
trainer/Policy mu Max               2.81194
trainer/Policy mu Min              -2.73398
trainer/Policy log std Mean        -2.07954
trainer/Policy log std Std          0.503042
trainer/Policy log std Max         -0.228815
trainer/Policy log std Min         -3.02353
trainer/Alpha                       0.0744279
trainer/Alpha Loss                 -0.026572
exploration/num steps total     91700
exploration/num paths total       917
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.23984
exploration/Rewards Std             0.987375
exploration/Rewards Max            -0.0757599
exploration/Rewards Min            -6.5143
exploration/Returns Mean         -123.984
exploration/Returns Std            73.1344
exploration/Returns Max           -36.5525
exploration/Returns Min          -259.339
exploration/Actions Mean           -0.0304481
exploration/Actions Std             0.186536
exploration/Actions Max             0.838069
exploration/Actions Min            -0.997942
exploration/Num Paths               5
exploration/Average Returns      -123.984
evaluation/num steps total     274500
evaluation/num paths total       2745
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.65747
evaluation/Rewards Std              1.94113
evaluation/Rewards Max             -0.0680107
evaluation/Rewards Min             -9.91682
evaluation/Returns Mean          -165.747
evaluation/Returns Std            176.148
evaluation/Returns Max            -20.5739
evaluation/Returns Min           -498.596
evaluation/Actions Mean             0.0167439
evaluation/Actions Std              0.170728
evaluation/Actions Max              0.999451
evaluation/Actions Min             -0.989891
evaluation/Num Paths               15
evaluation/Average Returns       -165.747
time/data storing (s)               0.00285991
time/evaluation sampling (s)        0.327366
time/exploration sampling (s)       0.145577
time/logging (s)                    0.0036052
time/saving (s)                     0.00155701
time/training (s)                   1.95907
time/epoch (s)                      2.44003
time/total (s)                    448
Epoch                             182
-----------------------------  ---------------
2019-04-23 01:21:01.512809 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 183 finished
-----------------------------  ---------------
replay_buffer/size              92200
trainer/QF1 Loss                  448.165
trainer/QF2 Loss                  451.758
trainer/Policy Loss                88.6254
trainer/Q1 Predictions Mean       -86.878
trainer/Q1 Predictions Std         68.7541
trainer/Q1 Predictions Max        -13.6851
trainer/Q1 Predictions Min       -254.425
trainer/Q2 Predictions Mean       -86.8975
trainer/Q2 Predictions Std         68.8298
trainer/Q2 Predictions Max        -13.7182
trainer/Q2 Predictions Min       -255.013
trainer/Q Targets Mean            -85.5854
trainer/Q Targets Std              68.685
trainer/Q Targets Max              -4.72492
trainer/Q Targets Min            -257.456
trainer/Log Pis Mean                2.32499
trainer/Log Pis Std                 1.49459
trainer/Log Pis Max                 9.88866
trainer/Log Pis Min                -0.484957
trainer/Policy mu Mean             -0.0174244
trainer/Policy mu Std               0.793508
trainer/Policy mu Max               3.7868
trainer/Policy mu Min              -2.67292
trainer/Policy log std Mean        -2.0885
trainer/Policy log std Std          0.605382
trainer/Policy log std Max         -0.244233
trainer/Policy log std Min         -2.90363
trainer/Alpha                       0.0771155
trainer/Alpha Loss                  0.832803
exploration/num steps total     92200
exploration/num paths total       922
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.43374
exploration/Rewards Std             1.8749
exploration/Rewards Max            -0.0267018
exploration/Rewards Min            -8.3352
exploration/Returns Mean         -143.374
exploration/Returns Std           169.728
exploration/Returns Max           -19.9219
exploration/Returns Min          -471.299
exploration/Actions Mean            0.00780502
exploration/Actions Std             0.21369
exploration/Actions Max             0.99997
exploration/Actions Min            -0.995899
exploration/Num Paths               5
exploration/Average Returns      -143.374
evaluation/num steps total     276000
evaluation/num paths total       2760
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.47917
evaluation/Rewards Std              1.35485
evaluation/Rewards Max             -0.0515598
evaluation/Rewards Min            -10.4719
evaluation/Returns Mean          -147.917
evaluation/Returns Std            101.768
evaluation/Returns Max             -8.84704
evaluation/Returns Min           -307.278
evaluation/Actions Mean             0.00523345
evaluation/Actions Std              0.180487
evaluation/Actions Max              0.997988
evaluation/Actions Min             -0.999696
evaluation/Num Paths               15
evaluation/Average Returns       -147.917
time/data storing (s)               0.00310802
time/evaluation sampling (s)        0.333684
time/exploration sampling (s)       0.140625
time/logging (s)                    0.00476694
time/saving (s)                     0.00191131
time/training (s)                   1.98018
time/epoch (s)                      2.46428
time/total (s)                    450.469
Epoch                             183
-----------------------------  ---------------
2019-04-23 01:21:03.966173 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 184 finished
-----------------------------  ---------------
replay_buffer/size              92700
trainer/QF1 Loss                  306.72
trainer/QF2 Loss                  307.795
trainer/Policy Loss                82.4493
trainer/Q1 Predictions Mean       -81.3137
trainer/Q1 Predictions Std         69.9923
trainer/Q1 Predictions Max        -13.7399
trainer/Q1 Predictions Min       -254.194
trainer/Q2 Predictions Mean       -81.3458
trainer/Q2 Predictions Std         69.9255
trainer/Q2 Predictions Max        -13.861
trainer/Q2 Predictions Min       -254.072
trainer/Q Targets Mean            -79.73
trainer/Q Targets Std              71.219
trainer/Q Targets Max              -0.131605
trainer/Q Targets Min            -255.915
trainer/Log Pis Mean                1.78362
trainer/Log Pis Std                 1.15969
trainer/Log Pis Max                 4.85859
trainer/Log Pis Min                -2.36688
trainer/Policy mu Mean              0.0328099
trainer/Policy mu Std               0.802112
trainer/Policy mu Max               2.74234
trainer/Policy mu Min              -2.1554
trainer/Policy log std Mean        -1.89835
trainer/Policy log std Std          0.60959
trainer/Policy log std Max         -0.251594
trainer/Policy log std Min         -2.86624
trainer/Alpha                       0.0789571
trainer/Alpha Loss                 -0.549288
exploration/num steps total     92700
exploration/num paths total       927
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.12432
exploration/Rewards Std             1.47908
exploration/Rewards Max            -0.00766342
exploration/Rewards Min            -9.23113
exploration/Returns Mean         -112.432
exploration/Returns Std            92.666
exploration/Returns Max           -19.1849
exploration/Returns Min          -276.248
exploration/Actions Mean            0.00865539
exploration/Actions Std             0.244185
exploration/Actions Max             0.999858
exploration/Actions Min            -0.999338
exploration/Num Paths               5
exploration/Average Returns      -112.432
evaluation/num steps total     277500
evaluation/num paths total       2775
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.3709
evaluation/Rewards Std              1.80246
evaluation/Rewards Max             -0.0514506
evaluation/Rewards Min             -9.50014
evaluation/Returns Mean          -137.09
evaluation/Returns Std            167.004
evaluation/Returns Max            -13.0249
evaluation/Returns Min           -534.35
evaluation/Actions Mean            -0.00296074
evaluation/Actions Std              0.163454
evaluation/Actions Max              0.995036
evaluation/Actions Min             -0.998253
evaluation/Num Paths               15
evaluation/Average Returns       -137.09
time/data storing (s)               0.00294291
time/evaluation sampling (s)        0.330945
time/exploration sampling (s)       0.13551
time/logging (s)                    0.00475317
time/saving (s)                     0.00192053
time/training (s)                   1.96951
time/epoch (s)                      2.44558
time/total (s)                    452.919
Epoch                             184
-----------------------------  ---------------
2019-04-23 01:21:06.440871 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 185 finished
-----------------------------  ---------------
replay_buffer/size              93200
trainer/QF1 Loss                    4.79805
trainer/QF2 Loss                    4.30825
trainer/Policy Loss                87.288
trainer/Q1 Predictions Mean       -85.9387
trainer/Q1 Predictions Std         73.57
trainer/Q1 Predictions Max        -13.3665
trainer/Q1 Predictions Min       -255.379
trainer/Q2 Predictions Mean       -85.9422
trainer/Q2 Predictions Std         73.6425
trainer/Q2 Predictions Max        -13.1186
trainer/Q2 Predictions Min       -255.719
trainer/Q Targets Mean            -87.4042
trainer/Q Targets Std              74.6025
trainer/Q Targets Max             -13.5454
trainer/Q Targets Min            -256.494
trainer/Log Pis Mean                1.87149
trainer/Log Pis Std                 1.2777
trainer/Log Pis Max                 6.28798
trainer/Log Pis Min                -3.93586
trainer/Policy mu Mean             -0.0356027
trainer/Policy mu Std               0.659173
trainer/Policy mu Max               2.271
trainer/Policy mu Min              -2.67056
trainer/Policy log std Mean        -2.01573
trainer/Policy log std Std          0.54164
trainer/Policy log std Max         -0.469152
trainer/Policy log std Min         -2.96266
trainer/Alpha                       0.0754648
trainer/Alpha Loss                 -0.332062
exploration/num steps total     93200
exploration/num paths total       932
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.5343
exploration/Rewards Std             1.374
exploration/Rewards Max            -0.0233308
exploration/Rewards Min            -9.79597
exploration/Returns Mean         -153.43
exploration/Returns Std           112.896
exploration/Returns Max           -43.9415
exploration/Returns Min          -291.697
exploration/Actions Mean            0.011846
exploration/Actions Std             0.191328
exploration/Actions Max             0.998911
exploration/Actions Min            -0.990041
exploration/Num Paths               5
exploration/Average Returns      -153.43
evaluation/num steps total     279000
evaluation/num paths total       2790
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.98244
evaluation/Rewards Std              2.19145
evaluation/Rewards Max             -0.0571087
evaluation/Rewards Min            -10.1268
evaluation/Returns Mean          -198.244
evaluation/Returns Std            207.673
evaluation/Returns Max            -16.7743
evaluation/Returns Min           -503.89
evaluation/Actions Mean            -0.00334766
evaluation/Actions Std              0.165781
evaluation/Actions Max              0.997782
evaluation/Actions Min             -0.999107
evaluation/Num Paths               15
evaluation/Average Returns       -198.244
time/data storing (s)               0.00300465
time/evaluation sampling (s)        0.336865
time/exploration sampling (s)       0.141007
time/logging (s)                    0.00475252
time/saving (s)                     0.00191518
time/training (s)                   1.97948
time/epoch (s)                      2.46702
time/total (s)                    455.391
Epoch                             185
-----------------------------  ---------------
2019-04-23 01:21:08.895438 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 186 finished
-----------------------------  ---------------
replay_buffer/size              93700
trainer/QF1 Loss                    2.69461
trainer/QF2 Loss                    2.4309
trainer/Policy Loss                91.0526
trainer/Q1 Predictions Mean       -89.3425
trainer/Q1 Predictions Std         70.4129
trainer/Q1 Predictions Max        -13.7275
trainer/Q1 Predictions Min       -250.427
trainer/Q2 Predictions Mean       -89.3861
trainer/Q2 Predictions Std         70.5123
trainer/Q2 Predictions Max        -13.9032
trainer/Q2 Predictions Min       -251.243
trainer/Q Targets Mean            -90.2339
trainer/Q Targets Std              71.2654
trainer/Q Targets Max             -13.6876
trainer/Q Targets Min            -255.898
trainer/Log Pis Mean                2.22499
trainer/Log Pis Std                 1.16069
trainer/Log Pis Max                 7.3886
trainer/Log Pis Min                -0.381778
trainer/Policy mu Mean             -0.0833365
trainer/Policy mu Std               0.809751
trainer/Policy mu Max               3.43669
trainer/Policy mu Min              -2.28581
trainer/Policy log std Mean        -2.02044
trainer/Policy log std Std          0.595105
trainer/Policy log std Max         -0.301213
trainer/Policy log std Min         -3.00902
trainer/Alpha                       0.0749929
trainer/Alpha Loss                  0.582818
exploration/num steps total     93700
exploration/num paths total       937
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.56093
exploration/Rewards Std             1.30819
exploration/Rewards Max            -0.0230083
exploration/Rewards Min            -9.40079
exploration/Returns Mean         -156.093
exploration/Returns Std            93.6643
exploration/Returns Max           -49.4668
exploration/Returns Min          -270.06
exploration/Actions Mean            0.0352463
exploration/Actions Std             0.200823
exploration/Actions Max             0.998848
exploration/Actions Min            -0.655912
exploration/Num Paths               5
exploration/Average Returns      -156.093
evaluation/num steps total     280500
evaluation/num paths total       2805
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.36559
evaluation/Rewards Std              1.78777
evaluation/Rewards Max             -0.0195877
evaluation/Rewards Min            -11.7915
evaluation/Returns Mean          -136.559
evaluation/Returns Std            154.692
evaluation/Returns Max            -18.9459
evaluation/Returns Min           -492.063
evaluation/Actions Mean             0.00145803
evaluation/Actions Std              0.18283
evaluation/Actions Max              0.999108
evaluation/Actions Min             -0.999583
evaluation/Num Paths               15
evaluation/Average Returns       -136.559
time/data storing (s)               0.00301806
time/evaluation sampling (s)        0.327295
time/exploration sampling (s)       0.138214
time/logging (s)                    0.00464588
time/saving (s)                     0.00152963
time/training (s)                   1.97216
time/epoch (s)                      2.44687
time/total (s)                    457.842
Epoch                             186
-----------------------------  ---------------
2019-04-23 01:21:11.349272 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 187 finished
-----------------------------  ---------------
replay_buffer/size              94200
trainer/QF1 Loss                    5.92685
trainer/QF2 Loss                    5.69969
trainer/Policy Loss                77.0418
trainer/Q1 Predictions Mean       -75.8132
trainer/Q1 Predictions Std         74.8454
trainer/Q1 Predictions Max        -13.168
trainer/Q1 Predictions Min       -250.362
trainer/Q2 Predictions Mean       -75.7859
trainer/Q2 Predictions Std         74.8219
trainer/Q2 Predictions Max        -13.2562
trainer/Q2 Predictions Min       -250.588
trainer/Q Targets Mean            -76.0684
trainer/Q Targets Std              75.7263
trainer/Q Targets Max              -0.691886
trainer/Q Targets Min            -251.731
trainer/Log Pis Mean                1.67815
trainer/Log Pis Std                 1.09298
trainer/Log Pis Max                 4.23829
trainer/Log Pis Min                -2.04797
trainer/Policy mu Mean             -0.0965881
trainer/Policy mu Std               0.628234
trainer/Policy mu Max               2.56959
trainer/Policy mu Min              -2.0615
trainer/Policy log std Mean        -2.02519
trainer/Policy log std Std          0.500809
trainer/Policy log std Max         -0.547831
trainer/Policy log std Min         -2.85781
trainer/Alpha                       0.074397
trainer/Alpha Loss                 -0.836264
exploration/num steps total     94200
exploration/num paths total       942
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.81294
exploration/Rewards Std             2.03518
exploration/Rewards Max            -0.0145043
exploration/Rewards Min            -9.43737
exploration/Returns Mean         -181.294
exploration/Returns Std           177.078
exploration/Returns Max           -35.4827
exploration/Returns Min          -484.486
exploration/Actions Mean            0.00808696
exploration/Actions Std             0.235075
exploration/Actions Max             0.994661
exploration/Actions Min            -0.999497
exploration/Num Paths               5
exploration/Average Returns      -181.294
evaluation/num steps total     282000
evaluation/num paths total       2820
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.81067
evaluation/Rewards Std              1.66642
evaluation/Rewards Max             -0.0577459
evaluation/Rewards Min            -10.5167
evaluation/Returns Mean          -181.067
evaluation/Returns Std            151.816
evaluation/Returns Max            -20.1078
evaluation/Returns Min           -486.389
evaluation/Actions Mean            -0.00150325
evaluation/Actions Std              0.174233
evaluation/Actions Max              0.99246
evaluation/Actions Min             -0.998062
evaluation/Num Paths               15
evaluation/Average Returns       -181.067
time/data storing (s)               0.00283941
time/evaluation sampling (s)        0.322823
time/exploration sampling (s)       0.138118
time/logging (s)                    0.00480491
time/saving (s)                     0.00194979
time/training (s)                   1.97689
time/epoch (s)                      2.44743
time/total (s)                    460.293
Epoch                             187
-----------------------------  ---------------
2019-04-23 01:21:13.839322 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 188 finished
-----------------------------  ---------------
replay_buffer/size              94700
trainer/QF1 Loss                  186.902
trainer/QF2 Loss                  186.524
trainer/Policy Loss                79.1665
trainer/Q1 Predictions Mean       -77.7142
trainer/Q1 Predictions Std         68.441
trainer/Q1 Predictions Max        -13.2993
trainer/Q1 Predictions Min       -246.39
trainer/Q2 Predictions Mean       -77.7685
trainer/Q2 Predictions Std         68.4865
trainer/Q2 Predictions Max        -13.2562
trainer/Q2 Predictions Min       -247.299
trainer/Q Targets Mean            -77.3641
trainer/Q Targets Std              70.4775
trainer/Q Targets Max              -0.293611
trainer/Q Targets Min            -251.933
trainer/Log Pis Mean                1.96834
trainer/Log Pis Std                 1.11348
trainer/Log Pis Max                 5.28947
trainer/Log Pis Min                -1.71603
trainer/Policy mu Mean             -0.0800538
trainer/Policy mu Std               0.695352
trainer/Policy mu Max               3.15508
trainer/Policy mu Min              -2.19748
trainer/Policy log std Mean        -2.04913
trainer/Policy log std Std          0.54462
trainer/Policy log std Max         -0.466642
trainer/Policy log std Min         -2.88824
trainer/Alpha                       0.0739474
trainer/Alpha Loss                 -0.0824455
exploration/num steps total     94700
exploration/num paths total       947
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.51585
exploration/Rewards Std             1.50249
exploration/Rewards Max            -0.0325417
exploration/Rewards Min           -10.0396
exploration/Returns Mean         -151.585
exploration/Returns Std            66.2649
exploration/Returns Max           -76.5482
exploration/Returns Min          -255.966
exploration/Actions Mean            0.0124567
exploration/Actions Std             0.233252
exploration/Actions Max             0.999639
exploration/Actions Min            -0.999993
exploration/Num Paths               5
exploration/Average Returns      -151.585
evaluation/num steps total     283500
evaluation/num paths total       2835
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.3546
evaluation/Rewards Std              1.38708
evaluation/Rewards Max             -0.147583
evaluation/Rewards Min             -9.50953
evaluation/Returns Mean          -135.46
evaluation/Returns Std            115.119
evaluation/Returns Max            -18.8808
evaluation/Returns Min           -471.632
evaluation/Actions Mean             0.00461003
evaluation/Actions Std              0.170977
evaluation/Actions Max              0.999382
evaluation/Actions Min             -0.999647
evaluation/Num Paths               15
evaluation/Average Returns       -135.46
time/data storing (s)               0.00371111
time/evaluation sampling (s)        0.327566
time/exploration sampling (s)       0.140316
time/logging (s)                    0.0047983
time/saving (s)                     0.0107108
time/training (s)                   1.99557
time/epoch (s)                      2.48267
time/total (s)                    462.78
Epoch                             188
-----------------------------  ---------------
2019-04-23 01:21:16.296880 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 189 finished
-----------------------------  ---------------
replay_buffer/size              95200
trainer/QF1 Loss                    6.93914
trainer/QF2 Loss                    6.87203
trainer/Policy Loss                83.7726
trainer/Q1 Predictions Mean       -82.538
trainer/Q1 Predictions Std         70.1635
trainer/Q1 Predictions Max        -12.7638
trainer/Q1 Predictions Min       -245.854
trainer/Q2 Predictions Mean       -82.5248
trainer/Q2 Predictions Std         70.187
trainer/Q2 Predictions Max        -12.6871
trainer/Q2 Predictions Min       -246.301
trainer/Q Targets Mean            -83.9101
trainer/Q Targets Std              71.5254
trainer/Q Targets Max              -0.302702
trainer/Q Targets Min            -249.556
trainer/Log Pis Mean                1.88676
trainer/Log Pis Std                 1.15635
trainer/Log Pis Max                 5.79172
trainer/Log Pis Min                -2.29075
trainer/Policy mu Mean             -0.133801
trainer/Policy mu Std               0.668071
trainer/Policy mu Max               2.93564
trainer/Policy mu Min              -2.37478
trainer/Policy log std Mean        -2.04735
trainer/Policy log std Std          0.549706
trainer/Policy log std Max         -0.308013
trainer/Policy log std Min         -2.86815
trainer/Alpha                       0.0745943
trainer/Alpha Loss                 -0.293934
exploration/num steps total     95200
exploration/num paths total       952
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.74242
exploration/Rewards Std             1.22619
exploration/Rewards Max            -0.17566
exploration/Rewards Min            -9.58336
exploration/Returns Mean         -174.242
exploration/Returns Std            72.6509
exploration/Returns Max           -74.5293
exploration/Returns Min          -267.746
exploration/Actions Mean           -0.0111898
exploration/Actions Std             0.229577
exploration/Actions Max             0.993642
exploration/Actions Min            -0.999822
exploration/Num Paths               5
exploration/Average Returns      -174.242
evaluation/num steps total     285000
evaluation/num paths total       2850
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.65272
evaluation/Rewards Std              1.74846
evaluation/Rewards Max             -0.0265183
evaluation/Rewards Min            -10.8515
evaluation/Returns Mean          -165.272
evaluation/Returns Std            145.281
evaluation/Returns Max            -19.5252
evaluation/Returns Min           -447.104
evaluation/Actions Mean             0.012652
evaluation/Actions Std              0.186806
evaluation/Actions Max              0.999644
evaluation/Actions Min             -0.999512
evaluation/Num Paths               15
evaluation/Average Returns       -165.272
time/data storing (s)               0.00431947
time/evaluation sampling (s)        0.322628
time/exploration sampling (s)       0.141276
time/logging (s)                    0.00473058
time/saving (s)                     0.00194294
time/training (s)                   1.97655
time/epoch (s)                      2.45145
time/total (s)                    465.235
Epoch                             189
-----------------------------  ---------------
2019-04-23 01:21:18.724995 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 190 finished
-----------------------------  ---------------
replay_buffer/size              95700
trainer/QF1 Loss                  468.594
trainer/QF2 Loss                  466.439
trainer/Policy Loss                89.0883
trainer/Q1 Predictions Mean       -87.7366
trainer/Q1 Predictions Std         79.1736
trainer/Q1 Predictions Max        -12.9863
trainer/Q1 Predictions Min       -253.437
trainer/Q2 Predictions Mean       -87.719
trainer/Q2 Predictions Std         79.0904
trainer/Q2 Predictions Max        -12.894
trainer/Q2 Predictions Min       -253.479
trainer/Q Targets Mean            -85.8461
trainer/Q Targets Std              78.515
trainer/Q Targets Max              -4.62772
trainer/Q Targets Min            -252.521
trainer/Log Pis Mean                1.86411
trainer/Log Pis Std                 1.27608
trainer/Log Pis Max                 5.4089
trainer/Log Pis Min                -3.18389
trainer/Policy mu Mean             -0.115639
trainer/Policy mu Std               0.670105
trainer/Policy mu Max               2.33434
trainer/Policy mu Min              -2.43855
trainer/Policy log std Mean        -1.98084
trainer/Policy log std Std          0.536193
trainer/Policy log std Max         -0.3502
trainer/Policy log std Min         -2.81568
trainer/Alpha                       0.0746582
trainer/Alpha Loss                 -0.352618
exploration/num steps total     95700
exploration/num paths total       957
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.63033
exploration/Rewards Std             1.37683
exploration/Rewards Max            -0.134416
exploration/Rewards Min            -9.2596
exploration/Returns Mean         -163.033
exploration/Returns Std           103.34
exploration/Returns Max           -61.0856
exploration/Returns Min          -318.392
exploration/Actions Mean           -0.0100746
exploration/Actions Std             0.226081
exploration/Actions Max             0.9961
exploration/Actions Min            -0.999986
exploration/Num Paths               5
exploration/Average Returns      -163.033
evaluation/num steps total     286500
evaluation/num paths total       2865
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.40911
evaluation/Rewards Std              1.59398
evaluation/Rewards Max             -0.104987
evaluation/Rewards Min            -10.0703
evaluation/Returns Mean          -140.911
evaluation/Returns Std            133.635
evaluation/Returns Max            -19.0617
evaluation/Returns Min           -474.738
evaluation/Actions Mean             0.00142963
evaluation/Actions Std              0.186936
evaluation/Actions Max              0.999621
evaluation/Actions Min             -0.999888
evaluation/Num Paths               15
evaluation/Average Returns       -140.911
time/data storing (s)               0.0029463
time/evaluation sampling (s)        0.329789
time/exploration sampling (s)       0.134904
time/logging (s)                    0.00476591
time/saving (s)                     0.00194957
time/training (s)                   1.94616
time/epoch (s)                      2.42051
time/total (s)                    467.66
Epoch                             190
-----------------------------  ---------------
2019-04-23 01:21:21.194446 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 191 finished
-----------------------------  ----------------
replay_buffer/size              96200
trainer/QF1 Loss                    0.720101
trainer/QF2 Loss                    0.851022
trainer/Policy Loss                82.2651
trainer/Q1 Predictions Mean       -81.0139
trainer/Q1 Predictions Std         75.02
trainer/Q1 Predictions Max        -12.8801
trainer/Q1 Predictions Min       -248.504
trainer/Q2 Predictions Mean       -80.9761
trainer/Q2 Predictions Std         75.0068
trainer/Q2 Predictions Max        -12.8262
trainer/Q2 Predictions Min       -249.357
trainer/Q Targets Mean            -81.5144
trainer/Q Targets Std              75.4624
trainer/Q Targets Max             -13.4086
trainer/Q Targets Min            -249.988
trainer/Log Pis Mean                2.03061
trainer/Log Pis Std                 1.2196
trainer/Log Pis Max                 7.28975
trainer/Log Pis Min                -2.29915
trainer/Policy mu Mean             -0.080145
trainer/Policy mu Std               0.734486
trainer/Policy mu Max               3.29199
trainer/Policy mu Min              -2.60395
trainer/Policy log std Mean        -1.99743
trainer/Policy log std Std          0.542424
trainer/Policy log std Max         -0.361351
trainer/Policy log std Min         -2.98235
trainer/Alpha                       0.0743527
trainer/Alpha Loss                  0.0795568
exploration/num steps total     96200
exploration/num paths total       962
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.36627
exploration/Rewards Std             1.0267
exploration/Rewards Max            -0.0560238
exploration/Rewards Min            -9.46693
exploration/Returns Mean         -136.627
exploration/Returns Std            80.2814
exploration/Returns Max           -33.2931
exploration/Returns Min          -275.034
exploration/Actions Mean            0.000288895
exploration/Actions Std             0.18685
exploration/Actions Max             0.997157
exploration/Actions Min            -0.997856
exploration/Num Paths               5
exploration/Average Returns      -136.627
evaluation/num steps total     288000
evaluation/num paths total       2880
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.78363
evaluation/Rewards Std              1.82285
evaluation/Rewards Max             -0.0659869
evaluation/Rewards Min             -9.05098
evaluation/Returns Mean          -178.363
evaluation/Returns Std            168.91
evaluation/Returns Max            -32.9621
evaluation/Returns Min           -509.045
evaluation/Actions Mean             0.00069245
evaluation/Actions Std              0.164965
evaluation/Actions Max              0.995882
evaluation/Actions Min             -0.998041
evaluation/Num Paths               15
evaluation/Average Returns       -178.363
time/data storing (s)               0.00301514
time/evaluation sampling (s)        0.328196
time/exploration sampling (s)       0.142727
time/logging (s)                    0.00476463
time/saving (s)                     0.0019538
time/training (s)                   1.98106
time/epoch (s)                      2.46172
time/total (s)                    470.126
Epoch                             191
-----------------------------  ----------------
2019-04-23 01:21:23.618106 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 192 finished
-----------------------------  ---------------
replay_buffer/size              96700
trainer/QF1 Loss                   62.6957
trainer/QF2 Loss                   62.8934
trainer/Policy Loss                82.2574
trainer/Q1 Predictions Mean       -80.4331
trainer/Q1 Predictions Std         64.2141
trainer/Q1 Predictions Max        -12.9674
trainer/Q1 Predictions Min       -219.956
trainer/Q2 Predictions Mean       -80.3895
trainer/Q2 Predictions Std         64.2263
trainer/Q2 Predictions Max        -12.9975
trainer/Q2 Predictions Min       -219.588
trainer/Q Targets Mean            -80.5331
trainer/Q Targets Std              65.5203
trainer/Q Targets Max              -1.6925
trainer/Q Targets Min            -222.409
trainer/Log Pis Mean                2.306
trainer/Log Pis Std                 1.03045
trainer/Log Pis Max                 5.19728
trainer/Log Pis Min                 0.266234
trainer/Policy mu Mean              0.0200323
trainer/Policy mu Std               0.74391
trainer/Policy mu Max               3.27623
trainer/Policy mu Min              -2.42141
trainer/Policy log std Mean        -2.09064
trainer/Policy log std Std          0.578168
trainer/Policy log std Max         -0.336248
trainer/Policy log std Min         -2.97717
trainer/Alpha                       0.0765853
trainer/Alpha Loss                  0.786269
exploration/num steps total     96700
exploration/num paths total       967
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.433229
exploration/Rewards Std             0.862415
exploration/Rewards Max            -0.0247382
exploration/Rewards Min            -7.90037
exploration/Returns Mean          -43.3229
exploration/Returns Std            13.6226
exploration/Returns Max           -18.7339
exploration/Returns Min           -59.9007
exploration/Actions Mean            0.0165225
exploration/Actions Std             0.202443
exploration/Actions Max             0.999143
exploration/Actions Min            -0.998965
exploration/Num Paths               5
exploration/Average Returns       -43.3229
evaluation/num steps total     289500
evaluation/num paths total       2895
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.57783
evaluation/Rewards Std              1.59377
evaluation/Rewards Max             -0.112269
evaluation/Rewards Min            -10.3911
evaluation/Returns Mean          -157.783
evaluation/Returns Std            130.05
evaluation/Returns Max            -24.4044
evaluation/Returns Min           -504.84
evaluation/Actions Mean             0.0122154
evaluation/Actions Std              0.183876
evaluation/Actions Max              0.998701
evaluation/Actions Min             -0.998101
evaluation/Num Paths               15
evaluation/Average Returns       -157.783
time/data storing (s)               0.00286976
time/evaluation sampling (s)        0.33412
time/exploration sampling (s)       0.140395
time/logging (s)                    0.00475774
time/saving (s)                     0.0019312
time/training (s)                   1.93192
time/epoch (s)                      2.41599
time/total (s)                    472.547
Epoch                             192
-----------------------------  ---------------
2019-04-23 01:21:26.070141 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 193 finished
-----------------------------  ---------------
replay_buffer/size              97200
trainer/QF1 Loss                   29.3285
trainer/QF2 Loss                   29.4835
trainer/Policy Loss                87.6086
trainer/Q1 Predictions Mean       -86.2478
trainer/Q1 Predictions Std         74.1154
trainer/Q1 Predictions Max        -13.0167
trainer/Q1 Predictions Min       -241.921
trainer/Q2 Predictions Mean       -86.2723
trainer/Q2 Predictions Std         74.118
trainer/Q2 Predictions Max        -12.9826
trainer/Q2 Predictions Min       -241.962
trainer/Q Targets Mean            -85.8161
trainer/Q Targets Std              75.0442
trainer/Q Targets Max              -0.0474868
trainer/Q Targets Min            -243.077
trainer/Log Pis Mean                1.89929
trainer/Log Pis Std                 1.26081
trainer/Log Pis Max                 6.70519
trainer/Log Pis Min                -2.89272
trainer/Policy mu Mean             -0.156035
trainer/Policy mu Std               0.623311
trainer/Policy mu Max               2.46526
trainer/Policy mu Min              -2.5565
trainer/Policy log std Mean        -2.08487
trainer/Policy log std Std          0.497955
trainer/Policy log std Max         -0.49473
trainer/Policy log std Min         -2.89916
trainer/Alpha                       0.0784949
trainer/Alpha Loss                 -0.256287
exploration/num steps total     97200
exploration/num paths total       972
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.59729
exploration/Rewards Std             1.0016
exploration/Rewards Max            -0.0218955
exploration/Rewards Min            -8.01134
exploration/Returns Mean          -59.729
exploration/Returns Std            35.8558
exploration/Returns Max           -27.1939
exploration/Returns Min          -128.623
exploration/Actions Mean           -0.0106602
exploration/Actions Std             0.208165
exploration/Actions Max             0.997437
exploration/Actions Min            -0.999515
exploration/Num Paths               5
exploration/Average Returns       -59.729
evaluation/num steps total     291000
evaluation/num paths total       2910
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.2995
evaluation/Rewards Std              1.72207
evaluation/Rewards Max             -0.0439111
evaluation/Rewards Min            -10.9151
evaluation/Returns Mean          -129.95
evaluation/Returns Std            136.192
evaluation/Returns Max            -22.1573
evaluation/Returns Min           -434.072
evaluation/Actions Mean             0.00344662
evaluation/Actions Std              0.196562
evaluation/Actions Max              0.999221
evaluation/Actions Min             -0.999511
evaluation/Num Paths               15
evaluation/Average Returns       -129.95
time/data storing (s)               0.00301587
time/evaluation sampling (s)        0.325001
time/exploration sampling (s)       0.138839
time/logging (s)                    0.00477221
time/saving (s)                     0.0019246
time/training (s)                   1.97081
time/epoch (s)                      2.44436
time/total (s)                    474.996
Epoch                             193
-----------------------------  ---------------
2019-04-23 01:21:28.538165 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 194 finished
-----------------------------  ---------------
replay_buffer/size              97700
trainer/QF1 Loss                    1.53728
trainer/QF2 Loss                    1.50359
trainer/Policy Loss                86.7071
trainer/Q1 Predictions Mean       -85.4697
trainer/Q1 Predictions Std         69.3055
trainer/Q1 Predictions Max        -12.5652
trainer/Q1 Predictions Min       -249.399
trainer/Q2 Predictions Mean       -85.459
trainer/Q2 Predictions Std         69.364
trainer/Q2 Predictions Max        -12.4567
trainer/Q2 Predictions Min       -249.304
trainer/Q Targets Mean            -86.1978
trainer/Q Targets Std              69.888
trainer/Q Targets Max             -13.3093
trainer/Q Targets Min            -250.351
trainer/Log Pis Mean                1.86444
trainer/Log Pis Std                 1.20969
trainer/Log Pis Max                 5.20362
trainer/Log Pis Min                -2.71318
trainer/Policy mu Mean             -0.155998
trainer/Policy mu Std               0.694884
trainer/Policy mu Max               2.97304
trainer/Policy mu Min              -2.66982
trainer/Policy log std Mean        -2.0286
trainer/Policy log std Std          0.543334
trainer/Policy log std Max         -0.47221
trainer/Policy log std Min         -2.98819
trainer/Alpha                       0.0778133
trainer/Alpha Loss                 -0.346148
exploration/num steps total     97700
exploration/num paths total       977
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -2.15725
exploration/Rewards Std             1.73012
exploration/Rewards Max            -0.0724099
exploration/Rewards Min            -9.14411
exploration/Returns Mean         -215.725
exploration/Returns Std           167.057
exploration/Returns Max           -35.7194
exploration/Returns Min          -516.015
exploration/Actions Mean           -0.00389058
exploration/Actions Std             0.214486
exploration/Actions Max             0.980444
exploration/Actions Min            -0.999107
exploration/Num Paths               5
exploration/Average Returns      -215.725
evaluation/num steps total     292500
evaluation/num paths total       2925
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.40701
evaluation/Rewards Std              1.46205
evaluation/Rewards Max             -0.0917086
evaluation/Rewards Min             -8.49578
evaluation/Returns Mean          -140.701
evaluation/Returns Std            129.718
evaluation/Returns Max            -26.4621
evaluation/Returns Min           -456.224
evaluation/Actions Mean             0.00710659
evaluation/Actions Std              0.153105
evaluation/Actions Max              0.998811
evaluation/Actions Min             -0.995563
evaluation/Num Paths               15
evaluation/Average Returns       -140.701
time/data storing (s)               0.00301086
time/evaluation sampling (s)        0.32798
time/exploration sampling (s)       0.137826
time/logging (s)                    0.00476416
time/saving (s)                     0.00193509
time/training (s)                   1.98477
time/epoch (s)                      2.46028
time/total (s)                    477.461
Epoch                             194
-----------------------------  ---------------
2019-04-23 01:21:30.994918 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 195 finished
-----------------------------  ---------------
replay_buffer/size              98200
trainer/QF1 Loss                  591.611
trainer/QF2 Loss                  595.962
trainer/Policy Loss                86.0166
trainer/Q1 Predictions Mean       -84.6235
trainer/Q1 Predictions Std         64.937
trainer/Q1 Predictions Max        -13.1696
trainer/Q1 Predictions Min       -247.28
trainer/Q2 Predictions Mean       -84.6233
trainer/Q2 Predictions Std         65.054
trainer/Q2 Predictions Max        -13.3009
trainer/Q2 Predictions Min       -248.205
trainer/Q Targets Mean            -82.0354
trainer/Q Targets Std              63.9329
trainer/Q Targets Max              -1.76637
trainer/Q Targets Min            -245.28
trainer/Log Pis Mean                2.10355
trainer/Log Pis Std                 1.28621
trainer/Log Pis Max                 6.25373
trainer/Log Pis Min                -4.08218
trainer/Policy mu Mean             -0.0572203
trainer/Policy mu Std               0.829544
trainer/Policy mu Max               2.72206
trainer/Policy mu Min              -2.39914
trainer/Policy log std Mean        -1.95937
trainer/Policy log std Std          0.616879
trainer/Policy log std Max         -0.35036
trainer/Policy log std Min         -2.89303
trainer/Alpha                       0.07692
trainer/Alpha Loss                  0.265601
exploration/num steps total     98200
exploration/num paths total       982
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.972068
exploration/Rewards Std             0.927832
exploration/Rewards Max            -0.0173554
exploration/Rewards Min            -8.62093
exploration/Returns Mean          -97.2068
exploration/Returns Std            47.7432
exploration/Returns Max           -42.4035
exploration/Returns Min          -177.746
exploration/Actions Mean            0.0195668
exploration/Actions Std             0.198249
exploration/Actions Max             0.999811
exploration/Actions Min            -0.992097
exploration/Num Paths               5
exploration/Average Returns       -97.2068
evaluation/num steps total     294000
evaluation/num paths total       2940
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.7012
evaluation/Rewards Std              1.81701
evaluation/Rewards Max             -0.0400097
evaluation/Rewards Min            -10.1024
evaluation/Returns Mean          -170.12
evaluation/Returns Std            153.607
evaluation/Returns Max            -26.1035
evaluation/Returns Min           -470.254
evaluation/Actions Mean             0.0226661
evaluation/Actions Std              0.193889
evaluation/Actions Max              0.998323
evaluation/Actions Min             -0.998172
evaluation/Num Paths               15
evaluation/Average Returns       -170.12
time/data storing (s)               0.00302868
time/evaluation sampling (s)        0.327975
time/exploration sampling (s)       0.136386
time/logging (s)                    0.00475064
time/saving (s)                     0.00192364
time/training (s)                   1.9749
time/epoch (s)                      2.44897
time/total (s)                    479.914
Epoch                             195
-----------------------------  ---------------
2019-04-23 01:21:33.438810 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 196 finished
-----------------------------  ---------------
replay_buffer/size              98700
trainer/QF1 Loss                  465.33
trainer/QF2 Loss                  464.152
trainer/Policy Loss                89.6304
trainer/Q1 Predictions Mean       -88.0817
trainer/Q1 Predictions Std         77.121
trainer/Q1 Predictions Max        -12.6859
trainer/Q1 Predictions Min       -250.115
trainer/Q2 Predictions Mean       -88.1837
trainer/Q2 Predictions Std         77.1351
trainer/Q2 Predictions Max        -12.8513
trainer/Q2 Predictions Min       -249.423
trainer/Q Targets Mean            -86.4391
trainer/Q Targets Std              76.664
trainer/Q Targets Max              -4.72741
trainer/Q Targets Min            -250.315
trainer/Log Pis Mean                1.98161
trainer/Log Pis Std                 1.18511
trainer/Log Pis Max                 4.82746
trainer/Log Pis Min                -1.56832
trainer/Policy mu Mean              0.0315281
trainer/Policy mu Std               0.689272
trainer/Policy mu Max               2.94943
trainer/Policy mu Min              -2.23763
trainer/Policy log std Mean        -2.07284
trainer/Policy log std Std          0.526008
trainer/Policy log std Max         -0.514133
trainer/Policy log std Min         -2.86097
trainer/Alpha                       0.0777349
trainer/Alpha Loss                 -0.046971
exploration/num steps total     98700
exploration/num paths total       987
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.796498
exploration/Rewards Std             1.17569
exploration/Rewards Max            -0.0189741
exploration/Rewards Min            -8.39875
exploration/Returns Mean          -79.6498
exploration/Returns Std            69.5582
exploration/Returns Max           -34.9156
exploration/Returns Min          -218.305
exploration/Actions Mean            0.00161438
exploration/Actions Std             0.212906
exploration/Actions Max             0.997568
exploration/Actions Min            -0.999805
exploration/Num Paths               5
exploration/Average Returns       -79.6498
evaluation/num steps total     295500
evaluation/num paths total       2955
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.4563
evaluation/Rewards Std              1.54902
evaluation/Rewards Max             -0.0211605
evaluation/Rewards Min             -9.63119
evaluation/Returns Mean          -145.63
evaluation/Returns Std            132.763
evaluation/Returns Max            -31.7098
evaluation/Returns Min           -508.662
evaluation/Actions Mean             0.0115788
evaluation/Actions Std              0.159745
evaluation/Actions Max              0.999338
evaluation/Actions Min             -0.998943
evaluation/Num Paths               15
evaluation/Average Returns       -145.63
time/data storing (s)               0.00291459
time/evaluation sampling (s)        0.330744
time/exploration sampling (s)       0.136239
time/logging (s)                    0.00480067
time/saving (s)                     0.00158167
time/training (s)                   1.96006
time/epoch (s)                      2.43634
time/total (s)                    482.355
Epoch                             196
-----------------------------  ---------------
2019-04-23 01:21:35.905314 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 197 finished
-----------------------------  ---------------
replay_buffer/size              99200
trainer/QF1 Loss                  594.229
trainer/QF2 Loss                  593.818
trainer/Policy Loss                81.1377
trainer/Q1 Predictions Mean       -79.7731
trainer/Q1 Predictions Std         71.0804
trainer/Q1 Predictions Max        -12.9564
trainer/Q1 Predictions Min       -251.189
trainer/Q2 Predictions Mean       -79.8212
trainer/Q2 Predictions Std         71.1326
trainer/Q2 Predictions Max        -13.0187
trainer/Q2 Predictions Min       -251.49
trainer/Q Targets Mean            -77.0157
trainer/Q Targets Std              70.1648
trainer/Q Targets Max              -0.898751
trainer/Q Targets Min            -249.003
trainer/Log Pis Mean                1.9168
trainer/Log Pis Std                 1.27223
trainer/Log Pis Max                 6.0244
trainer/Log Pis Min                -2.12082
trainer/Policy mu Mean              0.0435315
trainer/Policy mu Std               0.773287
trainer/Policy mu Max               3.07722
trainer/Policy mu Min              -2.2016
trainer/Policy log std Mean        -1.99052
trainer/Policy log std Std          0.598768
trainer/Policy log std Max         -0.478075
trainer/Policy log std Min         -2.89485
trainer/Alpha                       0.0779035
trainer/Alpha Loss                 -0.21236
exploration/num steps total     99200
exploration/num paths total       992
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -2.24822
exploration/Rewards Std             2.43991
exploration/Rewards Max            -0.00854555
exploration/Rewards Min            -7.38222
exploration/Returns Mean         -224.822
exploration/Returns Std           228.375
exploration/Returns Max           -22.7195
exploration/Returns Min          -506.63
exploration/Actions Mean            0.0263425
exploration/Actions Std             0.268819
exploration/Actions Max             0.999804
exploration/Actions Min            -0.973058
exploration/Num Paths               5
exploration/Average Returns      -224.822
evaluation/num steps total     297000
evaluation/num paths total       2970
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.03071
evaluation/Rewards Std              1.51863
evaluation/Rewards Max             -0.0360992
evaluation/Rewards Min             -9.98054
evaluation/Returns Mean          -103.071
evaluation/Returns Std            125.931
evaluation/Returns Max            -12.8807
evaluation/Returns Min           -523.212
evaluation/Actions Mean             0.00729371
evaluation/Actions Std              0.170808
evaluation/Actions Max              0.998924
evaluation/Actions Min             -0.998619
evaluation/Num Paths               15
evaluation/Average Returns       -103.071
time/data storing (s)               0.00308158
time/evaluation sampling (s)        0.325913
time/exploration sampling (s)       0.137874
time/logging (s)                    0.00427994
time/saving (s)                     0.00204479
time/training (s)                   1.98502
time/epoch (s)                      2.45822
time/total (s)                    484.818
Epoch                             197
-----------------------------  ---------------
2019-04-23 01:21:38.358682 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 198 finished
-----------------------------  ---------------
replay_buffer/size              99700
trainer/QF1 Loss                   23.5107
trainer/QF2 Loss                   23.2351
trainer/Policy Loss                86.4635
trainer/Q1 Predictions Mean       -85.0433
trainer/Q1 Predictions Std         71.8227
trainer/Q1 Predictions Max        -12.5279
trainer/Q1 Predictions Min       -247.529
trainer/Q2 Predictions Mean       -85.0399
trainer/Q2 Predictions Std         71.8105
trainer/Q2 Predictions Max        -12.593
trainer/Q2 Predictions Min       -248.171
trainer/Q Targets Mean            -85.1154
trainer/Q Targets Std              72.8157
trainer/Q Targets Max              -0.658041
trainer/Q Targets Min            -246.714
trainer/Log Pis Mean                2.08826
trainer/Log Pis Std                 1.43008
trainer/Log Pis Max                 8.60369
trainer/Log Pis Min                -3.00144
trainer/Policy mu Mean             -0.170588
trainer/Policy mu Std               0.761527
trainer/Policy mu Max               3.73772
trainer/Policy mu Min              -3.81815
trainer/Policy log std Mean        -2.0378
trainer/Policy log std Std          0.562621
trainer/Policy log std Max         -0.213861
trainer/Policy log std Min         -2.92545
trainer/Alpha                       0.079449
trainer/Alpha Loss                  0.223552
exploration/num steps total     99700
exploration/num paths total       997
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.44421
exploration/Rewards Std             1.37231
exploration/Rewards Max            -0.114101
exploration/Rewards Min           -10.4752
exploration/Returns Mean         -144.421
exploration/Returns Std            82.4043
exploration/Returns Max           -64.9236
exploration/Returns Min          -257.634
exploration/Actions Mean           -0.00698225
exploration/Actions Std             0.200968
exploration/Actions Max             0.999841
exploration/Actions Min            -0.999717
exploration/Num Paths               5
exploration/Average Returns      -144.421
evaluation/num steps total     298500
evaluation/num paths total       2985
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.362
evaluation/Rewards Std              1.62662
evaluation/Rewards Max             -0.155193
evaluation/Rewards Min            -10.0538
evaluation/Returns Mean          -136.2
evaluation/Returns Std            140.717
evaluation/Returns Max            -20.4905
evaluation/Returns Min           -465.421
evaluation/Actions Mean             0.0106185
evaluation/Actions Std              0.164174
evaluation/Actions Max              0.99853
evaluation/Actions Min             -0.998075
evaluation/Num Paths               15
evaluation/Average Returns       -136.2
time/data storing (s)               0.00297872
time/evaluation sampling (s)        0.327995
time/exploration sampling (s)       0.141683
time/logging (s)                    0.00355494
time/saving (s)                     0.00154965
time/training (s)                   1.9671
time/epoch (s)                      2.44487
time/total (s)                    487.267
Epoch                             198
-----------------------------  ---------------
2019-04-23 01:21:40.819054 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 199 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                  352.685
trainer/QF2 Loss                  351.535
trainer/Policy Loss                75.1623
trainer/Q1 Predictions Mean       -74.0558
trainer/Q1 Predictions Std         65.6588
trainer/Q1 Predictions Max        -12.8071
trainer/Q1 Predictions Min       -240.557
trainer/Q2 Predictions Mean       -74.1143
trainer/Q2 Predictions Std         65.5915
trainer/Q2 Predictions Max        -12.9919
trainer/Q2 Predictions Min       -240.544
trainer/Q Targets Mean            -71.6577
trainer/Q Targets Std              66.5317
trainer/Q Targets Max              -0.303056
trainer/Q Targets Min            -242.102
trainer/Log Pis Mean                1.82492
trainer/Log Pis Std                 1.08601
trainer/Log Pis Max                 6.55197
trainer/Log Pis Min                -0.514025
trainer/Policy mu Mean             -0.149261
trainer/Policy mu Std               0.706241
trainer/Policy mu Max               2.89623
trainer/Policy mu Min              -2.45071
trainer/Policy log std Mean        -1.93683
trainer/Policy log std Std          0.490259
trainer/Policy log std Max         -0.417573
trainer/Policy log std Min         -2.76052
trainer/Alpha                       0.0777666
trainer/Alpha Loss                 -0.447133
exploration/num steps total    100200
exploration/num paths total      1002
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -3.11248
exploration/Rewards Std             1.90592
exploration/Rewards Max            -0.156457
exploration/Rewards Min            -9.86196
exploration/Returns Mean         -311.248
exploration/Returns Std           177.323
exploration/Returns Max           -73.4511
exploration/Returns Min          -465.608
exploration/Actions Mean           -0.0231033
exploration/Actions Std             0.261028
exploration/Actions Max             0.88655
exploration/Actions Min            -0.999991
exploration/Num Paths               5
exploration/Average Returns      -311.248
evaluation/num steps total     300000
evaluation/num paths total       3000
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.86527
evaluation/Rewards Std              1.63127
evaluation/Rewards Max             -0.0228426
evaluation/Rewards Min            -10.0862
evaluation/Returns Mean          -186.527
evaluation/Returns Std            144.767
evaluation/Returns Max            -16.7911
evaluation/Returns Min           -462.672
evaluation/Actions Mean             0.0111396
evaluation/Actions Std              0.18362
evaluation/Actions Max              0.998196
evaluation/Actions Min             -0.997966
evaluation/Num Paths               15
evaluation/Average Returns       -186.527
time/data storing (s)               0.00295302
time/evaluation sampling (s)        0.32964
time/exploration sampling (s)       0.138171
time/logging (s)                    0.00475084
time/saving (s)                     0.00194354
time/training (s)                   1.97686
time/epoch (s)                      2.45432
time/total (s)                    489.726
Epoch                             199
-----------------------------  ---------------
2019-04-23 01:21:43.289267 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 200 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                   14.171
trainer/QF2 Loss                   14.2117
trainer/Policy Loss                81.2285
trainer/Q1 Predictions Mean       -79.8463
trainer/Q1 Predictions Std         69.3058
trainer/Q1 Predictions Max        -12.6012
trainer/Q1 Predictions Min       -243.843
trainer/Q2 Predictions Mean       -79.856
trainer/Q2 Predictions Std         69.3235
trainer/Q2 Predictions Max        -12.4737
trainer/Q2 Predictions Min       -243.601
trainer/Q Targets Mean            -80.4697
trainer/Q Targets Std              70.5611
trainer/Q Targets Max              -2.32289
trainer/Q Targets Min            -245.905
trainer/Log Pis Mean                2.15019
trainer/Log Pis Std                 1.34907
trainer/Log Pis Max                 8.48309
trainer/Log Pis Min                -2.75483
trainer/Policy mu Mean              0.0153606
trainer/Policy mu Std               0.857558
trainer/Policy mu Max               3.22909
trainer/Policy mu Min              -2.40631
trainer/Policy log std Mean        -1.96421
trainer/Policy log std Std          0.599448
trainer/Policy log std Max         -0.281937
trainer/Policy log std Min         -2.89635
trainer/Alpha                       0.0765465
trainer/Alpha Loss                  0.385973
exploration/num steps total    100700
exploration/num paths total      1007
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -3.24815
exploration/Rewards Std             1.59841
exploration/Rewards Max            -0.651907
exploration/Rewards Min            -9.11224
exploration/Returns Mean         -324.815
exploration/Returns Std           154.328
exploration/Returns Max           -86.9758
exploration/Returns Min          -495.506
exploration/Actions Mean           -0.000666101
exploration/Actions Std             0.238566
exploration/Actions Max             0.997493
exploration/Actions Min            -0.995519
exploration/Num Paths               5
exploration/Average Returns      -324.815
evaluation/num steps total     301500
evaluation/num paths total       3015
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.40028
evaluation/Rewards Std              1.79584
evaluation/Rewards Max             -0.0923545
evaluation/Rewards Min            -10.5196
evaluation/Returns Mean          -140.028
evaluation/Returns Std            157.716
evaluation/Returns Max            -16.5036
evaluation/Returns Min           -517.007
evaluation/Actions Mean             0.0133105
evaluation/Actions Std              0.165437
evaluation/Actions Max              0.999387
evaluation/Actions Min             -0.999226
evaluation/Num Paths               15
evaluation/Average Returns       -140.028
time/data storing (s)               0.00285638
time/evaluation sampling (s)        0.326752
time/exploration sampling (s)       0.141277
time/logging (s)                    0.00474776
time/saving (s)                     0.00947456
time/training (s)                   1.97782
time/epoch (s)                      2.46293
time/total (s)                    492.193
Epoch                             200
-----------------------------  ----------------
2019-04-23 01:21:45.763409 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 201 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                  168.26
trainer/QF2 Loss                  167.908
trainer/Policy Loss                79.1957
trainer/Q1 Predictions Mean       -77.7845
trainer/Q1 Predictions Std         70.9534
trainer/Q1 Predictions Max        -13.7086
trainer/Q1 Predictions Min       -235.49
trainer/Q2 Predictions Mean       -77.8283
trainer/Q2 Predictions Std         70.9393
trainer/Q2 Predictions Max        -13.6422
trainer/Q2 Predictions Min       -235.71
trainer/Q Targets Mean            -76.5948
trainer/Q Targets Std              71.8503
trainer/Q Targets Max              -2.7608
trainer/Q Targets Min            -237.368
trainer/Log Pis Mean                2.07996
trainer/Log Pis Std                 1.37749
trainer/Log Pis Max                 7.45341
trainer/Log Pis Min                -1.6676
trainer/Policy mu Mean             -0.162188
trainer/Policy mu Std               0.850206
trainer/Policy mu Max               2.58894
trainer/Policy mu Min              -3.58366
trainer/Policy log std Mean        -1.9152
trainer/Policy log std Std          0.588803
trainer/Policy log std Max         -0.168145
trainer/Policy log std Min         -2.99123
trainer/Alpha                       0.0766592
trainer/Alpha Loss                  0.205376
exploration/num steps total    101200
exploration/num paths total      1012
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.7796
exploration/Rewards Std             1.4075
exploration/Rewards Max            -0.00938189
exploration/Rewards Min            -9.09576
exploration/Returns Mean         -177.96
exploration/Returns Std           121.573
exploration/Returns Max           -24.4317
exploration/Returns Min          -287.354
exploration/Actions Mean           -0.00243703
exploration/Actions Std             0.220831
exploration/Actions Max             0.994034
exploration/Actions Min            -0.995816
exploration/Num Paths               5
exploration/Average Returns      -177.96
evaluation/num steps total     303000
evaluation/num paths total       3030
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.28192
evaluation/Rewards Std              1.68879
evaluation/Rewards Max             -0.0987406
evaluation/Rewards Min             -8.78307
evaluation/Returns Mean          -128.192
evaluation/Returns Std            148.722
evaluation/Returns Max            -13.7977
evaluation/Returns Min           -468.625
evaluation/Actions Mean             0.0036469
evaluation/Actions Std              0.176159
evaluation/Actions Max              0.998919
evaluation/Actions Min             -0.999563
evaluation/Num Paths               15
evaluation/Average Returns       -128.192
time/data storing (s)               0.00289688
time/evaluation sampling (s)        0.330708
time/exploration sampling (s)       0.140265
time/logging (s)                    0.00481287
time/saving (s)                     0.00217578
time/training (s)                   1.98548
time/epoch (s)                      2.46634
time/total (s)                    494.664
Epoch                             201
-----------------------------  ---------------
2019-04-23 01:21:48.212935 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 202 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.631554
trainer/QF2 Loss                    0.642457
trainer/Policy Loss                76.9895
trainer/Q1 Predictions Mean       -75.471
trainer/Q1 Predictions Std         58.9466
trainer/Q1 Predictions Max        -12.5459
trainer/Q1 Predictions Min       -237.034
trainer/Q2 Predictions Mean       -75.3922
trainer/Q2 Predictions Std         58.8721
trainer/Q2 Predictions Max        -12.5028
trainer/Q2 Predictions Min       -237.519
trainer/Q Targets Mean            -75.7729
trainer/Q Targets Std              58.9552
trainer/Q Targets Max             -12.5203
trainer/Q Targets Min            -237.689
trainer/Log Pis Mean                2.14907
trainer/Log Pis Std                 1.27738
trainer/Log Pis Max                 6.14246
trainer/Log Pis Min                -2.09323
trainer/Policy mu Mean             -0.0851076
trainer/Policy mu Std               0.83313
trainer/Policy mu Max               3.31229
trainer/Policy mu Min              -2.42208
trainer/Policy log std Mean        -1.94994
trainer/Policy log std Std          0.570902
trainer/Policy log std Max         -0.522826
trainer/Policy log std Min         -2.92605
trainer/Alpha                       0.0763091
trainer/Alpha Loss                  0.383586
exploration/num steps total    101700
exploration/num paths total      1017
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.21078
exploration/Rewards Std             1.29125
exploration/Rewards Max            -0.0852094
exploration/Rewards Min            -9.65071
exploration/Returns Mean         -121.078
exploration/Returns Std            77.9397
exploration/Returns Max           -48.7764
exploration/Returns Min          -271.802
exploration/Actions Mean           -0.0188719
exploration/Actions Std             0.207767
exploration/Actions Max             0.944722
exploration/Actions Min            -0.999909
exploration/Num Paths               5
exploration/Average Returns      -121.078
evaluation/num steps total     304500
evaluation/num paths total       3045
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.5253
evaluation/Rewards Std              1.84005
evaluation/Rewards Max             -0.00821453
evaluation/Rewards Min             -8.70364
evaluation/Returns Mean          -152.53
evaluation/Returns Std            173.974
evaluation/Returns Max             -5.39516
evaluation/Returns Min           -470.839
evaluation/Actions Mean             0.00171928
evaluation/Actions Std              0.160873
evaluation/Actions Max              0.998619
evaluation/Actions Min             -0.998581
evaluation/Num Paths               15
evaluation/Average Returns       -152.53
time/data storing (s)               0.0026832
time/evaluation sampling (s)        0.330017
time/exploration sampling (s)       0.13667
time/logging (s)                    0.00475785
time/saving (s)                     0.00193559
time/training (s)                   1.96551
time/epoch (s)                      2.44157
time/total (s)                    497.11
Epoch                             202
-----------------------------  ---------------
2019-04-23 01:21:50.689631 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 203 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.00055
trainer/QF2 Loss                    1.06038
trainer/Policy Loss                94.7768
trainer/Q1 Predictions Mean       -93.4007
trainer/Q1 Predictions Std         78.5385
trainer/Q1 Predictions Max        -12.2187
trainer/Q1 Predictions Min       -242.527
trainer/Q2 Predictions Mean       -93.4053
trainer/Q2 Predictions Std         78.5451
trainer/Q2 Predictions Max        -12.1359
trainer/Q2 Predictions Min       -242.107
trainer/Q Targets Mean            -93.9594
trainer/Q Targets Std              79.0659
trainer/Q Targets Max             -12.45
trainer/Q Targets Min            -242.539
trainer/Log Pis Mean                2.0299
trainer/Log Pis Std                 1.35377
trainer/Log Pis Max                 5.62533
trainer/Log Pis Min                -2.62177
trainer/Policy mu Mean              0.0211287
trainer/Policy mu Std               0.897187
trainer/Policy mu Max               3.05673
trainer/Policy mu Min              -3.28992
trainer/Policy log std Mean        -1.86688
trainer/Policy log std Std          0.598979
trainer/Policy log std Max         -0.454923
trainer/Policy log std Min         -2.86313
trainer/Alpha                       0.0771762
trainer/Alpha Loss                  0.0766014
exploration/num steps total    102200
exploration/num paths total      1022
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -2.71782
exploration/Rewards Std             1.92637
exploration/Rewards Max            -0.0102693
exploration/Rewards Min            -5.52473
exploration/Returns Mean         -271.782
exploration/Returns Std           190.62
exploration/Returns Max           -29.944
exploration/Returns Min          -488.448
exploration/Actions Mean           -0.013411
exploration/Actions Std             0.219342
exploration/Actions Max             0.910159
exploration/Actions Min            -0.986803
exploration/Num Paths               5
exploration/Average Returns      -271.782
evaluation/num steps total     306000
evaluation/num paths total       3060
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.14516
evaluation/Rewards Std              1.73395
evaluation/Rewards Max             -0.101727
evaluation/Rewards Min            -10.4824
evaluation/Returns Mean          -114.516
evaluation/Returns Std            147.707
evaluation/Returns Max            -15.2043
evaluation/Returns Min           -484.471
evaluation/Actions Mean            -0.00711371
evaluation/Actions Std              0.185086
evaluation/Actions Max              0.999281
evaluation/Actions Min             -0.999764
evaluation/Num Paths               15
evaluation/Average Returns       -114.516
time/data storing (s)               0.00302898
time/evaluation sampling (s)        0.321752
time/exploration sampling (s)       0.139655
time/logging (s)                    0.00477984
time/saving (s)                     0.00192034
time/training (s)                   1.99775
time/epoch (s)                      2.46889
time/total (s)                    499.584
Epoch                             203
-----------------------------  ---------------
2019-04-23 01:21:53.158963 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 204 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.05393
trainer/QF2 Loss                    0.98793
trainer/Policy Loss                77.2978
trainer/Q1 Predictions Mean       -76.0503
trainer/Q1 Predictions Std         69.7596
trainer/Q1 Predictions Max        -12.0793
trainer/Q1 Predictions Min       -235.894
trainer/Q2 Predictions Mean       -76.0055
trainer/Q2 Predictions Std         69.7455
trainer/Q2 Predictions Max        -12.0714
trainer/Q2 Predictions Min       -235.319
trainer/Q Targets Mean            -76.6528
trainer/Q Targets Std              70.0355
trainer/Q Targets Max             -12.2339
trainer/Q Targets Min            -236.507
trainer/Log Pis Mean                1.86228
trainer/Log Pis Std                 1.49513
trainer/Log Pis Max                 5.89959
trainer/Log Pis Min                -4.85469
trainer/Policy mu Mean             -0.115555
trainer/Policy mu Std               0.682737
trainer/Policy mu Max               2.21199
trainer/Policy mu Min              -3.13566
trainer/Policy log std Mean        -2.02248
trainer/Policy log std Std          0.51942
trainer/Policy log std Max         -0.325198
trainer/Policy log std Min         -2.89903
trainer/Alpha                       0.0759821
trainer/Alpha Loss                 -0.354944
exploration/num steps total    102700
exploration/num paths total      1027
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.53326
exploration/Rewards Std             1.55334
exploration/Rewards Max            -0.0118557
exploration/Rewards Min            -5.11652
exploration/Returns Mean         -153.326
exploration/Returns Std           149.268
exploration/Returns Max           -29.2827
exploration/Returns Min          -427.42
exploration/Actions Mean            0.00792413
exploration/Actions Std             0.179621
exploration/Actions Max             0.99008
exploration/Actions Min            -0.984863
exploration/Num Paths               5
exploration/Average Returns      -153.326
evaluation/num steps total     307500
evaluation/num paths total       3075
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.63104
evaluation/Rewards Std              1.89073
evaluation/Rewards Max             -0.01445
evaluation/Rewards Min            -10.4878
evaluation/Returns Mean          -163.104
evaluation/Returns Std            165.753
evaluation/Returns Max            -13.2542
evaluation/Returns Min           -450.818
evaluation/Actions Mean             0.0117642
evaluation/Actions Std              0.180829
evaluation/Actions Max              0.99806
evaluation/Actions Min             -0.999747
evaluation/Num Paths               15
evaluation/Average Returns       -163.104
time/data storing (s)               0.00276545
time/evaluation sampling (s)        0.323433
time/exploration sampling (s)       0.139479
time/logging (s)                    0.00478595
time/saving (s)                     0.00195749
time/training (s)                   1.98909
time/epoch (s)                      2.46152
time/total (s)                    502.05
Epoch                             204
-----------------------------  ---------------
2019-04-23 01:21:55.637548 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 205 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   24.7431
trainer/QF2 Loss                   24.8861
trainer/Policy Loss                77.3315
trainer/Q1 Predictions Mean       -76.1121
trainer/Q1 Predictions Std         68.746
trainer/Q1 Predictions Max        -13.7048
trainer/Q1 Predictions Min       -237.002
trainer/Q2 Predictions Mean       -76.1069
trainer/Q2 Predictions Std         68.7402
trainer/Q2 Predictions Max        -13.7202
trainer/Q2 Predictions Min       -237.892
trainer/Q Targets Mean            -75.9898
trainer/Q Targets Std              69.8218
trainer/Q Targets Max              -0.928087
trainer/Q Targets Min            -240.584
trainer/Log Pis Mean                1.84614
trainer/Log Pis Std                 1.19128
trainer/Log Pis Max                 5.38878
trainer/Log Pis Min                -1.90266
trainer/Policy mu Mean             -0.037879
trainer/Policy mu Std               0.729464
trainer/Policy mu Max               2.80248
trainer/Policy mu Min              -3.26748
trainer/Policy log std Mean        -1.99486
trainer/Policy log std Std          0.518625
trainer/Policy log std Max         -0.4892
trainer/Policy log std Min         -2.80504
trainer/Alpha                       0.0756406
trainer/Alpha Loss                 -0.397204
exploration/num steps total    103200
exploration/num paths total      1032
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.19127
exploration/Rewards Std             1.27312
exploration/Rewards Max            -0.0217601
exploration/Rewards Min            -9.74435
exploration/Returns Mean         -119.127
exploration/Returns Std            93.7776
exploration/Returns Max           -27.5014
exploration/Returns Min          -278.658
exploration/Actions Mean           -0.00560846
exploration/Actions Std             0.224686
exploration/Actions Max             0.999523
exploration/Actions Min            -0.998998
exploration/Num Paths               5
exploration/Average Returns      -119.127
evaluation/num steps total     309000
evaluation/num paths total       3090
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.09266
evaluation/Rewards Std              1.51439
evaluation/Rewards Max             -0.129003
evaluation/Rewards Min             -9.77438
evaluation/Returns Mean          -109.266
evaluation/Returns Std            128.643
evaluation/Returns Max            -15.8717
evaluation/Returns Min           -492.029
evaluation/Actions Mean            -0.00750563
evaluation/Actions Std              0.161228
evaluation/Actions Max              0.998531
evaluation/Actions Min             -0.997501
evaluation/Num Paths               15
evaluation/Average Returns       -109.266
time/data storing (s)               0.00278873
time/evaluation sampling (s)        0.328878
time/exploration sampling (s)       0.140889
time/logging (s)                    0.0042109
time/saving (s)                     0.00193023
time/training (s)                   1.9915
time/epoch (s)                      2.47019
time/total (s)                    504.524
Epoch                             205
-----------------------------  ---------------
2019-04-23 01:21:58.115550 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 206 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   22.361
trainer/QF2 Loss                   22.8092
trainer/Policy Loss                76.1495
trainer/Q1 Predictions Mean       -74.5795
trainer/Q1 Predictions Std         68.1718
trainer/Q1 Predictions Max        -12.1988
trainer/Q1 Predictions Min       -234.714
trainer/Q2 Predictions Mean       -74.5849
trainer/Q2 Predictions Std         68.1416
trainer/Q2 Predictions Max        -12.3417
trainer/Q2 Predictions Min       -234.591
trainer/Q Targets Mean            -74.9543
trainer/Q Targets Std              69.2584
trainer/Q Targets Max              -1.80639
trainer/Q Targets Min            -235.891
trainer/Log Pis Mean                2.04403
trainer/Log Pis Std                 1.59324
trainer/Log Pis Max                 6.28318
trainer/Log Pis Min                -6.32571
trainer/Policy mu Mean              0.0402259
trainer/Policy mu Std               0.764042
trainer/Policy mu Max               3.20349
trainer/Policy mu Min              -2.72035
trainer/Policy log std Mean        -2.01612
trainer/Policy log std Std          0.525025
trainer/Policy log std Max         -0.273437
trainer/Policy log std Min         -2.88165
trainer/Alpha                       0.0754016
trainer/Alpha Loss                  0.113805
exploration/num steps total    103700
exploration/num paths total      1037
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.65301
exploration/Rewards Std             1.51814
exploration/Rewards Max            -0.0338313
exploration/Rewards Min           -11.3388
exploration/Returns Mean         -165.301
exploration/Returns Std            92.1885
exploration/Returns Max           -36.4412
exploration/Returns Min          -276.405
exploration/Actions Mean           -0.0166358
exploration/Actions Std             0.256729
exploration/Actions Max             0.997708
exploration/Actions Min            -0.999948
exploration/Num Paths               5
exploration/Average Returns      -165.301
evaluation/num steps total     310500
evaluation/num paths total       3105
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.11503
evaluation/Rewards Std              1.57625
evaluation/Rewards Max             -0.00495475
evaluation/Rewards Min            -10.9255
evaluation/Returns Mean          -111.503
evaluation/Returns Std            125.086
evaluation/Returns Max            -15.217
evaluation/Returns Min           -479.283
evaluation/Actions Mean             0.00639976
evaluation/Actions Std              0.171015
evaluation/Actions Max              0.999567
evaluation/Actions Min             -0.999722
evaluation/Num Paths               15
evaluation/Average Returns       -111.503
time/data storing (s)               0.00264963
time/evaluation sampling (s)        0.334403
time/exploration sampling (s)       0.143909
time/logging (s)                    0.00474152
time/saving (s)                     0.00186015
time/training (s)                   1.98326
time/epoch (s)                      2.47083
time/total (s)                    507
Epoch                             206
-----------------------------  ---------------
2019-04-23 01:22:00.575260 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 207 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   62.2571
trainer/QF2 Loss                   62.2071
trainer/Policy Loss                83.1428
trainer/Q1 Predictions Mean       -81.8015
trainer/Q1 Predictions Std         73.2263
trainer/Q1 Predictions Max        -12.2163
trainer/Q1 Predictions Min       -243.66
trainer/Q2 Predictions Mean       -81.8199
trainer/Q2 Predictions Std         73.2116
trainer/Q2 Predictions Max        -12.3477
trainer/Q2 Predictions Min       -243.664
trainer/Q Targets Mean            -81.1852
trainer/Q Targets Std              74.407
trainer/Q Targets Max              -0.339241
trainer/Q Targets Min            -246.023
trainer/Log Pis Mean                1.9805
trainer/Log Pis Std                 1.37665
trainer/Log Pis Max                 8.08967
trainer/Log Pis Min                -3.87682
trainer/Policy mu Mean             -0.254839
trainer/Policy mu Std               0.707635
trainer/Policy mu Max               1.70508
trainer/Policy mu Min              -2.79374
trainer/Policy log std Mean        -2.02975
trainer/Policy log std Std          0.527264
trainer/Policy log std Max         -0.622184
trainer/Policy log std Min         -2.83197
trainer/Alpha                       0.0760598
trainer/Alpha Loss                 -0.0502249
exploration/num steps total    104200
exploration/num paths total      1042
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -2.20238
exploration/Rewards Std             1.98044
exploration/Rewards Max            -0.0106699
exploration/Rewards Min            -9.34957
exploration/Returns Mean         -220.238
exploration/Returns Std           175.864
exploration/Returns Max           -37.3282
exploration/Returns Min          -460.266
exploration/Actions Mean           -0.0168621
exploration/Actions Std             0.249745
exploration/Actions Max             0.997356
exploration/Actions Min            -0.999705
exploration/Num Paths               5
exploration/Average Returns      -220.238
evaluation/num steps total     312000
evaluation/num paths total       3120
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.6175
evaluation/Rewards Std              1.72115
evaluation/Rewards Max             -0.12261
evaluation/Rewards Min            -11.603
evaluation/Returns Mean          -161.75
evaluation/Returns Std            129.841
evaluation/Returns Max            -25.9112
evaluation/Returns Min           -453.703
evaluation/Actions Mean             0.00387848
evaluation/Actions Std              0.193819
evaluation/Actions Max              0.999243
evaluation/Actions Min             -0.999869
evaluation/Num Paths               15
evaluation/Average Returns       -161.75
time/data storing (s)               0.00269409
time/evaluation sampling (s)        0.323643
time/exploration sampling (s)       0.135882
time/logging (s)                    0.00475467
time/saving (s)                     0.00194413
time/training (s)                   1.98305
time/epoch (s)                      2.45196
time/total (s)                    509.456
Epoch                             207
-----------------------------  ---------------
2019-04-23 01:22:03.053244 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 208 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    2.08629
trainer/QF2 Loss                    2.35398
trainer/Policy Loss                78.8143
trainer/Q1 Predictions Mean       -77.5722
trainer/Q1 Predictions Std         70.6269
trainer/Q1 Predictions Max        -12.6862
trainer/Q1 Predictions Min       -243.722
trainer/Q2 Predictions Mean       -77.5741
trainer/Q2 Predictions Std         70.598
trainer/Q2 Predictions Max        -12.7524
trainer/Q2 Predictions Min       -245.934
trainer/Q Targets Mean            -78.3652
trainer/Q Targets Std              71.4762
trainer/Q Targets Max             -12.306
trainer/Q Targets Min            -243.149
trainer/Log Pis Mean                1.78247
trainer/Log Pis Std                 1.21803
trainer/Log Pis Max                 5.33891
trainer/Log Pis Min                -2.57553
trainer/Policy mu Mean              0.0524886
trainer/Policy mu Std               0.724122
trainer/Policy mu Max               3.69913
trainer/Policy mu Min              -2.16993
trainer/Policy log std Mean        -1.91236
trainer/Policy log std Std          0.47737
trainer/Policy log std Max         -0.374293
trainer/Policy log std Min         -2.59176
trainer/Alpha                       0.0740491
trainer/Alpha Loss                 -0.566184
exploration/num steps total    104700
exploration/num paths total      1047
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -2.64862
exploration/Rewards Std             2.30519
exploration/Rewards Max            -0.0296363
exploration/Rewards Min            -6.39366
exploration/Returns Mean         -264.862
exploration/Returns Std           222.29
exploration/Returns Max           -28.995
exploration/Returns Min          -527.556
exploration/Actions Mean            0.0172103
exploration/Actions Std             0.202117
exploration/Actions Max             0.995598
exploration/Actions Min            -0.918969
exploration/Num Paths               5
exploration/Average Returns      -264.862
evaluation/num steps total     313500
evaluation/num paths total       3135
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.39042
evaluation/Rewards Std              1.6162
evaluation/Rewards Max             -0.0939254
evaluation/Rewards Min            -10.9214
evaluation/Returns Mean          -139.042
evaluation/Returns Std            135.862
evaluation/Returns Max            -23.8407
evaluation/Returns Min           -554.621
evaluation/Actions Mean            -0.00628865
evaluation/Actions Std              0.177086
evaluation/Actions Max              0.999541
evaluation/Actions Min             -0.999849
evaluation/Num Paths               15
evaluation/Average Returns       -139.042
time/data storing (s)               0.00287524
time/evaluation sampling (s)        0.331064
time/exploration sampling (s)       0.139473
time/logging (s)                    0.00386965
time/saving (s)                     0.00153787
time/training (s)                   1.99062
time/epoch (s)                      2.46944
time/total (s)                    511.929
Epoch                             208
-----------------------------  ---------------
2019-04-23 01:22:05.483902 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 209 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    4.12041
trainer/QF2 Loss                    3.79744
trainer/Policy Loss                89.2221
trainer/Q1 Predictions Mean       -87.7773
trainer/Q1 Predictions Std         73.6835
trainer/Q1 Predictions Max        -11.7691
trainer/Q1 Predictions Min       -241.77
trainer/Q2 Predictions Mean       -87.8443
trainer/Q2 Predictions Std         73.7808
trainer/Q2 Predictions Max        -11.6895
trainer/Q2 Predictions Min       -241.854
trainer/Q Targets Mean            -89.3629
trainer/Q Targets Std              74.7985
trainer/Q Targets Max             -12.0964
trainer/Q Targets Min            -243.792
trainer/Log Pis Mean                1.94205
trainer/Log Pis Std                 1.30509
trainer/Log Pis Max                 6.90495
trainer/Log Pis Min                -2.29307
trainer/Policy mu Mean             -0.0655944
trainer/Policy mu Std               0.759027
trainer/Policy mu Max               3.19952
trainer/Policy mu Min              -2.30649
trainer/Policy log std Mean        -2.01715
trainer/Policy log std Std          0.501596
trainer/Policy log std Max         -0.574638
trainer/Policy log std Min         -2.72627
trainer/Alpha                       0.071898
trainer/Alpha Loss                 -0.152556
exploration/num steps total    105200
exploration/num paths total      1052
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.612324
exploration/Rewards Std             1.15131
exploration/Rewards Max            -0.0110438
exploration/Rewards Min            -8.81719
exploration/Returns Mean          -61.2324
exploration/Returns Std            51.5453
exploration/Returns Max           -17.1075
exploration/Returns Min          -162.106
exploration/Actions Mean            0.0369527
exploration/Actions Std             0.216172
exploration/Actions Max             0.999899
exploration/Actions Min            -0.86907
exploration/Num Paths               5
exploration/Average Returns       -61.2324
evaluation/num steps total     315000
evaluation/num paths total       3150
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.09208
evaluation/Rewards Std              1.84722
evaluation/Rewards Max             -0.0543841
evaluation/Rewards Min             -9.88025
evaluation/Returns Mean          -109.208
evaluation/Returns Std            166.66
evaluation/Returns Max            -10.9548
evaluation/Returns Min           -536.859
evaluation/Actions Mean            -0.00307476
evaluation/Actions Std              0.171551
evaluation/Actions Max              0.999475
evaluation/Actions Min             -0.998727
evaluation/Num Paths               15
evaluation/Average Returns       -109.208
time/data storing (s)               0.00281136
time/evaluation sampling (s)        0.332055
time/exploration sampling (s)       0.13738
time/logging (s)                    0.00478548
time/saving (s)                     0.00193532
time/training (s)                   1.94543
time/epoch (s)                      2.4244
time/total (s)                    514.358
Epoch                             209
-----------------------------  ---------------
2019-04-23 01:22:07.938236 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 210 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                  474.318
trainer/QF2 Loss                  472.574
trainer/Policy Loss               100.19
trainer/Q1 Predictions Mean       -98.6795
trainer/Q1 Predictions Std         79.7561
trainer/Q1 Predictions Max        -11.8361
trainer/Q1 Predictions Min       -241.939
trainer/Q2 Predictions Mean       -98.726
trainer/Q2 Predictions Std         79.8546
trainer/Q2 Predictions Max        -11.8445
trainer/Q2 Predictions Min       -243.744
trainer/Q Targets Mean            -97.5719
trainer/Q Targets Std              80.1037
trainer/Q Targets Max              -5.09974
trainer/Q Targets Min            -241.561
trainer/Log Pis Mean                2.12905
trainer/Log Pis Std                 1.40165
trainer/Log Pis Max                 9.03546
trainer/Log Pis Min                -1.9161
trainer/Policy mu Mean              0.186902
trainer/Policy mu Std               0.809207
trainer/Policy mu Max               4.07364
trainer/Policy mu Min              -2.76569
trainer/Policy log std Mean        -2.00068
trainer/Policy log std Std          0.535647
trainer/Policy log std Max         -0.0978861
trainer/Policy log std Min         -2.78593
trainer/Alpha                       0.0710792
trainer/Alpha Loss                  0.341208
exploration/num steps total    105700
exploration/num paths total      1057
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.96072
exploration/Rewards Std             2.22436
exploration/Rewards Max            -0.0120664
exploration/Rewards Min            -7.93221
exploration/Returns Mean         -196.072
exploration/Returns Std           207.802
exploration/Returns Max           -36.6096
exploration/Returns Min          -598.011
exploration/Actions Mean            0.0010638
exploration/Actions Std             0.220959
exploration/Actions Max             0.997227
exploration/Actions Min            -0.999838
exploration/Num Paths               5
exploration/Average Returns      -196.072
evaluation/num steps total     316500
evaluation/num paths total       3165
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.66944
evaluation/Rewards Std              2.02596
evaluation/Rewards Max             -0.0625786
evaluation/Rewards Min             -9.21588
evaluation/Returns Mean          -166.944
evaluation/Returns Std            185.898
evaluation/Returns Max            -21.6022
evaluation/Returns Min           -600.614
evaluation/Actions Mean            -5.84965e-05
evaluation/Actions Std              0.17338
evaluation/Actions Max              0.999187
evaluation/Actions Min             -0.999533
evaluation/Num Paths               15
evaluation/Average Returns       -166.944
time/data storing (s)               0.00282156
time/evaluation sampling (s)        0.332517
time/exploration sampling (s)       0.140261
time/logging (s)                    0.00485429
time/saving (s)                     0.00200267
time/training (s)                   1.96519
time/epoch (s)                      2.44765
time/total (s)                    516.809
Epoch                             210
-----------------------------  ----------------
2019-04-23 01:22:10.392407 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 211 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                  151.887
trainer/QF2 Loss                  151.62
trainer/Policy Loss                69.7421
trainer/Q1 Predictions Mean       -68.1351
trainer/Q1 Predictions Std         63.3846
trainer/Q1 Predictions Max        -11.4173
trainer/Q1 Predictions Min       -232.867
trainer/Q2 Predictions Mean       -68.1302
trainer/Q2 Predictions Std         63.3776
trainer/Q2 Predictions Max        -11.3063
trainer/Q2 Predictions Min       -233.32
trainer/Q Targets Mean            -68.3091
trainer/Q Targets Std              64.5722
trainer/Q Targets Max              -2.7479
trainer/Q Targets Min            -236.834
trainer/Log Pis Mean                2.10664
trainer/Log Pis Std                 1.06961
trainer/Log Pis Max                 5.65347
trainer/Log Pis Min                -0.737139
trainer/Policy mu Mean             -0.0918113
trainer/Policy mu Std               0.730666
trainer/Policy mu Max               3.06898
trainer/Policy mu Min              -2.2433
trainer/Policy log std Mean        -1.99953
trainer/Policy log std Std          0.485925
trainer/Policy log std Max         -0.518303
trainer/Policy log std Min         -2.78563
trainer/Alpha                       0.0712302
trainer/Alpha Loss                  0.281722
exploration/num steps total    106200
exploration/num paths total      1062
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -2.10783
exploration/Rewards Std             1.97875
exploration/Rewards Max            -0.0161641
exploration/Rewards Min           -10.3059
exploration/Returns Mean         -210.783
exploration/Returns Std           184.761
exploration/Returns Max           -32.2648
exploration/Returns Min          -525.851
exploration/Actions Mean           -0.00568033
exploration/Actions Std             0.211564
exploration/Actions Max             0.989724
exploration/Actions Min            -0.999747
exploration/Num Paths               5
exploration/Average Returns      -210.783
evaluation/num steps total     318000
evaluation/num paths total       3180
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.0863
evaluation/Rewards Std              1.09408
evaluation/Rewards Max             -0.0641789
evaluation/Rewards Min             -8.68074
evaluation/Returns Mean          -108.63
evaluation/Returns Std             76.0346
evaluation/Returns Max            -24.279
evaluation/Returns Min           -265.446
evaluation/Actions Mean             0.00976143
evaluation/Actions Std              0.187995
evaluation/Actions Max              0.999494
evaluation/Actions Min             -0.9991
evaluation/Num Paths               15
evaluation/Average Returns       -108.63
time/data storing (s)               0.00268309
time/evaluation sampling (s)        0.330666
time/exploration sampling (s)       0.140849
time/logging (s)                    0.00478116
time/saving (s)                     0.00192781
time/training (s)                   1.96543
time/epoch (s)                      2.44634
time/total (s)                    519.26
Epoch                             211
-----------------------------  ---------------
2019-04-23 01:22:12.884458 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 212 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   15.3932
trainer/QF2 Loss                   15.4012
trainer/Policy Loss                73.7363
trainer/Q1 Predictions Mean       -72.1971
trainer/Q1 Predictions Std         70.6787
trainer/Q1 Predictions Max        -11.7254
trainer/Q1 Predictions Min       -236.096
trainer/Q2 Predictions Mean       -72.1288
trainer/Q2 Predictions Std         70.6306
trainer/Q2 Predictions Max        -11.8053
trainer/Q2 Predictions Min       -234.866
trainer/Q Targets Mean            -72.7598
trainer/Q Targets Std              72.3927
trainer/Q Targets Max              -0.302891
trainer/Q Targets Min            -237.838
trainer/Log Pis Mean                2.23291
trainer/Log Pis Std                 1.38846
trainer/Log Pis Max                 6.09446
trainer/Log Pis Min                -1.5703
trainer/Policy mu Mean             -0.0890618
trainer/Policy mu Std               0.87654
trainer/Policy mu Max               2.86952
trainer/Policy mu Min              -2.99425
trainer/Policy log std Mean        -1.89785
trainer/Policy log std Std          0.60767
trainer/Policy log std Max         -0.151147
trainer/Policy log std Min         -2.84949
trainer/Alpha                       0.0724195
trainer/Alpha Loss                  0.611457
exploration/num steps total    106700
exploration/num paths total      1067
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.684544
exploration/Rewards Std             1.02379
exploration/Rewards Max            -0.0076102
exploration/Rewards Min           -10.61
exploration/Returns Mean          -68.4544
exploration/Returns Std            42.5139
exploration/Returns Max           -24.2563
exploration/Returns Min          -139.783
exploration/Actions Mean           -0.00965159
exploration/Actions Std             0.241408
exploration/Actions Max             0.997626
exploration/Actions Min            -0.997936
exploration/Num Paths               5
exploration/Average Returns       -68.4544
evaluation/num steps total     319500
evaluation/num paths total       3195
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.85731
evaluation/Rewards Std              1.71957
evaluation/Rewards Max             -0.0370297
evaluation/Rewards Min            -10.234
evaluation/Returns Mean          -185.731
evaluation/Returns Std            150.454
evaluation/Returns Max            -13.392
evaluation/Returns Min           -416.421
evaluation/Actions Mean             0.00825917
evaluation/Actions Std              0.178146
evaluation/Actions Max              0.998045
evaluation/Actions Min             -0.99979
evaluation/Num Paths               15
evaluation/Average Returns       -185.731
time/data storing (s)               0.00273154
time/evaluation sampling (s)        0.327747
time/exploration sampling (s)       0.136187
time/logging (s)                    0.00489921
time/saving (s)                     0.0102234
time/training (s)                   2.00298
time/epoch (s)                      2.48476
time/total (s)                    521.749
Epoch                             212
-----------------------------  ---------------
2019-04-23 01:22:15.359295 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 213 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                  166.636
trainer/QF2 Loss                  166.661
trainer/Policy Loss                71.9265
trainer/Q1 Predictions Mean       -70.3829
trainer/Q1 Predictions Std         62.9588
trainer/Q1 Predictions Max        -11.8519
trainer/Q1 Predictions Min       -235.825
trainer/Q2 Predictions Mean       -70.3551
trainer/Q2 Predictions Std         62.957
trainer/Q2 Predictions Max        -11.8564
trainer/Q2 Predictions Min       -236.337
trainer/Q Targets Mean            -68.6122
trainer/Q Targets Std              64.0833
trainer/Q Targets Max              -0.222148
trainer/Q Targets Min            -236.828
trainer/Log Pis Mean                2.21899
trainer/Log Pis Std                 1.2268
trainer/Log Pis Max                 6.65873
trainer/Log Pis Min                -1.83912
trainer/Policy mu Mean             -0.191923
trainer/Policy mu Std               0.827321
trainer/Policy mu Max               2.83874
trainer/Policy mu Min              -2.96529
trainer/Policy log std Mean        -1.98562
trainer/Policy log std Std          0.564201
trainer/Policy log std Max         -0.271198
trainer/Policy log std Min         -2.77103
trainer/Alpha                       0.0757411
trainer/Alpha Loss                  0.565096
exploration/num steps total    107200
exploration/num paths total      1072
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.55704
exploration/Rewards Std             1.68225
exploration/Rewards Max            -0.00948116
exploration/Rewards Min            -9.49295
exploration/Returns Mean         -155.704
exploration/Returns Std           145.965
exploration/Returns Max           -37.1037
exploration/Returns Min          -402.885
exploration/Actions Mean            0.00020519
exploration/Actions Std             0.212857
exploration/Actions Max             0.991327
exploration/Actions Min            -0.999981
exploration/Num Paths               5
exploration/Average Returns      -155.704
evaluation/num steps total     321000
evaluation/num paths total       3210
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.13089
evaluation/Rewards Std              1.3425
evaluation/Rewards Max             -0.157147
evaluation/Rewards Min            -10.7258
evaluation/Returns Mean          -113.089
evaluation/Returns Std            108.394
evaluation/Returns Max            -27.7943
evaluation/Returns Min           -389.078
evaluation/Actions Mean             0.0212098
evaluation/Actions Std              0.177616
evaluation/Actions Max              0.999695
evaluation/Actions Min             -0.999797
evaluation/Num Paths               15
evaluation/Average Returns       -113.089
time/data storing (s)               0.00286535
time/evaluation sampling (s)        0.328202
time/exploration sampling (s)       0.13896
time/logging (s)                    0.00476806
time/saving (s)                     0.00195358
time/training (s)                   1.99003
time/epoch (s)                      2.46678
time/total (s)                    524.22
Epoch                             213
-----------------------------  ---------------
2019-04-23 01:22:17.832052 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 214 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    4.51749
trainer/QF2 Loss                    4.52396
trainer/Policy Loss                80.4633
trainer/Q1 Predictions Mean       -79.0893
trainer/Q1 Predictions Std         72.2317
trainer/Q1 Predictions Max        -11.6305
trainer/Q1 Predictions Min       -240.014
trainer/Q2 Predictions Mean       -79.0687
trainer/Q2 Predictions Std         72.237
trainer/Q2 Predictions Max        -11.6811
trainer/Q2 Predictions Min       -239.812
trainer/Q Targets Mean            -79.0844
trainer/Q Targets Std              72.7563
trainer/Q Targets Max              -0.441574
trainer/Q Targets Min            -236.672
trainer/Log Pis Mean                1.99418
trainer/Log Pis Std                 1.37345
trainer/Log Pis Max                 7.49912
trainer/Log Pis Min                -1.9313
trainer/Policy mu Mean             -0.0962058
trainer/Policy mu Std               0.831243
trainer/Policy mu Max               2.7681
trainer/Policy mu Min              -3.42993
trainer/Policy log std Mean        -1.93737
trainer/Policy log std Std          0.544878
trainer/Policy log std Max          0.268808
trainer/Policy log std Min         -2.63769
trainer/Alpha                       0.0771147
trainer/Alpha Loss                 -0.0149098
exploration/num steps total    107700
exploration/num paths total      1077
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.75841
exploration/Rewards Std             1.44931
exploration/Rewards Max            -0.0231783
exploration/Rewards Min            -8.58535
exploration/Returns Mean         -175.841
exploration/Returns Std           132.72
exploration/Returns Max           -31.5701
exploration/Returns Min          -374.771
exploration/Actions Mean            0.00835085
exploration/Actions Std             0.23421
exploration/Actions Max             0.998846
exploration/Actions Min            -0.999641
exploration/Num Paths               5
exploration/Average Returns      -175.841
evaluation/num steps total     322500
evaluation/num paths total       3225
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.23434
evaluation/Rewards Std              1.23964
evaluation/Rewards Max             -0.0148584
evaluation/Rewards Min             -9.87171
evaluation/Returns Mean          -123.434
evaluation/Returns Std             92.3611
evaluation/Returns Max             -6.18203
evaluation/Returns Min           -293.028
evaluation/Actions Mean            -0.00868002
evaluation/Actions Std              0.184156
evaluation/Actions Max              0.997313
evaluation/Actions Min             -0.999947
evaluation/Num Paths               15
evaluation/Average Returns       -123.434
time/data storing (s)               0.00274653
time/evaluation sampling (s)        0.329593
time/exploration sampling (s)       0.142121
time/logging (s)                    0.00480061
time/saving (s)                     0.00194746
time/training (s)                   1.9836
time/epoch (s)                      2.46481
time/total (s)                    526.689
Epoch                             214
-----------------------------  ---------------
2019-04-23 01:22:20.301263 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 215 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   55.3143
trainer/QF2 Loss                   55.2775
trainer/Policy Loss                81.5588
trainer/Q1 Predictions Mean       -80.3327
trainer/Q1 Predictions Std         70.3202
trainer/Q1 Predictions Max        -11.6199
trainer/Q1 Predictions Min       -232.506
trainer/Q2 Predictions Mean       -80.3532
trainer/Q2 Predictions Std         70.3649
trainer/Q2 Predictions Max        -11.651
trainer/Q2 Predictions Min       -232.39
trainer/Q Targets Mean            -80.4271
trainer/Q Targets Std              71.4155
trainer/Q Targets Max              -1.68181
trainer/Q Targets Min            -235.653
trainer/Log Pis Mean                1.79992
trainer/Log Pis Std                 1.20111
trainer/Log Pis Max                 5.81398
trainer/Log Pis Min                -2.14893
trainer/Policy mu Mean              0.0747038
trainer/Policy mu Std               0.695224
trainer/Policy mu Max               3.24725
trainer/Policy mu Min              -2.34057
trainer/Policy log std Mean        -2.0249
trainer/Policy log std Std          0.472499
trainer/Policy log std Max         -0.143901
trainer/Policy log std Min         -2.69785
trainer/Alpha                       0.0762127
trainer/Alpha Loss                 -0.515076
exploration/num steps total    108200
exploration/num paths total      1082
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -3.59239
exploration/Rewards Std             1.81386
exploration/Rewards Max            -0.293214
exploration/Rewards Min            -6.24125
exploration/Returns Mean         -359.239
exploration/Returns Std           178.364
exploration/Returns Max          -143.618
exploration/Returns Min          -578.453
exploration/Actions Mean            0.0199307
exploration/Actions Std             0.181232
exploration/Actions Max             0.996585
exploration/Actions Min            -0.659109
exploration/Num Paths               5
exploration/Average Returns      -359.239
evaluation/num steps total     324000
evaluation/num paths total       3240
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.35982
evaluation/Rewards Std              1.97425
evaluation/Rewards Max             -0.0234742
evaluation/Rewards Min             -8.12892
evaluation/Returns Mean          -135.982
evaluation/Returns Std            188.419
evaluation/Returns Max            -10.7436
evaluation/Returns Min           -591.105
evaluation/Actions Mean             0.00909604
evaluation/Actions Std              0.158122
evaluation/Actions Max              0.998675
evaluation/Actions Min             -0.997488
evaluation/Num Paths               15
evaluation/Average Returns       -135.982
time/data storing (s)               0.00278937
time/evaluation sampling (s)        0.33076
time/exploration sampling (s)       0.137821
time/logging (s)                    0.00369514
time/saving (s)                     0.00195731
time/training (s)                   1.98325
time/epoch (s)                      2.46027
time/total (s)                    529.154
Epoch                             215
-----------------------------  ---------------
2019-04-23 01:22:22.761034 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 216 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    3.56822
trainer/QF2 Loss                    3.82416
trainer/Policy Loss                71.0666
trainer/Q1 Predictions Mean       -69.6456
trainer/Q1 Predictions Std         67.2342
trainer/Q1 Predictions Max        -11.079
trainer/Q1 Predictions Min       -232.153
trainer/Q2 Predictions Mean       -69.5998
trainer/Q2 Predictions Std         67.1795
trainer/Q2 Predictions Max        -11.0138
trainer/Q2 Predictions Min       -231.214
trainer/Q Targets Mean            -70.6784
trainer/Q Targets Std              67.9987
trainer/Q Targets Max              -0.328422
trainer/Q Targets Min            -235.589
trainer/Log Pis Mean                2.04504
trainer/Log Pis Std                 1.3707
trainer/Log Pis Max                 6.96708
trainer/Log Pis Min                -0.535487
trainer/Policy mu Mean             -0.155668
trainer/Policy mu Std               0.848737
trainer/Policy mu Max               3.6774
trainer/Policy mu Min              -2.96624
trainer/Policy log std Mean        -1.93771
trainer/Policy log std Std          0.612126
trainer/Policy log std Max         -0.107051
trainer/Policy log std Min         -2.79233
trainer/Alpha                       0.0773694
trainer/Alpha Loss                  0.115268
exploration/num steps total    108700
exploration/num paths total      1087
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.84086
exploration/Rewards Std             2.01431
exploration/Rewards Max            -0.0122872
exploration/Rewards Min            -6.95463
exploration/Returns Mean         -184.086
exploration/Returns Std           196.13
exploration/Returns Max           -16.4943
exploration/Returns Min          -512.609
exploration/Actions Mean           -0.0223188
exploration/Actions Std             0.211467
exploration/Actions Max             0.589331
exploration/Actions Min            -0.997712
exploration/Num Paths               5
exploration/Average Returns      -184.086
evaluation/num steps total     325500
evaluation/num paths total       3255
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.92926
evaluation/Rewards Std              1.51614
evaluation/Rewards Max             -0.0285089
evaluation/Rewards Min            -10.3455
evaluation/Returns Mean          -192.926
evaluation/Returns Std            125.012
evaluation/Returns Max            -46.5418
evaluation/Returns Min           -505.146
evaluation/Actions Mean             0.00734516
evaluation/Actions Std              0.19011
evaluation/Actions Max              0.999257
evaluation/Actions Min             -0.999666
evaluation/Num Paths               15
evaluation/Average Returns       -192.926
time/data storing (s)               0.00405021
time/evaluation sampling (s)        0.331962
time/exploration sampling (s)       0.138456
time/logging (s)                    0.00475719
time/saving (s)                     0.00155306
time/training (s)                   1.97223
time/epoch (s)                      2.453
time/total (s)                    531.611
Epoch                             216
-----------------------------  ---------------
2019-04-23 01:22:25.235227 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 217 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    2.05673
trainer/QF2 Loss                    1.92831
trainer/Policy Loss                73.7316
trainer/Q1 Predictions Mean       -72.2932
trainer/Q1 Predictions Std         64.9128
trainer/Q1 Predictions Max        -10.9911
trainer/Q1 Predictions Min       -231.255
trainer/Q2 Predictions Mean       -72.2956
trainer/Q2 Predictions Std         64.9323
trainer/Q2 Predictions Max        -11.074
trainer/Q2 Predictions Min       -231.574
trainer/Q Targets Mean            -73.3478
trainer/Q Targets Std              65.6955
trainer/Q Targets Max             -11.3186
trainer/Q Targets Min            -235.081
trainer/Log Pis Mean                2.02095
trainer/Log Pis Std                 1.15518
trainer/Log Pis Max                 6.47219
trainer/Log Pis Min                -1.83968
trainer/Policy mu Mean             -0.00435264
trainer/Policy mu Std               0.681784
trainer/Policy mu Max               3.13246
trainer/Policy mu Min              -2.44921
trainer/Policy log std Mean        -2.06746
trainer/Policy log std Std          0.481496
trainer/Policy log std Max         -0.368285
trainer/Policy log std Min         -2.83006
trainer/Alpha                       0.0736016
trainer/Alpha Loss                  0.0546682
exploration/num steps total    109200
exploration/num paths total      1092
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.23441
exploration/Rewards Std             0.930894
exploration/Rewards Max            -0.0172444
exploration/Rewards Min            -6.4876
exploration/Returns Mean         -123.441
exploration/Returns Std            76.5035
exploration/Returns Max           -35.2983
exploration/Returns Min          -258.09
exploration/Actions Mean            0.00805466
exploration/Actions Std             0.199827
exploration/Actions Max             0.999167
exploration/Actions Min            -0.97959
exploration/Num Paths               5
exploration/Average Returns      -123.441
evaluation/num steps total     327000
evaluation/num paths total       3270
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.23853
evaluation/Rewards Std              1.41135
evaluation/Rewards Max             -0.00251786
evaluation/Rewards Min             -9.87397
evaluation/Returns Mean          -123.853
evaluation/Returns Std            122.683
evaluation/Returns Max             -2.18748
evaluation/Returns Min           -443.494
evaluation/Actions Mean             0.00412535
evaluation/Actions Std              0.161422
evaluation/Actions Max              0.998971
evaluation/Actions Min             -0.991772
evaluation/Num Paths               15
evaluation/Average Returns       -123.853
time/data storing (s)               0.00283104
time/evaluation sampling (s)        0.334528
time/exploration sampling (s)       0.141125
time/logging (s)                    0.004754
time/saving (s)                     0.00194571
time/training (s)                   1.98092
time/epoch (s)                      2.4661
time/total (s)                    534.082
Epoch                             217
-----------------------------  ---------------
2019-04-23 01:22:27.699493 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 218 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    2.20634
trainer/QF2 Loss                    2.40738
trainer/Policy Loss                86.528
trainer/Q1 Predictions Mean       -85.2914
trainer/Q1 Predictions Std         80.3446
trainer/Q1 Predictions Max        -10.9994
trainer/Q1 Predictions Min       -228.286
trainer/Q2 Predictions Mean       -85.2244
trainer/Q2 Predictions Std         80.3165
trainer/Q2 Predictions Max        -11.1824
trainer/Q2 Predictions Min       -228.859
trainer/Q Targets Mean            -86.3074
trainer/Q Targets Std              81.2795
trainer/Q Targets Max             -11.2923
trainer/Q Targets Min            -231.708
trainer/Log Pis Mean                1.62391
trainer/Log Pis Std                 1.44919
trainer/Log Pis Max                 6.27635
trainer/Log Pis Min                -2.74371
trainer/Policy mu Mean              0.0141691
trainer/Policy mu Std               0.62298
trainer/Policy mu Max               3.48365
trainer/Policy mu Min              -2.08035
trainer/Policy log std Mean        -2.01095
trainer/Policy log std Std          0.481564
trainer/Policy log std Max         -0.367485
trainer/Policy log std Min         -2.68668
trainer/Alpha                       0.0735438
trainer/Alpha Loss                 -0.981472
exploration/num steps total    109700
exploration/num paths total      1097
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.29187
exploration/Rewards Std             1.70456
exploration/Rewards Max            -0.0171616
exploration/Rewards Min            -8.67516
exploration/Returns Mean         -129.187
exploration/Returns Std           145.883
exploration/Returns Max           -18.8127
exploration/Returns Min          -414.826
exploration/Actions Mean           -0.0051815
exploration/Actions Std             0.242078
exploration/Actions Max             0.999014
exploration/Actions Min            -0.999388
exploration/Num Paths               5
exploration/Average Returns      -129.187
evaluation/num steps total     328500
evaluation/num paths total       3285
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.48492
evaluation/Rewards Std              1.72478
evaluation/Rewards Max             -0.00861365
evaluation/Rewards Min            -11.3317
evaluation/Returns Mean          -148.492
evaluation/Returns Std            147.226
evaluation/Returns Max            -21.2147
evaluation/Returns Min           -443.139
evaluation/Actions Mean            -0.0109678
evaluation/Actions Std              0.188443
evaluation/Actions Max              0.999089
evaluation/Actions Min             -0.999796
evaluation/Num Paths               15
evaluation/Average Returns       -148.492
time/data storing (s)               0.00295722
time/evaluation sampling (s)        0.324375
time/exploration sampling (s)       0.136972
time/logging (s)                    0.00464016
time/saving (s)                     0.00155106
time/training (s)                   1.98564
time/epoch (s)                      2.45614
time/total (s)                    536.543
Epoch                             218
-----------------------------  ---------------
2019-04-23 01:22:30.158223 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 219 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                  186.183
trainer/QF2 Loss                  185.384
trainer/Policy Loss                69.8421
trainer/Q1 Predictions Mean       -68.2718
trainer/Q1 Predictions Std         71.5916
trainer/Q1 Predictions Max        -11.2643
trainer/Q1 Predictions Min       -227.947
trainer/Q2 Predictions Mean       -68.2813
trainer/Q2 Predictions Std         71.5598
trainer/Q2 Predictions Max        -11.2191
trainer/Q2 Predictions Min       -227.361
trainer/Q Targets Mean            -67.1414
trainer/Q Targets Std              72.6636
trainer/Q Targets Max              -1.0871
trainer/Q Targets Min            -230.105
trainer/Log Pis Mean                1.96917
trainer/Log Pis Std                 1.36649
trainer/Log Pis Max                 6.13969
trainer/Log Pis Min                -4.40193
trainer/Policy mu Mean              0.00380104
trainer/Policy mu Std               0.582972
trainer/Policy mu Max               2.49457
trainer/Policy mu Min              -2.42426
trainer/Policy log std Mean        -2.16491
trainer/Policy log std Std          0.46555
trainer/Policy log std Max         -0.439341
trainer/Policy log std Min         -2.68595
trainer/Alpha                       0.0764116
trainer/Alpha Loss                 -0.079281
exploration/num steps total    110200
exploration/num paths total      1102
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.748199
exploration/Rewards Std             0.972803
exploration/Rewards Max            -0.00831184
exploration/Rewards Min            -7.88822
exploration/Returns Mean          -74.8199
exploration/Returns Std            43.6096
exploration/Returns Max           -35.9006
exploration/Returns Min          -152.371
exploration/Actions Mean            0.00237102
exploration/Actions Std             0.223234
exploration/Actions Max             0.995193
exploration/Actions Min            -0.997464
exploration/Num Paths               5
exploration/Average Returns       -74.8199
evaluation/num steps total     330000
evaluation/num paths total       3300
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.99548
evaluation/Rewards Std              1.46619
evaluation/Rewards Max             -0.0204922
evaluation/Rewards Min            -10.5006
evaluation/Returns Mean          -199.548
evaluation/Returns Std            117.18
evaluation/Returns Max            -43.9215
evaluation/Returns Min           -393.238
evaluation/Actions Mean            -0.00116659
evaluation/Actions Std              0.181844
evaluation/Actions Max              0.999757
evaluation/Actions Min             -0.996818
evaluation/Num Paths               15
evaluation/Average Returns       -199.548
time/data storing (s)               0.00281826
time/evaluation sampling (s)        0.328153
time/exploration sampling (s)       0.138661
time/logging (s)                    0.00481798
time/saving (s)                     0.00196862
time/training (s)                   1.97445
time/epoch (s)                      2.45087
time/total (s)                    538.998
Epoch                             219
-----------------------------  ---------------
2019-04-23 01:22:32.612359 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 220 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   22.8797
trainer/QF2 Loss                   23.0345
trainer/Policy Loss                77.7728
trainer/Q1 Predictions Mean       -76.5393
trainer/Q1 Predictions Std         66.4138
trainer/Q1 Predictions Max        -11.4971
trainer/Q1 Predictions Min       -227.716
trainer/Q2 Predictions Mean       -76.4763
trainer/Q2 Predictions Std         66.3923
trainer/Q2 Predictions Max        -11.5799
trainer/Q2 Predictions Min       -228.343
trainer/Q Targets Mean            -76.6557
trainer/Q Targets Std              67.8026
trainer/Q Targets Max              -0.34246
trainer/Q Targets Min            -231.536
trainer/Log Pis Mean                1.84846
trainer/Log Pis Std                 1.2064
trainer/Log Pis Max                 4.98097
trainer/Log Pis Min                -2.04772
trainer/Policy mu Mean              0.0967623
trainer/Policy mu Std               0.692377
trainer/Policy mu Max               2.07792
trainer/Policy mu Min              -2.65189
trainer/Policy log std Mean        -2.02497
trainer/Policy log std Std          0.485991
trainer/Policy log std Max         -0.631849
trainer/Policy log std Min         -2.62212
trainer/Alpha                       0.0770837
trainer/Alpha Loss                 -0.388381
exploration/num steps total    110700
exploration/num paths total      1107
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -2.04456
exploration/Rewards Std             0.959051
exploration/Rewards Max            -0.748717
exploration/Rewards Min            -9.18715
exploration/Returns Mean         -204.456
exploration/Returns Std            71.6606
exploration/Returns Max          -140.49
exploration/Returns Min          -295.598
exploration/Actions Mean           -0.0170098
exploration/Actions Std             0.207087
exploration/Actions Max             0.997444
exploration/Actions Min            -0.996804
exploration/Num Paths               5
exploration/Average Returns      -204.456
evaluation/num steps total     331500
evaluation/num paths total       3315
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -2.04651
evaluation/Rewards Std              2.02246
evaluation/Rewards Max             -0.0563164
evaluation/Rewards Min             -9.07491
evaluation/Returns Mean          -204.651
evaluation/Returns Std            189.015
evaluation/Returns Max            -13.0295
evaluation/Returns Min           -629.983
evaluation/Actions Mean             0.00998954
evaluation/Actions Std              0.166943
evaluation/Actions Max              0.999594
evaluation/Actions Min             -0.996649
evaluation/Num Paths               15
evaluation/Average Returns       -204.651
time/data storing (s)               0.00273953
time/evaluation sampling (s)        0.328118
time/exploration sampling (s)       0.140152
time/logging (s)                    0.00497652
time/saving (s)                     0.00198734
time/training (s)                   1.96943
time/epoch (s)                      2.4474
time/total (s)                    541.449
Epoch                             220
-----------------------------  ---------------
2019-04-23 01:22:35.060464 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 221 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                  485.171
trainer/QF2 Loss                  486.453
trainer/Policy Loss                79.87
trainer/Q1 Predictions Mean       -78.4967
trainer/Q1 Predictions Std         74.6087
trainer/Q1 Predictions Max        -11.2471
trainer/Q1 Predictions Min       -227.762
trainer/Q2 Predictions Mean       -78.5019
trainer/Q2 Predictions Std         74.5762
trainer/Q2 Predictions Max        -11.2371
trainer/Q2 Predictions Min       -227.474
trainer/Q Targets Mean            -77.4817
trainer/Q Targets Std              74.7524
trainer/Q Targets Max              -0.492326
trainer/Q Targets Min            -231.727
trainer/Log Pis Mean                1.96769
trainer/Log Pis Std                 1.18914
trainer/Log Pis Max                 6.322
trainer/Log Pis Min                -1.43617
trainer/Policy mu Mean             -0.0974872
trainer/Policy mu Std               0.753525
trainer/Policy mu Max               3.06988
trainer/Policy mu Min              -2.91841
trainer/Policy log std Mean        -2.00513
trainer/Policy log std Std          0.550188
trainer/Policy log std Max         -0.295048
trainer/Policy log std Min         -2.6789
trainer/Alpha                       0.0767695
trainer/Alpha Loss                 -0.0829218
exploration/num steps total    111200
exploration/num paths total      1112
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -2.1125
exploration/Rewards Std             1.78592
exploration/Rewards Max            -0.036444
exploration/Rewards Min            -9.35592
exploration/Returns Mean         -211.25
exploration/Returns Std           160.596
exploration/Returns Max           -42.8523
exploration/Returns Min          -406.535
exploration/Actions Mean           -0.0163995
exploration/Actions Std             0.243673
exploration/Actions Max             0.999547
exploration/Actions Min            -0.999709
exploration/Num Paths               5
exploration/Average Returns      -211.25
evaluation/num steps total     333000
evaluation/num paths total       3330
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.49425
evaluation/Rewards Std              1.43802
evaluation/Rewards Max             -0.112895
evaluation/Rewards Min            -10.0672
evaluation/Returns Mean          -149.425
evaluation/Returns Std            110.696
evaluation/Returns Max            -25.3285
evaluation/Returns Min           -381.532
evaluation/Actions Mean             0.00833076
evaluation/Actions Std              0.180287
evaluation/Actions Max              0.999699
evaluation/Actions Min             -0.99907
evaluation/Num Paths               15
evaluation/Average Returns       -149.425
time/data storing (s)               0.00286045
time/evaluation sampling (s)        0.326036
time/exploration sampling (s)       0.140281
time/logging (s)                    0.00475039
time/saving (s)                     0.00189889
time/training (s)                   1.96377
time/epoch (s)                      2.4396
time/total (s)                    543.893
Epoch                             221
-----------------------------  ---------------
2019-04-23 01:22:37.529574 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 222 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    4.41374
trainer/QF2 Loss                    4.63933
trainer/Policy Loss                84.8945
trainer/Q1 Predictions Mean       -83.3919
trainer/Q1 Predictions Std         78.3018
trainer/Q1 Predictions Max        -10.8088
trainer/Q1 Predictions Min       -230.648
trainer/Q2 Predictions Mean       -83.3969
trainer/Q2 Predictions Std         78.2395
trainer/Q2 Predictions Max        -10.8227
trainer/Q2 Predictions Min       -230.101
trainer/Q Targets Mean            -84.2785
trainer/Q Targets Std              79.3407
trainer/Q Targets Max              -0.233782
trainer/Q Targets Min            -232.996
trainer/Log Pis Mean                2.14704
trainer/Log Pis Std                 1.59362
trainer/Log Pis Max                 5.98985
trainer/Log Pis Min                -3.87741
trainer/Policy mu Mean             -0.108346
trainer/Policy mu Std               0.909091
trainer/Policy mu Max               2.62113
trainer/Policy mu Min              -2.9746
trainer/Policy log std Mean        -1.93192
trainer/Policy log std Std          0.606745
trainer/Policy log std Max         -0.441436
trainer/Policy log std Min         -2.75669
trainer/Alpha                       0.0762439
trainer/Alpha Loss                  0.378451
exploration/num steps total    111700
exploration/num paths total      1117
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.60865
exploration/Rewards Std             1.33598
exploration/Rewards Max            -0.0182138
exploration/Rewards Min           -10.2105
exploration/Returns Mean         -160.865
exploration/Returns Std            80.4002
exploration/Returns Max           -41.8212
exploration/Returns Min          -267.805
exploration/Actions Mean            0.0118034
exploration/Actions Std             0.223002
exploration/Actions Max             0.999911
exploration/Actions Min            -0.999688
exploration/Num Paths               5
exploration/Average Returns      -160.865
evaluation/num steps total     334500
evaluation/num paths total       3345
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.868
evaluation/Rewards Std              2.01863
evaluation/Rewards Max             -0.0539978
evaluation/Rewards Min             -9.82306
evaluation/Returns Mean          -186.8
evaluation/Returns Std            180.864
evaluation/Returns Max            -14.0363
evaluation/Returns Min           -452.924
evaluation/Actions Mean            -0.0104267
evaluation/Actions Std              0.184754
evaluation/Actions Max              0.999414
evaluation/Actions Min             -0.999393
evaluation/Num Paths               15
evaluation/Average Returns       -186.8
time/data storing (s)               0.00277476
time/evaluation sampling (s)        0.3301
time/exploration sampling (s)       0.139767
time/logging (s)                    0.00495575
time/saving (s)                     0.00193883
time/training (s)                   1.98222
time/epoch (s)                      2.46176
time/total (s)                    546.359
Epoch                             222
-----------------------------  ---------------
2019-04-23 01:22:39.997180 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 223 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                  510.534
trainer/QF2 Loss                  509.955
trainer/Policy Loss                64.0431
trainer/Q1 Predictions Mean       -62.2999
trainer/Q1 Predictions Std         63.9358
trainer/Q1 Predictions Max        -11.1289
trainer/Q1 Predictions Min       -230.504
trainer/Q2 Predictions Mean       -62.2909
trainer/Q2 Predictions Std         63.8825
trainer/Q2 Predictions Max        -11.2511
trainer/Q2 Predictions Min       -230.127
trainer/Q Targets Mean            -60.0132
trainer/Q Targets Std              62.4987
trainer/Q Targets Max              -0.260616
trainer/Q Targets Min            -232.146
trainer/Log Pis Mean                2.18386
trainer/Log Pis Std                 1.32524
trainer/Log Pis Max                 8.42237
trainer/Log Pis Min                -1.21623
trainer/Policy mu Mean             -0.0557077
trainer/Policy mu Std               0.690779
trainer/Policy mu Max               3.1695
trainer/Policy mu Min              -3.59039
trainer/Policy log std Mean        -2.15633
trainer/Policy log std Std          0.486387
trainer/Policy log std Max         -0.503647
trainer/Policy log std Min         -2.83268
trainer/Alpha                       0.0731272
trainer/Alpha Loss                  0.480897
exploration/num steps total    112200
exploration/num paths total      1122
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.71353
exploration/Rewards Std             1.28704
exploration/Rewards Max            -0.00670275
exploration/Rewards Min            -8.28609
exploration/Returns Mean         -171.353
exploration/Returns Std           120.319
exploration/Returns Max           -20.6975
exploration/Returns Min          -336.725
exploration/Actions Mean            0.00740935
exploration/Actions Std             0.220326
exploration/Actions Max             0.999551
exploration/Actions Min            -0.999472
exploration/Num Paths               5
exploration/Average Returns      -171.353
evaluation/num steps total     336000
evaluation/num paths total       3360
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.53061
evaluation/Rewards Std              1.37285
evaluation/Rewards Max             -0.0632481
evaluation/Rewards Min            -10.1328
evaluation/Returns Mean          -153.061
evaluation/Returns Std            120.306
evaluation/Returns Max            -11.7204
evaluation/Returns Min           -343.232
evaluation/Actions Mean            -0.00386406
evaluation/Actions Std              0.165259
evaluation/Actions Max              0.998384
evaluation/Actions Min             -0.997384
evaluation/Num Paths               15
evaluation/Average Returns       -153.061
time/data storing (s)               0.00284349
time/evaluation sampling (s)        0.32494
time/exploration sampling (s)       0.141658
time/logging (s)                    0.00479409
time/saving (s)                     0.00193937
time/training (s)                   1.98316
time/epoch (s)                      2.45934
time/total (s)                    548.823
Epoch                             223
-----------------------------  ---------------
2019-04-23 01:22:42.463930 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 224 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.48108
trainer/QF2 Loss                    1.44103
trainer/Policy Loss                85.2863
trainer/Q1 Predictions Mean       -83.8402
trainer/Q1 Predictions Std         74.0229
trainer/Q1 Predictions Max        -10.975
trainer/Q1 Predictions Min       -230.736
trainer/Q2 Predictions Mean       -83.8463
trainer/Q2 Predictions Std         74.0693
trainer/Q2 Predictions Max        -11.0139
trainer/Q2 Predictions Min       -231.236
trainer/Q Targets Mean            -84.6892
trainer/Q Targets Std              74.6257
trainer/Q Targets Max             -11.1883
trainer/Q Targets Min            -234.622
trainer/Log Pis Mean                2.02431
trainer/Log Pis Std                 1.2872
trainer/Log Pis Max                 5.25535
trainer/Log Pis Min                -3.31073
trainer/Policy mu Mean              6.51658e-05
trainer/Policy mu Std               0.786905
trainer/Policy mu Max               3.14707
trainer/Policy mu Min              -2.54273
trainer/Policy log std Mean        -1.98396
trainer/Policy log std Std          0.524781
trainer/Policy log std Max         -0.415124
trainer/Policy log std Min         -2.74993
trainer/Alpha                       0.0776348
trainer/Alpha Loss                  0.0621359
exploration/num steps total    112700
exploration/num paths total      1127
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.98709
exploration/Rewards Std             1.63749
exploration/Rewards Max            -0.0202655
exploration/Rewards Min           -10.0468
exploration/Returns Mean         -198.709
exploration/Returns Std           139.007
exploration/Returns Max           -47.1941
exploration/Returns Min          -363.654
exploration/Actions Mean           -0.00466076
exploration/Actions Std             0.272034
exploration/Actions Max             0.999131
exploration/Actions Min            -0.997414
exploration/Num Paths               5
exploration/Average Returns      -198.709
evaluation/num steps total     337500
evaluation/num paths total       3375
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.79035
evaluation/Rewards Std              1.49696
evaluation/Rewards Max             -0.02856
evaluation/Rewards Min            -10.7335
evaluation/Returns Mean          -179.035
evaluation/Returns Std            127.9
evaluation/Returns Max             -5.16923
evaluation/Returns Min           -377.266
evaluation/Actions Mean            -0.00649505
evaluation/Actions Std              0.176269
evaluation/Actions Max              0.999051
evaluation/Actions Min             -0.999243
evaluation/Num Paths               15
evaluation/Average Returns       -179.035
time/data storing (s)               0.00278111
time/evaluation sampling (s)        0.328292
time/exploration sampling (s)       0.136205
time/logging (s)                    0.00478945
time/saving (s)                     0.0101612
time/training (s)                   1.97675
time/epoch (s)                      2.45898
time/total (s)                    551.286
Epoch                             224
-----------------------------  ----------------
2019-04-23 01:22:44.929159 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 225 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                  478.571
trainer/QF2 Loss                  478.05
trainer/Policy Loss                81.0266
trainer/Q1 Predictions Mean       -79.3409
trainer/Q1 Predictions Std         72.646
trainer/Q1 Predictions Max        -11.2455
trainer/Q1 Predictions Min       -233.483
trainer/Q2 Predictions Mean       -79.3154
trainer/Q2 Predictions Std         72.581
trainer/Q2 Predictions Max        -11.2596
trainer/Q2 Predictions Min       -233.705
trainer/Q Targets Mean            -77.4403
trainer/Q Targets Std              71.7285
trainer/Q Targets Max              -3.90348
trainer/Q Targets Min            -233.362
trainer/Log Pis Mean                2.12683
trainer/Log Pis Std                 1.01569
trainer/Log Pis Max                 5.33942
trainer/Log Pis Min                -2.10212
trainer/Policy mu Mean             -0.120502
trainer/Policy mu Std               0.720614
trainer/Policy mu Max               4.12659
trainer/Policy mu Min              -2.61605
trainer/Policy log std Mean        -2.06309
trainer/Policy log std Std          0.502628
trainer/Policy log std Max         -0.252475
trainer/Policy log std Min         -2.6959
trainer/Alpha                       0.0780228
trainer/Alpha Loss                  0.32352
exploration/num steps total    113200
exploration/num paths total      1132
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.30137
exploration/Rewards Std             1.31368
exploration/Rewards Max            -0.00941065
exploration/Rewards Min            -9.28354
exploration/Returns Mean         -130.137
exploration/Returns Std           114.828
exploration/Returns Max           -24.8263
exploration/Returns Min          -282.206
exploration/Actions Mean            0.0109611
exploration/Actions Std             0.188994
exploration/Actions Max             0.988356
exploration/Actions Min            -0.998743
exploration/Num Paths               5
exploration/Average Returns      -130.137
evaluation/num steps total     339000
evaluation/num paths total       3390
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.55321
evaluation/Rewards Std              1.56917
evaluation/Rewards Max             -0.0223639
evaluation/Rewards Min             -9.49947
evaluation/Returns Mean          -155.321
evaluation/Returns Std            142.641
evaluation/Returns Max             -9.89333
evaluation/Returns Min           -367.773
evaluation/Actions Mean            -0.00371469
evaluation/Actions Std              0.15997
evaluation/Actions Max              0.997563
evaluation/Actions Min             -0.999011
evaluation/Num Paths               15
evaluation/Average Returns       -155.321
time/data storing (s)               0.00275707
time/evaluation sampling (s)        0.327406
time/exploration sampling (s)       0.135327
time/logging (s)                    0.0038504
time/saving (s)                     0.00197604
time/training (s)                   1.98488
time/epoch (s)                      2.45619
time/total (s)                    553.747
Epoch                             225
-----------------------------  ---------------
2019-04-23 01:22:47.376010 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 226 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   19.1726
trainer/QF2 Loss                   19.4498
trainer/Policy Loss                62.9998
trainer/Q1 Predictions Mean       -61.6486
trainer/Q1 Predictions Std         60.6279
trainer/Q1 Predictions Max        -10.9683
trainer/Q1 Predictions Min       -228.826
trainer/Q2 Predictions Mean       -61.5632
trainer/Q2 Predictions Std         60.5012
trainer/Q2 Predictions Max        -10.9178
trainer/Q2 Predictions Min       -228.459
trainer/Q Targets Mean            -61.6901
trainer/Q Targets Std              61.3093
trainer/Q Targets Max              -1.44956
trainer/Q Targets Min            -230.571
trainer/Log Pis Mean                1.88408
trainer/Log Pis Std                 1.34176
trainer/Log Pis Max                 7.42515
trainer/Log Pis Min                -2.89728
trainer/Policy mu Mean             -0.0814702
trainer/Policy mu Std               0.679141
trainer/Policy mu Max               2.40284
trainer/Policy mu Min              -3.42602
trainer/Policy log std Mean        -2.08721
trainer/Policy log std Std          0.490036
trainer/Policy log std Max         -0.0950605
trainer/Policy log std Min         -2.81571
trainer/Alpha                       0.0785524
trainer/Alpha Loss                 -0.29489
exploration/num steps total    113700
exploration/num paths total      1137
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.876193
exploration/Rewards Std             1.23615
exploration/Rewards Max            -0.0120183
exploration/Rewards Min            -9.81733
exploration/Returns Mean          -87.6193
exploration/Returns Std            73.4052
exploration/Returns Max           -18.6005
exploration/Returns Min          -223.327
exploration/Actions Mean            0.00080543
exploration/Actions Std             0.212985
exploration/Actions Max             0.999918
exploration/Actions Min            -0.999525
exploration/Num Paths               5
exploration/Average Returns       -87.6193
evaluation/num steps total     340500
evaluation/num paths total       3405
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.23608
evaluation/Rewards Std              1.28335
evaluation/Rewards Max             -0.143404
evaluation/Rewards Min            -10.2555
evaluation/Returns Mean          -123.608
evaluation/Returns Std             88.3536
evaluation/Returns Max            -17.7663
evaluation/Returns Min           -286.673
evaluation/Actions Mean            -0.00257547
evaluation/Actions Std              0.175658
evaluation/Actions Max              0.999565
evaluation/Actions Min             -0.997715
evaluation/Num Paths               15
evaluation/Average Returns       -123.608
time/data storing (s)               0.00255611
time/evaluation sampling (s)        0.326988
time/exploration sampling (s)       0.136701
time/logging (s)                    0.00477996
time/saving (s)                     0.00193142
time/training (s)                   1.96675
time/epoch (s)                      2.4397
time/total (s)                    556.191
Epoch                             226
-----------------------------  ---------------
2019-04-23 01:22:49.842743 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 227 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    2.36893
trainer/QF2 Loss                    2.28868
trainer/Policy Loss                68.5489
trainer/Q1 Predictions Mean       -67.2051
trainer/Q1 Predictions Std         67.1372
trainer/Q1 Predictions Max        -10.7366
trainer/Q1 Predictions Min       -229.297
trainer/Q2 Predictions Mean       -67.1766
trainer/Q2 Predictions Std         67.1982
trainer/Q2 Predictions Max        -10.7847
trainer/Q2 Predictions Min       -229.866
trainer/Q Targets Mean            -67.6818
trainer/Q Targets Std              67.8774
trainer/Q Targets Max              -0.223766
trainer/Q Targets Min            -232.445
trainer/Log Pis Mean                1.92727
trainer/Log Pis Std                 1.13044
trainer/Log Pis Max                 4.95818
trainer/Log Pis Min                -1.67761
trainer/Policy mu Mean             -0.0175878
trainer/Policy mu Std               0.697242
trainer/Policy mu Max               3.57726
trainer/Policy mu Min              -2.79514
trainer/Policy log std Mean        -2.04204
trainer/Policy log std Std          0.489428
trainer/Policy log std Max         -0.38805
trainer/Policy log std Min         -2.83877
trainer/Alpha                       0.0748175
trainer/Alpha Loss                 -0.188564
exploration/num steps total    114200
exploration/num paths total      1142
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.982892
exploration/Rewards Std             1.57281
exploration/Rewards Max            -0.00334789
exploration/Rewards Min            -8.63447
exploration/Returns Mean          -98.2892
exploration/Returns Std            98.2461
exploration/Returns Max           -39.2915
exploration/Returns Min          -294.465
exploration/Actions Mean            0.00689033
exploration/Actions Std             0.243079
exploration/Actions Max             0.99953
exploration/Actions Min            -0.999074
exploration/Num Paths               5
exploration/Average Returns       -98.2892
evaluation/num steps total     342000
evaluation/num paths total       3420
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.88314
evaluation/Rewards Std              1.69025
evaluation/Rewards Max             -0.0405835
evaluation/Rewards Min            -10.9559
evaluation/Returns Mean          -188.314
evaluation/Returns Std            146.292
evaluation/Returns Max            -20.6649
evaluation/Returns Min           -418.683
evaluation/Actions Mean            -0.00390846
evaluation/Actions Std              0.185173
evaluation/Actions Max              0.999292
evaluation/Actions Min             -0.998304
evaluation/Num Paths               15
evaluation/Average Returns       -188.314
time/data storing (s)               0.00279107
time/evaluation sampling (s)        0.32651
time/exploration sampling (s)       0.136282
time/logging (s)                    0.0034927
time/saving (s)                     0.00158066
time/training (s)                   1.98704
time/epoch (s)                      2.4577
time/total (s)                    558.653
Epoch                             227
-----------------------------  ---------------
2019-04-23 01:22:52.327316 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 228 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   25.1226
trainer/QF2 Loss                   25.1265
trainer/Policy Loss                74.469
trainer/Q1 Predictions Mean       -72.8227
trainer/Q1 Predictions Std         71.1922
trainer/Q1 Predictions Max        -10.9772
trainer/Q1 Predictions Min       -229.418
trainer/Q2 Predictions Mean       -72.8336
trainer/Q2 Predictions Std         71.1414
trainer/Q2 Predictions Max        -10.9862
trainer/Q2 Predictions Min       -229.46
trainer/Q Targets Mean            -72.5596
trainer/Q Targets Std              72.2648
trainer/Q Targets Max              -0.506286
trainer/Q Targets Min            -231.215
trainer/Log Pis Mean                2.14548
trainer/Log Pis Std                 1.088
trainer/Log Pis Max                 5.96146
trainer/Log Pis Min                -2.40255
trainer/Policy mu Mean             -0.0356942
trainer/Policy mu Std               0.638065
trainer/Policy mu Max               2.92466
trainer/Policy mu Min              -2.44983
trainer/Policy log std Mean        -2.13365
trainer/Policy log std Std          0.466026
trainer/Policy log std Max         -0.359875
trainer/Policy log std Min         -2.7717
trainer/Alpha                       0.0738068
trainer/Alpha Loss                  0.379199
exploration/num steps total    114700
exploration/num paths total      1147
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.6468
exploration/Rewards Std             1.40009
exploration/Rewards Max            -0.118322
exploration/Rewards Min           -10.8159
exploration/Returns Mean         -164.68
exploration/Returns Std            94.7756
exploration/Returns Max           -42.8184
exploration/Returns Min          -322.677
exploration/Actions Mean            0.0107098
exploration/Actions Std             0.240605
exploration/Actions Max             0.999885
exploration/Actions Min            -0.997368
exploration/Num Paths               5
exploration/Average Returns      -164.68
evaluation/num steps total     343500
evaluation/num paths total       3435
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.84126
evaluation/Rewards Std              1.46125
evaluation/Rewards Max             -0.0346635
evaluation/Rewards Min             -9.84741
evaluation/Returns Mean          -184.126
evaluation/Returns Std            132.378
evaluation/Returns Max            -21.7541
evaluation/Returns Min           -377.989
evaluation/Actions Mean             0.00502038
evaluation/Actions Std              0.178353
evaluation/Actions Max              0.999779
evaluation/Actions Min             -0.99951
evaluation/Num Paths               15
evaluation/Average Returns       -184.126
time/data storing (s)               0.00281709
time/evaluation sampling (s)        0.33484
time/exploration sampling (s)       0.138306
time/logging (s)                    0.00477606
time/saving (s)                     0.00194971
time/training (s)                   1.99513
time/epoch (s)                      2.47781
time/total (s)                    561.135
Epoch                             228
-----------------------------  ---------------
2019-04-23 01:22:54.776929 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 229 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.598959
trainer/QF2 Loss                    0.499711
trainer/Policy Loss                80.7753
trainer/Q1 Predictions Mean       -79.4256
trainer/Q1 Predictions Std         77.6551
trainer/Q1 Predictions Max        -11.1115
trainer/Q1 Predictions Min       -236.233
trainer/Q2 Predictions Mean       -79.3929
trainer/Q2 Predictions Std         77.6747
trainer/Q2 Predictions Max        -11.0088
trainer/Q2 Predictions Min       -234.61
trainer/Q Targets Mean            -79.5856
trainer/Q Targets Std              77.8126
trainer/Q Targets Max             -10.9384
trainer/Q Targets Min            -235.439
trainer/Log Pis Mean                1.93382
trainer/Log Pis Std                 1.33903
trainer/Log Pis Max                 6.11791
trainer/Log Pis Min                -1.99419
trainer/Policy mu Mean             -0.246214
trainer/Policy mu Std               0.750782
trainer/Policy mu Max               2.17605
trainer/Policy mu Min              -4.10457
trainer/Policy log std Mean        -1.92718
trainer/Policy log std Std          0.578488
trainer/Policy log std Max          0.74763
trainer/Policy log std Min         -2.71445
trainer/Alpha                       0.0761327
trainer/Alpha Loss                 -0.170421
exploration/num steps total    115200
exploration/num paths total      1152
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.47118
exploration/Rewards Std             1.55924
exploration/Rewards Max            -0.0153247
exploration/Rewards Min            -9.70552
exploration/Returns Mean         -147.118
exploration/Returns Std           123.156
exploration/Returns Max           -29.1453
exploration/Returns Min          -333.083
exploration/Actions Mean           -0.0174888
exploration/Actions Std             0.20758
exploration/Actions Max             0.982759
exploration/Actions Min            -0.999978
exploration/Num Paths               5
exploration/Average Returns      -147.118
evaluation/num steps total     345000
evaluation/num paths total       3450
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.68955
evaluation/Rewards Std              1.52393
evaluation/Rewards Max             -0.0232683
evaluation/Rewards Min            -10.9492
evaluation/Returns Mean          -168.955
evaluation/Returns Std            124.315
evaluation/Returns Max            -21.8521
evaluation/Returns Min           -377.935
evaluation/Actions Mean            -0.0013003
evaluation/Actions Std              0.186289
evaluation/Actions Max              0.998659
evaluation/Actions Min             -0.999939
evaluation/Num Paths               15
evaluation/Average Returns       -168.955
time/data storing (s)               0.00263901
time/evaluation sampling (s)        0.325875
time/exploration sampling (s)       0.138815
time/logging (s)                    0.00369752
time/saving (s)                     0.00155309
time/training (s)                   1.96763
time/epoch (s)                      2.44021
time/total (s)                    563.58
Epoch                             229
-----------------------------  ---------------
2019-04-23 01:22:57.230148 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 230 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.789288
trainer/QF2 Loss                    0.692315
trainer/Policy Loss                75.9807
trainer/Q1 Predictions Mean       -74.4216
trainer/Q1 Predictions Std         64.1987
trainer/Q1 Predictions Max        -11.2257
trainer/Q1 Predictions Min       -228.338
trainer/Q2 Predictions Mean       -74.4497
trainer/Q2 Predictions Std         64.2452
trainer/Q2 Predictions Max        -11.2058
trainer/Q2 Predictions Min       -228.623
trainer/Q Targets Mean            -74.9991
trainer/Q Targets Std              64.5982
trainer/Q Targets Max             -10.9217
trainer/Q Targets Min            -230.74
trainer/Log Pis Mean                1.99824
trainer/Log Pis Std                 1.20367
trainer/Log Pis Max                 5.6248
trainer/Log Pis Min                -2.14552
trainer/Policy mu Mean             -0.115979
trainer/Policy mu Std               0.696373
trainer/Policy mu Max               2.07808
trainer/Policy mu Min              -3.12134
trainer/Policy log std Mean        -2.07551
trainer/Policy log std Std          0.502232
trainer/Policy log std Max         -0.323709
trainer/Policy log std Min         -2.77408
trainer/Alpha                       0.0753022
trainer/Alpha Loss                 -0.00454404
exploration/num steps total    115700
exploration/num paths total      1157
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.26689
exploration/Rewards Std             1.0617
exploration/Rewards Max            -0.00569534
exploration/Rewards Min            -8.29049
exploration/Returns Mean         -126.689
exploration/Returns Std            70.3319
exploration/Returns Max           -32.6942
exploration/Returns Min          -203.433
exploration/Actions Mean            0.021479
exploration/Actions Std             0.211757
exploration/Actions Max             0.999661
exploration/Actions Min            -0.922562
exploration/Num Paths               5
exploration/Average Returns      -126.689
evaluation/num steps total     346500
evaluation/num paths total       3465
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.13575
evaluation/Rewards Std              1.43938
evaluation/Rewards Max             -0.0754558
evaluation/Rewards Min             -9.70499
evaluation/Returns Mean          -113.575
evaluation/Returns Std            102.692
evaluation/Returns Max            -25.9548
evaluation/Returns Min           -289.866
evaluation/Actions Mean             0.018798
evaluation/Actions Std              0.193717
evaluation/Actions Max              0.999551
evaluation/Actions Min             -0.996861
evaluation/Num Paths               15
evaluation/Average Returns       -113.575
time/data storing (s)               0.00280732
time/evaluation sampling (s)        0.331227
time/exploration sampling (s)       0.140635
time/logging (s)                    0.0047327
time/saving (s)                     0.00194003
time/training (s)                   1.96533
time/epoch (s)                      2.44667
time/total (s)                    566.031
Epoch                             230
-----------------------------  ---------------
2019-04-23 01:22:59.676266 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 231 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.532423
trainer/QF2 Loss                    0.649367
trainer/Policy Loss                70.9602
trainer/Q1 Predictions Mean       -69.2539
trainer/Q1 Predictions Std         66.1924
trainer/Q1 Predictions Max        -11.2349
trainer/Q1 Predictions Min       -228.014
trainer/Q2 Predictions Mean       -69.3219
trainer/Q2 Predictions Std         66.1623
trainer/Q2 Predictions Max        -11.1786
trainer/Q2 Predictions Min       -228.056
trainer/Q Targets Mean            -69.4391
trainer/Q Targets Std              66.4133
trainer/Q Targets Max             -11.0411
trainer/Q Targets Min            -228.977
trainer/Log Pis Mean                2.16287
trainer/Log Pis Std                 1.50543
trainer/Log Pis Max                 7.62452
trainer/Log Pis Min                -5.17573
trainer/Policy mu Mean              0.0364839
trainer/Policy mu Std               0.819324
trainer/Policy mu Max               3.20139
trainer/Policy mu Min              -2.71935
trainer/Policy log std Mean        -2.02211
trainer/Policy log std Std          0.576849
trainer/Policy log std Max         -0.350349
trainer/Policy log std Min         -2.74044
trainer/Alpha                       0.07611
trainer/Alpha Loss                  0.419487
exploration/num steps total    116200
exploration/num paths total      1162
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.17693
exploration/Rewards Std             1.15469
exploration/Rewards Max            -0.00830896
exploration/Rewards Min            -9.63406
exploration/Returns Mean         -117.693
exploration/Returns Std            58.2418
exploration/Returns Max           -62.245
exploration/Returns Min          -196.678
exploration/Actions Mean            0.0158702
exploration/Actions Std             0.22892
exploration/Actions Max             0.999161
exploration/Actions Min            -0.991356
exploration/Num Paths               5
exploration/Average Returns      -117.693
evaluation/num steps total     348000
evaluation/num paths total       3480
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.00363
evaluation/Rewards Std              1.28271
evaluation/Rewards Max             -0.021704
evaluation/Rewards Min            -10.8709
evaluation/Returns Mean          -100.363
evaluation/Returns Std            111.256
evaluation/Returns Max             -4.78477
evaluation/Returns Min           -279.298
evaluation/Actions Mean             0.0240888
evaluation/Actions Std              0.157017
evaluation/Actions Max              0.998843
evaluation/Actions Min             -0.98011
evaluation/Num Paths               15
evaluation/Average Returns       -100.363
time/data storing (s)               0.00279341
time/evaluation sampling (s)        0.327546
time/exploration sampling (s)       0.13975
time/logging (s)                    0.00476996
time/saving (s)                     0.00196167
time/training (s)                   1.96119
time/epoch (s)                      2.43801
time/total (s)                    568.474
Epoch                             231
-----------------------------  ---------------
2019-04-23 01:23:02.145145 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 232 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                  221.003
trainer/QF2 Loss                  220.982
trainer/Policy Loss                73.5437
trainer/Q1 Predictions Mean       -71.8877
trainer/Q1 Predictions Std         67.6043
trainer/Q1 Predictions Max        -11.3239
trainer/Q1 Predictions Min       -230.062
trainer/Q2 Predictions Mean       -71.9214
trainer/Q2 Predictions Std         67.6136
trainer/Q2 Predictions Max        -11.4221
trainer/Q2 Predictions Min       -230.194
trainer/Q Targets Mean            -69.8497
trainer/Q Targets Std              68.2911
trainer/Q Targets Max              -1.62244
trainer/Q Targets Min            -230.719
trainer/Log Pis Mean                2.07215
trainer/Log Pis Std                 1.14309
trainer/Log Pis Max                 5.16384
trainer/Log Pis Min                -2.54041
trainer/Policy mu Mean             -0.0206845
trainer/Policy mu Std               0.771146
trainer/Policy mu Max               3.48285
trainer/Policy mu Min              -3.61828
trainer/Policy log std Mean        -2.03672
trainer/Policy log std Std          0.514929
trainer/Policy log std Max         -0.0480141
trainer/Policy log std Min         -2.81632
trainer/Alpha                       0.0744123
trainer/Alpha Loss                  0.187441
exploration/num steps total    116700
exploration/num paths total      1167
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.10317
exploration/Rewards Std             1.28855
exploration/Rewards Max            -0.00594879
exploration/Rewards Min            -6.69861
exploration/Returns Mean         -110.317
exploration/Returns Std           118.751
exploration/Returns Max           -16.6998
exploration/Returns Min          -329.488
exploration/Actions Mean            0.00152691
exploration/Actions Std             0.217832
exploration/Actions Max             0.985336
exploration/Actions Min            -0.982625
exploration/Num Paths               5
exploration/Average Returns      -110.317
evaluation/num steps total     349500
evaluation/num paths total       3495
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.27322
evaluation/Rewards Std              1.54221
evaluation/Rewards Max             -0.00745563
evaluation/Rewards Min             -9.99833
evaluation/Returns Mean          -127.322
evaluation/Returns Std            120.264
evaluation/Returns Max             -2.80583
evaluation/Returns Min           -345.753
evaluation/Actions Mean            -0.00816533
evaluation/Actions Std              0.194483
evaluation/Actions Max              0.998381
evaluation/Actions Min             -0.998601
evaluation/Num Paths               15
evaluation/Average Returns       -127.322
time/data storing (s)               0.00282629
time/evaluation sampling (s)        0.327087
time/exploration sampling (s)       0.144508
time/logging (s)                    0.00475376
time/saving (s)                     0.00193807
time/training (s)                   1.97944
time/epoch (s)                      2.46055
time/total (s)                    570.939
Epoch                             232
-----------------------------  ---------------
2019-04-23 01:23:04.601269 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 233 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   34.1969
trainer/QF2 Loss                   34.3523
trainer/Policy Loss                63.7729
trainer/Q1 Predictions Mean       -62.2747
trainer/Q1 Predictions Std         66.3297
trainer/Q1 Predictions Max        -11.0682
trainer/Q1 Predictions Min       -228.859
trainer/Q2 Predictions Mean       -62.2642
trainer/Q2 Predictions Std         66.3284
trainer/Q2 Predictions Max        -10.9913
trainer/Q2 Predictions Min       -229.406
trainer/Q Targets Mean            -61.8717
trainer/Q Targets Std              67.1457
trainer/Q Targets Max              -0.890358
trainer/Q Targets Min            -231.808
trainer/Log Pis Mean                1.96764
trainer/Log Pis Std                 1.56953
trainer/Log Pis Max                 6.13877
trainer/Log Pis Min                -4.16865
trainer/Policy mu Mean             -0.0992507
trainer/Policy mu Std               0.707264
trainer/Policy mu Max               1.95498
trainer/Policy mu Min              -3.19785
trainer/Policy log std Mean        -2.07491
trainer/Policy log std Std          0.512881
trainer/Policy log std Max         -0.0636789
trainer/Policy log std Min         -2.76958
trainer/Alpha                       0.0716226
trainer/Alpha Loss                 -0.0852999
exploration/num steps total    117200
exploration/num paths total      1172
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.50476
exploration/Rewards Std             1.41306
exploration/Rewards Max            -0.0143505
exploration/Rewards Min           -10.4677
exploration/Returns Mean         -150.476
exploration/Returns Std            98.8063
exploration/Returns Max           -35.6277
exploration/Returns Min          -278.723
exploration/Actions Mean           -0.0147933
exploration/Actions Std             0.246286
exploration/Actions Max             0.997614
exploration/Actions Min            -0.996985
exploration/Num Paths               5
exploration/Average Returns      -150.476
evaluation/num steps total     351000
evaluation/num paths total       3510
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.0686
evaluation/Rewards Std              1.25681
evaluation/Rewards Max             -0.0325124
evaluation/Rewards Min             -9.13272
evaluation/Returns Mean          -106.86
evaluation/Returns Std            104.156
evaluation/Returns Max            -11.1636
evaluation/Returns Min           -282.217
evaluation/Actions Mean             0.00288595
evaluation/Actions Std              0.166235
evaluation/Actions Max              0.999596
evaluation/Actions Min             -0.997557
evaluation/Num Paths               15
evaluation/Average Returns       -106.86
time/data storing (s)               0.0028503
time/evaluation sampling (s)        0.329103
time/exploration sampling (s)       0.140473
time/logging (s)                    0.00371945
time/saving (s)                     0.00157625
time/training (s)                   1.96899
time/epoch (s)                      2.44671
time/total (s)                    573.39
Epoch                             233
-----------------------------  ---------------
2019-04-23 01:23:07.068012 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 234 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.54536
trainer/QF2 Loss                    1.59047
trainer/Policy Loss                66.8945
trainer/Q1 Predictions Mean       -65.4524
trainer/Q1 Predictions Std         63.0633
trainer/Q1 Predictions Max        -10.9397
trainer/Q1 Predictions Min       -228.493
trainer/Q2 Predictions Mean       -65.4879
trainer/Q2 Predictions Std         63.0782
trainer/Q2 Predictions Max        -10.8444
trainer/Q2 Predictions Min       -229.438
trainer/Q Targets Mean            -66.2103
trainer/Q Targets Std              63.8394
trainer/Q Targets Max             -10.9672
trainer/Q Targets Min            -232.428
trainer/Log Pis Mean                1.80713
trainer/Log Pis Std                 1.21666
trainer/Log Pis Max                 4.89784
trainer/Log Pis Min                -3.5411
trainer/Policy mu Mean              0.0480454
trainer/Policy mu Std               0.661411
trainer/Policy mu Max               4.22809
trainer/Policy mu Min              -2.77137
trainer/Policy log std Mean        -2.02879
trainer/Policy log std Std          0.457942
trainer/Policy log std Max         -0.0720188
trainer/Policy log std Min         -2.83664
trainer/Alpha                       0.0680345
trainer/Alpha Loss                 -0.518335
exploration/num steps total    117700
exploration/num paths total      1177
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.65701
exploration/Rewards Std             1.15291
exploration/Rewards Max            -0.0566445
exploration/Rewards Min            -6.95343
exploration/Returns Mean         -165.701
exploration/Returns Std           105.036
exploration/Returns Max           -40.9412
exploration/Returns Min          -293.32
exploration/Actions Mean            0.00881368
exploration/Actions Std             0.211448
exploration/Actions Max             0.999554
exploration/Actions Min            -0.993416
exploration/Num Paths               5
exploration/Average Returns      -165.701
evaluation/num steps total     352500
evaluation/num paths total       3525
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.841633
evaluation/Rewards Std              1.21908
evaluation/Rewards Max             -0.109901
evaluation/Rewards Min            -10.6088
evaluation/Returns Mean           -84.1633
evaluation/Returns Std             74.1973
evaluation/Returns Max            -14.5033
evaluation/Returns Min           -314.887
evaluation/Actions Mean             0.000129421
evaluation/Actions Std              0.183263
evaluation/Actions Max              0.999856
evaluation/Actions Min             -0.999438
evaluation/Num Paths               15
evaluation/Average Returns        -84.1633
time/data storing (s)               0.00269908
time/evaluation sampling (s)        0.330059
time/exploration sampling (s)       0.137419
time/logging (s)                    0.00471855
time/saving (s)                     0.00193064
time/training (s)                   1.98423
time/epoch (s)                      2.46105
time/total (s)                    575.855
Epoch                             234
-----------------------------  ----------------
2019-04-23 01:23:09.520832 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 235 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.07901
trainer/QF2 Loss                    1.16053
trainer/Policy Loss                71.3375
trainer/Q1 Predictions Mean       -69.8271
trainer/Q1 Predictions Std         67.7924
trainer/Q1 Predictions Max        -10.8723
trainer/Q1 Predictions Min       -227.776
trainer/Q2 Predictions Mean       -69.7666
trainer/Q2 Predictions Std         67.8138
trainer/Q2 Predictions Max        -10.738
trainer/Q2 Predictions Min       -228.523
trainer/Q Targets Mean            -70.4699
trainer/Q Targets Std              68.3334
trainer/Q Targets Max             -11.192
trainer/Q Targets Min            -230.569
trainer/Log Pis Mean                2.13499
trainer/Log Pis Std                 1.33135
trainer/Log Pis Max                 5.66647
trainer/Log Pis Min                -2.90935
trainer/Policy mu Mean              0.118303
trainer/Policy mu Std               0.786086
trainer/Policy mu Max               3.22934
trainer/Policy mu Min              -2.71863
trainer/Policy log std Mean        -2.06196
trainer/Policy log std Std          0.511836
trainer/Policy log std Max         -0.260837
trainer/Policy log std Min         -2.76995
trainer/Alpha                       0.0725455
trainer/Alpha Loss                  0.35418
exploration/num steps total    118200
exploration/num paths total      1182
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.10451
exploration/Rewards Std             1.1686
exploration/Rewards Max            -0.00563757
exploration/Rewards Min            -6.63665
exploration/Returns Mean         -110.451
exploration/Returns Std            95.3449
exploration/Returns Max           -24.5665
exploration/Returns Min          -270.687
exploration/Actions Mean            0.0330813
exploration/Actions Std             0.205435
exploration/Actions Max             0.999761
exploration/Actions Min            -0.774753
exploration/Num Paths               5
exploration/Average Returns      -110.451
evaluation/num steps total     354000
evaluation/num paths total       3540
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.881844
evaluation/Rewards Std              1.12123
evaluation/Rewards Max             -0.0640733
evaluation/Rewards Min             -8.80121
evaluation/Returns Mean           -88.1844
evaluation/Returns Std             84.6372
evaluation/Returns Max            -19.982
evaluation/Returns Min           -277.004
evaluation/Actions Mean             0.00360671
evaluation/Actions Std              0.161802
evaluation/Actions Max              0.998452
evaluation/Actions Min             -0.999828
evaluation/Num Paths               15
evaluation/Average Returns        -88.1844
time/data storing (s)               0.00271198
time/evaluation sampling (s)        0.324525
time/exploration sampling (s)       0.135322
time/logging (s)                    0.0047266
time/saving (s)                     0.00193216
time/training (s)                   1.97534
time/epoch (s)                      2.44456
time/total (s)                    578.304
Epoch                             235
-----------------------------  ---------------
2019-04-23 01:23:12.003283 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 236 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                  585.835
trainer/QF2 Loss                  583.759
trainer/Policy Loss                60.8389
trainer/Q1 Predictions Mean       -59.4786
trainer/Q1 Predictions Std         58.9727
trainer/Q1 Predictions Max        -11.3476
trainer/Q1 Predictions Min       -224.953
trainer/Q2 Predictions Mean       -59.4934
trainer/Q2 Predictions Std         58.9494
trainer/Q2 Predictions Max        -11.4339
trainer/Q2 Predictions Min       -225.033
trainer/Q Targets Mean            -55.6892
trainer/Q Targets Std              57.9227
trainer/Q Targets Max              -0.12094
trainer/Q Targets Min            -226.897
trainer/Log Pis Mean                1.96588
trainer/Log Pis Std                 1.06966
trainer/Log Pis Max                 4.16978
trainer/Log Pis Min                -2.01681
trainer/Policy mu Mean              0.00785233
trainer/Policy mu Std               0.654385
trainer/Policy mu Max               2.00573
trainer/Policy mu Min              -2.70028
trainer/Policy log std Mean        -2.08029
trainer/Policy log std Std          0.458288
trainer/Policy log std Max         -0.579093
trainer/Policy log std Min         -2.71443
trainer/Alpha                       0.0706205
trainer/Alpha Loss                 -0.0904306
exploration/num steps total    118700
exploration/num paths total      1187
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.12769
exploration/Rewards Std             1.49984
exploration/Rewards Max            -0.00641898
exploration/Rewards Min           -11.5738
exploration/Returns Mean         -112.769
exploration/Returns Std           105.806
exploration/Returns Max           -31.2211
exploration/Returns Min          -321.014
exploration/Actions Mean            0.00738692
exploration/Actions Std             0.23165
exploration/Actions Max             0.999828
exploration/Actions Min            -0.99753
exploration/Num Paths               5
exploration/Average Returns      -112.769
evaluation/num steps total     355500
evaluation/num paths total       3555
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.26381
evaluation/Rewards Std              1.51101
evaluation/Rewards Max             -0.024194
evaluation/Rewards Min             -9.62987
evaluation/Returns Mean          -126.381
evaluation/Returns Std            122.512
evaluation/Returns Max            -19.5001
evaluation/Returns Min           -350.624
evaluation/Actions Mean             0.00358951
evaluation/Actions Std              0.17545
evaluation/Actions Max              0.998625
evaluation/Actions Min             -0.999484
evaluation/Num Paths               15
evaluation/Average Returns       -126.381
time/data storing (s)               0.00261859
time/evaluation sampling (s)        0.330376
time/exploration sampling (s)       0.139814
time/logging (s)                    0.00472723
time/saving (s)                     0.00618413
time/training (s)                   1.99048
time/epoch (s)                      2.4742
time/total (s)                    580.783
Epoch                             236
-----------------------------  ---------------
2019-04-23 01:23:14.466162 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 237 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                  478.669
trainer/QF2 Loss                  478.111
trainer/Policy Loss                71.8867
trainer/Q1 Predictions Mean       -70.2804
trainer/Q1 Predictions Std         70.3053
trainer/Q1 Predictions Max        -11.1604
trainer/Q1 Predictions Min       -223.49
trainer/Q2 Predictions Mean       -70.2073
trainer/Q2 Predictions Std         70.2
trainer/Q2 Predictions Max        -11.1629
trainer/Q2 Predictions Min       -223.46
trainer/Q Targets Mean            -68.4199
trainer/Q Targets Std              69.3824
trainer/Q Targets Max              -0.436061
trainer/Q Targets Min            -225.964
trainer/Log Pis Mean                2.07446
trainer/Log Pis Std                 1.12115
trainer/Log Pis Max                 4.87236
trainer/Log Pis Min                -2.57632
trainer/Policy mu Mean              0.00381796
trainer/Policy mu Std               0.659666
trainer/Policy mu Max               2.60736
trainer/Policy mu Min              -2.44116
trainer/Policy log std Mean        -2.08511
trainer/Policy log std Std          0.481785
trainer/Policy log std Max         -0.402118
trainer/Policy log std Min         -2.76226
trainer/Alpha                       0.0711622
trainer/Alpha Loss                  0.196782
exploration/num steps total    119200
exploration/num paths total      1192
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.351153
exploration/Rewards Std             0.671216
exploration/Rewards Max            -0.00661994
exploration/Rewards Min            -8.07107
exploration/Returns Mean          -35.1153
exploration/Returns Std             5.717
exploration/Returns Max           -28.5922
exploration/Returns Min           -44.5267
exploration/Actions Mean            0.00740449
exploration/Actions Std             0.191408
exploration/Actions Max             0.993239
exploration/Actions Min            -0.994865
exploration/Num Paths               5
exploration/Average Returns       -35.1153
evaluation/num steps total     357000
evaluation/num paths total       3570
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.887819
evaluation/Rewards Std              1.55111
evaluation/Rewards Max             -0.00217494
evaluation/Rewards Min             -9.66071
evaluation/Returns Mean           -88.7819
evaluation/Returns Std            116.882
evaluation/Returns Max             -2.54069
evaluation/Returns Min           -359.486
evaluation/Actions Mean            -0.00746684
evaluation/Actions Std              0.176948
evaluation/Actions Max              0.999692
evaluation/Actions Min             -0.999573
evaluation/Num Paths               15
evaluation/Average Returns        -88.7819
time/data storing (s)               0.00268216
time/evaluation sampling (s)        0.332225
time/exploration sampling (s)       0.137382
time/logging (s)                    0.00479402
time/saving (s)                     0.00194321
time/training (s)                   1.97615
time/epoch (s)                      2.45518
time/total (s)                    583.242
Epoch                             237
-----------------------------  ---------------
2019-04-23 01:23:16.918657 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 238 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.21212
trainer/QF2 Loss                    1.18916
trainer/Policy Loss                69.59
trainer/Q1 Predictions Mean       -67.9566
trainer/Q1 Predictions Std         68.993
trainer/Q1 Predictions Max        -11.3968
trainer/Q1 Predictions Min       -223.351
trainer/Q2 Predictions Mean       -67.9849
trainer/Q2 Predictions Std         68.9648
trainer/Q2 Predictions Max        -11.2765
trainer/Q2 Predictions Min       -223.619
trainer/Q Targets Mean            -68.5151
trainer/Q Targets Std              69.5689
trainer/Q Targets Max             -11.3835
trainer/Q Targets Min            -226.75
trainer/Log Pis Mean                2.03959
trainer/Log Pis Std                 1.55466
trainer/Log Pis Max                 8.38731
trainer/Log Pis Min                -2.62239
trainer/Policy mu Mean              0.0214246
trainer/Policy mu Std               0.818094
trainer/Policy mu Max               3.99869
trainer/Policy mu Min              -4.67624
trainer/Policy log std Mean        -2.03121
trainer/Policy log std Std          0.558358
trainer/Policy log std Max         -0.036179
trainer/Policy log std Min         -2.76752
trainer/Alpha                       0.0683239
trainer/Alpha Loss                  0.106238
exploration/num steps total    119700
exploration/num paths total      1197
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.71354
exploration/Rewards Std             1.4603
exploration/Rewards Max            -0.0332182
exploration/Rewards Min           -10.4518
exploration/Returns Mean         -171.354
exploration/Returns Std           130.609
exploration/Returns Max           -29.7932
exploration/Returns Min          -330.312
exploration/Actions Mean           -0.00460354
exploration/Actions Std             0.250237
exploration/Actions Max             0.980761
exploration/Actions Min            -0.999997
exploration/Num Paths               5
exploration/Average Returns      -171.354
evaluation/num steps total     358500
evaluation/num paths total       3585
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.947636
evaluation/Rewards Std              1.23521
evaluation/Rewards Max             -0.0136902
evaluation/Rewards Min            -10.3079
evaluation/Returns Mean           -94.7636
evaluation/Returns Std             88.2761
evaluation/Returns Max             -8.17196
evaluation/Returns Min           -282.263
evaluation/Actions Mean             0.00454463
evaluation/Actions Std              0.174757
evaluation/Actions Max              0.999321
evaluation/Actions Min             -0.999665
evaluation/Num Paths               15
evaluation/Average Returns        -94.7636
time/data storing (s)               0.00276782
time/evaluation sampling (s)        0.321775
time/exploration sampling (s)       0.138477
time/logging (s)                    0.00474007
time/saving (s)                     0.00155423
time/training (s)                   1.97469
time/epoch (s)                      2.44401
time/total (s)                    585.69
Epoch                             238
-----------------------------  ---------------
2019-04-23 01:23:19.368735 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 239 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                  282.744
trainer/QF2 Loss                  283.43
trainer/Policy Loss                68.253
trainer/Q1 Predictions Mean       -66.6218
trainer/Q1 Predictions Std         60.3924
trainer/Q1 Predictions Max        -10.8721
trainer/Q1 Predictions Min       -225.631
trainer/Q2 Predictions Mean       -66.6185
trainer/Q2 Predictions Std         60.5099
trainer/Q2 Predictions Max        -10.9043
trainer/Q2 Predictions Min       -226.509
trainer/Q Targets Mean            -64.4068
trainer/Q Targets Std              61.1082
trainer/Q Targets Max              -0.714343
trainer/Q Targets Min            -227.944
trainer/Log Pis Mean                2.09855
trainer/Log Pis Std                 1.18986
trainer/Log Pis Max                 5.70935
trainer/Log Pis Min                -1.69993
trainer/Policy mu Mean              0.0360717
trainer/Policy mu Std               0.625583
trainer/Policy mu Max               2.90413
trainer/Policy mu Min              -2.32386
trainer/Policy log std Mean        -2.10123
trainer/Policy log std Std          0.443239
trainer/Policy log std Max         -0.439424
trainer/Policy log std Min         -2.7368
trainer/Alpha                       0.067396
trainer/Alpha Loss                  0.265827
exploration/num steps total    120200
exploration/num paths total      1202
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.23289
exploration/Rewards Std             1.27917
exploration/Rewards Max            -0.0110568
exploration/Rewards Min            -9.09739
exploration/Returns Mean         -123.289
exploration/Returns Std            92.9331
exploration/Returns Max           -36.7429
exploration/Returns Min          -282.152
exploration/Actions Mean            0.000859304
exploration/Actions Std             0.222531
exploration/Actions Max             0.998593
exploration/Actions Min            -0.99591
exploration/Num Paths               5
exploration/Average Returns      -123.289
evaluation/num steps total     360000
evaluation/num paths total       3600
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.57996
evaluation/Rewards Std              1.40939
evaluation/Rewards Max             -0.042647
evaluation/Rewards Min             -8.48995
evaluation/Returns Mean          -157.996
evaluation/Returns Std            122.118
evaluation/Returns Max            -19.9275
evaluation/Returns Min           -357.593
evaluation/Actions Mean            -0.00172902
evaluation/Actions Std              0.166886
evaluation/Actions Max              0.998038
evaluation/Actions Min             -0.996216
evaluation/Num Paths               15
evaluation/Average Returns       -157.996
time/data storing (s)               0.00260984
time/evaluation sampling (s)        0.326408
time/exploration sampling (s)       0.137281
time/logging (s)                    0.00372969
time/saving (s)                     0.00195932
time/training (s)                   1.96857
time/epoch (s)                      2.44055
time/total (s)                    588.135
Epoch                             239
-----------------------------  ----------------
2019-04-23 01:23:21.837024 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 240 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.71141
trainer/QF2 Loss                    1.82295
trainer/Policy Loss                67.7927
trainer/Q1 Predictions Mean       -66.4161
trainer/Q1 Predictions Std         63.3259
trainer/Q1 Predictions Max        -11.0414
trainer/Q1 Predictions Min       -222.279
trainer/Q2 Predictions Mean       -66.3942
trainer/Q2 Predictions Std         63.2892
trainer/Q2 Predictions Max        -10.9926
trainer/Q2 Predictions Min       -222.284
trainer/Q Targets Mean            -67.2203
trainer/Q Targets Std              64.1225
trainer/Q Targets Max             -11.3715
trainer/Q Targets Min            -225.289
trainer/Log Pis Mean                1.84021
trainer/Log Pis Std                 1.25559
trainer/Log Pis Max                 6.60974
trainer/Log Pis Min                -2.63377
trainer/Policy mu Mean             -0.130683
trainer/Policy mu Std               0.686645
trainer/Policy mu Max               2.38855
trainer/Policy mu Min              -3.40123
trainer/Policy log std Mean        -2.00084
trainer/Policy log std Std          0.524171
trainer/Policy log std Max         -0.164832
trainer/Policy log std Min         -2.71965
trainer/Alpha                       0.0656861
trainer/Alpha Loss                 -0.435081
exploration/num steps total    120700
exploration/num paths total      1207
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -2.43447
exploration/Rewards Std             1.38935
exploration/Rewards Max            -0.00103667
exploration/Rewards Min            -9.29734
exploration/Returns Mean         -243.447
exploration/Returns Std           105.424
exploration/Returns Max           -43.1093
exploration/Returns Min          -328.227
exploration/Actions Mean           -0.00606324
exploration/Actions Std             0.34264
exploration/Actions Max             0.999962
exploration/Actions Min            -0.999904
exploration/Num Paths               5
exploration/Average Returns      -243.447
evaluation/num steps total     361500
evaluation/num paths total       3615
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.19211
evaluation/Rewards Std              1.32061
evaluation/Rewards Max             -0.0810163
evaluation/Rewards Min            -11.0182
evaluation/Returns Mean          -119.211
evaluation/Returns Std             96.2953
evaluation/Returns Max            -12.0568
evaluation/Returns Min           -314.715
evaluation/Actions Mean             0.0154641
evaluation/Actions Std              0.185277
evaluation/Actions Max              0.999359
evaluation/Actions Min             -0.999293
evaluation/Num Paths               15
evaluation/Average Returns       -119.211
time/data storing (s)               0.00265294
time/evaluation sampling (s)        0.334222
time/exploration sampling (s)       0.151502
time/logging (s)                    0.00469762
time/saving (s)                     0.00190787
time/training (s)                   1.96665
time/epoch (s)                      2.46163
time/total (s)                    590.602
Epoch                             240
-----------------------------  ---------------
2019-04-23 01:23:24.309503 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 241 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                  113.392
trainer/QF2 Loss                  112.394
trainer/Policy Loss                66.5003
trainer/Q1 Predictions Mean       -64.8178
trainer/Q1 Predictions Std         67.4968
trainer/Q1 Predictions Max        -10.8457
trainer/Q1 Predictions Min       -219.516
trainer/Q2 Predictions Mean       -64.8405
trainer/Q2 Predictions Std         67.4571
trainer/Q2 Predictions Max        -10.9139
trainer/Q2 Predictions Min       -219.576
trainer/Q Targets Mean            -64.4705
trainer/Q Targets Std              69.0564
trainer/Q Targets Max              -0.502003
trainer/Q Targets Min            -223.447
trainer/Log Pis Mean                2.16805
trainer/Log Pis Std                 1.4821
trainer/Log Pis Max                 7.82534
trainer/Log Pis Min                -1.31546
trainer/Policy mu Mean             -0.0823399
trainer/Policy mu Std               0.84485
trainer/Policy mu Max               3.42348
trainer/Policy mu Min              -3.51727
trainer/Policy log std Mean        -1.93376
trainer/Policy log std Std          0.605143
trainer/Policy log std Max         -0.0648346
trainer/Policy log std Min         -2.7799
trainer/Alpha                       0.0653332
trainer/Alpha Loss                  0.458489
exploration/num steps total    121200
exploration/num paths total      1212
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.999776
exploration/Rewards Std             1.07069
exploration/Rewards Max            -0.0122531
exploration/Rewards Min            -8.80274
exploration/Returns Mean          -99.9776
exploration/Returns Std            60.8861
exploration/Returns Max           -41.9284
exploration/Returns Min          -202.174
exploration/Actions Mean            0.00868037
exploration/Actions Std             0.199523
exploration/Actions Max             0.999693
exploration/Actions Min            -0.992664
exploration/Num Paths               5
exploration/Average Returns       -99.9776
evaluation/num steps total     363000
evaluation/num paths total       3630
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.25506
evaluation/Rewards Std              1.2254
evaluation/Rewards Max             -0.00553867
evaluation/Rewards Min             -9.82885
evaluation/Returns Mean          -125.506
evaluation/Returns Std             79.5971
evaluation/Returns Max            -25.4556
evaluation/Returns Min           -285.177
evaluation/Actions Mean             0.00968669
evaluation/Actions Std              0.190186
evaluation/Actions Max              0.999489
evaluation/Actions Min             -0.999305
evaluation/Num Paths               15
evaluation/Average Returns       -125.506
time/data storing (s)               0.00272869
time/evaluation sampling (s)        0.328005
time/exploration sampling (s)       0.138867
time/logging (s)                    0.00423949
time/saving (s)                     0.00193182
time/training (s)                   1.98798
time/epoch (s)                      2.46375
time/total (s)                    593.07
Epoch                             241
-----------------------------  ---------------
2019-04-23 01:23:26.731817 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 242 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    2.20337
trainer/QF2 Loss                    2.14018
trainer/Policy Loss                68.4963
trainer/Q1 Predictions Mean       -67.066
trainer/Q1 Predictions Std         63.7539
trainer/Q1 Predictions Max        -11.083
trainer/Q1 Predictions Min       -221.818
trainer/Q2 Predictions Mean       -67.112
trainer/Q2 Predictions Std         63.7577
trainer/Q2 Predictions Max        -11.1728
trainer/Q2 Predictions Min       -221.674
trainer/Q Targets Mean            -67.1895
trainer/Q Targets Std              63.9929
trainer/Q Targets Max              -0.153905
trainer/Q Targets Min            -222.336
trainer/Log Pis Mean                1.94152
trainer/Log Pis Std                 1.28113
trainer/Log Pis Max                 5.25999
trainer/Log Pis Min                -2.3672
trainer/Policy mu Mean             -0.0999949
trainer/Policy mu Std               0.702362
trainer/Policy mu Max               3.16933
trainer/Policy mu Min              -2.5596
trainer/Policy log std Mean        -2.04332
trainer/Policy log std Std          0.518718
trainer/Policy log std Max         -0.251943
trainer/Policy log std Min         -2.7245
trainer/Alpha                       0.0670415
trainer/Alpha Loss                 -0.158033
exploration/num steps total    121700
exploration/num paths total      1217
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.36226
exploration/Rewards Std             1.26997
exploration/Rewards Max            -0.0222009
exploration/Rewards Min            -6.89539
exploration/Returns Mean         -136.226
exploration/Returns Std           110.105
exploration/Returns Max           -27.682
exploration/Returns Min          -277.118
exploration/Actions Mean            0.00886654
exploration/Actions Std             0.233753
exploration/Actions Max             0.996144
exploration/Actions Min            -0.999862
exploration/Num Paths               5
exploration/Average Returns      -136.226
evaluation/num steps total     364500
evaluation/num paths total       3645
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.75329
evaluation/Rewards Std              1.4951
evaluation/Rewards Max             -0.118105
evaluation/Rewards Min            -10.8186
evaluation/Returns Mean          -175.329
evaluation/Returns Std            115.976
evaluation/Returns Max            -23.975
evaluation/Returns Min           -346.155
evaluation/Actions Mean            -0.00779448
evaluation/Actions Std              0.200656
evaluation/Actions Max              0.999454
evaluation/Actions Min             -0.999736
evaluation/Num Paths               15
evaluation/Average Returns       -175.329
time/data storing (s)               0.00284214
time/evaluation sampling (s)        0.326923
time/exploration sampling (s)       0.138801
time/logging (s)                    0.00473988
time/saving (s)                     0.00194137
time/training (s)                   1.93984
time/epoch (s)                      2.41509
time/total (s)                    595.489
Epoch                             242
-----------------------------  ---------------
2019-04-23 01:23:29.183967 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 243 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    4.43604
trainer/QF2 Loss                    4.62788
trainer/Policy Loss                69.6271
trainer/Q1 Predictions Mean       -68.0326
trainer/Q1 Predictions Std         69.0457
trainer/Q1 Predictions Max        -10.8883
trainer/Q1 Predictions Min       -232.632
trainer/Q2 Predictions Mean       -67.9826
trainer/Q2 Predictions Std         69.032
trainer/Q2 Predictions Max        -10.8645
trainer/Q2 Predictions Min       -230.487
trainer/Q Targets Mean            -68.9775
trainer/Q Targets Std              69.9182
trainer/Q Targets Max              -0.0939815
trainer/Q Targets Min            -233.708
trainer/Log Pis Mean                2.06586
trainer/Log Pis Std                 1.66329
trainer/Log Pis Max                 7.45407
trainer/Log Pis Min                -6.37163
trainer/Policy mu Mean             -0.0885276
trainer/Policy mu Std               0.845275
trainer/Policy mu Max               2.986
trainer/Policy mu Min              -3.84598
trainer/Policy log std Mean        -1.98188
trainer/Policy log std Std          0.569529
trainer/Policy log std Max          0.11465
trainer/Policy log std Min         -2.67805
trainer/Alpha                       0.0687856
trainer/Alpha Loss                  0.176284
exploration/num steps total    122200
exploration/num paths total      1222
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.681028
exploration/Rewards Std             1.0043
exploration/Rewards Max            -0.00666029
exploration/Rewards Min            -7.95062
exploration/Returns Mean          -68.1028
exploration/Returns Std            46.1966
exploration/Returns Max           -21.5661
exploration/Returns Min          -149.286
exploration/Actions Mean            0.00359448
exploration/Actions Std             0.213655
exploration/Actions Max             0.998759
exploration/Actions Min            -0.999486
exploration/Num Paths               5
exploration/Average Returns       -68.1028
evaluation/num steps total     366000
evaluation/num paths total       3660
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.25388
evaluation/Rewards Std              1.36844
evaluation/Rewards Max             -0.0502751
evaluation/Rewards Min             -9.95207
evaluation/Returns Mean          -125.388
evaluation/Returns Std            102.938
evaluation/Returns Max            -15.7266
evaluation/Returns Min           -318.876
evaluation/Actions Mean            -0.012986
evaluation/Actions Std              0.179745
evaluation/Actions Max              0.999595
evaluation/Actions Min             -0.999884
evaluation/Num Paths               15
evaluation/Average Returns       -125.388
time/data storing (s)               0.00283738
time/evaluation sampling (s)        0.327038
time/exploration sampling (s)       0.141833
time/logging (s)                    0.00474748
time/saving (s)                     0.00193394
time/training (s)                   1.96554
time/epoch (s)                      2.44393
time/total (s)                    597.938
Epoch                             243
-----------------------------  ---------------
2019-04-23 01:23:31.643256 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 244 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   57.8818
trainer/QF2 Loss                   58.0656
trainer/Policy Loss                69.7297
trainer/Q1 Predictions Mean       -68.0883
trainer/Q1 Predictions Std         68.1874
trainer/Q1 Predictions Max        -11.171
trainer/Q1 Predictions Min       -232.975
trainer/Q2 Predictions Mean       -67.966
trainer/Q2 Predictions Std         68.1286
trainer/Q2 Predictions Max        -11.0567
trainer/Q2 Predictions Min       -231.832
trainer/Q Targets Mean            -67.8881
trainer/Q Targets Std              69.3639
trainer/Q Targets Max              -0.329019
trainer/Q Targets Min            -235.991
trainer/Log Pis Mean                2.12529
trainer/Log Pis Std                 1.16292
trainer/Log Pis Max                 8.42873
trainer/Log Pis Min                -0.423726
trainer/Policy mu Mean             -0.00289122
trainer/Policy mu Std               0.742305
trainer/Policy mu Max               2.77382
trainer/Policy mu Min              -4.2976
trainer/Policy log std Mean        -1.96913
trainer/Policy log std Std          0.499002
trainer/Policy log std Max          0.296196
trainer/Policy log std Min         -2.71607
trainer/Alpha                       0.0659755
trainer/Alpha Loss                  0.34059
exploration/num steps total    122700
exploration/num paths total      1227
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -2.24338
exploration/Rewards Std             1.30596
exploration/Rewards Max            -0.0070583
exploration/Rewards Min            -9.98558
exploration/Returns Mean         -224.338
exploration/Returns Std           103.988
exploration/Returns Max           -58.4582
exploration/Returns Min          -355.545
exploration/Actions Mean            0.00882673
exploration/Actions Std             0.260858
exploration/Actions Max             0.999457
exploration/Actions Min            -0.998886
exploration/Num Paths               5
exploration/Average Returns      -224.338
evaluation/num steps total     367500
evaluation/num paths total       3675
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.40201
evaluation/Rewards Std              1.32079
evaluation/Rewards Max             -0.0479163
evaluation/Rewards Min            -10.2635
evaluation/Returns Mean          -140.201
evaluation/Returns Std            102.161
evaluation/Returns Max            -20.9999
evaluation/Returns Min           -358.763
evaluation/Actions Mean            -0.0104244
evaluation/Actions Std              0.193374
evaluation/Actions Max              0.999063
evaluation/Actions Min             -0.999912
evaluation/Num Paths               15
evaluation/Average Returns       -140.201
time/data storing (s)               0.00274305
time/evaluation sampling (s)        0.327703
time/exploration sampling (s)       0.136326
time/logging (s)                    0.00475292
time/saving (s)                     0.0019569
time/training (s)                   1.97775
time/epoch (s)                      2.45123
time/total (s)                    600.393
Epoch                             244
-----------------------------  ---------------
2019-04-23 01:23:34.141861 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 245 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    3.32322
trainer/QF2 Loss                    3.498
trainer/Policy Loss                80.7706
trainer/Q1 Predictions Mean       -79.5419
trainer/Q1 Predictions Std         68.1987
trainer/Q1 Predictions Max        -11.1443
trainer/Q1 Predictions Min       -217.818
trainer/Q2 Predictions Mean       -79.4608
trainer/Q2 Predictions Std         68.1322
trainer/Q2 Predictions Max        -11.183
trainer/Q2 Predictions Min       -217.87
trainer/Q Targets Mean            -79.879
trainer/Q Targets Std              69.1054
trainer/Q Targets Max              -0.298188
trainer/Q Targets Min            -221.367
trainer/Log Pis Mean                1.87879
trainer/Log Pis Std                 1.18453
trainer/Log Pis Max                 4.23797
trainer/Log Pis Min                -2.33682
trainer/Policy mu Mean             -0.195199
trainer/Policy mu Std               0.784991
trainer/Policy mu Max               2.42495
trainer/Policy mu Min              -2.30474
trainer/Policy log std Mean        -1.85778
trainer/Policy log std Std          0.609994
trainer/Policy log std Max         -0.480664
trainer/Policy log std Min         -2.6777
trainer/Alpha                       0.0631119
trainer/Alpha Loss                 -0.334855
exploration/num steps total    123200
exploration/num paths total      1232
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.861909
exploration/Rewards Std             1.3823
exploration/Rewards Max            -0.0141226
exploration/Rewards Min           -11.0669
exploration/Returns Mean          -86.1909
exploration/Returns Std            74.964
exploration/Returns Max           -25.75
exploration/Returns Min          -231.077
exploration/Actions Mean            0.0397777
exploration/Actions Std             0.235529
exploration/Actions Max             0.999896
exploration/Actions Min            -0.754618
exploration/Num Paths               5
exploration/Average Returns       -86.1909
evaluation/num steps total     369000
evaluation/num paths total       3690
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.826985
evaluation/Rewards Std              1.26828
evaluation/Rewards Max             -0.103068
evaluation/Rewards Min            -11.164
evaluation/Returns Mean           -82.6985
evaluation/Returns Std             68.2411
evaluation/Returns Max            -14.7464
evaluation/Returns Min           -240.041
evaluation/Actions Mean            -0.000461151
evaluation/Actions Std              0.196665
evaluation/Actions Max              0.999314
evaluation/Actions Min             -0.999685
evaluation/Num Paths               15
evaluation/Average Returns        -82.6985
time/data storing (s)               0.00313584
time/evaluation sampling (s)        0.331882
time/exploration sampling (s)       0.137082
time/logging (s)                    0.00386759
time/saving (s)                     0.00193137
time/training (s)                   2.01179
time/epoch (s)                      2.48969
time/total (s)                    602.887
Epoch                             245
-----------------------------  ----------------
2019-04-23 01:23:36.650116 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 246 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    3.25914
trainer/QF2 Loss                    3.21612
trainer/Policy Loss                66.6109
trainer/Q1 Predictions Mean       -65.3368
trainer/Q1 Predictions Std         64.1989
trainer/Q1 Predictions Max        -11.0394
trainer/Q1 Predictions Min       -220.909
trainer/Q2 Predictions Mean       -65.3469
trainer/Q2 Predictions Std         64.2048
trainer/Q2 Predictions Max        -11.0467
trainer/Q2 Predictions Min       -221.317
trainer/Q Targets Mean            -65.6199
trainer/Q Targets Std              64.8586
trainer/Q Targets Max              -1.28912
trainer/Q Targets Min            -223.343
trainer/Log Pis Mean                1.78504
trainer/Log Pis Std                 1.12356
trainer/Log Pis Max                 5.95552
trainer/Log Pis Min                -1.6048
trainer/Policy mu Mean              0.0705274
trainer/Policy mu Std               0.669918
trainer/Policy mu Max               3.07131
trainer/Policy mu Min              -2.17047
trainer/Policy log std Mean        -2.06217
trainer/Policy log std Std          0.451907
trainer/Policy log std Max         -0.525345
trainer/Policy log std Min         -2.77976
trainer/Alpha                       0.0646103
trainer/Alpha Loss                 -0.58889
exploration/num steps total    123700
exploration/num paths total      1237
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.88972
exploration/Rewards Std             1.48786
exploration/Rewards Max            -0.0103665
exploration/Rewards Min           -10.4432
exploration/Returns Mean         -188.972
exploration/Returns Std           132.116
exploration/Returns Max           -16.9929
exploration/Returns Min          -312.176
exploration/Actions Mean           -0.0046583
exploration/Actions Std             0.215182
exploration/Actions Max             0.987337
exploration/Actions Min            -0.999879
exploration/Num Paths               5
exploration/Average Returns      -188.972
evaluation/num steps total     370500
evaluation/num paths total       3705
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.994694
evaluation/Rewards Std              1.24012
evaluation/Rewards Max             -0.0269644
evaluation/Rewards Min             -9.00885
evaluation/Returns Mean           -99.4694
evaluation/Returns Std             94.6973
evaluation/Returns Max            -12.7336
evaluation/Returns Min           -356.46
evaluation/Actions Mean             0.00948751
evaluation/Actions Std              0.167842
evaluation/Actions Max              0.999135
evaluation/Actions Min             -0.998189
evaluation/Num Paths               15
evaluation/Average Returns        -99.4694
time/data storing (s)               0.00274721
time/evaluation sampling (s)        0.332366
time/exploration sampling (s)       0.137472
time/logging (s)                    0.00475345
time/saving (s)                     0.00193501
time/training (s)                   2.02301
time/epoch (s)                      2.50229
time/total (s)                    605.393
Epoch                             246
-----------------------------  ---------------
2019-04-23 01:23:39.109229 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 247 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                  184.102
trainer/QF2 Loss                  184.403
trainer/Policy Loss                81.9393
trainer/Q1 Predictions Mean       -80.6391
trainer/Q1 Predictions Std         67.8723
trainer/Q1 Predictions Max        -11.0268
trainer/Q1 Predictions Min       -218.949
trainer/Q2 Predictions Mean       -80.7197
trainer/Q2 Predictions Std         67.8901
trainer/Q2 Predictions Max        -11.0581
trainer/Q2 Predictions Min       -219.264
trainer/Q Targets Mean            -79.7995
trainer/Q Targets Std              69.3146
trainer/Q Targets Max              -0.771667
trainer/Q Targets Min            -222.891
trainer/Log Pis Mean                1.69848
trainer/Log Pis Std                 1.30002
trainer/Log Pis Max                 6.86895
trainer/Log Pis Min                -1.75671
trainer/Policy mu Mean             -0.144561
trainer/Policy mu Std               0.707632
trainer/Policy mu Max               3.20456
trainer/Policy mu Min              -3.08307
trainer/Policy log std Mean        -1.90046
trainer/Policy log std Std          0.513895
trainer/Policy log std Max         -0.250397
trainer/Policy log std Min         -2.60522
trainer/Alpha                       0.0638226
trainer/Alpha Loss                 -0.829596
exploration/num steps total    124200
exploration/num paths total      1242
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.894018
exploration/Rewards Std             1.3919
exploration/Rewards Max            -0.00690909
exploration/Rewards Min           -10.3522
exploration/Returns Mean          -89.4018
exploration/Returns Std            48.2419
exploration/Returns Max           -42.5897
exploration/Returns Min          -181.453
exploration/Actions Mean            0.0263035
exploration/Actions Std             0.246169
exploration/Actions Max             0.999677
exploration/Actions Min            -0.998212
exploration/Num Paths               5
exploration/Average Returns       -89.4018
evaluation/num steps total     372000
evaluation/num paths total       3720
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.72903
evaluation/Rewards Std              1.25201
evaluation/Rewards Max             -0.00490713
evaluation/Rewards Min             -9.54808
evaluation/Returns Mean           -72.903
evaluation/Returns Std             80.4019
evaluation/Returns Max             -5.57223
evaluation/Returns Min           -284.758
evaluation/Actions Mean             0.00336027
evaluation/Actions Std              0.183839
evaluation/Actions Max              0.998925
evaluation/Actions Min             -0.999667
evaluation/Num Paths               15
evaluation/Average Returns        -72.903
time/data storing (s)               0.00272829
time/evaluation sampling (s)        0.327187
time/exploration sampling (s)       0.137961
time/logging (s)                    0.00471662
time/saving (s)                     0.00195057
time/training (s)                   1.9765
time/epoch (s)                      2.45104
time/total (s)                    607.848
Epoch                             247
-----------------------------  ---------------
2019-04-23 01:23:41.554714 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 248 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    2.82692
trainer/QF2 Loss                    2.84975
trainer/Policy Loss                67.4535
trainer/Q1 Predictions Mean       -66.0678
trainer/Q1 Predictions Std         64.9114
trainer/Q1 Predictions Max        -10.9659
trainer/Q1 Predictions Min       -218.042
trainer/Q2 Predictions Mean       -66.0591
trainer/Q2 Predictions Std         64.9533
trainer/Q2 Predictions Max        -10.8523
trainer/Q2 Predictions Min       -218.121
trainer/Q Targets Mean            -66.3214
trainer/Q Targets Std              65.5975
trainer/Q Targets Max              -0.549136
trainer/Q Targets Min            -220.353
trainer/Log Pis Mean                2.06402
trainer/Log Pis Std                 1.31296
trainer/Log Pis Max                 5.78291
trainer/Log Pis Min                -1.99023
trainer/Policy mu Mean             -0.0594006
trainer/Policy mu Std               0.852468
trainer/Policy mu Max               2.75868
trainer/Policy mu Min              -3.15362
trainer/Policy log std Mean        -1.9436
trainer/Policy log std Std          0.574847
trainer/Policy log std Max         -0.157475
trainer/Policy log std Min         -2.7581
trainer/Alpha                       0.0630995
trainer/Alpha Loss                  0.17688
exploration/num steps total    124700
exploration/num paths total      1247
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -2.01885
exploration/Rewards Std             1.14958
exploration/Rewards Max            -0.026475
exploration/Rewards Min            -8.09411
exploration/Returns Mean         -201.885
exploration/Returns Std            91.3578
exploration/Returns Max           -40.2052
exploration/Returns Min          -274.108
exploration/Actions Mean            0.00231257
exploration/Actions Std             0.245216
exploration/Actions Max             0.998602
exploration/Actions Min            -0.998981
exploration/Num Paths               5
exploration/Average Returns      -201.885
evaluation/num steps total     373500
evaluation/num paths total       3735
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.58541
evaluation/Rewards Std              1.21771
evaluation/Rewards Max             -0.101412
evaluation/Rewards Min             -9.89036
evaluation/Returns Mean          -158.541
evaluation/Returns Std            100.547
evaluation/Returns Max            -18.4543
evaluation/Returns Min           -332.84
evaluation/Actions Mean             0.0219854
evaluation/Actions Std              0.171571
evaluation/Actions Max              0.998786
evaluation/Actions Min             -0.995952
evaluation/Num Paths               15
evaluation/Average Returns       -158.541
time/data storing (s)               0.00267919
time/evaluation sampling (s)        0.323054
time/exploration sampling (s)       0.137424
time/logging (s)                    0.00414804
time/saving (s)                     0.00154858
time/training (s)                   1.96797
time/epoch (s)                      2.43683
time/total (s)                    610.289
Epoch                             248
-----------------------------  ---------------
2019-04-23 01:23:44.071056 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 249 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    6.31645
trainer/QF2 Loss                    6.33801
trainer/Policy Loss                66.2541
trainer/Q1 Predictions Mean       -64.9008
trainer/Q1 Predictions Std         62.3711
trainer/Q1 Predictions Max        -11.099
trainer/Q1 Predictions Min       -216.545
trainer/Q2 Predictions Mean       -64.8786
trainer/Q2 Predictions Std         62.3814
trainer/Q2 Predictions Max        -11.1635
trainer/Q2 Predictions Min       -216.619
trainer/Q Targets Mean            -65.0808
trainer/Q Targets Std              63.1453
trainer/Q Targets Max              -0.50849
trainer/Q Targets Min            -219.167
trainer/Log Pis Mean                1.84923
trainer/Log Pis Std                 1.19187
trainer/Log Pis Max                 5.207
trainer/Log Pis Min                -3.09952
trainer/Policy mu Mean             -0.000111499
trainer/Policy mu Std               0.736936
trainer/Policy mu Max               2.78307
trainer/Policy mu Min              -4.00717
trainer/Policy log std Mean        -2.0338
trainer/Policy log std Std          0.533651
trainer/Policy log std Max          0.355583
trainer/Policy log std Min         -2.63867
trainer/Alpha                       0.0629113
trainer/Alpha Loss                 -0.41703
exploration/num steps total    125200
exploration/num paths total      1252
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.888115
exploration/Rewards Std             1.21237
exploration/Rewards Max            -0.0103815
exploration/Rewards Min           -10.7621
exploration/Returns Mean          -88.8115
exploration/Returns Std            76.9824
exploration/Returns Max           -17.6818
exploration/Returns Min          -206.517
exploration/Actions Mean            0.00979878
exploration/Actions Std             0.223793
exploration/Actions Max             0.999676
exploration/Actions Min            -0.998384
exploration/Num Paths               5
exploration/Average Returns       -88.8115
evaluation/num steps total     375000
evaluation/num paths total       3750
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.1357
evaluation/Rewards Std              1.22453
evaluation/Rewards Max             -0.0223395
evaluation/Rewards Min            -10.7809
evaluation/Returns Mean          -113.57
evaluation/Returns Std             95.0652
evaluation/Returns Max             -8.09837
evaluation/Returns Min           -273.819
evaluation/Actions Mean            -0.00868142
evaluation/Actions Std              0.167184
evaluation/Actions Max              0.999643
evaluation/Actions Min             -0.998984
evaluation/Num Paths               15
evaluation/Average Returns       -113.57
time/data storing (s)               0.00267994
time/evaluation sampling (s)        0.345436
time/exploration sampling (s)       0.16587
time/logging (s)                    0.00354905
time/saving (s)                     0.00980481
time/training (s)                   1.98066
time/epoch (s)                      2.508
time/total (s)                    612.801
Epoch                             249
-----------------------------  ----------------
2019-04-23 01:23:46.529483 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 250 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                   31.9202
trainer/QF2 Loss                   32.0391
trainer/Policy Loss                59.6853
trainer/Q1 Predictions Mean       -57.9039
trainer/Q1 Predictions Std         58.5715
trainer/Q1 Predictions Max        -11.2587
trainer/Q1 Predictions Min       -217.058
trainer/Q2 Predictions Mean       -57.9359
trainer/Q2 Predictions Std         58.5958
trainer/Q2 Predictions Max        -11.2835
trainer/Q2 Predictions Min       -217.043
trainer/Q Targets Mean            -57.6505
trainer/Q Targets Std              59.7484
trainer/Q Targets Max              -0.645437
trainer/Q Targets Min            -219.882
trainer/Log Pis Mean                2.14241
trainer/Log Pis Std                 1.27818
trainer/Log Pis Max                 6.43897
trainer/Log Pis Min                -2.45361
trainer/Policy mu Mean              0.0422977
trainer/Policy mu Std               0.64698
trainer/Policy mu Max               3.4248
trainer/Policy mu Min              -2.50417
trainer/Policy log std Mean        -2.10687
trainer/Policy log std Std          0.468177
trainer/Policy log std Max         -0.270205
trainer/Policy log std Min         -2.69799
trainer/Alpha                       0.0630268
trainer/Alpha Loss                  0.393654
exploration/num steps total    125700
exploration/num paths total      1257
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.613486
exploration/Rewards Std             0.920557
exploration/Rewards Max            -0.00797657
exploration/Rewards Min            -7.54749
exploration/Returns Mean          -61.3486
exploration/Returns Std            47.7196
exploration/Returns Max           -20.1872
exploration/Returns Min          -123.16
exploration/Actions Mean            0.00164463
exploration/Actions Std             0.222089
exploration/Actions Max             0.997386
exploration/Actions Min            -0.999751
exploration/Num Paths               5
exploration/Average Returns       -61.3486
evaluation/num steps total     376500
evaluation/num paths total       3765
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.33985
evaluation/Rewards Std              1.19653
evaluation/Rewards Max             -0.00846967
evaluation/Rewards Min            -10.4586
evaluation/Returns Mean          -133.985
evaluation/Returns Std             80.9243
evaluation/Returns Max            -29.328
evaluation/Returns Min           -284.393
evaluation/Actions Mean             0.000570633
evaluation/Actions Std              0.184907
evaluation/Actions Max              0.999736
evaluation/Actions Min             -0.999397
evaluation/Num Paths               15
evaluation/Average Returns       -133.985
time/data storing (s)               0.00266756
time/evaluation sampling (s)        0.326871
time/exploration sampling (s)       0.138114
time/logging (s)                    0.00471858
time/saving (s)                     0.00193704
time/training (s)                   1.97828
time/epoch (s)                      2.45259
time/total (s)                    615.258
Epoch                             250
-----------------------------  ----------------
2019-04-23 01:23:48.969992 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 251 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    4.39692
trainer/QF2 Loss                    4.33918
trainer/Policy Loss                71.9275
trainer/Q1 Predictions Mean       -70.6974
trainer/Q1 Predictions Std         62.8732
trainer/Q1 Predictions Max        -11.037
trainer/Q1 Predictions Min       -214.389
trainer/Q2 Predictions Mean       -70.6333
trainer/Q2 Predictions Std         62.8017
trainer/Q2 Predictions Max        -10.9951
trainer/Q2 Predictions Min       -214.512
trainer/Q Targets Mean            -70.3284
trainer/Q Targets Std              63.116
trainer/Q Targets Max              -0.154969
trainer/Q Targets Min            -216.33
trainer/Log Pis Mean                1.86794
trainer/Log Pis Std                 1.27017
trainer/Log Pis Max                 5.61655
trainer/Log Pis Min                -2.65159
trainer/Policy mu Mean             -0.218107
trainer/Policy mu Std               0.769993
trainer/Policy mu Max               3.25375
trainer/Policy mu Min              -2.77078
trainer/Policy log std Mean        -1.95928
trainer/Policy log std Std          0.484422
trainer/Policy log std Max         -0.438802
trainer/Policy log std Min         -2.61448
trainer/Alpha                       0.0656783
trainer/Alpha Loss                 -0.3596
exploration/num steps total    126200
exploration/num paths total      1262
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.891689
exploration/Rewards Std             1.31787
exploration/Rewards Max            -0.0104166
exploration/Rewards Min            -8.73477
exploration/Returns Mean          -89.1689
exploration/Returns Std           104.111
exploration/Returns Max           -19.2206
exploration/Returns Min          -296.008
exploration/Actions Mean            0.0237361
exploration/Actions Std             0.21733
exploration/Actions Max             0.999306
exploration/Actions Min            -0.993176
exploration/Num Paths               5
exploration/Average Returns       -89.1689
evaluation/num steps total     378000
evaluation/num paths total       3780
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.6295
evaluation/Rewards Std              1.18261
evaluation/Rewards Max             -0.0540632
evaluation/Rewards Min            -10.1309
evaluation/Returns Mean          -162.95
evaluation/Returns Std             95.9784
evaluation/Returns Max            -15.5777
evaluation/Returns Min           -286.053
evaluation/Actions Mean            -0.000159924
evaluation/Actions Std              0.171928
evaluation/Actions Max              0.997113
evaluation/Actions Min             -0.998509
evaluation/Num Paths               15
evaluation/Average Returns       -162.95
time/data storing (s)               0.00277207
time/evaluation sampling (s)        0.323614
time/exploration sampling (s)       0.132396
time/logging (s)                    0.00442149
time/saving (s)                     0.00192982
time/training (s)                   1.96774
time/epoch (s)                      2.43287
time/total (s)                    617.695
Epoch                             251
-----------------------------  ----------------
2019-04-23 01:23:51.439423 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 252 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.30587
trainer/QF2 Loss                    1.17119
trainer/Policy Loss                78.1191
trainer/Q1 Predictions Mean       -76.7063
trainer/Q1 Predictions Std         65.7715
trainer/Q1 Predictions Max        -10.8826
trainer/Q1 Predictions Min       -213.576
trainer/Q2 Predictions Mean       -76.678
trainer/Q2 Predictions Std         65.8105
trainer/Q2 Predictions Max        -10.8853
trainer/Q2 Predictions Min       -212.965
trainer/Q Targets Mean            -77.336
trainer/Q Targets Std              66.5033
trainer/Q Targets Max             -11.0697
trainer/Q Targets Min            -215.89
trainer/Log Pis Mean                1.78416
trainer/Log Pis Std                 1.29013
trainer/Log Pis Max                 5.43889
trainer/Log Pis Min                -3.36728
trainer/Policy mu Mean             -0.0428822
trainer/Policy mu Std               0.688162
trainer/Policy mu Max               3.09646
trainer/Policy mu Min              -3.70546
trainer/Policy log std Mean        -1.97529
trainer/Policy log std Std          0.487342
trainer/Policy log std Max         -0.29102
trainer/Policy log std Min         -2.65631
trainer/Alpha                       0.0600102
trainer/Alpha Loss                 -0.607175
exploration/num steps total    126700
exploration/num paths total      1267
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.840988
exploration/Rewards Std             1.11784
exploration/Rewards Max            -0.0127101
exploration/Rewards Min            -5.44689
exploration/Returns Mean          -84.0988
exploration/Returns Std           101.658
exploration/Returns Max           -19.4103
exploration/Returns Min          -283.904
exploration/Actions Mean           -0.0180464
exploration/Actions Std             0.225367
exploration/Actions Max             0.948506
exploration/Actions Min            -0.999852
exploration/Num Paths               5
exploration/Average Returns       -84.0988
evaluation/num steps total     379500
evaluation/num paths total       3795
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.23698
evaluation/Rewards Std              1.24866
evaluation/Rewards Max             -0.014098
evaluation/Rewards Min             -8.14984
evaluation/Returns Mean          -123.698
evaluation/Returns Std            105.697
evaluation/Returns Max            -14.112
evaluation/Returns Min           -285.406
evaluation/Actions Mean            -0.00475126
evaluation/Actions Std              0.167443
evaluation/Actions Max              0.997255
evaluation/Actions Min             -0.998935
evaluation/Num Paths               15
evaluation/Average Returns       -123.698
time/data storing (s)               0.00273616
time/evaluation sampling (s)        0.33663
time/exploration sampling (s)       0.141165
time/logging (s)                    0.00476988
time/saving (s)                     0.00194017
time/training (s)                   1.97435
time/epoch (s)                      2.46159
time/total (s)                    620.161
Epoch                             252
-----------------------------  ---------------
2019-04-23 01:23:53.910589 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 253 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                  408.239
trainer/QF2 Loss                  405.067
trainer/Policy Loss                68.8142
trainer/Q1 Predictions Mean       -67.3009
trainer/Q1 Predictions Std         64.9065
trainer/Q1 Predictions Max        -11.1334
trainer/Q1 Predictions Min       -216.293
trainer/Q2 Predictions Mean       -67.3074
trainer/Q2 Predictions Std         64.9027
trainer/Q2 Predictions Max        -10.994
trainer/Q2 Predictions Min       -216.4
trainer/Q Targets Mean            -66.1337
trainer/Q Targets Std              64.4599
trainer/Q Targets Max              -2.43988
trainer/Q Targets Min            -219.092
trainer/Log Pis Mean                1.98954
trainer/Log Pis Std                 1.2945
trainer/Log Pis Max                 6.04819
trainer/Log Pis Min                -3.65295
trainer/Policy mu Mean             -0.0688417
trainer/Policy mu Std               0.66599
trainer/Policy mu Max               2.50068
trainer/Policy mu Min              -3.22819
trainer/Policy log std Mean        -2.04408
trainer/Policy log std Std          0.488898
trainer/Policy log std Max         -0.39526
trainer/Policy log std Min         -2.68908
trainer/Alpha                       0.0582294
trainer/Alpha Loss                 -0.0297465
exploration/num steps total    127200
exploration/num paths total      1272
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.87666
exploration/Rewards Std             1.22584
exploration/Rewards Max            -0.292355
exploration/Rewards Min           -10.7916
exploration/Returns Mean         -187.666
exploration/Returns Std            77.4775
exploration/Returns Max           -84.3616
exploration/Returns Min          -321.078
exploration/Actions Mean            0.0151794
exploration/Actions Std             0.244758
exploration/Actions Max             0.99769
exploration/Actions Min            -0.994511
exploration/Num Paths               5
exploration/Average Returns      -187.666
evaluation/num steps total     381000
evaluation/num paths total       3810
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.07736
evaluation/Rewards Std              1.29401
evaluation/Rewards Max             -0.0541767
evaluation/Rewards Min             -9.79948
evaluation/Returns Mean          -107.736
evaluation/Returns Std             90.7494
evaluation/Returns Max            -20.4863
evaluation/Returns Min           -306.731
evaluation/Actions Mean             2.49252e-05
evaluation/Actions Std              0.188036
evaluation/Actions Max              0.998789
evaluation/Actions Min             -0.999258
evaluation/Num Paths               15
evaluation/Average Returns       -107.736
time/data storing (s)               0.00264801
time/evaluation sampling (s)        0.326007
time/exploration sampling (s)       0.143414
time/logging (s)                    0.00474846
time/saving (s)                     0.00193255
time/training (s)                   1.98386
time/epoch (s)                      2.46261
time/total (s)                    622.628
Epoch                             253
-----------------------------  ----------------
2019-04-23 01:23:56.395967 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 254 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.632363
trainer/QF2 Loss                    0.620794
trainer/Policy Loss                66.6845
trainer/Q1 Predictions Mean       -65.0029
trainer/Q1 Predictions Std         61.9797
trainer/Q1 Predictions Max        -11.1373
trainer/Q1 Predictions Min       -213.829
trainer/Q2 Predictions Mean       -65.038
trainer/Q2 Predictions Std         62.0097
trainer/Q2 Predictions Max        -11.0724
trainer/Q2 Predictions Min       -213.459
trainer/Q Targets Mean            -65.4239
trainer/Q Targets Std              62.2517
trainer/Q Targets Max             -11.0003
trainer/Q Targets Min            -214.647
trainer/Log Pis Mean                2.20434
trainer/Log Pis Std                 1.2516
trainer/Log Pis Max                 6.63073
trainer/Log Pis Min                -1.21937
trainer/Policy mu Mean             -0.0888264
trainer/Policy mu Std               0.748984
trainer/Policy mu Max               3.33409
trainer/Policy mu Min              -2.99341
trainer/Policy log std Mean        -2.04422
trainer/Policy log std Std          0.487687
trainer/Policy log std Max         -0.449867
trainer/Policy log std Min         -2.6249
trainer/Alpha                       0.0590377
trainer/Alpha Loss                  0.578189
exploration/num steps total    127700
exploration/num paths total      1277
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.914072
exploration/Rewards Std             1.12674
exploration/Rewards Max            -0.016443
exploration/Rewards Min            -9.298
exploration/Returns Mean          -91.4072
exploration/Returns Std            83.0076
exploration/Returns Max           -22.3984
exploration/Returns Min          -252.975
exploration/Actions Mean           -0.00523321
exploration/Actions Std             0.212407
exploration/Actions Max             0.999527
exploration/Actions Min            -0.996243
exploration/Num Paths               5
exploration/Average Returns       -91.4072
evaluation/num steps total     382500
evaluation/num paths total       3825
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.52556
evaluation/Rewards Std              1.20462
evaluation/Rewards Max             -0.0187326
evaluation/Rewards Min             -9.3234
evaluation/Returns Mean          -152.556
evaluation/Returns Std            101.654
evaluation/Returns Max             -3.82874
evaluation/Returns Min           -341.327
evaluation/Actions Mean             0.0114564
evaluation/Actions Std              0.177533
evaluation/Actions Max              0.99936
evaluation/Actions Min             -0.999075
evaluation/Num Paths               15
evaluation/Average Returns       -152.556
time/data storing (s)               0.0028377
time/evaluation sampling (s)        0.328682
time/exploration sampling (s)       0.139196
time/logging (s)                    0.00488934
time/saving (s)                     0.0019245
time/training (s)                   1.99942
time/epoch (s)                      2.47695
time/total (s)                    625.11
Epoch                             254
-----------------------------  ---------------
2019-04-23 01:23:58.866639 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 255 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.287847
trainer/QF2 Loss                    0.218898
trainer/Policy Loss                66.3235
trainer/Q1 Predictions Mean       -64.7813
trainer/Q1 Predictions Std         61.9897
trainer/Q1 Predictions Max        -10.9978
trainer/Q1 Predictions Min       -213.516
trainer/Q2 Predictions Mean       -64.8103
trainer/Q2 Predictions Std         61.9986
trainer/Q2 Predictions Max        -10.9577
trainer/Q2 Predictions Min       -213.633
trainer/Q Targets Mean            -64.7499
trainer/Q Targets Std              62.1428
trainer/Q Targets Max             -10.8849
trainer/Q Targets Min            -214.317
trainer/Log Pis Mean                1.85
trainer/Log Pis Std                 1.20682
trainer/Log Pis Max                 6.29498
trainer/Log Pis Min                -1.25479
trainer/Policy mu Mean             -0.0945987
trainer/Policy mu Std               0.695953
trainer/Policy mu Max               2.18508
trainer/Policy mu Min              -2.93452
trainer/Policy log std Mean        -2.00152
trainer/Policy log std Std          0.500444
trainer/Policy log std Max         -0.420741
trainer/Policy log std Min         -2.72491
trainer/Alpha                       0.0602552
trainer/Alpha Loss                 -0.421379
exploration/num steps total    128200
exploration/num paths total      1282
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.82353
exploration/Rewards Std             1.37618
exploration/Rewards Max            -0.0248832
exploration/Rewards Min            -8.3526
exploration/Returns Mean         -182.353
exploration/Returns Std           115.374
exploration/Returns Max           -30.2614
exploration/Returns Min          -351.802
exploration/Actions Mean           -0.0122089
exploration/Actions Std             0.257196
exploration/Actions Max             0.999638
exploration/Actions Min            -0.999963
exploration/Num Paths               5
exploration/Average Returns      -182.353
evaluation/num steps total     384000
evaluation/num paths total       3840
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.0513
evaluation/Rewards Std              1.21027
evaluation/Rewards Max             -0.0131122
evaluation/Rewards Min             -9.10384
evaluation/Returns Mean          -105.13
evaluation/Returns Std             87.1838
evaluation/Returns Max            -11.3141
evaluation/Returns Min           -267.141
evaluation/Actions Mean             0.00626292
evaluation/Actions Std              0.193174
evaluation/Actions Max              0.99621
evaluation/Actions Min             -0.999691
evaluation/Num Paths               15
evaluation/Average Returns       -105.13
time/data storing (s)               0.00276645
time/evaluation sampling (s)        0.321139
time/exploration sampling (s)       0.139471
time/logging (s)                    0.0048053
time/saving (s)                     0.00153482
time/training (s)                   1.99224
time/epoch (s)                      2.46195
time/total (s)                    627.576
Epoch                             255
-----------------------------  ---------------
2019-04-23 01:24:01.344774 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 256 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   90.2362
trainer/QF2 Loss                   89.9128
trainer/Policy Loss                65.8169
trainer/Q1 Predictions Mean       -64.2439
trainer/Q1 Predictions Std         57.3601
trainer/Q1 Predictions Max        -10.6657
trainer/Q1 Predictions Min       -210.462
trainer/Q2 Predictions Mean       -64.2968
trainer/Q2 Predictions Std         57.426
trainer/Q2 Predictions Max        -10.6225
trainer/Q2 Predictions Min       -210.076
trainer/Q Targets Mean            -63.9407
trainer/Q Targets Std              58.3092
trainer/Q Targets Max              -0.236123
trainer/Q Targets Min            -212.568
trainer/Log Pis Mean                1.97013
trainer/Log Pis Std                 1.5605
trainer/Log Pis Max                 8.64916
trainer/Log Pis Min                -5.51467
trainer/Policy mu Mean             -0.0169504
trainer/Policy mu Std               0.792794
trainer/Policy mu Max               2.64242
trainer/Policy mu Min              -4.14014
trainer/Policy log std Mean        -1.9922
trainer/Policy log std Std          0.554814
trainer/Policy log std Max         -0.247671
trainer/Policy log std Min         -2.7172
trainer/Alpha                       0.0586532
trainer/Alpha Loss                 -0.0847062
exploration/num steps total    128700
exploration/num paths total      1287
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.619909
exploration/Rewards Std             0.840285
exploration/Rewards Max            -0.0118517
exploration/Rewards Min            -7.12953
exploration/Returns Mean          -61.9909
exploration/Returns Std            39.2556
exploration/Returns Max           -32.0996
exploration/Returns Min          -133.501
exploration/Actions Mean            0.0141086
exploration/Actions Std             0.215145
exploration/Actions Max             0.999071
exploration/Actions Min            -0.998192
exploration/Num Paths               5
exploration/Average Returns       -61.9909
evaluation/num steps total     385500
evaluation/num paths total       3855
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.08399
evaluation/Rewards Std              1.20019
evaluation/Rewards Max             -0.0450776
evaluation/Rewards Min             -9.7548
evaluation/Returns Mean          -108.399
evaluation/Returns Std             83.5461
evaluation/Returns Max             -6.98697
evaluation/Returns Min           -307.492
evaluation/Actions Mean             0.0131518
evaluation/Actions Std              0.175182
evaluation/Actions Max              0.999588
evaluation/Actions Min             -0.995452
evaluation/Num Paths               15
evaluation/Average Returns       -108.399
time/data storing (s)               0.00279677
time/evaluation sampling (s)        0.324422
time/exploration sampling (s)       0.137491
time/logging (s)                    0.00427024
time/saving (s)                     0.00155562
time/training (s)                   1.99844
time/epoch (s)                      2.46897
time/total (s)                    630.05
Epoch                             256
-----------------------------  ---------------
2019-04-23 01:24:03.815440 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 257 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                  444.469
trainer/QF2 Loss                  446.168
trainer/Policy Loss                67.0791
trainer/Q1 Predictions Mean       -65.3452
trainer/Q1 Predictions Std         58.7733
trainer/Q1 Predictions Max        -10.8224
trainer/Q1 Predictions Min       -214.578
trainer/Q2 Predictions Mean       -65.3402
trainer/Q2 Predictions Std         58.692
trainer/Q2 Predictions Max        -10.7237
trainer/Q2 Predictions Min       -214.437
trainer/Q Targets Mean            -62.7499
trainer/Q Targets Std              58.348
trainer/Q Targets Max              -2.70768
trainer/Q Targets Min            -216.36
trainer/Log Pis Mean                2.11013
trainer/Log Pis Std                 1.19185
trainer/Log Pis Max                 5.64682
trainer/Log Pis Min                -2.51893
trainer/Policy mu Mean             -0.0885012
trainer/Policy mu Std               0.736991
trainer/Policy mu Max               2.70976
trainer/Policy mu Min              -3.18273
trainer/Policy log std Mean        -2.05022
trainer/Policy log std Std          0.508887
trainer/Policy log std Max         -0.422047
trainer/Policy log std Min         -2.71431
trainer/Alpha                       0.0584306
trainer/Alpha Loss                  0.312752
exploration/num steps total    129200
exploration/num paths total      1292
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.64063
exploration/Rewards Std             1.2297
exploration/Rewards Max            -0.180713
exploration/Rewards Min            -9.93736
exploration/Returns Mean         -164.063
exploration/Returns Std            74.7643
exploration/Returns Max           -80.9012
exploration/Returns Min          -253.981
exploration/Actions Mean           -0.00646135
exploration/Actions Std             0.233383
exploration/Actions Max             0.998321
exploration/Actions Min            -0.997905
exploration/Num Paths               5
exploration/Average Returns      -164.063
evaluation/num steps total     387000
evaluation/num paths total       3870
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.10131
evaluation/Rewards Std              1.46106
evaluation/Rewards Max             -0.0220786
evaluation/Rewards Min            -11.8602
evaluation/Returns Mean          -110.131
evaluation/Returns Std            105.193
evaluation/Returns Max             -4.46296
evaluation/Returns Min           -312.493
evaluation/Actions Mean            -0.00238961
evaluation/Actions Std              0.183777
evaluation/Actions Max              0.997916
evaluation/Actions Min             -0.999965
evaluation/Num Paths               15
evaluation/Average Returns       -110.131
time/data storing (s)               0.00284483
time/evaluation sampling (s)        0.32636
time/exploration sampling (s)       0.140901
time/logging (s)                    0.00476991
time/saving (s)                     0.00156246
time/training (s)                   1.98669
time/epoch (s)                      2.46313
time/total (s)                    632.517
Epoch                             257
-----------------------------  ---------------
2019-04-23 01:24:06.272232 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 258 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   51.084
trainer/QF2 Loss                   50.3813
trainer/Policy Loss                61.9112
trainer/Q1 Predictions Mean       -60.1959
trainer/Q1 Predictions Std         55.771
trainer/Q1 Predictions Max        -10.5903
trainer/Q1 Predictions Min       -212.482
trainer/Q2 Predictions Mean       -60.201
trainer/Q2 Predictions Std         55.8655
trainer/Q2 Predictions Max        -10.5653
trainer/Q2 Predictions Min       -212.547
trainer/Q Targets Mean            -60.0093
trainer/Q Targets Std              56.5378
trainer/Q Targets Max              -1.43868
trainer/Q Targets Min            -214.061
trainer/Log Pis Mean                2.1451
trainer/Log Pis Std                 1.42494
trainer/Log Pis Max                 7.53117
trainer/Log Pis Min                -2.47672
trainer/Policy mu Mean              0.0209061
trainer/Policy mu Std               0.842676
trainer/Policy mu Max               3.25324
trainer/Policy mu Min              -3.75345
trainer/Policy log std Mean        -2.04672
trainer/Policy log std Std          0.552665
trainer/Policy log std Max         -0.39616
trainer/Policy log std Min         -2.70665
trainer/Alpha                       0.0585589
trainer/Alpha Loss                  0.411764
exploration/num steps total    129700
exploration/num paths total      1297
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.931551
exploration/Rewards Std             1.42005
exploration/Rewards Max            -0.00939553
exploration/Rewards Min            -9.58155
exploration/Returns Mean          -93.1551
exploration/Returns Std            93.0466
exploration/Returns Max           -35.1089
exploration/Returns Min          -277.886
exploration/Actions Mean            0.00126286
exploration/Actions Std             0.234431
exploration/Actions Max             0.998723
exploration/Actions Min            -0.998347
exploration/Num Paths               5
exploration/Average Returns       -93.1551
evaluation/num steps total     388500
evaluation/num paths total       3885
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.37736
evaluation/Rewards Std              1.47781
evaluation/Rewards Max             -0.0633704
evaluation/Rewards Min            -11.0968
evaluation/Returns Mean          -137.736
evaluation/Returns Std            121.203
evaluation/Returns Max            -10.0033
evaluation/Returns Min           -336.263
evaluation/Actions Mean            -0.00104704
evaluation/Actions Std              0.178671
evaluation/Actions Max              0.999932
evaluation/Actions Min             -0.997354
evaluation/Num Paths               15
evaluation/Average Returns       -137.736
time/data storing (s)               0.00261446
time/evaluation sampling (s)        0.331156
time/exploration sampling (s)       0.137515
time/logging (s)                    0.00411823
time/saving (s)                     0.00195737
time/training (s)                   1.97026
time/epoch (s)                      2.44762
time/total (s)                    634.969
Epoch                             258
-----------------------------  ---------------
2019-04-23 01:24:08.709992 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 259 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                  715.574
trainer/QF2 Loss                  714.905
trainer/Policy Loss                74.6265
trainer/Q1 Predictions Mean       -73.1097
trainer/Q1 Predictions Std         65.0677
trainer/Q1 Predictions Max        -10.6508
trainer/Q1 Predictions Min       -212.788
trainer/Q2 Predictions Mean       -73.1186
trainer/Q2 Predictions Std         65.0438
trainer/Q2 Predictions Max        -10.7002
trainer/Q2 Predictions Min       -212.611
trainer/Q Targets Mean            -69.3651
trainer/Q Targets Std              63.3814
trainer/Q Targets Max              -4.83318
trainer/Q Targets Min            -213.512
trainer/Log Pis Mean                2.11871
trainer/Log Pis Std                 1.33142
trainer/Log Pis Max                 7.43461
trainer/Log Pis Min                -0.611758
trainer/Policy mu Mean             -0.202537
trainer/Policy mu Std               0.962796
trainer/Policy mu Max               2.99459
trainer/Policy mu Min              -4.44788
trainer/Policy log std Mean        -1.83738
trainer/Policy log std Std          0.649679
trainer/Policy log std Max         -0.198772
trainer/Policy log std Min         -2.61294
trainer/Alpha                       0.0588111
trainer/Alpha Loss                  0.336343
exploration/num steps total    130200
exploration/num paths total      1302
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.3971
exploration/Rewards Std             1.23881
exploration/Rewards Max            -0.0110079
exploration/Rewards Min            -9.39928
exploration/Returns Mean         -139.71
exploration/Returns Std            98.7523
exploration/Returns Max           -17.6676
exploration/Returns Min          -297.767
exploration/Actions Mean           -0.0299599
exploration/Actions Std             0.227605
exploration/Actions Max             0.615667
exploration/Actions Min            -0.999891
exploration/Num Paths               5
exploration/Average Returns      -139.71
evaluation/num steps total     390000
evaluation/num paths total       3900
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.28705
evaluation/Rewards Std              1.39396
evaluation/Rewards Max             -0.0412077
evaluation/Rewards Min            -11.0906
evaluation/Returns Mean          -128.705
evaluation/Returns Std             94.8605
evaluation/Returns Max            -47.4689
evaluation/Returns Min           -319.584
evaluation/Actions Mean            -0.0030011
evaluation/Actions Std              0.197637
evaluation/Actions Max              0.999783
evaluation/Actions Min             -0.999606
evaluation/Num Paths               15
evaluation/Average Returns       -128.705
time/data storing (s)               0.00282769
time/evaluation sampling (s)        0.328804
time/exploration sampling (s)       0.13752
time/logging (s)                    0.00471332
time/saving (s)                     0.00191477
time/training (s)                   1.95433
time/epoch (s)                      2.43011
time/total (s)                    637.404
Epoch                             259
-----------------------------  ---------------
2019-04-23 01:24:11.172135 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 260 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.65961
trainer/QF2 Loss                    1.8884
trainer/Policy Loss                63.7886
trainer/Q1 Predictions Mean       -62.347
trainer/Q1 Predictions Std         61.7678
trainer/Q1 Predictions Max        -10.6814
trainer/Q1 Predictions Min       -212.194
trainer/Q2 Predictions Mean       -62.2925
trainer/Q2 Predictions Std         61.7125
trainer/Q2 Predictions Max        -10.7052
trainer/Q2 Predictions Min       -212.147
trainer/Q Targets Mean            -63.1098
trainer/Q Targets Std              62.6016
trainer/Q Targets Max             -10.6279
trainer/Q Targets Min            -215.25
trainer/Log Pis Mean                1.94456
trainer/Log Pis Std                 1.15439
trainer/Log Pis Max                 5.33404
trainer/Log Pis Min                -1.53712
trainer/Policy mu Mean             -0.0641635
trainer/Policy mu Std               0.814653
trainer/Policy mu Max               3.68869
trainer/Policy mu Min              -3.13674
trainer/Policy log std Mean        -1.93969
trainer/Policy log std Std          0.592579
trainer/Policy log std Max         -0.107009
trainer/Policy log std Min         -2.69355
trainer/Alpha                       0.0590585
trainer/Alpha Loss                 -0.156861
exploration/num steps total    130700
exploration/num paths total      1307
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.29562
exploration/Rewards Std             1.50774
exploration/Rewards Max            -0.00471793
exploration/Rewards Min            -9.41514
exploration/Returns Mean         -129.562
exploration/Returns Std           120.342
exploration/Returns Max           -18.7312
exploration/Returns Min          -336.751
exploration/Actions Mean            0.0360247
exploration/Actions Std             0.255774
exploration/Actions Max             0.999452
exploration/Actions Min            -0.877679
exploration/Num Paths               5
exploration/Average Returns      -129.562
evaluation/num steps total     391500
evaluation/num paths total       3915
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.950601
evaluation/Rewards Std              1.23831
evaluation/Rewards Max             -0.026715
evaluation/Rewards Min             -8.94857
evaluation/Returns Mean           -95.0601
evaluation/Returns Std             92.084
evaluation/Returns Max            -11.4145
evaluation/Returns Min           -349.257
evaluation/Actions Mean            -0.0154173
evaluation/Actions Std              0.170571
evaluation/Actions Max              0.998014
evaluation/Actions Min             -0.999888
evaluation/Num Paths               15
evaluation/Average Returns        -95.0601
time/data storing (s)               0.00262558
time/evaluation sampling (s)        0.329183
time/exploration sampling (s)       0.136866
time/logging (s)                    0.00475587
time/saving (s)                     0.00187001
time/training (s)                   1.97847
time/epoch (s)                      2.45377
time/total (s)                    639.862
Epoch                             260
-----------------------------  ---------------
2019-04-23 01:24:13.644720 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 261 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                  191.423
trainer/QF2 Loss                  191.893
trainer/Policy Loss                73.4802
trainer/Q1 Predictions Mean       -71.8477
trainer/Q1 Predictions Std         68.2446
trainer/Q1 Predictions Max        -10.3874
trainer/Q1 Predictions Min       -205.694
trainer/Q2 Predictions Mean       -71.9434
trainer/Q2 Predictions Std         68.3451
trainer/Q2 Predictions Max        -10.4361
trainer/Q2 Predictions Min       -205.984
trainer/Q Targets Mean            -71.1693
trainer/Q Targets Std              70.1346
trainer/Q Targets Max              -1.99348
trainer/Q Targets Min            -210.696
trainer/Log Pis Mean                2.24637
trainer/Log Pis Std                 1.6279
trainer/Log Pis Max                 7.39859
trainer/Log Pis Min                -3.74295
trainer/Policy mu Mean             -0.285788
trainer/Policy mu Std               0.972253
trainer/Policy mu Max               3.28928
trainer/Policy mu Min              -3.21355
trainer/Policy log std Mean        -1.77989
trainer/Policy log std Std          0.659446
trainer/Policy log std Max         -0.264674
trainer/Policy log std Min         -2.61323
trainer/Alpha                       0.0623941
trainer/Alpha Loss                  0.683535
exploration/num steps total    131200
exploration/num paths total      1312
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.370174
exploration/Rewards Std             0.926368
exploration/Rewards Max            -0.00847876
exploration/Rewards Min            -9.32026
exploration/Returns Mean          -37.0174
exploration/Returns Std             7.73933
exploration/Returns Max           -26.7304
exploration/Returns Min           -49.9723
exploration/Actions Mean            0.0366532
exploration/Actions Std             0.205665
exploration/Actions Max             0.997021
exploration/Actions Min            -0.839619
exploration/Num Paths               5
exploration/Average Returns       -37.0174
evaluation/num steps total     393000
evaluation/num paths total       3930
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.645565
evaluation/Rewards Std              1.17862
evaluation/Rewards Max             -0.0599282
evaluation/Rewards Min             -9.74791
evaluation/Returns Mean           -64.5565
evaluation/Returns Std             56.7641
evaluation/Returns Max             -7.26922
evaluation/Returns Min           -211.595
evaluation/Actions Mean             0.00709858
evaluation/Actions Std              0.200145
evaluation/Actions Max              0.997418
evaluation/Actions Min             -0.999196
evaluation/Num Paths               15
evaluation/Average Returns        -64.5565
time/data storing (s)               0.00276609
time/evaluation sampling (s)        0.32514
time/exploration sampling (s)       0.137322
time/logging (s)                    0.00476159
time/saving (s)                     0.0101216
time/training (s)                   1.9847
time/epoch (s)                      2.46481
time/total (s)                    642.331
Epoch                             261
-----------------------------  ---------------
2019-04-23 01:24:16.123164 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 262 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    2.64964
trainer/QF2 Loss                    2.81954
trainer/Policy Loss                70.252
trainer/Q1 Predictions Mean       -68.759
trainer/Q1 Predictions Std         63.978
trainer/Q1 Predictions Max        -10.2629
trainer/Q1 Predictions Min       -229.856
trainer/Q2 Predictions Mean       -68.7434
trainer/Q2 Predictions Std         63.9018
trainer/Q2 Predictions Max        -10.2302
trainer/Q2 Predictions Min       -230.544
trainer/Q Targets Mean            -70.0045
trainer/Q Targets Std              64.897
trainer/Q Targets Max             -10.4818
trainer/Q Targets Min            -232.928
trainer/Log Pis Mean                1.86877
trainer/Log Pis Std                 1.30141
trainer/Log Pis Max                 5.61746
trainer/Log Pis Min                -3.88058
trainer/Policy mu Mean             -0.0928186
trainer/Policy mu Std               0.732587
trainer/Policy mu Max               2.7673
trainer/Policy mu Min              -3.90962
trainer/Policy log std Mean        -2.00143
trainer/Policy log std Std          0.600799
trainer/Policy log std Max          0.436446
trainer/Policy log std Min         -2.71472
trainer/Alpha                       0.0600034
trainer/Alpha Loss                 -0.369199
exploration/num steps total    131700
exploration/num paths total      1317
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.74076
exploration/Rewards Std             1.43196
exploration/Rewards Max            -0.0157163
exploration/Rewards Min            -8.16523
exploration/Returns Mean         -174.076
exploration/Returns Std           116.259
exploration/Returns Max           -22.893
exploration/Returns Min          -301.536
exploration/Actions Mean           -0.0189535
exploration/Actions Std             0.271529
exploration/Actions Max             0.960284
exploration/Actions Min            -0.999662
exploration/Num Paths               5
exploration/Average Returns      -174.076
evaluation/num steps total     394500
evaluation/num paths total       3945
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.5415
evaluation/Rewards Std              1.3363
evaluation/Rewards Max             -0.0545445
evaluation/Rewards Min             -9.78285
evaluation/Returns Mean          -154.15
evaluation/Returns Std            116.765
evaluation/Returns Max            -13.7436
evaluation/Returns Min           -320.975
evaluation/Actions Mean             0.00513273
evaluation/Actions Std              0.179612
evaluation/Actions Max              0.99649
evaluation/Actions Min             -0.996988
evaluation/Num Paths               15
evaluation/Average Returns       -154.15
time/data storing (s)               0.00274544
time/evaluation sampling (s)        0.329115
time/exploration sampling (s)       0.140524
time/logging (s)                    0.00481072
time/saving (s)                     0.00195868
time/training (s)                   1.99075
time/epoch (s)                      2.4699
time/total (s)                    644.805
Epoch                             262
-----------------------------  ---------------
2019-04-23 01:24:18.565387 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 263 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    6.6442
trainer/QF2 Loss                    6.70099
trainer/Policy Loss                68.6648
trainer/Q1 Predictions Mean       -67.3134
trainer/Q1 Predictions Std         60.4416
trainer/Q1 Predictions Max        -10.2596
trainer/Q1 Predictions Min       -206.328
trainer/Q2 Predictions Mean       -67.3502
trainer/Q2 Predictions Std         60.4231
trainer/Q2 Predictions Max        -10.2547
trainer/Q2 Predictions Min       -205.891
trainer/Q Targets Mean            -67.3844
trainer/Q Targets Std              61.0949
trainer/Q Targets Max              -1.03796
trainer/Q Targets Min            -208.244
trainer/Log Pis Mean                1.76094
trainer/Log Pis Std                 1.15551
trainer/Log Pis Max                 6.30574
trainer/Log Pis Min                -1.7105
trainer/Policy mu Mean             -0.210067
trainer/Policy mu Std               0.674957
trainer/Policy mu Max               2.33694
trainer/Policy mu Min              -2.17165
trainer/Policy log std Mean        -1.95042
trainer/Policy log std Std          0.555942
trainer/Policy log std Max         -0.518144
trainer/Policy log std Min         -2.69386
trainer/Alpha                       0.0600635
trainer/Alpha Loss                 -0.672297
exploration/num steps total    132200
exploration/num paths total      1322
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.52273
exploration/Rewards Std             1.34474
exploration/Rewards Max            -0.00298492
exploration/Rewards Min            -5.22876
exploration/Returns Mean         -152.273
exploration/Returns Std           126.843
exploration/Returns Max           -16.7371
exploration/Returns Min          -306.478
exploration/Actions Mean           -0.0113175
exploration/Actions Std             0.251405
exploration/Actions Max             0.944359
exploration/Actions Min            -0.998056
exploration/Num Paths               5
exploration/Average Returns      -152.273
evaluation/num steps total     396000
evaluation/num paths total       3960
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.984336
evaluation/Rewards Std              1.08797
evaluation/Rewards Max             -0.024553
evaluation/Rewards Min            -10.8294
evaluation/Returns Mean           -98.4336
evaluation/Returns Std             54.767
evaluation/Returns Max            -15.4696
evaluation/Returns Min           -210.989
evaluation/Actions Mean            -0.0106763
evaluation/Actions Std              0.189144
evaluation/Actions Max              0.997962
evaluation/Actions Min             -0.999866
evaluation/Num Paths               15
evaluation/Average Returns        -98.4336
time/data storing (s)               0.00260434
time/evaluation sampling (s)        0.322581
time/exploration sampling (s)       0.139409
time/logging (s)                    0.00483611
time/saving (s)                     0.00190185
time/training (s)                   1.9623
time/epoch (s)                      2.43363
time/total (s)                    647.243
Epoch                             263
-----------------------------  ---------------
2019-04-23 01:24:21.044715 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 264 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.17247
trainer/QF2 Loss                    1.31327
trainer/Policy Loss                81.8966
trainer/Q1 Predictions Mean       -80.5168
trainer/Q1 Predictions Std         63.8193
trainer/Q1 Predictions Max        -10.6929
trainer/Q1 Predictions Min       -207.29
trainer/Q2 Predictions Mean       -80.4348
trainer/Q2 Predictions Std         63.7276
trainer/Q2 Predictions Max        -10.7284
trainer/Q2 Predictions Min       -207.896
trainer/Q Targets Mean            -80.8816
trainer/Q Targets Std              64.4679
trainer/Q Targets Max             -10.7552
trainer/Q Targets Min            -210.702
trainer/Log Pis Mean                1.86872
trainer/Log Pis Std                 1.66526
trainer/Log Pis Max                 6.69441
trainer/Log Pis Min                -3.53646
trainer/Policy mu Mean              0.28301
trainer/Policy mu Std               0.82719
trainer/Policy mu Max               3.77695
trainer/Policy mu Min              -1.96509
trainer/Policy log std Mean        -1.89836
trainer/Policy log std Std          0.625645
trainer/Policy log std Max         -0.249842
trainer/Policy log std Min         -2.84918
trainer/Alpha                       0.0588153
trainer/Alpha Loss                 -0.371939
exploration/num steps total    132700
exploration/num paths total      1327
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.10265
exploration/Rewards Std             1.42119
exploration/Rewards Max            -0.00760302
exploration/Rewards Min           -10.174
exploration/Returns Mean         -110.265
exploration/Returns Std           105.252
exploration/Returns Max           -21.2124
exploration/Returns Min          -295.053
exploration/Actions Mean            0.0442372
exploration/Actions Std             0.224223
exploration/Actions Max             0.999821
exploration/Actions Min            -0.643049
exploration/Num Paths               5
exploration/Average Returns      -110.265
evaluation/num steps total     397500
evaluation/num paths total       3975
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.31624
evaluation/Rewards Std              1.39781
evaluation/Rewards Max             -0.0455635
evaluation/Rewards Min            -10.0801
evaluation/Returns Mean          -131.624
evaluation/Returns Std            106.821
evaluation/Returns Max            -30.9109
evaluation/Returns Min           -360.488
evaluation/Actions Mean             0.00334023
evaluation/Actions Std              0.183327
evaluation/Actions Max              0.999245
evaluation/Actions Min             -0.996294
evaluation/Num Paths               15
evaluation/Average Returns       -131.624
time/data storing (s)               0.00263985
time/evaluation sampling (s)        0.328416
time/exploration sampling (s)       0.139051
time/logging (s)                    0.00472161
time/saving (s)                     0.00194642
time/training (s)                   1.99389
time/epoch (s)                      2.47066
time/total (s)                    649.718
Epoch                             264
-----------------------------  ---------------
2019-04-23 01:24:23.501201 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 265 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.65112
trainer/QF2 Loss                    0.647127
trainer/Policy Loss                71.6039
trainer/Q1 Predictions Mean       -69.7577
trainer/Q1 Predictions Std         64.6596
trainer/Q1 Predictions Max        -10.0044
trainer/Q1 Predictions Min       -206.402
trainer/Q2 Predictions Mean       -69.765
trainer/Q2 Predictions Std         64.675
trainer/Q2 Predictions Max         -9.89821
trainer/Q2 Predictions Min       -206.496
trainer/Q Targets Mean            -70.203
trainer/Q Targets Std              64.9985
trainer/Q Targets Max             -10.2049
trainer/Q Targets Min            -207.86
trainer/Log Pis Mean                2.48677
trainer/Log Pis Std                 1.32248
trainer/Log Pis Max                 9.14738
trainer/Log Pis Min                -0.779674
trainer/Policy mu Mean             -0.26568
trainer/Policy mu Std               0.93204
trainer/Policy mu Max               3.85365
trainer/Policy mu Min              -2.94646
trainer/Policy log std Mean        -1.85886
trainer/Policy log std Std          0.627539
trainer/Policy log std Max         -0.433907
trainer/Policy log std Min         -2.61704
trainer/Alpha                       0.0566808
trainer/Alpha Loss                  1.39733
exploration/num steps total    133200
exploration/num paths total      1332
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.05017
exploration/Rewards Std             1.34777
exploration/Rewards Max            -0.00989744
exploration/Rewards Min            -7.23364
exploration/Returns Mean         -105.017
exploration/Returns Std            99.2903
exploration/Returns Max           -39.7199
exploration/Returns Min          -300.045
exploration/Actions Mean           -0.023669
exploration/Actions Std             0.258347
exploration/Actions Max             0.996504
exploration/Actions Min            -0.999685
exploration/Num Paths               5
exploration/Average Returns      -105.017
evaluation/num steps total     399000
evaluation/num paths total       3990
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.977258
evaluation/Rewards Std              1.19688
evaluation/Rewards Max             -0.0135001
evaluation/Rewards Min            -11.5658
evaluation/Returns Mean           -97.7258
evaluation/Returns Std             75.3483
evaluation/Returns Max             -9.56366
evaluation/Returns Min           -268.558
evaluation/Actions Mean             0.000951891
evaluation/Actions Std              0.185378
evaluation/Actions Max              0.999483
evaluation/Actions Min             -0.999823
evaluation/Num Paths               15
evaluation/Average Returns        -97.7258
time/data storing (s)               0.00259816
time/evaluation sampling (s)        0.333417
time/exploration sampling (s)       0.141531
time/logging (s)                    0.00414135
time/saving (s)                     0.00200626
time/training (s)                   1.96421
time/epoch (s)                      2.4479
time/total (s)                    652.171
Epoch                             265
-----------------------------  ----------------
2019-04-23 01:24:25.965153 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 266 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   30.071
trainer/QF2 Loss                   30.3447
trainer/Policy Loss                62.2344
trainer/Q1 Predictions Mean       -60.8627
trainer/Q1 Predictions Std         59.1475
trainer/Q1 Predictions Max         -9.99217
trainer/Q1 Predictions Min       -201.924
trainer/Q2 Predictions Mean       -60.8486
trainer/Q2 Predictions Std         59.1216
trainer/Q2 Predictions Max         -9.96593
trainer/Q2 Predictions Min       -201.633
trainer/Q Targets Mean            -60.7128
trainer/Q Targets Std              60.4499
trainer/Q Targets Max              -0.525621
trainer/Q Targets Min            -203.621
trainer/Log Pis Mean                1.90523
trainer/Log Pis Std                 1.08506
trainer/Log Pis Max                 4.96955
trainer/Log Pis Min                -3.10986
trainer/Policy mu Mean             -0.18153
trainer/Policy mu Std               0.676861
trainer/Policy mu Max               2.17685
trainer/Policy mu Min              -2.77946
trainer/Policy log std Mean        -1.99683
trainer/Policy log std Std          0.58775
trainer/Policy log std Max         -0.326377
trainer/Policy log std Min         -2.76541
trainer/Alpha                       0.0565551
trainer/Alpha Loss                 -0.272237
exploration/num steps total    133700
exploration/num paths total      1337
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.22991
exploration/Rewards Std             1.33138
exploration/Rewards Max            -0.00940956
exploration/Rewards Min            -9.74336
exploration/Returns Mean         -122.991
exploration/Returns Std            81.7342
exploration/Returns Max           -35.2124
exploration/Returns Min          -265.111
exploration/Actions Mean            0.0242135
exploration/Actions Std             0.24115
exploration/Actions Max             0.999406
exploration/Actions Min            -0.999989
exploration/Num Paths               5
exploration/Average Returns      -122.991
evaluation/num steps total     400500
evaluation/num paths total       4005
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.13713
evaluation/Rewards Std              1.26679
evaluation/Rewards Max             -0.052177
evaluation/Rewards Min            -10.9762
evaluation/Returns Mean          -113.713
evaluation/Returns Std             97.5597
evaluation/Returns Max            -15.7323
evaluation/Returns Min           -321.001
evaluation/Actions Mean            -0.0187806
evaluation/Actions Std              0.176379
evaluation/Actions Max              0.999571
evaluation/Actions Min             -0.999738
evaluation/Num Paths               15
evaluation/Average Returns       -113.713
time/data storing (s)               0.00278154
time/evaluation sampling (s)        0.332951
time/exploration sampling (s)       0.137321
time/logging (s)                    0.00478515
time/saving (s)                     0.00193043
time/training (s)                   1.97628
time/epoch (s)                      2.45604
time/total (s)                    654.632
Epoch                             266
-----------------------------  ---------------
2019-04-23 01:24:28.440821 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 267 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    2.05367
trainer/QF2 Loss                    2.2554
trainer/Policy Loss                63.9884
trainer/Q1 Predictions Mean       -62.1345
trainer/Q1 Predictions Std         55.8274
trainer/Q1 Predictions Max         -9.9737
trainer/Q1 Predictions Min       -196.918
trainer/Q2 Predictions Mean       -62.1664
trainer/Q2 Predictions Std         55.8849
trainer/Q2 Predictions Max         -9.95517
trainer/Q2 Predictions Min       -196.894
trainer/Q Targets Mean            -63.1389
trainer/Q Targets Std              56.6453
trainer/Q Targets Max             -10.0995
trainer/Q Targets Min            -201.195
trainer/Log Pis Mean                2.23566
trainer/Log Pis Std                 1.68673
trainer/Log Pis Max                 9.68533
trainer/Log Pis Min                -3.07502
trainer/Policy mu Mean             -0.203351
trainer/Policy mu Std               0.989556
trainer/Policy mu Max               3.52515
trainer/Policy mu Min              -3.46092
trainer/Policy log std Mean        -1.87114
trainer/Policy log std Std          0.643726
trainer/Policy log std Max         -0.378908
trainer/Policy log std Min         -2.65293
trainer/Alpha                       0.056541
trainer/Alpha Loss                  0.677028
exploration/num steps total    134200
exploration/num paths total      1342
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.805724
exploration/Rewards Std             0.930106
exploration/Rewards Max            -0.00540309
exploration/Rewards Min            -7.50762
exploration/Returns Mean          -80.5724
exploration/Returns Std            46.5253
exploration/Returns Max           -42.8384
exploration/Returns Min          -162.99
exploration/Actions Mean            0.0103153
exploration/Actions Std             0.228129
exploration/Actions Max             0.999681
exploration/Actions Min            -0.995618
exploration/Num Paths               5
exploration/Average Returns       -80.5724
evaluation/num steps total     402000
evaluation/num paths total       4020
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.777255
evaluation/Rewards Std              1.03517
evaluation/Rewards Max             -0.0175029
evaluation/Rewards Min             -8.3448
evaluation/Returns Mean           -77.7255
evaluation/Returns Std             70.5707
evaluation/Returns Max            -12.606
evaluation/Returns Min           -290.638
evaluation/Actions Mean             0.011122
evaluation/Actions Std              0.16563
evaluation/Actions Max              0.997293
evaluation/Actions Min             -0.999539
evaluation/Num Paths               15
evaluation/Average Returns        -77.7255
time/data storing (s)               0.00281243
time/evaluation sampling (s)        0.331677
time/exploration sampling (s)       0.139762
time/logging (s)                    0.00476615
time/saving (s)                     0.00194295
time/training (s)                   1.98601
time/epoch (s)                      2.46697
time/total (s)                    657.103
Epoch                             267
-----------------------------  ---------------
2019-04-23 01:24:30.958994 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 268 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.857375
trainer/QF2 Loss                    0.916889
trainer/Policy Loss                69.7946
trainer/Q1 Predictions Mean       -68.2233
trainer/Q1 Predictions Std         60.2626
trainer/Q1 Predictions Max        -10.0545
trainer/Q1 Predictions Min       -199.416
trainer/Q2 Predictions Mean       -68.1723
trainer/Q2 Predictions Std         60.1916
trainer/Q2 Predictions Max        -10.097
trainer/Q2 Predictions Min       -199.983
trainer/Q Targets Mean            -68.6704
trainer/Q Targets Std              60.7064
trainer/Q Targets Max             -10.1335
trainer/Q Targets Min            -202.53
trainer/Log Pis Mean                2.16295
trainer/Log Pis Std                 1.56361
trainer/Log Pis Max                 8.94249
trainer/Log Pis Min                -2.44121
trainer/Policy mu Mean             -0.180196
trainer/Policy mu Std               0.876678
trainer/Policy mu Max               3.07089
trainer/Policy mu Min              -3.72448
trainer/Policy log std Mean        -1.93907
trainer/Policy log std Std          0.621921
trainer/Policy log std Max         -0.342332
trainer/Policy log std Min         -2.71303
trainer/Alpha                       0.0565167
trainer/Alpha Loss                  0.468204
exploration/num steps total    134700
exploration/num paths total      1347
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.29513
exploration/Rewards Std             1.37247
exploration/Rewards Max            -0.0198417
exploration/Rewards Min            -8.55056
exploration/Returns Mean         -129.513
exploration/Returns Std           113.684
exploration/Returns Max           -23.0023
exploration/Returns Min          -281.28
exploration/Actions Mean           -0.00420625
exploration/Actions Std             0.251252
exploration/Actions Max             0.998395
exploration/Actions Min            -0.999359
exploration/Num Paths               5
exploration/Average Returns      -129.513
evaluation/num steps total     403500
evaluation/num paths total       4035
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.39303
evaluation/Rewards Std              1.35656
evaluation/Rewards Max             -0.0594496
evaluation/Rewards Min            -10.7374
evaluation/Returns Mean          -139.303
evaluation/Returns Std             97.8581
evaluation/Returns Max            -17.3042
evaluation/Returns Min           -310.475
evaluation/Actions Mean            -0.00617563
evaluation/Actions Std              0.191981
evaluation/Actions Max              0.998777
evaluation/Actions Min             -0.999828
evaluation/Num Paths               15
evaluation/Average Returns       -139.303
time/data storing (s)               0.00310854
time/evaluation sampling (s)        0.330714
time/exploration sampling (s)       0.160068
time/logging (s)                    0.00472451
time/saving (s)                     0.00194782
time/training (s)                   2.00889
time/epoch (s)                      2.50945
time/total (s)                    659.617
Epoch                             268
-----------------------------  ---------------
2019-04-23 01:24:33.439125 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 269 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.92142
trainer/QF2 Loss                    1.98543
trainer/Policy Loss                57.1705
trainer/Q1 Predictions Mean       -55.4607
trainer/Q1 Predictions Std         56.6535
trainer/Q1 Predictions Max        -10.0378
trainer/Q1 Predictions Min       -197.505
trainer/Q2 Predictions Mean       -55.4424
trainer/Q2 Predictions Std         56.6055
trainer/Q2 Predictions Max         -9.99348
trainer/Q2 Predictions Min       -197.81
trainer/Q Targets Mean            -55.6092
trainer/Q Targets Std              57.0917
trainer/Q Targets Max              -0.166407
trainer/Q Targets Min            -198.641
trainer/Log Pis Mean                2.06392
trainer/Log Pis Std                 1.3159
trainer/Log Pis Max                 6.55334
trainer/Log Pis Min                -1.81255
trainer/Policy mu Mean             -0.00407045
trainer/Policy mu Std               0.78057
trainer/Policy mu Max               2.45004
trainer/Policy mu Min              -3.45884
trainer/Policy log std Mean        -2.04492
trainer/Policy log std Std          0.561986
trainer/Policy log std Max         -0.392766
trainer/Policy log std Min         -2.84946
trainer/Alpha                       0.0550333
trainer/Alpha Loss                  0.185365
exploration/num steps total    135200
exploration/num paths total      1352
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.26451
exploration/Rewards Std             1.31973
exploration/Rewards Max            -0.0139795
exploration/Rewards Min            -9.98783
exploration/Returns Mean         -126.451
exploration/Returns Std            69.126
exploration/Returns Max           -28.4434
exploration/Returns Min          -205.95
exploration/Actions Mean           -0.0180553
exploration/Actions Std             0.278495
exploration/Actions Max             0.998714
exploration/Actions Min            -0.999998
exploration/Num Paths               5
exploration/Average Returns      -126.451
evaluation/num steps total     405000
evaluation/num paths total       4050
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.38959
evaluation/Rewards Std              1.39023
evaluation/Rewards Max             -0.0304044
evaluation/Rewards Min             -9.98468
evaluation/Returns Mean          -138.959
evaluation/Returns Std            106.932
evaluation/Returns Max             -7.66745
evaluation/Returns Min           -325.365
evaluation/Actions Mean            -0.0133898
evaluation/Actions Std              0.182132
evaluation/Actions Max              0.995519
evaluation/Actions Min             -0.999867
evaluation/Num Paths               15
evaluation/Average Returns       -138.959
time/data storing (s)               0.00277749
time/evaluation sampling (s)        0.332296
time/exploration sampling (s)       0.137721
time/logging (s)                    0.00534978
time/saving (s)                     0.00205334
time/training (s)                   1.99201
time/epoch (s)                      2.47221
time/total (s)                    662.094
Epoch                             269
-----------------------------  ---------------
2019-04-23 01:24:35.945596 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 270 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.555089
trainer/QF2 Loss                    0.429929
trainer/Policy Loss                60.5278
trainer/Q1 Predictions Mean       -58.7286
trainer/Q1 Predictions Std         56.1565
trainer/Q1 Predictions Max        -10.081
trainer/Q1 Predictions Min       -194.951
trainer/Q2 Predictions Mean       -58.7358
trainer/Q2 Predictions Std         56.1901
trainer/Q2 Predictions Max        -10.0808
trainer/Q2 Predictions Min       -194.829
trainer/Q Targets Mean            -59.0029
trainer/Q Targets Std              56.48
trainer/Q Targets Max              -9.93154
trainer/Q Targets Min            -195.502
trainer/Log Pis Mean                2.04331
trainer/Log Pis Std                 1.06203
trainer/Log Pis Max                 4.61051
trainer/Log Pis Min                -2.01344
trainer/Policy mu Mean             -0.0458666
trainer/Policy mu Std               0.751774
trainer/Policy mu Max               2.92942
trainer/Policy mu Min              -3.04533
trainer/Policy log std Mean        -2.0348
trainer/Policy log std Std          0.564653
trainer/Policy log std Max         -0.362656
trainer/Policy log std Min         -2.7186
trainer/Alpha                       0.055284
trainer/Alpha Loss                  0.125378
exploration/num steps total    135700
exploration/num paths total      1357
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.15313
exploration/Rewards Std             1.18949
exploration/Rewards Max            -0.00823263
exploration/Rewards Min            -6.44136
exploration/Returns Mean         -115.313
exploration/Returns Std           104.291
exploration/Returns Max           -25.7702
exploration/Returns Min          -309.871
exploration/Actions Mean           -0.00838618
exploration/Actions Std             0.209023
exploration/Actions Max             0.997403
exploration/Actions Min            -0.997206
exploration/Num Paths               5
exploration/Average Returns      -115.313
evaluation/num steps total     406500
evaluation/num paths total       4065
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.05188
evaluation/Rewards Std              1.29927
evaluation/Rewards Max             -0.0165445
evaluation/Rewards Min            -11.0931
evaluation/Returns Mean          -105.188
evaluation/Returns Std             96.0847
evaluation/Returns Max             -6.89129
evaluation/Returns Min           -315.953
evaluation/Actions Mean            -0.00983887
evaluation/Actions Std              0.176719
evaluation/Actions Max              0.993355
evaluation/Actions Min             -0.999867
evaluation/Num Paths               15
evaluation/Average Returns       -105.188
time/data storing (s)               0.00285792
time/evaluation sampling (s)        0.338615
time/exploration sampling (s)       0.15007
time/logging (s)                    0.00479712
time/saving (s)                     0.00195548
time/training (s)                   1.99817
time/epoch (s)                      2.49646
time/total (s)                    664.595
Epoch                             270
-----------------------------  ---------------
2019-04-23 01:24:38.416246 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 271 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    4.16977
trainer/QF2 Loss                    4.05831
trainer/Policy Loss                72.3208
trainer/Q1 Predictions Mean       -70.6428
trainer/Q1 Predictions Std         60.5255
trainer/Q1 Predictions Max         -9.96324
trainer/Q1 Predictions Min       -192.983
trainer/Q2 Predictions Mean       -70.6656
trainer/Q2 Predictions Std         60.5441
trainer/Q2 Predictions Max         -9.84152
trainer/Q2 Predictions Min       -192.764
trainer/Q Targets Mean            -71.7697
trainer/Q Targets Std              61.8276
trainer/Q Targets Max              -0.426029
trainer/Q Targets Min            -196.135
trainer/Log Pis Mean                2.09231
trainer/Log Pis Std                 1.45748
trainer/Log Pis Max                 5.70793
trainer/Log Pis Min                -2.27081
trainer/Policy mu Mean             -0.13846
trainer/Policy mu Std               0.9274
trainer/Policy mu Max               3.3022
trainer/Policy mu Min              -2.60551
trainer/Policy log std Mean        -1.81195
trainer/Policy log std Std          0.673376
trainer/Policy log std Max         -0.208379
trainer/Policy log std Min         -2.62515
trainer/Alpha                       0.0553507
trainer/Alpha Loss                  0.267155
exploration/num steps total    136200
exploration/num paths total      1362
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -2.03866
exploration/Rewards Std             1.26173
exploration/Rewards Max            -0.0115439
exploration/Rewards Min            -8.96104
exploration/Returns Mean         -203.866
exploration/Returns Std           101.341
exploration/Returns Max           -35.2779
exploration/Returns Min          -319.55
exploration/Actions Mean           -0.00212063
exploration/Actions Std             0.304043
exploration/Actions Max             0.993365
exploration/Actions Min            -0.999953
exploration/Num Paths               5
exploration/Average Returns      -203.866
evaluation/num steps total     408000
evaluation/num paths total       4080
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.20848
evaluation/Rewards Std              1.20841
evaluation/Rewards Max             -0.027175
evaluation/Rewards Min             -8.25768
evaluation/Returns Mean          -120.848
evaluation/Returns Std             91.7633
evaluation/Returns Max            -22.4769
evaluation/Returns Min           -299.825
evaluation/Actions Mean            -0.00709073
evaluation/Actions Std              0.191861
evaluation/Actions Max              0.997282
evaluation/Actions Min             -0.999842
evaluation/Num Paths               15
evaluation/Average Returns       -120.848
time/data storing (s)               0.00279526
time/evaluation sampling (s)        0.325715
time/exploration sampling (s)       0.137625
time/logging (s)                    0.00481793
time/saving (s)                     0.00193949
time/training (s)                   1.99002
time/epoch (s)                      2.46292
time/total (s)                    667.062
Epoch                             271
-----------------------------  ---------------
2019-04-23 01:24:40.859877 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 272 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.850931
trainer/QF2 Loss                    0.85745
trainer/Policy Loss                61.1231
trainer/Q1 Predictions Mean       -59.7448
trainer/Q1 Predictions Std         58.4683
trainer/Q1 Predictions Max         -9.85523
trainer/Q1 Predictions Min       -191.287
trainer/Q2 Predictions Mean       -59.7682
trainer/Q2 Predictions Std         58.4491
trainer/Q2 Predictions Max         -9.81329
trainer/Q2 Predictions Min       -191.748
trainer/Q Targets Mean            -60.2416
trainer/Q Targets Std              59.135
trainer/Q Targets Max              -9.77863
trainer/Q Targets Min            -194.301
trainer/Log Pis Mean                1.69097
trainer/Log Pis Std                 1.314
trainer/Log Pis Max                 4.86375
trainer/Log Pis Min                -3.828
trainer/Policy mu Mean              0.0192123
trainer/Policy mu Std               0.693773
trainer/Policy mu Max               2.84765
trainer/Policy mu Min              -2.21976
trainer/Policy log std Mean        -2.0019
trainer/Policy log std Std          0.596652
trainer/Policy log std Max         -0.435255
trainer/Policy log std Min         -2.79478
trainer/Alpha                       0.0572544
trainer/Alpha Loss                 -0.883827
exploration/num steps total    136700
exploration/num paths total      1367
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.707005
exploration/Rewards Std             0.853608
exploration/Rewards Max            -0.0139153
exploration/Rewards Min            -9.3684
exploration/Returns Mean          -70.7005
exploration/Returns Std            34.7937
exploration/Returns Max           -24.8568
exploration/Returns Min          -113.331
exploration/Actions Mean           -0.0159057
exploration/Actions Std             0.201056
exploration/Actions Max             0.98148
exploration/Actions Min            -0.999765
exploration/Num Paths               5
exploration/Average Returns       -70.7005
evaluation/num steps total     409500
evaluation/num paths total       4095
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.23604
evaluation/Rewards Std              1.43672
evaluation/Rewards Max             -0.0563981
evaluation/Rewards Min            -11.2193
evaluation/Returns Mean          -123.604
evaluation/Returns Std            115.498
evaluation/Returns Max            -10.8871
evaluation/Returns Min           -318.837
evaluation/Actions Mean             0.00390725
evaluation/Actions Std              0.170252
evaluation/Actions Max              0.999785
evaluation/Actions Min             -0.997144
evaluation/Num Paths               15
evaluation/Average Returns       -123.604
time/data storing (s)               0.00278007
time/evaluation sampling (s)        0.331714
time/exploration sampling (s)       0.138839
time/logging (s)                    0.00472219
time/saving (s)                     0.00160877
time/training (s)                   1.95662
time/epoch (s)                      2.43628
time/total (s)                    669.503
Epoch                             272
-----------------------------  ---------------
2019-04-23 01:24:43.335072 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 273 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   79.368
trainer/QF2 Loss                   79.9812
trainer/Policy Loss                57.5382
trainer/Q1 Predictions Mean       -56.0377
trainer/Q1 Predictions Std         49.7736
trainer/Q1 Predictions Max         -9.9642
trainer/Q1 Predictions Min       -181.692
trainer/Q2 Predictions Mean       -55.9974
trainer/Q2 Predictions Std         49.7326
trainer/Q2 Predictions Max         -9.94168
trainer/Q2 Predictions Min       -181.129
trainer/Q Targets Mean            -56.1482
trainer/Q Targets Std              50.7708
trainer/Q Targets Max              -1.77977
trainer/Q Targets Min            -184.732
trainer/Log Pis Mean                1.91181
trainer/Log Pis Std                 0.958739
trainer/Log Pis Max                 4.57729
trainer/Log Pis Min                -2.29017
trainer/Policy mu Mean             -0.0360226
trainer/Policy mu Std               0.684157
trainer/Policy mu Max               2.37392
trainer/Policy mu Min              -2.65306
trainer/Policy log std Mean        -1.92539
trainer/Policy log std Std          0.547858
trainer/Policy log std Max         -0.272694
trainer/Policy log std Min         -2.56579
trainer/Alpha                       0.0551849
trainer/Alpha Loss                 -0.25548
exploration/num steps total    137200
exploration/num paths total      1372
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.658473
exploration/Rewards Std             1.21437
exploration/Rewards Max            -0.00540603
exploration/Rewards Min            -9.53181
exploration/Returns Mean          -65.8473
exploration/Returns Std            47.1897
exploration/Returns Max           -20.0305
exploration/Returns Min          -154.87
exploration/Actions Mean            0.0142221
exploration/Actions Std             0.227029
exploration/Actions Max             0.999861
exploration/Actions Min            -0.998296
exploration/Num Paths               5
exploration/Average Returns       -65.8473
evaluation/num steps total     411000
evaluation/num paths total       4110
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.14704
evaluation/Rewards Std              1.23711
evaluation/Rewards Max             -0.0237279
evaluation/Rewards Min            -10.1158
evaluation/Returns Mean          -114.704
evaluation/Returns Std             87.3773
evaluation/Returns Max            -14.1503
evaluation/Returns Min           -317.057
evaluation/Actions Mean             0.00904602
evaluation/Actions Std              0.174902
evaluation/Actions Max              0.999097
evaluation/Actions Min             -0.999713
evaluation/Num Paths               15
evaluation/Average Returns       -114.704
time/data storing (s)               0.00286383
time/evaluation sampling (s)        0.334305
time/exploration sampling (s)       0.136394
time/logging (s)                    0.00390434
time/saving (s)                     0.00941451
time/training (s)                   1.979
time/epoch (s)                      2.46588
time/total (s)                    671.973
Epoch                             273
-----------------------------  ---------------
2019-04-23 01:24:45.778563 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 274 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.2862
trainer/QF2 Loss                    1.38663
trainer/Policy Loss                57.5782
trainer/Q1 Predictions Mean       -56.0495
trainer/Q1 Predictions Std         53.8459
trainer/Q1 Predictions Max         -9.82126
trainer/Q1 Predictions Min       -194.229
trainer/Q2 Predictions Mean       -56.0726
trainer/Q2 Predictions Std         53.8156
trainer/Q2 Predictions Max         -9.79875
trainer/Q2 Predictions Min       -192.225
trainer/Q Targets Mean            -56.779
trainer/Q Targets Std              54.5273
trainer/Q Targets Max             -10.013
trainer/Q Targets Min            -195.607
trainer/Log Pis Mean                1.8036
trainer/Log Pis Std                 1.35894
trainer/Log Pis Max                 6.09923
trainer/Log Pis Min                -2.82838
trainer/Policy mu Mean             -0.128838
trainer/Policy mu Std               0.679682
trainer/Policy mu Max               2.27259
trainer/Policy mu Min              -4.00994
trainer/Policy log std Mean        -2.03439
trainer/Policy log std Std          0.549061
trainer/Policy log std Max          0.0339567
trainer/Policy log std Min         -2.70136
trainer/Alpha                       0.0539803
trainer/Alpha Loss                 -0.573302
exploration/num steps total    137700
exploration/num paths total      1377
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.566089
exploration/Rewards Std             0.686564
exploration/Rewards Max            -0.0445252
exploration/Rewards Min            -7.12402
exploration/Returns Mean          -56.6089
exploration/Returns Std             9.03775
exploration/Returns Max           -44.9314
exploration/Returns Min           -70.9915
exploration/Actions Mean            0.00637446
exploration/Actions Std             0.232377
exploration/Actions Max             0.997169
exploration/Actions Min            -0.995324
exploration/Num Paths               5
exploration/Average Returns       -56.6089
evaluation/num steps total     412500
evaluation/num paths total       4125
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.999302
evaluation/Rewards Std              1.20043
evaluation/Rewards Max             -0.0450672
evaluation/Rewards Min             -8.30276
evaluation/Returns Mean           -99.9302
evaluation/Returns Std             89.0602
evaluation/Returns Max            -20.6462
evaluation/Returns Min           -275.323
evaluation/Actions Mean             0.0138197
evaluation/Actions Std              0.176548
evaluation/Actions Max              0.998022
evaluation/Actions Min             -0.999599
evaluation/Num Paths               15
evaluation/Average Returns        -99.9302
time/data storing (s)               0.00271187
time/evaluation sampling (s)        0.329302
time/exploration sampling (s)       0.141901
time/logging (s)                    0.00455421
time/saving (s)                     0.0019533
time/training (s)                   1.95624
time/epoch (s)                      2.43666
time/total (s)                    674.414
Epoch                             274
-----------------------------  ---------------
2019-04-23 01:24:48.225434 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 275 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                  175.165
trainer/QF2 Loss                  174.969
trainer/Policy Loss                66.8517
trainer/Q1 Predictions Mean       -65.4041
trainer/Q1 Predictions Std         57.8716
trainer/Q1 Predictions Max         -9.74045
trainer/Q1 Predictions Min       -190.331
trainer/Q2 Predictions Mean       -65.3901
trainer/Q2 Predictions Std         57.889
trainer/Q2 Predictions Max         -9.82279
trainer/Q2 Predictions Min       -191.021
trainer/Q Targets Mean            -64.0591
trainer/Q Targets Std              58.3231
trainer/Q Targets Max              -0.879694
trainer/Q Targets Min            -191.67
trainer/Log Pis Mean                1.8496
trainer/Log Pis Std                 1.42715
trainer/Log Pis Max                 5.21738
trainer/Log Pis Min                -3.25624
trainer/Policy mu Mean             -0.140826
trainer/Policy mu Std               0.819292
trainer/Policy mu Max               2.51978
trainer/Policy mu Min              -2.6432
trainer/Policy log std Mean        -1.88289
trainer/Policy log std Std          0.639158
trainer/Policy log std Max         -0.44355
trainer/Policy log std Min         -2.6828
trainer/Alpha                       0.0565026
trainer/Alpha Loss                 -0.432171
exploration/num steps total    138200
exploration/num paths total      1382
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.716211
exploration/Rewards Std             0.898975
exploration/Rewards Max            -0.00876171
exploration/Rewards Min            -7.95378
exploration/Returns Mean          -71.6211
exploration/Returns Std            53.0211
exploration/Returns Max           -16.2135
exploration/Returns Min          -160.51
exploration/Actions Mean           -0.00348526
exploration/Actions Std             0.186145
exploration/Actions Max             0.998641
exploration/Actions Min            -0.99375
exploration/Num Paths               5
exploration/Average Returns       -71.6211
evaluation/num steps total     414000
evaluation/num paths total       4140
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.1536
evaluation/Rewards Std              1.02138
evaluation/Rewards Max             -0.0203747
evaluation/Rewards Min            -10.2542
evaluation/Returns Mean          -115.36
evaluation/Returns Std             63.4006
evaluation/Returns Max            -14.5871
evaluation/Returns Min           -224.462
evaluation/Actions Mean            -0.0057449
evaluation/Actions Std              0.183304
evaluation/Actions Max              0.995322
evaluation/Actions Min             -0.999201
evaluation/Num Paths               15
evaluation/Average Returns       -115.36
time/data storing (s)               0.00273746
time/evaluation sampling (s)        0.332146
time/exploration sampling (s)       0.138002
time/logging (s)                    0.0047494
time/saving (s)                     0.00193808
time/training (s)                   1.95919
time/epoch (s)                      2.43876
time/total (s)                    676.857
Epoch                             275
-----------------------------  ---------------
2019-04-23 01:24:50.702036 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 276 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    4.42577
trainer/QF2 Loss                    4.4646
trainer/Policy Loss                62.9235
trainer/Q1 Predictions Mean       -61.4231
trainer/Q1 Predictions Std         57.0916
trainer/Q1 Predictions Max         -9.75326
trainer/Q1 Predictions Min       -183.161
trainer/Q2 Predictions Mean       -61.3965
trainer/Q2 Predictions Std         57.0904
trainer/Q2 Predictions Max         -9.78175
trainer/Q2 Predictions Min       -183.423
trainer/Q Targets Mean            -61.9497
trainer/Q Targets Std              58.153
trainer/Q Targets Max              -0.037237
trainer/Q Targets Min            -186.715
trainer/Log Pis Mean                1.88211
trainer/Log Pis Std                 1.57664
trainer/Log Pis Max                 6.47023
trainer/Log Pis Min                -3.41637
trainer/Policy mu Mean             -0.253431
trainer/Policy mu Std               0.778084
trainer/Policy mu Max               2.75714
trainer/Policy mu Min              -2.62682
trainer/Policy log std Mean        -1.89193
trainer/Policy log std Std          0.63252
trainer/Policy log std Max         -0.349519
trainer/Policy log std Min         -2.63981
trainer/Alpha                       0.0571341
trainer/Alpha Loss                 -0.337432
exploration/num steps total    138700
exploration/num paths total      1387
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.54031
exploration/Rewards Std             1.36189
exploration/Rewards Max            -0.0156929
exploration/Rewards Min           -10.0732
exploration/Returns Mean         -154.031
exploration/Returns Std           102.185
exploration/Returns Max           -29.6219
exploration/Returns Min          -309.698
exploration/Actions Mean            0.0017458
exploration/Actions Std             0.272548
exploration/Actions Max             0.996726
exploration/Actions Min            -0.99996
exploration/Num Paths               5
exploration/Average Returns      -154.031
evaluation/num steps total     415500
evaluation/num paths total       4155
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.853516
evaluation/Rewards Std              1.3067
evaluation/Rewards Max             -0.0381627
evaluation/Rewards Min            -10.5271
evaluation/Returns Mean           -85.3516
evaluation/Returns Std             69.4265
evaluation/Returns Max            -12.132
evaluation/Returns Min           -227.396
evaluation/Actions Mean            -0.00899462
evaluation/Actions Std              0.19475
evaluation/Actions Max              0.999706
evaluation/Actions Min             -0.999916
evaluation/Num Paths               15
evaluation/Average Returns        -85.3516
time/data storing (s)               0.00276896
time/evaluation sampling (s)        0.330709
time/exploration sampling (s)       0.140485
time/logging (s)                    0.00473689
time/saving (s)                     0.00192418
time/training (s)                   1.9872
time/epoch (s)                      2.46782
time/total (s)                    679.329
Epoch                             276
-----------------------------  ---------------
2019-04-23 01:24:53.144339 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 277 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                  192.313
trainer/QF2 Loss                  191.539
trainer/Policy Loss                59.2679
trainer/Q1 Predictions Mean       -57.6757
trainer/Q1 Predictions Std         54.9323
trainer/Q1 Predictions Max         -9.69974
trainer/Q1 Predictions Min       -181.142
trainer/Q2 Predictions Mean       -57.6338
trainer/Q2 Predictions Std         54.9854
trainer/Q2 Predictions Max         -9.64803
trainer/Q2 Predictions Min       -181.055
trainer/Q Targets Mean            -56.1707
trainer/Q Targets Std              55.7245
trainer/Q Targets Max              -0.706551
trainer/Q Targets Min            -182.509
trainer/Log Pis Mean                1.92589
trainer/Log Pis Std                 1.29677
trainer/Log Pis Max                 5.8463
trainer/Log Pis Min                -2.11184
trainer/Policy mu Mean             -0.158839
trainer/Policy mu Std               0.807172
trainer/Policy mu Max               2.89336
trainer/Policy mu Min              -3.4676
trainer/Policy log std Mean        -1.93686
trainer/Policy log std Std          0.595535
trainer/Policy log std Max         -0.446248
trainer/Policy log std Min         -2.59946
trainer/Alpha                       0.0559626
trainer/Alpha Loss                 -0.21367
exploration/num steps total    139200
exploration/num paths total      1392
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.7043
exploration/Rewards Std             1.03587
exploration/Rewards Max            -0.21847
exploration/Rewards Min           -10.4035
exploration/Returns Mean         -170.43
exploration/Returns Std            75.098
exploration/Returns Max           -61.1134
exploration/Returns Min          -293.704
exploration/Actions Mean           -0.0285281
exploration/Actions Std             0.255122
exploration/Actions Max             0.974224
exploration/Actions Min            -0.999866
exploration/Num Paths               5
exploration/Average Returns      -170.43
evaluation/num steps total     417000
evaluation/num paths total       4170
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.10289
evaluation/Rewards Std              1.14622
evaluation/Rewards Max             -0.0605599
evaluation/Rewards Min             -8.57669
evaluation/Returns Mean          -110.289
evaluation/Returns Std             90.1169
evaluation/Returns Max            -11.4776
evaluation/Returns Min           -228.312
evaluation/Actions Mean             0.0102499
evaluation/Actions Std              0.1707
evaluation/Actions Max              0.999291
evaluation/Actions Min             -0.999587
evaluation/Num Paths               15
evaluation/Average Returns       -110.289
time/data storing (s)               0.00261536
time/evaluation sampling (s)        0.324419
time/exploration sampling (s)       0.139398
time/logging (s)                    0.00473741
time/saving (s)                     0.00195503
time/training (s)                   1.96048
time/epoch (s)                      2.43361
time/total (s)                    681.767
Epoch                             277
-----------------------------  ---------------
2019-04-23 01:24:55.595252 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 278 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                  157.815
trainer/QF2 Loss                  157.277
trainer/Policy Loss                55.3986
trainer/Q1 Predictions Mean       -53.9989
trainer/Q1 Predictions Std         50.932
trainer/Q1 Predictions Max         -9.76287
trainer/Q1 Predictions Min       -178.064
trainer/Q2 Predictions Mean       -53.945
trainer/Q2 Predictions Std         50.9058
trainer/Q2 Predictions Max         -9.71157
trainer/Q2 Predictions Min       -178.164
trainer/Q Targets Mean            -53.3656
trainer/Q Targets Std              51.3059
trainer/Q Targets Max              -2.58392
trainer/Q Targets Min            -180.988
trainer/Log Pis Mean                1.7014
trainer/Log Pis Std                 1.30083
trainer/Log Pis Max                 5.86527
trainer/Log Pis Min                -3.59331
trainer/Policy mu Mean             -0.15606
trainer/Policy mu Std               0.647023
trainer/Policy mu Max               2.19531
trainer/Policy mu Min              -3.03656
trainer/Policy log std Mean        -1.98468
trainer/Policy log std Std          0.545973
trainer/Policy log std Max         -0.261677
trainer/Policy log std Min         -2.70408
trainer/Alpha                       0.0540093
trainer/Alpha Loss                 -0.871477
exploration/num steps total    139700
exploration/num paths total      1397
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.952053
exploration/Rewards Std             1.54013
exploration/Rewards Max            -0.00492378
exploration/Rewards Min           -11.0102
exploration/Returns Mean          -95.2053
exploration/Returns Std            95.1424
exploration/Returns Max           -30.3692
exploration/Returns Min          -283.102
exploration/Actions Mean            0.0248393
exploration/Actions Std             0.287374
exploration/Actions Max             0.999992
exploration/Actions Min            -0.999316
exploration/Num Paths               5
exploration/Average Returns       -95.2053
evaluation/num steps total     418500
evaluation/num paths total       4185
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.35357
evaluation/Rewards Std              1.39477
evaluation/Rewards Max             -0.0265672
evaluation/Rewards Min            -11.0094
evaluation/Returns Mean          -135.357
evaluation/Returns Std             96.5084
evaluation/Returns Max             -5.4063
evaluation/Returns Min           -322.581
evaluation/Actions Mean             0.00216138
evaluation/Actions Std              0.184283
evaluation/Actions Max              0.998976
evaluation/Actions Min             -0.999869
evaluation/Num Paths               15
evaluation/Average Returns       -135.357
time/data storing (s)               0.00274284
time/evaluation sampling (s)        0.326173
time/exploration sampling (s)       0.13615
time/logging (s)                    0.00476628
time/saving (s)                     0.00183142
time/training (s)                   1.97027
time/epoch (s)                      2.44194
time/total (s)                    684.214
Epoch                             278
-----------------------------  ---------------
2019-04-23 01:24:58.068145 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 279 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.35198
trainer/QF2 Loss                    1.39118
trainer/Policy Loss                61.7371
trainer/Q1 Predictions Mean       -59.9549
trainer/Q1 Predictions Std         57.4518
trainer/Q1 Predictions Max         -9.6161
trainer/Q1 Predictions Min       -176.963
trainer/Q2 Predictions Mean       -60.0049
trainer/Q2 Predictions Std         57.4043
trainer/Q2 Predictions Max         -9.70219
trainer/Q2 Predictions Min       -177.411
trainer/Q Targets Mean            -60.616
trainer/Q Targets Std              58.2698
trainer/Q Targets Max              -9.63382
trainer/Q Targets Min            -180.233
trainer/Log Pis Mean                2.06173
trainer/Log Pis Std                 1.42755
trainer/Log Pis Max                 7.14599
trainer/Log Pis Min                -1.83885
trainer/Policy mu Mean             -0.106016
trainer/Policy mu Std               0.763613
trainer/Policy mu Max               2.80448
trainer/Policy mu Min              -2.43842
trainer/Policy log std Mean        -1.91506
trainer/Policy log std Std          0.618467
trainer/Policy log std Max         -0.462415
trainer/Policy log std Min         -2.70989
trainer/Alpha                       0.0518765
trainer/Alpha Loss                  0.182659
exploration/num steps total    140200
exploration/num paths total      1402
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.59887
exploration/Rewards Std             1.58858
exploration/Rewards Max            -0.00712072
exploration/Rewards Min            -9.27053
exploration/Returns Mean         -159.887
exploration/Returns Std           118.991
exploration/Returns Max           -35.6964
exploration/Returns Min          -308.277
exploration/Actions Mean           -0.020317
exploration/Actions Std             0.293923
exploration/Actions Max             0.999044
exploration/Actions Min            -0.999576
exploration/Num Paths               5
exploration/Average Returns      -159.887
evaluation/num steps total     420000
evaluation/num paths total       4200
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.29044
evaluation/Rewards Std              1.25171
evaluation/Rewards Max             -0.0425488
evaluation/Rewards Min             -9.36419
evaluation/Returns Mean          -129.044
evaluation/Returns Std             99.4313
evaluation/Returns Max            -10.5638
evaluation/Returns Min           -293.087
evaluation/Actions Mean             0.0123872
evaluation/Actions Std              0.176469
evaluation/Actions Max              0.999454
evaluation/Actions Min             -0.995309
evaluation/Num Paths               15
evaluation/Average Returns       -129.044
time/data storing (s)               0.00258443
time/evaluation sampling (s)        0.336387
time/exploration sampling (s)       0.13875
time/logging (s)                    0.00353608
time/saving (s)                     0.0019366
time/training (s)                   1.97994
time/epoch (s)                      2.46314
time/total (s)                    686.681
Epoch                             279
-----------------------------  ---------------
2019-04-23 01:25:00.529253 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 280 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.781491
trainer/QF2 Loss                    0.821553
trainer/Policy Loss                66.414
trainer/Q1 Predictions Mean       -64.6383
trainer/Q1 Predictions Std         56.8772
trainer/Q1 Predictions Max         -9.5819
trainer/Q1 Predictions Min       -179.696
trainer/Q2 Predictions Mean       -64.6132
trainer/Q2 Predictions Std         56.8497
trainer/Q2 Predictions Max         -9.60255
trainer/Q2 Predictions Min       -179.941
trainer/Q Targets Mean            -65.0498
trainer/Q Targets Std              57.1028
trainer/Q Targets Max              -9.64761
trainer/Q Targets Min            -180.516
trainer/Log Pis Mean                2.11677
trainer/Log Pis Std                 1.52131
trainer/Log Pis Max                 6.28143
trainer/Log Pis Min                -6.21714
trainer/Policy mu Mean              0.0432712
trainer/Policy mu Std               0.889314
trainer/Policy mu Max               3.31013
trainer/Policy mu Min              -3.05243
trainer/Policy log std Mean        -1.93767
trainer/Policy log std Std          0.642733
trainer/Policy log std Max         -0.328118
trainer/Policy log std Min         -2.71386
trainer/Alpha                       0.0514617
trainer/Alpha Loss                  0.346442
exploration/num steps total    140700
exploration/num paths total      1407
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.905325
exploration/Rewards Std             1.33537
exploration/Rewards Max            -0.00728196
exploration/Rewards Min           -10.2167
exploration/Returns Mean          -90.5325
exploration/Returns Std            61.0985
exploration/Returns Max           -16.6311
exploration/Returns Min          -180.733
exploration/Actions Mean            0.00986371
exploration/Actions Std             0.241625
exploration/Actions Max             0.999688
exploration/Actions Min            -0.999608
exploration/Num Paths               5
exploration/Average Returns       -90.5325
evaluation/num steps total     421500
evaluation/num paths total       4215
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -2.02918
evaluation/Rewards Std              1.41794
evaluation/Rewards Max             -0.0384808
evaluation/Rewards Min            -10.8261
evaluation/Returns Mean          -202.918
evaluation/Returns Std            122.177
evaluation/Returns Max            -12.5159
evaluation/Returns Min           -349.432
evaluation/Actions Mean             0.00282062
evaluation/Actions Std              0.188251
evaluation/Actions Max              0.998702
evaluation/Actions Min             -0.997859
evaluation/Num Paths               15
evaluation/Average Returns       -202.918
time/data storing (s)               0.00274169
time/evaluation sampling (s)        0.325297
time/exploration sampling (s)       0.136445
time/logging (s)                    0.00473665
time/saving (s)                     0.00193413
time/training (s)                   1.98319
time/epoch (s)                      2.45435
time/total (s)                    689.14
Epoch                             280
-----------------------------  ---------------
2019-04-23 01:25:02.978539 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 281 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    4.02107
trainer/QF2 Loss                    3.96103
trainer/Policy Loss                62.6686
trainer/Q1 Predictions Mean       -60.9915
trainer/Q1 Predictions Std         57.1926
trainer/Q1 Predictions Max         -9.61608
trainer/Q1 Predictions Min       -179.2
trainer/Q2 Predictions Mean       -61.0127
trainer/Q2 Predictions Std         57.2549
trainer/Q2 Predictions Max         -9.66811
trainer/Q2 Predictions Min       -179.804
trainer/Q Targets Mean            -61.0475
trainer/Q Targets Std              57.6951
trainer/Q Targets Max              -0.337673
trainer/Q Targets Min            -180.504
trainer/Log Pis Mean                2.05998
trainer/Log Pis Std                 1.37185
trainer/Log Pis Max                 6.08601
trainer/Log Pis Min                -1.9815
trainer/Policy mu Mean             -0.168194
trainer/Policy mu Std               0.873724
trainer/Policy mu Max               2.40535
trainer/Policy mu Min              -3.29862
trainer/Policy log std Mean        -1.88157
trainer/Policy log std Std          0.666183
trainer/Policy log std Max         -0.287937
trainer/Policy log std Min         -2.65208
trainer/Alpha                       0.0553415
trainer/Alpha Loss                  0.173605
exploration/num steps total    141200
exploration/num paths total      1412
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.43863
exploration/Rewards Std             1.55199
exploration/Rewards Max            -0.0107149
exploration/Rewards Min            -8.91456
exploration/Returns Mean         -143.863
exploration/Returns Std           131.442
exploration/Returns Max           -24.0745
exploration/Returns Min          -307.556
exploration/Actions Mean            0.0190772
exploration/Actions Std             0.323496
exploration/Actions Max             0.999689
exploration/Actions Min            -0.998282
exploration/Num Paths               5
exploration/Average Returns      -143.863
evaluation/num steps total     423000
evaluation/num paths total       4230
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.24439
evaluation/Rewards Std              1.33643
evaluation/Rewards Max             -0.0110239
evaluation/Rewards Min             -8.80888
evaluation/Returns Mean          -124.439
evaluation/Returns Std            118.418
evaluation/Returns Max            -13.9428
evaluation/Returns Min           -303.838
evaluation/Actions Mean            -0.00220522
evaluation/Actions Std              0.158015
evaluation/Actions Max              0.996969
evaluation/Actions Min             -0.999618
evaluation/Num Paths               15
evaluation/Average Returns       -124.439
time/data storing (s)               0.00285101
time/evaluation sampling (s)        0.329001
time/exploration sampling (s)       0.135854
time/logging (s)                    0.00471513
time/saving (s)                     0.00193381
time/training (s)                   1.9664
time/epoch (s)                      2.44076
time/total (s)                    691.585
Epoch                             281
-----------------------------  ---------------
2019-04-23 01:25:05.446993 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 282 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                  173.886
trainer/QF2 Loss                  173.734
trainer/Policy Loss                71.3242
trainer/Q1 Predictions Mean       -70.0121
trainer/Q1 Predictions Std         60.1057
trainer/Q1 Predictions Max         -9.36791
trainer/Q1 Predictions Min       -174.556
trainer/Q2 Predictions Mean       -70.0698
trainer/Q2 Predictions Std         60.1311
trainer/Q2 Predictions Max         -9.44797
trainer/Q2 Predictions Min       -175.08
trainer/Q Targets Mean            -69.0077
trainer/Q Targets Std              61.3249
trainer/Q Targets Max              -0.40629
trainer/Q Targets Min            -177.108
trainer/Log Pis Mean                1.83007
trainer/Log Pis Std                 1.61379
trainer/Log Pis Max                 5.53466
trainer/Log Pis Min                -2.88467
trainer/Policy mu Mean             -0.21241
trainer/Policy mu Std               0.825789
trainer/Policy mu Max               2.56918
trainer/Policy mu Min              -2.82326
trainer/Policy log std Mean        -1.85824
trainer/Policy log std Std          0.630676
trainer/Policy log std Max         -0.341093
trainer/Policy log std Min         -2.61585
trainer/Alpha                       0.0547613
trainer/Alpha Loss                 -0.49361
exploration/num steps total    141700
exploration/num paths total      1417
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.657
exploration/Rewards Std             1.25825
exploration/Rewards Max            -0.0101314
exploration/Rewards Min            -8.99353
exploration/Returns Mean         -165.7
exploration/Returns Std           113.732
exploration/Returns Max           -16.7494
exploration/Returns Min          -297.251
exploration/Actions Mean           -0.000724436
exploration/Actions Std             0.279401
exploration/Actions Max             0.988817
exploration/Actions Min            -0.999665
exploration/Num Paths               5
exploration/Average Returns      -165.7
evaluation/num steps total     424500
evaluation/num paths total       4245
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.13923
evaluation/Rewards Std              1.2273
evaluation/Rewards Max             -0.0480654
evaluation/Rewards Min             -9.3596
evaluation/Returns Mean          -113.923
evaluation/Returns Std            100.888
evaluation/Returns Max            -12.2966
evaluation/Returns Min           -305.405
evaluation/Actions Mean            -0.00564553
evaluation/Actions Std              0.178563
evaluation/Actions Max              0.998989
evaluation/Actions Min             -0.999935
evaluation/Num Paths               15
evaluation/Average Returns       -113.923
time/data storing (s)               0.00278782
time/evaluation sampling (s)        0.32523
time/exploration sampling (s)       0.137073
time/logging (s)                    0.00477115
time/saving (s)                     0.00194847
time/training (s)                   1.98871
time/epoch (s)                      2.46052
time/total (s)                    694.049
Epoch                             282
-----------------------------  ----------------
2019-04-23 01:25:07.919922 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 283 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.801811
trainer/QF2 Loss                    0.727758
trainer/Policy Loss                58.9771
trainer/Q1 Predictions Mean       -57.2892
trainer/Q1 Predictions Std         55.1028
trainer/Q1 Predictions Max         -9.6176
trainer/Q1 Predictions Min       -172.322
trainer/Q2 Predictions Mean       -57.3413
trainer/Q2 Predictions Std         55.1206
trainer/Q2 Predictions Max         -9.69539
trainer/Q2 Predictions Min       -172.036
trainer/Q Targets Mean            -57.6971
trainer/Q Targets Std              55.5782
trainer/Q Targets Max              -9.58579
trainer/Q Targets Min            -173.616
trainer/Log Pis Mean                1.9541
trainer/Log Pis Std                 1.39463
trainer/Log Pis Max                 6.68927
trainer/Log Pis Min                -2.09939
trainer/Policy mu Mean             -0.0451595
trainer/Policy mu Std               0.777344
trainer/Policy mu Max               2.90582
trainer/Policy mu Min              -2.26907
trainer/Policy log std Mean        -1.96031
trainer/Policy log std Std          0.582955
trainer/Policy log std Max         -0.403012
trainer/Policy log std Min         -2.68934
trainer/Alpha                       0.0562887
trainer/Alpha Loss                 -0.132054
exploration/num steps total    142200
exploration/num paths total      1422
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.819508
exploration/Rewards Std             1.47271
exploration/Rewards Max            -0.00892455
exploration/Rewards Min           -10.6308
exploration/Returns Mean          -81.9508
exploration/Returns Std            45.715
exploration/Returns Max           -42.6502
exploration/Returns Min          -167.663
exploration/Actions Mean            0.0302097
exploration/Actions Std             0.252294
exploration/Actions Max             0.999956
exploration/Actions Min            -0.999769
exploration/Num Paths               5
exploration/Average Returns       -81.9508
evaluation/num steps total     426000
evaluation/num paths total       4260
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.46228
evaluation/Rewards Std              1.38459
evaluation/Rewards Max             -0.0545738
evaluation/Rewards Min             -9.00547
evaluation/Returns Mean          -146.228
evaluation/Returns Std            115.986
evaluation/Returns Max            -16.9788
evaluation/Returns Min           -338.963
evaluation/Actions Mean            -0.00413421
evaluation/Actions Std              0.191491
evaluation/Actions Max              0.997737
evaluation/Actions Min             -0.998795
evaluation/Num Paths               15
evaluation/Average Returns       -146.228
time/data storing (s)               0.00274897
time/evaluation sampling (s)        0.327102
time/exploration sampling (s)       0.141727
time/logging (s)                    0.00478458
time/saving (s)                     0.00206709
time/training (s)                   1.98646
time/epoch (s)                      2.46489
time/total (s)                    696.518
Epoch                             283
-----------------------------  ---------------
2019-04-23 01:25:10.372841 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 284 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                  255.673
trainer/QF2 Loss                  255.353
trainer/Policy Loss                65.6906
trainer/Q1 Predictions Mean       -63.9486
trainer/Q1 Predictions Std         56.5686
trainer/Q1 Predictions Max         -9.41053
trainer/Q1 Predictions Min       -172.053
trainer/Q2 Predictions Mean       -63.9703
trainer/Q2 Predictions Std         56.5978
trainer/Q2 Predictions Max         -9.37885
trainer/Q2 Predictions Min       -172.546
trainer/Q Targets Mean            -62.6216
trainer/Q Targets Std              56.6272
trainer/Q Targets Max              -0.219629
trainer/Q Targets Min            -174.19
trainer/Log Pis Mean                2.10384
trainer/Log Pis Std                 1.14057
trainer/Log Pis Max                 6.91681
trainer/Log Pis Min                -1.16785
trainer/Policy mu Mean              0.0332516
trainer/Policy mu Std               0.809986
trainer/Policy mu Max               3.75499
trainer/Policy mu Min              -2.82269
trainer/Policy log std Mean        -1.92754
trainer/Policy log std Std          0.599766
trainer/Policy log std Max         -0.516183
trainer/Policy log std Min         -2.60344
trainer/Alpha                       0.0533897
trainer/Alpha Loss                  0.304262
exploration/num steps total    142700
exploration/num paths total      1427
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.47641
exploration/Rewards Std             1.63776
exploration/Rewards Max            -0.00522497
exploration/Rewards Min            -9.58166
exploration/Returns Mean         -147.641
exploration/Returns Std           130.627
exploration/Returns Max           -20.6381
exploration/Returns Min          -308.892
exploration/Actions Mean           -0.000272081
exploration/Actions Std             0.289556
exploration/Actions Max             0.999348
exploration/Actions Min            -0.999925
exploration/Num Paths               5
exploration/Average Returns      -147.641
evaluation/num steps total     427500
evaluation/num paths total       4275
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.19768
evaluation/Rewards Std              1.18118
evaluation/Rewards Max             -0.0233475
evaluation/Rewards Min             -9.72366
evaluation/Returns Mean          -119.768
evaluation/Returns Std             86.7101
evaluation/Returns Max            -14.7471
evaluation/Returns Min           -347.691
evaluation/Actions Mean            -0.00758528
evaluation/Actions Std              0.183685
evaluation/Actions Max              0.997751
evaluation/Actions Min             -0.99972
evaluation/Num Paths               15
evaluation/Average Returns       -119.768
time/data storing (s)               0.002624
time/evaluation sampling (s)        0.32502
time/exploration sampling (s)       0.136314
time/logging (s)                    0.00474789
time/saving (s)                     0.00193146
time/training (s)                   1.97367
time/epoch (s)                      2.44431
time/total (s)                    698.966
Epoch                             284
-----------------------------  ----------------
2019-04-23 01:25:12.842438 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 285 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   13.7727
trainer/QF2 Loss                   13.4562
trainer/Policy Loss                61.4571
trainer/Q1 Predictions Mean       -59.9388
trainer/Q1 Predictions Std         55.1932
trainer/Q1 Predictions Max         -9.58758
trainer/Q1 Predictions Min       -177.499
trainer/Q2 Predictions Mean       -59.9299
trainer/Q2 Predictions Std         55.1836
trainer/Q2 Predictions Max         -9.62861
trainer/Q2 Predictions Min       -175.935
trainer/Q Targets Mean            -59.8471
trainer/Q Targets Std              55.8215
trainer/Q Targets Max              -1.46207
trainer/Q Targets Min            -178.247
trainer/Log Pis Mean                1.97861
trainer/Log Pis Std                 1.56074
trainer/Log Pis Max                 6.72616
trainer/Log Pis Min                -5.72076
trainer/Policy mu Mean              0.174178
trainer/Policy mu Std               0.820544
trainer/Policy mu Max               3.34022
trainer/Policy mu Min              -3.71056
trainer/Policy log std Mean        -1.94697
trainer/Policy log std Std          0.619896
trainer/Policy log std Max         -0.0646535
trainer/Policy log std Min         -2.69468
trainer/Alpha                       0.0544899
trainer/Alpha Loss                 -0.0622321
exploration/num steps total    143200
exploration/num paths total      1432
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.910891
exploration/Rewards Std             1.29983
exploration/Rewards Max            -0.00497668
exploration/Rewards Min           -10.2373
exploration/Returns Mean          -91.0891
exploration/Returns Std            63.3596
exploration/Returns Max           -13.6683
exploration/Returns Min          -179.101
exploration/Actions Mean           -0.0096086
exploration/Actions Std             0.241824
exploration/Actions Max             0.999127
exploration/Actions Min            -0.999988
exploration/Num Paths               5
exploration/Average Returns       -91.0891
evaluation/num steps total     429000
evaluation/num paths total       4290
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.24471
evaluation/Rewards Std              1.49706
evaluation/Rewards Max             -0.0313966
evaluation/Rewards Min            -10.038
evaluation/Returns Mean          -124.471
evaluation/Returns Std            120.874
evaluation/Returns Max             -6.69239
evaluation/Returns Min           -325.634
evaluation/Actions Mean            -0.0149162
evaluation/Actions Std              0.186452
evaluation/Actions Max              0.99697
evaluation/Actions Min             -0.999631
evaluation/Num Paths               15
evaluation/Average Returns       -124.471
time/data storing (s)               0.00276046
time/evaluation sampling (s)        0.326008
time/exploration sampling (s)       0.142481
time/logging (s)                    0.00473764
time/saving (s)                     0.00993384
time/training (s)                   1.97611
time/epoch (s)                      2.46204
time/total (s)                    701.432
Epoch                             285
-----------------------------  ---------------
2019-04-23 01:25:15.273809 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 286 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   53.3989
trainer/QF2 Loss                   53.4111
trainer/Policy Loss                53.5885
trainer/Q1 Predictions Mean       -51.9096
trainer/Q1 Predictions Std         53.0498
trainer/Q1 Predictions Max         -9.30992
trainer/Q1 Predictions Min       -179.032
trainer/Q2 Predictions Mean       -51.8635
trainer/Q2 Predictions Std         52.9826
trainer/Q2 Predictions Max         -9.32866
trainer/Q2 Predictions Min       -177.714
trainer/Q Targets Mean            -52.1111
trainer/Q Targets Std              54.2743
trainer/Q Targets Max              -0.369504
trainer/Q Targets Min            -181.51
trainer/Log Pis Mean                1.97915
trainer/Log Pis Std                 1.64122
trainer/Log Pis Max                 8.46358
trainer/Log Pis Min                -4.02641
trainer/Policy mu Mean             -0.00518104
trainer/Policy mu Std               0.763974
trainer/Policy mu Max               2.4183
trainer/Policy mu Min              -4.32751
trainer/Policy log std Mean        -2.05863
trainer/Policy log std Std          0.580858
trainer/Policy log std Max         -0.0905164
trainer/Policy log std Min         -2.88058
trainer/Alpha                       0.0560292
trainer/Alpha Loss                 -0.0600978
exploration/num steps total    143700
exploration/num paths total      1437
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.468212
exploration/Rewards Std             1.00764
exploration/Rewards Max            -0.0139587
exploration/Rewards Min            -8.27162
exploration/Returns Mean          -46.8212
exploration/Returns Std             7.65808
exploration/Returns Max           -37.7616
exploration/Returns Min           -58.7327
exploration/Actions Mean            0.0290472
exploration/Actions Std             0.234161
exploration/Actions Max             0.998949
exploration/Actions Min            -0.996857
exploration/Num Paths               5
exploration/Average Returns       -46.8212
evaluation/num steps total     430500
evaluation/num paths total       4305
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.52687
evaluation/Rewards Std              1.46407
evaluation/Rewards Max             -0.116785
evaluation/Rewards Min            -10.9555
evaluation/Returns Mean          -152.687
evaluation/Returns Std            107.398
evaluation/Returns Max            -25.0911
evaluation/Returns Min           -332.379
evaluation/Actions Mean            -0.00957802
evaluation/Actions Std              0.198141
evaluation/Actions Max              0.998857
evaluation/Actions Min             -0.999944
evaluation/Num Paths               15
evaluation/Average Returns       -152.687
time/data storing (s)               0.00263909
time/evaluation sampling (s)        0.329025
time/exploration sampling (s)       0.139588
time/logging (s)                    0.00507354
time/saving (s)                     0.0019748
time/training (s)                   1.94456
time/epoch (s)                      2.42286
time/total (s)                    703.859
Epoch                             286
-----------------------------  ---------------
2019-04-23 01:25:17.740815 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 287 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.275445
trainer/QF2 Loss                    0.323048
trainer/Policy Loss                50.3854
trainer/Q1 Predictions Mean       -48.5159
trainer/Q1 Predictions Std         52.0432
trainer/Q1 Predictions Max         -9.37165
trainer/Q1 Predictions Min       -199.641
trainer/Q2 Predictions Mean       -48.5269
trainer/Q2 Predictions Std         52.0488
trainer/Q2 Predictions Max         -9.38001
trainer/Q2 Predictions Min       -198.316
trainer/Q Targets Mean            -48.6267
trainer/Q Targets Std              52.0914
trainer/Q Targets Max              -9.41192
trainer/Q Targets Min            -199.859
trainer/Log Pis Mean                2.17485
trainer/Log Pis Std                 1.85335
trainer/Log Pis Max                13.38
trainer/Log Pis Min                -2.81942
trainer/Policy mu Mean             -0.178277
trainer/Policy mu Std               0.860435
trainer/Policy mu Max               2.46921
trainer/Policy mu Min              -5.12754
trainer/Policy log std Mean        -2.03248
trainer/Policy log std Std          0.566906
trainer/Policy log std Max          0.0852114
trainer/Policy log std Min         -2.71499
trainer/Alpha                       0.0565214
trainer/Alpha Loss                  0.502362
exploration/num steps total    144200
exploration/num paths total      1442
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.1489
exploration/Rewards Std             1.22888
exploration/Rewards Max            -0.00996678
exploration/Rewards Min            -8.86792
exploration/Returns Mean         -114.89
exploration/Returns Std            72.0552
exploration/Returns Max           -57.5526
exploration/Returns Min          -235.25
exploration/Actions Mean            0.0105074
exploration/Actions Std             0.225131
exploration/Actions Max             0.995391
exploration/Actions Min            -0.996678
exploration/Num Paths               5
exploration/Average Returns      -114.89
evaluation/num steps total     432000
evaluation/num paths total       4320
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.60551
evaluation/Rewards Std              1.30995
evaluation/Rewards Max             -0.0117019
evaluation/Rewards Min             -9.83602
evaluation/Returns Mean          -160.551
evaluation/Returns Std            112.024
evaluation/Returns Max             -8.43678
evaluation/Returns Min           -314.176
evaluation/Actions Mean            -0.013594
evaluation/Actions Std              0.17963
evaluation/Actions Max              0.99366
evaluation/Actions Min             -0.999932
evaluation/Num Paths               15
evaluation/Average Returns       -160.551
time/data storing (s)               0.002806
time/evaluation sampling (s)        0.319954
time/exploration sampling (s)       0.139418
time/logging (s)                    0.00480959
time/saving (s)                     0.00192762
time/training (s)                   1.9896
time/epoch (s)                      2.45851
time/total (s)                    706.322
Epoch                             287
-----------------------------  ---------------
2019-04-23 01:25:20.204536 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 288 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    3.11993
trainer/QF2 Loss                    2.75923
trainer/Policy Loss                46.2581
trainer/Q1 Predictions Mean       -44.4925
trainer/Q1 Predictions Std         42.2435
trainer/Q1 Predictions Max         -9.66834
trainer/Q1 Predictions Min       -153.218
trainer/Q2 Predictions Mean       -44.5434
trainer/Q2 Predictions Std         42.2682
trainer/Q2 Predictions Max         -9.6951
trainer/Q2 Predictions Min       -152.838
trainer/Q Targets Mean            -44.8603
trainer/Q Targets Std              42.8712
trainer/Q Targets Max              -0.282278
trainer/Q Targets Min            -155.071
trainer/Log Pis Mean                2.00184
trainer/Log Pis Std                 1.10539
trainer/Log Pis Max                 6.16318
trainer/Log Pis Min                -2.56533
trainer/Policy mu Mean             -0.0383649
trainer/Policy mu Std               0.628737
trainer/Policy mu Max               2.61464
trainer/Policy mu Min              -2.88015
trainer/Policy log std Mean        -2.07228
trainer/Policy log std Std          0.460947
trainer/Policy log std Max         -0.561438
trainer/Policy log std Min         -2.65709
trainer/Alpha                       0.0597012
trainer/Alpha Loss                  0.00517417
exploration/num steps total    144700
exploration/num paths total      1447
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.782766
exploration/Rewards Std             1.15823
exploration/Rewards Max            -0.00413871
exploration/Rewards Min           -10.3339
exploration/Returns Mean          -78.2766
exploration/Returns Std            65.1855
exploration/Returns Max           -34.7147
exploration/Returns Min          -207.734
exploration/Actions Mean            0.0115765
exploration/Actions Std             0.23076
exploration/Actions Max             0.998519
exploration/Actions Min            -0.999899
exploration/Num Paths               5
exploration/Average Returns       -78.2766
evaluation/num steps total     433500
evaluation/num paths total       4335
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.706366
evaluation/Rewards Std              1.314
evaluation/Rewards Max             -0.0206683
evaluation/Rewards Min            -10.2124
evaluation/Returns Mean           -70.6366
evaluation/Returns Std             81.7427
evaluation/Returns Max            -10.3697
evaluation/Returns Min           -356.248
evaluation/Actions Mean             0.00819252
evaluation/Actions Std              0.192835
evaluation/Actions Max              0.999345
evaluation/Actions Min             -0.998508
evaluation/Num Paths               15
evaluation/Average Returns        -70.6366
time/data storing (s)               0.0025937
time/evaluation sampling (s)        0.330045
time/exploration sampling (s)       0.142003
time/logging (s)                    0.00478734
time/saving (s)                     0.00195021
time/training (s)                   1.97341
time/epoch (s)                      2.45479
time/total (s)                    708.781
Epoch                             288
-----------------------------  ---------------
2019-04-23 01:25:22.655311 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 289 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   52.8681
trainer/QF2 Loss                   52.5732
trainer/Policy Loss                59.13
trainer/Q1 Predictions Mean       -57.4468
trainer/Q1 Predictions Std         50.9517
trainer/Q1 Predictions Max         -9.64791
trainer/Q1 Predictions Min       -158.429
trainer/Q2 Predictions Mean       -57.4771
trainer/Q2 Predictions Std         50.9863
trainer/Q2 Predictions Max         -9.57027
trainer/Q2 Predictions Min       -158.411
trainer/Q Targets Mean            -57.3176
trainer/Q Targets Std              51.7507
trainer/Q Targets Max              -1.18368
trainer/Q Targets Min            -161.029
trainer/Log Pis Mean                2.11213
trainer/Log Pis Std                 1.14598
trainer/Log Pis Max                 7.45364
trainer/Log Pis Min                -1.28667
trainer/Policy mu Mean             -0.125871
trainer/Policy mu Std               0.771517
trainer/Policy mu Max               2.81195
trainer/Policy mu Min              -3.14611
trainer/Policy log std Mean        -1.96957
trainer/Policy log std Std          0.579353
trainer/Policy log std Max         -0.410058
trainer/Policy log std Min         -2.73913
trainer/Alpha                       0.0585664
trainer/Alpha Loss                  0.318208
exploration/num steps total    145200
exploration/num paths total      1452
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.855624
exploration/Rewards Std             1.13045
exploration/Rewards Max            -0.0156377
exploration/Rewards Min           -10.1006
exploration/Returns Mean          -85.5624
exploration/Returns Std            62.8516
exploration/Returns Max           -26.4474
exploration/Returns Min          -195.556
exploration/Actions Mean            0.0169264
exploration/Actions Std             0.211575
exploration/Actions Max             0.999941
exploration/Actions Min            -0.983209
exploration/Num Paths               5
exploration/Average Returns       -85.5624
evaluation/num steps total     435000
evaluation/num paths total       4350
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.5581
evaluation/Rewards Std              1.40882
evaluation/Rewards Max             -0.0262096
evaluation/Rewards Min            -10.8344
evaluation/Returns Mean          -155.81
evaluation/Returns Std            111.548
evaluation/Returns Max            -21.4201
evaluation/Returns Min           -363.812
evaluation/Actions Mean            -0.0145993
evaluation/Actions Std              0.183834
evaluation/Actions Max              0.998356
evaluation/Actions Min             -0.999765
evaluation/Num Paths               15
evaluation/Average Returns       -155.81
time/data storing (s)               0.00273397
time/evaluation sampling (s)        0.327806
time/exploration sampling (s)       0.1397
time/logging (s)                    0.00494348
time/saving (s)                     0.001933
time/training (s)                   1.96478
time/epoch (s)                      2.4419
time/total (s)                    711.228
Epoch                             289
-----------------------------  ---------------
2019-04-23 01:25:25.103539 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 290 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.58227
trainer/QF2 Loss                    1.64165
trainer/Policy Loss                52.5436
trainer/Q1 Predictions Mean       -51.1641
trainer/Q1 Predictions Std         48.1343
trainer/Q1 Predictions Max         -9.57271
trainer/Q1 Predictions Min       -159.23
trainer/Q2 Predictions Mean       -51.156
trainer/Q2 Predictions Std         48.0783
trainer/Q2 Predictions Max         -9.51486
trainer/Q2 Predictions Min       -158.989
trainer/Q Targets Mean            -51.4232
trainer/Q Targets Std              48.4783
trainer/Q Targets Max              -0.144479
trainer/Q Targets Min            -159.862
trainer/Log Pis Mean                1.79993
trainer/Log Pis Std                 1.45297
trainer/Log Pis Max                 6.16581
trainer/Log Pis Min                -2.10679
trainer/Policy mu Mean             -0.146321
trainer/Policy mu Std               0.663997
trainer/Policy mu Max               1.92114
trainer/Policy mu Min              -2.59331
trainer/Policy log std Mean        -2.00874
trainer/Policy log std Std          0.506073
trainer/Policy log std Max         -0.467308
trainer/Policy log std Min         -2.59721
trainer/Alpha                       0.0602201
trainer/Alpha Loss                 -0.562098
exploration/num steps total    145700
exploration/num paths total      1457
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.27535
exploration/Rewards Std             1.28564
exploration/Rewards Max            -0.0164599
exploration/Rewards Min            -9.09834
exploration/Returns Mean         -127.535
exploration/Returns Std            87.6072
exploration/Returns Max           -50.5646
exploration/Returns Min          -291.117
exploration/Actions Mean           -0.00340813
exploration/Actions Std             0.237638
exploration/Actions Max             0.996949
exploration/Actions Min            -0.999991
exploration/Num Paths               5
exploration/Average Returns      -127.535
evaluation/num steps total     436500
evaluation/num paths total       4365
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.76347
evaluation/Rewards Std              1.32296
evaluation/Rewards Max             -0.124747
evaluation/Rewards Min             -9.15384
evaluation/Returns Mean          -176.347
evaluation/Returns Std            107.797
evaluation/Returns Max            -24.7353
evaluation/Returns Min           -415.679
evaluation/Actions Mean            -0.0188125
evaluation/Actions Std              0.18989
evaluation/Actions Max              0.992837
evaluation/Actions Min             -0.999958
evaluation/Num Paths               15
evaluation/Average Returns       -176.347
time/data storing (s)               0.00280797
time/evaluation sampling (s)        0.325937
time/exploration sampling (s)       0.139086
time/logging (s)                    0.00473918
time/saving (s)                     0.00193974
time/training (s)                   1.96457
time/epoch (s)                      2.43908
time/total (s)                    713.671
Epoch                             290
-----------------------------  ---------------
2019-04-23 01:25:27.555601 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 291 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.648388
trainer/QF2 Loss                    0.634696
trainer/Policy Loss                58.2803
trainer/Q1 Predictions Mean       -56.8319
trainer/Q1 Predictions Std         51.7932
trainer/Q1 Predictions Max         -9.48418
trainer/Q1 Predictions Min       -157.966
trainer/Q2 Predictions Mean       -56.8565
trainer/Q2 Predictions Std         51.8469
trainer/Q2 Predictions Max         -9.44552
trainer/Q2 Predictions Min       -158.384
trainer/Q Targets Mean            -57.3278
trainer/Q Targets Std              52.2007
trainer/Q Targets Max              -9.51633
trainer/Q Targets Min            -159.793
trainer/Log Pis Mean                1.73881
trainer/Log Pis Std                 1.25449
trainer/Log Pis Max                 5.87614
trainer/Log Pis Min                -2.55239
trainer/Policy mu Mean             -0.0898383
trainer/Policy mu Std               0.630731
trainer/Policy mu Max               2.36021
trainer/Policy mu Min              -2.15288
trainer/Policy log std Mean        -1.98969
trainer/Policy log std Std          0.56894
trainer/Policy log std Max         -0.571263
trainer/Policy log std Min         -2.65178
trainer/Alpha                       0.0567114
trainer/Alpha Loss                 -0.749539
exploration/num steps total    146200
exploration/num paths total      1462
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.723045
exploration/Rewards Std             1.03767
exploration/Rewards Max            -0.0177715
exploration/Rewards Min           -10.1519
exploration/Returns Mean          -72.3045
exploration/Returns Std            51.8675
exploration/Returns Max           -28.9888
exploration/Returns Min          -170.28
exploration/Actions Mean           -0.0130445
exploration/Actions Std             0.210754
exploration/Actions Max             0.999886
exploration/Actions Min            -0.997188
exploration/Num Paths               5
exploration/Average Returns       -72.3045
evaluation/num steps total     438000
evaluation/num paths total       4380
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.86591
evaluation/Rewards Std              1.35629
evaluation/Rewards Max             -0.0720442
evaluation/Rewards Min            -10.0446
evaluation/Returns Mean          -186.591
evaluation/Returns Std            105.423
evaluation/Returns Max            -26.6507
evaluation/Returns Min           -317.07
evaluation/Actions Mean            -0.00809901
evaluation/Actions Std              0.181311
evaluation/Actions Max              0.999481
evaluation/Actions Min             -0.99995
evaluation/Num Paths               15
evaluation/Average Returns       -186.591
time/data storing (s)               0.00266787
time/evaluation sampling (s)        0.33271
time/exploration sampling (s)       0.137341
time/logging (s)                    0.00474984
time/saving (s)                     0.00155848
time/training (s)                   1.9642
time/epoch (s)                      2.44323
time/total (s)                    716.119
Epoch                             291
-----------------------------  ---------------
2019-04-23 01:25:30.013906 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 292 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    2.29096
trainer/QF2 Loss                    2.3223
trainer/Policy Loss                54.0757
trainer/Q1 Predictions Mean       -52.3072
trainer/Q1 Predictions Std         51.6415
trainer/Q1 Predictions Max         -9.37605
trainer/Q1 Predictions Min       -158.556
trainer/Q2 Predictions Mean       -52.278
trainer/Q2 Predictions Std         51.6371
trainer/Q2 Predictions Max         -9.26329
trainer/Q2 Predictions Min       -159.391
trainer/Q Targets Mean            -52.4864
trainer/Q Targets Std              52.0035
trainer/Q Targets Max              -0.13682
trainer/Q Targets Min            -160.873
trainer/Log Pis Mean                2.14865
trainer/Log Pis Std                 1.24707
trainer/Log Pis Max                 8.17955
trainer/Log Pis Min                -1.42424
trainer/Policy mu Mean             -0.0123315
trainer/Policy mu Std               0.754299
trainer/Policy mu Max               3.6464
trainer/Policy mu Min              -2.53706
trainer/Policy log std Mean        -2.04358
trainer/Policy log std Std          0.623461
trainer/Policy log std Max         -0.342424
trainer/Policy log std Min         -2.73657
trainer/Alpha                       0.0559959
trainer/Alpha Loss                  0.428484
exploration/num steps total    146700
exploration/num paths total      1467
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.7278
exploration/Rewards Std             1.63937
exploration/Rewards Max            -0.00508822
exploration/Rewards Min           -10.2559
exploration/Returns Mean         -172.78
exploration/Returns Std           108.337
exploration/Returns Max           -22.2875
exploration/Returns Min          -313.73
exploration/Actions Mean            0.0113195
exploration/Actions Std             0.303813
exploration/Actions Max             0.999272
exploration/Actions Min            -0.999876
exploration/Num Paths               5
exploration/Average Returns      -172.78
evaluation/num steps total     439500
evaluation/num paths total       4395
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.17202
evaluation/Rewards Std              1.37337
evaluation/Rewards Max             -0.0111956
evaluation/Rewards Min            -11.4853
evaluation/Returns Mean          -117.202
evaluation/Returns Std            106.782
evaluation/Returns Max             -5.83452
evaluation/Returns Min           -298.14
evaluation/Actions Mean             0.00073483
evaluation/Actions Std              0.168127
evaluation/Actions Max              0.999839
evaluation/Actions Min             -0.999776
evaluation/Num Paths               15
evaluation/Average Returns       -117.202
time/data storing (s)               0.00257726
time/evaluation sampling (s)        0.334205
time/exploration sampling (s)       0.139013
time/logging (s)                    0.00470799
time/saving (s)                     0.00192015
time/training (s)                   1.96694
time/epoch (s)                      2.44936
time/total (s)                    718.573
Epoch                             292
-----------------------------  ---------------
2019-04-23 01:25:32.472085 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 293 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.11273
trainer/QF2 Loss                    1.09472
trainer/Policy Loss                61.9561
trainer/Q1 Predictions Mean       -60.2889
trainer/Q1 Predictions Std         51.6708
trainer/Q1 Predictions Max         -9.72225
trainer/Q1 Predictions Min       -159.459
trainer/Q2 Predictions Mean       -60.3314
trainer/Q2 Predictions Std         51.7064
trainer/Q2 Predictions Max         -9.68156
trainer/Q2 Predictions Min       -159.686
trainer/Q Targets Mean            -60.0885
trainer/Q Targets Std              51.8517
trainer/Q Targets Max              -0.25513
trainer/Q Targets Min            -157.855
trainer/Log Pis Mean                2.0133
trainer/Log Pis Std                 1.29968
trainer/Log Pis Max                 5.733
trainer/Log Pis Min                -2.2914
trainer/Policy mu Mean             -0.176448
trainer/Policy mu Std               0.795079
trainer/Policy mu Max               2.63733
trainer/Policy mu Min              -3.56605
trainer/Policy log std Mean        -1.98319
trainer/Policy log std Std          0.604074
trainer/Policy log std Max         -0.556968
trainer/Policy log std Min         -2.77838
trainer/Alpha                       0.0575605
trainer/Alpha Loss                  0.0379876
exploration/num steps total    147200
exploration/num paths total      1472
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.1467
exploration/Rewards Std             1.15612
exploration/Rewards Max            -0.0130422
exploration/Rewards Min            -8.48172
exploration/Returns Mean         -114.67
exploration/Returns Std           102.759
exploration/Returns Max           -15.1941
exploration/Returns Min          -296.314
exploration/Actions Mean           -0.0046473
exploration/Actions Std             0.215402
exploration/Actions Max             0.998822
exploration/Actions Min            -0.995384
exploration/Num Paths               5
exploration/Average Returns      -114.67
evaluation/num steps total     441000
evaluation/num paths total       4410
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.24476
evaluation/Rewards Std              1.38937
evaluation/Rewards Max             -0.0104771
evaluation/Rewards Min            -11.1332
evaluation/Returns Mean          -124.476
evaluation/Returns Std             99.2892
evaluation/Returns Max             -7.2469
evaluation/Returns Min           -306.887
evaluation/Actions Mean            -0.0126502
evaluation/Actions Std              0.199295
evaluation/Actions Max              0.998813
evaluation/Actions Min             -0.999982
evaluation/Num Paths               15
evaluation/Average Returns       -124.476
time/data storing (s)               0.00268962
time/evaluation sampling (s)        0.322436
time/exploration sampling (s)       0.136628
time/logging (s)                    0.00477094
time/saving (s)                     0.00193511
time/training (s)                   1.9809
time/epoch (s)                      2.44936
time/total (s)                    721.027
Epoch                             293
-----------------------------  ---------------
2019-04-23 01:25:34.927520 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 294 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                  214.593
trainer/QF2 Loss                  213.884
trainer/Policy Loss                56.1371
trainer/Q1 Predictions Mean       -54.4438
trainer/Q1 Predictions Std         52.6707
trainer/Q1 Predictions Max         -9.15172
trainer/Q1 Predictions Min       -156.758
trainer/Q2 Predictions Mean       -54.4915
trainer/Q2 Predictions Std         52.7096
trainer/Q2 Predictions Max         -9.2036
trainer/Q2 Predictions Min       -156.762
trainer/Q Targets Mean            -53.4523
trainer/Q Targets Std              52.7408
trainer/Q Targets Max              -0.173076
trainer/Q Targets Min            -158.051
trainer/Log Pis Mean                2.07893
trainer/Log Pis Std                 1.17096
trainer/Log Pis Max                 4.97403
trainer/Log Pis Min                -3.43678
trainer/Policy mu Mean              0.034961
trainer/Policy mu Std               0.75227
trainer/Policy mu Max               2.63122
trainer/Policy mu Min              -2.64488
trainer/Policy log std Mean        -1.96511
trainer/Policy log std Std          0.592006
trainer/Policy log std Max         -0.462132
trainer/Policy log std Min         -2.82468
trainer/Alpha                       0.0587745
trainer/Alpha Loss                  0.223689
exploration/num steps total    147700
exploration/num paths total      1477
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -2.27158
exploration/Rewards Std             0.758944
exploration/Rewards Max            -1.0666
exploration/Rewards Min            -7.5157
exploration/Returns Mean         -227.158
exploration/Returns Std            39.8821
exploration/Returns Max          -175.888
exploration/Returns Min          -267.301
exploration/Actions Mean           -0.000884257
exploration/Actions Std             0.347452
exploration/Actions Max             0.997839
exploration/Actions Min            -0.999612
exploration/Num Paths               5
exploration/Average Returns      -227.158
evaluation/num steps total     442500
evaluation/num paths total       4425
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.12909
evaluation/Rewards Std              1.4737
evaluation/Rewards Max             -0.0201815
evaluation/Rewards Min            -10.1704
evaluation/Returns Mean          -112.909
evaluation/Returns Std            104.987
evaluation/Returns Max            -13.9051
evaluation/Returns Min           -338.44
evaluation/Actions Mean             0.00938959
evaluation/Actions Std              0.188173
evaluation/Actions Max              0.99975
evaluation/Actions Min             -0.999132
evaluation/Num Paths               15
evaluation/Average Returns       -112.909
time/data storing (s)               0.00279249
time/evaluation sampling (s)        0.324157
time/exploration sampling (s)       0.141371
time/logging (s)                    0.00481129
time/saving (s)                     0.00196045
time/training (s)                   1.97139
time/epoch (s)                      2.44648
time/total (s)                    723.478
Epoch                             294
-----------------------------  ----------------
2019-04-23 01:25:37.403836 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 295 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                   15.2388
trainer/QF2 Loss                   14.7328
trainer/Policy Loss                55.3034
trainer/Q1 Predictions Mean       -53.9141
trainer/Q1 Predictions Std         48.5096
trainer/Q1 Predictions Max         -9.46145
trainer/Q1 Predictions Min       -153.373
trainer/Q2 Predictions Mean       -53.941
trainer/Q2 Predictions Std         48.5284
trainer/Q2 Predictions Max         -9.40347
trainer/Q2 Predictions Min       -155.3
trainer/Q Targets Mean            -54.0325
trainer/Q Targets Std              49.3145
trainer/Q Targets Max              -4.22746
trainer/Q Targets Min            -155.952
trainer/Log Pis Mean                1.77032
trainer/Log Pis Std                 1.43451
trainer/Log Pis Max                 6.67264
trainer/Log Pis Min                -2.34058
trainer/Policy mu Mean             -0.131101
trainer/Policy mu Std               0.829541
trainer/Policy mu Max               3.15233
trainer/Policy mu Min              -2.33884
trainer/Policy log std Mean        -1.92049
trainer/Policy log std Std          0.611392
trainer/Policy log std Max         -0.52251
trainer/Policy log std Min         -2.63912
trainer/Alpha                       0.0576886
trainer/Alpha Loss                 -0.655172
exploration/num steps total    148200
exploration/num paths total      1482
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.26112
exploration/Rewards Std             1.43396
exploration/Rewards Max            -0.00670983
exploration/Rewards Min            -9.99567
exploration/Returns Mean         -126.112
exploration/Returns Std           109.717
exploration/Returns Max           -18.7824
exploration/Returns Min          -293.297
exploration/Actions Mean           -0.000212376
exploration/Actions Std             0.252901
exploration/Actions Max             0.995928
exploration/Actions Min            -0.997097
exploration/Num Paths               5
exploration/Average Returns      -126.112
evaluation/num steps total     444000
evaluation/num paths total       4440
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.33263
evaluation/Rewards Std              1.06325
evaluation/Rewards Max             -0.0103647
evaluation/Rewards Min             -8.41204
evaluation/Returns Mean          -133.263
evaluation/Returns Std             87.9244
evaluation/Returns Max            -11.8437
evaluation/Returns Min           -288.43
evaluation/Actions Mean            -0.0015243
evaluation/Actions Std              0.167494
evaluation/Actions Max              0.999364
evaluation/Actions Min             -0.99611
evaluation/Num Paths               15
evaluation/Average Returns       -133.263
time/data storing (s)               0.00270014
time/evaluation sampling (s)        0.32897
time/exploration sampling (s)       0.138471
time/logging (s)                    0.00515283
time/saving (s)                     0.00200972
time/training (s)                   1.99036
time/epoch (s)                      2.46767
time/total (s)                    725.95
Epoch                             295
-----------------------------  ----------------
2019-04-23 01:25:39.865627 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 296 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                  219.428
trainer/QF2 Loss                  218.409
trainer/Policy Loss                62.5313
trainer/Q1 Predictions Mean       -61.1109
trainer/Q1 Predictions Std         51.9525
trainer/Q1 Predictions Max         -9.01322
trainer/Q1 Predictions Min       -156.791
trainer/Q2 Predictions Mean       -61.1021
trainer/Q2 Predictions Std         51.9218
trainer/Q2 Predictions Max         -9.0579
trainer/Q2 Predictions Min       -155.97
trainer/Q Targets Mean            -60.5984
trainer/Q Targets Std              52.2148
trainer/Q Targets Max              -0.0878302
trainer/Q Targets Min            -156.977
trainer/Log Pis Mean                2.0256
trainer/Log Pis Std                 1.43524
trainer/Log Pis Max                 6.77035
trainer/Log Pis Min                -1.95858
trainer/Policy mu Mean             -0.155798
trainer/Policy mu Std               0.863362
trainer/Policy mu Max               2.50423
trainer/Policy mu Min              -3.16644
trainer/Policy log std Mean        -1.97387
trainer/Policy log std Std          0.601786
trainer/Policy log std Max         -0.312574
trainer/Policy log std Min         -2.85019
trainer/Alpha                       0.0596932
trainer/Alpha Loss                  0.0721673
exploration/num steps total    148700
exploration/num paths total      1487
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.72062
exploration/Rewards Std             1.25295
exploration/Rewards Max            -0.0257913
exploration/Rewards Min            -8.47446
exploration/Returns Mean         -172.062
exploration/Returns Std           102.484
exploration/Returns Max           -42.9457
exploration/Returns Min          -289.324
exploration/Actions Mean            0.0001657
exploration/Actions Std             0.237491
exploration/Actions Max             0.999092
exploration/Actions Min            -0.999803
exploration/Num Paths               5
exploration/Average Returns      -172.062
evaluation/num steps total     445500
evaluation/num paths total       4455
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.3775
evaluation/Rewards Std              1.15209
evaluation/Rewards Max             -0.0106019
evaluation/Rewards Min             -9.14202
evaluation/Returns Mean          -137.75
evaluation/Returns Std             95.227
evaluation/Returns Max             -8.53624
evaluation/Returns Min           -303.138
evaluation/Actions Mean            -0.00650395
evaluation/Actions Std              0.171361
evaluation/Actions Max              0.999147
evaluation/Actions Min             -0.999167
evaluation/Num Paths               15
evaluation/Average Returns       -137.75
time/data storing (s)               0.00266833
time/evaluation sampling (s)        0.325308
time/exploration sampling (s)       0.139161
time/logging (s)                    0.00481835
time/saving (s)                     0.00192003
time/training (s)                   1.97851
time/epoch (s)                      2.45239
time/total (s)                    728.407
Epoch                             296
-----------------------------  ---------------
2019-04-23 01:25:42.339204 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 297 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.339372
trainer/QF2 Loss                    0.482587
trainer/Policy Loss                46.3611
trainer/Q1 Predictions Mean       -44.5266
trainer/Q1 Predictions Std         47.6031
trainer/Q1 Predictions Max         -9.00792
trainer/Q1 Predictions Min       -153.335
trainer/Q2 Predictions Mean       -44.5023
trainer/Q2 Predictions Std         47.5496
trainer/Q2 Predictions Max         -8.9095
trainer/Q2 Predictions Min       -152.896
trainer/Q Targets Mean            -44.6443
trainer/Q Targets Std              47.8397
trainer/Q Targets Max              -9.15787
trainer/Q Targets Min            -152.917
trainer/Log Pis Mean                2.2546
trainer/Log Pis Std                 1.74411
trainer/Log Pis Max                11.4919
trainer/Log Pis Min                -0.846813
trainer/Policy mu Mean             -0.241819
trainer/Policy mu Std               0.968103
trainer/Policy mu Max               3.01453
trainer/Policy mu Min              -4.15807
trainer/Policy log std Mean        -1.95811
trainer/Policy log std Std          0.670092
trainer/Policy log std Max          0.325875
trainer/Policy log std Min         -2.78449
trainer/Alpha                       0.0592693
trainer/Alpha Loss                  0.719442
exploration/num steps total    149200
exploration/num paths total      1492
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.464944
exploration/Rewards Std             0.565517
exploration/Rewards Max            -0.00955988
exploration/Rewards Min            -6.91321
exploration/Returns Mean          -46.4944
exploration/Returns Std            20.1586
exploration/Returns Max           -20.098
exploration/Returns Min           -81.4358
exploration/Actions Mean           -0.0161083
exploration/Actions Std             0.170488
exploration/Actions Max             0.776448
exploration/Actions Min            -0.999746
exploration/Num Paths               5
exploration/Average Returns       -46.4944
evaluation/num steps total     447000
evaluation/num paths total       4470
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.948232
evaluation/Rewards Std              1.18965
evaluation/Rewards Max             -0.0282974
evaluation/Rewards Min            -10.4171
evaluation/Returns Mean           -94.8232
evaluation/Returns Std             78.5296
evaluation/Returns Max            -11.854
evaluation/Returns Min           -268.2
evaluation/Actions Mean            -0.00411179
evaluation/Actions Std              0.180567
evaluation/Actions Max              0.99782
evaluation/Actions Min             -0.999805
evaluation/Num Paths               15
evaluation/Average Returns        -94.8232
time/data storing (s)               0.00319137
time/evaluation sampling (s)        0.32915
time/exploration sampling (s)       0.137062
time/logging (s)                    0.00477828
time/saving (s)                     0.0103431
time/training (s)                   1.97986
time/epoch (s)                      2.46439
time/total (s)                    730.876
Epoch                             297
-----------------------------  ---------------
2019-04-23 01:25:44.791491 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 298 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    2.08121
trainer/QF2 Loss                    1.95491
trainer/Policy Loss                59.2849
trainer/Q1 Predictions Mean       -57.6052
trainer/Q1 Predictions Std         50.7847
trainer/Q1 Predictions Max         -9.10771
trainer/Q1 Predictions Min       -157.517
trainer/Q2 Predictions Mean       -57.6473
trainer/Q2 Predictions Std         50.8284
trainer/Q2 Predictions Max         -9.08581
trainer/Q2 Predictions Min       -157.238
trainer/Q Targets Mean            -57.8727
trainer/Q Targets Std              51.2331
trainer/Q Targets Max              -0.101033
trainer/Q Targets Min            -157.196
trainer/Log Pis Mean                2.04647
trainer/Log Pis Std                 1.64446
trainer/Log Pis Max                11.3262
trainer/Log Pis Min                -1.59274
trainer/Policy mu Mean              0.0207463
trainer/Policy mu Std               0.848018
trainer/Policy mu Max               4.16281
trainer/Policy mu Min              -3.13575
trainer/Policy log std Mean        -1.93491
trainer/Policy log std Std          0.66106
trainer/Policy log std Max         -0.338477
trainer/Policy log std Min         -2.79746
trainer/Alpha                       0.0605951
trainer/Alpha Loss                  0.130294
exploration/num steps total    149700
exploration/num paths total      1497
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.852799
exploration/Rewards Std             0.929393
exploration/Rewards Max            -0.00191035
exploration/Rewards Min            -7.04177
exploration/Returns Mean          -85.2799
exploration/Returns Std            81.3795
exploration/Returns Max           -14.1916
exploration/Returns Min          -242.702
exploration/Actions Mean           -0.00497209
exploration/Actions Std             0.258319
exploration/Actions Max             0.99747
exploration/Actions Min            -0.992093
exploration/Num Paths               5
exploration/Average Returns       -85.2799
evaluation/num steps total     448500
evaluation/num paths total       4485
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.998837
evaluation/Rewards Std              1.29263
evaluation/Rewards Max             -0.00248769
evaluation/Rewards Min             -9.56491
evaluation/Returns Mean           -99.8837
evaluation/Returns Std             97.0327
evaluation/Returns Max             -5.86093
evaluation/Returns Min           -285.644
evaluation/Actions Mean             0.0114185
evaluation/Actions Std              0.16487
evaluation/Actions Max              0.999427
evaluation/Actions Min             -0.997834
evaluation/Num Paths               15
evaluation/Average Returns        -99.8837
time/data storing (s)               0.00258733
time/evaluation sampling (s)        0.32876
time/exploration sampling (s)       0.138822
time/logging (s)                    0.0047752
time/saving (s)                     0.0019358
time/training (s)                   1.96682
time/epoch (s)                      2.4437
time/total (s)                    733.323
Epoch                             298
-----------------------------  ---------------
2019-04-23 01:25:47.238797 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 299 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.70873
trainer/QF2 Loss                    1.86254
trainer/Policy Loss                59.5685
trainer/Q1 Predictions Mean       -58.1581
trainer/Q1 Predictions Std         52.5864
trainer/Q1 Predictions Max         -9.36696
trainer/Q1 Predictions Min       -153.946
trainer/Q2 Predictions Mean       -58.107
trainer/Q2 Predictions Std         52.4734
trainer/Q2 Predictions Max         -9.34705
trainer/Q2 Predictions Min       -153.596
trainer/Q Targets Mean            -58.967
trainer/Q Targets Std              53.4419
trainer/Q Targets Max              -9.32722
trainer/Q Targets Min            -157.477
trainer/Log Pis Mean                1.7592
trainer/Log Pis Std                 1.38343
trainer/Log Pis Max                 5.44008
trainer/Log Pis Min                -4.56048
trainer/Policy mu Mean             -0.156315
trainer/Policy mu Std               0.780987
trainer/Policy mu Max               3.38688
trainer/Policy mu Min              -2.76648
trainer/Policy log std Mean        -1.91938
trainer/Policy log std Std          0.596265
trainer/Policy log std Max         -0.402249
trainer/Policy log std Min         -2.69192
trainer/Alpha                       0.0600147
trainer/Alpha Loss                 -0.677363
exploration/num steps total    150200
exploration/num paths total      1502
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.782022
exploration/Rewards Std             1.21079
exploration/Rewards Max            -0.0175393
exploration/Rewards Min            -5.68352
exploration/Returns Mean          -78.2022
exploration/Returns Std           108.558
exploration/Returns Max           -14.6841
exploration/Returns Min          -294.827
exploration/Actions Mean           -0.0161065
exploration/Actions Std             0.243297
exploration/Actions Max             0.997232
exploration/Actions Min            -0.990216
exploration/Num Paths               5
exploration/Average Returns       -78.2022
evaluation/num steps total     450000
evaluation/num paths total       4500
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.44376
evaluation/Rewards Std              1.26462
evaluation/Rewards Max             -0.0525948
evaluation/Rewards Min             -9.36694
evaluation/Returns Mean          -144.376
evaluation/Returns Std            104.8
evaluation/Returns Max            -25.5329
evaluation/Returns Min           -312.937
evaluation/Actions Mean            -0.00628593
evaluation/Actions Std              0.161048
evaluation/Actions Max              0.998638
evaluation/Actions Min             -0.998855
evaluation/Num Paths               15
evaluation/Average Returns       -144.376
time/data storing (s)               0.00278976
time/evaluation sampling (s)        0.329138
time/exploration sampling (s)       0.136693
time/logging (s)                    0.00474443
time/saving (s)                     0.00191605
time/training (s)                   1.963
time/epoch (s)                      2.43828
time/total (s)                    735.766
Epoch                             299
-----------------------------  ---------------
2019-04-23 01:25:49.693910 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 300 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                  162.115
trainer/QF2 Loss                  162.085
trainer/Policy Loss                60.2149
trainer/Q1 Predictions Mean       -58.4512
trainer/Q1 Predictions Std         52.619
trainer/Q1 Predictions Max         -9.09308
trainer/Q1 Predictions Min       -159.239
trainer/Q2 Predictions Mean       -58.419
trainer/Q2 Predictions Std         52.5918
trainer/Q2 Predictions Max         -9.13796
trainer/Q2 Predictions Min       -160.11
trainer/Q Targets Mean            -57.5894
trainer/Q Targets Std              52.7341
trainer/Q Targets Max              -2.70399
trainer/Q Targets Min            -158.45
trainer/Log Pis Mean                2.15849
trainer/Log Pis Std                 1.38077
trainer/Log Pis Max                 8.83485
trainer/Log Pis Min                -3.11026
trainer/Policy mu Mean              0.17914
trainer/Policy mu Std               0.848149
trainer/Policy mu Max               3.15132
trainer/Policy mu Min              -2.49089
trainer/Policy log std Mean        -1.95548
trainer/Policy log std Std          0.649077
trainer/Policy log std Max         -0.232779
trainer/Policy log std Min         -2.76128
trainer/Alpha                       0.0585192
trainer/Alpha Loss                  0.449854
exploration/num steps total    150700
exploration/num paths total      1507
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.459433
exploration/Rewards Std             0.832048
exploration/Rewards Max            -0.00865593
exploration/Rewards Min            -8.93695
exploration/Returns Mean          -45.9433
exploration/Returns Std            37.6912
exploration/Returns Max           -12.874
exploration/Returns Min          -118.763
exploration/Actions Mean            0.00745453
exploration/Actions Std             0.191142
exploration/Actions Max             0.999872
exploration/Actions Min            -0.994689
exploration/Num Paths               5
exploration/Average Returns       -45.9433
evaluation/num steps total     451500
evaluation/num paths total       4515
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.48733
evaluation/Rewards Std              1.45415
evaluation/Rewards Max             -0.0259181
evaluation/Rewards Min             -9.81876
evaluation/Returns Mean          -148.733
evaluation/Returns Std            115.074
evaluation/Returns Max            -22.0517
evaluation/Returns Min           -313.263
evaluation/Actions Mean            -0.00706433
evaluation/Actions Std              0.194253
evaluation/Actions Max              0.999632
evaluation/Actions Min             -0.997129
evaluation/Num Paths               15
evaluation/Average Returns       -148.733
time/data storing (s)               0.0026655
time/evaluation sampling (s)        0.329044
time/exploration sampling (s)       0.141768
time/logging (s)                    0.00480748
time/saving (s)                     0.00193433
time/training (s)                   1.96582
time/epoch (s)                      2.44604
time/total (s)                    738.217
Epoch                             300
-----------------------------  ---------------
2019-04-23 01:25:52.148375 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 301 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   51.8095
trainer/QF2 Loss                   52.8437
trainer/Policy Loss                57.2394
trainer/Q1 Predictions Mean       -55.435
trainer/Q1 Predictions Std         47.8086
trainer/Q1 Predictions Max         -9.3208
trainer/Q1 Predictions Min       -148.691
trainer/Q2 Predictions Mean       -55.4079
trainer/Q2 Predictions Std         47.8054
trainer/Q2 Predictions Max         -9.29812
trainer/Q2 Predictions Min       -148.53
trainer/Q Targets Mean            -55.3297
trainer/Q Targets Std              48.725
trainer/Q Targets Max              -0.977953
trainer/Q Targets Min            -150.464
trainer/Log Pis Mean                2.10377
trainer/Log Pis Std                 1.19739
trainer/Log Pis Max                 6.41153
trainer/Log Pis Min                -1.73029
trainer/Policy mu Mean             -0.090737
trainer/Policy mu Std               0.753957
trainer/Policy mu Max               3.24394
trainer/Policy mu Min              -2.48048
trainer/Policy log std Mean        -2.00269
trainer/Policy log std Std          0.583526
trainer/Policy log std Max         -0.256418
trainer/Policy log std Min         -2.69772
trainer/Alpha                       0.0598508
trainer/Alpha Loss                  0.292231
exploration/num steps total    151200
exploration/num paths total      1512
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.35137
exploration/Rewards Std             1.6163
exploration/Rewards Max            -0.011769
exploration/Rewards Min            -9.99407
exploration/Returns Mean         -135.137
exploration/Returns Std           117.677
exploration/Returns Max           -25.8083
exploration/Returns Min          -322.334
exploration/Actions Mean           -0.0159161
exploration/Actions Std             0.23737
exploration/Actions Max             0.996197
exploration/Actions Min            -0.999923
exploration/Num Paths               5
exploration/Average Returns      -135.137
evaluation/num steps total     453000
evaluation/num paths total       4530
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.0404
evaluation/Rewards Std              1.00236
evaluation/Rewards Max             -0.0428526
evaluation/Rewards Min             -9.25484
evaluation/Returns Mean          -104.04
evaluation/Returns Std             79.3044
evaluation/Returns Max            -11.824
evaluation/Returns Min           -241.517
evaluation/Actions Mean            -0.00256841
evaluation/Actions Std              0.146855
evaluation/Actions Max              0.995273
evaluation/Actions Min             -0.998866
evaluation/Num Paths               15
evaluation/Average Returns       -104.04
time/data storing (s)               0.00300037
time/evaluation sampling (s)        0.333071
time/exploration sampling (s)       0.147604
time/logging (s)                    0.00474227
time/saving (s)                     0.00194621
time/training (s)                   1.95492
time/epoch (s)                      2.44528
time/total (s)                    740.667
Epoch                             301
-----------------------------  ---------------
2019-04-23 01:25:54.619876 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 302 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    3.6877
trainer/QF2 Loss                    3.5971
trainer/Policy Loss                51.5322
trainer/Q1 Predictions Mean       -49.952
trainer/Q1 Predictions Std         45.7422
trainer/Q1 Predictions Max         -9.16913
trainer/Q1 Predictions Min       -149.507
trainer/Q2 Predictions Mean       -49.9883
trainer/Q2 Predictions Std         45.7763
trainer/Q2 Predictions Max         -9.21033
trainer/Q2 Predictions Min       -148.874
trainer/Q Targets Mean            -50.9704
trainer/Q Targets Std              46.827
trainer/Q Targets Max              -0.273816
trainer/Q Targets Min            -153.315
trainer/Log Pis Mean                1.86774
trainer/Log Pis Std                 1.08526
trainer/Log Pis Max                 4.11364
trainer/Log Pis Min                -2.84996
trainer/Policy mu Mean              0.0261563
trainer/Policy mu Std               0.630344
trainer/Policy mu Max               2.64468
trainer/Policy mu Min              -2.24107
trainer/Policy log std Mean        -2.03734
trainer/Policy log std Std          0.538109
trainer/Policy log std Max         -0.393455
trainer/Policy log std Min         -2.80031
trainer/Alpha                       0.058913
trainer/Alpha Loss                 -0.37454
exploration/num steps total    151700
exploration/num paths total      1517
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.19116
exploration/Rewards Std             1.10786
exploration/Rewards Max            -0.0119781
exploration/Rewards Min           -10.4017
exploration/Returns Mean         -119.116
exploration/Returns Std            77.5782
exploration/Returns Max           -47.2154
exploration/Returns Min          -269.105
exploration/Actions Mean           -0.0101037
exploration/Actions Std             0.218466
exploration/Actions Max             0.986527
exploration/Actions Min            -0.997932
exploration/Num Paths               5
exploration/Average Returns      -119.116
evaluation/num steps total     454500
evaluation/num paths total       4545
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.709074
evaluation/Rewards Std              1.18006
evaluation/Rewards Max             -0.0657729
evaluation/Rewards Min            -11.2336
evaluation/Returns Mean           -70.9074
evaluation/Returns Std             64.9571
evaluation/Returns Max            -13.1997
evaluation/Returns Min           -237.577
evaluation/Actions Mean             0.0111615
evaluation/Actions Std              0.192759
evaluation/Actions Max              0.99879
evaluation/Actions Min             -0.999664
evaluation/Num Paths               15
evaluation/Average Returns        -70.9074
time/data storing (s)               0.00287432
time/evaluation sampling (s)        0.326017
time/exploration sampling (s)       0.140376
time/logging (s)                    0.0048219
time/saving (s)                     0.00194457
time/training (s)                   1.98642
time/epoch (s)                      2.46246
time/total (s)                    743.134
Epoch                             302
-----------------------------  ---------------
2019-04-23 01:25:57.105902 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 303 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.594682
trainer/QF2 Loss                    0.517063
trainer/Policy Loss                57.9837
trainer/Q1 Predictions Mean       -56.2256
trainer/Q1 Predictions Std         52.0527
trainer/Q1 Predictions Max         -9.32028
trainer/Q1 Predictions Min       -156.831
trainer/Q2 Predictions Mean       -56.2493
trainer/Q2 Predictions Std         52.107
trainer/Q2 Predictions Max         -9.31012
trainer/Q2 Predictions Min       -156.434
trainer/Q Targets Mean            -56.3404
trainer/Q Targets Std              52.3462
trainer/Q Targets Max              -9.24375
trainer/Q Targets Min            -158.038
trainer/Log Pis Mean                2.20542
trainer/Log Pis Std                 1.22512
trainer/Log Pis Max                 6.39803
trainer/Log Pis Min                -1.81556
trainer/Policy mu Mean             -0.165969
trainer/Policy mu Std               0.814593
trainer/Policy mu Max               2.74962
trainer/Policy mu Min              -2.56135
trainer/Policy log std Mean        -1.97351
trainer/Policy log std Std          0.585514
trainer/Policy log std Max         -0.561044
trainer/Policy log std Min         -2.72182
trainer/Alpha                       0.0612998
trainer/Alpha Loss                  0.573562
exploration/num steps total    152200
exploration/num paths total      1522
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.898836
exploration/Rewards Std             1.0225
exploration/Rewards Max            -0.0032331
exploration/Rewards Min            -8.0897
exploration/Returns Mean          -89.8836
exploration/Returns Std            67.3056
exploration/Returns Max           -23.3784
exploration/Returns Min          -181.295
exploration/Actions Mean            0.00274794
exploration/Actions Std             0.217076
exploration/Actions Max             0.996132
exploration/Actions Min            -0.999978
exploration/Num Paths               5
exploration/Average Returns       -89.8836
evaluation/num steps total     456000
evaluation/num paths total       4560
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.40833
evaluation/Rewards Std              1.47508
evaluation/Rewards Max             -0.00607125
evaluation/Rewards Min             -9.9515
evaluation/Returns Mean          -140.833
evaluation/Returns Std            108.119
evaluation/Returns Max            -15.943
evaluation/Returns Min           -312.303
evaluation/Actions Mean            -0.0144493
evaluation/Actions Std              0.199137
evaluation/Actions Max              0.996694
evaluation/Actions Min             -0.999927
evaluation/Num Paths               15
evaluation/Average Returns       -140.833
time/data storing (s)               0.00268833
time/evaluation sampling (s)        0.325864
time/exploration sampling (s)       0.1531
time/logging (s)                    0.00481282
time/saving (s)                     0.00194002
time/training (s)                   1.98852
time/epoch (s)                      2.47693
time/total (s)                    745.615
Epoch                             303
-----------------------------  ---------------
2019-04-23 01:25:59.569237 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 304 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                  200.387
trainer/QF2 Loss                  200.024
trainer/Policy Loss                52.5706
trainer/Q1 Predictions Mean       -50.7352
trainer/Q1 Predictions Std         48.8535
trainer/Q1 Predictions Max         -8.99344
trainer/Q1 Predictions Min       -150.671
trainer/Q2 Predictions Mean       -50.742
trainer/Q2 Predictions Std         48.877
trainer/Q2 Predictions Max         -9.00435
trainer/Q2 Predictions Min       -151.015
trainer/Q Targets Mean            -49.3681
trainer/Q Targets Std              49.1682
trainer/Q Targets Max              -2.00231
trainer/Q Targets Min            -151.15
trainer/Log Pis Mean                2.08345
trainer/Log Pis Std                 1.34078
trainer/Log Pis Max                 7.19563
trainer/Log Pis Min                -2.58849
trainer/Policy mu Mean             -0.106543
trainer/Policy mu Std               0.717379
trainer/Policy mu Max               2.24645
trainer/Policy mu Min              -2.84078
trainer/Policy log std Mean        -2.08084
trainer/Policy log std Std          0.55681
trainer/Policy log std Max         -0.428377
trainer/Policy log std Min         -2.83119
trainer/Alpha                       0.0614899
trainer/Alpha Loss                  0.232739
exploration/num steps total    152700
exploration/num paths total      1527
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.707184
exploration/Rewards Std             1.15254
exploration/Rewards Max            -0.00414595
exploration/Rewards Min            -8.16351
exploration/Returns Mean          -70.7184
exploration/Returns Std            47.437
exploration/Returns Max           -23.6749
exploration/Returns Min          -146.074
exploration/Actions Mean            0.0191069
exploration/Actions Std             0.229992
exploration/Actions Max             0.999752
exploration/Actions Min            -0.999439
exploration/Num Paths               5
exploration/Average Returns       -70.7184
evaluation/num steps total     457500
evaluation/num paths total       4575
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.19706
evaluation/Rewards Std              1.37173
evaluation/Rewards Max             -0.0459304
evaluation/Rewards Min             -9.66585
evaluation/Returns Mean          -119.706
evaluation/Returns Std            104.415
evaluation/Returns Max            -17.04
evaluation/Returns Min           -320.532
evaluation/Actions Mean             0.00273799
evaluation/Actions Std              0.18173
evaluation/Actions Max              0.999056
evaluation/Actions Min             -0.99925
evaluation/Num Paths               15
evaluation/Average Returns       -119.706
time/data storing (s)               0.00268925
time/evaluation sampling (s)        0.323898
time/exploration sampling (s)       0.139887
time/logging (s)                    0.00435416
time/saving (s)                     0.00196312
time/training (s)                   1.98101
time/epoch (s)                      2.4538
time/total (s)                    748.073
Epoch                             304
-----------------------------  ---------------
2019-04-23 01:26:02.032603 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 305 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                  157.757
trainer/QF2 Loss                  157.739
trainer/Policy Loss                57.8577
trainer/Q1 Predictions Mean       -56.1235
trainer/Q1 Predictions Std         50.6328
trainer/Q1 Predictions Max         -8.84813
trainer/Q1 Predictions Min       -160.017
trainer/Q2 Predictions Mean       -56.1054
trainer/Q2 Predictions Std         50.6411
trainer/Q2 Predictions Max         -8.90276
trainer/Q2 Predictions Min       -159.419
trainer/Q Targets Mean            -55.2071
trainer/Q Targets Std              50.5814
trainer/Q Targets Max              -2.85103
trainer/Q Targets Min            -158.019
trainer/Log Pis Mean                2.09129
trainer/Log Pis Std                 1.31559
trainer/Log Pis Max                 7.71871
trainer/Log Pis Min                -1.74081
trainer/Policy mu Mean              0.113038
trainer/Policy mu Std               0.797416
trainer/Policy mu Max               2.92857
trainer/Policy mu Min              -2.48224
trainer/Policy log std Mean        -1.98722
trainer/Policy log std Std          0.582641
trainer/Policy log std Max         -0.196919
trainer/Policy log std Min         -2.79549
trainer/Alpha                       0.060678
trainer/Alpha Loss                  0.255819
exploration/num steps total    153200
exploration/num paths total      1532
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.1598
exploration/Rewards Std             1.43361
exploration/Rewards Max            -0.0138794
exploration/Rewards Min            -9.31095
exploration/Returns Mean         -115.98
exploration/Returns Std           104.549
exploration/Returns Max           -25.296
exploration/Returns Min          -312.628
exploration/Actions Mean           -0.0170607
exploration/Actions Std             0.270551
exploration/Actions Max             0.982408
exploration/Actions Min            -0.999264
exploration/Num Paths               5
exploration/Average Returns      -115.98
evaluation/num steps total     459000
evaluation/num paths total       4590
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.46937
evaluation/Rewards Std              1.2544
evaluation/Rewards Max             -0.0341985
evaluation/Rewards Min             -8.75503
evaluation/Returns Mean          -146.937
evaluation/Returns Std            106.431
evaluation/Returns Max            -22.2622
evaluation/Returns Min           -353.132
evaluation/Actions Mean            -0.000580484
evaluation/Actions Std              0.166492
evaluation/Actions Max              0.999631
evaluation/Actions Min             -0.998127
evaluation/Num Paths               15
evaluation/Average Returns       -146.937
time/data storing (s)               0.00331071
time/evaluation sampling (s)        0.321458
time/exploration sampling (s)       0.144079
time/logging (s)                    0.00354288
time/saving (s)                     0.00152701
time/training (s)                   1.97991
time/epoch (s)                      2.45383
time/total (s)                    750.532
Epoch                             305
-----------------------------  ----------------
2019-04-23 01:26:04.499689 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 306 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.04714
trainer/QF2 Loss                    1.09946
trainer/Policy Loss                50.489
trainer/Q1 Predictions Mean       -49.0022
trainer/Q1 Predictions Std         51.0429
trainer/Q1 Predictions Max         -9.09166
trainer/Q1 Predictions Min       -158.785
trainer/Q2 Predictions Mean       -48.9783
trainer/Q2 Predictions Std         50.9909
trainer/Q2 Predictions Max         -9.16731
trainer/Q2 Predictions Min       -158.778
trainer/Q Targets Mean            -49.4554
trainer/Q Targets Std              51.5856
trainer/Q Targets Max              -9.10926
trainer/Q Targets Min            -157.556
trainer/Log Pis Mean                1.80458
trainer/Log Pis Std                 1.48394
trainer/Log Pis Max                 6.75472
trainer/Log Pis Min                -2.81493
trainer/Policy mu Mean              0.0922907
trainer/Policy mu Std               0.645305
trainer/Policy mu Max               2.67263
trainer/Policy mu Min              -2.26453
trainer/Policy log std Mean        -2.02223
trainer/Policy log std Std          0.520739
trainer/Policy log std Max         -0.506374
trainer/Policy log std Min         -2.67872
trainer/Alpha                       0.060775
trainer/Alpha Loss                 -0.547277
exploration/num steps total    153700
exploration/num paths total      1537
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.85962
exploration/Rewards Std             1.23434
exploration/Rewards Max            -0.00916092
exploration/Rewards Min           -10.004
exploration/Returns Mean          -85.962
exploration/Returns Std            81.0673
exploration/Returns Max           -18.7616
exploration/Returns Min          -207.489
exploration/Actions Mean           -0.00810826
exploration/Actions Std             0.233289
exploration/Actions Max             0.999423
exploration/Actions Min            -0.999904
exploration/Num Paths               5
exploration/Average Returns       -85.962
evaluation/num steps total     460500
evaluation/num paths total       4605
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.59793
evaluation/Rewards Std              1.24312
evaluation/Rewards Max             -0.0141266
evaluation/Rewards Min            -10.3396
evaluation/Returns Mean          -159.793
evaluation/Returns Std             98.3871
evaluation/Returns Max            -14.4276
evaluation/Returns Min           -295.98
evaluation/Actions Mean             0.00925108
evaluation/Actions Std              0.166223
evaluation/Actions Max              0.998855
evaluation/Actions Min             -0.999032
evaluation/Num Paths               15
evaluation/Average Returns       -159.793
time/data storing (s)               0.00273482
time/evaluation sampling (s)        0.329307
time/exploration sampling (s)       0.141108
time/logging (s)                    0.00487272
time/saving (s)                     0.00199988
time/training (s)                   1.97981
time/epoch (s)                      2.45983
time/total (s)                    752.996
Epoch                             306
-----------------------------  ---------------
2019-04-23 01:26:06.946685 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 307 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.1089
trainer/QF2 Loss                    1.16548
trainer/Policy Loss                46.0915
trainer/Q1 Predictions Mean       -44.426
trainer/Q1 Predictions Std         42.8746
trainer/Q1 Predictions Max         -9.11297
trainer/Q1 Predictions Min       -145.723
trainer/Q2 Predictions Mean       -44.3953
trainer/Q2 Predictions Std         42.8269
trainer/Q2 Predictions Max         -9.16662
trainer/Q2 Predictions Min       -145.773
trainer/Q Targets Mean            -45.1158
trainer/Q Targets Std              43.3304
trainer/Q Targets Max              -9.1225
trainer/Q Targets Min            -148.646
trainer/Log Pis Mean                1.86557
trainer/Log Pis Std                 1.54402
trainer/Log Pis Max                11.8367
trainer/Log Pis Min                -2.26138
trainer/Policy mu Mean             -0.0328201
trainer/Policy mu Std               0.750304
trainer/Policy mu Max               4.08723
trainer/Policy mu Min              -3.99436
trainer/Policy log std Mean        -2.0699
trainer/Policy log std Std          0.513204
trainer/Policy log std Max         -0.257281
trainer/Policy log std Min         -2.77677
trainer/Alpha                       0.0616678
trainer/Alpha Loss                 -0.374516
exploration/num steps total    154200
exploration/num paths total      1542
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.949305
exploration/Rewards Std             1.52325
exploration/Rewards Max            -0.0104032
exploration/Rewards Min           -10.6391
exploration/Returns Mean          -94.9305
exploration/Returns Std            98.2997
exploration/Returns Max           -18.5886
exploration/Returns Min          -286.733
exploration/Actions Mean            0.0133042
exploration/Actions Std             0.224849
exploration/Actions Max             0.999587
exploration/Actions Min            -0.996582
exploration/Num Paths               5
exploration/Average Returns       -94.9305
evaluation/num steps total     462000
evaluation/num paths total       4620
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.35804
evaluation/Rewards Std              1.19838
evaluation/Rewards Max             -0.0138694
evaluation/Rewards Min             -8.78982
evaluation/Returns Mean          -135.804
evaluation/Returns Std            107.482
evaluation/Returns Max             -8.90927
evaluation/Returns Min           -287.591
evaluation/Actions Mean            -0.0028968
evaluation/Actions Std              0.152979
evaluation/Actions Max              0.997886
evaluation/Actions Min             -0.999547
evaluation/Num Paths               15
evaluation/Average Returns       -135.804
time/data storing (s)               0.00273439
time/evaluation sampling (s)        0.325697
time/exploration sampling (s)       0.13842
time/logging (s)                    0.0047215
time/saving (s)                     0.00192529
time/training (s)                   1.96391
time/epoch (s)                      2.43741
time/total (s)                    755.438
Epoch                             307
-----------------------------  ---------------
2019-04-23 01:26:09.409321 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 308 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.39519
trainer/QF2 Loss                    0.314472
trainer/Policy Loss                50.7523
trainer/Q1 Predictions Mean       -49.0093
trainer/Q1 Predictions Std         46.431
trainer/Q1 Predictions Max         -8.94879
trainer/Q1 Predictions Min       -149.406
trainer/Q2 Predictions Mean       -49.0944
trainer/Q2 Predictions Std         46.4628
trainer/Q2 Predictions Max         -8.93795
trainer/Q2 Predictions Min       -149.675
trainer/Q Targets Mean            -49.3291
trainer/Q Targets Std              46.6534
trainer/Q Targets Max              -8.98101
trainer/Q Targets Min            -150.214
trainer/Log Pis Mean                1.99373
trainer/Log Pis Std                 1.3185
trainer/Log Pis Max                 5.92496
trainer/Log Pis Min                -4.30847
trainer/Policy mu Mean             -0.0387845
trainer/Policy mu Std               0.698622
trainer/Policy mu Max               2.62943
trainer/Policy mu Min              -2.86491
trainer/Policy log std Mean        -2.07944
trainer/Policy log std Std          0.563789
trainer/Policy log std Max         -0.4076
trainer/Policy log std Min         -2.7494
trainer/Alpha                       0.0611667
trainer/Alpha Loss                 -0.0175161
exploration/num steps total    154700
exploration/num paths total      1547
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.23105
exploration/Rewards Std             1.15584
exploration/Rewards Max            -0.00678352
exploration/Rewards Min            -7.44611
exploration/Returns Mean         -123.105
exploration/Returns Std            90.2351
exploration/Returns Max           -28.8873
exploration/Returns Min          -287.033
exploration/Actions Mean            0.0101903
exploration/Actions Std             0.219085
exploration/Actions Max             0.997941
exploration/Actions Min            -0.993605
exploration/Num Paths               5
exploration/Average Returns      -123.105
evaluation/num steps total     463500
evaluation/num paths total       4635
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.01708
evaluation/Rewards Std              1.06782
evaluation/Rewards Max             -0.0187862
evaluation/Rewards Min             -9.93975
evaluation/Returns Mean          -101.708
evaluation/Returns Std             72.711
evaluation/Returns Max             -6.90958
evaluation/Returns Min           -225.18
evaluation/Actions Mean             0.00160159
evaluation/Actions Std              0.181302
evaluation/Actions Max              0.997993
evaluation/Actions Min             -0.999667
evaluation/Num Paths               15
evaluation/Average Returns       -101.708
time/data storing (s)               0.00280358
time/evaluation sampling (s)        0.326878
time/exploration sampling (s)       0.141352
time/logging (s)                    0.00479893
time/saving (s)                     0.00193473
time/training (s)                   1.97579
time/epoch (s)                      2.45356
time/total (s)                    757.897
Epoch                             308
-----------------------------  ---------------
2019-04-23 01:26:11.855706 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 309 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.341874
trainer/QF2 Loss                    0.260728
trainer/Policy Loss                53.5346
trainer/Q1 Predictions Mean       -51.8665
trainer/Q1 Predictions Std         50.4921
trainer/Q1 Predictions Max         -9.00948
trainer/Q1 Predictions Min       -153.707
trainer/Q2 Predictions Mean       -51.8828
trainer/Q2 Predictions Std         50.5541
trainer/Q2 Predictions Max         -9.03913
trainer/Q2 Predictions Min       -156.579
trainer/Q Targets Mean            -52.0845
trainer/Q Targets Std              50.7283
trainer/Q Targets Max              -9.04981
trainer/Q Targets Min            -155.902
trainer/Log Pis Mean                2.01737
trainer/Log Pis Std                 1.16557
trainer/Log Pis Max                 5.45706
trainer/Log Pis Min                -1.88142
trainer/Policy mu Mean              0.043812
trainer/Policy mu Std               0.680798
trainer/Policy mu Max               2.53923
trainer/Policy mu Min              -2.3735
trainer/Policy log std Mean        -2.0784
trainer/Policy log std Std          0.526248
trainer/Policy log std Max         -0.517505
trainer/Policy log std Min         -2.8346
trainer/Alpha                       0.0626635
trainer/Alpha Loss                  0.0481177
exploration/num steps total    155200
exploration/num paths total      1552
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.299853
exploration/Rewards Std             0.782868
exploration/Rewards Max            -0.0139347
exploration/Rewards Min            -8.95397
exploration/Returns Mean          -29.9853
exploration/Returns Std            18.8551
exploration/Returns Max           -12.8333
exploration/Returns Min           -64.5938
exploration/Actions Mean           -0.0111742
exploration/Actions Std             0.189121
exploration/Actions Max             0.999835
exploration/Actions Min            -0.995132
exploration/Num Paths               5
exploration/Average Returns       -29.9853
evaluation/num steps total     465000
evaluation/num paths total       4650
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.04423
evaluation/Rewards Std              1.41985
evaluation/Rewards Max             -0.0128311
evaluation/Rewards Min            -10.0526
evaluation/Returns Mean          -104.423
evaluation/Returns Std            104.83
evaluation/Returns Max             -8.94843
evaluation/Returns Min           -350.025
evaluation/Actions Mean             0.00806758
evaluation/Actions Std              0.197124
evaluation/Actions Max              0.998636
evaluation/Actions Min             -0.999038
evaluation/Num Paths               15
evaluation/Average Returns       -104.423
time/data storing (s)               0.00263644
time/evaluation sampling (s)        0.33081
time/exploration sampling (s)       0.136736
time/logging (s)                    0.00486536
time/saving (s)                     0.00202831
time/training (s)                   1.96095
time/epoch (s)                      2.43803
time/total (s)                    760.338
Epoch                             309
-----------------------------  ---------------
2019-04-23 01:26:14.323460 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 310 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    2.77689
trainer/QF2 Loss                    2.52069
trainer/Policy Loss                59.719
trainer/Q1 Predictions Mean       -57.9591
trainer/Q1 Predictions Std         48.9101
trainer/Q1 Predictions Max         -8.76264
trainer/Q1 Predictions Min       -156.682
trainer/Q2 Predictions Mean       -58.0073
trainer/Q2 Predictions Std         49.0113
trainer/Q2 Predictions Max         -8.79562
trainer/Q2 Predictions Min       -159.177
trainer/Q Targets Mean            -58.5741
trainer/Q Targets Std              49.5026
trainer/Q Targets Max              -0.17053
trainer/Q Targets Min            -161.716
trainer/Log Pis Mean                2.01153
trainer/Log Pis Std                 1.10199
trainer/Log Pis Max                 5.48066
trainer/Log Pis Min                -1.9732
trainer/Policy mu Mean             -0.0483535
trainer/Policy mu Std               0.724147
trainer/Policy mu Max               1.77946
trainer/Policy mu Min              -2.9246
trainer/Policy log std Mean        -1.99988
trainer/Policy log std Std          0.548661
trainer/Policy log std Max         -0.446241
trainer/Policy log std Min         -2.82354
trainer/Alpha                       0.0636033
trainer/Alpha Loss                  0.0317652
exploration/num steps total    155700
exploration/num paths total      1557
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.980758
exploration/Rewards Std             1.1331
exploration/Rewards Max            -0.0243023
exploration/Rewards Min            -9.0901
exploration/Returns Mean          -98.0758
exploration/Returns Std            74.3241
exploration/Returns Max           -23.8203
exploration/Returns Min          -229.31
exploration/Actions Mean            0.00824971
exploration/Actions Std             0.223994
exploration/Actions Max             0.996534
exploration/Actions Min            -0.998525
exploration/Num Paths               5
exploration/Average Returns       -98.0758
evaluation/num steps total     466500
evaluation/num paths total       4665
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.972304
evaluation/Rewards Std              1.18694
evaluation/Rewards Max             -0.0385486
evaluation/Rewards Min             -9.43389
evaluation/Returns Mean           -97.2304
evaluation/Returns Std             93.7628
evaluation/Returns Max             -8.59825
evaluation/Returns Min           -293.59
evaluation/Actions Mean            -0.000939735
evaluation/Actions Std              0.164263
evaluation/Actions Max              0.998849
evaluation/Actions Min             -0.999763
evaluation/Num Paths               15
evaluation/Average Returns        -97.2304
time/data storing (s)               0.00281054
time/evaluation sampling (s)        0.332152
time/exploration sampling (s)       0.140341
time/logging (s)                    0.004774
time/saving (s)                     0.00990941
time/training (s)                   1.9684
time/epoch (s)                      2.45839
time/total (s)                    762.801
Epoch                             310
-----------------------------  ----------------
2019-04-23 01:26:16.772157 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 311 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                  213.509
trainer/QF2 Loss                  213.39
trainer/Policy Loss                55.3838
trainer/Q1 Predictions Mean       -53.7201
trainer/Q1 Predictions Std         48.6304
trainer/Q1 Predictions Max         -8.80055
trainer/Q1 Predictions Min       -151.199
trainer/Q2 Predictions Mean       -53.7314
trainer/Q2 Predictions Std         48.6398
trainer/Q2 Predictions Max         -8.71545
trainer/Q2 Predictions Min       -152.827
trainer/Q Targets Mean            -52.833
trainer/Q Targets Std              48.389
trainer/Q Targets Max              -3.24948
trainer/Q Targets Min            -154.843
trainer/Log Pis Mean                1.87987
trainer/Log Pis Std                 1.11584
trainer/Log Pis Max                 5.01185
trainer/Log Pis Min                -1.99711
trainer/Policy mu Mean             -0.00105993
trainer/Policy mu Std               0.598163
trainer/Policy mu Max               2.77841
trainer/Policy mu Min              -2.56203
trainer/Policy log std Mean        -2.11299
trainer/Policy log std Std          0.484948
trainer/Policy log std Max         -0.454009
trainer/Policy log std Min         -2.79346
trainer/Alpha                       0.0648794
trainer/Alpha Loss                 -0.3286
exploration/num steps total    156200
exploration/num paths total      1562
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.614565
exploration/Rewards Std             0.820019
exploration/Rewards Max            -0.0105385
exploration/Rewards Min            -8.8055
exploration/Returns Mean          -61.4565
exploration/Returns Std            37.0912
exploration/Returns Max           -23.5618
exploration/Returns Min          -120.805
exploration/Actions Mean            0.00966199
exploration/Actions Std             0.218358
exploration/Actions Max             0.998049
exploration/Actions Min            -0.996238
exploration/Num Paths               5
exploration/Average Returns       -61.4565
evaluation/num steps total     468000
evaluation/num paths total       4680
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.883708
evaluation/Rewards Std              1.13413
evaluation/Rewards Max             -0.0242474
evaluation/Rewards Min            -11.1843
evaluation/Returns Mean           -88.3708
evaluation/Returns Std             87.1424
evaluation/Returns Max             -8.21819
evaluation/Returns Min           -287.954
evaluation/Actions Mean             0.00297278
evaluation/Actions Std              0.166893
evaluation/Actions Max              0.997903
evaluation/Actions Min             -0.998297
evaluation/Num Paths               15
evaluation/Average Returns        -88.3708
time/data storing (s)               0.0026903
time/evaluation sampling (s)        0.327421
time/exploration sampling (s)       0.135423
time/logging (s)                    0.00480573
time/saving (s)                     0.00196605
time/training (s)                   1.96721
time/epoch (s)                      2.43952
time/total (s)                    765.246
Epoch                             311
-----------------------------  ---------------
2019-04-23 01:26:19.245239 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 312 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    5.77493
trainer/QF2 Loss                    5.70272
trainer/Policy Loss                50.6072
trainer/Q1 Predictions Mean       -48.7565
trainer/Q1 Predictions Std         46.3326
trainer/Q1 Predictions Max         -8.77119
trainer/Q1 Predictions Min       -156.409
trainer/Q2 Predictions Mean       -48.7941
trainer/Q2 Predictions Std         46.3899
trainer/Q2 Predictions Max         -8.70869
trainer/Q2 Predictions Min       -156.558
trainer/Q Targets Mean            -48.6171
trainer/Q Targets Std              46.564
trainer/Q Targets Max              -0.836819
trainer/Q Targets Min            -155.833
trainer/Log Pis Mean                2.09478
trainer/Log Pis Std                 1.51383
trainer/Log Pis Max                 6.12789
trainer/Log Pis Min                -2.53512
trainer/Policy mu Mean             -0.00119438
trainer/Policy mu Std               0.909126
trainer/Policy mu Max               3.20214
trainer/Policy mu Min              -3.8841
trainer/Policy log std Mean        -1.94998
trainer/Policy log std Std          0.582366
trainer/Policy log std Max         -0.199518
trainer/Policy log std Min         -2.66147
trainer/Alpha                       0.0646052
trainer/Alpha Loss                  0.259638
exploration/num steps total    156700
exploration/num paths total      1567
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.613477
exploration/Rewards Std             0.583316
exploration/Rewards Max            -0.00704856
exploration/Rewards Min            -6.30861
exploration/Returns Mean          -61.3477
exploration/Returns Std            31.028
exploration/Returns Max           -14.0438
exploration/Returns Min           -98.4482
exploration/Actions Mean           -0.0046301
exploration/Actions Std             0.197314
exploration/Actions Max             0.99917
exploration/Actions Min            -0.995899
exploration/Num Paths               5
exploration/Average Returns       -61.3477
evaluation/num steps total     469500
evaluation/num paths total       4695
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.23579
evaluation/Rewards Std              1.2477
evaluation/Rewards Max             -0.0419911
evaluation/Rewards Min            -10.3356
evaluation/Returns Mean          -123.579
evaluation/Returns Std             88.8458
evaluation/Returns Max            -27.0143
evaluation/Returns Min           -318.94
evaluation/Actions Mean             0.00710132
evaluation/Actions Std              0.187071
evaluation/Actions Max              0.999512
evaluation/Actions Min             -0.999119
evaluation/Num Paths               15
evaluation/Average Returns       -123.579
time/data storing (s)               0.00264959
time/evaluation sampling (s)        0.330178
time/exploration sampling (s)       0.136846
time/logging (s)                    0.0047119
time/saving (s)                     0.00194577
time/training (s)                   1.9875
time/epoch (s)                      2.46384
time/total (s)                    767.714
Epoch                             312
-----------------------------  ---------------
2019-04-23 01:26:21.707338 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 313 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    2.73137
trainer/QF2 Loss                    2.71108
trainer/Policy Loss                50.4483
trainer/Q1 Predictions Mean       -48.8682
trainer/Q1 Predictions Std         46.7941
trainer/Q1 Predictions Max         -8.45538
trainer/Q1 Predictions Min       -150.289
trainer/Q2 Predictions Mean       -48.8404
trainer/Q2 Predictions Std         46.8095
trainer/Q2 Predictions Max         -8.52418
trainer/Q2 Predictions Min       -149.943
trainer/Q Targets Mean            -49.093
trainer/Q Targets Std              47.3912
trainer/Q Targets Max              -0.0474868
trainer/Q Targets Min            -151.623
trainer/Log Pis Mean                1.96424
trainer/Log Pis Std                 1.42187
trainer/Log Pis Max                 6.95717
trainer/Log Pis Min                -3.17789
trainer/Policy mu Mean             -0.15957
trainer/Policy mu Std               0.724383
trainer/Policy mu Max               2.56153
trainer/Policy mu Min              -2.76292
trainer/Policy log std Mean        -2.03317
trainer/Policy log std Std          0.548735
trainer/Policy log std Max         -0.318652
trainer/Policy log std Min         -2.82725
trainer/Alpha                       0.0630681
trainer/Alpha Loss                 -0.098822
exploration/num steps total    157200
exploration/num paths total      1572
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.08127
exploration/Rewards Std             1.32232
exploration/Rewards Max            -0.000142869
exploration/Rewards Min           -10.4904
exploration/Returns Mean         -108.127
exploration/Returns Std            91.427
exploration/Returns Max           -25.356
exploration/Returns Min          -271.219
exploration/Actions Mean            0.000784549
exploration/Actions Std             0.252941
exploration/Actions Max             0.998031
exploration/Actions Min            -0.989602
exploration/Num Paths               5
exploration/Average Returns      -108.127
evaluation/num steps total     471000
evaluation/num paths total       4710
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.949105
evaluation/Rewards Std              1.17442
evaluation/Rewards Max             -0.0326686
evaluation/Rewards Min             -9.80743
evaluation/Returns Mean           -94.9105
evaluation/Returns Std             82.9116
evaluation/Returns Max            -10.4684
evaluation/Returns Min           -284.45
evaluation/Actions Mean             0.0156741
evaluation/Actions Std              0.163244
evaluation/Actions Max              0.999236
evaluation/Actions Min             -0.997795
evaluation/Num Paths               15
evaluation/Average Returns        -94.9105
time/data storing (s)               0.00270465
time/evaluation sampling (s)        0.3301
time/exploration sampling (s)       0.136469
time/logging (s)                    0.00471414
time/saving (s)                     0.00190184
time/training (s)                   1.97709
time/epoch (s)                      2.45298
time/total (s)                    770.171
Epoch                             313
-----------------------------  ----------------
2019-04-23 01:26:24.160105 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 314 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.393193
trainer/QF2 Loss                    0.505748
trainer/Policy Loss                53.7226
trainer/Q1 Predictions Mean       -52.1148
trainer/Q1 Predictions Std         51.329
trainer/Q1 Predictions Max         -8.68436
trainer/Q1 Predictions Min       -155.294
trainer/Q2 Predictions Mean       -52.1001
trainer/Q2 Predictions Std         51.3401
trainer/Q2 Predictions Max         -8.76751
trainer/Q2 Predictions Min       -154.779
trainer/Q Targets Mean            -52.3805
trainer/Q Targets Std              51.5764
trainer/Q Targets Max              -8.6892
trainer/Q Targets Min            -157.284
trainer/Log Pis Mean                1.92754
trainer/Log Pis Std                 1.34711
trainer/Log Pis Max                 5.94001
trainer/Log Pis Min                -2.54993
trainer/Policy mu Mean             -0.0315152
trainer/Policy mu Std               0.654888
trainer/Policy mu Max               2.83611
trainer/Policy mu Min              -3.12981
trainer/Policy log std Mean        -2.10436
trainer/Policy log std Std          0.488361
trainer/Policy log std Max         -0.561178
trainer/Policy log std Min         -2.90667
trainer/Alpha                       0.0637759
trainer/Alpha Loss                 -0.199451
exploration/num steps total    157700
exploration/num paths total      1577
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.54401
exploration/Rewards Std             1.08157
exploration/Rewards Max            -0.347639
exploration/Rewards Min            -9.553
exploration/Returns Mean         -154.401
exploration/Returns Std            82.9953
exploration/Returns Max           -83.9404
exploration/Returns Min          -314.998
exploration/Actions Mean           -0.0164804
exploration/Actions Std             0.23023
exploration/Actions Max             0.999474
exploration/Actions Min            -0.997462
exploration/Num Paths               5
exploration/Average Returns      -154.401
evaluation/num steps total     472500
evaluation/num paths total       4725
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.54604
evaluation/Rewards Std              1.21588
evaluation/Rewards Max             -0.0500932
evaluation/Rewards Min             -7.51741
evaluation/Returns Mean          -154.604
evaluation/Returns Std            110.085
evaluation/Returns Max             -7.73202
evaluation/Returns Min           -305.37
evaluation/Actions Mean            -0.00341082
evaluation/Actions Std              0.163243
evaluation/Actions Max              0.996849
evaluation/Actions Min             -0.996255
evaluation/Num Paths               15
evaluation/Average Returns       -154.604
time/data storing (s)               0.00273164
time/evaluation sampling (s)        0.328957
time/exploration sampling (s)       0.139765
time/logging (s)                    0.00471194
time/saving (s)                     0.00195089
time/training (s)                   1.96707
time/epoch (s)                      2.44518
time/total (s)                    772.62
Epoch                             314
-----------------------------  ---------------
2019-04-23 01:26:26.637099 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 315 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    7.55242
trainer/QF2 Loss                    7.57418
trainer/Policy Loss                58.0964
trainer/Q1 Predictions Mean       -56.63
trainer/Q1 Predictions Std         50.4784
trainer/Q1 Predictions Max         -8.79151
trainer/Q1 Predictions Min       -152.562
trainer/Q2 Predictions Mean       -56.5739
trainer/Q2 Predictions Std         50.4763
trainer/Q2 Predictions Max         -8.76382
trainer/Q2 Predictions Min       -152.785
trainer/Q Targets Mean            -57.1525
trainer/Q Targets Std              51.3572
trainer/Q Targets Max              -1.54361
trainer/Q Targets Min            -154.49
trainer/Log Pis Mean                1.83058
trainer/Log Pis Std                 1.41155
trainer/Log Pis Max                 6.95105
trainer/Log Pis Min                -2.78771
trainer/Policy mu Mean             -0.0919222
trainer/Policy mu Std               0.743461
trainer/Policy mu Max               3.20432
trainer/Policy mu Min              -3.02846
trainer/Policy log std Mean        -1.96317
trainer/Policy log std Std          0.567535
trainer/Policy log std Max         -0.533726
trainer/Policy log std Min         -2.87807
trainer/Alpha                       0.0653663
trainer/Alpha Loss                 -0.462132
exploration/num steps total    158200
exploration/num paths total      1582
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.624201
exploration/Rewards Std             1.28176
exploration/Rewards Max            -0.00757232
exploration/Rewards Min           -11.4664
exploration/Returns Mean          -62.4201
exploration/Returns Std            24.6716
exploration/Returns Max           -36.6594
exploration/Returns Min          -105.375
exploration/Actions Mean           -0.0263186
exploration/Actions Std             0.244704
exploration/Actions Max             0.983003
exploration/Actions Min            -0.999807
exploration/Num Paths               5
exploration/Average Returns       -62.4201
evaluation/num steps total     474000
evaluation/num paths total       4740
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.21437
evaluation/Rewards Std              1.30694
evaluation/Rewards Max             -0.0285094
evaluation/Rewards Min            -10.7741
evaluation/Returns Mean          -121.437
evaluation/Returns Std            101.567
evaluation/Returns Max             -9.86083
evaluation/Returns Min           -291.065
evaluation/Actions Mean             0.0100368
evaluation/Actions Std              0.16944
evaluation/Actions Max              0.999005
evaluation/Actions Min             -0.996186
evaluation/Num Paths               15
evaluation/Average Returns       -121.437
time/data storing (s)               0.00279561
time/evaluation sampling (s)        0.326001
time/exploration sampling (s)       0.140733
time/logging (s)                    0.00478266
time/saving (s)                     0.00162032
time/training (s)                   1.99194
time/epoch (s)                      2.46787
time/total (s)                    775.093
Epoch                             315
-----------------------------  ---------------
2019-04-23 01:26:29.117691 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 316 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    3.4519
trainer/QF2 Loss                    3.45473
trainer/Policy Loss                52.3583
trainer/Q1 Predictions Mean       -50.5663
trainer/Q1 Predictions Std         49.067
trainer/Q1 Predictions Max         -8.47432
trainer/Q1 Predictions Min       -155.571
trainer/Q2 Predictions Mean       -50.5404
trainer/Q2 Predictions Std         49.1019
trainer/Q2 Predictions Max         -8.42197
trainer/Q2 Predictions Min       -156.439
trainer/Q Targets Mean            -51.517
trainer/Q Targets Std              50.1287
trainer/Q Targets Max              -0.299855
trainer/Q Targets Min            -159.061
trainer/Log Pis Mean                2.15829
trainer/Log Pis Std                 1.14891
trainer/Log Pis Max                 6.32929
trainer/Log Pis Min                -0.588873
trainer/Policy mu Mean             -0.0982949
trainer/Policy mu Std               0.694505
trainer/Policy mu Max               2.55832
trainer/Policy mu Min              -3.08417
trainer/Policy log std Mean        -2.08246
trainer/Policy log std Std          0.525364
trainer/Policy log std Max         -0.3627
trainer/Policy log std Min         -2.79686
trainer/Alpha                       0.0651404
trainer/Alpha Loss                  0.432322
exploration/num steps total    158700
exploration/num paths total      1587
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.83026
exploration/Rewards Std             1.0165
exploration/Rewards Max            -0.0166535
exploration/Rewards Min            -7.67261
exploration/Returns Mean          -83.026
exploration/Returns Std            81.9529
exploration/Returns Max           -18.1137
exploration/Returns Min          -239.766
exploration/Actions Mean           -0.0175104
exploration/Actions Std             0.22291
exploration/Actions Max             0.971736
exploration/Actions Min            -0.995413
exploration/Num Paths               5
exploration/Average Returns       -83.026
evaluation/num steps total     475500
evaluation/num paths total       4755
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.764509
evaluation/Rewards Std              1.08698
evaluation/Rewards Max             -0.0306985
evaluation/Rewards Min             -9.9066
evaluation/Returns Mean           -76.4509
evaluation/Returns Std             83.6878
evaluation/Returns Max             -5.73931
evaluation/Returns Min           -304.276
evaluation/Actions Mean            -0.00440553
evaluation/Actions Std              0.164662
evaluation/Actions Max              0.999379
evaluation/Actions Min             -0.997843
evaluation/Num Paths               15
evaluation/Average Returns        -76.4509
time/data storing (s)               0.00274465
time/evaluation sampling (s)        0.32748
time/exploration sampling (s)       0.139624
time/logging (s)                    0.00473703
time/saving (s)                     0.00179376
time/training (s)                   1.99452
time/epoch (s)                      2.4709
time/total (s)                    777.568
Epoch                             316
-----------------------------  ---------------
2019-04-23 01:26:31.592562 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 317 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                  246.899
trainer/QF2 Loss                  245.927
trainer/Policy Loss                50.9379
trainer/Q1 Predictions Mean       -48.9502
trainer/Q1 Predictions Std         46.6139
trainer/Q1 Predictions Max         -8.68897
trainer/Q1 Predictions Min       -153.795
trainer/Q2 Predictions Mean       -48.9417
trainer/Q2 Predictions Std         46.6751
trainer/Q2 Predictions Max         -8.59084
trainer/Q2 Predictions Min       -155.703
trainer/Q Targets Mean            -46.8723
trainer/Q Targets Std              46.8639
trainer/Q Targets Max              -0.196118
trainer/Q Targets Min            -156.084
trainer/Log Pis Mean                2.25111
trainer/Log Pis Std                 1.13487
trainer/Log Pis Max                 7.11932
trainer/Log Pis Min                -0.667822
trainer/Policy mu Mean              0.0104717
trainer/Policy mu Std               0.590677
trainer/Policy mu Max               3.03552
trainer/Policy mu Min              -2.97627
trainer/Policy log std Mean        -2.17338
trainer/Policy log std Std          0.439186
trainer/Policy log std Max         -0.593447
trainer/Policy log std Min         -2.90904
trainer/Alpha                       0.0679305
trainer/Alpha Loss                  0.675321
exploration/num steps total    159200
exploration/num paths total      1592
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.14612
exploration/Rewards Std             0.931291
exploration/Rewards Max            -0.0162587
exploration/Rewards Min            -8.29371
exploration/Returns Mean         -114.612
exploration/Returns Std            50.4173
exploration/Returns Max           -35.4401
exploration/Returns Min          -181.742
exploration/Actions Mean            0.0254878
exploration/Actions Std             0.201597
exploration/Actions Max             0.999788
exploration/Actions Min            -0.919994
exploration/Num Paths               5
exploration/Average Returns      -114.612
evaluation/num steps total     477000
evaluation/num paths total       4770
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.18004
evaluation/Rewards Std              1.43927
evaluation/Rewards Max             -0.0255119
evaluation/Rewards Min            -10.2686
evaluation/Returns Mean          -118.004
evaluation/Returns Std            114.701
evaluation/Returns Max             -3.18997
evaluation/Returns Min           -309.832
evaluation/Actions Mean             0.0107631
evaluation/Actions Std              0.183707
evaluation/Actions Max              0.999507
evaluation/Actions Min             -0.997553
evaluation/Num Paths               15
evaluation/Average Returns       -118.004
time/data storing (s)               0.00262201
time/evaluation sampling (s)        0.327238
time/exploration sampling (s)       0.138667
time/logging (s)                    0.00449559
time/saving (s)                     0.00153631
time/training (s)                   1.99079
time/epoch (s)                      2.46535
time/total (s)                    780.038
Epoch                             317
-----------------------------  ---------------
2019-04-23 01:26:34.049915 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 318 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.598524
trainer/QF2 Loss                    0.46133
trainer/Policy Loss                52.8841
trainer/Q1 Predictions Mean       -51.2918
trainer/Q1 Predictions Std         51.5117
trainer/Q1 Predictions Max         -8.49177
trainer/Q1 Predictions Min       -161.386
trainer/Q2 Predictions Mean       -51.2956
trainer/Q2 Predictions Std         51.5606
trainer/Q2 Predictions Max         -8.54114
trainer/Q2 Predictions Min       -161.138
trainer/Q Targets Mean            -51.5814
trainer/Q Targets Std              51.8561
trainer/Q Targets Max              -8.58027
trainer/Q Targets Min            -160.32
trainer/Log Pis Mean                1.91155
trainer/Log Pis Std                 1.30969
trainer/Log Pis Max                 5.26778
trainer/Log Pis Min                -2.5339
trainer/Policy mu Mean             -0.0553731
trainer/Policy mu Std               0.644835
trainer/Policy mu Max               2.54607
trainer/Policy mu Min              -2.38497
trainer/Policy log std Mean        -2.09381
trainer/Policy log std Std          0.494816
trainer/Policy log std Max         -0.639225
trainer/Policy log std Min         -2.77884
trainer/Alpha                       0.0688196
trainer/Alpha Loss                 -0.236687
exploration/num steps total    159700
exploration/num paths total      1597
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.04416
exploration/Rewards Std             1.3834
exploration/Rewards Max            -0.015677
exploration/Rewards Min           -11.3577
exploration/Returns Mean         -104.416
exploration/Returns Std            82.3319
exploration/Returns Max           -33.8385
exploration/Returns Min          -260.671
exploration/Actions Mean           -0.0194542
exploration/Actions Std             0.250502
exploration/Actions Max             0.999318
exploration/Actions Min            -0.999955
exploration/Num Paths               5
exploration/Average Returns      -104.416
evaluation/num steps total     478500
evaluation/num paths total       4785
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.637821
evaluation/Rewards Std              1.40367
evaluation/Rewards Max             -0.0270089
evaluation/Rewards Min            -11.3723
evaluation/Returns Mean           -63.7821
evaluation/Returns Std             68.183
evaluation/Returns Max            -14.3316
evaluation/Returns Min           -290.214
evaluation/Actions Mean             0.0197967
evaluation/Actions Std              0.211037
evaluation/Actions Max              0.999652
evaluation/Actions Min             -0.99821
evaluation/Num Paths               15
evaluation/Average Returns        -63.7821
time/data storing (s)               0.00279288
time/evaluation sampling (s)        0.330777
time/exploration sampling (s)       0.139878
time/logging (s)                    0.00375603
time/saving (s)                     0.00192798
time/training (s)                   1.96822
time/epoch (s)                      2.44736
time/total (s)                    782.49
Epoch                             318
-----------------------------  ---------------
2019-04-23 01:26:36.502226 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 319 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   15.7131
trainer/QF2 Loss                   15.4654
trainer/Policy Loss                60.7025
trainer/Q1 Predictions Mean       -59.2535
trainer/Q1 Predictions Std         46.6153
trainer/Q1 Predictions Max         -8.62111
trainer/Q1 Predictions Min       -158.383
trainer/Q2 Predictions Mean       -59.2932
trainer/Q2 Predictions Std         46.6334
trainer/Q2 Predictions Max         -8.56367
trainer/Q2 Predictions Min       -158.809
trainer/Q Targets Mean            -59.7375
trainer/Q Targets Std              47.672
trainer/Q Targets Max              -0.697817
trainer/Q Targets Min            -161.587
trainer/Log Pis Mean                2.07563
trainer/Log Pis Std                 1.33376
trainer/Log Pis Max                 6.3575
trainer/Log Pis Min                -3.17211
trainer/Policy mu Mean             -0.0287905
trainer/Policy mu Std               0.824061
trainer/Policy mu Max               3.05102
trainer/Policy mu Min              -2.72848
trainer/Policy log std Mean        -1.96202
trainer/Policy log std Std          0.550581
trainer/Policy log std Max         -0.33479
trainer/Policy log std Min         -2.74906
trainer/Alpha                       0.0682679
trainer/Alpha Loss                  0.20303
exploration/num steps total    160200
exploration/num paths total      1602
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.703
exploration/Rewards Std             1.00724
exploration/Rewards Max            -0.00293752
exploration/Rewards Min            -7.90727
exploration/Returns Mean          -70.3
exploration/Returns Std            68.7806
exploration/Returns Max           -18.1943
exploration/Returns Min          -205.857
exploration/Actions Mean           -0.00566146
exploration/Actions Std             0.212391
exploration/Actions Max             0.999968
exploration/Actions Min            -0.999968
exploration/Num Paths               5
exploration/Average Returns       -70.3
evaluation/num steps total     480000
evaluation/num paths total       4800
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.98934
evaluation/Rewards Std              1.41266
evaluation/Rewards Max             -0.00131567
evaluation/Rewards Min            -10.2633
evaluation/Returns Mean           -98.934
evaluation/Returns Std            106.736
evaluation/Returns Max            -15.86
evaluation/Returns Min           -336.596
evaluation/Actions Mean            -0.0028184
evaluation/Actions Std              0.184362
evaluation/Actions Max              0.998624
evaluation/Actions Min             -0.997908
evaluation/Num Paths               15
evaluation/Average Returns        -98.934
time/data storing (s)               0.00260014
time/evaluation sampling (s)        0.332093
time/exploration sampling (s)       0.138379
time/logging (s)                    0.00475172
time/saving (s)                     0.00193609
time/training (s)                   1.96392
time/epoch (s)                      2.44368
time/total (s)                    784.939
Epoch                             319
-----------------------------  ---------------
2019-04-23 01:26:38.953750 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 320 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.949439
trainer/QF2 Loss                    0.882246
trainer/Policy Loss                50.2317
trainer/Q1 Predictions Mean       -48.801
trainer/Q1 Predictions Std         47.9676
trainer/Q1 Predictions Max         -8.78085
trainer/Q1 Predictions Min       -156.049
trainer/Q2 Predictions Mean       -48.8089
trainer/Q2 Predictions Std         47.9992
trainer/Q2 Predictions Max         -8.78413
trainer/Q2 Predictions Min       -158.237
trainer/Q Targets Mean            -49.3412
trainer/Q Targets Std              48.4935
trainer/Q Targets Max              -8.57818
trainer/Q Targets Min            -158.313
trainer/Log Pis Mean                1.79843
trainer/Log Pis Std                 1.30031
trainer/Log Pis Max                 5.10232
trainer/Log Pis Min                -2.52988
trainer/Policy mu Mean              0.00250155
trainer/Policy mu Std               0.602495
trainer/Policy mu Max               1.66619
trainer/Policy mu Min              -2.07119
trainer/Policy log std Mean        -2.10057
trainer/Policy log std Std          0.48118
trainer/Policy log std Max         -0.665336
trainer/Policy log std Min         -2.65864
trainer/Alpha                       0.0686603
trainer/Alpha Loss                 -0.53992
exploration/num steps total    160700
exploration/num paths total      1607
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.652667
exploration/Rewards Std             1.0431
exploration/Rewards Max            -0.0144696
exploration/Rewards Min           -10.0761
exploration/Returns Mean          -65.2667
exploration/Returns Std            33.01
exploration/Returns Max           -25.6423
exploration/Returns Min          -124.431
exploration/Actions Mean            0.00459624
exploration/Actions Std             0.201105
exploration/Actions Max             0.998615
exploration/Actions Min            -0.999879
exploration/Num Paths               5
exploration/Average Returns       -65.2667
evaluation/num steps total     481500
evaluation/num paths total       4815
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.36116
evaluation/Rewards Std              1.23123
evaluation/Rewards Max             -0.0314041
evaluation/Rewards Min             -9.26849
evaluation/Returns Mean          -136.116
evaluation/Returns Std             92.7124
evaluation/Returns Max            -15.0988
evaluation/Returns Min           -304.94
evaluation/Actions Mean             0.00525989
evaluation/Actions Std              0.17862
evaluation/Actions Max              0.999056
evaluation/Actions Min             -0.998289
evaluation/Num Paths               15
evaluation/Average Returns       -136.116
time/data storing (s)               0.00259508
time/evaluation sampling (s)        0.327352
time/exploration sampling (s)       0.139653
time/logging (s)                    0.00476083
time/saving (s)                     0.00181823
time/training (s)                   1.96604
time/epoch (s)                      2.44222
time/total (s)                    787.386
Epoch                             320
-----------------------------  ---------------
2019-04-23 01:26:41.393500 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 321 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    2.19252
trainer/QF2 Loss                    2.17027
trainer/Policy Loss                55.5541
trainer/Q1 Predictions Mean       -53.6928
trainer/Q1 Predictions Std         49.786
trainer/Q1 Predictions Max         -8.6175
trainer/Q1 Predictions Min       -156.687
trainer/Q2 Predictions Mean       -53.6949
trainer/Q2 Predictions Std         49.8005
trainer/Q2 Predictions Max         -8.58396
trainer/Q2 Predictions Min       -157.746
trainer/Q Targets Mean            -54.0997
trainer/Q Targets Std              50.3742
trainer/Q Targets Max              -0.205661
trainer/Q Targets Min            -160.088
trainer/Log Pis Mean                2.2368
trainer/Log Pis Std                 1.11826
trainer/Log Pis Max                 6.46077
trainer/Log Pis Min                -2.67863
trainer/Policy mu Mean              0.113452
trainer/Policy mu Std               0.804064
trainer/Policy mu Max               3.28457
trainer/Policy mu Min              -3.01489
trainer/Policy log std Mean        -1.9809
trainer/Policy log std Std          0.546286
trainer/Policy log std Max         -0.427736
trainer/Policy log std Min         -2.80333
trainer/Alpha                       0.0668407
trainer/Alpha Loss                  0.640667
exploration/num steps total    161200
exploration/num paths total      1612
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.79808
exploration/Rewards Std             1.40721
exploration/Rewards Max            -0.0401583
exploration/Rewards Min            -9.2719
exploration/Returns Mean         -179.808
exploration/Returns Std            85.2412
exploration/Returns Max           -74.0089
exploration/Returns Min          -316.804
exploration/Actions Mean            0.00126094
exploration/Actions Std             0.259441
exploration/Actions Max             0.999447
exploration/Actions Min            -0.999804
exploration/Num Paths               5
exploration/Average Returns      -179.808
evaluation/num steps total     483000
evaluation/num paths total       4830
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.4577
evaluation/Rewards Std              1.35225
evaluation/Rewards Max             -0.0645993
evaluation/Rewards Min             -9.66221
evaluation/Returns Mean          -145.77
evaluation/Returns Std             96.6744
evaluation/Returns Max            -21.8021
evaluation/Returns Min           -318.543
evaluation/Actions Mean            -0.00200929
evaluation/Actions Std              0.187525
evaluation/Actions Max              0.999562
evaluation/Actions Min             -0.996455
evaluation/Num Paths               15
evaluation/Average Returns       -145.77
time/data storing (s)               0.00258036
time/evaluation sampling (s)        0.329436
time/exploration sampling (s)       0.135844
time/logging (s)                    0.00473214
time/saving (s)                     0.00194256
time/training (s)                   1.95668
time/epoch (s)                      2.43121
time/total (s)                    789.821
Epoch                             321
-----------------------------  ---------------
2019-04-23 01:26:43.887545 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 322 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   17.5838
trainer/QF2 Loss                   17.3754
trainer/Policy Loss                54.6216
trainer/Q1 Predictions Mean       -52.9732
trainer/Q1 Predictions Std         49.0136
trainer/Q1 Predictions Max         -8.4263
trainer/Q1 Predictions Min       -161.929
trainer/Q2 Predictions Mean       -53.0256
trainer/Q2 Predictions Std         49.1054
trainer/Q2 Predictions Max         -8.38501
trainer/Q2 Predictions Min       -165.445
trainer/Q Targets Mean            -53.0029
trainer/Q Targets Std              50.0337
trainer/Q Targets Max              -0.044453
trainer/Q Targets Min            -164.722
trainer/Log Pis Mean                2.05819
trainer/Log Pis Std                 1.15662
trainer/Log Pis Max                 5.23033
trainer/Log Pis Min                -1.33048
trainer/Policy mu Mean             -0.105057
trainer/Policy mu Std               0.789384
trainer/Policy mu Max               2.64764
trainer/Policy mu Min              -2.7161
trainer/Policy log std Mean        -1.99222
trainer/Policy log std Std          0.52702
trainer/Policy log std Max         -0.587206
trainer/Policy log std Min         -2.72585
trainer/Alpha                       0.0667777
trainer/Alpha Loss                  0.157493
exploration/num steps total    161700
exploration/num paths total      1617
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.30775
exploration/Rewards Std             0.949173
exploration/Rewards Max            -0.0105383
exploration/Rewards Min            -8.59308
exploration/Returns Mean         -130.775
exploration/Returns Std            52.7776
exploration/Returns Max           -32.407
exploration/Returns Min          -188.241
exploration/Actions Mean            0.0177785
exploration/Actions Std             0.205423
exploration/Actions Max             0.99963
exploration/Actions Min            -0.995397
exploration/Num Paths               5
exploration/Average Returns      -130.775
evaluation/num steps total     484500
evaluation/num paths total       4845
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.32896
evaluation/Rewards Std              1.42593
evaluation/Rewards Max             -0.00662681
evaluation/Rewards Min            -12.0558
evaluation/Returns Mean          -132.896
evaluation/Returns Std             91.2078
evaluation/Returns Max            -16.7084
evaluation/Returns Min           -299.392
evaluation/Actions Mean             0.0137117
evaluation/Actions Std              0.209642
evaluation/Actions Max              0.999598
evaluation/Actions Min             -0.999624
evaluation/Num Paths               15
evaluation/Average Returns       -132.896
time/data storing (s)               0.00373688
time/evaluation sampling (s)        0.330043
time/exploration sampling (s)       0.160043
time/logging (s)                    0.00475725
time/saving (s)                     0.0102208
time/training (s)                   1.97584
time/epoch (s)                      2.48464
time/total (s)                    792.31
Epoch                             322
-----------------------------  ---------------
2019-04-23 01:26:46.365662 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 323 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                  107.523
trainer/QF2 Loss                  107.743
trainer/Policy Loss                47.8827
trainer/Q1 Predictions Mean       -46.0901
trainer/Q1 Predictions Std         47.2672
trainer/Q1 Predictions Max         -8.29185
trainer/Q1 Predictions Min       -156.669
trainer/Q2 Predictions Mean       -46.079
trainer/Q2 Predictions Std         47.2803
trainer/Q2 Predictions Max         -8.34938
trainer/Q2 Predictions Min       -155.657
trainer/Q Targets Mean            -45.013
trainer/Q Targets Std              47.4217
trainer/Q Targets Max              -0.983035
trainer/Q Targets Min            -157.434
trainer/Log Pis Mean                2.17254
trainer/Log Pis Std                 1.26878
trainer/Log Pis Max                 5.85028
trainer/Log Pis Min                -2.3172
trainer/Policy mu Mean             -0.10055
trainer/Policy mu Std               0.709749
trainer/Policy mu Max               2.3045
trainer/Policy mu Min              -3.20824
trainer/Policy log std Mean        -2.08719
trainer/Policy log std Std          0.481127
trainer/Policy log std Max         -0.446223
trainer/Policy log std Min         -2.72505
trainer/Alpha                       0.067122
trainer/Alpha Loss                  0.466074
exploration/num steps total    162200
exploration/num paths total      1622
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.26788
exploration/Rewards Std             1.1339
exploration/Rewards Max            -0.00627744
exploration/Rewards Min            -7.58438
exploration/Returns Mean         -126.788
exploration/Returns Std            84.6364
exploration/Returns Max           -29.3874
exploration/Returns Min          -240.745
exploration/Actions Mean           -0.019182
exploration/Actions Std             0.221932
exploration/Actions Max             0.998248
exploration/Actions Min            -0.998676
exploration/Num Paths               5
exploration/Average Returns      -126.788
evaluation/num steps total     486000
evaluation/num paths total       4860
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.969103
evaluation/Rewards Std              1.22249
evaluation/Rewards Max             -0.0130573
evaluation/Rewards Min            -11.9004
evaluation/Returns Mean           -96.9103
evaluation/Returns Std             94.2615
evaluation/Returns Max             -1.8389
evaluation/Returns Min           -275.111
evaluation/Actions Mean             0.0132495
evaluation/Actions Std              0.180668
evaluation/Actions Max              0.999556
evaluation/Actions Min             -0.998582
evaluation/Num Paths               15
evaluation/Average Returns        -96.9103
time/data storing (s)               0.00277178
time/evaluation sampling (s)        0.328453
time/exploration sampling (s)       0.135454
time/logging (s)                    0.00477567
time/saving (s)                     0.00197303
time/training (s)                   1.99532
time/epoch (s)                      2.46875
time/total (s)                    794.783
Epoch                             323
-----------------------------  ---------------
2019-04-23 01:26:48.809394 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 324 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    6.37953
trainer/QF2 Loss                    5.9713
trainer/Policy Loss                54.2348
trainer/Q1 Predictions Mean       -52.5172
trainer/Q1 Predictions Std         50.9696
trainer/Q1 Predictions Max         -8.5446
trainer/Q1 Predictions Min       -163.364
trainer/Q2 Predictions Mean       -52.5536
trainer/Q2 Predictions Std         51.0802
trainer/Q2 Predictions Max         -8.53175
trainer/Q2 Predictions Min       -166.816
trainer/Q Targets Mean            -52.6743
trainer/Q Targets Std              51.7089
trainer/Q Targets Max              -0.142142
trainer/Q Targets Min            -167.376
trainer/Log Pis Mean                2.00589
trainer/Log Pis Std                 1.36897
trainer/Log Pis Max                 7.51667
trainer/Log Pis Min                -1.80265
trainer/Policy mu Mean             -0.175426
trainer/Policy mu Std               0.76915
trainer/Policy mu Max               2.68772
trainer/Policy mu Min              -3.23413
trainer/Policy log std Mean        -2.00144
trainer/Policy log std Std          0.551314
trainer/Policy log std Max         -0.103421
trainer/Policy log std Min         -2.69355
trainer/Alpha                       0.0661256
trainer/Alpha Loss                  0.0160034
exploration/num steps total    162700
exploration/num paths total      1627
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.995724
exploration/Rewards Std             1.26052
exploration/Rewards Max            -0.0136065
exploration/Rewards Min            -9.07674
exploration/Returns Mean          -99.5724
exploration/Returns Std            88.7817
exploration/Returns Max           -18.9445
exploration/Returns Min          -261.744
exploration/Actions Mean           -0.00137816
exploration/Actions Std             0.243745
exploration/Actions Max             0.998547
exploration/Actions Min            -0.998741
exploration/Num Paths               5
exploration/Average Returns       -99.5724
evaluation/num steps total     487500
evaluation/num paths total       4875
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.745395
evaluation/Rewards Std              1.08802
evaluation/Rewards Max             -0.0152983
evaluation/Rewards Min             -9.19191
evaluation/Returns Mean           -74.5395
evaluation/Returns Std             90.8834
evaluation/Returns Max             -3.15011
evaluation/Returns Min           -277.722
evaluation/Actions Mean            -0.00308407
evaluation/Actions Std              0.155246
evaluation/Actions Max              0.997286
evaluation/Actions Min             -0.996274
evaluation/Num Paths               15
evaluation/Average Returns        -74.5395
time/data storing (s)               0.00274701
time/evaluation sampling (s)        0.333773
time/exploration sampling (s)       0.138561
time/logging (s)                    0.00473219
time/saving (s)                     0.00196041
time/training (s)                   1.95261
time/epoch (s)                      2.43439
time/total (s)                    797.222
Epoch                             324
-----------------------------  ---------------
2019-04-23 01:26:51.285975 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 325 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                  425.363
trainer/QF2 Loss                  425.859
trainer/Policy Loss                55.3594
trainer/Q1 Predictions Mean       -53.8723
trainer/Q1 Predictions Std         48.6861
trainer/Q1 Predictions Max         -8.74057
trainer/Q1 Predictions Min       -160.09
trainer/Q2 Predictions Mean       -53.8752
trainer/Q2 Predictions Std         48.8184
trainer/Q2 Predictions Max         -8.72915
trainer/Q2 Predictions Min       -164.579
trainer/Q Targets Mean            -49.9721
trainer/Q Targets Std              48.4756
trainer/Q Targets Max              -0.213132
trainer/Q Targets Min            -163.416
trainer/Log Pis Mean                1.88949
trainer/Log Pis Std                 1.27192
trainer/Log Pis Max                 6.62159
trainer/Log Pis Min                -3.53141
trainer/Policy mu Mean             -0.110849
trainer/Policy mu Std               0.711081
trainer/Policy mu Max               2.61866
trainer/Policy mu Min              -3.0222
trainer/Policy log std Mean        -2.00913
trainer/Policy log std Std          0.481284
trainer/Policy log std Max         -0.335928
trainer/Policy log std Min         -2.6564
trainer/Alpha                       0.0649114
trainer/Alpha Loss                 -0.302194
exploration/num steps total    163200
exploration/num paths total      1632
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.981049
exploration/Rewards Std             1.23564
exploration/Rewards Max            -0.00482801
exploration/Rewards Min           -10.8293
exploration/Returns Mean          -98.1049
exploration/Returns Std            53.4991
exploration/Returns Max           -39.4832
exploration/Returns Min          -180.637
exploration/Actions Mean            0.0378774
exploration/Actions Std             0.23564
exploration/Actions Max             0.999358
exploration/Actions Min            -0.942419
exploration/Num Paths               5
exploration/Average Returns       -98.1049
evaluation/num steps total     489000
evaluation/num paths total       4890
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.32908
evaluation/Rewards Std              1.22655
evaluation/Rewards Max             -0.0544234
evaluation/Rewards Min            -12.1126
evaluation/Returns Mean          -132.908
evaluation/Returns Std             91.815
evaluation/Returns Max            -11.7001
evaluation/Returns Min           -267.513
evaluation/Actions Mean             0.00531592
evaluation/Actions Std              0.168199
evaluation/Actions Max              0.999864
evaluation/Actions Min             -0.999456
evaluation/Num Paths               15
evaluation/Average Returns       -132.908
time/data storing (s)               0.00272933
time/evaluation sampling (s)        0.329447
time/exploration sampling (s)       0.140773
time/logging (s)                    0.00477194
time/saving (s)                     0.00194189
time/training (s)                   1.98755
time/epoch (s)                      2.46722
time/total (s)                    799.694
Epoch                             325
-----------------------------  ---------------
2019-04-23 01:26:53.763535 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 326 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.938669
trainer/QF2 Loss                    0.754938
trainer/Policy Loss                57.8394
trainer/Q1 Predictions Mean       -56.1936
trainer/Q1 Predictions Std         48.869
trainer/Q1 Predictions Max         -8.25509
trainer/Q1 Predictions Min       -156.386
trainer/Q2 Predictions Mean       -56.2376
trainer/Q2 Predictions Std         48.9165
trainer/Q2 Predictions Max         -8.27375
trainer/Q2 Predictions Min       -157.58
trainer/Q Targets Mean            -56.6412
trainer/Q Targets Std              49.3085
trainer/Q Targets Max              -8.56032
trainer/Q Targets Min            -161.124
trainer/Log Pis Mean                1.97901
trainer/Log Pis Std                 1.37314
trainer/Log Pis Max                 6.64546
trainer/Log Pis Min                -3.84137
trainer/Policy mu Mean             -0.0879471
trainer/Policy mu Std               0.713434
trainer/Policy mu Max               3.60718
trainer/Policy mu Min              -2.71666
trainer/Policy log std Mean        -2.06664
trainer/Policy log std Std          0.509666
trainer/Policy log std Max         -0.388368
trainer/Policy log std Min         -2.7343
trainer/Alpha                       0.0643396
trainer/Alpha Loss                 -0.057575
exploration/num steps total    163700
exploration/num paths total      1637
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.85417
exploration/Rewards Std             1.15235
exploration/Rewards Max            -0.037911
exploration/Rewards Min            -9.76117
exploration/Returns Mean         -185.417
exploration/Returns Std            71.8095
exploration/Returns Max           -72.184
exploration/Returns Min          -285.813
exploration/Actions Mean           -0.0231582
exploration/Actions Std             0.224723
exploration/Actions Max             0.933863
exploration/Actions Min            -0.999002
exploration/Num Paths               5
exploration/Average Returns      -185.417
evaluation/num steps total     490500
evaluation/num paths total       4905
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.851522
evaluation/Rewards Std              1.4433
evaluation/Rewards Max             -0.0522859
evaluation/Rewards Min            -11.1802
evaluation/Returns Mean           -85.1522
evaluation/Returns Std             91.4472
evaluation/Returns Max             -7.59635
evaluation/Returns Min           -295.671
evaluation/Actions Mean             0.00605643
evaluation/Actions Std              0.204351
evaluation/Actions Max              0.999682
evaluation/Actions Min             -0.998962
evaluation/Num Paths               15
evaluation/Average Returns        -85.1522
time/data storing (s)               0.00279974
time/evaluation sampling (s)        0.331458
time/exploration sampling (s)       0.137972
time/logging (s)                    0.00471671
time/saving (s)                     0.00152457
time/training (s)                   1.9896
time/epoch (s)                      2.46807
time/total (s)                    802.166
Epoch                             326
-----------------------------  ---------------
2019-04-23 01:26:56.233429 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 327 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                  220.535
trainer/QF2 Loss                  223.266
trainer/Policy Loss                58.794
trainer/Q1 Predictions Mean       -57.4224
trainer/Q1 Predictions Std         50.2963
trainer/Q1 Predictions Max         -8.46863
trainer/Q1 Predictions Min       -155.828
trainer/Q2 Predictions Mean       -57.4362
trainer/Q2 Predictions Std         50.3054
trainer/Q2 Predictions Max         -8.42549
trainer/Q2 Predictions Min       -155.66
trainer/Q Targets Mean            -56.6157
trainer/Q Targets Std              50.2732
trainer/Q Targets Max              -5.49214
trainer/Q Targets Min            -157.06
trainer/Log Pis Mean                1.86902
trainer/Log Pis Std                 1.25699
trainer/Log Pis Max                 5.00952
trainer/Log Pis Min                -1.24901
trainer/Policy mu Mean             -0.194624
trainer/Policy mu Std               0.720376
trainer/Policy mu Max               2.78381
trainer/Policy mu Min              -2.7969
trainer/Policy log std Mean        -2.00587
trainer/Policy log std Std          0.499812
trainer/Policy log std Max         -0.330761
trainer/Policy log std Min         -2.67504
trainer/Alpha                       0.0632439
trainer/Alpha Loss                 -0.361605
exploration/num steps total    164200
exploration/num paths total      1642
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.09738
exploration/Rewards Std             1.25597
exploration/Rewards Max            -0.00683775
exploration/Rewards Min            -8.34257
exploration/Returns Mean         -109.738
exploration/Returns Std           101.919
exploration/Returns Max           -23.7502
exploration/Returns Min          -270.767
exploration/Actions Mean           -0.0237908
exploration/Actions Std             0.213314
exploration/Actions Max             0.996538
exploration/Actions Min            -0.999977
exploration/Num Paths               5
exploration/Average Returns      -109.738
evaluation/num steps total     492000
evaluation/num paths total       4920
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.994208
evaluation/Rewards Std              1.32639
evaluation/Rewards Max             -0.0295427
evaluation/Rewards Min            -10.8556
evaluation/Returns Mean           -99.4208
evaluation/Returns Std             75.2827
evaluation/Returns Max             -7.69218
evaluation/Returns Min           -242.522
evaluation/Actions Mean             0.00944149
evaluation/Actions Std              0.195339
evaluation/Actions Max              0.998154
evaluation/Actions Min             -0.999942
evaluation/Num Paths               15
evaluation/Average Returns        -99.4208
time/data storing (s)               0.00299531
time/evaluation sampling (s)        0.333387
time/exploration sampling (s)       0.137582
time/logging (s)                    0.00503137
time/saving (s)                     0.00171001
time/training (s)                   1.9801
time/epoch (s)                      2.46081
time/total (s)                    804.632
Epoch                             327
-----------------------------  ---------------
2019-04-23 01:26:58.701261 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 328 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.458956
trainer/QF2 Loss                    0.421642
trainer/Policy Loss                48.9729
trainer/Q1 Predictions Mean       -47.3341
trainer/Q1 Predictions Std         46.0709
trainer/Q1 Predictions Max         -8.3446
trainer/Q1 Predictions Min       -155.324
trainer/Q2 Predictions Mean       -47.2981
trainer/Q2 Predictions Std         46.0161
trainer/Q2 Predictions Max         -8.35378
trainer/Q2 Predictions Min       -155.482
trainer/Q Targets Mean            -47.4733
trainer/Q Targets Std              46.4192
trainer/Q Targets Max              -8.43269
trainer/Q Targets Min            -157.618
trainer/Log Pis Mean                1.9205
trainer/Log Pis Std                 0.991212
trainer/Log Pis Max                 4.52852
trainer/Log Pis Min                -0.99942
trainer/Policy mu Mean             -0.0332037
trainer/Policy mu Std               0.633048
trainer/Policy mu Max               2.73212
trainer/Policy mu Min              -2.43976
trainer/Policy log std Mean        -2.05165
trainer/Policy log std Std          0.49386
trainer/Policy log std Max         -0.298481
trainer/Policy log std Min         -2.72981
trainer/Alpha                       0.0616731
trainer/Alpha Loss                 -0.221477
exploration/num steps total    164700
exploration/num paths total      1647
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.317409
exploration/Rewards Std             0.802529
exploration/Rewards Max            -0.00629664
exploration/Rewards Min            -8.37299
exploration/Returns Mean          -31.7409
exploration/Returns Std            12.9649
exploration/Returns Max           -18.017
exploration/Returns Min           -55.3608
exploration/Actions Mean            0.00693782
exploration/Actions Std             0.214116
exploration/Actions Max             0.998091
exploration/Actions Min            -0.99279
exploration/Num Paths               5
exploration/Average Returns       -31.7409
evaluation/num steps total     493500
evaluation/num paths total       4935
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.22631
evaluation/Rewards Std              1.21098
evaluation/Rewards Max             -0.0480992
evaluation/Rewards Min             -9.20926
evaluation/Returns Mean          -122.631
evaluation/Returns Std             96.0888
evaluation/Returns Max            -11.5113
evaluation/Returns Min           -271.042
evaluation/Actions Mean            -0.00437041
evaluation/Actions Std              0.184598
evaluation/Actions Max              0.998954
evaluation/Actions Min             -0.999017
evaluation/Num Paths               15
evaluation/Average Returns       -122.631
time/data storing (s)               0.00272266
time/evaluation sampling (s)        0.326972
time/exploration sampling (s)       0.138371
time/logging (s)                    0.00478467
time/saving (s)                     0.00193778
time/training (s)                   1.9833
time/epoch (s)                      2.45809
time/total (s)                    807.095
Epoch                             328
-----------------------------  ---------------
2019-04-23 01:27:01.161823 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 329 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    6.63004
trainer/QF2 Loss                    6.68882
trainer/Policy Loss                52.0068
trainer/Q1 Predictions Mean       -50.6506
trainer/Q1 Predictions Std         47.4685
trainer/Q1 Predictions Max         -8.40752
trainer/Q1 Predictions Min       -151.137
trainer/Q2 Predictions Mean       -50.6098
trainer/Q2 Predictions Std         47.4373
trainer/Q2 Predictions Max         -8.37179
trainer/Q2 Predictions Min       -152.593
trainer/Q Targets Mean            -50.9248
trainer/Q Targets Std              48.327
trainer/Q Targets Max              -0.214537
trainer/Q Targets Min            -153.827
trainer/Log Pis Mean                1.6426
trainer/Log Pis Std                 1.1222
trainer/Log Pis Max                 4.16082
trainer/Log Pis Min                -1.27185
trainer/Policy mu Mean             -0.00640601
trainer/Policy mu Std               0.536381
trainer/Policy mu Max               2.13275
trainer/Policy mu Min              -2.01419
trainer/Policy log std Mean        -2.12191
trainer/Policy log std Std          0.461748
trainer/Policy log std Max         -0.506594
trainer/Policy log std Min         -2.79271
trainer/Alpha                       0.0620909
trainer/Alpha Loss                 -0.993289
exploration/num steps total    165200
exploration/num paths total      1652
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.7114
exploration/Rewards Std             1.34373
exploration/Rewards Max            -0.0208299
exploration/Rewards Min            -9.96762
exploration/Returns Mean         -171.14
exploration/Returns Std            89.4289
exploration/Returns Max           -46.8711
exploration/Returns Min          -280.12
exploration/Actions Mean            0.00470152
exploration/Actions Std             0.249773
exploration/Actions Max             0.998429
exploration/Actions Min            -0.998904
exploration/Num Paths               5
exploration/Average Returns      -171.14
evaluation/num steps total     495000
evaluation/num paths total       4950
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.11184
evaluation/Rewards Std              1.03823
evaluation/Rewards Max             -0.0395847
evaluation/Rewards Min             -9.41948
evaluation/Returns Mean          -111.184
evaluation/Returns Std             73.2177
evaluation/Returns Max            -19.0223
evaluation/Returns Min           -280.176
evaluation/Actions Mean             0.00182296
evaluation/Actions Std              0.179267
evaluation/Actions Max              0.997872
evaluation/Actions Min             -0.995785
evaluation/Num Paths               15
evaluation/Average Returns       -111.184
time/data storing (s)               0.00258995
time/evaluation sampling (s)        0.33296
time/exploration sampling (s)       0.137482
time/logging (s)                    0.00483496
time/saving (s)                     0.00162116
time/training (s)                   1.97248
time/epoch (s)                      2.45196
time/total (s)                    809.55
Epoch                             329
-----------------------------  ---------------
2019-04-23 01:27:03.614432 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 330 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.38234
trainer/QF2 Loss                    1.37133
trainer/Policy Loss                47.4421
trainer/Q1 Predictions Mean       -45.5725
trainer/Q1 Predictions Std         41.1141
trainer/Q1 Predictions Max         -8.24532
trainer/Q1 Predictions Min       -147.003
trainer/Q2 Predictions Mean       -45.5722
trainer/Q2 Predictions Std         41.1083
trainer/Q2 Predictions Max         -8.20379
trainer/Q2 Predictions Min       -147.302
trainer/Q Targets Mean            -46.3634
trainer/Q Targets Std              41.7724
trainer/Q Targets Max              -8.47789
trainer/Q Targets Min            -149.655
trainer/Log Pis Mean                2.09874
trainer/Log Pis Std                 1.28571
trainer/Log Pis Max                 7.8182
trainer/Log Pis Min                -2.21853
trainer/Policy mu Mean             -0.0107786
trainer/Policy mu Std               0.71571
trainer/Policy mu Max               2.93701
trainer/Policy mu Min              -4.35236
trainer/Policy log std Mean        -2.08293
trainer/Policy log std Std          0.509027
trainer/Policy log std Max         -0.189422
trainer/Policy log std Min         -2.81201
trainer/Alpha                       0.0627298
trainer/Alpha Loss                  0.273414
exploration/num steps total    165700
exploration/num paths total      1657
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.603136
exploration/Rewards Std             0.892015
exploration/Rewards Max            -0.00132696
exploration/Rewards Min            -5.5934
exploration/Returns Mean          -60.3136
exploration/Returns Std            74.2463
exploration/Returns Max           -15.26
exploration/Returns Min          -208.426
exploration/Actions Mean            0.000221651
exploration/Actions Std             0.206629
exploration/Actions Max             0.999309
exploration/Actions Min            -0.997695
exploration/Num Paths               5
exploration/Average Returns       -60.3136
evaluation/num steps total     496500
evaluation/num paths total       4965
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.551303
evaluation/Rewards Std              1.14904
evaluation/Rewards Max             -0.0153177
evaluation/Rewards Min            -11.4543
evaluation/Returns Mean           -55.1303
evaluation/Returns Std             47.3866
evaluation/Returns Max            -14.0091
evaluation/Returns Min           -191.991
evaluation/Actions Mean             0.00284622
evaluation/Actions Std              0.189431
evaluation/Actions Max              0.999095
evaluation/Actions Min             -0.999795
evaluation/Num Paths               15
evaluation/Average Returns        -55.1303
time/data storing (s)               0.00275226
time/evaluation sampling (s)        0.326383
time/exploration sampling (s)       0.136007
time/logging (s)                    0.00473438
time/saving (s)                     0.00195141
time/training (s)                   1.97134
time/epoch (s)                      2.44316
time/total (s)                    811.998
Epoch                             330
-----------------------------  ----------------
2019-04-23 01:27:06.056695 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 331 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   80.1319
trainer/QF2 Loss                   79.9405
trainer/Policy Loss                49.9094
trainer/Q1 Predictions Mean       -48.5078
trainer/Q1 Predictions Std         47.2437
trainer/Q1 Predictions Max         -8.23772
trainer/Q1 Predictions Min       -154.502
trainer/Q2 Predictions Mean       -48.4437
trainer/Q2 Predictions Std         47.1592
trainer/Q2 Predictions Max         -8.26808
trainer/Q2 Predictions Min       -153.812
trainer/Q Targets Mean            -47.8635
trainer/Q Targets Std              48.0422
trainer/Q Targets Max              -0.0251391
trainer/Q Targets Min            -153.318
trainer/Log Pis Mean                1.81204
trainer/Log Pis Std                 1.38453
trainer/Log Pis Max                 6.38991
trainer/Log Pis Min                -4.58411
trainer/Policy mu Mean             -0.092753
trainer/Policy mu Std               0.630912
trainer/Policy mu Max               1.92723
trainer/Policy mu Min              -2.75026
trainer/Policy log std Mean        -2.04103
trainer/Policy log std Std          0.482605
trainer/Policy log std Max         -0.496592
trainer/Policy log std Min         -2.81192
trainer/Alpha                       0.0622457
trainer/Alpha Loss                 -0.521908
exploration/num steps total    166200
exploration/num paths total      1662
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.467487
exploration/Rewards Std             1.0011
exploration/Rewards Max            -0.0107118
exploration/Rewards Min            -8.93169
exploration/Returns Mean          -46.7487
exploration/Returns Std            17.9756
exploration/Returns Max           -18.0143
exploration/Returns Min           -72.3221
exploration/Actions Mean            0.0199944
exploration/Actions Std             0.219292
exploration/Actions Max             0.999782
exploration/Actions Min            -0.993165
exploration/Num Paths               5
exploration/Average Returns       -46.7487
evaluation/num steps total     498000
evaluation/num paths total       4980
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.40785
evaluation/Rewards Std              1.24077
evaluation/Rewards Max             -0.0824158
evaluation/Rewards Min             -9.5771
evaluation/Returns Mean          -140.785
evaluation/Returns Std            106.944
evaluation/Returns Max            -10.237
evaluation/Returns Min           -282.778
evaluation/Actions Mean            -0.00089747
evaluation/Actions Std              0.162204
evaluation/Actions Max              0.977286
evaluation/Actions Min             -0.998528
evaluation/Num Paths               15
evaluation/Average Returns       -140.785
time/data storing (s)               0.00267034
time/evaluation sampling (s)        0.331996
time/exploration sampling (s)       0.135369
time/logging (s)                    0.00478247
time/saving (s)                     0.0019415
time/training (s)                   1.95623
time/epoch (s)                      2.43299
time/total (s)                    814.435
Epoch                             331
-----------------------------  ---------------
2019-04-23 01:27:08.519995 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 332 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    3.36879
trainer/QF2 Loss                    3.39523
trainer/Policy Loss                51.3789
trainer/Q1 Predictions Mean       -49.8028
trainer/Q1 Predictions Std         47.198
trainer/Q1 Predictions Max         -8.11652
trainer/Q1 Predictions Min       -153.463
trainer/Q2 Predictions Mean       -49.8359
trainer/Q2 Predictions Std         47.1879
trainer/Q2 Predictions Max         -8.17859
trainer/Q2 Predictions Min       -154.89
trainer/Q Targets Mean            -50.0887
trainer/Q Targets Std              47.6544
trainer/Q Targets Max              -0.849512
trainer/Q Targets Min            -154.524
trainer/Log Pis Mean                1.87993
trainer/Log Pis Std                 1.22404
trainer/Log Pis Max                 5.53174
trainer/Log Pis Min                -1.38508
trainer/Policy mu Mean             -0.0345802
trainer/Policy mu Std               0.60227
trainer/Policy mu Max               2.23806
trainer/Policy mu Min              -2.80725
trainer/Policy log std Mean        -2.12324
trainer/Policy log std Std          0.480754
trainer/Policy log std Max         -0.499926
trainer/Policy log std Min         -2.8367
trainer/Alpha                       0.0613508
trainer/Alpha Loss                 -0.335133
exploration/num steps total    166700
exploration/num paths total      1667
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.72366
exploration/Rewards Std             1.49822
exploration/Rewards Max            -0.00995863
exploration/Rewards Min            -9.44033
exploration/Returns Mean         -172.366
exploration/Returns Std           111.737
exploration/Returns Max           -16.6123
exploration/Returns Min          -289.434
exploration/Actions Mean            0.0198084
exploration/Actions Std             0.289783
exploration/Actions Max             0.997426
exploration/Actions Min            -0.991449
exploration/Num Paths               5
exploration/Average Returns      -172.366
evaluation/num steps total     499500
evaluation/num paths total       4995
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.977343
evaluation/Rewards Std              1.05551
evaluation/Rewards Max             -0.00817499
evaluation/Rewards Min             -8.24329
evaluation/Returns Mean           -97.7343
evaluation/Returns Std             74.7044
evaluation/Returns Max            -14.9595
evaluation/Returns Min           -242.194
evaluation/Actions Mean             0.00182205
evaluation/Actions Std              0.17354
evaluation/Actions Max              0.997036
evaluation/Actions Min             -0.998417
evaluation/Num Paths               15
evaluation/Average Returns        -97.7343
time/data storing (s)               0.00268942
time/evaluation sampling (s)        0.332397
time/exploration sampling (s)       0.136739
time/logging (s)                    0.00492205
time/saving (s)                     0.00193621
time/training (s)                   1.97619
time/epoch (s)                      2.45488
time/total (s)                    816.894
Epoch                             332
-----------------------------  ---------------
2019-04-23 01:27:10.989050 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 333 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.212417
trainer/QF2 Loss                    0.140924
trainer/Policy Loss                53.6982
trainer/Q1 Predictions Mean       -51.7722
trainer/Q1 Predictions Std         46.8551
trainer/Q1 Predictions Max         -8.37529
trainer/Q1 Predictions Min       -153.145
trainer/Q2 Predictions Mean       -51.7962
trainer/Q2 Predictions Std         46.8711
trainer/Q2 Predictions Max         -8.36164
trainer/Q2 Predictions Min       -153.896
trainer/Q Targets Mean            -51.8443
trainer/Q Targets Std              47.1142
trainer/Q Targets Max              -8.18202
trainer/Q Targets Min            -154.158
trainer/Log Pis Mean                2.16423
trainer/Log Pis Std                 1.07774
trainer/Log Pis Max                 6.33358
trainer/Log Pis Min                -0.628692
trainer/Policy mu Mean              0.00544602
trainer/Policy mu Std               0.632522
trainer/Policy mu Max               3.71535
trainer/Policy mu Min              -2.55636
trainer/Policy log std Mean        -2.12903
trainer/Policy log std Std          0.515376
trainer/Policy log std Max         -0.31058
trainer/Policy log std Min         -2.92908
trainer/Alpha                       0.0608039
trainer/Alpha Loss                  0.459861
exploration/num steps total    167200
exploration/num paths total      1672
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.52515
exploration/Rewards Std             1.05179
exploration/Rewards Max            -0.00537766
exploration/Rewards Min            -9.82671
exploration/Returns Mean          -52.515
exploration/Returns Std            20.5736
exploration/Returns Max           -27.7417
exploration/Returns Min           -87.8748
exploration/Actions Mean           -0.00107444
exploration/Actions Std             0.23213
exploration/Actions Max             0.999568
exploration/Actions Min            -0.998838
exploration/Num Paths               5
exploration/Average Returns       -52.515
evaluation/num steps total     501000
evaluation/num paths total       5010
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.766285
evaluation/Rewards Std              1.14386
evaluation/Rewards Max             -0.0166609
evaluation/Rewards Min             -9.46053
evaluation/Returns Mean           -76.6285
evaluation/Returns Std             68.4248
evaluation/Returns Max            -14.9456
evaluation/Returns Min           -237.238
evaluation/Actions Mean             0.00802268
evaluation/Actions Std              0.183898
evaluation/Actions Max              0.999166
evaluation/Actions Min             -0.998789
evaluation/Num Paths               15
evaluation/Average Returns        -76.6285
time/data storing (s)               0.00275366
time/evaluation sampling (s)        0.324699
time/exploration sampling (s)       0.136129
time/logging (s)                    0.00477813
time/saving (s)                     0.00167498
time/training (s)                   1.99022
time/epoch (s)                      2.46025
time/total (s)                    819.358
Epoch                             333
-----------------------------  ---------------
2019-04-23 01:27:13.456748 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 334 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.63873
trainer/QF2 Loss                    1.50932
trainer/Policy Loss                51.0305
trainer/Q1 Predictions Mean       -49.3801
trainer/Q1 Predictions Std         50.1302
trainer/Q1 Predictions Max         -8.09087
trainer/Q1 Predictions Min       -155.978
trainer/Q2 Predictions Mean       -49.3675
trainer/Q2 Predictions Std         50.2386
trainer/Q2 Predictions Max         -8.04123
trainer/Q2 Predictions Min       -156.257
trainer/Q Targets Mean            -50.2128
trainer/Q Targets Std              50.9754
trainer/Q Targets Max              -8.19797
trainer/Q Targets Min            -156.117
trainer/Log Pis Mean                1.84616
trainer/Log Pis Std                 1.22918
trainer/Log Pis Max                 5.59169
trainer/Log Pis Min                -2.94714
trainer/Policy mu Mean             -0.0354252
trainer/Policy mu Std               0.638973
trainer/Policy mu Max               2.87101
trainer/Policy mu Min              -2.75887
trainer/Policy log std Mean        -2.12053
trainer/Policy log std Std          0.511102
trainer/Policy log std Max         -0.501182
trainer/Policy log std Min         -2.81189
trainer/Alpha                       0.059389
trainer/Alpha Loss                 -0.434362
exploration/num steps total    167700
exploration/num paths total      1677
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.10264
exploration/Rewards Std             1.08589
exploration/Rewards Max            -0.015872
exploration/Rewards Min            -9.25932
exploration/Returns Mean         -110.264
exploration/Returns Std            74.4007
exploration/Returns Max           -13.7663
exploration/Returns Min          -200.855
exploration/Actions Mean           -0.00890592
exploration/Actions Std             0.236421
exploration/Actions Max             0.997536
exploration/Actions Min            -0.999761
exploration/Num Paths               5
exploration/Average Returns      -110.264
evaluation/num steps total     502500
evaluation/num paths total       5025
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.23888
evaluation/Rewards Std              1.29607
evaluation/Rewards Max             -0.0611116
evaluation/Rewards Min             -8.79469
evaluation/Returns Mean          -123.888
evaluation/Returns Std            102.888
evaluation/Returns Max             -9.77476
evaluation/Returns Min           -308.818
evaluation/Actions Mean            -0.00795042
evaluation/Actions Std              0.181109
evaluation/Actions Max              0.999365
evaluation/Actions Min             -0.99934
evaluation/Num Paths               15
evaluation/Average Returns       -123.888
time/data storing (s)               0.00273985
time/evaluation sampling (s)        0.326522
time/exploration sampling (s)       0.137379
time/logging (s)                    0.00474326
time/saving (s)                     0.00966709
time/training (s)                   1.97712
time/epoch (s)                      2.45818
time/total (s)                    821.821
Epoch                             334
-----------------------------  ---------------
2019-04-23 01:27:15.933602 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 335 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                  283.791
trainer/QF2 Loss                  283.913
trainer/Policy Loss                55.8879
trainer/Q1 Predictions Mean       -54.2628
trainer/Q1 Predictions Std         49.182
trainer/Q1 Predictions Max         -8.3982
trainer/Q1 Predictions Min       -153.938
trainer/Q2 Predictions Mean       -54.2716
trainer/Q2 Predictions Std         49.2163
trainer/Q2 Predictions Max         -8.41339
trainer/Q2 Predictions Min       -154.914
trainer/Q Targets Mean            -51.9043
trainer/Q Targets Std              49.0181
trainer/Q Targets Max              -0.0603853
trainer/Q Targets Min            -155.386
trainer/Log Pis Mean                1.97119
trainer/Log Pis Std                 1.212
trainer/Log Pis Max                 5.53562
trainer/Log Pis Min                -3.53558
trainer/Policy mu Mean             -0.0420115
trainer/Policy mu Std               0.648163
trainer/Policy mu Max               3.02903
trainer/Policy mu Min              -2.57771
trainer/Policy log std Mean        -2.07914
trainer/Policy log std Std          0.481758
trainer/Policy log std Max         -0.304898
trainer/Policy log std Min         -2.90757
trainer/Alpha                       0.0612696
trainer/Alpha Loss                 -0.0804448
exploration/num steps total    168200
exploration/num paths total      1682
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.877489
exploration/Rewards Std             0.857013
exploration/Rewards Max            -0.014225
exploration/Rewards Min            -7.17914
exploration/Returns Mean          -87.7489
exploration/Returns Std            55.3268
exploration/Returns Max           -27.4547
exploration/Returns Min          -176.273
exploration/Actions Mean            0.000934633
exploration/Actions Std             0.221585
exploration/Actions Max             0.99539
exploration/Actions Min            -0.999931
exploration/Num Paths               5
exploration/Average Returns       -87.7489
evaluation/num steps total     504000
evaluation/num paths total       5040
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.708723
evaluation/Rewards Std              1.16202
evaluation/Rewards Max             -0.0273552
evaluation/Rewards Min            -10.0097
evaluation/Returns Mean           -70.8723
evaluation/Returns Std             84.1997
evaluation/Returns Max             -7.26549
evaluation/Returns Min           -294.594
evaluation/Actions Mean             7.23356e-05
evaluation/Actions Std              0.151394
evaluation/Actions Max              0.999477
evaluation/Actions Min             -0.996998
evaluation/Num Paths               15
evaluation/Average Returns        -70.8723
time/data storing (s)               0.00289718
time/evaluation sampling (s)        0.323109
time/exploration sampling (s)       0.140783
time/logging (s)                    0.00485193
time/saving (s)                     0.00194423
time/training (s)                   1.99387
time/epoch (s)                      2.46745
time/total (s)                    824.293
Epoch                             335
-----------------------------  ----------------
2019-04-23 01:27:18.389393 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 336 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.81826
trainer/QF2 Loss                    1.95277
trainer/Policy Loss                49.2312
trainer/Q1 Predictions Mean       -47.4653
trainer/Q1 Predictions Std         44.6504
trainer/Q1 Predictions Max         -8.16076
trainer/Q1 Predictions Min       -151.428
trainer/Q2 Predictions Mean       -47.4049
trainer/Q2 Predictions Std         44.6282
trainer/Q2 Predictions Max         -8.05771
trainer/Q2 Predictions Min       -150.744
trainer/Q Targets Mean            -48.0054
trainer/Q Targets Std              45.3041
trainer/Q Targets Max              -0.105198
trainer/Q Targets Min            -154.165
trainer/Log Pis Mean                2.07445
trainer/Log Pis Std                 1.17237
trainer/Log Pis Max                 5.7899
trainer/Log Pis Min                -1.62434
trainer/Policy mu Mean              0.00446285
trainer/Policy mu Std               0.682573
trainer/Policy mu Max               2.98781
trainer/Policy mu Min              -2.9039
trainer/Policy log std Mean        -2.08327
trainer/Policy log std Std          0.505318
trainer/Policy log std Max         -0.567684
trainer/Policy log std Min         -2.79705
trainer/Alpha                       0.0602912
trainer/Alpha Loss                  0.209101
exploration/num steps total    168700
exploration/num paths total      1687
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.629372
exploration/Rewards Std             0.812134
exploration/Rewards Max            -0.00812221
exploration/Rewards Min            -7.63961
exploration/Returns Mean          -62.9372
exploration/Returns Std            38.731
exploration/Returns Max           -20.3754
exploration/Returns Min          -117.469
exploration/Actions Mean            0.00399275
exploration/Actions Std             0.194213
exploration/Actions Max             0.999183
exploration/Actions Min            -0.993699
exploration/Num Paths               5
exploration/Average Returns       -62.9372
evaluation/num steps total     505500
evaluation/num paths total       5055
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.942843
evaluation/Rewards Std              1.33476
evaluation/Rewards Max             -0.0462074
evaluation/Rewards Min            -10.0796
evaluation/Returns Mean           -94.2843
evaluation/Returns Std             84.8944
evaluation/Returns Max            -19.3144
evaluation/Returns Min           -280.438
evaluation/Actions Mean             0.0174953
evaluation/Actions Std              0.177733
evaluation/Actions Max              0.999517
evaluation/Actions Min             -0.998246
evaluation/Num Paths               15
evaluation/Average Returns        -94.2843
time/data storing (s)               0.00263761
time/evaluation sampling (s)        0.332617
time/exploration sampling (s)       0.141694
time/logging (s)                    0.00474916
time/saving (s)                     0.00192322
time/training (s)                   1.96265
time/epoch (s)                      2.44627
time/total (s)                    826.743
Epoch                             336
-----------------------------  ---------------
2019-04-23 01:27:20.856210 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 337 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.22756
trainer/QF2 Loss                    1.23041
trainer/Policy Loss                49.6968
trainer/Q1 Predictions Mean       -47.9856
trainer/Q1 Predictions Std         45.9375
trainer/Q1 Predictions Max         -8.15915
trainer/Q1 Predictions Min       -155.602
trainer/Q2 Predictions Mean       -47.9763
trainer/Q2 Predictions Std         45.9393
trainer/Q2 Predictions Max         -8.155
trainer/Q2 Predictions Min       -156.484
trainer/Q Targets Mean            -48.3123
trainer/Q Targets Std              46.3153
trainer/Q Targets Max              -0.314614
trainer/Q Targets Min            -155.95
trainer/Log Pis Mean                1.99297
trainer/Log Pis Std                 1.13807
trainer/Log Pis Max                 5.26717
trainer/Log Pis Min                -1.49868
trainer/Policy mu Mean             -0.116179
trainer/Policy mu Std               0.659743
trainer/Policy mu Max               2.82141
trainer/Policy mu Min              -2.30628
trainer/Policy log std Mean        -2.09765
trainer/Policy log std Std          0.465122
trainer/Policy log std Max         -0.578068
trainer/Policy log std Min         -2.82807
trainer/Alpha                       0.0609549
trainer/Alpha Loss                 -0.0196774
exploration/num steps total    169200
exploration/num paths total      1692
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.959363
exploration/Rewards Std             1.29733
exploration/Rewards Max            -0.0214184
exploration/Rewards Min           -10.1833
exploration/Returns Mean          -95.9363
exploration/Returns Std            64.1192
exploration/Returns Max           -22.565
exploration/Returns Min          -207.064
exploration/Actions Mean            0.0102519
exploration/Actions Std             0.24173
exploration/Actions Max             0.998613
exploration/Actions Min            -0.999869
exploration/Num Paths               5
exploration/Average Returns       -95.9363
evaluation/num steps total     507000
evaluation/num paths total       5070
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.11639
evaluation/Rewards Std              1.23267
evaluation/Rewards Max             -0.0206584
evaluation/Rewards Min             -8.46122
evaluation/Returns Mean          -111.639
evaluation/Returns Std             98.9686
evaluation/Returns Max             -8.88666
evaluation/Returns Min           -318.474
evaluation/Actions Mean            -0.00170639
evaluation/Actions Std              0.184751
evaluation/Actions Max              0.99796
evaluation/Actions Min             -0.999376
evaluation/Num Paths               15
evaluation/Average Returns       -111.639
time/data storing (s)               0.00257907
time/evaluation sampling (s)        0.325661
time/exploration sampling (s)       0.143021
time/logging (s)                    0.00470266
time/saving (s)                     0.00188578
time/training (s)                   1.9795
time/epoch (s)                      2.45735
time/total (s)                    829.205
Epoch                             337
-----------------------------  ---------------
2019-04-23 01:27:23.311416 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 338 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.999914
trainer/QF2 Loss                    1.13308
trainer/Policy Loss                47.2853
trainer/Q1 Predictions Mean       -45.6815
trainer/Q1 Predictions Std         42.7661
trainer/Q1 Predictions Max         -8.01663
trainer/Q1 Predictions Min       -153.495
trainer/Q2 Predictions Mean       -45.6123
trainer/Q2 Predictions Std         42.7541
trainer/Q2 Predictions Max         -8.03827
trainer/Q2 Predictions Min       -153.607
trainer/Q Targets Mean            -46.3476
trainer/Q Targets Std              43.3151
trainer/Q Targets Max              -8.08349
trainer/Q Targets Min            -154.893
trainer/Log Pis Mean                1.87718
trainer/Log Pis Std                 1.37465
trainer/Log Pis Max                 6.22509
trainer/Log Pis Min                -3.70686
trainer/Policy mu Mean             -0.0789603
trainer/Policy mu Std               0.575902
trainer/Policy mu Max               2.40366
trainer/Policy mu Min              -3.21878
trainer/Policy log std Mean        -2.16205
trainer/Policy log std Std          0.478332
trainer/Policy log std Max         -0.575722
trainer/Policy log std Min         -2.8415
trainer/Alpha                       0.0608437
trainer/Alpha Loss                 -0.343829
exploration/num steps total    169700
exploration/num paths total      1697
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.700847
exploration/Rewards Std             1.02104
exploration/Rewards Max            -0.0114661
exploration/Rewards Min            -8.74438
exploration/Returns Mean          -70.0847
exploration/Returns Std            64.1801
exploration/Returns Max           -18.2816
exploration/Returns Min          -195.712
exploration/Actions Mean           -0.0308511
exploration/Actions Std             0.213053
exploration/Actions Max             0.987109
exploration/Actions Min            -0.999721
exploration/Num Paths               5
exploration/Average Returns       -70.0847
evaluation/num steps total     508500
evaluation/num paths total       5085
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.0175
evaluation/Rewards Std              1.32537
evaluation/Rewards Max             -0.0311231
evaluation/Rewards Min            -11.0825
evaluation/Returns Mean          -101.75
evaluation/Returns Std             95.2173
evaluation/Returns Max            -11.0878
evaluation/Returns Min           -309.075
evaluation/Actions Mean            -0.00543796
evaluation/Actions Std              0.186858
evaluation/Actions Max              0.998338
evaluation/Actions Min             -0.999738
evaluation/Num Paths               15
evaluation/Average Returns       -101.75
time/data storing (s)               0.00281737
time/evaluation sampling (s)        0.336009
time/exploration sampling (s)       0.137706
time/logging (s)                    0.00476282
time/saving (s)                     0.00204946
time/training (s)                   1.96329
time/epoch (s)                      2.44664
time/total (s)                    831.655
Epoch                             338
-----------------------------  ---------------
2019-04-23 01:27:25.764319 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 339 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.11395
trainer/QF2 Loss                    1.1819
trainer/Policy Loss                43.3569
trainer/Q1 Predictions Mean       -41.944
trainer/Q1 Predictions Std         45.578
trainer/Q1 Predictions Max         -8.26926
trainer/Q1 Predictions Min       -160.826
trainer/Q2 Predictions Mean       -41.9506
trainer/Q2 Predictions Std         45.5528
trainer/Q2 Predictions Max         -8.26019
trainer/Q2 Predictions Min       -161.311
trainer/Q Targets Mean            -42.0778
trainer/Q Targets Std              46.08
trainer/Q Targets Max              -0.0670676
trainer/Q Targets Min            -161.043
trainer/Log Pis Mean                1.67369
trainer/Log Pis Std                 1.10232
trainer/Log Pis Max                 4.44286
trainer/Log Pis Min                -1.08985
trainer/Policy mu Mean             -0.0328065
trainer/Policy mu Std               0.531909
trainer/Policy mu Max               2.17431
trainer/Policy mu Min              -2.79222
trainer/Policy log std Mean        -2.13235
trainer/Policy log std Std          0.452784
trainer/Policy log std Max         -0.210351
trainer/Policy log std Min         -2.8445
trainer/Alpha                       0.0620428
trainer/Alpha Loss                 -0.907107
exploration/num steps total    170200
exploration/num paths total      1702
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.53316
exploration/Rewards Std             1.14052
exploration/Rewards Max            -0.00900149
exploration/Rewards Min            -9.68343
exploration/Returns Mean         -153.316
exploration/Returns Std            61.0954
exploration/Returns Max           -68.7717
exploration/Returns Min          -216.807
exploration/Actions Mean            0.00382549
exploration/Actions Std             0.267109
exploration/Actions Max             0.994505
exploration/Actions Min            -0.999828
exploration/Num Paths               5
exploration/Average Returns      -153.316
evaluation/num steps total     510000
evaluation/num paths total       5100
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.931615
evaluation/Rewards Std              1.15243
evaluation/Rewards Max             -0.101756
evaluation/Rewards Min            -11.2682
evaluation/Returns Mean           -93.1615
evaluation/Returns Std             70.1093
evaluation/Returns Max            -22.4332
evaluation/Returns Min           -286.373
evaluation/Actions Mean             0.00344232
evaluation/Actions Std              0.183742
evaluation/Actions Max              0.999687
evaluation/Actions Min             -0.997541
evaluation/Num Paths               15
evaluation/Average Returns        -93.1615
time/data storing (s)               0.00274905
time/evaluation sampling (s)        0.332302
time/exploration sampling (s)       0.136082
time/logging (s)                    0.00479534
time/saving (s)                     0.00192374
time/training (s)                   1.96536
time/epoch (s)                      2.44321
time/total (s)                    834.103
Epoch                             339
-----------------------------  ---------------
2019-04-23 01:27:28.228723 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 340 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   39.0649
trainer/QF2 Loss                   38.9999
trainer/Policy Loss                46.0074
trainer/Q1 Predictions Mean       -44.1963
trainer/Q1 Predictions Std         43.6994
trainer/Q1 Predictions Max         -8.2575
trainer/Q1 Predictions Min       -151.882
trainer/Q2 Predictions Mean       -44.2105
trainer/Q2 Predictions Std         43.6934
trainer/Q2 Predictions Max         -8.24508
trainer/Q2 Predictions Min       -151.595
trainer/Q Targets Mean            -43.9668
trainer/Q Targets Std              44.3399
trainer/Q Targets Max              -2.35896
trainer/Q Targets Min            -153.631
trainer/Log Pis Mean                2.12553
trainer/Log Pis Std                 1.27481
trainer/Log Pis Max                 6.61883
trainer/Log Pis Min                -2.26453
trainer/Policy mu Mean              0.0096228
trainer/Policy mu Std               0.62772
trainer/Policy mu Max               2.96209
trainer/Policy mu Min              -2.19588
trainer/Policy log std Mean        -2.12818
trainer/Policy log std Std          0.476685
trainer/Policy log std Max         -0.433934
trainer/Policy log std Min         -2.90454
trainer/Alpha                       0.0613628
trainer/Alpha Loss                  0.350351
exploration/num steps total    170700
exploration/num paths total      1707
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.58748
exploration/Rewards Std             1.25115
exploration/Rewards Max            -0.0180913
exploration/Rewards Min            -9.05451
exploration/Returns Mean         -158.748
exploration/Returns Std           100.654
exploration/Returns Max           -27.8807
exploration/Returns Min          -286.058
exploration/Actions Mean            0.00459062
exploration/Actions Std             0.212181
exploration/Actions Max             0.998128
exploration/Actions Min            -0.993272
exploration/Num Paths               5
exploration/Average Returns      -158.748
evaluation/num steps total     511500
evaluation/num paths total       5115
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.22322
evaluation/Rewards Std              1.33727
evaluation/Rewards Max             -0.0420939
evaluation/Rewards Min            -11.0956
evaluation/Returns Mean          -122.322
evaluation/Returns Std             88.7137
evaluation/Returns Max             -5.70899
evaluation/Returns Min           -288.182
evaluation/Actions Mean            -0.00790424
evaluation/Actions Std              0.188372
evaluation/Actions Max              0.997442
evaluation/Actions Min             -0.999696
evaluation/Num Paths               15
evaluation/Average Returns       -122.322
time/data storing (s)               0.00272573
time/evaluation sampling (s)        0.329999
time/exploration sampling (s)       0.136576
time/logging (s)                    0.00474339
time/saving (s)                     0.00194303
time/training (s)                   1.97879
time/epoch (s)                      2.45478
time/total (s)                    836.563
Epoch                             340
-----------------------------  ---------------
2019-04-23 01:27:30.703557 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 341 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.959866
trainer/QF2 Loss                    0.974567
trainer/Policy Loss                55.9887
trainer/Q1 Predictions Mean       -54.3418
trainer/Q1 Predictions Std         51.6054
trainer/Q1 Predictions Max         -7.9947
trainer/Q1 Predictions Min       -160.52
trainer/Q2 Predictions Mean       -54.3617
trainer/Q2 Predictions Std         51.563
trainer/Q2 Predictions Max         -8.02245
trainer/Q2 Predictions Min       -160.404
trainer/Q Targets Mean            -54.5827
trainer/Q Targets Std              51.7512
trainer/Q Targets Max              -0.246282
trainer/Q Targets Min            -158.813
trainer/Log Pis Mean                2.15326
trainer/Log Pis Std                 1.07996
trainer/Log Pis Max                 5.51868
trainer/Log Pis Min                -2.31606
trainer/Policy mu Mean             -0.0786818
trainer/Policy mu Std               0.70693
trainer/Policy mu Max               2.86978
trainer/Policy mu Min              -2.31592
trainer/Policy log std Mean        -2.10561
trainer/Policy log std Std          0.535092
trainer/Policy log std Max         -0.648281
trainer/Policy log std Min         -2.95615
trainer/Alpha                       0.0607568
trainer/Alpha Loss                  0.429296
exploration/num steps total    171200
exploration/num paths total      1712
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.56946
exploration/Rewards Std             1.42316
exploration/Rewards Max            -0.00836177
exploration/Rewards Min            -8.67026
exploration/Returns Mean         -156.946
exploration/Returns Std           106.948
exploration/Returns Max           -41.2289
exploration/Returns Min          -290.312
exploration/Actions Mean            0.0193646
exploration/Actions Std             0.22488
exploration/Actions Max             0.996934
exploration/Actions Min            -0.999151
exploration/Num Paths               5
exploration/Average Returns      -156.946
evaluation/num steps total     513000
evaluation/num paths total       5130
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.07683
evaluation/Rewards Std              1.44552
evaluation/Rewards Max             -0.00339419
evaluation/Rewards Min            -11.8053
evaluation/Returns Mean          -107.683
evaluation/Returns Std            118.238
evaluation/Returns Max            -10.2205
evaluation/Returns Min           -309.934
evaluation/Actions Mean            -0.00422088
evaluation/Actions Std              0.179933
evaluation/Actions Max              0.998653
evaluation/Actions Min             -0.999381
evaluation/Num Paths               15
evaluation/Average Returns       -107.683
time/data storing (s)               0.00285437
time/evaluation sampling (s)        0.329271
time/exploration sampling (s)       0.139489
time/logging (s)                    0.00405245
time/saving (s)                     0.00196067
time/training (s)                   1.98707
time/epoch (s)                      2.4647
time/total (s)                    839.032
Epoch                             341
-----------------------------  ---------------
2019-04-23 01:27:33.170698 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 342 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.65136
trainer/QF2 Loss                    1.55481
trainer/Policy Loss                59.0882
trainer/Q1 Predictions Mean       -57.3666
trainer/Q1 Predictions Std         51.4789
trainer/Q1 Predictions Max         -8.07095
trainer/Q1 Predictions Min       -159.261
trainer/Q2 Predictions Mean       -57.3534
trainer/Q2 Predictions Std         51.5535
trainer/Q2 Predictions Max         -8.10324
trainer/Q2 Predictions Min       -158.832
trainer/Q Targets Mean            -57.8707
trainer/Q Targets Std              52.121
trainer/Q Targets Max              -0.203038
trainer/Q Targets Min            -158.614
trainer/Log Pis Mean                2.08044
trainer/Log Pis Std                 1.19299
trainer/Log Pis Max                 8.10417
trainer/Log Pis Min                -1.25697
trainer/Policy mu Mean              0.00209516
trainer/Policy mu Std               0.625396
trainer/Policy mu Max               2.6033
trainer/Policy mu Min              -2.27482
trainer/Policy log std Mean        -2.1196
trainer/Policy log std Std          0.497277
trainer/Policy log std Max         -0.550529
trainer/Policy log std Min         -3.05331
trainer/Alpha                       0.0611519
trainer/Alpha Loss                  0.22479
exploration/num steps total    171700
exploration/num paths total      1717
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.678108
exploration/Rewards Std             1.32039
exploration/Rewards Max            -0.00973734
exploration/Rewards Min           -11.3541
exploration/Returns Mean          -67.8108
exploration/Returns Std            43.1867
exploration/Returns Max           -22.9708
exploration/Returns Min          -134.877
exploration/Actions Mean            0.0133026
exploration/Actions Std             0.240025
exploration/Actions Max             0.999702
exploration/Actions Min            -0.998912
exploration/Num Paths               5
exploration/Average Returns       -67.8108
evaluation/num steps total     514500
evaluation/num paths total       5145
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.15285
evaluation/Rewards Std              1.05647
evaluation/Rewards Max             -0.0858236
evaluation/Rewards Min             -7.3433
evaluation/Returns Mean          -115.285
evaluation/Returns Std             90.6681
evaluation/Returns Max            -15.1315
evaluation/Returns Min           -277.451
evaluation/Actions Mean             0.0016785
evaluation/Actions Std              0.145892
evaluation/Actions Max              0.997239
evaluation/Actions Min             -0.997691
evaluation/Num Paths               15
evaluation/Average Returns       -115.285
time/data storing (s)               0.00271598
time/evaluation sampling (s)        0.329775
time/exploration sampling (s)       0.136555
time/logging (s)                    0.00476099
time/saving (s)                     0.00194425
time/training (s)                   1.9829
time/epoch (s)                      2.45865
time/total (s)                    841.495
Epoch                             342
-----------------------------  ---------------
2019-04-23 01:27:35.614604 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 343 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   40.0604
trainer/QF2 Loss                   39.9111
trainer/Policy Loss                50.4831
trainer/Q1 Predictions Mean       -48.8381
trainer/Q1 Predictions Std         50.2656
trainer/Q1 Predictions Max         -7.87876
trainer/Q1 Predictions Min       -152.981
trainer/Q2 Predictions Mean       -48.847
trainer/Q2 Predictions Std         50.3045
trainer/Q2 Predictions Max         -7.90145
trainer/Q2 Predictions Min       -153.654
trainer/Q Targets Mean            -48.8593
trainer/Q Targets Std              51.7222
trainer/Q Targets Max              -0.111833
trainer/Q Targets Min            -157.113
trainer/Log Pis Mean                1.89178
trainer/Log Pis Std                 1.1622
trainer/Log Pis Max                 5.84488
trainer/Log Pis Min                -2.04992
trainer/Policy mu Mean             -0.00748346
trainer/Policy mu Std               0.541294
trainer/Policy mu Max               2.76955
trainer/Policy mu Min              -2.87304
trainer/Policy log std Mean        -2.17589
trainer/Policy log std Std          0.477254
trainer/Policy log std Max         -0.498713
trainer/Policy log std Min         -3.01354
trainer/Alpha                       0.0607432
trainer/Alpha Loss                 -0.303137
exploration/num steps total    172200
exploration/num paths total      1722
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.644552
exploration/Rewards Std             0.946572
exploration/Rewards Max            -0.0183817
exploration/Rewards Min            -8.51233
exploration/Returns Mean          -64.4552
exploration/Returns Std            25.555
exploration/Returns Max           -18.062
exploration/Returns Min           -87.4686
exploration/Actions Mean            0.00519187
exploration/Actions Std             0.209408
exploration/Actions Max             0.999788
exploration/Actions Min            -0.999462
exploration/Num Paths               5
exploration/Average Returns       -64.4552
evaluation/num steps total     516000
evaluation/num paths total       5160
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.14627
evaluation/Rewards Std              1.30911
evaluation/Rewards Max             -0.0433866
evaluation/Rewards Min            -10.6904
evaluation/Returns Mean          -114.627
evaluation/Returns Std             90.4473
evaluation/Returns Max            -18.256
evaluation/Returns Min           -254.481
evaluation/Actions Mean            -0.00251881
evaluation/Actions Std              0.199061
evaluation/Actions Max              0.998109
evaluation/Actions Min             -0.998602
evaluation/Num Paths               15
evaluation/Average Returns       -114.627
time/data storing (s)               0.00257709
time/evaluation sampling (s)        0.326284
time/exploration sampling (s)       0.135943
time/logging (s)                    0.00476606
time/saving (s)                     0.0019416
time/training (s)                   1.96283
time/epoch (s)                      2.43434
time/total (s)                    843.934
Epoch                             343
-----------------------------  ---------------
2019-04-23 01:27:38.094021 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 344 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   12.858
trainer/QF2 Loss                   13.0013
trainer/Policy Loss                49.0995
trainer/Q1 Predictions Mean       -47.6066
trainer/Q1 Predictions Std         43.8961
trainer/Q1 Predictions Max         -8.26498
trainer/Q1 Predictions Min       -156.986
trainer/Q2 Predictions Mean       -47.6037
trainer/Q2 Predictions Std         43.8726
trainer/Q2 Predictions Max         -8.23614
trainer/Q2 Predictions Min       -157.536
trainer/Q Targets Mean            -47.3316
trainer/Q Targets Std              44.2115
trainer/Q Targets Max              -0.743806
trainer/Q Targets Min            -156.228
trainer/Log Pis Mean                1.90658
trainer/Log Pis Std                 1.02415
trainer/Log Pis Max                 4.85116
trainer/Log Pis Min                -2.86856
trainer/Policy mu Mean             -0.100304
trainer/Policy mu Std               0.599311
trainer/Policy mu Max               3.26478
trainer/Policy mu Min              -2.41712
trainer/Policy log std Mean        -2.09995
trainer/Policy log std Std          0.486502
trainer/Policy log std Max         -0.25061
trainer/Policy log std Min         -2.88447
trainer/Alpha                       0.0615563
trainer/Alpha Loss                 -0.260423
exploration/num steps total    172700
exploration/num paths total      1727
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.628297
exploration/Rewards Std             1.01815
exploration/Rewards Max            -0.00606389
exploration/Rewards Min            -7.49868
exploration/Returns Mean          -62.8297
exploration/Returns Std            61.4476
exploration/Returns Max           -18.9951
exploration/Returns Min          -184.06
exploration/Actions Mean            0.0259368
exploration/Actions Std             0.248092
exploration/Actions Max             0.999085
exploration/Actions Min            -0.995551
exploration/Num Paths               5
exploration/Average Returns       -62.8297
evaluation/num steps total     517500
evaluation/num paths total       5175
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.13146
evaluation/Rewards Std              1.45474
evaluation/Rewards Max             -0.0567647
evaluation/Rewards Min            -10.1127
evaluation/Returns Mean          -113.146
evaluation/Returns Std             95.881
evaluation/Returns Max            -18.7901
evaluation/Returns Min           -325.636
evaluation/Actions Mean             0.00272461
evaluation/Actions Std              0.203824
evaluation/Actions Max              0.999117
evaluation/Actions Min             -0.999297
evaluation/Num Paths               15
evaluation/Average Returns       -113.146
time/data storing (s)               0.0028151
time/evaluation sampling (s)        0.332602
time/exploration sampling (s)       0.141479
time/logging (s)                    0.00478782
time/saving (s)                     0.00196185
time/training (s)                   1.98628
time/epoch (s)                      2.46992
time/total (s)                    846.408
Epoch                             344
-----------------------------  ---------------
2019-04-23 01:27:40.571817 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 345 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.580319
trainer/QF2 Loss                    0.463196
trainer/Policy Loss                57.1938
trainer/Q1 Predictions Mean       -55.4088
trainer/Q1 Predictions Std         48.6979
trainer/Q1 Predictions Max         -7.92087
trainer/Q1 Predictions Min       -163.077
trainer/Q2 Predictions Mean       -55.3842
trainer/Q2 Predictions Std         48.7408
trainer/Q2 Predictions Max         -7.93744
trainer/Q2 Predictions Min       -164.82
trainer/Q Targets Mean            -55.7021
trainer/Q Targets Std              49.1077
trainer/Q Targets Max              -8.08536
trainer/Q Targets Min            -166.966
trainer/Log Pis Mean                2.1481
trainer/Log Pis Std                 1.47387
trainer/Log Pis Max                 7.30765
trainer/Log Pis Min                -1.99935
trainer/Policy mu Mean             -0.157278
trainer/Policy mu Std               0.890291
trainer/Policy mu Max               3.31405
trainer/Policy mu Min              -3.30675
trainer/Policy log std Mean        -1.95954
trainer/Policy log std Std          0.618001
trainer/Policy log std Max         -0.429516
trainer/Policy log std Min         -2.98015
trainer/Alpha                       0.0616568
trainer/Alpha Loss                  0.412621
exploration/num steps total    173200
exploration/num paths total      1732
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.448915
exploration/Rewards Std             0.768307
exploration/Rewards Max            -0.00909614
exploration/Rewards Min            -7.22818
exploration/Returns Mean          -44.8915
exploration/Returns Std            19.5739
exploration/Returns Max           -21.3665
exploration/Returns Min           -80.0621
exploration/Actions Mean            0.00776859
exploration/Actions Std             0.20409
exploration/Actions Max             0.999793
exploration/Actions Min            -0.992272
exploration/Num Paths               5
exploration/Average Returns       -44.8915
evaluation/num steps total     519000
evaluation/num paths total       5190
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.59399
evaluation/Rewards Std              1.08045
evaluation/Rewards Max             -0.0208118
evaluation/Rewards Min             -9.21285
evaluation/Returns Mean           -59.399
evaluation/Returns Std             68.3842
evaluation/Returns Max            -10.3766
evaluation/Returns Min           -293.196
evaluation/Actions Mean             0.0138392
evaluation/Actions Std              0.170724
evaluation/Actions Max              0.999656
evaluation/Actions Min             -0.99948
evaluation/Num Paths               15
evaluation/Average Returns        -59.399
time/data storing (s)               0.00265684
time/evaluation sampling (s)        0.328562
time/exploration sampling (s)       0.138323
time/logging (s)                    0.00476166
time/saving (s)                     0.00194616
time/training (s)                   1.99192
time/epoch (s)                      2.46817
time/total (s)                    848.881
Epoch                             345
-----------------------------  ---------------
2019-04-23 01:27:43.051692 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 346 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.410306
trainer/QF2 Loss                    0.44164
trainer/Policy Loss                53.0581
trainer/Q1 Predictions Mean       -51.2712
trainer/Q1 Predictions Std         51.6749
trainer/Q1 Predictions Max         -8.02678
trainer/Q1 Predictions Min       -155.402
trainer/Q2 Predictions Mean       -51.236
trainer/Q2 Predictions Std         51.6089
trainer/Q2 Predictions Max         -8.04362
trainer/Q2 Predictions Min       -155.829
trainer/Q Targets Mean            -51.479
trainer/Q Targets Std              52.03
trainer/Q Targets Max              -8.12134
trainer/Q Targets Min            -157.754
trainer/Log Pis Mean                2.0925
trainer/Log Pis Std                 1.11834
trainer/Log Pis Max                 4.90568
trainer/Log Pis Min                -2.05509
trainer/Policy mu Mean             -0.172365
trainer/Policy mu Std               0.612439
trainer/Policy mu Max               1.55592
trainer/Policy mu Min              -3.47434
trainer/Policy log std Mean        -2.16126
trainer/Policy log std Std          0.493895
trainer/Policy log std Max         -0.15985
trainer/Policy log std Min         -3.0138
trainer/Alpha                       0.0581747
trainer/Alpha Loss                  0.263107
exploration/num steps total    173700
exploration/num paths total      1737
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.40025
exploration/Rewards Std             1.04384
exploration/Rewards Max            -0.0150689
exploration/Rewards Min           -10.4217
exploration/Returns Mean          -40.025
exploration/Returns Std            15.9591
exploration/Returns Max           -25.135
exploration/Returns Min           -60.7453
exploration/Actions Mean            0.0175935
exploration/Actions Std             0.222306
exploration/Actions Max             0.997721
exploration/Actions Min            -0.999326
exploration/Num Paths               5
exploration/Average Returns       -40.025
evaluation/num steps total     520500
evaluation/num paths total       5205
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.629672
evaluation/Rewards Std              1.13281
evaluation/Rewards Max             -0.0110787
evaluation/Rewards Min             -8.87065
evaluation/Returns Mean           -62.9672
evaluation/Returns Std             85.2108
evaluation/Returns Max             -3.66504
evaluation/Returns Min           -329.823
evaluation/Actions Mean            -0.00383012
evaluation/Actions Std              0.175623
evaluation/Actions Max              0.998647
evaluation/Actions Min             -0.99918
evaluation/Num Paths               15
evaluation/Average Returns        -62.9672
time/data storing (s)               0.00284408
time/evaluation sampling (s)        0.326884
time/exploration sampling (s)       0.139021
time/logging (s)                    0.00475554
time/saving (s)                     0.0101575
time/training (s)                   1.98639
time/epoch (s)                      2.47005
time/total (s)                    851.355
Epoch                             346
-----------------------------  ---------------
2019-04-23 01:27:45.487616 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 347 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                  214.554
trainer/QF2 Loss                  216.657
trainer/Policy Loss                46.0065
trainer/Q1 Predictions Mean       -44.1669
trainer/Q1 Predictions Std         43.9507
trainer/Q1 Predictions Max         -7.91618
trainer/Q1 Predictions Min       -153.693
trainer/Q2 Predictions Mean       -44.1473
trainer/Q2 Predictions Std         43.9251
trainer/Q2 Predictions Max         -7.92255
trainer/Q2 Predictions Min       -153.873
trainer/Q Targets Mean            -43.0686
trainer/Q Targets Std              43.3768
trainer/Q Targets Max              -0.108076
trainer/Q Targets Min            -155.301
trainer/Log Pis Mean                2.10871
trainer/Log Pis Std                 1.30332
trainer/Log Pis Max                 7.33976
trainer/Log Pis Min                -0.855398
trainer/Policy mu Mean             -0.0704404
trainer/Policy mu Std               0.792658
trainer/Policy mu Max               3.6665
trainer/Policy mu Min              -2.89626
trainer/Policy log std Mean        -2.01334
trainer/Policy log std Std          0.555149
trainer/Policy log std Max         -0.224103
trainer/Policy log std Min         -2.80037
trainer/Alpha                       0.0604811
trainer/Alpha Loss                  0.304953
exploration/num steps total    174200
exploration/num paths total      1742
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.636177
exploration/Rewards Std             0.803424
exploration/Rewards Max            -0.00623118
exploration/Rewards Min            -7.76279
exploration/Returns Mean          -63.6177
exploration/Returns Std            28.6348
exploration/Returns Max           -22.7428
exploration/Returns Min          -103.446
exploration/Actions Mean            0.0266011
exploration/Actions Std             0.218218
exploration/Actions Max             0.999756
exploration/Actions Min            -0.992666
exploration/Num Paths               5
exploration/Average Returns       -63.6177
evaluation/num steps total     522000
evaluation/num paths total       5220
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.601911
evaluation/Rewards Std              1.05223
evaluation/Rewards Max             -0.0196461
evaluation/Rewards Min             -8.61956
evaluation/Returns Mean           -60.1911
evaluation/Returns Std             53.2044
evaluation/Returns Max            -17.0674
evaluation/Returns Min           -234.412
evaluation/Actions Mean             0.0153342
evaluation/Actions Std              0.18179
evaluation/Actions Max              0.999743
evaluation/Actions Min             -0.996442
evaluation/Num Paths               15
evaluation/Average Returns        -60.1911
time/data storing (s)               0.00286286
time/evaluation sampling (s)        0.323367
time/exploration sampling (s)       0.140563
time/logging (s)                    0.00373556
time/saving (s)                     0.00175124
time/training (s)                   1.95333
time/epoch (s)                      2.42561
time/total (s)                    853.785
Epoch                             347
-----------------------------  ---------------
2019-04-23 01:27:47.943836 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 348 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   34.2514
trainer/QF2 Loss                   34.4689
trainer/Policy Loss                56.8377
trainer/Q1 Predictions Mean       -54.9623
trainer/Q1 Predictions Std         50.1406
trainer/Q1 Predictions Max         -7.83985
trainer/Q1 Predictions Min       -154.088
trainer/Q2 Predictions Mean       -54.9642
trainer/Q2 Predictions Std         50.0834
trainer/Q2 Predictions Max         -7.83078
trainer/Q2 Predictions Min       -154.481
trainer/Q Targets Mean            -54.905
trainer/Q Targets Std              50.9016
trainer/Q Targets Max              -1.47028
trainer/Q Targets Min            -156.317
trainer/Log Pis Mean                2.03745
trainer/Log Pis Std                 1.12978
trainer/Log Pis Max                 6.54545
trainer/Log Pis Min                -0.777688
trainer/Policy mu Mean             -0.00983154
trainer/Policy mu Std               0.694116
trainer/Policy mu Max               3.46153
trainer/Policy mu Min              -2.47758
trainer/Policy log std Mean        -2.03974
trainer/Policy log std Std          0.544346
trainer/Policy log std Max         -0.338045
trainer/Policy log std Min         -2.96305
trainer/Alpha                       0.0620442
trainer/Alpha Loss                  0.104102
exploration/num steps total    174700
exploration/num paths total      1747
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.19288
exploration/Rewards Std             1.05708
exploration/Rewards Max            -0.0146448
exploration/Rewards Min            -7.38849
exploration/Returns Mean         -119.288
exploration/Returns Std            77.5301
exploration/Returns Max           -16.8763
exploration/Returns Min          -211.262
exploration/Actions Mean           -0.0039924
exploration/Actions Std             0.214552
exploration/Actions Max             0.998808
exploration/Actions Min            -0.999019
exploration/Num Paths               5
exploration/Average Returns      -119.288
evaluation/num steps total     523500
evaluation/num paths total       5235
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.881426
evaluation/Rewards Std              1.21752
evaluation/Rewards Max             -0.0280579
evaluation/Rewards Min            -11.6179
evaluation/Returns Mean           -88.1426
evaluation/Returns Std             77.0214
evaluation/Returns Max            -15.7338
evaluation/Returns Min           -234.312
evaluation/Actions Mean            -0.00324264
evaluation/Actions Std              0.188475
evaluation/Actions Max              0.999689
evaluation/Actions Min             -0.999699
evaluation/Num Paths               15
evaluation/Average Returns        -88.1426
time/data storing (s)               0.00266664
time/evaluation sampling (s)        0.332986
time/exploration sampling (s)       0.138128
time/logging (s)                    0.00486936
time/saving (s)                     0.00194717
time/training (s)                   1.96868
time/epoch (s)                      2.44928
time/total (s)                    856.239
Epoch                             348
-----------------------------  ---------------
2019-04-23 01:27:50.413650 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 349 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.460771
trainer/QF2 Loss                    0.411606
trainer/Policy Loss                49.2879
trainer/Q1 Predictions Mean       -47.4764
trainer/Q1 Predictions Std         50.526
trainer/Q1 Predictions Max         -7.92393
trainer/Q1 Predictions Min       -156.041
trainer/Q2 Predictions Mean       -47.4963
trainer/Q2 Predictions Std         50.5091
trainer/Q2 Predictions Max         -8.0403
trainer/Q2 Predictions Min       -155.877
trainer/Q Targets Mean            -47.8833
trainer/Q Targets Std              50.8923
trainer/Q Targets Max              -8.09375
trainer/Q Targets Min            -155.743
trainer/Log Pis Mean                2.02626
trainer/Log Pis Std                 1.10866
trainer/Log Pis Max                 5.97163
trainer/Log Pis Min                -1.5742
trainer/Policy mu Mean             -0.138934
trainer/Policy mu Std               0.580049
trainer/Policy mu Max               2.15712
trainer/Policy mu Min              -2.73753
trainer/Policy log std Mean        -2.14251
trainer/Policy log std Std          0.495051
trainer/Policy log std Max         -0.0843703
trainer/Policy log std Min         -2.91824
trainer/Alpha                       0.0630971
trainer/Alpha Loss                  0.0725731
exploration/num steps total    175200
exploration/num paths total      1752
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.966164
exploration/Rewards Std             1.04247
exploration/Rewards Max            -0.0100643
exploration/Rewards Min            -8.84982
exploration/Returns Mean          -96.6164
exploration/Returns Std            86.808
exploration/Returns Max           -21.5367
exploration/Returns Min          -213.49
exploration/Actions Mean           -0.0101525
exploration/Actions Std             0.212599
exploration/Actions Max             0.998152
exploration/Actions Min            -0.994377
exploration/Num Paths               5
exploration/Average Returns       -96.6164
evaluation/num steps total     525000
evaluation/num paths total       5250
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.958944
evaluation/Rewards Std              1.18969
evaluation/Rewards Max             -0.00746208
evaluation/Rewards Min            -10.0604
evaluation/Returns Mean           -95.8944
evaluation/Returns Std             87.0372
evaluation/Returns Max             -7.49858
evaluation/Returns Min           -282.658
evaluation/Actions Mean            -0.00308294
evaluation/Actions Std              0.172342
evaluation/Actions Max              0.996333
evaluation/Actions Min             -0.999747
evaluation/Num Paths               15
evaluation/Average Returns        -95.8944
time/data storing (s)               0.00281417
time/evaluation sampling (s)        0.327311
time/exploration sampling (s)       0.138858
time/logging (s)                    0.00475277
time/saving (s)                     0.00194343
time/training (s)                   1.98383
time/epoch (s)                      2.45951
time/total (s)                    858.704
Epoch                             349
-----------------------------  ---------------
2019-04-23 01:27:52.849056 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 350 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                  120.317
trainer/QF2 Loss                  121.579
trainer/Policy Loss                54.4402
trainer/Q1 Predictions Mean       -52.769
trainer/Q1 Predictions Std         48.0904
trainer/Q1 Predictions Max         -8.14594
trainer/Q1 Predictions Min       -152.649
trainer/Q2 Predictions Mean       -52.7831
trainer/Q2 Predictions Std         48.1224
trainer/Q2 Predictions Max         -8.10843
trainer/Q2 Predictions Min       -151.81
trainer/Q Targets Mean            -51.9245
trainer/Q Targets Std              48.8695
trainer/Q Targets Max              -0.117366
trainer/Q Targets Min            -155.14
trainer/Log Pis Mean                1.91272
trainer/Log Pis Std                 1.56608
trainer/Log Pis Max                 7.92746
trainer/Log Pis Min                -3.41893
trainer/Policy mu Mean             -0.114091
trainer/Policy mu Std               0.685923
trainer/Policy mu Max               2.77193
trainer/Policy mu Min              -4.41899
trainer/Policy log std Mean        -2.09257
trainer/Policy log std Std          0.478395
trainer/Policy log std Max         -0.092813
trainer/Policy log std Min         -2.94227
trainer/Alpha                       0.0635002
trainer/Alpha Loss                 -0.240592
exploration/num steps total    175700
exploration/num paths total      1757
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.721254
exploration/Rewards Std             1.15634
exploration/Rewards Max            -0.0110492
exploration/Rewards Min            -9.49754
exploration/Returns Mean          -72.1254
exploration/Returns Std            68.9508
exploration/Returns Max           -19.7155
exploration/Returns Min          -207.364
exploration/Actions Mean            0.0200688
exploration/Actions Std             0.241804
exploration/Actions Max             0.999757
exploration/Actions Min            -0.99118
exploration/Num Paths               5
exploration/Average Returns       -72.1254
evaluation/num steps total     526500
evaluation/num paths total       5265
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.824706
evaluation/Rewards Std              1.16429
evaluation/Rewards Max             -0.0328141
evaluation/Rewards Min             -9.96905
evaluation/Returns Mean           -82.4706
evaluation/Returns Std             58.9104
evaluation/Returns Max            -11.6346
evaluation/Returns Min           -219.833
evaluation/Actions Mean             0.0016684
evaluation/Actions Std              0.192863
evaluation/Actions Max              0.99952
evaluation/Actions Min             -0.998754
evaluation/Num Paths               15
evaluation/Average Returns        -82.4706
time/data storing (s)               0.00266713
time/evaluation sampling (s)        0.329629
time/exploration sampling (s)       0.137996
time/logging (s)                    0.00480578
time/saving (s)                     0.00163569
time/training (s)                   1.94914
time/epoch (s)                      2.42587
time/total (s)                    861.134
Epoch                             350
-----------------------------  ---------------
2019-04-23 01:27:55.317604 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 351 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                  220.029
trainer/QF2 Loss                  219.139
trainer/Policy Loss                57.8747
trainer/Q1 Predictions Mean       -56.1048
trainer/Q1 Predictions Std         52.9262
trainer/Q1 Predictions Max         -8.02628
trainer/Q1 Predictions Min       -156.172
trainer/Q2 Predictions Mean       -56.1125
trainer/Q2 Predictions Std         52.8114
trainer/Q2 Predictions Max         -8.0321
trainer/Q2 Predictions Min       -156.905
trainer/Q Targets Mean            -54.7016
trainer/Q Targets Std              52.3175
trainer/Q Targets Max              -2.62344
trainer/Q Targets Min            -155.764
trainer/Log Pis Mean                2.12966
trainer/Log Pis Std                 1.49367
trainer/Log Pis Max                 8.09311
trainer/Log Pis Min                -1.40026
trainer/Policy mu Mean             -0.226968
trainer/Policy mu Std               0.847771
trainer/Policy mu Max               3.33783
trainer/Policy mu Min              -3.96551
trainer/Policy log std Mean        -1.98419
trainer/Policy log std Std          0.570445
trainer/Policy log std Max         -0.285679
trainer/Policy log std Min         -2.86845
trainer/Alpha                       0.0642489
trainer/Alpha Loss                  0.355944
exploration/num steps total    176200
exploration/num paths total      1762
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.813627
exploration/Rewards Std             1.0583
exploration/Rewards Max            -0.0122148
exploration/Rewards Min            -9.32747
exploration/Returns Mean          -81.3627
exploration/Returns Std            78.0793
exploration/Returns Max           -13.1125
exploration/Returns Min          -201.559
exploration/Actions Mean           -0.00314285
exploration/Actions Std             0.213316
exploration/Actions Max             0.999483
exploration/Actions Min            -0.996922
exploration/Num Paths               5
exploration/Average Returns       -81.3627
evaluation/num steps total     528000
evaluation/num paths total       5280
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.642395
evaluation/Rewards Std              1.10203
evaluation/Rewards Max             -0.0209502
evaluation/Rewards Min             -9.82125
evaluation/Returns Mean           -64.2395
evaluation/Returns Std             73.4818
evaluation/Returns Max             -9.1796
evaluation/Returns Min           -217.131
evaluation/Actions Mean            -0.00178286
evaluation/Actions Std              0.182847
evaluation/Actions Max              0.998183
evaluation/Actions Min             -0.999598
evaluation/Num Paths               15
evaluation/Average Returns        -64.2395
time/data storing (s)               0.00274378
time/evaluation sampling (s)        0.333496
time/exploration sampling (s)       0.140942
time/logging (s)                    0.00483744
time/saving (s)                     0.00194756
time/training (s)                   1.97493
time/epoch (s)                      2.4589
time/total (s)                    863.598
Epoch                             351
-----------------------------  ---------------
2019-04-23 01:27:57.772151 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 352 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.10178
trainer/QF2 Loss                    1.08844
trainer/Policy Loss                50.6857
trainer/Q1 Predictions Mean       -49.1826
trainer/Q1 Predictions Std         48.3397
trainer/Q1 Predictions Max         -8.03869
trainer/Q1 Predictions Min       -153.639
trainer/Q2 Predictions Mean       -49.2215
trainer/Q2 Predictions Std         48.3688
trainer/Q2 Predictions Max         -8.0513
trainer/Q2 Predictions Min       -153.199
trainer/Q Targets Mean            -49.301
trainer/Q Targets Std              48.5834
trainer/Q Targets Max              -0.276489
trainer/Q Targets Min            -154.91
trainer/Log Pis Mean                1.67971
trainer/Log Pis Std                 1.35099
trainer/Log Pis Max                 5.08829
trainer/Log Pis Min                -1.74014
trainer/Policy mu Mean              0.0663247
trainer/Policy mu Std               0.588898
trainer/Policy mu Max               3.04993
trainer/Policy mu Min              -2.80444
trainer/Policy log std Mean        -2.10066
trainer/Policy log std Std          0.472493
trainer/Policy log std Max         -0.52215
trainer/Policy log std Min         -2.93327
trainer/Alpha                       0.06333
trainer/Alpha Loss                 -0.88377
exploration/num steps total    176700
exploration/num paths total      1767
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.25675
exploration/Rewards Std             1.30749
exploration/Rewards Max            -0.00863544
exploration/Rewards Min            -7.72059
exploration/Returns Mean         -125.675
exploration/Returns Std           103.038
exploration/Returns Max           -32.2071
exploration/Returns Min          -271.054
exploration/Actions Mean           -0.0109827
exploration/Actions Std             0.232961
exploration/Actions Max             0.998156
exploration/Actions Min            -0.998461
exploration/Num Paths               5
exploration/Average Returns      -125.675
evaluation/num steps total     529500
evaluation/num paths total       5295
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.830667
evaluation/Rewards Std              0.904053
evaluation/Rewards Max             -0.0136189
evaluation/Rewards Min             -6.70631
evaluation/Returns Mean           -83.0667
evaluation/Returns Std             69.2319
evaluation/Returns Max            -11.2404
evaluation/Returns Min           -195.637
evaluation/Actions Mean             0.00653145
evaluation/Actions Std              0.164736
evaluation/Actions Max              0.999306
evaluation/Actions Min             -0.999166
evaluation/Num Paths               15
evaluation/Average Returns        -83.0667
time/data storing (s)               0.00283496
time/evaluation sampling (s)        0.322103
time/exploration sampling (s)       0.138357
time/logging (s)                    0.00495831
time/saving (s)                     0.0019304
time/training (s)                   1.97477
time/epoch (s)                      2.44495
time/total (s)                    866.047
Epoch                             352
-----------------------------  ---------------
2019-04-23 01:28:00.237549 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 353 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    2.40459
trainer/QF2 Loss                    2.64767
trainer/Policy Loss                58.6491
trainer/Q1 Predictions Mean       -57.0714
trainer/Q1 Predictions Std         50.5129
trainer/Q1 Predictions Max         -8.16657
trainer/Q1 Predictions Min       -151.689
trainer/Q2 Predictions Mean       -57.0236
trainer/Q2 Predictions Std         50.459
trainer/Q2 Predictions Max         -8.13848
trainer/Q2 Predictions Min       -150.92
trainer/Q Targets Mean            -58.0906
trainer/Q Targets Std              51.4265
trainer/Q Targets Max              -8.12938
trainer/Q Targets Min            -155.353
trainer/Log Pis Mean                1.85913
trainer/Log Pis Std                 1.0764
trainer/Log Pis Max                 6.00326
trainer/Log Pis Min                -1.19509
trainer/Policy mu Mean             -0.122416
trainer/Policy mu Std               0.695558
trainer/Policy mu Max               2.49155
trainer/Policy mu Min              -3.42787
trainer/Policy log std Mean        -2.04036
trainer/Policy log std Std          0.559941
trainer/Policy log std Max         -0.342683
trainer/Policy log std Min         -2.92877
trainer/Alpha                       0.0611964
trainer/Alpha Loss                 -0.393535
exploration/num steps total    177200
exploration/num paths total      1772
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.56353
exploration/Rewards Std             1.22142
exploration/Rewards Max            -0.00584661
exploration/Rewards Min            -9.97958
exploration/Returns Mean          -56.353
exploration/Returns Std            25.6551
exploration/Returns Max           -19.0164
exploration/Returns Min           -91.7703
exploration/Actions Mean           -0.00675938
exploration/Actions Std             0.226416
exploration/Actions Max             0.999851
exploration/Actions Min            -0.998835
exploration/Num Paths               5
exploration/Average Returns       -56.353
evaluation/num steps total     531000
evaluation/num paths total       5310
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.830093
evaluation/Rewards Std              1.21448
evaluation/Rewards Max             -0.0349731
evaluation/Rewards Min             -9.84684
evaluation/Returns Mean           -83.0093
evaluation/Returns Std             90.4053
evaluation/Returns Max             -5.81338
evaluation/Returns Min           -292.015
evaluation/Actions Mean             0.000684733
evaluation/Actions Std              0.180618
evaluation/Actions Max              0.998844
evaluation/Actions Min             -0.99628
evaluation/Num Paths               15
evaluation/Average Returns        -83.0093
time/data storing (s)               0.00272521
time/evaluation sampling (s)        0.328583
time/exploration sampling (s)       0.135631
time/logging (s)                    0.00477205
time/saving (s)                     0.00155698
time/training (s)                   1.98224
time/epoch (s)                      2.45551
time/total (s)                    868.507
Epoch                             353
-----------------------------  ----------------
2019-04-23 01:28:02.710078 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 354 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.72059
trainer/QF2 Loss                    1.87298
trainer/Policy Loss                53.8187
trainer/Q1 Predictions Mean       -51.8973
trainer/Q1 Predictions Std         49.876
trainer/Q1 Predictions Max         -7.96676
trainer/Q1 Predictions Min       -153.856
trainer/Q2 Predictions Mean       -51.8613
trainer/Q2 Predictions Std         49.8608
trainer/Q2 Predictions Max         -7.93788
trainer/Q2 Predictions Min       -154.484
trainer/Q Targets Mean            -52.8123
trainer/Q Targets Std              50.6999
trainer/Q Targets Max              -8.06176
trainer/Q Targets Min            -157.12
trainer/Log Pis Mean                2.15505
trainer/Log Pis Std                 1.1403
trainer/Log Pis Max                 9.07519
trainer/Log Pis Min                -0.213198
trainer/Policy mu Mean              0.0664963
trainer/Policy mu Std               0.611384
trainer/Policy mu Max               3.11282
trainer/Policy mu Min              -2.63007
trainer/Policy log std Mean        -2.15007
trainer/Policy log std Std          0.482666
trainer/Policy log std Max         -0.542861
trainer/Policy log std Min         -3.05571
trainer/Alpha                       0.059841
trainer/Alpha Loss                  0.436648
exploration/num steps total    177700
exploration/num paths total      1777
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.77008
exploration/Rewards Std             1.20405
exploration/Rewards Max            -0.00922501
exploration/Rewards Min            -3.2211
exploration/Returns Mean         -177.008
exploration/Returns Std           117.599
exploration/Returns Max           -12.2
exploration/Returns Min          -273.143
exploration/Actions Mean            0.00117211
exploration/Actions Std             0.247421
exploration/Actions Max             0.991136
exploration/Actions Min            -0.956318
exploration/Num Paths               5
exploration/Average Returns      -177.008
evaluation/num steps total     532500
evaluation/num paths total       5325
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.13077
evaluation/Rewards Std              1.35759
evaluation/Rewards Max             -0.00785641
evaluation/Rewards Min             -9.97967
evaluation/Returns Mean          -113.077
evaluation/Returns Std             97.6722
evaluation/Returns Max             -2.25794
evaluation/Returns Min           -284.391
evaluation/Actions Mean             0.0143808
evaluation/Actions Std              0.196803
evaluation/Actions Max              0.999071
evaluation/Actions Min             -0.997042
evaluation/Num Paths               15
evaluation/Average Returns       -113.077
time/data storing (s)               0.00274244
time/evaluation sampling (s)        0.330574
time/exploration sampling (s)       0.136513
time/logging (s)                    0.00477869
time/saving (s)                     0.00196541
time/training (s)                   1.9863
time/epoch (s)                      2.46287
time/total (s)                    870.974
Epoch                             354
-----------------------------  ---------------
2019-04-23 01:28:05.163094 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 355 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.917732
trainer/QF2 Loss                    0.89522
trainer/Policy Loss                42.6117
trainer/Q1 Predictions Mean       -40.9247
trainer/Q1 Predictions Std         41.5501
trainer/Q1 Predictions Max         -8.0544
trainer/Q1 Predictions Min       -153.453
trainer/Q2 Predictions Mean       -40.9273
trainer/Q2 Predictions Std         41.6009
trainer/Q2 Predictions Max         -8.09896
trainer/Q2 Predictions Min       -154.781
trainer/Q Targets Mean            -40.9928
trainer/Q Targets Std              41.8315
trainer/Q Targets Max              -0.105198
trainer/Q Targets Min            -155.517
trainer/Log Pis Mean                1.89096
trainer/Log Pis Std                 1.41447
trainer/Log Pis Max                 7.73565
trainer/Log Pis Min                -2.64565
trainer/Policy mu Mean              0.0991426
trainer/Policy mu Std               0.547074
trainer/Policy mu Max               2.85489
trainer/Policy mu Min              -2.8448
trainer/Policy log std Mean        -2.21256
trainer/Policy log std Std          0.427829
trainer/Policy log std Max         -0.408109
trainer/Policy log std Min         -3.01596
trainer/Alpha                       0.058144
trainer/Alpha Loss                 -0.310202
exploration/num steps total    178200
exploration/num paths total      1782
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.559244
exploration/Rewards Std             1.33088
exploration/Rewards Max            -0.0155465
exploration/Rewards Min           -11.1852
exploration/Returns Mean          -55.9244
exploration/Returns Std            28.9182
exploration/Returns Max           -15.5798
exploration/Returns Min           -99.5413
exploration/Actions Mean            0.00583471
exploration/Actions Std             0.23399
exploration/Actions Max             0.999892
exploration/Actions Min            -0.99911
exploration/Num Paths               5
exploration/Average Returns       -55.9244
evaluation/num steps total     534000
evaluation/num paths total       5340
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.951135
evaluation/Rewards Std              1.33247
evaluation/Rewards Max             -0.0369746
evaluation/Rewards Min             -9.46034
evaluation/Returns Mean           -95.1135
evaluation/Returns Std            103.27
evaluation/Returns Max             -8.20626
evaluation/Returns Min           -318.214
evaluation/Actions Mean            -0.0140623
evaluation/Actions Std              0.170594
evaluation/Actions Max              0.997844
evaluation/Actions Min             -0.999428
evaluation/Num Paths               15
evaluation/Average Returns        -95.1135
time/data storing (s)               0.00300125
time/evaluation sampling (s)        0.326925
time/exploration sampling (s)       0.140228
time/logging (s)                    0.00473972
time/saving (s)                     0.00153181
time/training (s)                   1.96672
time/epoch (s)                      2.44315
time/total (s)                    873.422
Epoch                             355
-----------------------------  ---------------
2019-04-23 01:28:07.627986 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 356 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.158324
trainer/QF2 Loss                    0.164687
trainer/Policy Loss                35.3809
trainer/Q1 Predictions Mean       -33.4176
trainer/Q1 Predictions Std         36.1759
trainer/Q1 Predictions Max         -8.01183
trainer/Q1 Predictions Min       -158.972
trainer/Q2 Predictions Mean       -33.4483
trainer/Q2 Predictions Std         36.1888
trainer/Q2 Predictions Max         -8.0358
trainer/Q2 Predictions Min       -159.06
trainer/Q Targets Mean            -33.5951
trainer/Q Targets Std              36.2822
trainer/Q Targets Max              -8.05047
trainer/Q Targets Min            -159.261
trainer/Log Pis Mean                2.10164
trainer/Log Pis Std                 1.02372
trainer/Log Pis Max                 6.59366
trainer/Log Pis Min                -0.695264
trainer/Policy mu Mean             -0.0533581
trainer/Policy mu Std               0.573489
trainer/Policy mu Max               2.33376
trainer/Policy mu Min              -2.76687
trainer/Policy log std Mean        -2.16893
trainer/Policy log std Std          0.497415
trainer/Policy log std Max         -0.227106
trainer/Policy log std Min         -2.88036
trainer/Alpha                       0.0592926
trainer/Alpha Loss                  0.287174
exploration/num steps total    178700
exploration/num paths total      1787
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.14544
exploration/Rewards Std             1.07274
exploration/Rewards Max            -0.0174922
exploration/Rewards Min            -9.4749
exploration/Returns Mean         -114.544
exploration/Returns Std            70.6383
exploration/Returns Max           -20.8117
exploration/Returns Min          -204.56
exploration/Actions Mean           -0.00815179
exploration/Actions Std             0.259235
exploration/Actions Max             0.994238
exploration/Actions Min            -0.99951
exploration/Num Paths               5
exploration/Average Returns      -114.544
evaluation/num steps total     535500
evaluation/num paths total       5355
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.513986
evaluation/Rewards Std              0.956793
evaluation/Rewards Max             -0.0186478
evaluation/Rewards Min             -9.1706
evaluation/Returns Mean           -51.3986
evaluation/Returns Std             60.0949
evaluation/Returns Max             -2.61045
evaluation/Returns Min           -187.998
evaluation/Actions Mean             0.0106027
evaluation/Actions Std              0.164799
evaluation/Actions Max              0.999346
evaluation/Actions Min             -0.99824
evaluation/Num Paths               15
evaluation/Average Returns        -51.3986
time/data storing (s)               0.00264223
time/evaluation sampling (s)        0.32325
time/exploration sampling (s)       0.145294
time/logging (s)                    0.00482128
time/saving (s)                     0.00192991
time/training (s)                   1.97734
time/epoch (s)                      2.45528
time/total (s)                    875.882
Epoch                             356
-----------------------------  ---------------
2019-04-23 01:28:10.098157 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 357 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   62.6558
trainer/QF2 Loss                   61.5449
trainer/Policy Loss                46.1114
trainer/Q1 Predictions Mean       -44.4424
trainer/Q1 Predictions Std         45.5849
trainer/Q1 Predictions Max         -7.88457
trainer/Q1 Predictions Min       -151.163
trainer/Q2 Predictions Mean       -44.468
trainer/Q2 Predictions Std         45.589
trainer/Q2 Predictions Max         -7.93165
trainer/Q2 Predictions Min       -151.34
trainer/Q Targets Mean            -43.8761
trainer/Q Targets Std              46.0652
trainer/Q Targets Max              -0.232732
trainer/Q Targets Min            -152.427
trainer/Log Pis Mean                1.88873
trainer/Log Pis Std                 1.08749
trainer/Log Pis Max                 4.347
trainer/Log Pis Min                -1.65379
trainer/Policy mu Mean             -0.0219902
trainer/Policy mu Std               0.578153
trainer/Policy mu Max               2.87258
trainer/Policy mu Min              -2.63026
trainer/Policy log std Mean        -2.14196
trainer/Policy log std Std          0.445063
trainer/Policy log std Max         -0.574369
trainer/Policy log std Min         -2.85553
trainer/Alpha                       0.0600318
trainer/Alpha Loss                 -0.312982
exploration/num steps total    179200
exploration/num paths total      1792
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.98856
exploration/Rewards Std             1.38323
exploration/Rewards Max            -0.0091455
exploration/Rewards Min            -9.87122
exploration/Returns Mean          -98.856
exploration/Returns Std            99.106
exploration/Returns Max           -14.2607
exploration/Returns Min          -278.015
exploration/Actions Mean           -0.0010928
exploration/Actions Std             0.205173
exploration/Actions Max             0.999728
exploration/Actions Min            -0.998169
exploration/Num Paths               5
exploration/Average Returns       -98.856
evaluation/num steps total     537000
evaluation/num paths total       5370
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.34595
evaluation/Rewards Std              1.47891
evaluation/Rewards Max             -0.00485941
evaluation/Rewards Min            -10.6411
evaluation/Returns Mean          -134.595
evaluation/Returns Std             94.8686
evaluation/Returns Max            -33.0841
evaluation/Returns Min           -292.062
evaluation/Actions Mean             0.0149806
evaluation/Actions Std              0.204292
evaluation/Actions Max              0.998991
evaluation/Actions Min             -0.999674
evaluation/Num Paths               15
evaluation/Average Returns       -134.595
time/data storing (s)               0.00269094
time/evaluation sampling (s)        0.322491
time/exploration sampling (s)       0.139209
time/logging (s)                    0.00487775
time/saving (s)                     0.00194228
time/training (s)                   1.98925
time/epoch (s)                      2.46046
time/total (s)                    878.347
Epoch                             357
-----------------------------  ---------------
2019-04-23 01:28:12.578811 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 358 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                  214.595
trainer/QF2 Loss                  214.048
trainer/Policy Loss                48.5079
trainer/Q1 Predictions Mean       -46.9205
trainer/Q1 Predictions Std         45.1566
trainer/Q1 Predictions Max         -7.93148
trainer/Q1 Predictions Min       -154.412
trainer/Q2 Predictions Mean       -46.8934
trainer/Q2 Predictions Std         45.0963
trainer/Q2 Predictions Max         -7.97789
trainer/Q2 Predictions Min       -154.118
trainer/Q Targets Mean            -45.4292
trainer/Q Targets Std              44.3272
trainer/Q Targets Max              -2.68701
trainer/Q Targets Min            -155.687
trainer/Log Pis Mean                1.83155
trainer/Log Pis Std                 1.14911
trainer/Log Pis Max                 5.53045
trainer/Log Pis Min                -2.05079
trainer/Policy mu Mean              0.0446925
trainer/Policy mu Std               0.553619
trainer/Policy mu Max               3.02825
trainer/Policy mu Min              -3.36593
trainer/Policy log std Mean        -2.11317
trainer/Policy log std Std          0.461841
trainer/Policy log std Max         -0.383711
trainer/Policy log std Min         -2.75042
trainer/Alpha                       0.0582964
trainer/Alpha Loss                 -0.478748
exploration/num steps total    179700
exploration/num paths total      1797
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.72218
exploration/Rewards Std             1.42976
exploration/Rewards Max            -0.0180643
exploration/Rewards Min            -9.61066
exploration/Returns Mean         -172.218
exploration/Returns Std           113.802
exploration/Returns Max           -33.3399
exploration/Returns Min          -314.259
exploration/Actions Mean           -0.0210353
exploration/Actions Std             0.223166
exploration/Actions Max             0.998874
exploration/Actions Min            -0.998739
exploration/Num Paths               5
exploration/Average Returns      -172.218
evaluation/num steps total     538500
evaluation/num paths total       5385
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.759532
evaluation/Rewards Std              1.20809
evaluation/Rewards Max             -0.0239924
evaluation/Rewards Min            -10.421
evaluation/Returns Mean           -75.9532
evaluation/Returns Std             98.5433
evaluation/Returns Max             -3.01306
evaluation/Returns Min           -327.618
evaluation/Actions Mean            -0.00811721
evaluation/Actions Std              0.174145
evaluation/Actions Max              0.994957
evaluation/Actions Min             -0.996481
evaluation/Num Paths               15
evaluation/Average Returns        -75.9532
time/data storing (s)               0.00277843
time/evaluation sampling (s)        0.33118
time/exploration sampling (s)       0.139969
time/logging (s)                    0.00495123
time/saving (s)                     0.0107338
time/training (s)                   1.98131
time/epoch (s)                      2.47092
time/total (s)                    880.822
Epoch                             358
-----------------------------  ---------------
2019-04-23 01:28:15.043698 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 359 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.190303
trainer/QF2 Loss                    0.184858
trainer/Policy Loss                49.2221
trainer/Q1 Predictions Mean       -47.5938
trainer/Q1 Predictions Std         44.6777
trainer/Q1 Predictions Max         -8.04668
trainer/Q1 Predictions Min       -151.736
trainer/Q2 Predictions Mean       -47.5939
trainer/Q2 Predictions Std         44.6878
trainer/Q2 Predictions Max         -8.06138
trainer/Q2 Predictions Min       -151.494
trainer/Q Targets Mean            -47.8111
trainer/Q Targets Std              44.845
trainer/Q Targets Max              -7.92708
trainer/Q Targets Min            -152.68
trainer/Log Pis Mean                1.85959
trainer/Log Pis Std                 1.37118
trainer/Log Pis Max                 8.11307
trainer/Log Pis Min                -1.56844
trainer/Policy mu Mean             -0.0390835
trainer/Policy mu Std               0.647423
trainer/Policy mu Max               2.24713
trainer/Policy mu Min              -3.34301
trainer/Policy log std Mean        -2.11068
trainer/Policy log std Std          0.47311
trainer/Policy log std Max         -0.39511
trainer/Policy log std Min         -2.89833
trainer/Alpha                       0.0585008
trainer/Alpha Loss                 -0.39859
exploration/num steps total    180200
exploration/num paths total      1802
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.69929
exploration/Rewards Std             0.889319
exploration/Rewards Max            -0.511949
exploration/Rewards Min            -7.84146
exploration/Returns Mean         -169.929
exploration/Returns Std            77.0644
exploration/Returns Max           -78.6428
exploration/Returns Min          -292.982
exploration/Actions Mean           -0.0162977
exploration/Actions Std             0.224868
exploration/Actions Max             0.992531
exploration/Actions Min            -0.997017
exploration/Num Paths               5
exploration/Average Returns      -169.929
evaluation/num steps total     540000
evaluation/num paths total       5400
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.644203
evaluation/Rewards Std              1.13706
evaluation/Rewards Max             -0.0558277
evaluation/Rewards Min             -9.06765
evaluation/Returns Mean           -64.4203
evaluation/Returns Std             86.9964
evaluation/Returns Max            -15.0901
evaluation/Returns Min           -280.12
evaluation/Actions Mean             0.00313092
evaluation/Actions Std              0.166743
evaluation/Actions Max              0.999721
evaluation/Actions Min             -0.997439
evaluation/Num Paths               15
evaluation/Average Returns        -64.4203
time/data storing (s)               0.00310936
time/evaluation sampling (s)        0.321324
time/exploration sampling (s)       0.140499
time/logging (s)                    0.00475876
time/saving (s)                     0.00196061
time/training (s)                   1.98389
time/epoch (s)                      2.45554
time/total (s)                    883.282
Epoch                             359
-----------------------------  ---------------
2019-04-23 01:28:17.487755 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 360 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.46374
trainer/QF2 Loss                    1.55352
trainer/Policy Loss                50.0387
trainer/Q1 Predictions Mean       -48.1856
trainer/Q1 Predictions Std         46.7179
trainer/Q1 Predictions Max         -7.93035
trainer/Q1 Predictions Min       -154.566
trainer/Q2 Predictions Mean       -48.1914
trainer/Q2 Predictions Std         46.7213
trainer/Q2 Predictions Max         -7.92247
trainer/Q2 Predictions Min       -154.726
trainer/Q Targets Mean            -48.3246
trainer/Q Targets Std              47.0616
trainer/Q Targets Max              -0.128629
trainer/Q Targets Min            -155.381
trainer/Log Pis Mean                2.09362
trainer/Log Pis Std                 1.39111
trainer/Log Pis Max                 7.96167
trainer/Log Pis Min                -1.74855
trainer/Policy mu Mean             -0.146464
trainer/Policy mu Std               0.768956
trainer/Policy mu Max               3.27161
trainer/Policy mu Min              -4.54936
trainer/Policy log std Mean        -2.08407
trainer/Policy log std Std          0.529949
trainer/Policy log std Max          0.0816131
trainer/Policy log std Min         -2.795
trainer/Alpha                       0.0600773
trainer/Alpha Loss                  0.263265
exploration/num steps total    180700
exploration/num paths total      1807
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.833581
exploration/Rewards Std             0.952147
exploration/Rewards Max            -0.0122095
exploration/Rewards Min            -8.0807
exploration/Returns Mean          -83.3581
exploration/Returns Std            81.5037
exploration/Returns Max           -14.1247
exploration/Returns Min          -195.599
exploration/Actions Mean           -0.00869422
exploration/Actions Std             0.192144
exploration/Actions Max             0.983815
exploration/Actions Min            -0.999949
exploration/Num Paths               5
exploration/Average Returns       -83.3581
evaluation/num steps total     541500
evaluation/num paths total       5415
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.553933
evaluation/Rewards Std              1.01668
evaluation/Rewards Max             -0.0299293
evaluation/Rewards Min             -9.46712
evaluation/Returns Mean           -55.3933
evaluation/Returns Std             47.7563
evaluation/Returns Max             -3.84237
evaluation/Returns Min           -187.531
evaluation/Actions Mean            -0.0015365
evaluation/Actions Std              0.173724
evaluation/Actions Max              0.999455
evaluation/Actions Min             -0.999349
evaluation/Num Paths               15
evaluation/Average Returns        -55.3933
time/data storing (s)               0.00276067
time/evaluation sampling (s)        0.329135
time/exploration sampling (s)       0.139139
time/logging (s)                    0.00474446
time/saving (s)                     0.00154194
time/training (s)                   1.95658
time/epoch (s)                      2.4339
time/total (s)                    885.72
Epoch                             360
-----------------------------  ---------------
2019-04-23 01:28:19.937266 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 361 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.555111
trainer/QF2 Loss                    0.510239
trainer/Policy Loss                43.4879
trainer/Q1 Predictions Mean       -41.5934
trainer/Q1 Predictions Std         44.3112
trainer/Q1 Predictions Max         -7.70428
trainer/Q1 Predictions Min       -152.388
trainer/Q2 Predictions Mean       -41.62
trainer/Q2 Predictions Std         44.3315
trainer/Q2 Predictions Max         -7.79162
trainer/Q2 Predictions Min       -152.381
trainer/Q Targets Mean            -42.014
trainer/Q Targets Std              44.634
trainer/Q Targets Max              -7.95765
trainer/Q Targets Min            -152.971
trainer/Log Pis Mean                2.1008
trainer/Log Pis Std                 1.13416
trainer/Log Pis Max                 6.26697
trainer/Log Pis Min                -1.65588
trainer/Policy mu Mean             -0.0607208
trainer/Policy mu Std               0.559859
trainer/Policy mu Max               2.60141
trainer/Policy mu Min              -2.71673
trainer/Policy log std Mean        -2.17055
trainer/Policy log std Std          0.446966
trainer/Policy log std Max         -0.550351
trainer/Policy log std Min         -2.88813
trainer/Alpha                       0.0595002
trainer/Alpha Loss                  0.28444
exploration/num steps total    181200
exploration/num paths total      1812
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.52901
exploration/Rewards Std             0.731507
exploration/Rewards Max            -0.255072
exploration/Rewards Min            -5.53598
exploration/Returns Mean         -152.901
exploration/Returns Std            63.0716
exploration/Returns Max           -48.8598
exploration/Returns Min          -218.118
exploration/Actions Mean            0.00167632
exploration/Actions Std             0.209142
exploration/Actions Max             0.985604
exploration/Actions Min            -0.9753
exploration/Num Paths               5
exploration/Average Returns      -152.901
evaluation/num steps total     543000
evaluation/num paths total       5430
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.0713
evaluation/Rewards Std              1.21209
evaluation/Rewards Max             -0.00936461
evaluation/Rewards Min             -9.33043
evaluation/Returns Mean          -107.13
evaluation/Returns Std             88.8802
evaluation/Returns Max            -10.8676
evaluation/Returns Min           -280.362
evaluation/Actions Mean            -0.00883662
evaluation/Actions Std              0.171173
evaluation/Actions Max              0.98934
evaluation/Actions Min             -0.999409
evaluation/Num Paths               15
evaluation/Average Returns       -107.13
time/data storing (s)               0.00260424
time/evaluation sampling (s)        0.331537
time/exploration sampling (s)       0.137091
time/logging (s)                    0.00420296
time/saving (s)                     0.0019157
time/training (s)                   1.96193
time/epoch (s)                      2.43928
time/total (s)                    888.164
Epoch                             361
-----------------------------  ---------------
2019-04-23 01:28:22.385486 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 362 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                  113.723
trainer/QF2 Loss                  113.071
trainer/Policy Loss                52.1753
trainer/Q1 Predictions Mean       -50.4806
trainer/Q1 Predictions Std         47.368
trainer/Q1 Predictions Max         -7.85369
trainer/Q1 Predictions Min       -154.607
trainer/Q2 Predictions Mean       -50.5011
trainer/Q2 Predictions Std         47.3797
trainer/Q2 Predictions Max         -7.87309
trainer/Q2 Predictions Min       -155.629
trainer/Q Targets Mean            -49.7511
trainer/Q Targets Std              47.669
trainer/Q Targets Max              -2.11876
trainer/Q Targets Min            -155.835
trainer/Log Pis Mean                1.95391
trainer/Log Pis Std                 0.978639
trainer/Log Pis Max                 5.09242
trainer/Log Pis Min                -1.84394
trainer/Policy mu Mean             -0.110826
trainer/Policy mu Std               0.536551
trainer/Policy mu Max               2.61519
trainer/Policy mu Min              -2.49107
trainer/Policy log std Mean        -2.12075
trainer/Policy log std Std          0.45524
trainer/Policy log std Max         -0.594696
trainer/Policy log std Min         -2.76335
trainer/Alpha                       0.0609001
trainer/Alpha Loss                 -0.128996
exploration/num steps total    181700
exploration/num paths total      1817
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.38456
exploration/Rewards Std             1.24926
exploration/Rewards Max            -0.0263464
exploration/Rewards Min            -8.93289
exploration/Returns Mean         -138.456
exploration/Returns Std            62.1485
exploration/Returns Max           -57.9855
exploration/Returns Min          -227.101
exploration/Actions Mean           -0.00380192
exploration/Actions Std             0.261091
exploration/Actions Max             0.998568
exploration/Actions Min            -0.999988
exploration/Num Paths               5
exploration/Average Returns      -138.456
evaluation/num steps total     544500
evaluation/num paths total       5445
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.925691
evaluation/Rewards Std              1.2898
evaluation/Rewards Max             -0.0872464
evaluation/Rewards Min            -10.7672
evaluation/Returns Mean           -92.5691
evaluation/Returns Std             71.0313
evaluation/Returns Max            -22.4612
evaluation/Returns Min           -265.277
evaluation/Actions Mean            -0.00478171
evaluation/Actions Std              0.20218
evaluation/Actions Max              0.999474
evaluation/Actions Min             -0.99911
evaluation/Num Paths               15
evaluation/Average Returns        -92.5691
time/data storing (s)               0.00276482
time/evaluation sampling (s)        0.326688
time/exploration sampling (s)       0.138619
time/logging (s)                    0.00474429
time/saving (s)                     0.00195242
time/training (s)                   1.96457
time/epoch (s)                      2.43933
time/total (s)                    890.608
Epoch                             362
-----------------------------  ---------------
2019-04-23 01:28:24.840561 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 363 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   65.1707
trainer/QF2 Loss                   64.5322
trainer/Policy Loss                48.3469
trainer/Q1 Predictions Mean       -46.3107
trainer/Q1 Predictions Std         45.032
trainer/Q1 Predictions Max         -8.00637
trainer/Q1 Predictions Min       -151.088
trainer/Q2 Predictions Mean       -46.3106
trainer/Q2 Predictions Std         45.0743
trainer/Q2 Predictions Max         -8.03064
trainer/Q2 Predictions Min       -150.541
trainer/Q Targets Mean            -45.541
trainer/Q Targets Std              45.4888
trainer/Q Targets Max              -0.0526206
trainer/Q Targets Min            -152.175
trainer/Log Pis Mean                2.25444
trainer/Log Pis Std                 1.25281
trainer/Log Pis Max                 6.64245
trainer/Log Pis Min                -2.0226
trainer/Policy mu Mean             -0.0953181
trainer/Policy mu Std               0.612688
trainer/Policy mu Max               4.21127
trainer/Policy mu Min              -2.30896
trainer/Policy log std Mean        -2.18404
trainer/Policy log std Std          0.446753
trainer/Policy log std Max         -0.515034
trainer/Policy log std Min         -2.88662
trainer/Alpha                       0.0604545
trainer/Alpha Loss                  0.713979
exploration/num steps total    182200
exploration/num paths total      1822
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.31172
exploration/Rewards Std             1.11761
exploration/Rewards Max            -0.0187439
exploration/Rewards Min            -5.76011
exploration/Returns Mean         -131.172
exploration/Returns Std           105.179
exploration/Returns Max           -17.1225
exploration/Returns Min          -272.895
exploration/Actions Mean           -0.0171379
exploration/Actions Std             0.208522
exploration/Actions Max             0.964593
exploration/Actions Min            -0.996015
exploration/Num Paths               5
exploration/Average Returns      -131.172
evaluation/num steps total     546000
evaluation/num paths total       5460
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.03832
evaluation/Rewards Std              1.21537
evaluation/Rewards Max             -0.0102551
evaluation/Rewards Min            -11.6373
evaluation/Returns Mean          -103.832
evaluation/Returns Std             88.8627
evaluation/Returns Max            -11.6147
evaluation/Returns Min           -279.388
evaluation/Actions Mean            -0.0192611
evaluation/Actions Std              0.192112
evaluation/Actions Max              0.996307
evaluation/Actions Min             -0.999839
evaluation/Num Paths               15
evaluation/Average Returns       -103.832
time/data storing (s)               0.00274599
time/evaluation sampling (s)        0.327454
time/exploration sampling (s)       0.136347
time/logging (s)                    0.00477502
time/saving (s)                     0.00192535
time/training (s)                   1.97205
time/epoch (s)                      2.4453
time/total (s)                    893.058
Epoch                             363
-----------------------------  ---------------
2019-04-23 01:28:27.311437 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 364 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.630684
trainer/QF2 Loss                    0.779153
trainer/Policy Loss                47.8756
trainer/Q1 Predictions Mean       -46.1754
trainer/Q1 Predictions Std         46.9253
trainer/Q1 Predictions Max         -7.79075
trainer/Q1 Predictions Min       -150.631
trainer/Q2 Predictions Mean       -46.1287
trainer/Q2 Predictions Std         46.8406
trainer/Q2 Predictions Max         -7.96423
trainer/Q2 Predictions Min       -149.806
trainer/Q Targets Mean            -46.3369
trainer/Q Targets Std              47.4103
trainer/Q Targets Max              -7.81351
trainer/Q Targets Min            -151.92
trainer/Log Pis Mean                1.87657
trainer/Log Pis Std                 1.55746
trainer/Log Pis Max                 8.2811
trainer/Log Pis Min                -2.94188
trainer/Policy mu Mean             -0.148732
trainer/Policy mu Std               0.660415
trainer/Policy mu Max               2.39905
trainer/Policy mu Min              -3.46989
trainer/Policy log std Mean        -2.1865
trainer/Policy log std Std          0.420795
trainer/Policy log std Max         -0.3586
trainer/Policy log std Min         -2.99875
trainer/Alpha                       0.0607291
trainer/Alpha Loss                 -0.34577
exploration/num steps total    182700
exploration/num paths total      1827
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.02406
exploration/Rewards Std             0.991341
exploration/Rewards Max            -0.0346817
exploration/Rewards Min           -10.4615
exploration/Returns Mean         -102.406
exploration/Returns Std            31.3748
exploration/Returns Max           -66.1969
exploration/Returns Min          -147.882
exploration/Actions Mean           -0.00955898
exploration/Actions Std             0.230264
exploration/Actions Max             0.999848
exploration/Actions Min            -0.99956
exploration/Num Paths               5
exploration/Average Returns      -102.406
evaluation/num steps total     547500
evaluation/num paths total       5475
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.668333
evaluation/Rewards Std              1.01207
evaluation/Rewards Max             -0.0140343
evaluation/Rewards Min             -7.92174
evaluation/Returns Mean           -66.8333
evaluation/Returns Std             75.3125
evaluation/Returns Max             -2.04726
evaluation/Returns Min           -287.325
evaluation/Actions Mean            -0.00506279
evaluation/Actions Std              0.172782
evaluation/Actions Max              0.997812
evaluation/Actions Min             -0.997913
evaluation/Num Paths               15
evaluation/Average Returns        -66.8333
time/data storing (s)               0.00268059
time/evaluation sampling (s)        0.330007
time/exploration sampling (s)       0.135287
time/logging (s)                    0.00474351
time/saving (s)                     0.00192404
time/training (s)                   1.98677
time/epoch (s)                      2.46141
time/total (s)                    895.524
Epoch                             364
-----------------------------  ---------------
2019-04-23 01:28:29.763954 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 365 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.20006
trainer/QF2 Loss                    0.254931
trainer/Policy Loss                45.8324
trainer/Q1 Predictions Mean       -44.1554
trainer/Q1 Predictions Std         42.1289
trainer/Q1 Predictions Max         -7.88729
trainer/Q1 Predictions Min       -148.386
trainer/Q2 Predictions Mean       -44.1058
trainer/Q2 Predictions Std         42.1161
trainer/Q2 Predictions Max         -7.93566
trainer/Q2 Predictions Min       -148.029
trainer/Q Targets Mean            -44.3306
trainer/Q Targets Std              42.2508
trainer/Q Targets Max              -7.77624
trainer/Q Targets Min            -149.489
trainer/Log Pis Mean                1.8841
trainer/Log Pis Std                 1.16339
trainer/Log Pis Max                 3.75204
trainer/Log Pis Min                -3.14023
trainer/Policy mu Mean             -0.0428262
trainer/Policy mu Std               0.409258
trainer/Policy mu Max               2.52361
trainer/Policy mu Min              -1.40757
trainer/Policy log std Mean        -2.21571
trainer/Policy log std Std          0.319087
trainer/Policy log std Max         -0.70121
trainer/Policy log std Min         -2.9744
trainer/Alpha                       0.0601036
trainer/Alpha Loss                 -0.325879
exploration/num steps total    183200
exploration/num paths total      1832
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.953545
exploration/Rewards Std             1.31684
exploration/Rewards Max            -0.00483194
exploration/Rewards Min            -9.60977
exploration/Returns Mean          -95.3545
exploration/Returns Std            56.133
exploration/Returns Max           -33.5946
exploration/Returns Min          -176.105
exploration/Actions Mean            0.0223448
exploration/Actions Std             0.246327
exploration/Actions Max             0.998828
exploration/Actions Min            -0.99873
exploration/Num Paths               5
exploration/Average Returns       -95.3545
evaluation/num steps total     549000
evaluation/num paths total       5490
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.61214
evaluation/Rewards Std              1.26905
evaluation/Rewards Max             -0.0106973
evaluation/Rewards Min            -10.4981
evaluation/Returns Mean          -161.214
evaluation/Returns Std             92.0125
evaluation/Returns Max             -3.89342
evaluation/Returns Min           -290.91
evaluation/Actions Mean             0.00129474
evaluation/Actions Std              0.195192
evaluation/Actions Max              0.998012
evaluation/Actions Min             -0.99938
evaluation/Num Paths               15
evaluation/Average Returns       -161.214
time/data storing (s)               0.00281641
time/evaluation sampling (s)        0.332687
time/exploration sampling (s)       0.136543
time/logging (s)                    0.00480342
time/saving (s)                     0.00197167
time/training (s)                   1.96392
time/epoch (s)                      2.44274
time/total (s)                    897.971
Epoch                             365
-----------------------------  ---------------
2019-04-23 01:28:32.232438 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 366 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   29.2127
trainer/QF2 Loss                   29.6059
trainer/Policy Loss                47.8323
trainer/Q1 Predictions Mean       -45.8799
trainer/Q1 Predictions Std         46.1503
trainer/Q1 Predictions Max         -7.69473
trainer/Q1 Predictions Min       -151.392
trainer/Q2 Predictions Mean       -45.8467
trainer/Q2 Predictions Std         46.1068
trainer/Q2 Predictions Max         -7.76113
trainer/Q2 Predictions Min       -151.337
trainer/Q Targets Mean            -45.8784
trainer/Q Targets Std              46.7915
trainer/Q Targets Max              -0.878098
trainer/Q Targets Min            -151.954
trainer/Log Pis Mean                2.17704
trainer/Log Pis Std                 1.18997
trainer/Log Pis Max                 7.21273
trainer/Log Pis Min                -0.625647
trainer/Policy mu Mean             -0.0619551
trainer/Policy mu Std               0.686465
trainer/Policy mu Max               3.64369
trainer/Policy mu Min              -3.42707
trainer/Policy log std Mean        -2.13743
trainer/Policy log std Std          0.456381
trainer/Policy log std Max          0.144908
trainer/Policy log std Min         -2.92911
trainer/Alpha                       0.0612201
trainer/Alpha Loss                  0.494525
exploration/num steps total    183700
exploration/num paths total      1837
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.59998
exploration/Rewards Std             1.38877
exploration/Rewards Max            -0.010263
exploration/Rewards Min            -9.63855
exploration/Returns Mean         -159.998
exploration/Returns Std           106.585
exploration/Returns Max           -23.7326
exploration/Returns Min          -276.174
exploration/Actions Mean           -0.018778
exploration/Actions Std             0.228423
exploration/Actions Max             0.98411
exploration/Actions Min            -0.999174
exploration/Num Paths               5
exploration/Average Returns      -159.998
evaluation/num steps total     550500
evaluation/num paths total       5505
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.17921
evaluation/Rewards Std              1.10873
evaluation/Rewards Max             -0.12756
evaluation/Rewards Min             -9.34329
evaluation/Returns Mean          -117.921
evaluation/Returns Std             75.1034
evaluation/Returns Max            -19.8194
evaluation/Returns Min           -274.457
evaluation/Actions Mean             0.0230888
evaluation/Actions Std              0.173559
evaluation/Actions Max              0.998369
evaluation/Actions Min             -0.999286
evaluation/Num Paths               15
evaluation/Average Returns       -117.921
time/data storing (s)               0.00257358
time/evaluation sampling (s)        0.334311
time/exploration sampling (s)       0.138768
time/logging (s)                    0.00477384
time/saving (s)                     0.00193102
time/training (s)                   1.97653
time/epoch (s)                      2.45889
time/total (s)                    900.434
Epoch                             366
-----------------------------  ---------------
2019-04-23 01:28:34.696208 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 367 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                  142.31
trainer/QF2 Loss                  142.307
trainer/Policy Loss                51.4275
trainer/Q1 Predictions Mean       -49.7031
trainer/Q1 Predictions Std         48.7347
trainer/Q1 Predictions Max         -7.75954
trainer/Q1 Predictions Min       -151.702
trainer/Q2 Predictions Mean       -49.6691
trainer/Q2 Predictions Std         48.7606
trainer/Q2 Predictions Max         -7.73777
trainer/Q2 Predictions Min       -151.866
trainer/Q Targets Mean            -48.5575
trainer/Q Targets Std              48.7737
trainer/Q Targets Max              -0.171421
trainer/Q Targets Min            -152.457
trainer/Log Pis Mean                1.96059
trainer/Log Pis Std                 1.30191
trainer/Log Pis Max                 9.50088
trainer/Log Pis Min                -1.67947
trainer/Policy mu Mean              0.0368365
trainer/Policy mu Std               0.612918
trainer/Policy mu Max               2.98826
trainer/Policy mu Min              -2.47238
trainer/Policy log std Mean        -2.16504
trainer/Policy log std Std          0.455637
trainer/Policy log std Max         -0.433667
trainer/Policy log std Min         -2.75803
trainer/Alpha                       0.0641964
trainer/Alpha Loss                 -0.108203
exploration/num steps total    184200
exploration/num paths total      1842
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.24188
exploration/Rewards Std             1.27474
exploration/Rewards Max            -0.0082839
exploration/Rewards Min            -8.38331
exploration/Returns Mean         -124.188
exploration/Returns Std           104.249
exploration/Returns Max           -15.949
exploration/Returns Min          -283.575
exploration/Actions Mean           -0.0187844
exploration/Actions Std             0.19975
exploration/Actions Max             0.947007
exploration/Actions Min            -0.999913
exploration/Num Paths               5
exploration/Average Returns      -124.188
evaluation/num steps total     552000
evaluation/num paths total       5520
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.579767
evaluation/Rewards Std              0.999574
evaluation/Rewards Max             -0.0123991
evaluation/Rewards Min             -9.38341
evaluation/Returns Mean           -57.9767
evaluation/Returns Std             47.8899
evaluation/Returns Max            -10.1363
evaluation/Returns Min           -196.059
evaluation/Actions Mean            -0.00413304
evaluation/Actions Std              0.181842
evaluation/Actions Max              0.99622
evaluation/Actions Min             -0.99807
evaluation/Num Paths               15
evaluation/Average Returns        -57.9767
time/data storing (s)               0.00276247
time/evaluation sampling (s)        0.324112
time/exploration sampling (s)       0.137371
time/logging (s)                    0.00374425
time/saving (s)                     0.00232215
time/training (s)                   1.98246
time/epoch (s)                      2.45277
time/total (s)                    902.892
Epoch                             367
-----------------------------  ---------------
2019-04-23 01:28:37.155930 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 368 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.981904
trainer/QF2 Loss                    0.89638
trainer/Policy Loss                46.1216
trainer/Q1 Predictions Mean       -44.5787
trainer/Q1 Predictions Std         40.5231
trainer/Q1 Predictions Max         -7.86101
trainer/Q1 Predictions Min       -150.538
trainer/Q2 Predictions Mean       -44.6082
trainer/Q2 Predictions Std         40.5855
trainer/Q2 Predictions Max         -7.83531
trainer/Q2 Predictions Min       -151.842
trainer/Q Targets Mean            -45.1957
trainer/Q Targets Std              41.0978
trainer/Q Targets Max              -7.91526
trainer/Q Targets Min            -153.187
trainer/Log Pis Mean                1.82409
trainer/Log Pis Std                 1.22713
trainer/Log Pis Max                 4.38163
trainer/Log Pis Min                -1.33679
trainer/Policy mu Mean              0.0187118
trainer/Policy mu Std               0.561095
trainer/Policy mu Max               2.66199
trainer/Policy mu Min              -2.46697
trainer/Policy log std Mean        -2.14754
trainer/Policy log std Std          0.46657
trainer/Policy log std Max         -0.233002
trainer/Policy log std Min         -2.8298
trainer/Alpha                       0.0643901
trainer/Alpha Loss                 -0.482471
exploration/num steps total    184700
exploration/num paths total      1847
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.281215
exploration/Rewards Std             0.780062
exploration/Rewards Max            -0.00421111
exploration/Rewards Min            -8.95261
exploration/Returns Mean          -28.1215
exploration/Returns Std            12.0054
exploration/Returns Max           -12.9039
exploration/Returns Min           -48.7577
exploration/Actions Mean           -0.00594125
exploration/Actions Std             0.212616
exploration/Actions Max             0.999086
exploration/Actions Min            -0.998719
exploration/Num Paths               5
exploration/Average Returns       -28.1215
evaluation/num steps total     553500
evaluation/num paths total       5535
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.801237
evaluation/Rewards Std              1.11881
evaluation/Rewards Max             -0.0113125
evaluation/Rewards Min             -8.36619
evaluation/Returns Mean           -80.1237
evaluation/Returns Std             80.6773
evaluation/Returns Max             -3.61773
evaluation/Returns Min           -280.346
evaluation/Actions Mean             0.00334717
evaluation/Actions Std              0.176035
evaluation/Actions Max              0.998984
evaluation/Actions Min             -0.99738
evaluation/Num Paths               15
evaluation/Average Returns        -80.1237
time/data storing (s)               0.00282507
time/evaluation sampling (s)        0.324323
time/exploration sampling (s)       0.150307
time/logging (s)                    0.00356188
time/saving (s)                     0.00183302
time/training (s)                   1.96706
time/epoch (s)                      2.44991
time/total (s)                    905.346
Epoch                             368
-----------------------------  ---------------
2019-04-23 01:28:39.620442 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 369 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                  108.274
trainer/QF2 Loss                  107.87
trainer/Policy Loss                41.8637
trainer/Q1 Predictions Mean       -40.052
trainer/Q1 Predictions Std         39.5204
trainer/Q1 Predictions Max         -7.85377
trainer/Q1 Predictions Min       -143.91
trainer/Q2 Predictions Mean       -40.0147
trainer/Q2 Predictions Std         39.4517
trainer/Q2 Predictions Max         -7.85888
trainer/Q2 Predictions Min       -143.528
trainer/Q Targets Mean            -39.167
trainer/Q Targets Std              40.0167
trainer/Q Targets Max              -0.199481
trainer/Q Targets Min            -145.851
trainer/Log Pis Mean                1.95574
trainer/Log Pis Std                 1.13974
trainer/Log Pis Max                 5.96481
trainer/Log Pis Min                -1.92974
trainer/Policy mu Mean              0.0157756
trainer/Policy mu Std               0.340537
trainer/Policy mu Max               0.926934
trainer/Policy mu Min              -3.07518
trainer/Policy log std Mean        -2.32138
trainer/Policy log std Std          0.301522
trainer/Policy log std Max         -0.764856
trainer/Policy log std Min         -2.91182
trainer/Alpha                       0.0633755
trainer/Alpha Loss                 -0.122094
exploration/num steps total    185200
exploration/num paths total      1852
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.94551
exploration/Rewards Std             1.14565
exploration/Rewards Max            -0.0080424
exploration/Rewards Min            -8.60723
exploration/Returns Mean         -194.551
exploration/Returns Std            83.3382
exploration/Returns Max           -51.8072
exploration/Returns Min          -278.761
exploration/Actions Mean            0.000433218
exploration/Actions Std             0.204801
exploration/Actions Max             0.998851
exploration/Actions Min            -0.997399
exploration/Num Paths               5
exploration/Average Returns      -194.551
evaluation/num steps total     555000
evaluation/num paths total       5550
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.23686
evaluation/Rewards Std              1.13024
evaluation/Rewards Max             -0.0176912
evaluation/Rewards Min             -8.48175
evaluation/Returns Mean          -123.686
evaluation/Returns Std             92.6115
evaluation/Returns Max             -8.84326
evaluation/Returns Min           -276.389
evaluation/Actions Mean            -0.00840913
evaluation/Actions Std              0.157182
evaluation/Actions Max              0.998138
evaluation/Actions Min             -0.999716
evaluation/Num Paths               15
evaluation/Average Returns       -123.686
time/data storing (s)               0.00274304
time/evaluation sampling (s)        0.324343
time/exploration sampling (s)       0.13808
time/logging (s)                    0.00478844
time/saving (s)                     0.00196594
time/training (s)                   1.98445
time/epoch (s)                      2.45637
time/total (s)                    907.807
Epoch                             369
-----------------------------  ----------------
2019-04-23 01:28:42.100620 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 370 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                  102.67
trainer/QF2 Loss                  101.461
trainer/Policy Loss                53.2745
trainer/Q1 Predictions Mean       -51.7512
trainer/Q1 Predictions Std         49.844
trainer/Q1 Predictions Max         -7.73163
trainer/Q1 Predictions Min       -150.534
trainer/Q2 Predictions Mean       -51.7454
trainer/Q2 Predictions Std         49.8758
trainer/Q2 Predictions Max         -7.74906
trainer/Q2 Predictions Min       -152.015
trainer/Q Targets Mean            -50.7749
trainer/Q Targets Std              51.3967
trainer/Q Targets Max              -0.108076
trainer/Q Targets Min            -152.796
trainer/Log Pis Mean                1.86755
trainer/Log Pis Std                 1.04879
trainer/Log Pis Max                 4.84865
trainer/Log Pis Min                -0.870115
trainer/Policy mu Mean             -0.110212
trainer/Policy mu Std               0.56231
trainer/Policy mu Max               1.9162
trainer/Policy mu Min              -3.16854
trainer/Policy log std Mean        -2.11414
trainer/Policy log std Std          0.440157
trainer/Policy log std Max         -0.398051
trainer/Policy log std Min         -2.78885
trainer/Alpha                       0.0655334
trainer/Alpha Loss                 -0.360925
exploration/num steps total    185700
exploration/num paths total      1857
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.567528
exploration/Rewards Std             1.14842
exploration/Rewards Max            -0.0108726
exploration/Rewards Min           -10.4917
exploration/Returns Mean          -56.7528
exploration/Returns Std            32.6248
exploration/Returns Max           -17.2679
exploration/Returns Min          -107.937
exploration/Actions Mean           -0.0168663
exploration/Actions Std             0.225902
exploration/Actions Max             0.997003
exploration/Actions Min            -0.999702
exploration/Num Paths               5
exploration/Average Returns       -56.7528
evaluation/num steps total     556500
evaluation/num paths total       5565
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.941148
evaluation/Rewards Std              1.13348
evaluation/Rewards Max             -0.0539584
evaluation/Rewards Min             -9.72139
evaluation/Returns Mean           -94.1148
evaluation/Returns Std             86.6268
evaluation/Returns Max            -14.4626
evaluation/Returns Min           -273.679
evaluation/Actions Mean             0.00232392
evaluation/Actions Std              0.173838
evaluation/Actions Max              0.998358
evaluation/Actions Min             -0.996798
evaluation/Num Paths               15
evaluation/Average Returns        -94.1148
time/data storing (s)               0.00310284
time/evaluation sampling (s)        0.329135
time/exploration sampling (s)       0.135822
time/logging (s)                    0.00489162
time/saving (s)                     0.00631088
time/training (s)                   1.99102
time/epoch (s)                      2.47028
time/total (s)                    910.281
Epoch                             370
-----------------------------  ---------------
2019-04-23 01:28:44.549329 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 371 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.449144
trainer/QF2 Loss                    0.504103
trainer/Policy Loss                44.5759
trainer/Q1 Predictions Mean       -42.8695
trainer/Q1 Predictions Std         42.2852
trainer/Q1 Predictions Max         -7.89128
trainer/Q1 Predictions Min       -148.492
trainer/Q2 Predictions Mean       -42.861
trainer/Q2 Predictions Std         42.2764
trainer/Q2 Predictions Max         -7.86219
trainer/Q2 Predictions Min       -148.092
trainer/Q Targets Mean            -43.3297
trainer/Q Targets Std              42.6522
trainer/Q Targets Max              -7.78888
trainer/Q Targets Min            -149.863
trainer/Log Pis Mean                1.90036
trainer/Log Pis Std                 1.35908
trainer/Log Pis Max                 6.23608
trainer/Log Pis Min                -4.81988
trainer/Policy mu Mean             -0.00349139
trainer/Policy mu Std               0.573183
trainer/Policy mu Max               3.07222
trainer/Policy mu Min              -2.41455
trainer/Policy log std Mean        -2.19937
trainer/Policy log std Std          0.448554
trainer/Policy log std Max         -0.474842
trainer/Policy log std Min         -2.89313
trainer/Alpha                       0.0642816
trainer/Alpha Loss                 -0.273447
exploration/num steps total    186200
exploration/num paths total      1862
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.16694
exploration/Rewards Std             1.01202
exploration/Rewards Max            -0.0109697
exploration/Rewards Min            -9.83507
exploration/Returns Mean         -116.694
exploration/Returns Std            62.8517
exploration/Returns Max           -20.1155
exploration/Returns Min          -169.929
exploration/Actions Mean            0.01396
exploration/Actions Std             0.213907
exploration/Actions Max             0.998402
exploration/Actions Min            -0.991022
exploration/Num Paths               5
exploration/Average Returns      -116.694
evaluation/num steps total     558000
evaluation/num paths total       5580
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.52766
evaluation/Rewards Std              1.38753
evaluation/Rewards Max             -0.0476095
evaluation/Rewards Min            -10.0111
evaluation/Returns Mean          -152.766
evaluation/Returns Std            109.94
evaluation/Returns Max             -5.80678
evaluation/Returns Min           -294.106
evaluation/Actions Mean            -0.00724403
evaluation/Actions Std              0.179455
evaluation/Actions Max              0.999306
evaluation/Actions Min             -0.997868
evaluation/Num Paths               15
evaluation/Average Returns       -152.766
time/data storing (s)               0.00261918
time/evaluation sampling (s)        0.326442
time/exploration sampling (s)       0.136422
time/logging (s)                    0.00478304
time/saving (s)                     0.00191067
time/training (s)                   1.96836
time/epoch (s)                      2.44054
time/total (s)                    912.726
Epoch                             371
-----------------------------  ---------------
2019-04-23 01:28:47.009412 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 372 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                  138.607
trainer/QF2 Loss                  139.225
trainer/Policy Loss                46.8243
trainer/Q1 Predictions Mean       -45.0649
trainer/Q1 Predictions Std         43.339
trainer/Q1 Predictions Max         -7.58347
trainer/Q1 Predictions Min       -144.288
trainer/Q2 Predictions Mean       -45.0469
trainer/Q2 Predictions Std         43.2678
trainer/Q2 Predictions Max         -7.60315
trainer/Q2 Predictions Min       -144.608
trainer/Q Targets Mean            -44.168
trainer/Q Targets Std              43.1659
trainer/Q Targets Max              -2.52201
trainer/Q Targets Min            -146.606
trainer/Log Pis Mean                1.98679
trainer/Log Pis Std                 0.893597
trainer/Log Pis Max                 4.8713
trainer/Log Pis Min                -1.04789
trainer/Policy mu Mean              0.0352988
trainer/Policy mu Std               0.562587
trainer/Policy mu Max               3.07391
trainer/Policy mu Min              -1.65762
trainer/Policy log std Mean        -2.12836
trainer/Policy log std Std          0.418543
trainer/Policy log std Max         -0.438854
trainer/Policy log std Min         -2.85228
trainer/Alpha                       0.0683533
trainer/Alpha Loss                 -0.0354496
exploration/num steps total    186700
exploration/num paths total      1867
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.713545
exploration/Rewards Std             1.14975
exploration/Rewards Max            -0.00479399
exploration/Rewards Min            -8.58955
exploration/Returns Mean          -71.3545
exploration/Returns Std            75.1078
exploration/Returns Max           -17.9485
exploration/Returns Min          -219.31
exploration/Actions Mean           -0.0213682
exploration/Actions Std             0.222217
exploration/Actions Max             0.997045
exploration/Actions Min            -0.999588
exploration/Num Paths               5
exploration/Average Returns       -71.3545
evaluation/num steps total     559500
evaluation/num paths total       5595
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.878165
evaluation/Rewards Std              1.25003
evaluation/Rewards Max             -0.0100401
evaluation/Rewards Min             -9.67649
evaluation/Returns Mean           -87.8165
evaluation/Returns Std             65.0802
evaluation/Returns Max            -17.0695
evaluation/Returns Min           -226.089
evaluation/Actions Mean            -0.00656568
evaluation/Actions Std              0.197249
evaluation/Actions Max              0.997778
evaluation/Actions Min             -0.998745
evaluation/Num Paths               15
evaluation/Average Returns        -87.8165
time/data storing (s)               0.00267598
time/evaluation sampling (s)        0.331627
time/exploration sampling (s)       0.140359
time/logging (s)                    0.00477579
time/saving (s)                     0.00191381
time/training (s)                   1.96867
time/epoch (s)                      2.45002
time/total (s)                    915.18
Epoch                             372
-----------------------------  ---------------
2019-04-23 01:28:49.474808 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 373 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.505415
trainer/QF2 Loss                    0.652881
trainer/Policy Loss                45.8361
trainer/Q1 Predictions Mean       -43.8838
trainer/Q1 Predictions Std         42.6681
trainer/Q1 Predictions Max         -7.88754
trainer/Q1 Predictions Min       -144.025
trainer/Q2 Predictions Mean       -43.9384
trainer/Q2 Predictions Std         42.6884
trainer/Q2 Predictions Max         -7.89046
trainer/Q2 Predictions Min       -143.926
trainer/Q Targets Mean            -44.1587
trainer/Q Targets Std              43.0023
trainer/Q Targets Max              -7.63847
trainer/Q Targets Min            -144.102
trainer/Log Pis Mean                2.05328
trainer/Log Pis Std                 1.31551
trainer/Log Pis Max                 7.76721
trainer/Log Pis Min                -1.30159
trainer/Policy mu Mean              0.0562014
trainer/Policy mu Std               0.647122
trainer/Policy mu Max               3.88149
trainer/Policy mu Min              -2.93058
trainer/Policy log std Mean        -2.19158
trainer/Policy log std Std          0.481805
trainer/Policy log std Max          0.315945
trainer/Policy log std Min         -2.77463
trainer/Alpha                       0.0683066
trainer/Alpha Loss                  0.142992
exploration/num steps total    187200
exploration/num paths total      1872
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.93447
exploration/Rewards Std             1.21622
exploration/Rewards Max            -0.00288749
exploration/Rewards Min            -9.077
exploration/Returns Mean         -193.447
exploration/Returns Std            77.6383
exploration/Returns Max           -52.313
exploration/Returns Min          -289.195
exploration/Actions Mean           -0.000384916
exploration/Actions Std             0.264149
exploration/Actions Max             0.997979
exploration/Actions Min            -0.998241
exploration/Num Paths               5
exploration/Average Returns      -193.447
evaluation/num steps total     561000
evaluation/num paths total       5610
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.487546
evaluation/Rewards Std              1.20653
evaluation/Rewards Max             -0.0375877
evaluation/Rewards Min            -10.706
evaluation/Returns Mean           -48.7546
evaluation/Returns Std             18.3975
evaluation/Returns Max            -12.7578
evaluation/Returns Min            -84.0283
evaluation/Actions Mean             0.00300873
evaluation/Actions Std              0.212949
evaluation/Actions Max              0.999104
evaluation/Actions Min             -0.997861
evaluation/Num Paths               15
evaluation/Average Returns        -48.7546
time/data storing (s)               0.00266672
time/evaluation sampling (s)        0.32774
time/exploration sampling (s)       0.136957
time/logging (s)                    0.00478336
time/saving (s)                     0.00193726
time/training (s)                   1.98257
time/epoch (s)                      2.45665
time/total (s)                    917.642
Epoch                             373
-----------------------------  ----------------
2019-04-23 01:28:51.922784 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 374 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   29.5924
trainer/QF2 Loss                   29.7154
trainer/Policy Loss                45.9593
trainer/Q1 Predictions Mean       -44.2347
trainer/Q1 Predictions Std         44.6122
trainer/Q1 Predictions Max         -7.3563
trainer/Q1 Predictions Min       -143.746
trainer/Q2 Predictions Mean       -44.2629
trainer/Q2 Predictions Std         44.6395
trainer/Q2 Predictions Max         -7.42024
trainer/Q2 Predictions Min       -143.51
trainer/Q Targets Mean            -44.1158
trainer/Q Targets Std              45.3753
trainer/Q Targets Max              -0.100059
trainer/Q Targets Min            -144.128
trainer/Log Pis Mean                1.947
trainer/Log Pis Std                 0.964258
trainer/Log Pis Max                 3.6426
trainer/Log Pis Min                -1.36603
trainer/Policy mu Mean             -0.00200586
trainer/Policy mu Std               0.548324
trainer/Policy mu Max               2.45677
trainer/Policy mu Min              -2.88761
trainer/Policy log std Mean        -2.17317
trainer/Policy log std Std          0.460074
trainer/Policy log std Max         -0.404083
trainer/Policy log std Min         -2.88109
trainer/Alpha                       0.067471
trainer/Alpha Loss                 -0.142899
exploration/num steps total    187700
exploration/num paths total      1877
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.58258
exploration/Rewards Std             1.26377
exploration/Rewards Max            -0.0169654
exploration/Rewards Min            -8.22419
exploration/Returns Mean         -158.258
exploration/Returns Std            89.4819
exploration/Returns Max           -53.9802
exploration/Returns Min          -281.71
exploration/Actions Mean           -0.0142555
exploration/Actions Std             0.212007
exploration/Actions Max             0.989077
exploration/Actions Min            -0.999636
exploration/Num Paths               5
exploration/Average Returns      -158.258
evaluation/num steps total     562500
evaluation/num paths total       5625
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.74757
evaluation/Rewards Std              1.20961
evaluation/Rewards Max             -0.00638119
evaluation/Rewards Min            -11.7842
evaluation/Returns Mean           -74.757
evaluation/Returns Std             68.5543
evaluation/Returns Max            -12.2925
evaluation/Returns Min           -214.192
evaluation/Actions Mean             0.0125435
evaluation/Actions Std              0.182466
evaluation/Actions Max              0.999391
evaluation/Actions Min             -0.995183
evaluation/Num Paths               15
evaluation/Average Returns        -74.757
time/data storing (s)               0.00268373
time/evaluation sampling (s)        0.325093
time/exploration sampling (s)       0.139477
time/logging (s)                    0.00476379
time/saving (s)                     0.00164485
time/training (s)                   1.96424
time/epoch (s)                      2.4379
time/total (s)                    920.084
Epoch                             374
-----------------------------  ---------------
2019-04-23 01:28:54.399136 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 375 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    2.1088
trainer/QF2 Loss                    2.18191
trainer/Policy Loss                47.4906
trainer/Q1 Predictions Mean       -46.0173
trainer/Q1 Predictions Std         45.0709
trainer/Q1 Predictions Max         -7.68239
trainer/Q1 Predictions Min       -150.067
trainer/Q2 Predictions Mean       -46.0081
trainer/Q2 Predictions Std         45.0697
trainer/Q2 Predictions Max         -7.70581
trainer/Q2 Predictions Min       -150.082
trainer/Q Targets Mean            -45.9552
trainer/Q Targets Std              45.331
trainer/Q Targets Max              -0.0412408
trainer/Q Targets Min            -150.258
trainer/Log Pis Mean                1.70633
trainer/Log Pis Std                 1.36851
trainer/Log Pis Max                 7.82395
trainer/Log Pis Min                -2.23334
trainer/Policy mu Mean              0.0787243
trainer/Policy mu Std               0.62391
trainer/Policy mu Max               3.13153
trainer/Policy mu Min              -1.86452
trainer/Policy log std Mean        -2.12876
trainer/Policy log std Std          0.476199
trainer/Policy log std Max         -0.46095
trainer/Policy log std Min         -2.89764
trainer/Alpha                       0.0667505
trainer/Alpha Loss                 -0.794883
exploration/num steps total    188200
exploration/num paths total      1882
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.333832
exploration/Rewards Std             0.838133
exploration/Rewards Max            -0.0107831
exploration/Rewards Min            -9.36492
exploration/Returns Mean          -33.3832
exploration/Returns Std            14.6316
exploration/Returns Max           -18.6119
exploration/Returns Min           -59.5256
exploration/Actions Mean            0.008685
exploration/Actions Std             0.20712
exploration/Actions Max             0.999935
exploration/Actions Min            -0.999479
exploration/Num Paths               5
exploration/Average Returns       -33.3832
evaluation/num steps total     564000
evaluation/num paths total       5640
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.32493
evaluation/Rewards Std              1.29617
evaluation/Rewards Max             -0.0433187
evaluation/Rewards Min            -11.3028
evaluation/Returns Mean          -132.493
evaluation/Returns Std             99.0284
evaluation/Returns Max             -7.56244
evaluation/Returns Min           -268.327
evaluation/Actions Mean            -0.0102778
evaluation/Actions Std              0.184678
evaluation/Actions Max              0.998893
evaluation/Actions Min             -0.99895
evaluation/Num Paths               15
evaluation/Average Returns       -132.493
time/data storing (s)               0.00261532
time/evaluation sampling (s)        0.332903
time/exploration sampling (s)       0.140009
time/logging (s)                    0.00474986
time/saving (s)                     0.00172268
time/training (s)                   1.9843
time/epoch (s)                      2.4663
time/total (s)                    922.555
Epoch                             375
-----------------------------  ---------------
2019-04-23 01:28:56.863330 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 376 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.712567
trainer/QF2 Loss                    0.728138
trainer/Policy Loss                48.5073
trainer/Q1 Predictions Mean       -46.7618
trainer/Q1 Predictions Std         49.0762
trainer/Q1 Predictions Max         -7.71686
trainer/Q1 Predictions Min       -150.271
trainer/Q2 Predictions Mean       -46.7782
trainer/Q2 Predictions Std         49.1085
trainer/Q2 Predictions Max         -7.75252
trainer/Q2 Predictions Min       -151.008
trainer/Q Targets Mean            -46.6033
trainer/Q Targets Std              49.0779
trainer/Q Targets Max              -0.209338
trainer/Q Targets Min            -150.026
trainer/Log Pis Mean                1.96688
trainer/Log Pis Std                 1.24087
trainer/Log Pis Max                 4.87837
trainer/Log Pis Min                -2.40527
trainer/Policy mu Mean             -0.0769486
trainer/Policy mu Std               0.629889
trainer/Policy mu Max               2.73584
trainer/Policy mu Min              -2.61719
trainer/Policy log std Mean        -2.14875
trainer/Policy log std Std          0.448703
trainer/Policy log std Max         -0.442976
trainer/Policy log std Min         -2.82832
trainer/Alpha                       0.0675357
trainer/Alpha Loss                 -0.0892537
exploration/num steps total    188700
exploration/num paths total      1887
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.16666
exploration/Rewards Std             1.39275
exploration/Rewards Max            -0.00787131
exploration/Rewards Min            -9.62959
exploration/Returns Mean         -116.666
exploration/Returns Std            58.7864
exploration/Returns Max           -44.0853
exploration/Returns Min          -193.592
exploration/Actions Mean           -0.0135176
exploration/Actions Std             0.253021
exploration/Actions Max             0.998198
exploration/Actions Min            -0.999831
exploration/Num Paths               5
exploration/Average Returns      -116.666
evaluation/num steps total     565500
evaluation/num paths total       5655
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.706082
evaluation/Rewards Std              0.976983
evaluation/Rewards Max             -0.00740555
evaluation/Rewards Min             -9.58632
evaluation/Returns Mean           -70.6082
evaluation/Returns Std             69.4867
evaluation/Returns Max             -6.47206
evaluation/Returns Min           -243.113
evaluation/Actions Mean             0.00171111
evaluation/Actions Std              0.166252
evaluation/Actions Max              0.99797
evaluation/Actions Min             -0.999045
evaluation/Num Paths               15
evaluation/Average Returns        -70.6082
time/data storing (s)               0.00275935
time/evaluation sampling (s)        0.326527
time/exploration sampling (s)       0.138468
time/logging (s)                    0.00475358
time/saving (s)                     0.00192635
time/training (s)                   1.9798
time/epoch (s)                      2.45424
time/total (s)                    925.014
Epoch                             376
-----------------------------  ---------------
2019-04-23 01:28:59.317711 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 377 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.468528
trainer/QF2 Loss                    0.506165
trainer/Policy Loss                44.9487
trainer/Q1 Predictions Mean       -43.0923
trainer/Q1 Predictions Std         44.3775
trainer/Q1 Predictions Max         -7.64048
trainer/Q1 Predictions Min       -149.303
trainer/Q2 Predictions Mean       -43.0554
trainer/Q2 Predictions Std         44.3484
trainer/Q2 Predictions Max         -7.66754
trainer/Q2 Predictions Min       -148.666
trainer/Q Targets Mean            -43.4981
trainer/Q Targets Std              44.6678
trainer/Q Targets Max              -7.68644
trainer/Q Targets Min            -150.336
trainer/Log Pis Mean                2.11937
trainer/Log Pis Std                 0.97092
trainer/Log Pis Max                 4.42126
trainer/Log Pis Min                -1.00865
trainer/Policy mu Mean             -0.0353397
trainer/Policy mu Std               0.524329
trainer/Policy mu Max               2.72537
trainer/Policy mu Min              -2.16146
trainer/Policy log std Mean        -2.21754
trainer/Policy log std Std          0.385637
trainer/Policy log std Max         -0.820087
trainer/Policy log std Min         -2.73675
trainer/Alpha                       0.067096
trainer/Alpha Loss                  0.322513
exploration/num steps total    189200
exploration/num paths total      1892
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.68922
exploration/Rewards Std             1.11544
exploration/Rewards Max            -0.0156315
exploration/Rewards Min            -6.73485
exploration/Returns Mean         -168.922
exploration/Returns Std           101.237
exploration/Returns Max           -27.4751
exploration/Returns Min          -280.559
exploration/Actions Mean           -0.0160943
exploration/Actions Std             0.196277
exploration/Actions Max             0.99695
exploration/Actions Min            -0.996852
exploration/Num Paths               5
exploration/Average Returns      -168.922
evaluation/num steps total     567000
evaluation/num paths total       5670
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.947627
evaluation/Rewards Std              1.35036
evaluation/Rewards Max             -0.0155583
evaluation/Rewards Min            -10.9274
evaluation/Returns Mean           -94.7627
evaluation/Returns Std             92.2226
evaluation/Returns Max             -7.25682
evaluation/Returns Min           -280.752
evaluation/Actions Mean             0.00731438
evaluation/Actions Std              0.19215
evaluation/Actions Max              0.999449
evaluation/Actions Min             -0.998683
evaluation/Num Paths               15
evaluation/Average Returns        -94.7627
time/data storing (s)               0.00279561
time/evaluation sampling (s)        0.323679
time/exploration sampling (s)       0.138059
time/logging (s)                    0.00469616
time/saving (s)                     0.00198687
time/training (s)                   1.97309
time/epoch (s)                      2.44431
time/total (s)                    927.463
Epoch                             377
-----------------------------  ---------------
2019-04-23 01:29:01.790075 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 378 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.44362
trainer/QF2 Loss                    1.34756
trainer/Policy Loss                45.2484
trainer/Q1 Predictions Mean       -43.3461
trainer/Q1 Predictions Std         41.7558
trainer/Q1 Predictions Max         -7.72686
trainer/Q1 Predictions Min       -142.18
trainer/Q2 Predictions Mean       -43.3614
trainer/Q2 Predictions Std         41.7898
trainer/Q2 Predictions Max         -7.74087
trainer/Q2 Predictions Min       -142.537
trainer/Q Targets Mean            -44.1016
trainer/Q Targets Std              42.588
trainer/Q Targets Max              -7.60311
trainer/Q Targets Min            -146.1
trainer/Log Pis Mean                2.11735
trainer/Log Pis Std                 0.934854
trainer/Log Pis Max                 4.31237
trainer/Log Pis Min                -1.37837
trainer/Policy mu Mean             -0.131337
trainer/Policy mu Std               0.523261
trainer/Policy mu Max               2.08483
trainer/Policy mu Min              -2.99608
trainer/Policy log std Mean        -2.19366
trainer/Policy log std Std          0.38132
trainer/Policy log std Max         -0.556059
trainer/Policy log std Min         -2.80936
trainer/Alpha                       0.0674282
trainer/Alpha Loss                  0.316471
exploration/num steps total    189700
exploration/num paths total      1897
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.36103
exploration/Rewards Std             1.08485
exploration/Rewards Max            -0.0128527
exploration/Rewards Min            -7.38544
exploration/Returns Mean         -136.103
exploration/Returns Std            93.6738
exploration/Returns Max           -18.595
exploration/Returns Min          -240.191
exploration/Actions Mean           -0.00520568
exploration/Actions Std             0.205543
exploration/Actions Max             0.996257
exploration/Actions Min            -0.998956
exploration/Num Paths               5
exploration/Average Returns      -136.103
evaluation/num steps total     568500
evaluation/num paths total       5685
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.64533
evaluation/Rewards Std              0.949057
evaluation/Rewards Max             -0.0441447
evaluation/Rewards Min             -8.74907
evaluation/Returns Mean           -64.533
evaluation/Returns Std             63.648
evaluation/Returns Max             -8.86045
evaluation/Returns Min           -218.847
evaluation/Actions Mean             0.000795853
evaluation/Actions Std              0.14944
evaluation/Actions Max              0.999129
evaluation/Actions Min             -0.999012
evaluation/Num Paths               15
evaluation/Average Returns        -64.533
time/data storing (s)               0.0028083
time/evaluation sampling (s)        0.33008
time/exploration sampling (s)       0.13568
time/logging (s)                    0.00446113
time/saving (s)                     0.00195362
time/training (s)                   1.9875
time/epoch (s)                      2.46248
time/total (s)                    929.929
Epoch                             378
-----------------------------  ----------------
2019-04-23 01:29:04.258577 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 379 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   11.6716
trainer/QF2 Loss                   11.5916
trainer/Policy Loss                42.8659
trainer/Q1 Predictions Mean       -41.217
trainer/Q1 Predictions Std         44.5035
trainer/Q1 Predictions Max         -7.64402
trainer/Q1 Predictions Min       -148.107
trainer/Q2 Predictions Mean       -41.2284
trainer/Q2 Predictions Std         44.5488
trainer/Q2 Predictions Max         -7.68374
trainer/Q2 Predictions Min       -148.069
trainer/Q Targets Mean            -41.0854
trainer/Q Targets Std              45.2392
trainer/Q Targets Max              -0.23347
trainer/Q Targets Min            -149.243
trainer/Log Pis Mean                1.81274
trainer/Log Pis Std                 1.39127
trainer/Log Pis Max                 6.14269
trainer/Log Pis Min                -4.03724
trainer/Policy mu Mean              0.0439176
trainer/Policy mu Std               0.615762
trainer/Policy mu Max               3.27323
trainer/Policy mu Min              -2.48902
trainer/Policy log std Mean        -2.10807
trainer/Policy log std Std          0.472947
trainer/Policy log std Max         -0.524773
trainer/Policy log std Min         -2.81808
trainer/Alpha                       0.0656761
trainer/Alpha Loss                 -0.509847
exploration/num steps total    190200
exploration/num paths total      1902
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.05073
exploration/Rewards Std             1.23229
exploration/Rewards Max            -0.0187504
exploration/Rewards Min            -8.42369
exploration/Returns Mean         -105.073
exploration/Returns Std           108.507
exploration/Returns Max           -18.4294
exploration/Returns Min          -312.504
exploration/Actions Mean            0.00935579
exploration/Actions Std             0.200254
exploration/Actions Max             0.999996
exploration/Actions Min            -0.997244
exploration/Num Paths               5
exploration/Average Returns      -105.073
evaluation/num steps total     570000
evaluation/num paths total       5700
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.913264
evaluation/Rewards Std              1.05599
evaluation/Rewards Max             -0.0236267
evaluation/Rewards Min             -9.40678
evaluation/Returns Mean           -91.3264
evaluation/Returns Std             68.8968
evaluation/Returns Max            -15.5275
evaluation/Returns Min           -213.51
evaluation/Actions Mean             0.0105909
evaluation/Actions Std              0.183867
evaluation/Actions Max              0.999751
evaluation/Actions Min             -0.998408
evaluation/Num Paths               15
evaluation/Average Returns        -91.3264
time/data storing (s)               0.00275553
time/evaluation sampling (s)        0.332617
time/exploration sampling (s)       0.136687
time/logging (s)                    0.00473854
time/saving (s)                     0.00194737
time/training (s)                   1.98089
time/epoch (s)                      2.45964
time/total (s)                    932.392
Epoch                             379
-----------------------------  ---------------
2019-04-23 01:29:06.698238 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 380 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                   80.6506
trainer/QF2 Loss                   79.8365
trainer/Policy Loss                49.6003
trainer/Q1 Predictions Mean       -47.6805
trainer/Q1 Predictions Std         46.7565
trainer/Q1 Predictions Max         -7.51651
trainer/Q1 Predictions Min       -158.41
trainer/Q2 Predictions Mean       -47.6855
trainer/Q2 Predictions Std         46.8014
trainer/Q2 Predictions Max         -7.56092
trainer/Q2 Predictions Min       -159.608
trainer/Q Targets Mean            -46.6942
trainer/Q Targets Std              47.5991
trainer/Q Targets Max              -0.197184
trainer/Q Targets Min            -162.161
trainer/Log Pis Mean                2.16167
trainer/Log Pis Std                 1.2264
trainer/Log Pis Max                 5.43431
trainer/Log Pis Min                -2.80548
trainer/Policy mu Mean             -0.140242
trainer/Policy mu Std               0.560045
trainer/Policy mu Max               1.73676
trainer/Policy mu Min              -2.95896
trainer/Policy log std Mean        -2.20456
trainer/Policy log std Std          0.463268
trainer/Policy log std Max         -0.415089
trainer/Policy log std Min         -2.85443
trainer/Alpha                       0.0636529
trainer/Alpha Loss                  0.445315
exploration/num steps total    190700
exploration/num paths total      1907
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.609482
exploration/Rewards Std             0.716411
exploration/Rewards Max            -0.00902159
exploration/Rewards Min            -6.49301
exploration/Returns Mean          -60.9482
exploration/Returns Std            52.0473
exploration/Returns Max           -14.7696
exploration/Returns Min          -148.03
exploration/Actions Mean            0.0176744
exploration/Actions Std             0.186601
exploration/Actions Max             0.999709
exploration/Actions Min            -0.850374
exploration/Num Paths               5
exploration/Average Returns       -60.9482
evaluation/num steps total     571500
evaluation/num paths total       5715
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.821409
evaluation/Rewards Std              1.02828
evaluation/Rewards Max             -0.0270128
evaluation/Rewards Min             -9.71465
evaluation/Returns Mean           -82.1409
evaluation/Returns Std             67.6353
evaluation/Returns Max            -14.2352
evaluation/Returns Min           -223.222
evaluation/Actions Mean             0.000309514
evaluation/Actions Std              0.182806
evaluation/Actions Max              0.997459
evaluation/Actions Min             -0.997593
evaluation/Num Paths               15
evaluation/Average Returns        -82.1409
time/data storing (s)               0.00280875
time/evaluation sampling (s)        0.325561
time/exploration sampling (s)       0.13637
time/logging (s)                    0.0035366
time/saving (s)                     0.00196954
time/training (s)                   1.95804
time/epoch (s)                      2.42829
time/total (s)                    934.825
Epoch                             380
-----------------------------  ----------------
2019-04-23 01:29:09.171266 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 381 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.341928
trainer/QF2 Loss                    0.34612
trainer/Policy Loss                57.3086
trainer/Q1 Predictions Mean       -55.4502
trainer/Q1 Predictions Std         46.9057
trainer/Q1 Predictions Max         -7.70255
trainer/Q1 Predictions Min       -158.36
trainer/Q2 Predictions Mean       -55.4487
trainer/Q2 Predictions Std         46.9256
trainer/Q2 Predictions Max         -7.6755
trainer/Q2 Predictions Min       -158.75
trainer/Q Targets Mean            -55.6727
trainer/Q Targets Std              47.0686
trainer/Q Targets Max              -7.73826
trainer/Q Targets Min            -161.42
trainer/Log Pis Mean                2.0737
trainer/Log Pis Std                 1.1082
trainer/Log Pis Max                 5.30083
trainer/Log Pis Min                -1.94448
trainer/Policy mu Mean             -0.105211
trainer/Policy mu Std               0.599768
trainer/Policy mu Max               2.55148
trainer/Policy mu Min              -3.01033
trainer/Policy log std Mean        -2.08485
trainer/Policy log std Std          0.44661
trainer/Policy log std Max         -0.293721
trainer/Policy log std Min         -2.96603
trainer/Alpha                       0.0682538
trainer/Alpha Loss                  0.197874
exploration/num steps total    191200
exploration/num paths total      1912
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.15537
exploration/Rewards Std             1.29656
exploration/Rewards Max            -0.0268174
exploration/Rewards Min            -8.75141
exploration/Returns Mean         -115.537
exploration/Returns Std            76.6492
exploration/Returns Max           -30.5539
exploration/Returns Min          -235.134
exploration/Actions Mean            0.00870783
exploration/Actions Std             0.249059
exploration/Actions Max             0.99939
exploration/Actions Min            -0.999244
exploration/Num Paths               5
exploration/Average Returns      -115.537
evaluation/num steps total     573000
evaluation/num paths total       5730
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.04691
evaluation/Rewards Std              1.25829
evaluation/Rewards Max             -0.0135932
evaluation/Rewards Min             -9.8173
evaluation/Returns Mean          -104.691
evaluation/Returns Std             74.0228
evaluation/Returns Max            -14.2617
evaluation/Returns Min           -227.207
evaluation/Actions Mean             0.0105517
evaluation/Actions Std              0.183429
evaluation/Actions Max              0.998596
evaluation/Actions Min             -0.998547
evaluation/Num Paths               15
evaluation/Average Returns       -104.691
time/data storing (s)               0.00280124
time/evaluation sampling (s)        0.32531
time/exploration sampling (s)       0.138941
time/logging (s)                    0.00476903
time/saving (s)                     0.00193113
time/training (s)                   1.99102
time/epoch (s)                      2.46478
time/total (s)                    937.295
Epoch                             381
-----------------------------  ---------------
2019-04-23 01:29:11.642208 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 382 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                  132.078
trainer/QF2 Loss                  133.491
trainer/Policy Loss                46.6435
trainer/Q1 Predictions Mean       -44.8854
trainer/Q1 Predictions Std         48.0773
trainer/Q1 Predictions Max         -7.4692
trainer/Q1 Predictions Min       -146.076
trainer/Q2 Predictions Mean       -44.9145
trainer/Q2 Predictions Std         48.173
trainer/Q2 Predictions Max         -7.50637
trainer/Q2 Predictions Min       -145.924
trainer/Q Targets Mean            -43.8214
trainer/Q Targets Std              48.204
trainer/Q Targets Max              -0.340971
trainer/Q Targets Min            -147.058
trainer/Log Pis Mean                1.89632
trainer/Log Pis Std                 1.30411
trainer/Log Pis Max                 6.48287
trainer/Log Pis Min                -2.0868
trainer/Policy mu Mean             -0.0573101
trainer/Policy mu Std               0.453625
trainer/Policy mu Max               2.25868
trainer/Policy mu Min              -3.26317
trainer/Policy log std Mean        -2.29366
trainer/Policy log std Std          0.345502
trainer/Policy log std Max         -0.710605
trainer/Policy log std Min         -2.89735
trainer/Alpha                       0.0638739
trainer/Alpha Loss                 -0.285218
exploration/num steps total    191700
exploration/num paths total      1917
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.938902
exploration/Rewards Std             0.959837
exploration/Rewards Max            -0.0159293
exploration/Rewards Min            -7.80752
exploration/Returns Mean          -93.8902
exploration/Returns Std            68.0334
exploration/Returns Max           -26.3177
exploration/Returns Min          -210.831
exploration/Actions Mean            0.00762057
exploration/Actions Std             0.21034
exploration/Actions Max             0.994448
exploration/Actions Min            -0.995052
exploration/Num Paths               5
exploration/Average Returns       -93.8902
evaluation/num steps total     574500
evaluation/num paths total       5745
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.1583
evaluation/Rewards Std              1.25957
evaluation/Rewards Max             -0.0394647
evaluation/Rewards Min            -10.5618
evaluation/Returns Mean          -115.83
evaluation/Returns Std             77.7467
evaluation/Returns Max            -10.6381
evaluation/Returns Min           -279.15
evaluation/Actions Mean             0.00116352
evaluation/Actions Std              0.196686
evaluation/Actions Max              0.99931
evaluation/Actions Min             -0.995308
evaluation/Num Paths               15
evaluation/Average Returns       -115.83
time/data storing (s)               0.00261376
time/evaluation sampling (s)        0.332684
time/exploration sampling (s)       0.138695
time/logging (s)                    0.00354312
time/saving (s)                     0.00191523
time/training (s)                   1.98021
time/epoch (s)                      2.45966
time/total (s)                    939.759
Epoch                             382
-----------------------------  ---------------
2019-04-23 01:29:14.150065 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 383 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.185581
trainer/QF2 Loss                    0.230865
trainer/Policy Loss                51.3463
trainer/Q1 Predictions Mean       -49.3442
trainer/Q1 Predictions Std         46.2802
trainer/Q1 Predictions Max         -7.44974
trainer/Q1 Predictions Min       -149.261
trainer/Q2 Predictions Mean       -49.3078
trainer/Q2 Predictions Std         46.2327
trainer/Q2 Predictions Max         -7.48728
trainer/Q2 Predictions Min       -149.141
trainer/Q Targets Mean            -49.3566
trainer/Q Targets Std              46.335
trainer/Q Targets Max              -7.41891
trainer/Q Targets Min            -150.173
trainer/Log Pis Mean                2.19194
trainer/Log Pis Std                 1.18744
trainer/Log Pis Max                 6.46821
trainer/Log Pis Min                -1.85832
trainer/Policy mu Mean             -0.151156
trainer/Policy mu Std               0.684863
trainer/Policy mu Max               2.57953
trainer/Policy mu Min              -3.42611
trainer/Policy log std Mean        -2.17122
trainer/Policy log std Std          0.431901
trainer/Policy log std Max         -0.193618
trainer/Policy log std Min         -2.82966
trainer/Alpha                       0.0695428
trainer/Alpha Loss                  0.51172
exploration/num steps total    192200
exploration/num paths total      1922
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.595476
exploration/Rewards Std             0.927257
exploration/Rewards Max            -0.0204798
exploration/Rewards Min            -7.40636
exploration/Returns Mean          -59.5476
exploration/Returns Std            58.697
exploration/Returns Max           -21.0054
exploration/Returns Min          -175.228
exploration/Actions Mean            0.00583291
exploration/Actions Std             0.192434
exploration/Actions Max             0.991972
exploration/Actions Min            -0.999334
exploration/Num Paths               5
exploration/Average Returns       -59.5476
evaluation/num steps total     576000
evaluation/num paths total       5760
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.754297
evaluation/Rewards Std              1.165
evaluation/Rewards Max             -0.0191244
evaluation/Rewards Min             -9.37646
evaluation/Returns Mean           -75.4297
evaluation/Returns Std             64.0529
evaluation/Returns Max             -7.73167
evaluation/Returns Min           -197.115
evaluation/Actions Mean             0.00646886
evaluation/Actions Std              0.194154
evaluation/Actions Max              0.998391
evaluation/Actions Min             -0.998722
evaluation/Num Paths               15
evaluation/Average Returns        -75.4297
time/data storing (s)               0.00270164
time/evaluation sampling (s)        0.351824
time/exploration sampling (s)       0.135943
time/logging (s)                    0.004779
time/saving (s)                     0.0100697
time/training (s)                   1.99383
time/epoch (s)                      2.49915
time/total (s)                    942.262
Epoch                             383
-----------------------------  ---------------
2019-04-23 01:29:16.629947 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 384 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   10.0124
trainer/QF2 Loss                   10.0468
trainer/Policy Loss                45.6812
trainer/Q1 Predictions Mean       -43.8928
trainer/Q1 Predictions Std         45.8594
trainer/Q1 Predictions Max         -7.25087
trainer/Q1 Predictions Min       -146.517
trainer/Q2 Predictions Mean       -43.8851
trainer/Q2 Predictions Std         45.8392
trainer/Q2 Predictions Max         -7.25869
trainer/Q2 Predictions Min       -145.68
trainer/Q Targets Mean            -44.2238
trainer/Q Targets Std              46.674
trainer/Q Targets Max              -0.664068
trainer/Q Targets Min            -148.343
trainer/Log Pis Mean                2.02753
trainer/Log Pis Std                 1.0296
trainer/Log Pis Max                 6.54136
trainer/Log Pis Min                -2.50775
trainer/Policy mu Mean             -0.0296148
trainer/Policy mu Std               0.508717
trainer/Policy mu Max               2.3598
trainer/Policy mu Min              -2.41442
trainer/Policy log std Mean        -2.15218
trainer/Policy log std Std          0.375999
trainer/Policy log std Max         -0.659112
trainer/Policy log std Min         -2.76122
trainer/Alpha                       0.0697884
trainer/Alpha Loss                  0.0732823
exploration/num steps total    192700
exploration/num paths total      1927
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.940433
exploration/Rewards Std             1.14771
exploration/Rewards Max            -0.00390303
exploration/Rewards Min            -6.22205
exploration/Returns Mean          -94.0433
exploration/Returns Std            94.9449
exploration/Returns Max           -23.9288
exploration/Returns Min          -278.047
exploration/Actions Mean            0.0119981
exploration/Actions Std             0.199172
exploration/Actions Max             0.992619
exploration/Actions Min            -0.975652
exploration/Num Paths               5
exploration/Average Returns       -94.0433
evaluation/num steps total     577500
evaluation/num paths total       5775
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.16353
evaluation/Rewards Std              1.32178
evaluation/Rewards Max             -0.0413468
evaluation/Rewards Min             -9.60835
evaluation/Returns Mean          -116.353
evaluation/Returns Std            109.196
evaluation/Returns Max             -5.5781
evaluation/Returns Min           -288.163
evaluation/Actions Mean            -0.0179614
evaluation/Actions Std              0.178412
evaluation/Actions Max              0.999304
evaluation/Actions Min             -0.998498
evaluation/Num Paths               15
evaluation/Average Returns       -116.353
time/data storing (s)               0.00276875
time/evaluation sampling (s)        0.326318
time/exploration sampling (s)       0.136758
time/logging (s)                    0.00486123
time/saving (s)                     0.00192158
time/training (s)                   1.99726
time/epoch (s)                      2.46989
time/total (s)                    944.737
Epoch                             384
-----------------------------  ---------------
2019-04-23 01:29:19.113422 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 385 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    2.15997
trainer/QF2 Loss                    2.34305
trainer/Policy Loss                44.0659
trainer/Q1 Predictions Mean       -42.3077
trainer/Q1 Predictions Std         42.974
trainer/Q1 Predictions Max         -7.30616
trainer/Q1 Predictions Min       -143.351
trainer/Q2 Predictions Mean       -42.2332
trainer/Q2 Predictions Std         42.903
trainer/Q2 Predictions Max         -7.35148
trainer/Q2 Predictions Min       -142.98
trainer/Q Targets Mean            -42.9374
trainer/Q Targets Std              43.5933
trainer/Q Targets Max              -0.46044
trainer/Q Targets Min            -145.331
trainer/Log Pis Mean                1.97899
trainer/Log Pis Std                 1.32268
trainer/Log Pis Max                 6.98456
trainer/Log Pis Min                -2.32362
trainer/Policy mu Mean             -0.0859686
trainer/Policy mu Std               0.597673
trainer/Policy mu Max               3.75607
trainer/Policy mu Min              -3.9346
trainer/Policy log std Mean        -2.24695
trainer/Policy log std Std          0.41646
trainer/Policy log std Max         -0.472289
trainer/Policy log std Min         -2.95607
trainer/Alpha                       0.0676866
trainer/Alpha Loss                 -0.056589
exploration/num steps total    193200
exploration/num paths total      1932
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.938615
exploration/Rewards Std             1.2605
exploration/Rewards Max            -0.0111593
exploration/Rewards Min            -8.69058
exploration/Returns Mean          -93.8615
exploration/Returns Std            97.4595
exploration/Returns Max           -17.3202
exploration/Returns Min          -283.36
exploration/Actions Mean            0.00266425
exploration/Actions Std             0.21172
exploration/Actions Max             0.999484
exploration/Actions Min            -0.999034
exploration/Num Paths               5
exploration/Average Returns       -93.8615
evaluation/num steps total     579000
evaluation/num paths total       5790
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.856705
evaluation/Rewards Std              1.1597
evaluation/Rewards Max             -0.0192638
evaluation/Rewards Min            -11.2522
evaluation/Returns Mean           -85.6705
evaluation/Returns Std             84.0921
evaluation/Returns Max             -9.67773
evaluation/Returns Min           -305.38
evaluation/Actions Mean             0.0106949
evaluation/Actions Std              0.174905
evaluation/Actions Max              0.999297
evaluation/Actions Min             -0.998276
evaluation/Num Paths               15
evaluation/Average Returns        -85.6705
time/data storing (s)               0.00278128
time/evaluation sampling (s)        0.321139
time/exploration sampling (s)       0.136883
time/logging (s)                    0.00479557
time/saving (s)                     0.00200843
time/training (s)                   2.0057
time/epoch (s)                      2.4733
time/total (s)                    947.214
Epoch                             385
-----------------------------  ---------------
2019-04-23 01:29:21.581878 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 386 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                  124.517
trainer/QF2 Loss                  124.357
trainer/Policy Loss                44.7668
trainer/Q1 Predictions Mean       -42.9331
trainer/Q1 Predictions Std         43.6838
trainer/Q1 Predictions Max         -7.40283
trainer/Q1 Predictions Min       -155.064
trainer/Q2 Predictions Mean       -42.9744
trainer/Q2 Predictions Std         43.72
trainer/Q2 Predictions Max         -7.4019
trainer/Q2 Predictions Min       -157.102
trainer/Q Targets Mean            -42.2619
trainer/Q Targets Std              43.7021
trainer/Q Targets Max              -2.33618
trainer/Q Targets Min            -155.785
trainer/Log Pis Mean                2.07985
trainer/Log Pis Std                 1.41428
trainer/Log Pis Max                 7.52262
trainer/Log Pis Min                -3.68893
trainer/Policy mu Mean             -0.098971
trainer/Policy mu Std               0.698375
trainer/Policy mu Max               3.54097
trainer/Policy mu Min              -2.75908
trainer/Policy log std Mean        -2.17811
trainer/Policy log std Std          0.525748
trainer/Policy log std Max         -0.126974
trainer/Policy log std Min         -2.94817
trainer/Alpha                       0.0684504
trainer/Alpha Loss                  0.214113
exploration/num steps total    193700
exploration/num paths total      1937
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.15741
exploration/Rewards Std             1.29007
exploration/Rewards Max            -0.00965511
exploration/Rewards Min            -7.25429
exploration/Returns Mean         -115.741
exploration/Returns Std           103.737
exploration/Returns Max           -32.1911
exploration/Returns Min          -294.507
exploration/Actions Mean            0.00149811
exploration/Actions Std             0.234366
exploration/Actions Max             0.996627
exploration/Actions Min            -0.99886
exploration/Num Paths               5
exploration/Average Returns      -115.741
evaluation/num steps total     580500
evaluation/num paths total       5805
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.07802
evaluation/Rewards Std              1.21877
evaluation/Rewards Max             -0.0180808
evaluation/Rewards Min            -10.556
evaluation/Returns Mean          -107.802
evaluation/Returns Std             73.9744
evaluation/Returns Max             -6.9371
evaluation/Returns Min           -291.486
evaluation/Actions Mean             0.0124954
evaluation/Actions Std              0.185988
evaluation/Actions Max              0.999098
evaluation/Actions Min             -0.997739
evaluation/Num Paths               15
evaluation/Average Returns       -107.802
time/data storing (s)               0.0028149
time/evaluation sampling (s)        0.328527
time/exploration sampling (s)       0.138124
time/logging (s)                    0.00477242
time/saving (s)                     0.00191536
time/training (s)                   1.98388
time/epoch (s)                      2.46003
time/total (s)                    949.679
Epoch                             386
-----------------------------  ---------------
2019-04-23 01:29:24.044726 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 387 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.255203
trainer/QF2 Loss                    0.543072
trainer/Policy Loss                45.3446
trainer/Q1 Predictions Mean       -43.5335
trainer/Q1 Predictions Std         45.5365
trainer/Q1 Predictions Max         -7.33195
trainer/Q1 Predictions Min       -149.774
trainer/Q2 Predictions Mean       -43.5635
trainer/Q2 Predictions Std         45.5754
trainer/Q2 Predictions Max         -7.38405
trainer/Q2 Predictions Min       -149.358
trainer/Q Targets Mean            -43.508
trainer/Q Targets Std              45.6252
trainer/Q Targets Max              -7.29466
trainer/Q Targets Min            -150.529
trainer/Log Pis Mean                2.08296
trainer/Log Pis Std                 1.07184
trainer/Log Pis Max                 5.92112
trainer/Log Pis Min                -2.34283
trainer/Policy mu Mean             -0.105571
trainer/Policy mu Std               0.529098
trainer/Policy mu Max               2.85245
trainer/Policy mu Min              -2.50374
trainer/Policy log std Mean        -2.20333
trainer/Policy log std Std          0.418472
trainer/Policy log std Max         -0.629984
trainer/Policy log std Min         -2.80042
trainer/Alpha                       0.069009
trainer/Alpha Loss                  0.221808
exploration/num steps total    194200
exploration/num paths total      1942
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.42039
exploration/Rewards Std             1.27711
exploration/Rewards Max            -0.0136077
exploration/Rewards Min           -10.3193
exploration/Returns Mean         -142.039
exploration/Returns Std            94.3418
exploration/Returns Max           -32.1317
exploration/Returns Min          -274.058
exploration/Actions Mean            0.0111263
exploration/Actions Std             0.230103
exploration/Actions Max             0.998803
exploration/Actions Min            -0.998243
exploration/Num Paths               5
exploration/Average Returns      -142.039
evaluation/num steps total     582000
evaluation/num paths total       5820
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.797712
evaluation/Rewards Std              1.04615
evaluation/Rewards Max             -0.00425131
evaluation/Rewards Min            -11.5197
evaluation/Returns Mean           -79.7712
evaluation/Returns Std             65.5713
evaluation/Returns Max            -10.9477
evaluation/Returns Min           -199.116
evaluation/Actions Mean             0.0157022
evaluation/Actions Std              0.179271
evaluation/Actions Max              0.998928
evaluation/Actions Min             -0.996943
evaluation/Num Paths               15
evaluation/Average Returns        -79.7712
time/data storing (s)               0.00276578
time/evaluation sampling (s)        0.328491
time/exploration sampling (s)       0.141585
time/logging (s)                    0.00439316
time/saving (s)                     0.00194662
time/training (s)                   1.97308
time/epoch (s)                      2.45226
time/total (s)                    952.136
Epoch                             387
-----------------------------  ---------------
2019-04-23 01:29:26.509860 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 388 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0872101
trainer/QF2 Loss                    0.0707848
trainer/Policy Loss                36.2353
trainer/Q1 Predictions Mean       -34.3549
trainer/Q1 Predictions Std         38.9482
trainer/Q1 Predictions Max         -7.23935
trainer/Q1 Predictions Min       -144.216
trainer/Q2 Predictions Mean       -34.4053
trainer/Q2 Predictions Std         38.9798
trainer/Q2 Predictions Max         -7.18184
trainer/Q2 Predictions Min       -144.326
trainer/Q Targets Mean            -34.4092
trainer/Q Targets Std              38.9149
trainer/Q Targets Max              -7.32645
trainer/Q Targets Min            -143.955
trainer/Log Pis Mean                1.94573
trainer/Log Pis Std                 1.08955
trainer/Log Pis Max                 4.79872
trainer/Log Pis Min                -1.89339
trainer/Policy mu Mean             -0.044326
trainer/Policy mu Std               0.509423
trainer/Policy mu Max               3.30171
trainer/Policy mu Min              -2.6548
trainer/Policy log std Mean        -2.20941
trainer/Policy log std Std          0.388277
trainer/Policy log std Max         -0.182789
trainer/Policy log std Min         -2.82706
trainer/Alpha                       0.0717498
trainer/Alpha Loss                 -0.142982
exploration/num steps total    194700
exploration/num paths total      1947
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.267314
exploration/Rewards Std             0.633394
exploration/Rewards Max            -0.00590179
exploration/Rewards Min            -7.10823
exploration/Returns Mean          -26.7314
exploration/Returns Std             8.0648
exploration/Returns Max           -16.721
exploration/Returns Min           -38.2833
exploration/Actions Mean           -0.00264692
exploration/Actions Std             0.211049
exploration/Actions Max             0.998884
exploration/Actions Min            -0.998885
exploration/Num Paths               5
exploration/Average Returns       -26.7314
evaluation/num steps total     583500
evaluation/num paths total       5835
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.20879
evaluation/Rewards Std              1.15022
evaluation/Rewards Max             -0.00539307
evaluation/Rewards Min             -9.77102
evaluation/Returns Mean          -120.879
evaluation/Returns Std             82.7071
evaluation/Returns Max            -11.9968
evaluation/Returns Min           -275.374
evaluation/Actions Mean            -0.00605779
evaluation/Actions Std              0.177444
evaluation/Actions Max              0.996508
evaluation/Actions Min             -0.998801
evaluation/Num Paths               15
evaluation/Average Returns       -120.879
time/data storing (s)               0.00283275
time/evaluation sampling (s)        0.322862
time/exploration sampling (s)       0.138325
time/logging (s)                    0.00452867
time/saving (s)                     0.00191672
time/training (s)                   1.98467
time/epoch (s)                      2.45513
time/total (s)                    954.595
Epoch                             388
-----------------------------  ---------------
2019-04-23 01:29:28.971762 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 389 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    2.68965
trainer/QF2 Loss                    2.61484
trainer/Policy Loss                43.3518
trainer/Q1 Predictions Mean       -41.6266
trainer/Q1 Predictions Std         45.7493
trainer/Q1 Predictions Max         -7.40632
trainer/Q1 Predictions Min       -149.006
trainer/Q2 Predictions Mean       -41.6076
trainer/Q2 Predictions Std         45.7387
trainer/Q2 Predictions Max         -7.4379
trainer/Q2 Predictions Min       -148.717
trainer/Q Targets Mean            -41.706
trainer/Q Targets Std              46.2033
trainer/Q Targets Max              -0.27755
trainer/Q Targets Min            -149.335
trainer/Log Pis Mean                1.98274
trainer/Log Pis Std                 1.07928
trainer/Log Pis Max                 5.82619
trainer/Log Pis Min                -2.46593
trainer/Policy mu Mean              0.0701569
trainer/Policy mu Std               0.496506
trainer/Policy mu Max               2.60247
trainer/Policy mu Min              -2.50344
trainer/Policy log std Mean        -2.20465
trainer/Policy log std Std          0.397208
trainer/Policy log std Max         -0.406712
trainer/Policy log std Min         -2.80328
trainer/Alpha                       0.0713576
trainer/Alpha Loss                 -0.0455528
exploration/num steps total    195200
exploration/num paths total      1952
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.01146
exploration/Rewards Std             1.04353
exploration/Rewards Max            -0.0317641
exploration/Rewards Min            -6.20571
exploration/Returns Mean         -101.146
exploration/Returns Std            86.7376
exploration/Returns Max           -21.1207
exploration/Returns Min          -266.543
exploration/Actions Mean           -0.00934308
exploration/Actions Std             0.196696
exploration/Actions Max             0.996677
exploration/Actions Min            -0.998722
exploration/Num Paths               5
exploration/Average Returns      -101.146
evaluation/num steps total     585000
evaluation/num paths total       5850
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.979727
evaluation/Rewards Std              1.09433
evaluation/Rewards Max             -0.0605187
evaluation/Rewards Min            -11.2452
evaluation/Returns Mean           -97.9727
evaluation/Returns Std             77.3075
evaluation/Returns Max             -9.19321
evaluation/Returns Min           -268.779
evaluation/Actions Mean             0.00420871
evaluation/Actions Std              0.167391
evaluation/Actions Max              0.999631
evaluation/Actions Min             -0.994706
evaluation/Num Paths               15
evaluation/Average Returns        -97.9727
time/data storing (s)               0.00276377
time/evaluation sampling (s)        0.329797
time/exploration sampling (s)       0.14041
time/logging (s)                    0.004785
time/saving (s)                     0.00194245
time/training (s)                   1.97253
time/epoch (s)                      2.45223
time/total (s)                    957.052
Epoch                             389
-----------------------------  ---------------
2019-04-23 01:29:31.440625 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 390 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   67.5998
trainer/QF2 Loss                   68.2641
trainer/Policy Loss                39.2124
trainer/Q1 Predictions Mean       -37.1909
trainer/Q1 Predictions Std         37.2374
trainer/Q1 Predictions Max         -7.09936
trainer/Q1 Predictions Min       -141.868
trainer/Q2 Predictions Mean       -37.2133
trainer/Q2 Predictions Std         37.2885
trainer/Q2 Predictions Max         -6.99833
trainer/Q2 Predictions Min       -141.871
trainer/Q Targets Mean            -36.8817
trainer/Q Targets Std              37.7028
trainer/Q Targets Max              -1.55523
trainer/Q Targets Min            -144.112
trainer/Log Pis Mean                2.13014
trainer/Log Pis Std                 1.22075
trainer/Log Pis Max                 6.86608
trainer/Log Pis Min                -2.3433
trainer/Policy mu Mean             -0.0439895
trainer/Policy mu Std               0.587681
trainer/Policy mu Max               3.50563
trainer/Policy mu Min              -2.58673
trainer/Policy log std Mean        -2.16755
trainer/Policy log std Std          0.449171
trainer/Policy log std Max         -0.383572
trainer/Policy log std Min         -2.79695
trainer/Alpha                       0.0696924
trainer/Alpha Loss                  0.346651
exploration/num steps total    195700
exploration/num paths total      1957
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.821312
exploration/Rewards Std             0.97192
exploration/Rewards Max            -0.0248519
exploration/Rewards Min           -10.7792
exploration/Returns Mean          -82.1312
exploration/Returns Std            43.4932
exploration/Returns Max           -35.3508
exploration/Returns Min          -153.665
exploration/Actions Mean            0.0193982
exploration/Actions Std             0.191441
exploration/Actions Max             0.999351
exploration/Actions Min            -0.976654
exploration/Num Paths               5
exploration/Average Returns       -82.1312
evaluation/num steps total     586500
evaluation/num paths total       5865
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.807831
evaluation/Rewards Std              1.22817
evaluation/Rewards Max             -0.0359152
evaluation/Rewards Min            -10.691
evaluation/Returns Mean           -80.7831
evaluation/Returns Std             84.8857
evaluation/Returns Max             -8.04613
evaluation/Returns Min           -279.159
evaluation/Actions Mean            -0.00522175
evaluation/Actions Std              0.187681
evaluation/Actions Max              0.999383
evaluation/Actions Min             -0.996123
evaluation/Num Paths               15
evaluation/Average Returns        -80.7831
time/data storing (s)               0.00281191
time/evaluation sampling (s)        0.325454
time/exploration sampling (s)       0.136299
time/logging (s)                    0.00478098
time/saving (s)                     0.00194338
time/training (s)                   1.98857
time/epoch (s)                      2.45986
time/total (s)                    959.516
Epoch                             390
-----------------------------  ---------------
2019-04-23 01:29:33.901871 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 391 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   10.5758
trainer/QF2 Loss                   10.4852
trainer/Policy Loss                52.6277
trainer/Q1 Predictions Mean       -50.6855
trainer/Q1 Predictions Std         46.3735
trainer/Q1 Predictions Max         -7.31225
trainer/Q1 Predictions Min       -152.598
trainer/Q2 Predictions Mean       -50.6515
trainer/Q2 Predictions Std         46.3636
trainer/Q2 Predictions Max         -7.37372
trainer/Q2 Predictions Min       -153.124
trainer/Q Targets Mean            -50.5723
trainer/Q Targets Std              46.807
trainer/Q Targets Max              -0.249718
trainer/Q Targets Min            -153.364
trainer/Log Pis Mean                2.17401
trainer/Log Pis Std                 1.03481
trainer/Log Pis Max                 4.65236
trainer/Log Pis Min                -1.74098
trainer/Policy mu Mean             -0.113907
trainer/Policy mu Std               0.549624
trainer/Policy mu Max               2.25822
trainer/Policy mu Min              -2.70921
trainer/Policy log std Mean        -2.17762
trainer/Policy log std Std          0.477196
trainer/Policy log std Max         -0.405494
trainer/Policy log std Min         -2.85183
trainer/Alpha                       0.0702228
trainer/Alpha Loss                  0.462178
exploration/num steps total    196200
exploration/num paths total      1962
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.974383
exploration/Rewards Std             1.10608
exploration/Rewards Max            -0.0158473
exploration/Rewards Min            -7.22731
exploration/Returns Mean          -97.4383
exploration/Returns Std            85.1563
exploration/Returns Max           -16.6409
exploration/Returns Min          -208.963
exploration/Actions Mean            0.0106973
exploration/Actions Std             0.212264
exploration/Actions Max             0.998113
exploration/Actions Min            -0.999625
exploration/Num Paths               5
exploration/Average Returns       -97.4383
evaluation/num steps total     588000
evaluation/num paths total       5880
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.02906
evaluation/Rewards Std              1.23065
evaluation/Rewards Max             -0.0384158
evaluation/Rewards Min            -10.1553
evaluation/Returns Mean          -102.906
evaluation/Returns Std             90.7881
evaluation/Returns Max             -8.15931
evaluation/Returns Min           -271.524
evaluation/Actions Mean             0.0147108
evaluation/Actions Std              0.175439
evaluation/Actions Max              0.999335
evaluation/Actions Min             -0.992725
evaluation/Num Paths               15
evaluation/Average Returns       -102.906
time/data storing (s)               0.00281308
time/evaluation sampling (s)        0.333676
time/exploration sampling (s)       0.139056
time/logging (s)                    0.00475443
time/saving (s)                     0.00194314
time/training (s)                   1.96879
time/epoch (s)                      2.45103
time/total (s)                    961.971
Epoch                             391
-----------------------------  ---------------
2019-04-23 01:29:36.364434 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 392 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                  147.507
trainer/QF2 Loss                  147.638
trainer/Policy Loss                50.4825
trainer/Q1 Predictions Mean       -48.739
trainer/Q1 Predictions Std         42.9524
trainer/Q1 Predictions Max         -7.15417
trainer/Q1 Predictions Min       -143.756
trainer/Q2 Predictions Mean       -48.7288
trainer/Q2 Predictions Std         42.9045
trainer/Q2 Predictions Max         -7.15248
trainer/Q2 Predictions Min       -143.527
trainer/Q Targets Mean            -47.332
trainer/Q Targets Std              43.0661
trainer/Q Targets Max              -2.00551
trainer/Q Targets Min            -144.251
trainer/Log Pis Mean                1.94074
trainer/Log Pis Std                 1.1605
trainer/Log Pis Max                 5.50025
trainer/Log Pis Min                -2.62682
trainer/Policy mu Mean             -0.0812626
trainer/Policy mu Std               0.534618
trainer/Policy mu Max               2.25645
trainer/Policy mu Min              -2.69172
trainer/Policy log std Mean        -2.17209
trainer/Policy log std Std          0.432076
trainer/Policy log std Max         -0.431411
trainer/Policy log std Min         -2.83667
trainer/Alpha                       0.0697473
trainer/Alpha Loss                 -0.157788
exploration/num steps total    196700
exploration/num paths total      1967
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.794842
exploration/Rewards Std             1.44808
exploration/Rewards Max            -0.0151751
exploration/Rewards Min           -11.3493
exploration/Returns Mean          -79.4842
exploration/Returns Std            43.6583
exploration/Returns Max           -31.3418
exploration/Returns Min          -159.596
exploration/Actions Mean            0.00589194
exploration/Actions Std             0.260998
exploration/Actions Max             0.999964
exploration/Actions Min            -0.997445
exploration/Num Paths               5
exploration/Average Returns       -79.4842
evaluation/num steps total     589500
evaluation/num paths total       5895
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.26069
evaluation/Rewards Std              1.40985
evaluation/Rewards Max             -0.0201559
evaluation/Rewards Min            -10.6256
evaluation/Returns Mean          -126.069
evaluation/Returns Std             94.4929
evaluation/Returns Max            -16.8903
evaluation/Returns Min           -289.126
evaluation/Actions Mean            -0.00657381
evaluation/Actions Std              0.204288
evaluation/Actions Max              0.999305
evaluation/Actions Min             -0.998617
evaluation/Num Paths               15
evaluation/Average Returns       -126.069
time/data storing (s)               0.00254589
time/evaluation sampling (s)        0.327254
time/exploration sampling (s)       0.136126
time/logging (s)                    0.00472357
time/saving (s)                     0.00197484
time/training (s)                   1.97976
time/epoch (s)                      2.45239
time/total (s)                    964.428
Epoch                             392
-----------------------------  ---------------
2019-04-23 01:29:38.836575 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 393 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                  120.785
trainer/QF2 Loss                  121.201
trainer/Policy Loss                54.8488
trainer/Q1 Predictions Mean       -53.0798
trainer/Q1 Predictions Std         47.8605
trainer/Q1 Predictions Max         -7.15502
trainer/Q1 Predictions Min       -146.448
trainer/Q2 Predictions Mean       -53.1046
trainer/Q2 Predictions Std         47.8775
trainer/Q2 Predictions Max         -7.20718
trainer/Q2 Predictions Min       -147.253
trainer/Q Targets Mean            -52.4652
trainer/Q Targets Std              48.4673
trainer/Q Targets Max              -0.28322
trainer/Q Targets Min            -149.019
trainer/Log Pis Mean                1.97138
trainer/Log Pis Std                 1.00446
trainer/Log Pis Max                 4.21701
trainer/Log Pis Min                -2.17015
trainer/Policy mu Mean             -0.0625849
trainer/Policy mu Std               0.51743
trainer/Policy mu Max               3.00611
trainer/Policy mu Min              -2.85506
trainer/Policy log std Mean        -2.17695
trainer/Policy log std Std          0.41654
trainer/Policy log std Max         -0.618574
trainer/Policy log std Min         -2.90029
trainer/Alpha                       0.0702122
trainer/Alpha Loss                 -0.0760269
exploration/num steps total    197200
exploration/num paths total      1972
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.68218
exploration/Rewards Std             1.18526
exploration/Rewards Max            -0.0113901
exploration/Rewards Min            -8.98267
exploration/Returns Mean          -68.218
exploration/Returns Std            57.8155
exploration/Returns Max           -27.4301
exploration/Returns Min          -181.651
exploration/Actions Mean           -0.0186591
exploration/Actions Std             0.218517
exploration/Actions Max             0.998781
exploration/Actions Min            -0.999238
exploration/Num Paths               5
exploration/Average Returns       -68.218
evaluation/num steps total     591000
evaluation/num paths total       5910
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.13316
evaluation/Rewards Std              1.18211
evaluation/Rewards Max             -0.00814464
evaluation/Rewards Min             -8.26231
evaluation/Returns Mean          -113.316
evaluation/Returns Std             89.9885
evaluation/Returns Max            -15.9695
evaluation/Returns Min           -267.785
evaluation/Actions Mean             0.0111069
evaluation/Actions Std              0.173455
evaluation/Actions Max              0.999149
evaluation/Actions Min             -0.997041
evaluation/Num Paths               15
evaluation/Average Returns       -113.316
time/data storing (s)               0.00257417
time/evaluation sampling (s)        0.32424
time/exploration sampling (s)       0.137868
time/logging (s)                    0.00472809
time/saving (s)                     0.00194674
time/training (s)                   1.99056
time/epoch (s)                      2.46192
time/total (s)                    966.894
Epoch                             393
-----------------------------  ---------------
2019-04-23 01:29:41.297608 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 394 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    2.16975
trainer/QF2 Loss                    2.21032
trainer/Policy Loss                43.7665
trainer/Q1 Predictions Mean       -41.8728
trainer/Q1 Predictions Std         44.5406
trainer/Q1 Predictions Max         -7.27537
trainer/Q1 Predictions Min       -155.028
trainer/Q2 Predictions Mean       -41.8464
trainer/Q2 Predictions Std         44.5301
trainer/Q2 Predictions Max         -7.3045
trainer/Q2 Predictions Min       -155.319
trainer/Q Targets Mean            -42.3663
trainer/Q Targets Std              45.2839
trainer/Q Targets Max              -0.0369302
trainer/Q Targets Min            -154.945
trainer/Log Pis Mean                2.11659
trainer/Log Pis Std                 1.14817
trainer/Log Pis Max                 6.05396
trainer/Log Pis Min                -1.81402
trainer/Policy mu Mean             -0.121187
trainer/Policy mu Std               0.548877
trainer/Policy mu Max               2.98734
trainer/Policy mu Min              -3.16163
trainer/Policy log std Mean        -2.2519
trainer/Policy log std Std          0.423448
trainer/Policy log std Max         -0.48289
trainer/Policy log std Min         -2.85192
trainer/Alpha                       0.070355
trainer/Alpha Loss                  0.309449
exploration/num steps total    197700
exploration/num paths total      1977
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.12065
exploration/Rewards Std             1.12116
exploration/Rewards Max            -0.00948965
exploration/Rewards Min            -6.07865
exploration/Returns Mean         -112.065
exploration/Returns Std            89.9249
exploration/Returns Max           -32.3332
exploration/Returns Min          -272.718
exploration/Actions Mean            0.00315232
exploration/Actions Std             0.211192
exploration/Actions Max             0.998584
exploration/Actions Min            -0.991375
exploration/Num Paths               5
exploration/Average Returns      -112.065
evaluation/num steps total     592500
evaluation/num paths total       5925
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.975351
evaluation/Rewards Std              1.33636
evaluation/Rewards Max             -0.0513321
evaluation/Rewards Min             -9.78221
evaluation/Returns Mean           -97.5351
evaluation/Returns Std            101.99
evaluation/Returns Max            -11.6344
evaluation/Returns Min           -292.703
evaluation/Actions Mean            -0.0190636
evaluation/Actions Std              0.187029
evaluation/Actions Max              0.998707
evaluation/Actions Min             -0.999434
evaluation/Num Paths               15
evaluation/Average Returns        -97.5351
time/data storing (s)               0.00254508
time/evaluation sampling (s)        0.329531
time/exploration sampling (s)       0.136064
time/logging (s)                    0.00348536
time/saving (s)                     0.0015495
time/training (s)                   1.97654
time/epoch (s)                      2.44972
time/total (s)                    969.349
Epoch                             394
-----------------------------  ---------------
2019-04-23 01:29:43.788101 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 395 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.839689
trainer/QF2 Loss                    0.849828
trainer/Policy Loss                40.774
trainer/Q1 Predictions Mean       -39.2191
trainer/Q1 Predictions Std         43.5364
trainer/Q1 Predictions Max         -7.09606
trainer/Q1 Predictions Min       -146.54
trainer/Q2 Predictions Mean       -39.1921
trainer/Q2 Predictions Std         43.5039
trainer/Q2 Predictions Max         -7.12857
trainer/Q2 Predictions Min       -145.729
trainer/Q Targets Mean            -39.3723
trainer/Q Targets Std              43.7525
trainer/Q Targets Max              -0.074979
trainer/Q Targets Min            -146.11
trainer/Log Pis Mean                1.81956
trainer/Log Pis Std                 1.10122
trainer/Log Pis Max                 5.62067
trainer/Log Pis Min                -1.35156
trainer/Policy mu Mean             -0.11807
trainer/Policy mu Std               0.449805
trainer/Policy mu Max               1.39106
trainer/Policy mu Min              -2.71704
trainer/Policy log std Mean        -2.16804
trainer/Policy log std Std          0.350493
trainer/Policy log std Max         -0.568342
trainer/Policy log std Min         -2.95483
trainer/Alpha                       0.0691126
trainer/Alpha Loss                 -0.482121
exploration/num steps total    198200
exploration/num paths total      1982
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.732237
exploration/Rewards Std             1.09773
exploration/Rewards Max            -0.0165047
exploration/Rewards Min           -10.3397
exploration/Returns Mean          -73.2237
exploration/Returns Std            45.985
exploration/Returns Max           -31.7074
exploration/Returns Min          -158.202
exploration/Actions Mean           -0.0256664
exploration/Actions Std             0.238586
exploration/Actions Max             0.999596
exploration/Actions Min            -0.999955
exploration/Num Paths               5
exploration/Average Returns       -73.2237
evaluation/num steps total     594000
evaluation/num paths total       5940
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.998777
evaluation/Rewards Std              1.32686
evaluation/Rewards Max             -0.0320754
evaluation/Rewards Min            -10.2072
evaluation/Returns Mean           -99.8777
evaluation/Returns Std             95.3643
evaluation/Returns Max             -4.05449
evaluation/Returns Min           -295.993
evaluation/Actions Mean            -0.00304379
evaluation/Actions Std              0.188348
evaluation/Actions Max              0.999153
evaluation/Actions Min             -0.998202
evaluation/Num Paths               15
evaluation/Average Returns        -99.8777
time/data storing (s)               0.00275719
time/evaluation sampling (s)        0.33031
time/exploration sampling (s)       0.136782
time/logging (s)                    0.00380077
time/saving (s)                     0.00955446
time/training (s)                   1.9974
time/epoch (s)                      2.48061
time/total (s)                    971.833
Epoch                             395
-----------------------------  ---------------
2019-04-23 01:29:46.252858 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 396 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    2.22923
trainer/QF2 Loss                    2.29156
trainer/Policy Loss                47.5197
trainer/Q1 Predictions Mean       -45.6244
trainer/Q1 Predictions Std         42.2681
trainer/Q1 Predictions Max         -6.98315
trainer/Q1 Predictions Min       -140.516
trainer/Q2 Predictions Mean       -45.6126
trainer/Q2 Predictions Std         42.2723
trainer/Q2 Predictions Max         -6.9769
trainer/Q2 Predictions Min       -140.76
trainer/Q Targets Mean            -46.6529
trainer/Q Targets Std              43.2721
trainer/Q Targets Max              -7.11349
trainer/Q Targets Min            -143.652
trainer/Log Pis Mean                2.06317
trainer/Log Pis Std                 1.16846
trainer/Log Pis Max                 5.33345
trainer/Log Pis Min                -2.56968
trainer/Policy mu Mean             -0.0452842
trainer/Policy mu Std               0.453784
trainer/Policy mu Max               2.62804
trainer/Policy mu Min              -2.49358
trainer/Policy log std Mean        -2.26712
trainer/Policy log std Std          0.35211
trainer/Policy log std Max         -0.512979
trainer/Policy log std Min         -2.79947
trainer/Alpha                       0.0699047
trainer/Alpha Loss                  0.168072
exploration/num steps total    198700
exploration/num paths total      1987
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.931791
exploration/Rewards Std             1.25492
exploration/Rewards Max            -0.0116265
exploration/Rewards Min            -8.22949
exploration/Returns Mean          -93.1791
exploration/Returns Std            95.3743
exploration/Returns Max           -27.3527
exploration/Returns Min          -278.501
exploration/Actions Mean           -0.0180967
exploration/Actions Std             0.208905
exploration/Actions Max             0.987205
exploration/Actions Min            -0.997694
exploration/Num Paths               5
exploration/Average Returns       -93.1791
evaluation/num steps total     595500
evaluation/num paths total       5955
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.632558
evaluation/Rewards Std              1.09035
evaluation/Rewards Max             -0.0432487
evaluation/Rewards Min             -9.97147
evaluation/Returns Mean           -63.2558
evaluation/Returns Std             56.292
evaluation/Returns Max            -15.5119
evaluation/Returns Min           -182.126
evaluation/Actions Mean             0.000722665
evaluation/Actions Std              0.18487
evaluation/Actions Max              0.99886
evaluation/Actions Min             -0.998899
evaluation/Num Paths               15
evaluation/Average Returns        -63.2558
time/data storing (s)               0.0026535
time/evaluation sampling (s)        0.322513
time/exploration sampling (s)       0.135261
time/logging (s)                    0.00411148
time/saving (s)                     0.00196679
time/training (s)                   1.99062
time/epoch (s)                      2.45713
time/total (s)                    974.295
Epoch                             396
-----------------------------  ----------------
2019-04-23 01:29:48.703882 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 397 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   79.0308
trainer/QF2 Loss                   79.7648
trainer/Policy Loss                37.4756
trainer/Q1 Predictions Mean       -35.5039
trainer/Q1 Predictions Std         42.53
trainer/Q1 Predictions Max         -7.0258
trainer/Q1 Predictions Min       -143.066
trainer/Q2 Predictions Mean       -35.5185
trainer/Q2 Predictions Std         42.5181
trainer/Q2 Predictions Max         -6.99954
trainer/Q2 Predictions Min       -142.376
trainer/Q Targets Mean            -35.3959
trainer/Q Targets Std              43.1601
trainer/Q Targets Max              -2.0631
trainer/Q Targets Min            -146.011
trainer/Log Pis Mean                2.10455
trainer/Log Pis Std                 1.37561
trainer/Log Pis Max                 7.15444
trainer/Log Pis Min                -2.21095
trainer/Policy mu Mean             -0.0216601
trainer/Policy mu Std               0.545199
trainer/Policy mu Max               2.56368
trainer/Policy mu Min              -3.34795
trainer/Policy log std Mean        -2.26272
trainer/Policy log std Std          0.384886
trainer/Policy log std Max         -0.624713
trainer/Policy log std Min         -2.87576
trainer/Alpha                       0.0697719
trainer/Alpha Loss                  0.278375
exploration/num steps total    199200
exploration/num paths total      1992
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.745832
exploration/Rewards Std             0.840774
exploration/Rewards Max            -0.00398684
exploration/Rewards Min            -3.33122
exploration/Returns Mean          -74.5832
exploration/Returns Std            81.1358
exploration/Returns Max           -12.9596
exploration/Returns Min          -228.176
exploration/Actions Mean           -0.00510397
exploration/Actions Std             0.167936
exploration/Actions Max             0.996398
exploration/Actions Min            -0.965792
exploration/Num Paths               5
exploration/Average Returns       -74.5832
evaluation/num steps total     597000
evaluation/num paths total       5970
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.979265
evaluation/Rewards Std              1.22439
evaluation/Rewards Max             -0.0157901
evaluation/Rewards Min            -10.2785
evaluation/Returns Mean           -97.9265
evaluation/Returns Std            113.53
evaluation/Returns Max             -8.13651
evaluation/Returns Min           -303.311
evaluation/Actions Mean            -0.00953394
evaluation/Actions Std              0.131967
evaluation/Actions Max              0.992093
evaluation/Actions Min             -0.996455
evaluation/Num Paths               15
evaluation/Average Returns        -97.9265
time/data storing (s)               0.00272252
time/evaluation sampling (s)        0.327531
time/exploration sampling (s)       0.13721
time/logging (s)                    0.00482351
time/saving (s)                     0.00191837
time/training (s)                   1.96767
time/epoch (s)                      2.44188
time/total (s)                    976.741
Epoch                             397
-----------------------------  ---------------
2019-04-23 01:29:51.178255 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 398 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.86941
trainer/QF2 Loss                    1.98859
trainer/Policy Loss                45.996
trainer/Q1 Predictions Mean       -44.2738
trainer/Q1 Predictions Std         45.8035
trainer/Q1 Predictions Max         -7.18883
trainer/Q1 Predictions Min       -147.62
trainer/Q2 Predictions Mean       -44.2779
trainer/Q2 Predictions Std         45.8726
trainer/Q2 Predictions Max         -7.2619
trainer/Q2 Predictions Min       -149.384
trainer/Q Targets Mean            -45.1288
trainer/Q Targets Std              46.7798
trainer/Q Targets Max              -7.13673
trainer/Q Targets Min            -149.008
trainer/Log Pis Mean                1.94836
trainer/Log Pis Std                 1.314
trainer/Log Pis Max                 6.09715
trainer/Log Pis Min                -2.90528
trainer/Policy mu Mean             -0.0766116
trainer/Policy mu Std               0.596034
trainer/Policy mu Max               3.12053
trainer/Policy mu Min              -2.57202
trainer/Policy log std Mean        -2.21135
trainer/Policy log std Std          0.432182
trainer/Policy log std Max         -0.460652
trainer/Policy log std Min         -2.95886
trainer/Alpha                       0.0715583
trainer/Alpha Loss                 -0.136206
exploration/num steps total    199700
exploration/num paths total      1997
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.22402
exploration/Rewards Std             1.30485
exploration/Rewards Max            -0.00784717
exploration/Rewards Min           -10.1341
exploration/Returns Mean         -122.402
exploration/Returns Std           110.988
exploration/Returns Max           -18.0604
exploration/Returns Min          -271.624
exploration/Actions Mean           -0.00751281
exploration/Actions Std             0.225444
exploration/Actions Max             0.981408
exploration/Actions Min            -0.998236
exploration/Num Paths               5
exploration/Average Returns      -122.402
evaluation/num steps total     598500
evaluation/num paths total       5985
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.867195
evaluation/Rewards Std              0.98389
evaluation/Rewards Max             -0.0506783
evaluation/Rewards Min             -8.10838
evaluation/Returns Mean           -86.7195
evaluation/Returns Std             78.4207
evaluation/Returns Max             -7.53637
evaluation/Returns Min           -269.194
evaluation/Actions Mean            -0.00276907
evaluation/Actions Std              0.156941
evaluation/Actions Max              0.996062
evaluation/Actions Min             -0.999633
evaluation/Num Paths               15
evaluation/Average Returns        -86.7195
time/data storing (s)               0.00268566
time/evaluation sampling (s)        0.327743
time/exploration sampling (s)       0.13898
time/logging (s)                    0.00472836
time/saving (s)                     0.0017845
time/training (s)                   1.98806
time/epoch (s)                      2.46398
time/total (s)                    979.209
Epoch                             398
-----------------------------  ---------------
2019-04-23 01:29:53.649870 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 399 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.578929
trainer/QF2 Loss                    0.608734
trainer/Policy Loss                46.414
trainer/Q1 Predictions Mean       -44.6712
trainer/Q1 Predictions Std         42.9882
trainer/Q1 Predictions Max         -7.14561
trainer/Q1 Predictions Min       -144.741
trainer/Q2 Predictions Mean       -44.6586
trainer/Q2 Predictions Std         42.9697
trainer/Q2 Predictions Max         -7.15991
trainer/Q2 Predictions Min       -144.368
trainer/Q Targets Mean            -45.1273
trainer/Q Targets Std              43.442
trainer/Q Targets Max              -7.08375
trainer/Q Targets Min            -145.791
trainer/Log Pis Mean                1.92185
trainer/Log Pis Std                 1.2022
trainer/Log Pis Max                 5.23145
trainer/Log Pis Min                -1.87841
trainer/Policy mu Mean             -0.114374
trainer/Policy mu Std               0.498379
trainer/Policy mu Max               1.70033
trainer/Policy mu Min              -2.53231
trainer/Policy log std Mean        -2.15937
trainer/Policy log std Std          0.412112
trainer/Policy log std Max         -0.706143
trainer/Policy log std Min         -2.94387
trainer/Alpha                       0.0723678
trainer/Alpha Loss                 -0.205236
exploration/num steps total    200200
exploration/num paths total      2002
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.08677
exploration/Rewards Std             1.25012
exploration/Rewards Max            -0.00294244
exploration/Rewards Min            -9.43509
exploration/Returns Mean         -108.677
exploration/Returns Std            96.1025
exploration/Returns Max           -26.1969
exploration/Returns Min          -280.216
exploration/Actions Mean           -0.0321845
exploration/Actions Std             0.207681
exploration/Actions Max             0.767663
exploration/Actions Min            -0.999874
exploration/Num Paths               5
exploration/Average Returns      -108.677
evaluation/num steps total     600000
evaluation/num paths total       6000
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.746788
evaluation/Rewards Std              1.19304
evaluation/Rewards Max             -0.00210847
evaluation/Rewards Min             -9.71001
evaluation/Returns Mean           -74.6788
evaluation/Returns Std             65.9933
evaluation/Returns Max             -8.05692
evaluation/Returns Min           -220.616
evaluation/Actions Mean             0.0199936
evaluation/Actions Std              0.195519
evaluation/Actions Max              0.997993
evaluation/Actions Min             -0.995446
evaluation/Num Paths               15
evaluation/Average Returns        -74.6788
time/data storing (s)               0.00257049
time/evaluation sampling (s)        0.32549
time/exploration sampling (s)       0.137995
time/logging (s)                    0.00352914
time/saving (s)                     0.00162469
time/training (s)                   1.98895
time/epoch (s)                      2.46016
time/total (s)                    981.674
Epoch                             399
-----------------------------  ---------------
2019-04-23 01:29:56.109332 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 400 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   33.4592
trainer/QF2 Loss                   33.4039
trainer/Policy Loss                45.8821
trainer/Q1 Predictions Mean       -44.0168
trainer/Q1 Predictions Std         42.768
trainer/Q1 Predictions Max         -6.85928
trainer/Q1 Predictions Min       -146.858
trainer/Q2 Predictions Mean       -43.9999
trainer/Q2 Predictions Std         42.7769
trainer/Q2 Predictions Max         -6.8514
trainer/Q2 Predictions Min       -146.94
trainer/Q Targets Mean            -43.9222
trainer/Q Targets Std              43.9078
trainer/Q Targets Max              -0.664068
trainer/Q Targets Min            -148.642
trainer/Log Pis Mean                2.03742
trainer/Log Pis Std                 1.01794
trainer/Log Pis Max                 6.28501
trainer/Log Pis Min                -0.524783
trainer/Policy mu Mean             -0.0818263
trainer/Policy mu Std               0.457786
trainer/Policy mu Max               2.57337
trainer/Policy mu Min              -2.71668
trainer/Policy log std Mean        -2.24082
trainer/Policy log std Std          0.381857
trainer/Policy log std Max         -0.527039
trainer/Policy log std Min         -2.99305
trainer/Alpha                       0.071331
trainer/Alpha Loss                  0.0987986
exploration/num steps total    200700
exploration/num paths total      2007
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.60572
exploration/Rewards Std             1.06185
exploration/Rewards Max            -0.00452869
exploration/Rewards Min           -10.2453
exploration/Returns Mean          -60.572
exploration/Returns Std            38.7733
exploration/Returns Max           -14.8609
exploration/Returns Min          -109.026
exploration/Actions Mean           -0.0144738
exploration/Actions Std             0.219749
exploration/Actions Max             0.999399
exploration/Actions Min            -0.999282
exploration/Num Paths               5
exploration/Average Returns       -60.572
evaluation/num steps total     601500
evaluation/num paths total       6015
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.71391
evaluation/Rewards Std              1.18305
evaluation/Rewards Max             -0.00845278
evaluation/Rewards Min             -9.81418
evaluation/Returns Mean           -71.391
evaluation/Returns Std             76.9293
evaluation/Returns Max            -10.9196
evaluation/Returns Min           -282.296
evaluation/Actions Mean            -0.00261736
evaluation/Actions Std              0.184298
evaluation/Actions Max              0.997764
evaluation/Actions Min             -0.998318
evaluation/Num Paths               15
evaluation/Average Returns        -71.391
time/data storing (s)               0.00304969
time/evaluation sampling (s)        0.325368
time/exploration sampling (s)       0.139693
time/logging (s)                    0.00474789
time/saving (s)                     0.0019468
time/training (s)                   1.97677
time/epoch (s)                      2.45158
time/total (s)                    984.129
Epoch                             400
-----------------------------  ---------------
2019-04-23 01:29:58.584153 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 401 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   21.632
trainer/QF2 Loss                   21.7228
trainer/Policy Loss                39.4675
trainer/Q1 Predictions Mean       -37.7755
trainer/Q1 Predictions Std         40.8386
trainer/Q1 Predictions Max         -6.90778
trainer/Q1 Predictions Min       -141.565
trainer/Q2 Predictions Mean       -37.7725
trainer/Q2 Predictions Std         40.8643
trainer/Q2 Predictions Max         -6.99968
trainer/Q2 Predictions Min       -141.104
trainer/Q Targets Mean            -37.6095
trainer/Q Targets Std              41.5862
trainer/Q Targets Max              -0.0526206
trainer/Q Targets Min            -143.83
trainer/Log Pis Mean                1.85216
trainer/Log Pis Std                 1.01331
trainer/Log Pis Max                 3.4362
trainer/Log Pis Min                -1.42225
trainer/Policy mu Mean              0.0278208
trainer/Policy mu Std               0.300391
trainer/Policy mu Max               1.5002
trainer/Policy mu Min              -1.09539
trainer/Policy log std Mean        -2.25199
trainer/Policy log std Std          0.307559
trainer/Policy log std Max         -0.90977
trainer/Policy log std Min         -2.89799
trainer/Alpha                       0.0713749
trainer/Alpha Loss                 -0.390276
exploration/num steps total    201200
exploration/num paths total      2012
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.4263
exploration/Rewards Std             1.14177
exploration/Rewards Max            -0.00550399
exploration/Rewards Min           -10.4409
exploration/Returns Mean          -42.63
exploration/Returns Std            15.6056
exploration/Returns Max           -20.4845
exploration/Returns Min           -66.0558
exploration/Actions Mean           -0.0045555
exploration/Actions Std             0.241786
exploration/Actions Max             0.999644
exploration/Actions Min            -0.997989
exploration/Num Paths               5
exploration/Average Returns       -42.63
evaluation/num steps total     603000
evaluation/num paths total       6030
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.774777
evaluation/Rewards Std              1.27905
evaluation/Rewards Max             -0.0065661
evaluation/Rewards Min            -11.2106
evaluation/Returns Mean           -77.4777
evaluation/Returns Std             86.8913
evaluation/Returns Max             -3.66044
evaluation/Returns Min           -314.51
evaluation/Actions Mean            -0.00860115
evaluation/Actions Std              0.181614
evaluation/Actions Max              0.998807
evaluation/Actions Min             -0.998807
evaluation/Num Paths               15
evaluation/Average Returns        -77.4777
time/data storing (s)               0.00258922
time/evaluation sampling (s)        0.327678
time/exploration sampling (s)       0.136036
time/logging (s)                    0.0047597
time/saving (s)                     0.00155954
time/training (s)                   1.99294
time/epoch (s)                      2.46556
time/total (s)                    986.6
Epoch                             401
-----------------------------  ---------------
2019-04-23 01:30:01.061293 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 402 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.24938
trainer/QF2 Loss                    1.33051
trainer/Policy Loss                46.3596
trainer/Q1 Predictions Mean       -44.5878
trainer/Q1 Predictions Std         45.6542
trainer/Q1 Predictions Max         -7.0051
trainer/Q1 Predictions Min       -143.78
trainer/Q2 Predictions Mean       -44.5529
trainer/Q2 Predictions Std         45.5734
trainer/Q2 Predictions Max         -7.03476
trainer/Q2 Predictions Min       -143.36
trainer/Q Targets Mean            -44.6291
trainer/Q Targets Std              45.9261
trainer/Q Targets Max              -0.193856
trainer/Q Targets Min            -145.076
trainer/Log Pis Mean                2.02577
trainer/Log Pis Std                 1.22071
trainer/Log Pis Max                 6.55028
trainer/Log Pis Min                -1.55462
trainer/Policy mu Mean             -0.0722698
trainer/Policy mu Std               0.51683
trainer/Policy mu Max               1.4637
trainer/Policy mu Min              -2.95302
trainer/Policy log std Mean        -2.20213
trainer/Policy log std Std          0.450625
trainer/Policy log std Max         -0.245903
trainer/Policy log std Min         -2.91686
trainer/Alpha                       0.0696864
trainer/Alpha Loss                  0.0686328
exploration/num steps total    201700
exploration/num paths total      2017
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.669877
exploration/Rewards Std             0.919314
exploration/Rewards Max            -0.00895275
exploration/Rewards Min            -7.41558
exploration/Returns Mean          -66.9877
exploration/Returns Std            66.9126
exploration/Returns Max           -17.4743
exploration/Returns Min          -188.683
exploration/Actions Mean            0.00041716
exploration/Actions Std             0.191351
exploration/Actions Max             0.998853
exploration/Actions Min            -0.996525
exploration/Num Paths               5
exploration/Average Returns       -66.9877
evaluation/num steps total     604500
evaluation/num paths total       6045
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.882899
evaluation/Rewards Std              1.30205
evaluation/Rewards Max             -0.0129122
evaluation/Rewards Min             -9.94691
evaluation/Returns Mean           -88.2899
evaluation/Returns Std             85.017
evaluation/Returns Max            -15.6108
evaluation/Returns Min           -289.48
evaluation/Actions Mean             0.00501762
evaluation/Actions Std              0.203856
evaluation/Actions Max              0.998716
evaluation/Actions Min             -0.998982
evaluation/Num Paths               15
evaluation/Average Returns        -88.2899
time/data storing (s)               0.00274007
time/evaluation sampling (s)        0.326651
time/exploration sampling (s)       0.139417
time/logging (s)                    0.00471971
time/saving (s)                     0.00192296
time/training (s)                   1.99134
time/epoch (s)                      2.46679
time/total (s)                    989.071
Epoch                             402
-----------------------------  ---------------
2019-04-23 01:30:03.534744 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 403 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.507506
trainer/QF2 Loss                    0.579098
trainer/Policy Loss                42.6354
trainer/Q1 Predictions Mean       -41.028
trainer/Q1 Predictions Std         40.5144
trainer/Q1 Predictions Max         -7.19857
trainer/Q1 Predictions Min       -142.127
trainer/Q2 Predictions Mean       -40.9858
trainer/Q2 Predictions Std         40.5229
trainer/Q2 Predictions Max         -7.23864
trainer/Q2 Predictions Min       -141.571
trainer/Q Targets Mean            -41.3646
trainer/Q Targets Std              40.833
trainer/Q Targets Max              -7.1345
trainer/Q Targets Min            -143.784
trainer/Log Pis Mean                1.85192
trainer/Log Pis Std                 1.1314
trainer/Log Pis Max                 5.01545
trainer/Log Pis Min                -2.33869
trainer/Policy mu Mean             -0.0526016
trainer/Policy mu Std               0.523878
trainer/Policy mu Max               2.55806
trainer/Policy mu Min              -2.70779
trainer/Policy log std Mean        -2.15256
trainer/Policy log std Std          0.417395
trainer/Policy log std Max         -0.446801
trainer/Policy log std Min         -2.79708
trainer/Alpha                       0.0707455
trainer/Alpha Loss                 -0.392184
exploration/num steps total    202200
exploration/num paths total      2022
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.765684
exploration/Rewards Std             0.896988
exploration/Rewards Max            -0.014334
exploration/Rewards Min            -8.55069
exploration/Returns Mean          -76.5684
exploration/Returns Std            60.1591
exploration/Returns Max           -13.563
exploration/Returns Min          -180.366
exploration/Actions Mean           -0.00704754
exploration/Actions Std             0.185863
exploration/Actions Max             0.996687
exploration/Actions Min            -0.99696
exploration/Num Paths               5
exploration/Average Returns       -76.5684
evaluation/num steps total     606000
evaluation/num paths total       6060
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.25838
evaluation/Rewards Std              1.33944
evaluation/Rewards Max             -0.0444312
evaluation/Rewards Min             -9.02599
evaluation/Returns Mean          -125.838
evaluation/Returns Std            104.556
evaluation/Returns Max            -10.9037
evaluation/Returns Min           -307.276
evaluation/Actions Mean             0.011485
evaluation/Actions Std              0.193365
evaluation/Actions Max              0.998978
evaluation/Actions Min             -0.996184
evaluation/Num Paths               15
evaluation/Average Returns       -125.838
time/data storing (s)               0.00272957
time/evaluation sampling (s)        0.328137
time/exploration sampling (s)       0.138599
time/logging (s)                    0.00476326
time/saving (s)                     0.00156726
time/training (s)                   1.98828
time/epoch (s)                      2.46407
time/total (s)                    991.539
Epoch                             403
-----------------------------  ---------------
2019-04-23 01:30:05.997260 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 404 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    9.51137
trainer/QF2 Loss                    9.41895
trainer/Policy Loss                35.8783
trainer/Q1 Predictions Mean       -34.2618
trainer/Q1 Predictions Std         39.706
trainer/Q1 Predictions Max         -7.08342
trainer/Q1 Predictions Min       -140.754
trainer/Q2 Predictions Mean       -34.2513
trainer/Q2 Predictions Std         39.6856
trainer/Q2 Predictions Max         -7.11373
trainer/Q2 Predictions Min       -140.213
trainer/Q Targets Mean            -34.5442
trainer/Q Targets Std              40.4717
trainer/Q Targets Max              -0.703544
trainer/Q Targets Min            -142.43
trainer/Log Pis Mean                1.82322
trainer/Log Pis Std                 0.978117
trainer/Log Pis Max                 4.26843
trainer/Log Pis Min                -1.19604
trainer/Policy mu Mean              0.0384602
trainer/Policy mu Std               0.35274
trainer/Policy mu Max               2.72743
trainer/Policy mu Min              -1.29833
trainer/Policy log std Mean        -2.25154
trainer/Policy log std Std          0.314206
trainer/Policy log std Max         -0.615452
trainer/Policy log std Min         -2.9138
trainer/Alpha                       0.0717367
trainer/Alpha Loss                 -0.465738
exploration/num steps total    202700
exploration/num paths total      2027
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.835976
exploration/Rewards Std             1.18064
exploration/Rewards Max            -0.00615897
exploration/Rewards Min            -9.14995
exploration/Returns Mean          -83.5976
exploration/Returns Std            57.3908
exploration/Returns Max           -28.7981
exploration/Returns Min          -182.127
exploration/Actions Mean            0.0254519
exploration/Actions Std             0.21953
exploration/Actions Max             0.999717
exploration/Actions Min            -0.970259
exploration/Num Paths               5
exploration/Average Returns       -83.5976
evaluation/num steps total     607500
evaluation/num paths total       6075
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.821021
evaluation/Rewards Std              1.09526
evaluation/Rewards Max             -0.0123542
evaluation/Rewards Min             -9.44792
evaluation/Returns Mean           -82.1021
evaluation/Returns Std             83.9214
evaluation/Returns Max            -15.8533
evaluation/Returns Min           -297.412
evaluation/Actions Mean            -0.00232329
evaluation/Actions Std              0.166653
evaluation/Actions Max              0.997191
evaluation/Actions Min             -0.996544
evaluation/Num Paths               15
evaluation/Average Returns        -82.1021
time/data storing (s)               0.00273611
time/evaluation sampling (s)        0.328209
time/exploration sampling (s)       0.135693
time/logging (s)                    0.00477622
time/saving (s)                     0.00154678
time/training (s)                   1.97919
time/epoch (s)                      2.45215
time/total (s)                    993.995
Epoch                             404
-----------------------------  ---------------
2019-04-23 01:30:08.473791 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 405 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   21.9695
trainer/QF2 Loss                   21.7875
trainer/Policy Loss                48.9583
trainer/Q1 Predictions Mean       -47.0953
trainer/Q1 Predictions Std         41.3115
trainer/Q1 Predictions Max         -7.18579
trainer/Q1 Predictions Min       -139.543
trainer/Q2 Predictions Mean       -47.1365
trainer/Q2 Predictions Std         41.322
trainer/Q2 Predictions Max         -7.18238
trainer/Q2 Predictions Min       -139.45
trainer/Q Targets Mean            -47.2292
trainer/Q Targets Std              41.8897
trainer/Q Targets Max              -1.86507
trainer/Q Targets Min            -140.168
trainer/Log Pis Mean                2.15983
trainer/Log Pis Std                 0.989417
trainer/Log Pis Max                 4.95534
trainer/Log Pis Min                -1.12313
trainer/Policy mu Mean             -0.132627
trainer/Policy mu Std               0.556228
trainer/Policy mu Max               1.85571
trainer/Policy mu Min              -2.67434
trainer/Policy log std Mean        -2.20781
trainer/Policy log std Std          0.426453
trainer/Policy log std Max         -0.632422
trainer/Policy log std Min         -2.90216
trainer/Alpha                       0.0713591
trainer/Alpha Loss                  0.422009
exploration/num steps total    203200
exploration/num paths total      2032
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.63318
exploration/Rewards Std             1.52169
exploration/Rewards Max            -0.0106988
exploration/Rewards Min           -10.5149
exploration/Returns Mean         -163.318
exploration/Returns Std           109.047
exploration/Returns Max           -56.1594
exploration/Returns Min          -305.797
exploration/Actions Mean           -0.0162459
exploration/Actions Std             0.234318
exploration/Actions Max             0.99899
exploration/Actions Min            -0.998945
exploration/Num Paths               5
exploration/Average Returns      -163.318
evaluation/num steps total     609000
evaluation/num paths total       6090
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.2495
evaluation/Rewards Std              1.39869
evaluation/Rewards Max             -0.0353093
evaluation/Rewards Min            -10.2042
evaluation/Returns Mean          -124.95
evaluation/Returns Std            112.713
evaluation/Returns Max            -10.0581
evaluation/Returns Min           -297.105
evaluation/Actions Mean            -0.0142338
evaluation/Actions Std              0.186491
evaluation/Actions Max              0.998567
evaluation/Actions Min             -0.999227
evaluation/Num Paths               15
evaluation/Average Returns       -124.95
time/data storing (s)               0.00276753
time/evaluation sampling (s)        0.335287
time/exploration sampling (s)       0.137984
time/logging (s)                    0.0047852
time/saving (s)                     0.00194374
time/training (s)                   1.98341
time/epoch (s)                      2.46618
time/total (s)                    996.466
Epoch                             405
-----------------------------  ---------------
2019-04-23 01:30:10.942396 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 406 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    2.96317
trainer/QF2 Loss                    2.97067
trainer/Policy Loss                50.1148
trainer/Q1 Predictions Mean       -48.2698
trainer/Q1 Predictions Std         42.2137
trainer/Q1 Predictions Max         -6.90357
trainer/Q1 Predictions Min       -140.396
trainer/Q2 Predictions Mean       -48.2279
trainer/Q2 Predictions Std         42.2107
trainer/Q2 Predictions Max         -6.98998
trainer/Q2 Predictions Min       -139.778
trainer/Q Targets Mean            -48.4636
trainer/Q Targets Std              42.9107
trainer/Q Targets Max              -0.0955894
trainer/Q Targets Min            -142.181
trainer/Log Pis Mean                2.086
trainer/Log Pis Std                 1.27603
trainer/Log Pis Max                 7.64143
trainer/Log Pis Min                -3.04596
trainer/Policy mu Mean             -0.0468471
trainer/Policy mu Std               0.563332
trainer/Policy mu Max               2.84274
trainer/Policy mu Min              -2.7609
trainer/Policy log std Mean        -2.21161
trainer/Policy log std Std          0.441665
trainer/Policy log std Max         -0.237612
trainer/Policy log std Min         -2.84523
trainer/Alpha                       0.0725779
trainer/Alpha Loss                  0.225596
exploration/num steps total    203700
exploration/num paths total      2037
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.553486
exploration/Rewards Std             1.0392
exploration/Rewards Max            -0.00488048
exploration/Rewards Min            -8.76197
exploration/Returns Mean          -55.3486
exploration/Returns Std            25.328
exploration/Returns Max           -35.4899
exploration/Returns Min          -104.06
exploration/Actions Mean            0.0132056
exploration/Actions Std             0.226245
exploration/Actions Max             0.999709
exploration/Actions Min            -0.998247
exploration/Num Paths               5
exploration/Average Returns       -55.3486
evaluation/num steps total     610500
evaluation/num paths total       6105
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.02632
evaluation/Rewards Std              1.27038
evaluation/Rewards Max             -0.0157538
evaluation/Rewards Min            -10.871
evaluation/Returns Mean          -102.632
evaluation/Returns Std             83.1084
evaluation/Returns Max            -15.3962
evaluation/Returns Min           -286.612
evaluation/Actions Mean             0.000129902
evaluation/Actions Std              0.196965
evaluation/Actions Max              0.99792
evaluation/Actions Min             -0.998293
evaluation/Num Paths               15
evaluation/Average Returns       -102.632
time/data storing (s)               0.00290554
time/evaluation sampling (s)        0.327909
time/exploration sampling (s)       0.13952
time/logging (s)                    0.00478696
time/saving (s)                     0.00155479
time/training (s)                   1.98159
time/epoch (s)                      2.45827
time/total (s)                    998.929
Epoch                             406
-----------------------------  ----------------
2019-04-23 01:30:13.405436 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 407 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                  122.304
trainer/QF2 Loss                  122.455
trainer/Policy Loss                49.7578
trainer/Q1 Predictions Mean       -48.0438
trainer/Q1 Predictions Std         46.1931
trainer/Q1 Predictions Max         -7.25778
trainer/Q1 Predictions Min       -141.459
trainer/Q2 Predictions Mean       -48.0481
trainer/Q2 Predictions Std         46.185
trainer/Q2 Predictions Max         -7.25815
trainer/Q2 Predictions Min       -140.583
trainer/Q Targets Mean            -47.2822
trainer/Q Targets Std              46.781
trainer/Q Targets Max              -0.685458
trainer/Q Targets Min            -142.144
trainer/Log Pis Mean                1.85294
trainer/Log Pis Std                 1.20139
trainer/Log Pis Max                 4.2521
trainer/Log Pis Min                -3.66753
trainer/Policy mu Mean             -0.0189584
trainer/Policy mu Std               0.48762
trainer/Policy mu Max               3.42676
trainer/Policy mu Min              -2.24525
trainer/Policy log std Mean        -2.22135
trainer/Policy log std Std          0.393572
trainer/Policy log std Max         -0.816502
trainer/Policy log std Min         -3.01299
trainer/Alpha                       0.0704637
trainer/Alpha Loss                 -0.390125
exploration/num steps total    204200
exploration/num paths total      2042
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.12371
exploration/Rewards Std             1.11217
exploration/Rewards Max            -0.00967676
exploration/Rewards Min            -7.10769
exploration/Returns Mean         -112.371
exploration/Returns Std            95.8358
exploration/Returns Max           -20.2265
exploration/Returns Min          -276.861
exploration/Actions Mean           -0.0224893
exploration/Actions Std             0.184161
exploration/Actions Max             0.861762
exploration/Actions Min            -0.999824
exploration/Num Paths               5
exploration/Average Returns      -112.371
evaluation/num steps total     612000
evaluation/num paths total       6120
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.951666
evaluation/Rewards Std              1.21746
evaluation/Rewards Max             -0.0186817
evaluation/Rewards Min            -11.1518
evaluation/Returns Mean           -95.1666
evaluation/Returns Std             77.58
evaluation/Returns Max            -20.2876
evaluation/Returns Min           -282.671
evaluation/Actions Mean             0.00676672
evaluation/Actions Std              0.197432
evaluation/Actions Max              0.998989
evaluation/Actions Min             -0.995085
evaluation/Num Paths               15
evaluation/Average Returns        -95.1666
time/data storing (s)               0.00279183
time/evaluation sampling (s)        0.328997
time/exploration sampling (s)       0.135096
time/logging (s)                    0.00477156
time/saving (s)                     0.00975725
time/training (s)                   1.97124
time/epoch (s)                      2.45266
time/total (s)                   1001.39
Epoch                             407
-----------------------------  ---------------
2019-04-23 01:30:15.857085 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 408 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.345441
trainer/QF2 Loss                    0.435226
trainer/Policy Loss                41.9683
trainer/Q1 Predictions Mean       -40.3207
trainer/Q1 Predictions Std         41.596
trainer/Q1 Predictions Max         -6.95619
trainer/Q1 Predictions Min       -139.45
trainer/Q2 Predictions Mean       -40.2771
trainer/Q2 Predictions Std         41.5415
trainer/Q2 Predictions Max         -6.91019
trainer/Q2 Predictions Min       -138.759
trainer/Q Targets Mean            -40.7357
trainer/Q Targets Std              41.8972
trainer/Q Targets Max              -7.00149
trainer/Q Targets Min            -139.903
trainer/Log Pis Mean                1.82225
trainer/Log Pis Std                 1.38341
trainer/Log Pis Max                 4.74197
trainer/Log Pis Min                -6.65329
trainer/Policy mu Mean             -0.0484378
trainer/Policy mu Std               0.479207
trainer/Policy mu Max               1.90164
trainer/Policy mu Min              -3.35078
trainer/Policy log std Mean        -2.21918
trainer/Policy log std Std          0.414775
trainer/Policy log std Max          0.0704091
trainer/Policy log std Min         -2.86814
trainer/Alpha                       0.0718154
trainer/Alpha Loss                 -0.468139
exploration/num steps total    204700
exploration/num paths total      2047
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.21558
exploration/Rewards Std             1.15698
exploration/Rewards Max            -0.0130167
exploration/Rewards Min            -8.01101
exploration/Returns Mean         -121.558
exploration/Returns Std            95.9544
exploration/Returns Max           -16.6661
exploration/Returns Min          -281.396
exploration/Actions Mean            0.0015606
exploration/Actions Std             0.190256
exploration/Actions Max             0.998513
exploration/Actions Min            -0.99715
exploration/Num Paths               5
exploration/Average Returns      -121.558
evaluation/num steps total     613500
evaluation/num paths total       6135
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.780984
evaluation/Rewards Std              1.31124
evaluation/Rewards Max             -0.0214211
evaluation/Rewards Min            -11.7915
evaluation/Returns Mean           -78.0984
evaluation/Returns Std             57.6742
evaluation/Returns Max             -6.75748
evaluation/Returns Min           -184.706
evaluation/Actions Mean             0.00393974
evaluation/Actions Std              0.212058
evaluation/Actions Max              0.998929
evaluation/Actions Min             -0.999424
evaluation/Num Paths               15
evaluation/Average Returns        -78.0984
time/data storing (s)               0.00275126
time/evaluation sampling (s)        0.322645
time/exploration sampling (s)       0.138434
time/logging (s)                    0.0047296
time/saving (s)                     0.0019169
time/training (s)                   1.9707
time/epoch (s)                      2.44118
time/total (s)                   1003.83
Epoch                             408
-----------------------------  ---------------
2019-04-23 01:30:18.328998 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 409 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.254186
trainer/QF2 Loss                    0.227912
trainer/Policy Loss                39.8049
trainer/Q1 Predictions Mean       -37.9178
trainer/Q1 Predictions Std         42.8986
trainer/Q1 Predictions Max         -6.78818
trainer/Q1 Predictions Min       -143.269
trainer/Q2 Predictions Mean       -37.9439
trainer/Q2 Predictions Std         42.9121
trainer/Q2 Predictions Max         -6.8914
trainer/Q2 Predictions Min       -143.413
trainer/Q Targets Mean            -38.1515
trainer/Q Targets Std              43.1331
trainer/Q Targets Max              -6.98764
trainer/Q Targets Min            -144.002
trainer/Log Pis Mean                2.04898
trainer/Log Pis Std                 1.39175
trainer/Log Pis Max                 8.01903
trainer/Log Pis Min                -2.52492
trainer/Policy mu Mean              0.014185
trainer/Policy mu Std               0.460519
trainer/Policy mu Max               3.43154
trainer/Policy mu Min              -1.54565
trainer/Policy log std Mean        -2.30681
trainer/Policy log std Std          0.381936
trainer/Policy log std Max         -0.586533
trainer/Policy log std Min         -2.89933
trainer/Alpha                       0.0702389
trainer/Alpha Loss                  0.13009
exploration/num steps total    205200
exploration/num paths total      2052
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.481342
exploration/Rewards Std             0.925615
exploration/Rewards Max            -0.0130657
exploration/Rewards Min           -10.1247
exploration/Returns Mean          -48.1342
exploration/Returns Std            31.7198
exploration/Returns Max           -17.5953
exploration/Returns Min          -102.587
exploration/Actions Mean            0.0018568
exploration/Actions Std             0.203862
exploration/Actions Max             0.998506
exploration/Actions Min            -0.991378
exploration/Num Paths               5
exploration/Average Returns       -48.1342
evaluation/num steps total     615000
evaluation/num paths total       6150
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.758595
evaluation/Rewards Std              1.22403
evaluation/Rewards Max             -0.00830626
evaluation/Rewards Min            -11.4903
evaluation/Returns Mean           -75.8595
evaluation/Returns Std             49.0436
evaluation/Returns Max            -12.3007
evaluation/Returns Min           -165.724
evaluation/Actions Mean             0.0181881
evaluation/Actions Std              0.21299
evaluation/Actions Max              0.999418
evaluation/Actions Min             -0.999013
evaluation/Num Paths               15
evaluation/Average Returns        -75.8595
time/data storing (s)               0.00263283
time/evaluation sampling (s)        0.345133
time/exploration sampling (s)       0.138841
time/logging (s)                    0.00481956
time/saving (s)                     0.00196193
time/training (s)                   1.96931
time/epoch (s)                      2.4627
time/total (s)                   1006.3
Epoch                             409
-----------------------------  ---------------
2019-04-23 01:30:20.787722 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 410 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   21.0765
trainer/QF2 Loss                   21.0979
trainer/Policy Loss                41.5505
trainer/Q1 Predictions Mean       -39.7339
trainer/Q1 Predictions Std         43.4933
trainer/Q1 Predictions Max         -7.01962
trainer/Q1 Predictions Min       -144.758
trainer/Q2 Predictions Mean       -39.764
trainer/Q2 Predictions Std         43.4509
trainer/Q2 Predictions Max         -6.9923
trainer/Q2 Predictions Min       -144.913
trainer/Q Targets Mean            -39.5322
trainer/Q Targets Std              43.7683
trainer/Q Targets Max              -0.898722
trainer/Q Targets Min            -144.077
trainer/Log Pis Mean                1.96967
trainer/Log Pis Std                 1.19613
trainer/Log Pis Max                 5.18505
trainer/Log Pis Min                -1.48133
trainer/Policy mu Mean             -0.0872462
trainer/Policy mu Std               0.525362
trainer/Policy mu Max               3.03856
trainer/Policy mu Min              -2.86027
trainer/Policy log std Mean        -2.22095
trainer/Policy log std Std          0.408268
trainer/Policy log std Max         -0.34254
trainer/Policy log std Min         -2.86451
trainer/Alpha                       0.0713307
trainer/Alpha Loss                 -0.080079
exploration/num steps total    205700
exploration/num paths total      2057
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.358814
exploration/Rewards Std             1.03496
exploration/Rewards Max            -0.00889284
exploration/Rewards Min            -9.13514
exploration/Returns Mean          -35.8814
exploration/Returns Std            12.2129
exploration/Returns Max           -15.2022
exploration/Returns Min           -52.6777
exploration/Actions Mean           -0.0175846
exploration/Actions Std             0.219787
exploration/Actions Max             0.998132
exploration/Actions Min            -0.999641
exploration/Num Paths               5
exploration/Average Returns       -35.8814
evaluation/num steps total     616500
evaluation/num paths total       6165
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.561551
evaluation/Rewards Std              1.16672
evaluation/Rewards Max             -0.022713
evaluation/Rewards Min            -10.6504
evaluation/Returns Mean           -56.1551
evaluation/Returns Std             47.3359
evaluation/Returns Max             -8.77773
evaluation/Returns Min           -189.661
evaluation/Actions Mean             0.0118056
evaluation/Actions Std              0.195677
evaluation/Actions Max              0.998813
evaluation/Actions Min             -0.998109
evaluation/Num Paths               15
evaluation/Average Returns        -56.1551
time/data storing (s)               0.00334706
time/evaluation sampling (s)        0.329686
time/exploration sampling (s)       0.145131
time/logging (s)                    0.00476765
time/saving (s)                     0.00154049
time/training (s)                   1.96376
time/epoch (s)                      2.44823
time/total (s)                   1008.75
Epoch                             410
-----------------------------  ---------------
2019-04-23 01:30:23.257272 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 411 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                  117.256
trainer/QF2 Loss                  117.562
trainer/Policy Loss                42.8156
trainer/Q1 Predictions Mean       -40.873
trainer/Q1 Predictions Std         39.9165
trainer/Q1 Predictions Max         -6.86585
trainer/Q1 Predictions Min       -139.266
trainer/Q2 Predictions Mean       -40.8604
trainer/Q2 Predictions Std         39.8793
trainer/Q2 Predictions Max         -6.9177
trainer/Q2 Predictions Min       -139.11
trainer/Q Targets Mean            -40.2139
trainer/Q Targets Std              39.8301
trainer/Q Targets Max              -2.31918
trainer/Q Targets Min            -140.147
trainer/Log Pis Mean                2.12565
trainer/Log Pis Std                 1.12976
trainer/Log Pis Max                 7.74443
trainer/Log Pis Min                -0.364166
trainer/Policy mu Mean             -0.0080307
trainer/Policy mu Std               0.560837
trainer/Policy mu Max               3.5286
trainer/Policy mu Min              -2.89356
trainer/Policy log std Mean        -2.19508
trainer/Policy log std Std          0.444283
trainer/Policy log std Max         -0.0337228
trainer/Policy log std Min         -2.93098
trainer/Alpha                       0.0714438
trainer/Alpha Loss                  0.331576
exploration/num steps total    206200
exploration/num paths total      2062
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.858927
exploration/Rewards Std             1.18648
exploration/Rewards Max            -0.00350894
exploration/Rewards Min            -9.31805
exploration/Returns Mean          -85.8927
exploration/Returns Std            58.889
exploration/Returns Max           -22.177
exploration/Returns Min          -190.002
exploration/Actions Mean            0.0115443
exploration/Actions Std             0.239396
exploration/Actions Max             0.999871
exploration/Actions Min            -0.996061
exploration/Num Paths               5
exploration/Average Returns       -85.8927
evaluation/num steps total     618000
evaluation/num paths total       6180
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.980003
evaluation/Rewards Std              1.25687
evaluation/Rewards Max             -0.0330668
evaluation/Rewards Min            -10.276
evaluation/Returns Mean           -98.0003
evaluation/Returns Std             95.8976
evaluation/Returns Max             -9.23069
evaluation/Returns Min           -294.208
evaluation/Actions Mean            -0.0142956
evaluation/Actions Std              0.166887
evaluation/Actions Max              0.994511
evaluation/Actions Min             -0.997681
evaluation/Num Paths               15
evaluation/Average Returns        -98.0003
time/data storing (s)               0.00276042
time/evaluation sampling (s)        0.33008
time/exploration sampling (s)       0.144113
time/logging (s)                    0.00477438
time/saving (s)                     0.00193357
time/training (s)                   1.97546
time/epoch (s)                      2.45912
time/total (s)                   1011.21
Epoch                             411
-----------------------------  ---------------
2019-04-23 01:30:25.717971 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 412 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.64339
trainer/QF2 Loss                    1.60941
trainer/Policy Loss                40.6139
trainer/Q1 Predictions Mean       -38.7187
trainer/Q1 Predictions Std         40.218
trainer/Q1 Predictions Max         -6.83143
trainer/Q1 Predictions Min       -141.651
trainer/Q2 Predictions Mean       -38.7646
trainer/Q2 Predictions Std         40.2573
trainer/Q2 Predictions Max         -6.84967
trainer/Q2 Predictions Min       -142.078
trainer/Q Targets Mean            -39.1864
trainer/Q Targets Std              40.7835
trainer/Q Targets Max              -0.164603
trainer/Q Targets Min            -143.436
trainer/Log Pis Mean                1.99964
trainer/Log Pis Std                 1.2669
trainer/Log Pis Max                 6.28287
trainer/Log Pis Min                -3.64662
trainer/Policy mu Mean             -0.00404642
trainer/Policy mu Std               0.55858
trainer/Policy mu Max               2.5559
trainer/Policy mu Min              -2.3409
trainer/Policy log std Mean        -2.21015
trainer/Policy log std Std          0.433061
trainer/Policy log std Max         -0.611391
trainer/Policy log std Min         -2.91058
trainer/Alpha                       0.0688669
trainer/Alpha Loss                 -0.000965825
exploration/num steps total    206700
exploration/num paths total      2067
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.975446
exploration/Rewards Std             1.18822
exploration/Rewards Max            -0.024835
exploration/Rewards Min           -10.0793
exploration/Returns Mean          -97.5446
exploration/Returns Std            43.0883
exploration/Returns Max           -63.394
exploration/Returns Min          -176.379
exploration/Actions Mean           -0.00193551
exploration/Actions Std             0.220335
exploration/Actions Max             0.999835
exploration/Actions Min            -0.999088
exploration/Num Paths               5
exploration/Average Returns       -97.5446
evaluation/num steps total     619500
evaluation/num paths total       6195
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.02137
evaluation/Rewards Std              1.0584
evaluation/Rewards Max             -0.0500791
evaluation/Rewards Min            -10.5228
evaluation/Returns Mean          -102.137
evaluation/Returns Std             78.6932
evaluation/Returns Max             -9.14186
evaluation/Returns Min           -309.391
evaluation/Actions Mean            -0.00523282
evaluation/Actions Std              0.174667
evaluation/Actions Max              0.997392
evaluation/Actions Min             -0.99784
evaluation/Num Paths               15
evaluation/Average Returns       -102.137
time/data storing (s)               0.00274399
time/evaluation sampling (s)        0.329551
time/exploration sampling (s)       0.138555
time/logging (s)                    0.00478151
time/saving (s)                     0.00195527
time/training (s)                   1.97263
time/epoch (s)                      2.45021
time/total (s)                   1013.67
Epoch                             412
-----------------------------  ----------------
2019-04-23 01:30:28.192051 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 413 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.614351
trainer/QF2 Loss                    0.477739
trainer/Policy Loss                38.5748
trainer/Q1 Predictions Mean       -36.5928
trainer/Q1 Predictions Std         37.7497
trainer/Q1 Predictions Max         -7.00491
trainer/Q1 Predictions Min       -138.852
trainer/Q2 Predictions Mean       -36.6277
trainer/Q2 Predictions Std         37.7203
trainer/Q2 Predictions Max         -7.04183
trainer/Q2 Predictions Min       -138.505
trainer/Q Targets Mean            -37.0343
trainer/Q Targets Std              38.0303
trainer/Q Targets Max              -6.99122
trainer/Q Targets Min            -139.542
trainer/Log Pis Mean                2.09666
trainer/Log Pis Std                 1.2356
trainer/Log Pis Max                 5.50009
trainer/Log Pis Min                -3.41659
trainer/Policy mu Mean             -0.0662445
trainer/Policy mu Std               0.623502
trainer/Policy mu Max               2.60129
trainer/Policy mu Min              -3.11861
trainer/Policy log std Mean        -2.17033
trainer/Policy log std Std          0.498068
trainer/Policy log std Max         -0.297881
trainer/Policy log std Min         -2.82065
trainer/Alpha                       0.0684458
trainer/Alpha Loss                  0.259202
exploration/num steps total    207200
exploration/num paths total      2072
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.40491
exploration/Rewards Std             1.21755
exploration/Rewards Max            -0.0120799
exploration/Rewards Min            -9.32186
exploration/Returns Mean         -140.491
exploration/Returns Std            88.5351
exploration/Returns Max           -25.7869
exploration/Returns Min          -217.851
exploration/Actions Mean            0.0151627
exploration/Actions Std             0.246875
exploration/Actions Max             0.99994
exploration/Actions Min            -0.999383
exploration/Num Paths               5
exploration/Average Returns      -140.491
evaluation/num steps total     621000
evaluation/num paths total       6210
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.2125
evaluation/Rewards Std              1.34138
evaluation/Rewards Max             -0.0570414
evaluation/Rewards Min            -10.7862
evaluation/Returns Mean          -121.25
evaluation/Returns Std             78.5706
evaluation/Returns Max            -25.2032
evaluation/Returns Min           -290.444
evaluation/Actions Mean            -0.0192109
evaluation/Actions Std              0.199527
evaluation/Actions Max              0.998904
evaluation/Actions Min             -0.998979
evaluation/Num Paths               15
evaluation/Average Returns       -121.25
time/data storing (s)               0.002755
time/evaluation sampling (s)        0.335136
time/exploration sampling (s)       0.138094
time/logging (s)                    0.00476945
time/saving (s)                     0.00195305
time/training (s)                   1.9808
time/epoch (s)                      2.46351
time/total (s)                   1016.14
Epoch                             413
-----------------------------  ---------------
2019-04-23 01:30:30.671502 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 414 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.389474
trainer/QF2 Loss                    0.386691
trainer/Policy Loss                47.3219
trainer/Q1 Predictions Mean       -45.3244
trainer/Q1 Predictions Std         44.2966
trainer/Q1 Predictions Max         -6.79183
trainer/Q1 Predictions Min       -140.973
trainer/Q2 Predictions Mean       -45.3184
trainer/Q2 Predictions Std         44.2734
trainer/Q2 Predictions Max         -6.79291
trainer/Q2 Predictions Min       -140.348
trainer/Q Targets Mean            -45.6523
trainer/Q Targets Std              44.6851
trainer/Q Targets Max              -7.05638
trainer/Q Targets Min            -142.314
trainer/Log Pis Mean                2.13857
trainer/Log Pis Std                 0.886984
trainer/Log Pis Max                 4.3491
trainer/Log Pis Min                -1.26404
trainer/Policy mu Mean             -0.0496625
trainer/Policy mu Std               0.423823
trainer/Policy mu Max               2.48632
trainer/Policy mu Min              -2.49137
trainer/Policy log std Mean        -2.2797
trainer/Policy log std Std          0.347045
trainer/Policy log std Max         -0.581867
trainer/Policy log std Min         -3.05276
trainer/Alpha                       0.0674401
trainer/Alpha Loss                  0.373676
exploration/num steps total    207700
exploration/num paths total      2077
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.819155
exploration/Rewards Std             1.30933
exploration/Rewards Max            -0.0086879
exploration/Rewards Min            -7.97269
exploration/Returns Mean          -81.9155
exploration/Returns Std           109.413
exploration/Returns Max           -14.2685
exploration/Returns Min          -299.291
exploration/Actions Mean            0.015509
exploration/Actions Std             0.182915
exploration/Actions Max             0.998971
exploration/Actions Min            -0.992859
exploration/Num Paths               5
exploration/Average Returns       -81.9155
evaluation/num steps total     622500
evaluation/num paths total       6225
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.573064
evaluation/Rewards Std              0.884599
evaluation/Rewards Max             -0.00736746
evaluation/Rewards Min             -9.27726
evaluation/Returns Mean           -57.3064
evaluation/Returns Std             45.0714
evaluation/Returns Max            -13.0731
evaluation/Returns Min           -182.701
evaluation/Actions Mean             0.0087463
evaluation/Actions Std              0.178953
evaluation/Actions Max              0.99769
evaluation/Actions Min             -0.996507
evaluation/Num Paths               15
evaluation/Average Returns        -57.3064
time/data storing (s)               0.00274349
time/evaluation sampling (s)        0.325532
time/exploration sampling (s)       0.136973
time/logging (s)                    0.00394804
time/saving (s)                     0.00196274
time/training (s)                   1.99704
time/epoch (s)                      2.4682
time/total (s)                   1018.61
Epoch                             414
-----------------------------  ---------------
2019-04-23 01:30:33.117598 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 415 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.34574
trainer/QF2 Loss                    0.388969
trainer/Policy Loss                44.1748
trainer/Q1 Predictions Mean       -42.325
trainer/Q1 Predictions Std         44.41
trainer/Q1 Predictions Max         -7.22539
trainer/Q1 Predictions Min       -141.357
trainer/Q2 Predictions Mean       -42.2912
trainer/Q2 Predictions Std         44.3792
trainer/Q2 Predictions Max         -7.20713
trainer/Q2 Predictions Min       -141.108
trainer/Q Targets Mean            -42.6183
trainer/Q Targets Std              44.5537
trainer/Q Targets Max              -7.0259
trainer/Q Targets Min            -141.828
trainer/Log Pis Mean                2.00468
trainer/Log Pis Std                 1.14271
trainer/Log Pis Max                 5.64118
trainer/Log Pis Min                -1.75311
trainer/Policy mu Mean             -0.027145
trainer/Policy mu Std               0.401946
trainer/Policy mu Max               2.60384
trainer/Policy mu Min              -2.07516
trainer/Policy log std Mean        -2.29988
trainer/Policy log std Std          0.389951
trainer/Policy log std Max         -0.64695
trainer/Policy log std Min         -2.90203
trainer/Alpha                       0.0673847
trainer/Alpha Loss                  0.0126336
exploration/num steps total    208200
exploration/num paths total      2082
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.955159
exploration/Rewards Std             0.985892
exploration/Rewards Max            -0.00958951
exploration/Rewards Min            -7.31146
exploration/Returns Mean          -95.5159
exploration/Returns Std            46.7121
exploration/Returns Max           -39.993
exploration/Returns Min          -161.901
exploration/Actions Mean            0.00403417
exploration/Actions Std             0.223475
exploration/Actions Max             0.998034
exploration/Actions Min            -0.997958
exploration/Num Paths               5
exploration/Average Returns       -95.5159
evaluation/num steps total     624000
evaluation/num paths total       6240
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.02875
evaluation/Rewards Std              1.32256
evaluation/Rewards Max             -0.0463838
evaluation/Rewards Min            -11.3411
evaluation/Returns Mean          -102.875
evaluation/Returns Std             68.1474
evaluation/Returns Max            -15.3042
evaluation/Returns Min           -281.521
evaluation/Actions Mean             0.0340689
evaluation/Actions Std              0.20131
evaluation/Actions Max              0.998847
evaluation/Actions Min             -0.996579
evaluation/Num Paths               15
evaluation/Average Returns       -102.875
time/data storing (s)               0.00274685
time/evaluation sampling (s)        0.329364
time/exploration sampling (s)       0.139218
time/logging (s)                    0.00477095
time/saving (s)                     0.00195045
time/training (s)                   1.95836
time/epoch (s)                      2.43641
time/total (s)                   1021.05
Epoch                             415
-----------------------------  ---------------
2019-04-23 01:30:35.593087 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 416 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.05734
trainer/QF2 Loss                    1.12211
trainer/Policy Loss                33.5392
trainer/Q1 Predictions Mean       -31.7109
trainer/Q1 Predictions Std         37.0631
trainer/Q1 Predictions Max         -7.01054
trainer/Q1 Predictions Min       -139.287
trainer/Q2 Predictions Mean       -31.6916
trainer/Q2 Predictions Std         37.025
trainer/Q2 Predictions Max         -7.05536
trainer/Q2 Predictions Min       -139.34
trainer/Q Targets Mean            -31.9461
trainer/Q Targets Std              37.2522
trainer/Q Targets Max              -0.569982
trainer/Q Targets Min            -139.604
trainer/Log Pis Mean                1.93461
trainer/Log Pis Std                 1.08998
trainer/Log Pis Max                 3.65464
trainer/Log Pis Min                -2.31784
trainer/Policy mu Mean             -0.0117139
trainer/Policy mu Std               0.334795
trainer/Policy mu Max               2.38312
trainer/Policy mu Min              -1.69394
trainer/Policy log std Mean        -2.28959
trainer/Policy log std Std          0.341348
trainer/Policy log std Max         -0.598307
trainer/Policy log std Min         -2.90094
trainer/Alpha                       0.0683054
trainer/Alpha Loss                 -0.175489
exploration/num steps total    208700
exploration/num paths total      2087
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.778873
exploration/Rewards Std             1.37538
exploration/Rewards Max            -0.0139493
exploration/Rewards Min           -11.5482
exploration/Returns Mean          -77.8873
exploration/Returns Std            64.9315
exploration/Returns Max           -24.0847
exploration/Returns Min          -202.866
exploration/Actions Mean            0.00944971
exploration/Actions Std             0.246311
exploration/Actions Max             0.997214
exploration/Actions Min            -0.999077
exploration/Num Paths               5
exploration/Average Returns       -77.8873
evaluation/num steps total     625500
evaluation/num paths total       6255
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.932278
evaluation/Rewards Std              1.2827
evaluation/Rewards Max             -0.0366369
evaluation/Rewards Min            -10.3992
evaluation/Returns Mean           -93.2278
evaluation/Returns Std             73.8357
evaluation/Returns Max            -22.576
evaluation/Returns Min           -292.66
evaluation/Actions Mean            -0.000247029
evaluation/Actions Std              0.196396
evaluation/Actions Max              0.998434
evaluation/Actions Min             -0.998095
evaluation/Num Paths               15
evaluation/Average Returns        -93.2278
time/data storing (s)               0.00265285
time/evaluation sampling (s)        0.327175
time/exploration sampling (s)       0.138373
time/logging (s)                    0.00480891
time/saving (s)                     0.00192196
time/training (s)                   1.99005
time/epoch (s)                      2.46498
time/total (s)                   1023.52
Epoch                             416
-----------------------------  ----------------
2019-04-23 01:30:38.082328 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 417 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   22.5756
trainer/QF2 Loss                   22.7017
trainer/Policy Loss                37.4205
trainer/Q1 Predictions Mean       -35.6185
trainer/Q1 Predictions Std         41.6067
trainer/Q1 Predictions Max         -7.23821
trainer/Q1 Predictions Min       -138.175
trainer/Q2 Predictions Mean       -35.607
trainer/Q2 Predictions Std         41.6217
trainer/Q2 Predictions Max         -7.22835
trainer/Q2 Predictions Min       -137.867
trainer/Q Targets Mean            -35.5198
trainer/Q Targets Std              42.1064
trainer/Q Targets Max              -0.827819
trainer/Q Targets Min            -139.655
trainer/Log Pis Mean                1.87673
trainer/Log Pis Std                 1.42031
trainer/Log Pis Max                 5.05874
trainer/Log Pis Min                -6.1682
trainer/Policy mu Mean             -0.0561384
trainer/Policy mu Std               0.441626
trainer/Policy mu Max               2.55476
trainer/Policy mu Min              -3.08153
trainer/Policy log std Mean        -2.27819
trainer/Policy log std Std          0.365971
trainer/Policy log std Max         -0.558705
trainer/Policy log std Min         -2.96394
trainer/Alpha                       0.0691812
trainer/Alpha Loss                 -0.329263
exploration/num steps total    209200
exploration/num paths total      2092
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.75204
exploration/Rewards Std             1.44712
exploration/Rewards Max            -0.0184337
exploration/Rewards Min           -10.2841
exploration/Returns Mean         -175.204
exploration/Returns Std            94.4733
exploration/Returns Max           -59.2005
exploration/Returns Min          -275.902
exploration/Actions Mean            0.0188571
exploration/Actions Std             0.23021
exploration/Actions Max             0.999281
exploration/Actions Min            -0.996169
exploration/Num Paths               5
exploration/Average Returns      -175.204
evaluation/num steps total     627000
evaluation/num paths total       6270
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.385104
evaluation/Rewards Std              0.874471
evaluation/Rewards Max             -0.0123619
evaluation/Rewards Min             -9.59328
evaluation/Returns Mean           -38.5104
evaluation/Returns Std             38.8732
evaluation/Returns Max             -5.59499
evaluation/Returns Min           -145.249
evaluation/Actions Mean            -0.00734824
evaluation/Actions Std              0.157884
evaluation/Actions Max              0.992401
evaluation/Actions Min             -0.998738
evaluation/Num Paths               15
evaluation/Average Returns        -38.5104
time/data storing (s)               0.00266008
time/evaluation sampling (s)        0.327013
time/exploration sampling (s)       0.139382
time/logging (s)                    0.00500682
time/saving (s)                     0.00155472
time/training (s)                   2.00311
time/epoch (s)                      2.47873
time/total (s)                   1026
Epoch                             417
-----------------------------  ---------------
2019-04-23 01:30:40.564089 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 418 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.593265
trainer/QF2 Loss                    0.549506
trainer/Policy Loss                41.5106
trainer/Q1 Predictions Mean       -39.5364
trainer/Q1 Predictions Std         41.9986
trainer/Q1 Predictions Max         -6.94127
trainer/Q1 Predictions Min       -138.476
trainer/Q2 Predictions Mean       -39.5707
trainer/Q2 Predictions Std         42.0447
trainer/Q2 Predictions Max         -6.99351
trainer/Q2 Predictions Min       -138.133
trainer/Q Targets Mean            -40.0122
trainer/Q Targets Std              42.4259
trainer/Q Targets Max              -7.02136
trainer/Q Targets Min            -139.683
trainer/Log Pis Mean                2.04317
trainer/Log Pis Std                 1.31609
trainer/Log Pis Max                 6.09406
trainer/Log Pis Min                -4.83837
trainer/Policy mu Mean             -0.0265859
trainer/Policy mu Std               0.612253
trainer/Policy mu Max               3.09
trainer/Policy mu Min              -3.20344
trainer/Policy log std Mean        -2.23594
trainer/Policy log std Std          0.437693
trainer/Policy log std Max         -0.554272
trainer/Policy log std Min         -2.91539
trainer/Alpha                       0.0695937
trainer/Alpha Loss                  0.115046
exploration/num steps total    209700
exploration/num paths total      2097
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.43362
exploration/Rewards Std             1.19223
exploration/Rewards Max            -0.0198584
exploration/Rewards Min            -8.3495
exploration/Returns Mean         -143.362
exploration/Returns Std           101.184
exploration/Returns Max           -21.0646
exploration/Returns Min          -279.392
exploration/Actions Mean           -0.0251553
exploration/Actions Std             0.21769
exploration/Actions Max             0.842321
exploration/Actions Min            -0.998368
exploration/Num Paths               5
exploration/Average Returns      -143.362
evaluation/num steps total     628500
evaluation/num paths total       6285
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.891386
evaluation/Rewards Std              1.27107
evaluation/Rewards Max             -0.0475357
evaluation/Rewards Min             -9.90124
evaluation/Returns Mean           -89.1386
evaluation/Returns Std             63.0768
evaluation/Returns Max            -17.7273
evaluation/Returns Min           -216.65
evaluation/Actions Mean             0.0174902
evaluation/Actions Std              0.205204
evaluation/Actions Max              0.999195
evaluation/Actions Min             -0.999208
evaluation/Num Paths               15
evaluation/Average Returns        -89.1386
time/data storing (s)               0.00275498
time/evaluation sampling (s)        0.325123
time/exploration sampling (s)       0.136716
time/logging (s)                    0.00484309
time/saving (s)                     0.00194761
time/training (s)                   1.99979
time/epoch (s)                      2.47117
time/total (s)                   1028.48
Epoch                             418
-----------------------------  ---------------
2019-04-23 01:30:43.046177 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 419 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                  109.407
trainer/QF2 Loss                  110.48
trainer/Policy Loss                48.5169
trainer/Q1 Predictions Mean       -46.5451
trainer/Q1 Predictions Std         41.3629
trainer/Q1 Predictions Max         -6.82867
trainer/Q1 Predictions Min       -138.789
trainer/Q2 Predictions Mean       -46.5747
trainer/Q2 Predictions Std         41.4088
trainer/Q2 Predictions Max         -6.87662
trainer/Q2 Predictions Min       -138.612
trainer/Q Targets Mean            -45.7581
trainer/Q Targets Std              41.4088
trainer/Q Targets Max              -3.27614
trainer/Q Targets Min            -138.993
trainer/Log Pis Mean                2.21855
trainer/Log Pis Std                 1.13387
trainer/Log Pis Max                 6.49667
trainer/Log Pis Min                -1.82631
trainer/Policy mu Mean             -0.0481069
trainer/Policy mu Std               0.504026
trainer/Policy mu Max               2.91518
trainer/Policy mu Min              -3.02027
trainer/Policy log std Mean        -2.30725
trainer/Policy log std Std          0.403796
trainer/Policy log std Max         -0.620254
trainer/Policy log std Min         -3.08319
trainer/Alpha                       0.0698068
trainer/Alpha Loss                  0.581822
exploration/num steps total    210200
exploration/num paths total      2102
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.03024
exploration/Rewards Std             1.23428
exploration/Rewards Max            -0.0160988
exploration/Rewards Min            -7.2598
exploration/Returns Mean         -103.024
exploration/Returns Std           101.355
exploration/Returns Max           -20.161
exploration/Returns Min          -283.257
exploration/Actions Mean           -0.00902108
exploration/Actions Std             0.217863
exploration/Actions Max             0.989739
exploration/Actions Min            -0.996217
exploration/Num Paths               5
exploration/Average Returns      -103.024
evaluation/num steps total     630000
evaluation/num paths total       6300
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.04748
evaluation/Rewards Std              1.29986
evaluation/Rewards Max             -0.0358968
evaluation/Rewards Min             -9.97091
evaluation/Returns Mean          -104.748
evaluation/Returns Std             88.2664
evaluation/Returns Max            -12.2807
evaluation/Returns Min           -271.991
evaluation/Actions Mean             0.000859381
evaluation/Actions Std              0.175854
evaluation/Actions Max              0.99891
evaluation/Actions Min             -0.998101
evaluation/Num Paths               15
evaluation/Average Returns       -104.748
time/data storing (s)               0.0027516
time/evaluation sampling (s)        0.327328
time/exploration sampling (s)       0.138367
time/logging (s)                    0.00475297
time/saving (s)                     0.00989443
time/training (s)                   1.98832
time/epoch (s)                      2.47142
time/total (s)                   1030.95
Epoch                             419
-----------------------------  ----------------
2019-04-23 01:30:45.524383 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 420 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.34066
trainer/QF2 Loss                    0.385522
trainer/Policy Loss                43.6471
trainer/Q1 Predictions Mean       -42.0068
trainer/Q1 Predictions Std         43.3258
trainer/Q1 Predictions Max         -7.08009
trainer/Q1 Predictions Min       -141.988
trainer/Q2 Predictions Mean       -41.9903
trainer/Q2 Predictions Std         43.2756
trainer/Q2 Predictions Max         -7.07745
trainer/Q2 Predictions Min       -141.139
trainer/Q Targets Mean            -42.3959
trainer/Q Targets Std              43.6138
trainer/Q Targets Max              -6.9782
trainer/Q Targets Min            -142.792
trainer/Log Pis Mean                1.77596
trainer/Log Pis Std                 0.972809
trainer/Log Pis Max                 3.55184
trainer/Log Pis Min                -1.18097
trainer/Policy mu Mean              0.0181426
trainer/Policy mu Std               0.314483
trainer/Policy mu Max               0.941965
trainer/Policy mu Min              -2.11662
trainer/Policy log std Mean        -2.19896
trainer/Policy log std Std          0.34562
trainer/Policy log std Max         -0.741343
trainer/Policy log std Min         -3.07502
trainer/Alpha                       0.0691061
trainer/Alpha Loss                 -0.598575
exploration/num steps total    210700
exploration/num paths total      2107
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.16549
exploration/Rewards Std             1.35004
exploration/Rewards Max            -0.00298212
exploration/Rewards Min            -9.47479
exploration/Returns Mean         -116.549
exploration/Returns Std           104.798
exploration/Returns Max           -30.7622
exploration/Returns Min          -301.551
exploration/Actions Mean           -0.0124695
exploration/Actions Std             0.238476
exploration/Actions Max             0.999067
exploration/Actions Min            -0.997134
exploration/Num Paths               5
exploration/Average Returns      -116.549
evaluation/num steps total     631500
evaluation/num paths total       6315
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.06433
evaluation/Rewards Std              1.01009
evaluation/Rewards Max             -0.0272448
evaluation/Rewards Min             -8.63377
evaluation/Returns Mean          -106.433
evaluation/Returns Std             74.2061
evaluation/Returns Max            -15.1426
evaluation/Returns Min           -276.749
evaluation/Actions Mean            -0.00109621
evaluation/Actions Std              0.170289
evaluation/Actions Max              0.998873
evaluation/Actions Min             -0.992945
evaluation/Num Paths               15
evaluation/Average Returns       -106.433
time/data storing (s)               0.00266241
time/evaluation sampling (s)        0.326401
time/exploration sampling (s)       0.139689
time/logging (s)                    0.00392909
time/saving (s)                     0.00192683
time/training (s)                   1.99272
time/epoch (s)                      2.46732
time/total (s)                   1033.43
Epoch                             420
-----------------------------  ---------------
2019-04-23 01:30:48.005498 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 421 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                  179.442
trainer/QF2 Loss                  180.105
trainer/Policy Loss                33.9466
trainer/Q1 Predictions Mean       -31.9939
trainer/Q1 Predictions Std         37.1034
trainer/Q1 Predictions Max         -7.03877
trainer/Q1 Predictions Min       -137.657
trainer/Q2 Predictions Mean       -32.0046
trainer/Q2 Predictions Std         37.1162
trainer/Q2 Predictions Max         -7.03491
trainer/Q2 Predictions Min       -137.8
trainer/Q Targets Mean            -31.0482
trainer/Q Targets Std              36.146
trainer/Q Targets Max              -3.35079
trainer/Q Targets Min            -139.377
trainer/Log Pis Mean                2.03999
trainer/Log Pis Std                 0.960896
trainer/Log Pis Max                 4.58185
trainer/Log Pis Min                -1.16673
trainer/Policy mu Mean             -0.0463777
trainer/Policy mu Std               0.319584
trainer/Policy mu Max               0.786909
trainer/Policy mu Min              -3.28586
trainer/Policy log std Mean        -2.31574
trainer/Policy log std Std          0.302357
trainer/Policy log std Max         -0.549591
trainer/Policy log std Min         -2.90732
trainer/Alpha                       0.0677501
trainer/Alpha Loss                  0.10766
exploration/num steps total    211200
exploration/num paths total      2112
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.905969
exploration/Rewards Std             1.3042
exploration/Rewards Max            -0.00833791
exploration/Rewards Min            -9.39606
exploration/Returns Mean          -90.5969
exploration/Returns Std            98.5001
exploration/Returns Max           -15.2213
exploration/Returns Min          -283.511
exploration/Actions Mean           -0.0165974
exploration/Actions Std             0.221685
exploration/Actions Max             0.998558
exploration/Actions Min            -0.999524
exploration/Num Paths               5
exploration/Average Returns       -90.5969
evaluation/num steps total     633000
evaluation/num paths total       6330
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.879847
evaluation/Rewards Std              1.1456
evaluation/Rewards Max             -0.0182304
evaluation/Rewards Min             -9.14425
evaluation/Returns Mean           -87.9847
evaluation/Returns Std             76.856
evaluation/Returns Max             -2.46606
evaluation/Returns Min           -284.244
evaluation/Actions Mean             0.0018245
evaluation/Actions Std              0.173631
evaluation/Actions Max              0.998644
evaluation/Actions Min             -0.995888
evaluation/Num Paths               15
evaluation/Average Returns        -87.9847
time/data storing (s)               0.00271563
time/evaluation sampling (s)        0.328107
time/exploration sampling (s)       0.140607
time/logging (s)                    0.00483647
time/saving (s)                     0.00192538
time/training (s)                   1.99317
time/epoch (s)                      2.47136
time/total (s)                   1035.9
Epoch                             421
-----------------------------  ---------------
2019-04-23 01:30:50.490057 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 422 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.129695
trainer/QF2 Loss                    0.087725
trainer/Policy Loss                38.9436
trainer/Q1 Predictions Mean       -37.107
trainer/Q1 Predictions Std         38.9714
trainer/Q1 Predictions Max         -7.05562
trainer/Q1 Predictions Min       -151.241
trainer/Q2 Predictions Mean       -37.1056
trainer/Q2 Predictions Std         38.9363
trainer/Q2 Predictions Max         -7.05832
trainer/Q2 Predictions Min       -151.508
trainer/Q Targets Mean            -37.2253
trainer/Q Targets Std              38.9578
trainer/Q Targets Max              -7.07574
trainer/Q Targets Min            -152.549
trainer/Log Pis Mean                1.94144
trainer/Log Pis Std                 1.19595
trainer/Log Pis Max                 6.87572
trainer/Log Pis Min                -3.04072
trainer/Policy mu Mean             -0.0786058
trainer/Policy mu Std               0.505259
trainer/Policy mu Max               1.83841
trainer/Policy mu Min              -3.31928
trainer/Policy log std Mean        -2.25143
trainer/Policy log std Std          0.409276
trainer/Policy log std Max         -0.368796
trainer/Policy log std Min         -2.99041
trainer/Alpha                       0.069946
trainer/Alpha Loss                 -0.155781
exploration/num steps total    211700
exploration/num paths total      2117
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.34091
exploration/Rewards Std             1.08551
exploration/Rewards Max            -0.0289543
exploration/Rewards Min            -7.50082
exploration/Returns Mean         -134.091
exploration/Returns Std            90.3924
exploration/Returns Max           -18.5489
exploration/Returns Min          -264.68
exploration/Actions Mean           -0.0132498
exploration/Actions Std             0.20536
exploration/Actions Max             0.942629
exploration/Actions Min            -0.998678
exploration/Num Paths               5
exploration/Average Returns      -134.091
evaluation/num steps total     634500
evaluation/num paths total       6345
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.662003
evaluation/Rewards Std              1.16707
evaluation/Rewards Max             -0.0409417
evaluation/Rewards Min             -9.77965
evaluation/Returns Mean           -66.2003
evaluation/Returns Std             45.0455
evaluation/Returns Max            -12.6582
evaluation/Returns Min           -154.518
evaluation/Actions Mean            -0.00402142
evaluation/Actions Std              0.201939
evaluation/Actions Max              0.998355
evaluation/Actions Min             -0.999625
evaluation/Num Paths               15
evaluation/Average Returns        -66.2003
time/data storing (s)               0.00280528
time/evaluation sampling (s)        0.32418
time/exploration sampling (s)       0.141023
time/logging (s)                    0.00350958
time/saving (s)                     0.00193275
time/training (s)                   2.00078
time/epoch (s)                      2.47424
time/total (s)                   1038.38
Epoch                             422
-----------------------------  ---------------
2019-04-23 01:30:52.937714 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 423 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.2061
trainer/QF2 Loss                    1.19612
trainer/Policy Loss                38.5599
trainer/Q1 Predictions Mean       -36.7971
trainer/Q1 Predictions Std         41.7566
trainer/Q1 Predictions Max         -6.95732
trainer/Q1 Predictions Min       -138.407
trainer/Q2 Predictions Mean       -36.7847
trainer/Q2 Predictions Std         41.7959
trainer/Q2 Predictions Max         -6.96678
trainer/Q2 Predictions Min       -138.378
trainer/Q Targets Mean            -37.1072
trainer/Q Targets Std              42.2782
trainer/Q Targets Max              -0.074979
trainer/Q Targets Min            -139.635
trainer/Log Pis Mean                1.89348
trainer/Log Pis Std                 1.12387
trainer/Log Pis Max                 5.00169
trainer/Log Pis Min                -2.19191
trainer/Policy mu Mean             -0.0131325
trainer/Policy mu Std               0.531244
trainer/Policy mu Max               3.01753
trainer/Policy mu Min              -2.40089
trainer/Policy log std Mean        -2.18034
trainer/Policy log std Std          0.40533
trainer/Policy log std Max         -0.556489
trainer/Policy log std Min         -3.14456
trainer/Alpha                       0.0686984
trainer/Alpha Loss                 -0.285271
exploration/num steps total    212200
exploration/num paths total      2122
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.555051
exploration/Rewards Std             1.11401
exploration/Rewards Max            -0.00646635
exploration/Rewards Min           -10.2352
exploration/Returns Mean          -55.5051
exploration/Returns Std            27.1871
exploration/Returns Max           -28.3425
exploration/Returns Min          -103.929
exploration/Actions Mean            0.0312321
exploration/Actions Std             0.22725
exploration/Actions Max             0.99999
exploration/Actions Min            -0.999317
exploration/Num Paths               5
exploration/Average Returns       -55.5051
evaluation/num steps total     636000
evaluation/num paths total       6360
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.944708
evaluation/Rewards Std              1.0438
evaluation/Rewards Max             -0.0421009
evaluation/Rewards Min             -9.6544
evaluation/Returns Mean           -94.4708
evaluation/Returns Std             65.1644
evaluation/Returns Max            -11.1335
evaluation/Returns Min           -216.778
evaluation/Actions Mean            -0.00171674
evaluation/Actions Std              0.180644
evaluation/Actions Max              0.995273
evaluation/Actions Min             -0.9991
evaluation/Num Paths               15
evaluation/Average Returns        -94.4708
time/data storing (s)               0.00282788
time/evaluation sampling (s)        0.326192
time/exploration sampling (s)       0.13738
time/logging (s)                    0.00424926
time/saving (s)                     0.00193045
time/training (s)                   1.96589
time/epoch (s)                      2.43846
time/total (s)                   1040.82
Epoch                             423
-----------------------------  ---------------
2019-04-23 01:30:55.416992 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 424 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.36128
trainer/QF2 Loss                    1.20709
trainer/Policy Loss                40.2891
trainer/Q1 Predictions Mean       -38.3424
trainer/Q1 Predictions Std         45.6586
trainer/Q1 Predictions Max         -7.05233
trainer/Q1 Predictions Min       -162.237
trainer/Q2 Predictions Mean       -38.359
trainer/Q2 Predictions Std         45.689
trainer/Q2 Predictions Max         -7.10547
trainer/Q2 Predictions Min       -163.191
trainer/Q Targets Mean            -39.0033
trainer/Q Targets Std              46.4455
trainer/Q Targets Max              -7.1129
trainer/Q Targets Min            -168.292
trainer/Log Pis Mean                2.01976
trainer/Log Pis Std                 1.20201
trainer/Log Pis Max                 6.54694
trainer/Log Pis Min                -2.30758
trainer/Policy mu Mean             -0.0678963
trainer/Policy mu Std               0.444752
trainer/Policy mu Max               1.42714
trainer/Policy mu Min              -3.45089
trainer/Policy log std Mean        -2.30713
trainer/Policy log std Std          0.368595
trainer/Policy log std Max         -0.461103
trainer/Policy log std Min         -2.97341
trainer/Alpha                       0.0670473
trainer/Alpha Loss                  0.0533903
exploration/num steps total    212700
exploration/num paths total      2127
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.820715
exploration/Rewards Std             1.01629
exploration/Rewards Max            -0.00896842
exploration/Rewards Min            -8.3251
exploration/Returns Mean          -82.0715
exploration/Returns Std            48.9885
exploration/Returns Max           -24.7937
exploration/Returns Min          -141.777
exploration/Actions Mean            0.00378816
exploration/Actions Std             0.207207
exploration/Actions Max             0.999503
exploration/Actions Min            -0.991913
exploration/Num Paths               5
exploration/Average Returns       -82.0715
evaluation/num steps total     637500
evaluation/num paths total       6375
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.831891
evaluation/Rewards Std              0.929172
evaluation/Rewards Max             -0.0429453
evaluation/Rewards Min             -9.05442
evaluation/Returns Mean           -83.1891
evaluation/Returns Std             63.9581
evaluation/Returns Max             -9.82931
evaluation/Returns Min           -200.363
evaluation/Actions Mean            -0.00683319
evaluation/Actions Std              0.163698
evaluation/Actions Max              0.99891
evaluation/Actions Min             -0.997198
evaluation/Num Paths               15
evaluation/Average Returns        -83.1891
time/data storing (s)               0.00293154
time/evaluation sampling (s)        0.330116
time/exploration sampling (s)       0.141876
time/logging (s)                    0.00485023
time/saving (s)                     0.00191914
time/training (s)                   1.98762
time/epoch (s)                      2.46931
time/total (s)                   1043.3
Epoch                             424
-----------------------------  ---------------
2019-04-23 01:30:57.890138 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 425 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                  104.399
trainer/QF2 Loss                  104.203
trainer/Policy Loss                35.8697
trainer/Q1 Predictions Mean       -34.0993
trainer/Q1 Predictions Std         40.1138
trainer/Q1 Predictions Max         -7.12311
trainer/Q1 Predictions Min       -137.572
trainer/Q2 Predictions Mean       -34.0695
trainer/Q2 Predictions Std         40.0948
trainer/Q2 Predictions Max         -7.11657
trainer/Q2 Predictions Min       -137.225
trainer/Q Targets Mean            -33.4836
trainer/Q Targets Std              40.0346
trainer/Q Targets Max              -1.78952
trainer/Q Targets Min            -138.921
trainer/Log Pis Mean                1.83737
trainer/Log Pis Std                 1.29444
trainer/Log Pis Max                 5.71726
trainer/Log Pis Min                -3.57537
trainer/Policy mu Mean              0.00756769
trainer/Policy mu Std               0.567235
trainer/Policy mu Max               2.89907
trainer/Policy mu Min              -3.38751
trainer/Policy log std Mean        -2.23252
trainer/Policy log std Std          0.407018
trainer/Policy log std Max         -0.263245
trainer/Policy log std Min         -3.00862
trainer/Alpha                       0.0686456
trainer/Alpha Loss                 -0.43568
exploration/num steps total    213200
exploration/num paths total      2132
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.05717
exploration/Rewards Std             1.46
exploration/Rewards Max            -0.00662704
exploration/Rewards Min           -10.7129
exploration/Returns Mean         -105.717
exploration/Returns Std            76.3278
exploration/Returns Max           -24.0417
exploration/Returns Min          -200.779
exploration/Actions Mean            0.00808654
exploration/Actions Std             0.24547
exploration/Actions Max             0.998201
exploration/Actions Min            -0.999376
exploration/Num Paths               5
exploration/Average Returns      -105.717
evaluation/num steps total     639000
evaluation/num paths total       6390
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.77078
evaluation/Rewards Std              1.16358
evaluation/Rewards Max             -0.0221833
evaluation/Rewards Min            -11.1287
evaluation/Returns Mean           -77.078
evaluation/Returns Std             55.4199
evaluation/Returns Max            -16.5961
evaluation/Returns Min           -181.74
evaluation/Actions Mean             0.0124091
evaluation/Actions Std              0.181426
evaluation/Actions Max              0.999251
evaluation/Actions Min             -0.998113
evaluation/Num Paths               15
evaluation/Average Returns        -77.078
time/data storing (s)               0.00272144
time/evaluation sampling (s)        0.324695
time/exploration sampling (s)       0.135259
time/logging (s)                    0.00482167
time/saving (s)                     0.00194695
time/training (s)                   1.99347
time/epoch (s)                      2.46291
time/total (s)                   1045.77
Epoch                             425
-----------------------------  ---------------
2019-04-23 01:31:00.355359 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 426 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.399822
trainer/QF2 Loss                    0.401336
trainer/Policy Loss                37.0966
trainer/Q1 Predictions Mean       -35.099
trainer/Q1 Predictions Std         39.2504
trainer/Q1 Predictions Max         -6.90166
trainer/Q1 Predictions Min       -138.131
trainer/Q2 Predictions Mean       -35.1098
trainer/Q2 Predictions Std         39.233
trainer/Q2 Predictions Max         -6.89894
trainer/Q2 Predictions Min       -138.044
trainer/Q Targets Mean            -35.5414
trainer/Q Targets Std              39.5872
trainer/Q Targets Max              -6.97822
trainer/Q Targets Min            -138.943
trainer/Log Pis Mean                2.07164
trainer/Log Pis Std                 1.14855
trainer/Log Pis Max                 9.74797
trainer/Log Pis Min                -0.813261
trainer/Policy mu Mean             -0.0304461
trainer/Policy mu Std               0.410002
trainer/Policy mu Max               3.07178
trainer/Policy mu Min              -2.95252
trainer/Policy log std Mean        -2.27724
trainer/Policy log std Std          0.342759
trainer/Policy log std Max         -0.164626
trainer/Policy log std Min         -2.94607
trainer/Alpha                       0.0694206
trainer/Alpha Loss                  0.191097
exploration/num steps total    213700
exploration/num paths total      2137
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.83988
exploration/Rewards Std             1.16652
exploration/Rewards Max            -0.029091
exploration/Rewards Min            -8.19356
exploration/Returns Mean         -183.988
exploration/Returns Std            98.7402
exploration/Returns Max           -31.19
exploration/Returns Min          -283.912
exploration/Actions Mean           -0.0153371
exploration/Actions Std             0.210782
exploration/Actions Max             0.997455
exploration/Actions Min            -0.997899
exploration/Num Paths               5
exploration/Average Returns      -183.988
evaluation/num steps total     640500
evaluation/num paths total       6405
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.819166
evaluation/Rewards Std              1.13623
evaluation/Rewards Max             -0.0461392
evaluation/Rewards Min            -11.3949
evaluation/Returns Mean           -81.9166
evaluation/Returns Std             60.7775
evaluation/Returns Max            -10.9032
evaluation/Returns Min           -215.752
evaluation/Actions Mean             0.0147775
evaluation/Actions Std              0.19184
evaluation/Actions Max              0.998801
evaluation/Actions Min             -0.997116
evaluation/Num Paths               15
evaluation/Average Returns        -81.9166
time/data storing (s)               0.00264694
time/evaluation sampling (s)        0.327361
time/exploration sampling (s)       0.136858
time/logging (s)                    0.00479691
time/saving (s)                     0.0019356
time/training (s)                   1.98195
time/epoch (s)                      2.45555
time/total (s)                   1048.22
Epoch                             426
-----------------------------  ---------------
2019-04-23 01:31:02.830626 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 427 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   64.7208
trainer/QF2 Loss                   64.0809
trainer/Policy Loss                48.9314
trainer/Q1 Predictions Mean       -47.0302
trainer/Q1 Predictions Std         45.2713
trainer/Q1 Predictions Max         -6.95648
trainer/Q1 Predictions Min       -137.528
trainer/Q2 Predictions Mean       -47.1083
trainer/Q2 Predictions Std         45.3205
trainer/Q2 Predictions Max         -6.96446
trainer/Q2 Predictions Min       -137.496
trainer/Q Targets Mean            -46.6824
trainer/Q Targets Std              45.8157
trainer/Q Targets Max              -1.29835
trainer/Q Targets Min            -139.174
trainer/Log Pis Mean                2.01295
trainer/Log Pis Std                 0.95938
trainer/Log Pis Max                 4.34003
trainer/Log Pis Min                -1.8002
trainer/Policy mu Mean             -0.0650207
trainer/Policy mu Std               0.395141
trainer/Policy mu Max               1.77084
trainer/Policy mu Min              -2.23157
trainer/Policy log std Mean        -2.26406
trainer/Policy log std Std          0.344976
trainer/Policy log std Max         -0.837174
trainer/Policy log std Min         -3.05973
trainer/Alpha                       0.0684312
trainer/Alpha Loss                  0.0347214
exploration/num steps total    214200
exploration/num paths total      2142
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.12397
exploration/Rewards Std             1.25061
exploration/Rewards Max            -0.0270901
exploration/Rewards Min           -11.9786
exploration/Returns Mean         -112.397
exploration/Returns Std            75.3919
exploration/Returns Max           -25.1461
exploration/Returns Min          -233.723
exploration/Actions Mean           -0.0148556
exploration/Actions Std             0.240151
exploration/Actions Max             0.993836
exploration/Actions Min            -0.99825
exploration/Num Paths               5
exploration/Average Returns      -112.397
evaluation/num steps total     642000
evaluation/num paths total       6420
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.617685
evaluation/Rewards Std              1.09665
evaluation/Rewards Max             -0.0289865
evaluation/Rewards Min             -9.75063
evaluation/Returns Mean           -61.7685
evaluation/Returns Std             47.5165
evaluation/Returns Max             -7.7675
evaluation/Returns Min           -139.091
evaluation/Actions Mean             0.0241668
evaluation/Actions Std              0.180842
evaluation/Actions Max              0.99864
evaluation/Actions Min             -0.997714
evaluation/Num Paths               15
evaluation/Average Returns        -61.7685
time/data storing (s)               0.00273341
time/evaluation sampling (s)        0.327663
time/exploration sampling (s)       0.135473
time/logging (s)                    0.00482562
time/saving (s)                     0.0019408
time/training (s)                   1.99206
time/epoch (s)                      2.46469
time/total (s)                   1050.69
Epoch                             427
-----------------------------  ---------------
2019-04-23 01:31:05.309597 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 428 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.243122
trainer/QF2 Loss                    0.234518
trainer/Policy Loss                34.4943
trainer/Q1 Predictions Mean       -32.509
trainer/Q1 Predictions Std         38.2113
trainer/Q1 Predictions Max         -7.11782
trainer/Q1 Predictions Min       -137.79
trainer/Q2 Predictions Mean       -32.537
trainer/Q2 Predictions Std         38.2834
trainer/Q2 Predictions Max         -7.1701
trainer/Q2 Predictions Min       -137.65
trainer/Q Targets Mean            -32.7896
trainer/Q Targets Std              38.498
trainer/Q Targets Max              -6.98124
trainer/Q Targets Min            -138.595
trainer/Log Pis Mean                2.05326
trainer/Log Pis Std                 1.31804
trainer/Log Pis Max                 7.44559
trainer/Log Pis Min                -2.66218
trainer/Policy mu Mean             -0.0423961
trainer/Policy mu Std               0.530682
trainer/Policy mu Max               2.96007
trainer/Policy mu Min              -2.67423
trainer/Policy log std Mean        -2.25135
trainer/Policy log std Std          0.371342
trainer/Policy log std Max         -0.559795
trainer/Policy log std Min         -2.96527
trainer/Alpha                       0.0680908
trainer/Alpha Loss                  0.143118
exploration/num steps total    214700
exploration/num paths total      2147
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.12345
exploration/Rewards Std             1.28897
exploration/Rewards Max            -0.0276048
exploration/Rewards Min            -9.64894
exploration/Returns Mean         -112.345
exploration/Returns Std            95.7079
exploration/Returns Max           -26.804
exploration/Returns Min          -286.92
exploration/Actions Mean            0.0178747
exploration/Actions Std             0.206778
exploration/Actions Max             0.998129
exploration/Actions Min            -0.999333
exploration/Num Paths               5
exploration/Average Returns      -112.345
evaluation/num steps total     643500
evaluation/num paths total       6435
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.68253
evaluation/Rewards Std              1.10696
evaluation/Rewards Max             -0.0214026
evaluation/Rewards Min             -9.52013
evaluation/Returns Mean           -68.253
evaluation/Returns Std             53.6105
evaluation/Returns Max             -6.16024
evaluation/Returns Min           -166.401
evaluation/Actions Mean            -0.00482496
evaluation/Actions Std              0.189977
evaluation/Actions Max              0.998941
evaluation/Actions Min             -0.999443
evaluation/Num Paths               15
evaluation/Average Returns        -68.253
time/data storing (s)               0.0027246
time/evaluation sampling (s)        0.329835
time/exploration sampling (s)       0.136406
time/logging (s)                    0.00485425
time/saving (s)                     0.00194409
time/training (s)                   1.99258
time/epoch (s)                      2.46835
time/total (s)                   1053.17
Epoch                             428
-----------------------------  ---------------
2019-04-23 01:31:07.775212 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 429 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   10.0216
trainer/QF2 Loss                    9.75802
trainer/Policy Loss                36.9903
trainer/Q1 Predictions Mean       -35.0686
trainer/Q1 Predictions Std         37.4208
trainer/Q1 Predictions Max         -7.33084
trainer/Q1 Predictions Min       -157.166
trainer/Q2 Predictions Mean       -35.0144
trainer/Q2 Predictions Std         37.3975
trainer/Q2 Predictions Max         -7.2813
trainer/Q2 Predictions Min       -158.565
trainer/Q Targets Mean            -34.9885
trainer/Q Targets Std              37.9411
trainer/Q Targets Max              -0.171548
trainer/Q Targets Min            -161.87
trainer/Log Pis Mean                2.01461
trainer/Log Pis Std                 1.07961
trainer/Log Pis Max                 6.74535
trainer/Log Pis Min                -2.10469
trainer/Policy mu Mean             -0.0406581
trainer/Policy mu Std               0.522177
trainer/Policy mu Max               3.27708
trainer/Policy mu Min              -3.22199
trainer/Policy log std Mean        -2.16361
trainer/Policy log std Std          0.423838
trainer/Policy log std Max         -0.491236
trainer/Policy log std Min         -2.9349
trainer/Alpha                       0.0683973
trainer/Alpha Loss                  0.0391863
exploration/num steps total    215200
exploration/num paths total      2152
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.74376
exploration/Rewards Std             1.23645
exploration/Rewards Max            -0.0205125
exploration/Rewards Min           -11.4881
exploration/Returns Mean          -74.376
exploration/Returns Std            46.0948
exploration/Returns Max           -22.3184
exploration/Returns Min          -148.393
exploration/Actions Mean            0.00552032
exploration/Actions Std             0.241877
exploration/Actions Max             0.999622
exploration/Actions Min            -0.999485
exploration/Num Paths               5
exploration/Average Returns       -74.376
evaluation/num steps total     645000
evaluation/num paths total       6450
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.755808
evaluation/Rewards Std              1.10996
evaluation/Rewards Max             -0.0184193
evaluation/Rewards Min            -11.6591
evaluation/Returns Mean           -75.5808
evaluation/Returns Std             65.8993
evaluation/Returns Max            -11.7338
evaluation/Returns Min           -187.39
evaluation/Actions Mean            -0.0118924
evaluation/Actions Std              0.17376
evaluation/Actions Max              0.99805
evaluation/Actions Min             -0.999328
evaluation/Num Paths               15
evaluation/Average Returns        -75.5808
time/data storing (s)               0.00276763
time/evaluation sampling (s)        0.32741
time/exploration sampling (s)       0.139452
time/logging (s)                    0.00477426
time/saving (s)                     0.00155651
time/training (s)                   1.98013
time/epoch (s)                      2.45609
time/total (s)                   1055.63
Epoch                             429
-----------------------------  ---------------
2019-04-23 01:31:10.248531 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 430 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.47265
trainer/QF2 Loss                    1.47806
trainer/Policy Loss                40.2585
trainer/Q1 Predictions Mean       -38.2721
trainer/Q1 Predictions Std         41.0806
trainer/Q1 Predictions Max         -7.11574
trainer/Q1 Predictions Min       -156.376
trainer/Q2 Predictions Mean       -38.2861
trainer/Q2 Predictions Std         41.0902
trainer/Q2 Predictions Max         -7.12648
trainer/Q2 Predictions Min       -156.775
trainer/Q Targets Mean            -38.8937
trainer/Q Targets Std              41.953
trainer/Q Targets Max              -7.07075
trainer/Q Targets Min            -158.151
trainer/Log Pis Mean                2.08876
trainer/Log Pis Std                 1.11955
trainer/Log Pis Max                 6.73851
trainer/Log Pis Min                -1.05705
trainer/Policy mu Mean             -0.0582056
trainer/Policy mu Std               0.52194
trainer/Policy mu Max               2.74762
trainer/Policy mu Min              -2.94241
trainer/Policy log std Mean        -2.23908
trainer/Policy log std Std          0.42329
trainer/Policy log std Max         -0.682786
trainer/Policy log std Min         -2.98101
trainer/Alpha                       0.0690845
trainer/Alpha Loss                  0.237207
exploration/num steps total    215700
exploration/num paths total      2157
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.896783
exploration/Rewards Std             1.11951
exploration/Rewards Max            -0.0205326
exploration/Rewards Min            -8.01274
exploration/Returns Mean          -89.6783
exploration/Returns Std            35.339
exploration/Returns Max           -46.5426
exploration/Returns Min          -131.236
exploration/Actions Mean            0.0323953
exploration/Actions Std             0.23205
exploration/Actions Max             0.999844
exploration/Actions Min            -0.837212
exploration/Num Paths               5
exploration/Average Returns       -89.6783
evaluation/num steps total     646500
evaluation/num paths total       6465
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.740457
evaluation/Rewards Std              1.21045
evaluation/Rewards Max             -0.0132392
evaluation/Rewards Min            -11.0077
evaluation/Returns Mean           -74.0457
evaluation/Returns Std             73.4993
evaluation/Returns Max             -9.86787
evaluation/Returns Min           -272.714
evaluation/Actions Mean            -0.0125854
evaluation/Actions Std              0.193337
evaluation/Actions Max              0.997955
evaluation/Actions Min             -0.999238
evaluation/Num Paths               15
evaluation/Average Returns        -74.0457
time/data storing (s)               0.00276871
time/evaluation sampling (s)        0.33074
time/exploration sampling (s)       0.141615
time/logging (s)                    0.00476109
time/saving (s)                     0.00194613
time/training (s)                   1.98201
time/epoch (s)                      2.46385
time/total (s)                   1058.09
Epoch                             430
-----------------------------  ---------------
2019-04-23 01:31:12.733192 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 431 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   24.385
trainer/QF2 Loss                   24.5053
trainer/Policy Loss                43.5185
trainer/Q1 Predictions Mean       -41.4107
trainer/Q1 Predictions Std         42.5079
trainer/Q1 Predictions Max         -7.05087
trainer/Q1 Predictions Min       -135.744
trainer/Q2 Predictions Mean       -41.4459
trainer/Q2 Predictions Std         42.5323
trainer/Q2 Predictions Max         -7.07902
trainer/Q2 Predictions Min       -135.673
trainer/Q Targets Mean            -41.2546
trainer/Q Targets Std              43.3978
trainer/Q Targets Max              -0.236969
trainer/Q Targets Min            -137.04
trainer/Log Pis Mean                2.22368
trainer/Log Pis Std                 1.13152
trainer/Log Pis Max                 7.56075
trainer/Log Pis Min                -0.706706
trainer/Policy mu Mean             -0.100743
trainer/Policy mu Std               0.649105
trainer/Policy mu Max               2.86929
trainer/Policy mu Min              -3.27233
trainer/Policy log std Mean        -2.21341
trainer/Policy log std Std          0.470751
trainer/Policy log std Max         -0.362161
trainer/Policy log std Min         -2.9911
trainer/Alpha                       0.069336
trainer/Alpha Loss                  0.596962
exploration/num steps total    216200
exploration/num paths total      2162
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.04941
exploration/Rewards Std             1.14762
exploration/Rewards Max            -0.0120058
exploration/Rewards Min            -8.82253
exploration/Returns Mean         -104.941
exploration/Returns Std            77.5582
exploration/Returns Max           -29.6682
exploration/Returns Min          -200.888
exploration/Actions Mean            0.0207994
exploration/Actions Std             0.220843
exploration/Actions Max             0.998183
exploration/Actions Min            -0.998065
exploration/Num Paths               5
exploration/Average Returns      -104.941
evaluation/num steps total     648000
evaluation/num paths total       6480
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.840115
evaluation/Rewards Std              1.05533
evaluation/Rewards Max             -0.0102277
evaluation/Rewards Min             -9.64344
evaluation/Returns Mean           -84.0115
evaluation/Returns Std             52.2209
evaluation/Returns Max             -9.19392
evaluation/Returns Min           -196.467
evaluation/Actions Mean            -0.00591889
evaluation/Actions Std              0.175265
evaluation/Actions Max              0.998592
evaluation/Actions Min             -0.999141
evaluation/Num Paths               15
evaluation/Average Returns        -84.0115
time/data storing (s)               0.00272341
time/evaluation sampling (s)        0.328082
time/exploration sampling (s)       0.140397
time/logging (s)                    0.00477519
time/saving (s)                     0.00952123
time/training (s)                   1.98971
time/epoch (s)                      2.47521
time/total (s)                   1060.57
Epoch                             431
-----------------------------  ---------------
2019-04-23 01:31:15.178380 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 432 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.6681
trainer/QF2 Loss                    1.65029
trainer/Policy Loss                39.5799
trainer/Q1 Predictions Mean       -37.4812
trainer/Q1 Predictions Std         41.3081
trainer/Q1 Predictions Max         -7.00701
trainer/Q1 Predictions Min       -136.157
trainer/Q2 Predictions Mean       -37.4736
trainer/Q2 Predictions Std         41.2965
trainer/Q2 Predictions Max         -7.04029
trainer/Q2 Predictions Min       -136.092
trainer/Q Targets Mean            -37.4689
trainer/Q Targets Std              41.6512
trainer/Q Targets Max              -0.0940224
trainer/Q Targets Min            -136.95
trainer/Log Pis Mean                2.24505
trainer/Log Pis Std                 0.961882
trainer/Log Pis Max                 4.7648
trainer/Log Pis Min                -0.145048
trainer/Policy mu Mean             -0.00948627
trainer/Policy mu Std               0.397124
trainer/Policy mu Max               1.70167
trainer/Policy mu Min              -2.69799
trainer/Policy log std Mean        -2.29144
trainer/Policy log std Std          0.341299
trainer/Policy log std Max         -0.72306
trainer/Policy log std Min         -3.06035
trainer/Alpha                       0.0690354
trainer/Alpha Loss                  0.65509
exploration/num steps total    216700
exploration/num paths total      2167
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.11463
exploration/Rewards Std             0.83541
exploration/Rewards Max            -0.00439766
exploration/Rewards Min            -7.74771
exploration/Returns Mean         -111.463
exploration/Returns Std            47.7521
exploration/Returns Max           -49.4917
exploration/Returns Min          -183.137
exploration/Actions Mean            0.0105904
exploration/Actions Std             0.201331
exploration/Actions Max             0.969764
exploration/Actions Min            -0.999819
exploration/Num Paths               5
exploration/Average Returns      -111.463
evaluation/num steps total     649500
evaluation/num paths total       6495
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.22636
evaluation/Rewards Std              1.3683
evaluation/Rewards Max             -0.0969932
evaluation/Rewards Min            -10.5906
evaluation/Returns Mean          -122.636
evaluation/Returns Std             83.8294
evaluation/Returns Max            -11.671
evaluation/Returns Min           -265.238
evaluation/Actions Mean            -0.0103754
evaluation/Actions Std              0.195969
evaluation/Actions Max              0.997943
evaluation/Actions Min             -0.999043
evaluation/Num Paths               15
evaluation/Average Returns       -122.636
time/data storing (s)               0.00260285
time/evaluation sampling (s)        0.327156
time/exploration sampling (s)       0.137293
time/logging (s)                    0.00474633
time/saving (s)                     0.00193776
time/training (s)                   1.96094
time/epoch (s)                      2.43468
time/total (s)                   1063.01
Epoch                             432
-----------------------------  ---------------
2019-04-23 01:31:17.662199 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 433 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                  179.643
trainer/QF2 Loss                  179.75
trainer/Policy Loss                39.7521
trainer/Q1 Predictions Mean       -37.8497
trainer/Q1 Predictions Std         41.8598
trainer/Q1 Predictions Max         -6.91065
trainer/Q1 Predictions Min       -137.132
trainer/Q2 Predictions Mean       -37.8546
trainer/Q2 Predictions Std         41.8583
trainer/Q2 Predictions Max         -6.89726
trainer/Q2 Predictions Min       -137.28
trainer/Q Targets Mean            -36.7175
trainer/Q Targets Std              41.0556
trainer/Q Targets Max              -0.351532
trainer/Q Targets Min            -137.733
trainer/Log Pis Mean                1.98258
trainer/Log Pis Std                 1.25002
trainer/Log Pis Max                 7.51325
trainer/Log Pis Min                -2.41985
trainer/Policy mu Mean             -0.0194269
trainer/Policy mu Std               0.409845
trainer/Policy mu Max               3.49532
trainer/Policy mu Min              -2.95287
trainer/Policy log std Mean        -2.29814
trainer/Policy log std Std          0.304266
trainer/Policy log std Max         -0.529053
trainer/Policy log std Min         -3.0265
trainer/Alpha                       0.0676343
trainer/Alpha Loss                 -0.0469195
exploration/num steps total    217200
exploration/num paths total      2172
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.78765
exploration/Rewards Std             1.30752
exploration/Rewards Max            -0.00892647
exploration/Rewards Min           -11.6134
exploration/Returns Mean          -78.765
exploration/Returns Std            52.6271
exploration/Returns Max           -22.6783
exploration/Returns Min          -155.234
exploration/Actions Mean            0.0256882
exploration/Actions Std             0.223601
exploration/Actions Max             0.999891
exploration/Actions Min            -0.99775
exploration/Num Paths               5
exploration/Average Returns       -78.765
evaluation/num steps total     651000
evaluation/num paths total       6510
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.919598
evaluation/Rewards Std              1.12932
evaluation/Rewards Max             -0.0547423
evaluation/Rewards Min             -9.60773
evaluation/Returns Mean           -91.9598
evaluation/Returns Std             62.0282
evaluation/Returns Max             -7.11782
evaluation/Returns Min           -187.316
evaluation/Actions Mean             0.00131008
evaluation/Actions Std              0.191618
evaluation/Actions Max              0.99783
evaluation/Actions Min             -0.998774
evaluation/Num Paths               15
evaluation/Average Returns        -91.9598
time/data storing (s)               0.00263743
time/evaluation sampling (s)        0.322171
time/exploration sampling (s)       0.139685
time/logging (s)                    0.00474258
time/saving (s)                     0.0019247
time/training (s)                   2.00184
time/epoch (s)                      2.473
time/total (s)                   1065.49
Epoch                             433
-----------------------------  ---------------
2019-04-23 01:31:20.147969 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 434 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.20499
trainer/QF2 Loss                    1.28428
trainer/Policy Loss                40.5621
trainer/Q1 Predictions Mean       -38.6071
trainer/Q1 Predictions Std         38.6872
trainer/Q1 Predictions Max         -7.01325
trainer/Q1 Predictions Min       -147.332
trainer/Q2 Predictions Mean       -38.5887
trainer/Q2 Predictions Std         38.6957
trainer/Q2 Predictions Max         -7.02043
trainer/Q2 Predictions Min       -148.033
trainer/Q Targets Mean            -39.3058
trainer/Q Targets Std              39.3188
trainer/Q Targets Max              -6.92058
trainer/Q Targets Min            -149.354
trainer/Log Pis Mean                2.04897
trainer/Log Pis Std                 1.35122
trainer/Log Pis Max                 6.6608
trainer/Log Pis Min                -2.80316
trainer/Policy mu Mean             -0.0250042
trainer/Policy mu Std               0.577728
trainer/Policy mu Max               2.64676
trainer/Policy mu Min              -2.7484
trainer/Policy log std Mean        -2.21809
trainer/Policy log std Std          0.473948
trainer/Policy log std Max         -0.1083
trainer/Policy log std Min         -3.15525
trainer/Alpha                       0.0674431
trainer/Alpha Loss                  0.132041
exploration/num steps total    217700
exploration/num paths total      2177
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.74121
exploration/Rewards Std             0.79863
exploration/Rewards Max            -0.51856
exploration/Rewards Min            -5.79668
exploration/Returns Mean         -174.121
exploration/Returns Std            66.7948
exploration/Returns Max           -75.781
exploration/Returns Min          -285.617
exploration/Actions Mean            0.0040652
exploration/Actions Std             0.182546
exploration/Actions Max             0.984529
exploration/Actions Min            -0.997272
exploration/Num Paths               5
exploration/Average Returns      -174.121
evaluation/num steps total     652500
evaluation/num paths total       6525
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.694681
evaluation/Rewards Std              1.2852
evaluation/Rewards Max             -0.0254703
evaluation/Rewards Min             -9.98662
evaluation/Returns Mean           -69.4681
evaluation/Returns Std             76.8381
evaluation/Returns Max             -7.089
evaluation/Returns Min           -283.091
evaluation/Actions Mean            -6.14107e-05
evaluation/Actions Std              0.184283
evaluation/Actions Max              0.999493
evaluation/Actions Min             -0.998427
evaluation/Num Paths               15
evaluation/Average Returns        -69.4681
time/data storing (s)               0.00274868
time/evaluation sampling (s)        0.323366
time/exploration sampling (s)       0.141344
time/logging (s)                    0.00479956
time/saving (s)                     0.00205501
time/training (s)                   2.00075
time/epoch (s)                      2.47506
time/total (s)                   1067.97
Epoch                             434
-----------------------------  ----------------
2019-04-23 01:31:22.615583 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 435 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                  172.675
trainer/QF2 Loss                  172.858
trainer/Policy Loss                51.0236
trainer/Q1 Predictions Mean       -48.9729
trainer/Q1 Predictions Std         44.7764
trainer/Q1 Predictions Max         -6.79761
trainer/Q1 Predictions Min       -135.521
trainer/Q2 Predictions Mean       -48.9378
trainer/Q2 Predictions Std         44.7471
trainer/Q2 Predictions Max         -6.87582
trainer/Q2 Predictions Min       -134.735
trainer/Q Targets Mean            -48.405
trainer/Q Targets Std              45.018
trainer/Q Targets Max              -2.72258
trainer/Q Targets Min            -137.704
trainer/Log Pis Mean                2.16993
trainer/Log Pis Std                 1.16774
trainer/Log Pis Max                 8.10602
trainer/Log Pis Min                -1.96235
trainer/Policy mu Mean              0.00564213
trainer/Policy mu Std               0.487382
trainer/Policy mu Max               2.70313
trainer/Policy mu Min              -2.86389
trainer/Policy log std Mean        -2.26236
trainer/Policy log std Std          0.389325
trainer/Policy log std Max         -0.689444
trainer/Policy log std Min         -3.03546
trainer/Alpha                       0.0688586
trainer/Alpha Loss                  0.454694
exploration/num steps total    218200
exploration/num paths total      2182
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.727958
exploration/Rewards Std             1.03112
exploration/Rewards Max            -0.0161466
exploration/Rewards Min            -8.97964
exploration/Returns Mean          -72.7958
exploration/Returns Std            50.59
exploration/Returns Max           -19.2677
exploration/Returns Min          -154.342
exploration/Actions Mean           -0.0217552
exploration/Actions Std             0.224777
exploration/Actions Max             0.997245
exploration/Actions Min            -0.999174
exploration/Num Paths               5
exploration/Average Returns       -72.7958
evaluation/num steps total     654000
evaluation/num paths total       6540
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.661992
evaluation/Rewards Std              1.14145
evaluation/Rewards Max             -0.0461703
evaluation/Rewards Min            -10.7123
evaluation/Returns Mean           -66.1992
evaluation/Returns Std             69.4334
evaluation/Returns Max            -13.0641
evaluation/Returns Min           -212.324
evaluation/Actions Mean             0.00262192
evaluation/Actions Std              0.189029
evaluation/Actions Max              0.996425
evaluation/Actions Min             -0.999339
evaluation/Num Paths               15
evaluation/Average Returns        -66.1992
time/data storing (s)               0.0025695
time/evaluation sampling (s)        0.336248
time/exploration sampling (s)       0.140494
time/logging (s)                    0.00505472
time/saving (s)                     0.00195604
time/training (s)                   1.97193
time/epoch (s)                      2.45826
time/total (s)                   1070.43
Epoch                             435
-----------------------------  ---------------
2019-04-23 01:31:25.081118 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 436 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                   21.7661
trainer/QF2 Loss                   21.7616
trainer/Policy Loss                43.446
trainer/Q1 Predictions Mean       -41.6482
trainer/Q1 Predictions Std         42.9242
trainer/Q1 Predictions Max         -6.84706
trainer/Q1 Predictions Min       -137.676
trainer/Q2 Predictions Mean       -41.6509
trainer/Q2 Predictions Std         42.9169
trainer/Q2 Predictions Max         -6.89279
trainer/Q2 Predictions Min       -137.366
trainer/Q Targets Mean            -41.4061
trainer/Q Targets Std              43.1983
trainer/Q Targets Max              -0.967057
trainer/Q Targets Min            -137.331
trainer/Log Pis Mean                1.91816
trainer/Log Pis Std                 1.38348
trainer/Log Pis Max                 7.03327
trainer/Log Pis Min                -2.21475
trainer/Policy mu Mean             -0.0847509
trainer/Policy mu Std               0.539554
trainer/Policy mu Max               3.279
trainer/Policy mu Min              -2.71287
trainer/Policy log std Mean        -2.2019
trainer/Policy log std Std          0.458376
trainer/Policy log std Max         -0.169459
trainer/Policy log std Min         -3.02147
trainer/Alpha                       0.067419
trainer/Alpha Loss                 -0.220724
exploration/num steps total    218700
exploration/num paths total      2187
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.913276
exploration/Rewards Std             0.841045
exploration/Rewards Max            -0.0142753
exploration/Rewards Min            -7.42128
exploration/Returns Mean          -91.3276
exploration/Returns Std            59.7426
exploration/Returns Max           -20.6095
exploration/Returns Min          -191.496
exploration/Actions Mean           -0.00889942
exploration/Actions Std             0.211522
exploration/Actions Max             0.996174
exploration/Actions Min            -0.999598
exploration/Num Paths               5
exploration/Average Returns       -91.3276
evaluation/num steps total     655500
evaluation/num paths total       6555
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.865492
evaluation/Rewards Std              1.18701
evaluation/Rewards Max             -0.0509712
evaluation/Rewards Min             -9.63983
evaluation/Returns Mean           -86.5492
evaluation/Returns Std             88.9388
evaluation/Returns Max             -7.77534
evaluation/Returns Min           -299.618
evaluation/Actions Mean             0.000948969
evaluation/Actions Std              0.165208
evaluation/Actions Max              0.996177
evaluation/Actions Min             -0.998602
evaluation/Num Paths               15
evaluation/Average Returns        -86.5492
time/data storing (s)               0.00280296
time/evaluation sampling (s)        0.329181
time/exploration sampling (s)       0.139863
time/logging (s)                    0.00482756
time/saving (s)                     0.00196415
time/training (s)                   1.97749
time/epoch (s)                      2.45613
time/total (s)                   1072.89
Epoch                             436
-----------------------------  ----------------
2019-04-23 01:31:27.567604 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 437 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.876146
trainer/QF2 Loss                    0.795064
trainer/Policy Loss                46.9163
trainer/Q1 Predictions Mean       -44.9502
trainer/Q1 Predictions Std         44.5362
trainer/Q1 Predictions Max         -6.95079
trainer/Q1 Predictions Min       -141.809
trainer/Q2 Predictions Mean       -44.9319
trainer/Q2 Predictions Std         44.4926
trainer/Q2 Predictions Max         -6.97638
trainer/Q2 Predictions Min       -141.035
trainer/Q Targets Mean            -44.8747
trainer/Q Targets Std              44.4284
trainer/Q Targets Max              -0.0429493
trainer/Q Targets Min            -137.074
trainer/Log Pis Mean                2.12502
trainer/Log Pis Std                 1.1284
trainer/Log Pis Max                 7.72158
trainer/Log Pis Min                -2.23447
trainer/Policy mu Mean              0.0428375
trainer/Policy mu Std               0.535974
trainer/Policy mu Max               2.96009
trainer/Policy mu Min              -2.5493
trainer/Policy log std Mean        -2.24805
trainer/Policy log std Std          0.412962
trainer/Policy log std Max         -0.723823
trainer/Policy log std Min         -3.02366
trainer/Alpha                       0.0679475
trainer/Alpha Loss                  0.336208
exploration/num steps total    219200
exploration/num paths total      2192
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.29769
exploration/Rewards Std             1.11196
exploration/Rewards Max            -0.0256772
exploration/Rewards Min            -8.88399
exploration/Returns Mean         -129.769
exploration/Returns Std            73.4791
exploration/Returns Max           -51.6494
exploration/Returns Min          -254.387
exploration/Actions Mean           -0.00868436
exploration/Actions Std             0.228092
exploration/Actions Max             0.992553
exploration/Actions Min            -0.999348
exploration/Num Paths               5
exploration/Average Returns      -129.769
evaluation/num steps total     657000
evaluation/num paths total       6570
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.715557
evaluation/Rewards Std              1.12825
evaluation/Rewards Max             -0.043752
evaluation/Rewards Min            -10.8917
evaluation/Returns Mean           -71.5557
evaluation/Returns Std             62.7807
evaluation/Returns Max             -8.18455
evaluation/Returns Min           -185.875
evaluation/Actions Mean             0.00583095
evaluation/Actions Std              0.182179
evaluation/Actions Max              0.999354
evaluation/Actions Min             -0.999204
evaluation/Num Paths               15
evaluation/Average Returns        -71.5557
time/data storing (s)               0.00281074
time/evaluation sampling (s)        0.327476
time/exploration sampling (s)       0.136207
time/logging (s)                    0.00486382
time/saving (s)                     0.0019542
time/training (s)                   2.00221
time/epoch (s)                      2.47553
time/total (s)                   1075.37
Epoch                             437
-----------------------------  ---------------
2019-04-23 01:31:30.029917 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 438 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.5581
trainer/QF2 Loss                    1.60684
trainer/Policy Loss                39.8312
trainer/Q1 Predictions Mean       -37.8619
trainer/Q1 Predictions Std         41.0482
trainer/Q1 Predictions Max         -6.77237
trainer/Q1 Predictions Min       -136.207
trainer/Q2 Predictions Mean       -37.8327
trainer/Q2 Predictions Std         41.0751
trainer/Q2 Predictions Max         -6.80601
trainer/Q2 Predictions Min       -136.254
trainer/Q Targets Mean            -38.1868
trainer/Q Targets Std              41.6278
trainer/Q Targets Max              -0.150604
trainer/Q Targets Min            -137.575
trainer/Log Pis Mean                2.03905
trainer/Log Pis Std                 1.34523
trainer/Log Pis Max                10.6185
trainer/Log Pis Min                -0.50206
trainer/Policy mu Mean             -0.0203806
trainer/Policy mu Std               0.550451
trainer/Policy mu Max               3.36362
trainer/Policy mu Min              -3.03604
trainer/Policy log std Mean        -2.21438
trainer/Policy log std Std          0.388964
trainer/Policy log std Max         -0.436881
trainer/Policy log std Min         -2.86696
trainer/Alpha                       0.0717775
trainer/Alpha Loss                  0.102868
exploration/num steps total    219700
exploration/num paths total      2197
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.1153
exploration/Rewards Std             0.873635
exploration/Rewards Max            -0.0328113
exploration/Rewards Min            -7.87712
exploration/Returns Mean         -111.53
exploration/Returns Std            65.2272
exploration/Returns Max           -22.137
exploration/Returns Min          -197.719
exploration/Actions Mean            0.00252391
exploration/Actions Std             0.203199
exploration/Actions Max             0.994284
exploration/Actions Min            -0.99928
exploration/Num Paths               5
exploration/Average Returns      -111.53
evaluation/num steps total     658500
evaluation/num paths total       6585
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.995917
evaluation/Rewards Std              1.13503
evaluation/Rewards Max             -0.0242318
evaluation/Rewards Min             -9.65911
evaluation/Returns Mean           -99.5917
evaluation/Returns Std             87.2979
evaluation/Returns Max             -6.54029
evaluation/Returns Min           -278.721
evaluation/Actions Mean             0.000257139
evaluation/Actions Std              0.172898
evaluation/Actions Max              0.998546
evaluation/Actions Min             -0.999444
evaluation/Num Paths               15
evaluation/Average Returns        -99.5917
time/data storing (s)               0.00275088
time/evaluation sampling (s)        0.332781
time/exploration sampling (s)       0.135604
time/logging (s)                    0.00479624
time/saving (s)                     0.00193114
time/training (s)                   1.97365
time/epoch (s)                      2.45151
time/total (s)                   1077.83
Epoch                             438
-----------------------------  ----------------
2019-04-23 01:31:32.505180 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 439 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   22.3
trainer/QF2 Loss                   22.2605
trainer/Policy Loss                42.6837
trainer/Q1 Predictions Mean       -40.7372
trainer/Q1 Predictions Std         40.9299
trainer/Q1 Predictions Max         -6.86953
trainer/Q1 Predictions Min       -145.544
trainer/Q2 Predictions Mean       -40.72
trainer/Q2 Predictions Std         40.9299
trainer/Q2 Predictions Max         -6.91626
trainer/Q2 Predictions Min       -144.824
trainer/Q Targets Mean            -40.7768
trainer/Q Targets Std              41.6621
trainer/Q Targets Max              -1.06518
trainer/Q Targets Min            -144.51
trainer/Log Pis Mean                2.0857
trainer/Log Pis Std                 1.34518
trainer/Log Pis Max                 8.999
trainer/Log Pis Min                -2.91958
trainer/Policy mu Mean             -0.0724861
trainer/Policy mu Std               0.605643
trainer/Policy mu Max               2.65044
trainer/Policy mu Min              -3.48048
trainer/Policy log std Mean        -2.19443
trainer/Policy log std Std          0.429965
trainer/Policy log std Max         -0.550701
trainer/Policy log std Min         -2.95424
trainer/Alpha                       0.0694166
trainer/Alpha Loss                  0.228623
exploration/num steps total    220200
exploration/num paths total      2202
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.513628
exploration/Rewards Std             1.18738
exploration/Rewards Max            -0.0150997
exploration/Rewards Min           -10.1886
exploration/Returns Mean          -51.3628
exploration/Returns Std            19.9819
exploration/Returns Max           -17.4704
exploration/Returns Min           -74.1829
exploration/Actions Mean           -0.019726
exploration/Actions Std             0.221432
exploration/Actions Max             0.995963
exploration/Actions Min            -0.998978
exploration/Num Paths               5
exploration/Average Returns       -51.3628
evaluation/num steps total     660000
evaluation/num paths total       6600
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.405738
evaluation/Rewards Std              0.954735
evaluation/Rewards Max             -0.0149455
evaluation/Rewards Min             -8.62722
evaluation/Returns Mean           -40.5738
evaluation/Returns Std             32.423
evaluation/Returns Max             -9.77062
evaluation/Returns Min           -130.05
evaluation/Actions Mean             0.0145243
evaluation/Actions Std              0.186742
evaluation/Actions Max              0.998737
evaluation/Actions Min             -0.995805
evaluation/Num Paths               15
evaluation/Average Returns        -40.5738
time/data storing (s)               0.00275478
time/evaluation sampling (s)        0.32904
time/exploration sampling (s)       0.138327
time/logging (s)                    0.00357876
time/saving (s)                     0.00155634
time/training (s)                   1.98755
time/epoch (s)                      2.46281
time/total (s)                   1080.29
Epoch                             439
-----------------------------  ---------------
2019-04-23 01:31:34.961723 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 440 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.508334
trainer/QF2 Loss                    0.529559
trainer/Policy Loss                35.0821
trainer/Q1 Predictions Mean       -33.3271
trainer/Q1 Predictions Std         37.6649
trainer/Q1 Predictions Max         -6.86734
trainer/Q1 Predictions Min       -136.099
trainer/Q2 Predictions Mean       -33.3323
trainer/Q2 Predictions Std         37.6484
trainer/Q2 Predictions Max         -6.90729
trainer/Q2 Predictions Min       -135.825
trainer/Q Targets Mean            -33.2836
trainer/Q Targets Std              37.7253
trainer/Q Targets Max              -0.0539936
trainer/Q Targets Min            -136.011
trainer/Log Pis Mean                1.82983
trainer/Log Pis Std                 1.11921
trainer/Log Pis Max                 3.8102
trainer/Log Pis Min                -2.49359
trainer/Policy mu Mean             -0.0826703
trainer/Policy mu Std               0.398171
trainer/Policy mu Max               0.634805
trainer/Policy mu Min              -3.4546
trainer/Policy log std Mean        -2.28756
trainer/Policy log std Std          0.342828
trainer/Policy log std Max         -0.437811
trainer/Policy log std Min         -3.02844
trainer/Alpha                       0.0713346
trainer/Alpha Loss                 -0.449332
exploration/num steps total    220700
exploration/num paths total      2207
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.808328
exploration/Rewards Std             1.25925
exploration/Rewards Max            -0.0081269
exploration/Rewards Min            -8.14285
exploration/Returns Mean          -80.8328
exploration/Returns Std           103.442
exploration/Returns Max           -15.5677
exploration/Returns Min          -285.744
exploration/Actions Mean            0.0141211
exploration/Actions Std             0.20418
exploration/Actions Max             0.99396
exploration/Actions Min            -0.98563
exploration/Num Paths               5
exploration/Average Returns       -80.8328
evaluation/num steps total     661500
evaluation/num paths total       6615
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.456504
evaluation/Rewards Std              0.926939
evaluation/Rewards Max             -0.00441447
evaluation/Rewards Min             -9.82975
evaluation/Returns Mean           -45.6504
evaluation/Returns Std             44.4981
evaluation/Returns Max            -10.0426
evaluation/Returns Min           -127.956
evaluation/Actions Mean             0.00554714
evaluation/Actions Std              0.157091
evaluation/Actions Max              0.998564
evaluation/Actions Min             -0.99274
evaluation/Num Paths               15
evaluation/Average Returns        -45.6504
time/data storing (s)               0.00276887
time/evaluation sampling (s)        0.325316
time/exploration sampling (s)       0.136082
time/logging (s)                    0.00460159
time/saving (s)                     0.0015518
time/training (s)                   1.97692
time/epoch (s)                      2.44724
time/total (s)                   1082.75
Epoch                             440
-----------------------------  ---------------
2019-04-23 01:31:37.423265 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 441 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   21.3311
trainer/QF2 Loss                   21.5217
trainer/Policy Loss                41.0057
trainer/Q1 Predictions Mean       -39.2012
trainer/Q1 Predictions Std         39.9556
trainer/Q1 Predictions Max         -6.70645
trainer/Q1 Predictions Min       -132.587
trainer/Q2 Predictions Mean       -39.2018
trainer/Q2 Predictions Std         39.9887
trainer/Q2 Predictions Max         -6.72148
trainer/Q2 Predictions Min       -132.636
trainer/Q Targets Mean            -39.189
trainer/Q Targets Std              40.7136
trainer/Q Targets Max              -0.127707
trainer/Q Targets Min            -134.357
trainer/Log Pis Mean                1.8951
trainer/Log Pis Std                 1.13002
trainer/Log Pis Max                 5.77905
trainer/Log Pis Min                -2.67483
trainer/Policy mu Mean             -0.0582053
trainer/Policy mu Std               0.416254
trainer/Policy mu Max               1.6315
trainer/Policy mu Min              -2.42948
trainer/Policy log std Mean        -2.22816
trainer/Policy log std Std          0.371482
trainer/Policy log std Max         -0.456075
trainer/Policy log std Min         -2.99336
trainer/Alpha                       0.0746693
trainer/Alpha Loss                 -0.272163
exploration/num steps total    221200
exploration/num paths total      2212
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.02705
exploration/Rewards Std             0.827501
exploration/Rewards Max            -0.00525032
exploration/Rewards Min            -9.18876
exploration/Returns Mean         -102.705
exploration/Returns Std            53.0871
exploration/Returns Max           -23.6399
exploration/Returns Min          -188.378
exploration/Actions Mean            0.0112621
exploration/Actions Std             0.190173
exploration/Actions Max             0.994737
exploration/Actions Min            -0.998779
exploration/Num Paths               5
exploration/Average Returns      -102.705
evaluation/num steps total     663000
evaluation/num paths total       6630
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.989045
evaluation/Rewards Std              1.21663
evaluation/Rewards Max             -0.0212202
evaluation/Rewards Min             -9.5026
evaluation/Returns Mean           -98.9045
evaluation/Returns Std             87.0387
evaluation/Returns Max            -11.5268
evaluation/Returns Min           -287.738
evaluation/Actions Mean             0.00256029
evaluation/Actions Std              0.184947
evaluation/Actions Max              0.996911
evaluation/Actions Min             -0.997853
evaluation/Num Paths               15
evaluation/Average Returns        -98.9045
time/data storing (s)               0.00270615
time/evaluation sampling (s)        0.33604
time/exploration sampling (s)       0.136685
time/logging (s)                    0.00479252
time/saving (s)                     0.00190999
time/training (s)                   1.96996
time/epoch (s)                      2.4521
time/total (s)                   1085.2
Epoch                             441
-----------------------------  ---------------
2019-04-23 01:31:39.909882 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 442 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    2.20691
trainer/QF2 Loss                    2.13555
trainer/Policy Loss                35.5502
trainer/Q1 Predictions Mean       -33.8843
trainer/Q1 Predictions Std         35.586
trainer/Q1 Predictions Max         -6.72755
trainer/Q1 Predictions Min       -133.983
trainer/Q2 Predictions Mean       -33.8763
trainer/Q2 Predictions Std         35.574
trainer/Q2 Predictions Max         -6.77066
trainer/Q2 Predictions Min       -134.067
trainer/Q Targets Mean            -33.8575
trainer/Q Targets Std              35.7924
trainer/Q Targets Max              -0.111313
trainer/Q Targets Min            -134.252
trainer/Log Pis Mean                1.74813
trainer/Log Pis Std                 1.3081
trainer/Log Pis Max                 3.54453
trainer/Log Pis Min                -4.94469
trainer/Policy mu Mean             -0.0164691
trainer/Policy mu Std               0.236304
trainer/Policy mu Max               1.07859
trainer/Policy mu Min              -0.964348
trainer/Policy log std Mean        -2.27402
trainer/Policy log std Std          0.292353
trainer/Policy log std Max         -1.25074
trainer/Policy log std Min         -2.95279
trainer/Alpha                       0.0730672
trainer/Alpha Loss                 -0.658935
exploration/num steps total    221700
exploration/num paths total      2217
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.993742
exploration/Rewards Std             1.17592
exploration/Rewards Max            -0.011232
exploration/Rewards Min            -9.92898
exploration/Returns Mean          -99.3742
exploration/Returns Std            62.6925
exploration/Returns Max           -16.4283
exploration/Returns Min          -190.152
exploration/Actions Mean           -0.0202653
exploration/Actions Std             0.189477
exploration/Actions Max             0.948465
exploration/Actions Min            -0.999737
exploration/Num Paths               5
exploration/Average Returns       -99.3742
evaluation/num steps total     664500
evaluation/num paths total       6645
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.495501
evaluation/Rewards Std              0.938099
evaluation/Rewards Max             -0.00410133
evaluation/Rewards Min             -9.9029
evaluation/Returns Mean           -49.5501
evaluation/Returns Std             40.1722
evaluation/Returns Max            -12.8535
evaluation/Returns Min           -165.168
evaluation/Actions Mean             0.00842215
evaluation/Actions Std              0.181077
evaluation/Actions Max              0.998749
evaluation/Actions Min             -0.999622
evaluation/Num Paths               15
evaluation/Average Returns        -49.5501
time/data storing (s)               0.00276578
time/evaluation sampling (s)        0.328451
time/exploration sampling (s)       0.141531
time/logging (s)                    0.00481301
time/saving (s)                     0.00194875
time/training (s)                   1.99629
time/epoch (s)                      2.4758
time/total (s)                   1087.68
Epoch                             442
-----------------------------  ---------------
2019-04-23 01:31:42.387368 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 443 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.161943
trainer/QF2 Loss                    0.113698
trainer/Policy Loss                49.6656
trainer/Q1 Predictions Mean       -47.9555
trainer/Q1 Predictions Std         43.6977
trainer/Q1 Predictions Max         -7.00276
trainer/Q1 Predictions Min       -137.051
trainer/Q2 Predictions Mean       -47.961
trainer/Q2 Predictions Std         43.6848
trainer/Q2 Predictions Max         -7.01379
trainer/Q2 Predictions Min       -136.872
trainer/Q Targets Mean            -48.0107
trainer/Q Targets Std              43.7271
trainer/Q Targets Max              -6.99083
trainer/Q Targets Min            -136.275
trainer/Log Pis Mean                1.84738
trainer/Log Pis Std                 1.16558
trainer/Log Pis Max                 6.20206
trainer/Log Pis Min                -1.35219
trainer/Policy mu Mean             -0.0255268
trainer/Policy mu Std               0.481788
trainer/Policy mu Max               3.49732
trainer/Policy mu Min              -2.82035
trainer/Policy log std Mean        -2.19774
trainer/Policy log std Std          0.397082
trainer/Policy log std Max         -0.660742
trainer/Policy log std Min         -2.89673
trainer/Alpha                       0.0707382
trainer/Alpha Loss                 -0.40422
exploration/num steps total    222200
exploration/num paths total      2222
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.590163
exploration/Rewards Std             0.929365
exploration/Rewards Max            -0.0111313
exploration/Rewards Min            -7.40684
exploration/Returns Mean          -59.0163
exploration/Returns Std            44.418
exploration/Returns Max           -30.1341
exploration/Returns Min          -147.17
exploration/Actions Mean            0.0133434
exploration/Actions Std             0.224522
exploration/Actions Max             0.999811
exploration/Actions Min            -0.994652
exploration/Num Paths               5
exploration/Average Returns       -59.0163
evaluation/num steps total     666000
evaluation/num paths total       6660
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.09117
evaluation/Rewards Std              1.427
evaluation/Rewards Max             -0.0285798
evaluation/Rewards Min            -10.1047
evaluation/Returns Mean          -109.117
evaluation/Returns Std            100.076
evaluation/Returns Max            -17.9685
evaluation/Returns Min           -296.917
evaluation/Actions Mean            -0.0027929
evaluation/Actions Std              0.19335
evaluation/Actions Max              0.998833
evaluation/Actions Min             -0.998934
evaluation/Num Paths               15
evaluation/Average Returns       -109.117
time/data storing (s)               0.00264686
time/evaluation sampling (s)        0.328036
time/exploration sampling (s)       0.137488
time/logging (s)                    0.00486364
time/saving (s)                     0.00982674
time/training (s)                   1.98376
time/epoch (s)                      2.46662
time/total (s)                   1090.15
Epoch                             443
-----------------------------  ---------------
2019-04-23 01:31:44.870174 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 444 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   21.1326
trainer/QF2 Loss                   21.2022
trainer/Policy Loss                45.092
trainer/Q1 Predictions Mean       -43.3836
trainer/Q1 Predictions Std         41.0189
trainer/Q1 Predictions Max         -7.03366
trainer/Q1 Predictions Min       -146.316
trainer/Q2 Predictions Mean       -43.4356
trainer/Q2 Predictions Std         41.0726
trainer/Q2 Predictions Max         -6.97123
trainer/Q2 Predictions Min       -146.98
trainer/Q Targets Mean            -43.6757
trainer/Q Targets Std              41.8879
trainer/Q Targets Max              -0.783464
trainer/Q Targets Min            -148.57
trainer/Log Pis Mean                1.8469
trainer/Log Pis Std                 1.42227
trainer/Log Pis Max                 7.65121
trainer/Log Pis Min                -5.64914
trainer/Policy mu Mean             -0.120488
trainer/Policy mu Std               0.521216
trainer/Policy mu Max               2.44583
trainer/Policy mu Min              -2.98763
trainer/Policy log std Mean        -2.1372
trainer/Policy log std Std          0.438236
trainer/Policy log std Max         -0.281634
trainer/Policy log std Min         -2.7715
trainer/Alpha                       0.0686133
trainer/Alpha Loss                 -0.410163
exploration/num steps total    222700
exploration/num paths total      2227
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.852396
exploration/Rewards Std             1.10869
exploration/Rewards Max            -0.0101467
exploration/Rewards Min            -9.62712
exploration/Returns Mean          -85.2396
exploration/Returns Std            53.9143
exploration/Returns Max           -17.8601
exploration/Returns Min          -151.542
exploration/Actions Mean            0.0187859
exploration/Actions Std             0.215556
exploration/Actions Max             0.999827
exploration/Actions Min            -0.949899
exploration/Num Paths               5
exploration/Average Returns       -85.2396
evaluation/num steps total     667500
evaluation/num paths total       6675
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.784691
evaluation/Rewards Std              0.991947
evaluation/Rewards Max             -0.0206164
evaluation/Rewards Min             -9.95762
evaluation/Returns Mean           -78.4691
evaluation/Returns Std             63.5303
evaluation/Returns Max            -13.1676
evaluation/Returns Min           -184.375
evaluation/Actions Mean            -0.00990427
evaluation/Actions Std              0.181519
evaluation/Actions Max              0.99868
evaluation/Actions Min             -0.996382
evaluation/Num Paths               15
evaluation/Average Returns        -78.4691
time/data storing (s)               0.00288182
time/evaluation sampling (s)        0.328764
time/exploration sampling (s)       0.136688
time/logging (s)                    0.00478927
time/saving (s)                     0.00194247
time/training (s)                   1.99674
time/epoch (s)                      2.4718
time/total (s)                   1092.63
Epoch                             444
-----------------------------  ---------------
2019-04-23 01:31:47.328207 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 445 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.245659
trainer/QF2 Loss                    0.340922
trainer/Policy Loss                41.6259
trainer/Q1 Predictions Mean       -39.7549
trainer/Q1 Predictions Std         40.3066
trainer/Q1 Predictions Max         -6.70675
trainer/Q1 Predictions Min       -134.232
trainer/Q2 Predictions Mean       -39.7852
trainer/Q2 Predictions Std         40.3042
trainer/Q2 Predictions Max         -6.64212
trainer/Q2 Predictions Min       -133.789
trainer/Q Targets Mean            -39.9505
trainer/Q Targets Std              40.6277
trainer/Q Targets Max              -6.73946
trainer/Q Targets Min            -134.744
trainer/Log Pis Mean                1.98255
trainer/Log Pis Std                 1.3618
trainer/Log Pis Max                 9.83397
trainer/Log Pis Min                -2.46031
trainer/Policy mu Mean             -0.0393851
trainer/Policy mu Std               0.5778
trainer/Policy mu Max               2.85685
trainer/Policy mu Min              -3.60904
trainer/Policy log std Mean        -2.20979
trainer/Policy log std Std          0.429986
trainer/Policy log std Max         -0.273116
trainer/Policy log std Min         -2.88437
trainer/Alpha                       0.0687104
trainer/Alpha Loss                 -0.0467421
exploration/num steps total    223200
exploration/num paths total      2232
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.617071
exploration/Rewards Std             0.981033
exploration/Rewards Max            -0.00571698
exploration/Rewards Min            -7.57036
exploration/Returns Mean          -61.7071
exploration/Returns Std            57.2011
exploration/Returns Max           -16.5161
exploration/Returns Min          -174.588
exploration/Actions Mean            0.0158427
exploration/Actions Std             0.232573
exploration/Actions Max             0.996745
exploration/Actions Min            -0.999408
exploration/Num Paths               5
exploration/Average Returns       -61.7071
evaluation/num steps total     669000
evaluation/num paths total       6690
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.610628
evaluation/Rewards Std              1.14342
evaluation/Rewards Max             -0.0031137
evaluation/Rewards Min             -9.73872
evaluation/Returns Mean           -61.0628
evaluation/Returns Std             69.2999
evaluation/Returns Max             -4.62052
evaluation/Returns Min           -273.408
evaluation/Actions Mean             0.0100527
evaluation/Actions Std              0.179291
evaluation/Actions Max              0.998379
evaluation/Actions Min             -0.996753
evaluation/Num Paths               15
evaluation/Average Returns        -61.0628
time/data storing (s)               0.0026374
time/evaluation sampling (s)        0.328037
time/exploration sampling (s)       0.138837
time/logging (s)                    0.00353323
time/saving (s)                     0.0015582
time/training (s)                   1.97124
time/epoch (s)                      2.44585
time/total (s)                   1095.08
Epoch                             445
-----------------------------  ---------------
2019-04-23 01:31:49.793307 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 446 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.66548
trainer/QF2 Loss                    0.715264
trainer/Policy Loss                43.6969
trainer/Q1 Predictions Mean       -41.4949
trainer/Q1 Predictions Std         40.976
trainer/Q1 Predictions Max         -6.61923
trainer/Q1 Predictions Min       -147.324
trainer/Q2 Predictions Mean       -41.4738
trainer/Q2 Predictions Std         40.9371
trainer/Q2 Predictions Max         -6.63355
trainer/Q2 Predictions Min       -146.855
trainer/Q Targets Mean            -41.552
trainer/Q Targets Std              41.1525
trainer/Q Targets Max              -0.137113
trainer/Q Targets Min            -145.62
trainer/Log Pis Mean                2.255
trainer/Log Pis Std                 1.51186
trainer/Log Pis Max                 9.86313
trainer/Log Pis Min                -2.58217
trainer/Policy mu Mean             -0.0512368
trainer/Policy mu Std               0.70778
trainer/Policy mu Max               2.61033
trainer/Policy mu Min              -3.51026
trainer/Policy log std Mean        -2.16377
trainer/Policy log std Std          0.481043
trainer/Policy log std Max         -0.510786
trainer/Policy log std Min         -2.97125
trainer/Alpha                       0.0691641
trainer/Alpha Loss                  0.681154
exploration/num steps total    223700
exploration/num paths total      2237
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.730846
exploration/Rewards Std             1.07568
exploration/Rewards Max            -0.00595892
exploration/Rewards Min            -8.80059
exploration/Returns Mean          -73.0846
exploration/Returns Std            58.7675
exploration/Returns Max           -17.9136
exploration/Returns Min          -182.012
exploration/Actions Mean            0.00468104
exploration/Actions Std             0.21374
exploration/Actions Max             0.998953
exploration/Actions Min            -0.995383
exploration/Num Paths               5
exploration/Average Returns       -73.0846
evaluation/num steps total     670500
evaluation/num paths total       6705
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.73151
evaluation/Rewards Std              1.07214
evaluation/Rewards Max             -0.0147669
evaluation/Rewards Min            -10.3015
evaluation/Returns Mean           -73.151
evaluation/Returns Std             52.8197
evaluation/Returns Max            -12.2779
evaluation/Returns Min           -182.211
evaluation/Actions Mean            -0.0033006
evaluation/Actions Std              0.184282
evaluation/Actions Max              0.999172
evaluation/Actions Min             -0.998797
evaluation/Num Paths               15
evaluation/Average Returns        -73.151
time/data storing (s)               0.00272803
time/evaluation sampling (s)        0.328275
time/exploration sampling (s)       0.140099
time/logging (s)                    0.00482264
time/saving (s)                     0.00195068
time/training (s)                   1.97814
time/epoch (s)                      2.45602
time/total (s)                   1097.54
Epoch                             446
-----------------------------  ---------------
2019-04-23 01:31:52.270697 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 447 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                   21.3351
trainer/QF2 Loss                   21.2934
trainer/Policy Loss                42.0863
trainer/Q1 Predictions Mean       -40.2086
trainer/Q1 Predictions Std         37.4492
trainer/Q1 Predictions Max         -6.52335
trainer/Q1 Predictions Min       -133.188
trainer/Q2 Predictions Mean       -40.1731
trainer/Q2 Predictions Std         37.4294
trainer/Q2 Predictions Max         -6.57294
trainer/Q2 Predictions Min       -133.067
trainer/Q Targets Mean            -40.1026
trainer/Q Targets Std              38.0756
trainer/Q Targets Max              -0.168186
trainer/Q Targets Min            -134.705
trainer/Log Pis Mean                1.93389
trainer/Log Pis Std                 1.36589
trainer/Log Pis Max                 7.38041
trainer/Log Pis Min                -2.47897
trainer/Policy mu Mean             -0.0266283
trainer/Policy mu Std               0.524412
trainer/Policy mu Max               2.47785
trainer/Policy mu Min              -3.29284
trainer/Policy log std Mean        -2.26068
trainer/Policy log std Std          0.427711
trainer/Policy log std Max         -0.471558
trainer/Policy log std Min         -3.07478
trainer/Alpha                       0.06483
trainer/Alpha Loss                 -0.180862
exploration/num steps total    224200
exploration/num paths total      2242
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.478429
exploration/Rewards Std             0.931738
exploration/Rewards Max            -0.00320283
exploration/Rewards Min            -9.13278
exploration/Returns Mean          -47.8429
exploration/Returns Std            29.2032
exploration/Returns Max           -16.1316
exploration/Returns Min           -98.0846
exploration/Actions Mean           -0.000683725
exploration/Actions Std             0.218327
exploration/Actions Max             0.996862
exploration/Actions Min            -0.998232
exploration/Num Paths               5
exploration/Average Returns       -47.8429
evaluation/num steps total     672000
evaluation/num paths total       6720
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.545609
evaluation/Rewards Std              1.00189
evaluation/Rewards Max             -0.0230474
evaluation/Rewards Min            -10.9102
evaluation/Returns Mean           -54.5609
evaluation/Returns Std             46.4299
evaluation/Returns Max             -9.87941
evaluation/Returns Min           -174.465
evaluation/Actions Mean             0.0167125
evaluation/Actions Std              0.180584
evaluation/Actions Max              0.998598
evaluation/Actions Min             -0.998962
evaluation/Num Paths               15
evaluation/Average Returns        -54.5609
time/data storing (s)               0.00302333
time/evaluation sampling (s)        0.332138
time/exploration sampling (s)       0.151629
time/logging (s)                    0.00371055
time/saving (s)                     0.00193337
time/training (s)                   1.97293
time/epoch (s)                      2.46537
time/total (s)                   1100.01
Epoch                             447
-----------------------------  ----------------
2019-04-23 01:31:54.726657 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 448 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.133436
trainer/QF2 Loss                    0.16845
trainer/Policy Loss                36.0163
trainer/Q1 Predictions Mean       -34.1054
trainer/Q1 Predictions Std         36.2355
trainer/Q1 Predictions Max         -6.75569
trainer/Q1 Predictions Min       -134.195
trainer/Q2 Predictions Mean       -34.1523
trainer/Q2 Predictions Std         36.1958
trainer/Q2 Predictions Max         -6.77799
trainer/Q2 Predictions Min       -134.045
trainer/Q Targets Mean            -34.2845
trainer/Q Targets Std              36.3552
trainer/Q Targets Max              -6.65841
trainer/Q Targets Min            -134.177
trainer/Log Pis Mean                1.94101
trainer/Log Pis Std                 1.12697
trainer/Log Pis Max                 5.05784
trainer/Log Pis Min                -2.75179
trainer/Policy mu Mean             -0.00142038
trainer/Policy mu Std               0.367215
trainer/Policy mu Max               2.75918
trainer/Policy mu Min              -1.64505
trainer/Policy log std Mean        -2.25055
trainer/Policy log std Std          0.353585
trainer/Policy log std Max         -0.603508
trainer/Policy log std Min         -3.03939
trainer/Alpha                       0.0660875
trainer/Alpha Loss                 -0.16026
exploration/num steps total    224700
exploration/num paths total      2247
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.581043
exploration/Rewards Std             0.788198
exploration/Rewards Max            -0.0207194
exploration/Rewards Min            -7.94283
exploration/Returns Mean          -58.1043
exploration/Returns Std            43.053
exploration/Returns Max           -16.8483
exploration/Returns Min          -136.787
exploration/Actions Mean            0.00802856
exploration/Actions Std             0.197153
exploration/Actions Max             0.998147
exploration/Actions Min            -0.99381
exploration/Num Paths               5
exploration/Average Returns       -58.1043
evaluation/num steps total     673500
evaluation/num paths total       6735
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.01434
evaluation/Rewards Std              1.34699
evaluation/Rewards Max             -0.0532629
evaluation/Rewards Min            -12.1915
evaluation/Returns Mean          -101.434
evaluation/Returns Std             83.2318
evaluation/Returns Max            -13.6582
evaluation/Returns Min           -292.118
evaluation/Actions Mean             0.00306108
evaluation/Actions Std              0.206973
evaluation/Actions Max              0.999444
evaluation/Actions Min             -0.999762
evaluation/Num Paths               15
evaluation/Average Returns       -101.434
time/data storing (s)               0.00271761
time/evaluation sampling (s)        0.329722
time/exploration sampling (s)       0.136849
time/logging (s)                    0.0047938
time/saving (s)                     0.0019283
time/training (s)                   1.97066
time/epoch (s)                      2.44667
time/total (s)                   1102.46
Epoch                             448
-----------------------------  ---------------
2019-04-23 01:31:57.208903 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 449 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.98922
trainer/QF2 Loss                    1.03917
trainer/Policy Loss                40.7065
trainer/Q1 Predictions Mean       -38.834
trainer/Q1 Predictions Std         37.5673
trainer/Q1 Predictions Max         -6.6274
trainer/Q1 Predictions Min       -131.247
trainer/Q2 Predictions Mean       -38.795
trainer/Q2 Predictions Std         37.5499
trainer/Q2 Predictions Max         -6.64802
trainer/Q2 Predictions Min       -131.029
trainer/Q Targets Mean            -39.388
trainer/Q Targets Std              38.2167
trainer/Q Targets Max              -6.54968
trainer/Q Targets Min            -133.698
trainer/Log Pis Mean                1.95631
trainer/Log Pis Std                 1.26113
trainer/Log Pis Max                 7.08671
trainer/Log Pis Min                -2.4951
trainer/Policy mu Mean             -0.0522695
trainer/Policy mu Std               0.479623
trainer/Policy mu Max               2.43894
trainer/Policy mu Min              -3.05667
trainer/Policy log std Mean        -2.26279
trainer/Policy log std Std          0.396923
trainer/Policy log std Max         -0.261864
trainer/Policy log std Min         -2.99503
trainer/Alpha                       0.0681681
trainer/Alpha Loss                 -0.117333
exploration/num steps total    225200
exploration/num paths total      2252
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.660061
exploration/Rewards Std             0.887544
exploration/Rewards Max            -0.00769146
exploration/Rewards Min            -7.6526
exploration/Returns Mean          -66.0061
exploration/Returns Std            54.935
exploration/Returns Max           -16.6982
exploration/Returns Min          -149.88
exploration/Actions Mean            0.00680225
exploration/Actions Std             0.205544
exploration/Actions Max             0.999047
exploration/Actions Min            -0.99891
exploration/Num Paths               5
exploration/Average Returns       -66.0061
evaluation/num steps total     675000
evaluation/num paths total       6750
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.769372
evaluation/Rewards Std              0.958874
evaluation/Rewards Max             -0.0139882
evaluation/Rewards Min             -9.48123
evaluation/Returns Mean           -76.9372
evaluation/Returns Std             67.4618
evaluation/Returns Max             -8.18898
evaluation/Returns Min           -281.81
evaluation/Actions Mean             0.0133517
evaluation/Actions Std              0.159493
evaluation/Actions Max              0.999266
evaluation/Actions Min             -0.995326
evaluation/Num Paths               15
evaluation/Average Returns        -76.9372
time/data storing (s)               0.00280052
time/evaluation sampling (s)        0.33365
time/exploration sampling (s)       0.142828
time/logging (s)                    0.00477375
time/saving (s)                     0.00191574
time/training (s)                   1.98537
time/epoch (s)                      2.47134
time/total (s)                   1104.94
Epoch                             449
-----------------------------  ---------------
2019-04-23 01:31:59.745076 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 450 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                  167.762
trainer/QF2 Loss                  168.223
trainer/Policy Loss                41.9151
trainer/Q1 Predictions Mean       -39.9243
trainer/Q1 Predictions Std         44.5879
trainer/Q1 Predictions Max         -6.4422
trainer/Q1 Predictions Min       -151.53
trainer/Q2 Predictions Mean       -39.9721
trainer/Q2 Predictions Std         44.6207
trainer/Q2 Predictions Max         -6.43083
trainer/Q2 Predictions Min       -153.075
trainer/Q Targets Mean            -38.9368
trainer/Q Targets Std              44.139
trainer/Q Targets Max              -0.155988
trainer/Q Targets Min            -155.616
trainer/Log Pis Mean                2.03852
trainer/Log Pis Std                 1.33664
trainer/Log Pis Max                 8.2703
trainer/Log Pis Min                -1.71704
trainer/Policy mu Mean             -0.07975
trainer/Policy mu Std               0.650811
trainer/Policy mu Max               2.96098
trainer/Policy mu Min              -2.80791
trainer/Policy log std Mean        -2.15576
trainer/Policy log std Std          0.479943
trainer/Policy log std Max         -0.391484
trainer/Policy log std Min         -2.94122
trainer/Alpha                       0.0691772
trainer/Alpha Loss                  0.102891
exploration/num steps total    225700
exploration/num paths total      2257
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.621228
exploration/Rewards Std             0.860712
exploration/Rewards Max            -0.00620475
exploration/Rewards Min            -8.98806
exploration/Returns Mean          -62.1228
exploration/Returns Std            53.6992
exploration/Returns Max           -12.5095
exploration/Returns Min          -140.781
exploration/Actions Mean           -0.00392473
exploration/Actions Std             0.177107
exploration/Actions Max             0.998578
exploration/Actions Min            -0.991412
exploration/Num Paths               5
exploration/Average Returns       -62.1228
evaluation/num steps total     676500
evaluation/num paths total       6765
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.744832
evaluation/Rewards Std              1.11588
evaluation/Rewards Max             -0.0254942
evaluation/Rewards Min             -8.80036
evaluation/Returns Mean           -74.4832
evaluation/Returns Std             65.6023
evaluation/Returns Max            -11.5171
evaluation/Returns Min           -260.673
evaluation/Actions Mean            -0.0112469
evaluation/Actions Std              0.18862
evaluation/Actions Max              0.998442
evaluation/Actions Min             -0.998864
evaluation/Num Paths               15
evaluation/Average Returns        -74.4832
time/data storing (s)               0.00276575
time/evaluation sampling (s)        0.327059
time/exploration sampling (s)       0.138679
time/logging (s)                    0.00478738
time/saving (s)                     0.00168817
time/training (s)                   2.05022
time/epoch (s)                      2.5252
time/total (s)                   1107.47
Epoch                             450
-----------------------------  ---------------
2019-04-23 01:32:02.207534 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 451 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    2.14613
trainer/QF2 Loss                    2.12268
trainer/Policy Loss                37.923
trainer/Q1 Predictions Mean       -36.0405
trainer/Q1 Predictions Std         37.7813
trainer/Q1 Predictions Max         -6.54723
trainer/Q1 Predictions Min       -132.622
trainer/Q2 Predictions Mean       -36.0113
trainer/Q2 Predictions Std         37.778
trainer/Q2 Predictions Max         -6.59019
trainer/Q2 Predictions Min       -132.197
trainer/Q Targets Mean            -36.5896
trainer/Q Targets Std              38.6674
trainer/Q Targets Max              -0.0715623
trainer/Q Targets Min            -134.268
trainer/Log Pis Mean                1.94031
trainer/Log Pis Std                 1.16977
trainer/Log Pis Max                 6.02426
trainer/Log Pis Min                -1.58964
trainer/Policy mu Mean              0.0228224
trainer/Policy mu Std               0.482187
trainer/Policy mu Max               2.46004
trainer/Policy mu Min              -2.55833
trainer/Policy log std Mean        -2.25606
trainer/Policy log std Std          0.437853
trainer/Policy log std Max         -0.550558
trainer/Policy log std Min         -3.20648
trainer/Alpha                       0.0676468
trainer/Alpha Loss                 -0.16078
exploration/num steps total    226200
exploration/num paths total      2262
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.08989
exploration/Rewards Std             1.22481
exploration/Rewards Max            -0.00616953
exploration/Rewards Min            -9.11939
exploration/Returns Mean         -108.989
exploration/Returns Std            73.8219
exploration/Returns Max           -35.6314
exploration/Returns Min          -206.607
exploration/Actions Mean           -0.0261523
exploration/Actions Std             0.226778
exploration/Actions Max             0.974919
exploration/Actions Min            -0.998814
exploration/Num Paths               5
exploration/Average Returns      -108.989
evaluation/num steps total     678000
evaluation/num paths total       6780
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.882902
evaluation/Rewards Std              0.883381
evaluation/Rewards Max             -0.0131139
evaluation/Rewards Min             -8.67055
evaluation/Returns Mean           -88.2902
evaluation/Returns Std             66.942
evaluation/Returns Max             -6.16692
evaluation/Returns Min           -264.746
evaluation/Actions Mean            -0.0152585
evaluation/Actions Std              0.152806
evaluation/Actions Max              0.997999
evaluation/Actions Min             -0.99733
evaluation/Num Paths               15
evaluation/Average Returns        -88.2902
time/data storing (s)               0.0027324
time/evaluation sampling (s)        0.335101
time/exploration sampling (s)       0.137752
time/logging (s)                    0.00477845
time/saving (s)                     0.00194766
time/training (s)                   1.9692
time/epoch (s)                      2.45151
time/total (s)                   1109.92
Epoch                             451
-----------------------------  ---------------
2019-04-23 01:32:04.721124 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 452 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.69639
trainer/QF2 Loss                    0.661222
trainer/Policy Loss                39.7532
trainer/Q1 Predictions Mean       -37.9088
trainer/Q1 Predictions Std         38.6853
trainer/Q1 Predictions Max         -6.52903
trainer/Q1 Predictions Min       -134.348
trainer/Q2 Predictions Mean       -37.8832
trainer/Q2 Predictions Std         38.6527
trainer/Q2 Predictions Max         -6.57196
trainer/Q2 Predictions Min       -134.379
trainer/Q Targets Mean            -37.8512
trainer/Q Targets Std              38.7382
trainer/Q Targets Max              -0.144479
trainer/Q Targets Min            -133.868
trainer/Log Pis Mean                1.99874
trainer/Log Pis Std                 1.05083
trainer/Log Pis Max                 5.03365
trainer/Log Pis Min                -1.54079
trainer/Policy mu Mean             -0.0540833
trainer/Policy mu Std               0.416885
trainer/Policy mu Max               2.52538
trainer/Policy mu Min              -3.69022
trainer/Policy log std Mean        -2.31671
trainer/Policy log std Std          0.350282
trainer/Policy log std Max         -0.493639
trainer/Policy log std Min         -2.9963
trainer/Alpha                       0.0673364
trainer/Alpha Loss                 -0.00339681
exploration/num steps total    226700
exploration/num paths total      2267
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.609442
exploration/Rewards Std             0.897579
exploration/Rewards Max            -0.00374473
exploration/Rewards Min            -8.65174
exploration/Returns Mean          -60.9442
exploration/Returns Std            40.5585
exploration/Returns Max           -12.6149
exploration/Returns Min          -123.646
exploration/Actions Mean           -0.00747827
exploration/Actions Std             0.191394
exploration/Actions Max             0.994341
exploration/Actions Min            -0.99855
exploration/Num Paths               5
exploration/Average Returns       -60.9442
evaluation/num steps total     679500
evaluation/num paths total       6795
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.384862
evaluation/Rewards Std              0.923073
evaluation/Rewards Max             -0.00442118
evaluation/Rewards Min             -9.64321
evaluation/Returns Mean           -38.4862
evaluation/Returns Std             25.6513
evaluation/Returns Max            -10.9975
evaluation/Returns Min            -99.4966
evaluation/Actions Mean            -0.00426402
evaluation/Actions Std              0.184527
evaluation/Actions Max              0.99803
evaluation/Actions Min             -0.997424
evaluation/Num Paths               15
evaluation/Average Returns        -38.4862
time/data storing (s)               0.0026937
time/evaluation sampling (s)        0.329409
time/exploration sampling (s)       0.137841
time/logging (s)                    0.004816
time/saving (s)                     0.00153715
time/training (s)                   2.02646
time/epoch (s)                      2.50275
time/total (s)                   1112.43
Epoch                             452
-----------------------------  ---------------
2019-04-23 01:32:07.188081 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 453 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   85.1002
trainer/QF2 Loss                   85.0552
trainer/Policy Loss                43.4789
trainer/Q1 Predictions Mean       -41.6966
trainer/Q1 Predictions Std         39.2061
trainer/Q1 Predictions Max         -6.62363
trainer/Q1 Predictions Min       -133.632
trainer/Q2 Predictions Mean       -41.715
trainer/Q2 Predictions Std         39.2071
trainer/Q2 Predictions Max         -6.61367
trainer/Q2 Predictions Min       -133.095
trainer/Q Targets Mean            -41.4065
trainer/Q Targets Std              39.8053
trainer/Q Targets Max              -1.72188
trainer/Q Targets Min            -135.997
trainer/Log Pis Mean                1.82383
trainer/Log Pis Std                 1.40441
trainer/Log Pis Max                 4.17339
trainer/Log Pis Min                -4.14104
trainer/Policy mu Mean             -0.0748504
trainer/Policy mu Std               0.454525
trainer/Policy mu Max               2.64778
trainer/Policy mu Min              -2.91771
trainer/Policy log std Mean        -2.2508
trainer/Policy log std Std          0.370953
trainer/Policy log std Max         -0.234867
trainer/Policy log std Min         -3.15387
trainer/Alpha                       0.0672689
trainer/Alpha Loss                 -0.475474
exploration/num steps total    227200
exploration/num paths total      2272
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.10092
exploration/Rewards Std             0.984218
exploration/Rewards Max            -0.0224031
exploration/Rewards Min            -5.18814
exploration/Returns Mean         -110.092
exploration/Returns Std            87.8635
exploration/Returns Max           -17.3881
exploration/Returns Min          -276.952
exploration/Actions Mean           -0.00595397
exploration/Actions Std             0.191222
exploration/Actions Max             0.970713
exploration/Actions Min            -0.998108
exploration/Num Paths               5
exploration/Average Returns      -110.092
evaluation/num steps total     681000
evaluation/num paths total       6810
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.751736
evaluation/Rewards Std              1.12742
evaluation/Rewards Max             -0.0167533
evaluation/Rewards Min            -10.6917
evaluation/Returns Mean           -75.1736
evaluation/Returns Std             50.256
evaluation/Returns Max            -19.5618
evaluation/Returns Min           -177.511
evaluation/Actions Mean            -0.00375058
evaluation/Actions Std              0.187817
evaluation/Actions Max              0.999444
evaluation/Actions Min             -0.999147
evaluation/Num Paths               15
evaluation/Average Returns        -75.1736
time/data storing (s)               0.00263038
time/evaluation sampling (s)        0.324888
time/exploration sampling (s)       0.14598
time/logging (s)                    0.00476402
time/saving (s)                     0.00191852
time/training (s)                   1.97581
time/epoch (s)                      2.45599
time/total (s)                   1114.89
Epoch                             453
-----------------------------  ---------------
2019-04-23 01:32:09.661410 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 454 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   63.6833
trainer/QF2 Loss                   63.7093
trainer/Policy Loss                43.7463
trainer/Q1 Predictions Mean       -41.6488
trainer/Q1 Predictions Std         39.2503
trainer/Q1 Predictions Max         -6.60323
trainer/Q1 Predictions Min       -135.73
trainer/Q2 Predictions Mean       -41.6641
trainer/Q2 Predictions Std         39.2293
trainer/Q2 Predictions Max         -6.54123
trainer/Q2 Predictions Min       -135.467
trainer/Q Targets Mean            -40.7081
trainer/Q Targets Std              39.6013
trainer/Q Targets Max              -0.183163
trainer/Q Targets Min            -135.54
trainer/Log Pis Mean                2.18434
trainer/Log Pis Std                 1.09221
trainer/Log Pis Max                 5.18752
trainer/Log Pis Min                -0.855212
trainer/Policy mu Mean              0.04317
trainer/Policy mu Std               0.662936
trainer/Policy mu Max               3.24606
trainer/Policy mu Min              -3.02227
trainer/Policy log std Mean        -2.16494
trainer/Policy log std Std          0.476005
trainer/Policy log std Max         -0.543074
trainer/Policy log std Min         -3.17998
trainer/Alpha                       0.06456
trainer/Alpha Loss                  0.505139
exploration/num steps total    227700
exploration/num paths total      2277
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.30353
exploration/Rewards Std             1.16776
exploration/Rewards Max            -0.00442184
exploration/Rewards Min           -11.0818
exploration/Returns Mean         -130.353
exploration/Returns Std            52.0826
exploration/Returns Max           -47.9747
exploration/Returns Min          -189.722
exploration/Actions Mean           -0.00255333
exploration/Actions Std             0.217686
exploration/Actions Max             0.999317
exploration/Actions Min            -0.998276
exploration/Num Paths               5
exploration/Average Returns      -130.353
evaluation/num steps total     682500
evaluation/num paths total       6825
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.629427
evaluation/Rewards Std              0.960181
evaluation/Rewards Max             -0.022249
evaluation/Rewards Min             -9.87573
evaluation/Returns Mean           -62.9427
evaluation/Returns Std             47.5305
evaluation/Returns Max             -5.89456
evaluation/Returns Min           -166.677
evaluation/Actions Mean            -0.00539231
evaluation/Actions Std              0.165992
evaluation/Actions Max              0.998298
evaluation/Actions Min             -0.997016
evaluation/Num Paths               15
evaluation/Average Returns        -62.9427
time/data storing (s)               0.002781
time/evaluation sampling (s)        0.329427
time/exploration sampling (s)       0.135554
time/logging (s)                    0.00477844
time/saving (s)                     0.00193036
time/training (s)                   1.98794
time/epoch (s)                      2.46241
time/total (s)                   1117.36
Epoch                             454
-----------------------------  ---------------
2019-04-23 01:32:12.116107 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 455 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   61.561
trainer/QF2 Loss                   61.498
trainer/Policy Loss                34.4176
trainer/Q1 Predictions Mean       -32.2259
trainer/Q1 Predictions Std         33.348
trainer/Q1 Predictions Max         -6.6899
trainer/Q1 Predictions Min       -132.482
trainer/Q2 Predictions Mean       -32.2095
trainer/Q2 Predictions Std         33.3682
trainer/Q2 Predictions Max         -6.63626
trainer/Q2 Predictions Min       -132.448
trainer/Q Targets Mean            -31.645
trainer/Q Targets Std              33.3472
trainer/Q Targets Max              -0.873747
trainer/Q Targets Min            -133.442
trainer/Log Pis Mean                2.24642
trainer/Log Pis Std                 1.32133
trainer/Log Pis Max                 9.53319
trainer/Log Pis Min                -1.58798
trainer/Policy mu Mean              0.0242388
trainer/Policy mu Std               0.565438
trainer/Policy mu Max               3.50617
trainer/Policy mu Min              -2.91457
trainer/Policy log std Mean        -2.25935
trainer/Policy log std Std          0.421877
trainer/Policy log std Max         -0.17075
trainer/Policy log std Min         -2.93871
trainer/Alpha                       0.0647991
trainer/Alpha Loss                  0.674359
exploration/num steps total    228200
exploration/num paths total      2282
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.325606
exploration/Rewards Std             0.880608
exploration/Rewards Max            -0.00965543
exploration/Rewards Min            -7.54422
exploration/Returns Mean          -32.5606
exploration/Returns Std             9.90388
exploration/Returns Max           -16.435
exploration/Returns Min           -46.5083
exploration/Actions Mean            0.0374705
exploration/Actions Std             0.216533
exploration/Actions Max             0.999319
exploration/Actions Min            -0.571634
exploration/Num Paths               5
exploration/Average Returns       -32.5606
evaluation/num steps total     684000
evaluation/num paths total       6840
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.938267
evaluation/Rewards Std              1.23438
evaluation/Rewards Max             -0.0317417
evaluation/Rewards Min             -9.93278
evaluation/Returns Mean           -93.8267
evaluation/Returns Std             80.8326
evaluation/Returns Max             -8.94248
evaluation/Returns Min           -284.57
evaluation/Actions Mean            -0.00767351
evaluation/Actions Std              0.188394
evaluation/Actions Max              0.997141
evaluation/Actions Min             -0.999182
evaluation/Num Paths               15
evaluation/Average Returns        -93.8267
time/data storing (s)               0.0036656
time/evaluation sampling (s)        0.326448
time/exploration sampling (s)       0.139827
time/logging (s)                    0.00489332
time/saving (s)                     0.00939749
time/training (s)                   1.95956
time/epoch (s)                      2.44379
time/total (s)                   1119.81
Epoch                             455
-----------------------------  ---------------
2019-04-23 01:32:14.587914 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 456 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.60798
trainer/QF2 Loss                    1.72311
trainer/Policy Loss                39.9484
trainer/Q1 Predictions Mean       -38.2037
trainer/Q1 Predictions Std         40.5673
trainer/Q1 Predictions Max         -6.58498
trainer/Q1 Predictions Min       -137.863
trainer/Q2 Predictions Mean       -38.1846
trainer/Q2 Predictions Std         40.5461
trainer/Q2 Predictions Max         -6.615
trainer/Q2 Predictions Min       -137.017
trainer/Q Targets Mean            -38.582
trainer/Q Targets Std              41.2652
trainer/Q Targets Max              -0.302107
trainer/Q Targets Min            -139.094
trainer/Log Pis Mean                1.78114
trainer/Log Pis Std                 1.41388
trainer/Log Pis Max                 7.56509
trainer/Log Pis Min                -4.99785
trainer/Policy mu Mean             -0.0455642
trainer/Policy mu Std               0.391749
trainer/Policy mu Max               3.21782
trainer/Policy mu Min              -2.94623
trainer/Policy log std Mean        -2.256
trainer/Policy log std Std          0.360947
trainer/Policy log std Max         -0.295206
trainer/Policy log std Min         -3.07202
trainer/Alpha                       0.0646967
trainer/Alpha Loss                 -0.599225
exploration/num steps total    228700
exploration/num paths total      2287
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.635702
exploration/Rewards Std             0.88932
exploration/Rewards Max            -0.0187444
exploration/Rewards Min            -8.18017
exploration/Returns Mean          -63.5702
exploration/Returns Std            51.5256
exploration/Returns Max           -12.9074
exploration/Returns Min          -142.62
exploration/Actions Mean           -0.00782801
exploration/Actions Std             0.20503
exploration/Actions Max             0.999368
exploration/Actions Min            -0.999205
exploration/Num Paths               5
exploration/Average Returns       -63.5702
evaluation/num steps total     685500
evaluation/num paths total       6855
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.835169
evaluation/Rewards Std              1.09452
evaluation/Rewards Max             -0.0213128
evaluation/Rewards Min            -11.2126
evaluation/Returns Mean           -83.5169
evaluation/Returns Std             49.0817
evaluation/Returns Max            -13.1291
evaluation/Returns Min           -143.034
evaluation/Actions Mean            -0.00293544
evaluation/Actions Std              0.194841
evaluation/Actions Max              0.998897
evaluation/Actions Min             -0.999707
evaluation/Num Paths               15
evaluation/Average Returns        -83.5169
time/data storing (s)               0.00278555
time/evaluation sampling (s)        0.320663
time/exploration sampling (s)       0.139869
time/logging (s)                    0.0048074
time/saving (s)                     0.0019507
time/training (s)                   1.99065
time/epoch (s)                      2.46072
time/total (s)                   1122.27
Epoch                             456
-----------------------------  ---------------
2019-04-23 01:32:17.082778 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 457 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    2.07286
trainer/QF2 Loss                    2.13297
trainer/Policy Loss                43.4273
trainer/Q1 Predictions Mean       -41.5781
trainer/Q1 Predictions Std         39.5855
trainer/Q1 Predictions Max         -6.56595
trainer/Q1 Predictions Min       -133.75
trainer/Q2 Predictions Mean       -41.5241
trainer/Q2 Predictions Std         39.5776
trainer/Q2 Predictions Max         -6.58836
trainer/Q2 Predictions Min       -133.715
trainer/Q Targets Mean            -42.0445
trainer/Q Targets Std              40.4157
trainer/Q Targets Max              -0.0469399
trainer/Q Targets Min            -136.316
trainer/Log Pis Mean                1.94126
trainer/Log Pis Std                 1.19025
trainer/Log Pis Max                 6.5987
trainer/Log Pis Min                -2.20135
trainer/Policy mu Mean             -0.0204736
trainer/Policy mu Std               0.467011
trainer/Policy mu Max               3.02848
trainer/Policy mu Min              -2.61301
trainer/Policy log std Mean        -2.24953
trainer/Policy log std Std          0.381592
trainer/Policy log std Max         -0.596482
trainer/Policy log std Min         -3.06966
trainer/Alpha                       0.0669043
trainer/Alpha Loss                 -0.158861
exploration/num steps total    229200
exploration/num paths total      2292
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.758003
exploration/Rewards Std             1.1868
exploration/Rewards Max            -0.0234332
exploration/Rewards Min           -10.5771
exploration/Returns Mean          -75.8003
exploration/Returns Std            49.5335
exploration/Returns Max           -23.5234
exploration/Returns Min          -137.732
exploration/Actions Mean            0.0207389
exploration/Actions Std             0.233791
exploration/Actions Max             0.999101
exploration/Actions Min            -0.997517
exploration/Num Paths               5
exploration/Average Returns       -75.8003
evaluation/num steps total     687000
evaluation/num paths total       6870
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.745446
evaluation/Rewards Std              0.911871
evaluation/Rewards Max             -0.0588325
evaluation/Rewards Min             -9.67728
evaluation/Returns Mean           -74.5446
evaluation/Returns Std             50.1393
evaluation/Returns Max            -12.9119
evaluation/Returns Min           -162.526
evaluation/Actions Mean            -0.00631777
evaluation/Actions Std              0.171855
evaluation/Actions Max              0.995369
evaluation/Actions Min             -0.998239
evaluation/Num Paths               15
evaluation/Average Returns        -74.5446
time/data storing (s)               0.00273381
time/evaluation sampling (s)        0.330662
time/exploration sampling (s)       0.144389
time/logging (s)                    0.00406004
time/saving (s)                     0.00192782
time/training (s)                   1.99981
time/epoch (s)                      2.48358
time/total (s)                   1124.76
Epoch                             457
-----------------------------  ---------------
2019-04-23 01:32:19.562634 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 458 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.268928
trainer/QF2 Loss                    0.421442
trainer/Policy Loss                48.4039
trainer/Q1 Predictions Mean       -46.2023
trainer/Q1 Predictions Std         43.0346
trainer/Q1 Predictions Max         -6.61909
trainer/Q1 Predictions Min       -142.413
trainer/Q2 Predictions Mean       -46.1701
trainer/Q2 Predictions Std         43.0288
trainer/Q2 Predictions Max         -6.66307
trainer/Q2 Predictions Min       -142.251
trainer/Q Targets Mean            -46.1001
trainer/Q Targets Std              42.9186
trainer/Q Targets Max              -6.73054
trainer/Q Targets Min            -142.635
trainer/Log Pis Mean                2.26887
trainer/Log Pis Std                 1.39283
trainer/Log Pis Max                11.2086
trainer/Log Pis Min                -1.70581
trainer/Policy mu Mean              0.0191798
trainer/Policy mu Std               0.70125
trainer/Policy mu Max               4.01374
trainer/Policy mu Min              -2.45605
trainer/Policy log std Mean        -2.16546
trainer/Policy log std Std          0.502141
trainer/Policy log std Max         -0.235096
trainer/Policy log std Min         -2.96944
trainer/Alpha                       0.0611282
trainer/Alpha Loss                  0.751421
exploration/num steps total    229700
exploration/num paths total      2297
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.29193
exploration/Rewards Std             1.55992
exploration/Rewards Max            -0.00320288
exploration/Rewards Min            -9.05504
exploration/Returns Mean         -129.193
exploration/Returns Std           128.533
exploration/Returns Max           -17.6687
exploration/Returns Min          -354.288
exploration/Actions Mean            0.00201462
exploration/Actions Std             0.218963
exploration/Actions Max             0.999136
exploration/Actions Min            -0.994762
exploration/Num Paths               5
exploration/Average Returns      -129.193
evaluation/num steps total     688500
evaluation/num paths total       6885
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.652317
evaluation/Rewards Std              1.17517
evaluation/Rewards Max             -0.0134656
evaluation/Rewards Min            -10.2058
evaluation/Returns Mean           -65.2317
evaluation/Returns Std             65.6181
evaluation/Returns Max             -3.8148
evaluation/Returns Min           -197.66
evaluation/Actions Mean            -0.00655276
evaluation/Actions Std              0.184383
evaluation/Actions Max              0.99902
evaluation/Actions Min             -0.999115
evaluation/Num Paths               15
evaluation/Average Returns        -65.2317
time/data storing (s)               0.00276681
time/evaluation sampling (s)        0.331765
time/exploration sampling (s)       0.138788
time/logging (s)                    0.00411279
time/saving (s)                     0.00193419
time/training (s)                   1.99066
time/epoch (s)                      2.47003
time/total (s)                   1127.23
Epoch                             458
-----------------------------  ---------------
2019-04-23 01:32:22.033138 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 459 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.406678
trainer/QF2 Loss                    0.403226
trainer/Policy Loss                37.9748
trainer/Q1 Predictions Mean       -36.089
trainer/Q1 Predictions Std         34.8359
trainer/Q1 Predictions Max         -6.73484
trainer/Q1 Predictions Min       -135.797
trainer/Q2 Predictions Mean       -36.1033
trainer/Q2 Predictions Std         34.8174
trainer/Q2 Predictions Max         -6.7608
trainer/Q2 Predictions Min       -135.78
trainer/Q Targets Mean            -36.4262
trainer/Q Targets Std              35.2059
trainer/Q Targets Max              -6.81655
trainer/Q Targets Min            -137.883
trainer/Log Pis Mean                1.95504
trainer/Log Pis Std                 1.33876
trainer/Log Pis Max                 6.04485
trainer/Log Pis Min                -4.0826
trainer/Policy mu Mean              0.0469786
trainer/Policy mu Std               0.455658
trainer/Policy mu Max               3.58526
trainer/Policy mu Min              -1.13601
trainer/Policy log std Mean        -2.21668
trainer/Policy log std Std          0.399544
trainer/Policy log std Max         -0.517062
trainer/Policy log std Min         -2.96205
trainer/Alpha                       0.0620667
trainer/Alpha Loss                 -0.124956
exploration/num steps total    230200
exploration/num paths total      2302
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.88911
exploration/Rewards Std             1.26184
exploration/Rewards Max            -0.00492381
exploration/Rewards Min            -9.96406
exploration/Returns Mean         -188.911
exploration/Returns Std            83.7716
exploration/Returns Max           -56.7918
exploration/Returns Min          -282.61
exploration/Actions Mean           -0.0150954
exploration/Actions Std             0.270432
exploration/Actions Max             0.9982
exploration/Actions Min            -0.998708
exploration/Num Paths               5
exploration/Average Returns      -188.911
evaluation/num steps total     690000
evaluation/num paths total       6900
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.26484
evaluation/Rewards Std              1.31377
evaluation/Rewards Max             -0.0361714
evaluation/Rewards Min            -10.2384
evaluation/Returns Mean          -126.484
evaluation/Returns Std             93.6311
evaluation/Returns Max            -11.2397
evaluation/Returns Min           -279.53
evaluation/Actions Mean            -0.00121215
evaluation/Actions Std              0.177732
evaluation/Actions Max              0.999261
evaluation/Actions Min             -0.999502
evaluation/Num Paths               15
evaluation/Average Returns       -126.484
time/data storing (s)               0.00288763
time/evaluation sampling (s)        0.328344
time/exploration sampling (s)       0.150007
time/logging (s)                    0.00473912
time/saving (s)                     0.00193797
time/training (s)                   1.97226
time/epoch (s)                      2.46018
time/total (s)                   1129.7
Epoch                             459
-----------------------------  ---------------
2019-04-23 01:32:24.489507 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 460 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   19.7634
trainer/QF2 Loss                   19.7961
trainer/Policy Loss                42.7792
trainer/Q1 Predictions Mean       -40.9037
trainer/Q1 Predictions Std         40.6163
trainer/Q1 Predictions Max         -6.78538
trainer/Q1 Predictions Min       -138.711
trainer/Q2 Predictions Mean       -40.9438
trainer/Q2 Predictions Std         40.5961
trainer/Q2 Predictions Max         -6.82465
trainer/Q2 Predictions Min       -138.696
trainer/Q Targets Mean            -40.4557
trainer/Q Targets Std              40.8094
trainer/Q Targets Max              -0.631725
trainer/Q Targets Min            -138.229
trainer/Log Pis Mean                1.90195
trainer/Log Pis Std                 1.19728
trainer/Log Pis Max                 5.44123
trainer/Log Pis Min                -0.901258
trainer/Policy mu Mean              0.0151377
trainer/Policy mu Std               0.537532
trainer/Policy mu Max               2.91963
trainer/Policy mu Min              -2.90586
trainer/Policy log std Mean        -2.20705
trainer/Policy log std Std          0.434642
trainer/Policy log std Max         -0.519837
trainer/Policy log std Min         -3.07742
trainer/Alpha                       0.0594136
trainer/Alpha Loss                 -0.276808
exploration/num steps total    230700
exploration/num paths total      2307
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.694339
exploration/Rewards Std             1.01194
exploration/Rewards Max            -0.00336612
exploration/Rewards Min            -8.32937
exploration/Returns Mean          -69.4339
exploration/Returns Std            53.2832
exploration/Returns Max           -18.2192
exploration/Returns Min          -161.225
exploration/Actions Mean            0.019602
exploration/Actions Std             0.209068
exploration/Actions Max             0.999735
exploration/Actions Min            -0.99196
exploration/Num Paths               5
exploration/Average Returns       -69.4339
evaluation/num steps total     691500
evaluation/num paths total       6915
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.669047
evaluation/Rewards Std              0.991466
evaluation/Rewards Max             -0.00943887
evaluation/Rewards Min             -8.72985
evaluation/Returns Mean           -66.9047
evaluation/Returns Std             54.2016
evaluation/Returns Max             -7.88699
evaluation/Returns Min           -200.658
evaluation/Actions Mean             0.0157247
evaluation/Actions Std              0.173308
evaluation/Actions Max              0.997668
evaluation/Actions Min             -0.989505
evaluation/Num Paths               15
evaluation/Average Returns        -66.9047
time/data storing (s)               0.00269282
time/evaluation sampling (s)        0.325418
time/exploration sampling (s)       0.140578
time/logging (s)                    0.0047195
time/saving (s)                     0.00194127
time/training (s)                   1.96989
time/epoch (s)                      2.44524
time/total (s)                   1132.15
Epoch                             460
-----------------------------  ---------------
2019-04-23 01:32:26.958886 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 461 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   19.1117
trainer/QF2 Loss                   19.1312
trainer/Policy Loss                39.2419
trainer/Q1 Predictions Mean       -37.3485
trainer/Q1 Predictions Std         37.3912
trainer/Q1 Predictions Max         -6.50901
trainer/Q1 Predictions Min       -138.892
trainer/Q2 Predictions Mean       -37.3597
trainer/Q2 Predictions Std         37.4246
trainer/Q2 Predictions Max         -6.52516
trainer/Q2 Predictions Min       -138.838
trainer/Q Targets Mean            -36.9173
trainer/Q Targets Std              37.6009
trainer/Q Targets Max              -0.984804
trainer/Q Targets Min            -139.042
trainer/Log Pis Mean                1.89938
trainer/Log Pis Std                 1.2961
trainer/Log Pis Max                 6.57412
trainer/Log Pis Min                -2.35906
trainer/Policy mu Mean             -0.0323565
trainer/Policy mu Std               0.508578
trainer/Policy mu Max               2.86639
trainer/Policy mu Min              -3.45336
trainer/Policy log std Mean        -2.23056
trainer/Policy log std Std          0.423821
trainer/Policy log std Max         -0.393186
trainer/Policy log std Min         -3.02228
trainer/Alpha                       0.0581384
trainer/Alpha Loss                 -0.286256
exploration/num steps total    231200
exploration/num paths total      2312
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.786648
exploration/Rewards Std             0.96613
exploration/Rewards Max            -0.0256771
exploration/Rewards Min            -8.83641
exploration/Returns Mean          -78.6648
exploration/Returns Std            69.7605
exploration/Returns Max           -20.9108
exploration/Returns Min          -203.407
exploration/Actions Mean            0.0102494
exploration/Actions Std             0.198722
exploration/Actions Max             0.997452
exploration/Actions Min            -0.999911
exploration/Num Paths               5
exploration/Average Returns       -78.6648
evaluation/num steps total     693000
evaluation/num paths total       6930
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.968758
evaluation/Rewards Std              1.26269
evaluation/Rewards Max             -0.00968707
evaluation/Rewards Min             -9.91769
evaluation/Returns Mean           -96.8758
evaluation/Returns Std            100.103
evaluation/Returns Max             -5.72408
evaluation/Returns Min           -310.247
evaluation/Actions Mean            -0.010665
evaluation/Actions Std              0.156616
evaluation/Actions Max              0.998668
evaluation/Actions Min             -0.999184
evaluation/Num Paths               15
evaluation/Average Returns        -96.8758
time/data storing (s)               0.00259657
time/evaluation sampling (s)        0.322181
time/exploration sampling (s)       0.138667
time/logging (s)                    0.00433873
time/saving (s)                     0.00155808
time/training (s)                   1.98974
time/epoch (s)                      2.45908
time/total (s)                   1134.61
Epoch                             461
-----------------------------  ---------------
2019-04-23 01:32:29.429648 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 462 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.284955
trainer/QF2 Loss                    0.276197
trainer/Policy Loss                38.9976
trainer/Q1 Predictions Mean       -37.0645
trainer/Q1 Predictions Std         38.2004
trainer/Q1 Predictions Max         -6.53566
trainer/Q1 Predictions Min       -149.381
trainer/Q2 Predictions Mean       -37.0455
trainer/Q2 Predictions Std         38.1727
trainer/Q2 Predictions Max         -6.5365
trainer/Q2 Predictions Min       -149.267
trainer/Q Targets Mean            -37.2404
trainer/Q Targets Std              38.2177
trainer/Q Targets Max              -6.60933
trainer/Q Targets Min            -147.256
trainer/Log Pis Mean                1.99763
trainer/Log Pis Std                 1.40959
trainer/Log Pis Max                10.9122
trainer/Log Pis Min                -2.16394
trainer/Policy mu Mean              0.0453541
trainer/Policy mu Std               0.49856
trainer/Policy mu Max               3.62492
trainer/Policy mu Min              -2.73388
trainer/Policy log std Mean        -2.2276
trainer/Policy log std Std          0.43795
trainer/Policy log std Max         -0.116354
trainer/Policy log std Min         -3.07894
trainer/Alpha                       0.0578104
trainer/Alpha Loss                 -0.00675941
exploration/num steps total    231700
exploration/num paths total      2317
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.3368
exploration/Rewards Std             1.73396
exploration/Rewards Max            -0.00368581
exploration/Rewards Min            -9.72376
exploration/Returns Mean         -133.68
exploration/Returns Std           128.329
exploration/Returns Max           -40.392
exploration/Returns Min          -380.979
exploration/Actions Mean           -0.00775537
exploration/Actions Std             0.304402
exploration/Actions Max             0.999699
exploration/Actions Min            -0.999249
exploration/Num Paths               5
exploration/Average Returns      -133.68
evaluation/num steps total     694500
evaluation/num paths total       6945
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.12251
evaluation/Rewards Std              1.54139
evaluation/Rewards Max             -0.0158834
evaluation/Rewards Min            -11.1636
evaluation/Returns Mean          -112.251
evaluation/Returns Std            120.976
evaluation/Returns Max             -4.05112
evaluation/Returns Min           -389.242
evaluation/Actions Mean             0.0101779
evaluation/Actions Std              0.177205
evaluation/Actions Max              0.999854
evaluation/Actions Min             -0.99469
evaluation/Num Paths               15
evaluation/Average Returns       -112.251
time/data storing (s)               0.00307482
time/evaluation sampling (s)        0.328306
time/exploration sampling (s)       0.138719
time/logging (s)                    0.00476976
time/saving (s)                     0.0019494
time/training (s)                   1.98449
time/epoch (s)                      2.46131
time/total (s)                   1137.08
Epoch                             462
-----------------------------  ---------------
2019-04-23 01:32:31.894423 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 463 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.51029
trainer/QF2 Loss                    1.66153
trainer/Policy Loss                45.4056
trainer/Q1 Predictions Mean       -43.3654
trainer/Q1 Predictions Std         43.5803
trainer/Q1 Predictions Max         -6.58129
trainer/Q1 Predictions Min       -150.923
trainer/Q2 Predictions Mean       -43.4222
trainer/Q2 Predictions Std         43.6011
trainer/Q2 Predictions Max         -6.57374
trainer/Q2 Predictions Min       -151.439
trainer/Q Targets Mean            -43.6255
trainer/Q Targets Std              43.9175
trainer/Q Targets Max              -0.0886492
trainer/Q Targets Min            -150.066
trainer/Log Pis Mean                2.02205
trainer/Log Pis Std                 1.22081
trainer/Log Pis Max                 7.06163
trainer/Log Pis Min                -2.14594
trainer/Policy mu Mean             -0.0478476
trainer/Policy mu Std               0.502006
trainer/Policy mu Max               3.40487
trainer/Policy mu Min              -2.78755
trainer/Policy log std Mean        -2.2498
trainer/Policy log std Std          0.428234
trainer/Policy log std Max         -0.440536
trainer/Policy log std Min         -3.00367
trainer/Alpha                       0.059251
trainer/Alpha Loss                  0.0623092
exploration/num steps total    232200
exploration/num paths total      2322
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.579218
exploration/Rewards Std             0.914314
exploration/Rewards Max            -0.00863499
exploration/Rewards Min            -8.9456
exploration/Returns Mean          -57.9218
exploration/Returns Std            24.8944
exploration/Returns Max           -19.8747
exploration/Returns Min           -85.1381
exploration/Actions Mean           -0.0104717
exploration/Actions Std             0.19227
exploration/Actions Max             0.99956
exploration/Actions Min            -0.999435
exploration/Num Paths               5
exploration/Average Returns       -57.9218
evaluation/num steps total     696000
evaluation/num paths total       6960
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.987878
evaluation/Rewards Std              1.38486
evaluation/Rewards Max             -0.0193267
evaluation/Rewards Min             -9.31677
evaluation/Returns Mean           -98.7878
evaluation/Returns Std            106.709
evaluation/Returns Max             -9.70641
evaluation/Returns Min           -309.001
evaluation/Actions Mean             0.00299571
evaluation/Actions Std              0.168745
evaluation/Actions Max              0.998832
evaluation/Actions Min             -0.999112
evaluation/Num Paths               15
evaluation/Average Returns        -98.7878
time/data storing (s)               0.0027178
time/evaluation sampling (s)        0.324918
time/exploration sampling (s)       0.136057
time/logging (s)                    0.00355916
time/saving (s)                     0.00167766
time/training (s)                   1.98352
time/epoch (s)                      2.45245
time/total (s)                   1139.53
Epoch                             463
-----------------------------  ---------------
2019-04-23 01:32:34.377660 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 464 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.339515
trainer/QF2 Loss                    0.356929
trainer/Policy Loss                35.1156
trainer/Q1 Predictions Mean       -33.1255
trainer/Q1 Predictions Std         33.8318
trainer/Q1 Predictions Max         -6.44517
trainer/Q1 Predictions Min       -137.009
trainer/Q2 Predictions Mean       -33.1043
trainer/Q2 Predictions Std         33.8007
trainer/Q2 Predictions Max         -6.47683
trainer/Q2 Predictions Min       -136.566
trainer/Q Targets Mean            -33.505
trainer/Q Targets Std              34.1249
trainer/Q Targets Max              -6.42916
trainer/Q Targets Min            -137.345
trainer/Log Pis Mean                2.11873
trainer/Log Pis Std                 0.906103
trainer/Log Pis Max                 3.82203
trainer/Log Pis Min                -0.871108
trainer/Policy mu Mean             -0.0144388
trainer/Policy mu Std               0.254827
trainer/Policy mu Max               1.60496
trainer/Policy mu Min              -1.571
trainer/Policy log std Mean        -2.33169
trainer/Policy log std Std          0.309157
trainer/Policy log std Max         -0.742269
trainer/Policy log std Min         -3.20936
trainer/Alpha                       0.0620781
trainer/Alpha Loss                  0.329993
exploration/num steps total    232700
exploration/num paths total      2327
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.660367
exploration/Rewards Std             0.911283
exploration/Rewards Max            -0.0063848
exploration/Rewards Min            -7.4605
exploration/Returns Mean          -66.0367
exploration/Returns Std            46.4718
exploration/Returns Max           -28.427
exploration/Returns Min          -150.269
exploration/Actions Mean           -0.0104637
exploration/Actions Std             0.219601
exploration/Actions Max             0.996858
exploration/Actions Min            -0.99845
exploration/Num Paths               5
exploration/Average Returns       -66.0367
evaluation/num steps total     697500
evaluation/num paths total       6975
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.14219
evaluation/Rewards Std              1.27031
evaluation/Rewards Max             -0.0278039
evaluation/Rewards Min            -10.2137
evaluation/Returns Mean          -114.219
evaluation/Returns Std             82.3577
evaluation/Returns Max            -19.4987
evaluation/Returns Min           -312.226
evaluation/Actions Mean            -0.00268885
evaluation/Actions Std              0.19887
evaluation/Actions Max              0.999157
evaluation/Actions Min             -0.999464
evaluation/Num Paths               15
evaluation/Average Returns       -114.219
time/data storing (s)               0.00262284
time/evaluation sampling (s)        0.329247
time/exploration sampling (s)       0.140626
time/logging (s)                    0.00480593
time/saving (s)                     0.00192131
time/training (s)                   1.99475
time/epoch (s)                      2.47397
time/total (s)                   1142.01
Epoch                             464
-----------------------------  ---------------
2019-04-23 01:32:36.848644 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 465 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    2.44759
trainer/QF2 Loss                    2.28623
trainer/Policy Loss                41.2175
trainer/Q1 Predictions Mean       -39.2454
trainer/Q1 Predictions Std         38.7044
trainer/Q1 Predictions Max         -6.56039
trainer/Q1 Predictions Min       -136.666
trainer/Q2 Predictions Mean       -39.3024
trainer/Q2 Predictions Std         38.75
trainer/Q2 Predictions Max         -6.57382
trainer/Q2 Predictions Min       -136.384
trainer/Q Targets Mean            -39.4629
trainer/Q Targets Std              39.1989
trainer/Q Targets Max              -0.186372
trainer/Q Targets Min            -137.21
trainer/Log Pis Mean                2.02284
trainer/Log Pis Std                 1.11613
trainer/Log Pis Max                 6.04765
trainer/Log Pis Min                -2.34367
trainer/Policy mu Mean             -0.0454365
trainer/Policy mu Std               0.413214
trainer/Policy mu Max               3.42406
trainer/Policy mu Min              -2.91865
trainer/Policy log std Mean        -2.3
trainer/Policy log std Std          0.31459
trainer/Policy log std Max         -0.675822
trainer/Policy log std Min         -3.09745
trainer/Alpha                       0.0619937
trainer/Alpha Loss                  0.0635011
exploration/num steps total    233200
exploration/num paths total      2332
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.657808
exploration/Rewards Std             0.960458
exploration/Rewards Max            -0.00849472
exploration/Rewards Min            -8.49564
exploration/Returns Mean          -65.7808
exploration/Returns Std            30.9753
exploration/Returns Max           -27.7671
exploration/Returns Min          -106.35
exploration/Actions Mean           -0.00854375
exploration/Actions Std             0.207519
exploration/Actions Max             0.998174
exploration/Actions Min            -0.998043
exploration/Num Paths               5
exploration/Average Returns       -65.7808
evaluation/num steps total     699000
evaluation/num paths total       6990
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.39861
evaluation/Rewards Std              1.47145
evaluation/Rewards Max             -0.0339607
evaluation/Rewards Min            -10.1199
evaluation/Returns Mean          -139.861
evaluation/Returns Std            115.996
evaluation/Returns Max             -7.60162
evaluation/Returns Min           -309.669
evaluation/Actions Mean            -0.00366349
evaluation/Actions Std              0.181035
evaluation/Actions Max              0.99935
evaluation/Actions Min             -0.999601
evaluation/Num Paths               15
evaluation/Average Returns       -139.861
time/data storing (s)               0.0027308
time/evaluation sampling (s)        0.331119
time/exploration sampling (s)       0.140696
time/logging (s)                    0.00405856
time/saving (s)                     0.00162022
time/training (s)                   1.97963
time/epoch (s)                      2.45986
time/total (s)                   1144.48
Epoch                             465
-----------------------------  ---------------
2019-04-23 01:32:39.324209 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 466 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.00576
trainer/QF2 Loss                    0.995895
trainer/Policy Loss                37.2375
trainer/Q1 Predictions Mean       -35.0794
trainer/Q1 Predictions Std         41.5207
trainer/Q1 Predictions Max         -6.41014
trainer/Q1 Predictions Min       -138.818
trainer/Q2 Predictions Mean       -35.0975
trainer/Q2 Predictions Std         41.516
trainer/Q2 Predictions Max         -6.4328
trainer/Q2 Predictions Min       -138.484
trainer/Q Targets Mean            -35.1543
trainer/Q Targets Std              41.6778
trainer/Q Targets Max              -0.0746184
trainer/Q Targets Min            -139.455
trainer/Log Pis Mean                2.21764
trainer/Log Pis Std                 1.25022
trainer/Log Pis Max                 7.01482
trainer/Log Pis Min                -3.15837
trainer/Policy mu Mean             -0.0987596
trainer/Policy mu Std               0.492605
trainer/Policy mu Max               1.83988
trainer/Policy mu Min              -2.96383
trainer/Policy log std Mean        -2.31771
trainer/Policy log std Std          0.410102
trainer/Policy log std Max         -0.639
trainer/Policy log std Min         -2.92765
trainer/Alpha                       0.0620557
trainer/Alpha Loss                  0.605063
exploration/num steps total    233700
exploration/num paths total      2337
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.75809
exploration/Rewards Std             1.14014
exploration/Rewards Max            -0.00249701
exploration/Rewards Min            -7.41518
exploration/Returns Mean          -75.809
exploration/Returns Std           100.078
exploration/Returns Max           -18.8876
exploration/Returns Min          -275.661
exploration/Actions Mean           -1.4143e-05
exploration/Actions Std             0.210085
exploration/Actions Max             0.995845
exploration/Actions Min            -0.996508
exploration/Num Paths               5
exploration/Average Returns       -75.809
evaluation/num steps total     700500
evaluation/num paths total       7005
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.822157
evaluation/Rewards Std              1.04373
evaluation/Rewards Max             -0.00878483
evaluation/Rewards Min             -9.15523
evaluation/Returns Mean           -82.2157
evaluation/Returns Std             76.281
evaluation/Returns Max             -8.68051
evaluation/Returns Min           -259.123
evaluation/Actions Mean            -0.00698294
evaluation/Actions Std              0.152319
evaluation/Actions Max              0.998184
evaluation/Actions Min             -0.99654
evaluation/Num Paths               15
evaluation/Average Returns        -82.2157
time/data storing (s)               0.00277654
time/evaluation sampling (s)        0.330005
time/exploration sampling (s)       0.140792
time/logging (s)                    0.00479501
time/saving (s)                     0.00192846
time/training (s)                   1.98494
time/epoch (s)                      2.46523
time/total (s)                   1146.95
Epoch                             466
-----------------------------  ---------------
2019-04-23 01:32:41.804903 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 467 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.552551
trainer/QF2 Loss                    0.436581
trainer/Policy Loss                44.8877
trainer/Q1 Predictions Mean       -43.043
trainer/Q1 Predictions Std         42.9109
trainer/Q1 Predictions Max         -6.70904
trainer/Q1 Predictions Min       -160.92
trainer/Q2 Predictions Mean       -43.0275
trainer/Q2 Predictions Std         42.9529
trainer/Q2 Predictions Max         -6.78833
trainer/Q2 Predictions Min       -162.875
trainer/Q Targets Mean            -43.4343
trainer/Q Targets Std              43.3574
trainer/Q Targets Max              -6.50951
trainer/Q Targets Min            -165.228
trainer/Log Pis Mean                1.95218
trainer/Log Pis Std                 1.49811
trainer/Log Pis Max                 8.19937
trainer/Log Pis Min                -2.33277
trainer/Policy mu Mean             -0.0798628
trainer/Policy mu Std               0.541118
trainer/Policy mu Max               3.01416
trainer/Policy mu Min              -3.00295
trainer/Policy log std Mean        -2.24767
trainer/Policy log std Std          0.476076
trainer/Policy log std Max          0.179034
trainer/Policy log std Min         -2.99155
trainer/Alpha                       0.0614231
trainer/Alpha Loss                 -0.133426
exploration/num steps total    234200
exploration/num paths total      2342
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.04542
exploration/Rewards Std             1.53749
exploration/Rewards Max            -0.0172447
exploration/Rewards Min           -11.4924
exploration/Returns Mean         -104.542
exploration/Returns Std            42.758
exploration/Returns Max           -65.1164
exploration/Returns Min          -183.519
exploration/Actions Mean            0.0287524
exploration/Actions Std             0.246901
exploration/Actions Max             0.999754
exploration/Actions Min            -0.999948
exploration/Num Paths               5
exploration/Average Returns      -104.542
evaluation/num steps total     702000
evaluation/num paths total       7020
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.95675
evaluation/Rewards Std              1.33751
evaluation/Rewards Max             -0.0253408
evaluation/Rewards Min            -10.8804
evaluation/Returns Mean           -95.675
evaluation/Returns Std            105.69
evaluation/Returns Max             -7.17849
evaluation/Returns Min           -340.199
evaluation/Actions Mean            -0.00228124
evaluation/Actions Std              0.16832
evaluation/Actions Max              0.998517
evaluation/Actions Min             -0.998321
evaluation/Num Paths               15
evaluation/Average Returns        -95.675
time/data storing (s)               0.0025489
time/evaluation sampling (s)        0.33241
time/exploration sampling (s)       0.13764
time/logging (s)                    0.00477888
time/saving (s)                     0.0023207
time/training (s)                   1.98989
time/epoch (s)                      2.46959
time/total (s)                   1149.42
Epoch                             467
-----------------------------  ---------------
2019-04-23 01:32:44.304760 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 468 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                  181.725
trainer/QF2 Loss                  181.753
trainer/Policy Loss                42.4257
trainer/Q1 Predictions Mean       -40.5429
trainer/Q1 Predictions Std         41.7539
trainer/Q1 Predictions Max         -6.59032
trainer/Q1 Predictions Min       -148.167
trainer/Q2 Predictions Mean       -40.546
trainer/Q2 Predictions Std         41.7545
trainer/Q2 Predictions Max         -6.6067
trainer/Q2 Predictions Min       -148.25
trainer/Q Targets Mean            -39.5083
trainer/Q Targets Std              40.8339
trainer/Q Targets Max              -3.64254
trainer/Q Targets Min            -147.038
trainer/Log Pis Mean                1.97095
trainer/Log Pis Std                 1.09104
trainer/Log Pis Max                 3.70983
trainer/Log Pis Min                -1.96407
trainer/Policy mu Mean             -0.00966721
trainer/Policy mu Std               0.380659
trainer/Policy mu Max               1.78203
trainer/Policy mu Min              -2.26572
trainer/Policy log std Mean        -2.2576
trainer/Policy log std Std          0.3815
trainer/Policy log std Max         -0.408437
trainer/Policy log std Min         -3.01782
trainer/Alpha                       0.0603783
trainer/Alpha Loss                 -0.0815319
exploration/num steps total    234700
exploration/num paths total      2347
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.804066
exploration/Rewards Std             1.00043
exploration/Rewards Max            -0.00948636
exploration/Rewards Min            -7.66615
exploration/Returns Mean          -80.4066
exploration/Returns Std            64.78
exploration/Returns Max           -26.9255
exploration/Returns Min          -204.84
exploration/Actions Mean           -0.0190727
exploration/Actions Std             0.197661
exploration/Actions Max             0.997315
exploration/Actions Min            -0.998428
exploration/Num Paths               5
exploration/Average Returns       -80.4066
evaluation/num steps total     703500
evaluation/num paths total       7035
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.637826
evaluation/Rewards Std              1.11703
evaluation/Rewards Max             -0.00739283
evaluation/Rewards Min            -11.3517
evaluation/Returns Mean           -63.7826
evaluation/Returns Std             44.6542
evaluation/Returns Max             -9.98883
evaluation/Returns Min           -165.451
evaluation/Actions Mean            -0.000861754
evaluation/Actions Std              0.196961
evaluation/Actions Max              0.999139
evaluation/Actions Min             -0.998259
evaluation/Num Paths               15
evaluation/Average Returns        -63.7826
time/data storing (s)               0.00270231
time/evaluation sampling (s)        0.333979
time/exploration sampling (s)       0.13884
time/logging (s)                    0.0043994
time/saving (s)                     0.00953575
time/training (s)                   1.99868
time/epoch (s)                      2.48814
time/total (s)                   1151.91
Epoch                             468
-----------------------------  ----------------
2019-04-23 01:32:46.756901 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 469 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.58206
trainer/QF2 Loss                    1.6473
trainer/Policy Loss                39.4722
trainer/Q1 Predictions Mean       -37.5591
trainer/Q1 Predictions Std         36.6554
trainer/Q1 Predictions Max         -6.73386
trainer/Q1 Predictions Min       -137.317
trainer/Q2 Predictions Mean       -37.5229
trainer/Q2 Predictions Std         36.6471
trainer/Q2 Predictions Max         -6.62361
trainer/Q2 Predictions Min       -137.181
trainer/Q Targets Mean            -38.1298
trainer/Q Targets Std              37.2463
trainer/Q Targets Max              -0.206256
trainer/Q Targets Min            -139.657
trainer/Log Pis Mean                2.01005
trainer/Log Pis Std                 1.27106
trainer/Log Pis Max                 4.90526
trainer/Log Pis Min                -3.78091
trainer/Policy mu Mean              0.00124876
trainer/Policy mu Std               0.45516
trainer/Policy mu Max               2.82678
trainer/Policy mu Min              -2.77622
trainer/Policy log std Mean        -2.25422
trainer/Policy log std Std          0.400374
trainer/Policy log std Max         -0.544572
trainer/Policy log std Min         -3.03202
trainer/Alpha                       0.0598005
trainer/Alpha Loss                  0.0283044
exploration/num steps total    235200
exploration/num paths total      2352
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.55375
exploration/Rewards Std             1.37393
exploration/Rewards Max            -0.0171101
exploration/Rewards Min            -9.12073
exploration/Returns Mean         -155.375
exploration/Returns Std           103.896
exploration/Returns Max           -25.6512
exploration/Returns Min          -319.815
exploration/Actions Mean           -0.0248786
exploration/Actions Std             0.246912
exploration/Actions Max             0.993696
exploration/Actions Min            -0.999236
exploration/Num Paths               5
exploration/Average Returns      -155.375
evaluation/num steps total     705000
evaluation/num paths total       7050
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.689047
evaluation/Rewards Std              1.14504
evaluation/Rewards Max             -0.0220753
evaluation/Rewards Min            -10.2161
evaluation/Returns Mean           -68.9047
evaluation/Returns Std             56.8887
evaluation/Returns Max             -9.25756
evaluation/Returns Min           -212.212
evaluation/Actions Mean             0.0102004
evaluation/Actions Std              0.19854
evaluation/Actions Max              0.999073
evaluation/Actions Min             -0.998799
evaluation/Num Paths               15
evaluation/Average Returns        -68.9047
time/data storing (s)               0.00260593
time/evaluation sampling (s)        0.324572
time/exploration sampling (s)       0.135783
time/logging (s)                    0.00476614
time/saving (s)                     0.00195538
time/training (s)                   1.97286
time/epoch (s)                      2.44255
time/total (s)                   1154.36
Epoch                             469
-----------------------------  ---------------
2019-04-23 01:32:49.228750 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 470 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   21.7819
trainer/QF2 Loss                   21.7209
trainer/Policy Loss                38.0304
trainer/Q1 Predictions Mean       -36.154
trainer/Q1 Predictions Std         36.6554
trainer/Q1 Predictions Max         -6.68594
trainer/Q1 Predictions Min       -138
trainer/Q2 Predictions Mean       -36.1949
trainer/Q2 Predictions Std         36.6546
trainer/Q2 Predictions Max         -6.74669
trainer/Q2 Predictions Min       -138.1
trainer/Q Targets Mean            -35.9232
trainer/Q Targets Std              36.9402
trainer/Q Targets Max              -1.1617
trainer/Q Targets Min            -138.817
trainer/Log Pis Mean                1.97564
trainer/Log Pis Std                 0.964897
trainer/Log Pis Max                 5.04997
trainer/Log Pis Min                -1.06055
trainer/Policy mu Mean             -0.0913416
trainer/Policy mu Std               0.376575
trainer/Policy mu Max               2.1643
trainer/Policy mu Min              -2.37836
trainer/Policy log std Mean        -2.28787
trainer/Policy log std Std          0.349803
trainer/Policy log std Max         -0.698944
trainer/Policy log std Min         -2.99923
trainer/Alpha                       0.0612468
trainer/Alpha Loss                 -0.0680318
exploration/num steps total    235700
exploration/num paths total      2357
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.592372
exploration/Rewards Std             0.985701
exploration/Rewards Max            -0.0102591
exploration/Rewards Min            -8.3982
exploration/Returns Mean          -59.2372
exploration/Returns Std            66.0333
exploration/Returns Max           -15.6112
exploration/Returns Min          -190.296
exploration/Actions Mean           -0.00128788
exploration/Actions Std             0.207483
exploration/Actions Max             0.999543
exploration/Actions Min            -0.999337
exploration/Num Paths               5
exploration/Average Returns       -59.2372
evaluation/num steps total     706500
evaluation/num paths total       7065
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.540733
evaluation/Rewards Std              1.08105
evaluation/Rewards Max             -0.0117147
evaluation/Rewards Min             -9.3564
evaluation/Returns Mean           -54.0733
evaluation/Returns Std             50.7676
evaluation/Returns Max             -3.26894
evaluation/Returns Min           -178.853
evaluation/Actions Mean            -0.00292115
evaluation/Actions Std              0.188873
evaluation/Actions Max              0.999047
evaluation/Actions Min             -0.999131
evaluation/Num Paths               15
evaluation/Average Returns        -54.0733
time/data storing (s)               0.00277299
time/evaluation sampling (s)        0.326295
time/exploration sampling (s)       0.134583
time/logging (s)                    0.0049613
time/saving (s)                     0.00192924
time/training (s)                   1.99005
time/epoch (s)                      2.4606
time/total (s)                   1156.82
Epoch                             470
-----------------------------  ---------------
2019-04-23 01:32:51.688187 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 471 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   17.6657
trainer/QF2 Loss                   17.6176
trainer/Policy Loss                41.79
trainer/Q1 Predictions Mean       -39.9493
trainer/Q1 Predictions Std         42.6675
trainer/Q1 Predictions Max         -6.64865
trainer/Q1 Predictions Min       -138.4
trainer/Q2 Predictions Mean       -39.9497
trainer/Q2 Predictions Std         42.6827
trainer/Q2 Predictions Max         -6.63374
trainer/Q2 Predictions Min       -138.189
trainer/Q Targets Mean            -39.7076
trainer/Q Targets Std              42.8658
trainer/Q Targets Max              -0.631725
trainer/Q Targets Min            -138.064
trainer/Log Pis Mean                1.91263
trainer/Log Pis Std                 1.01535
trainer/Log Pis Max                 5.09704
trainer/Log Pis Min                -2.13627
trainer/Policy mu Mean             -0.0102967
trainer/Policy mu Std               0.374409
trainer/Policy mu Max               2.49596
trainer/Policy mu Min              -2.74727
trainer/Policy log std Mean        -2.2163
trainer/Policy log std Std          0.334997
trainer/Policy log std Max         -0.584741
trainer/Policy log std Min         -3.00367
trainer/Alpha                       0.0614409
trainer/Alpha Loss                 -0.243738
exploration/num steps total    236200
exploration/num paths total      2362
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.354888
exploration/Rewards Std             0.992864
exploration/Rewards Max            -0.00630597
exploration/Rewards Min            -8.30093
exploration/Returns Mean          -35.4888
exploration/Returns Std            13.4662
exploration/Returns Max           -17.7604
exploration/Returns Min           -55.2662
exploration/Actions Mean            0.0356701
exploration/Actions Std             0.208194
exploration/Actions Max             0.997954
exploration/Actions Min            -0.480491
exploration/Num Paths               5
exploration/Average Returns       -35.4888
evaluation/num steps total     708000
evaluation/num paths total       7080
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.833274
evaluation/Rewards Std              1.01941
evaluation/Rewards Max             -0.0155941
evaluation/Rewards Min             -8.34286
evaluation/Returns Mean           -83.3274
evaluation/Returns Std             83.1897
evaluation/Returns Max             -8.78609
evaluation/Returns Min           -287.151
evaluation/Actions Mean            -0.0060945
evaluation/Actions Std              0.147906
evaluation/Actions Max              0.997713
evaluation/Actions Min             -0.998244
evaluation/Num Paths               15
evaluation/Average Returns        -83.3274
time/data storing (s)               0.00260107
time/evaluation sampling (s)        0.332658
time/exploration sampling (s)       0.137387
time/logging (s)                    0.0047438
time/saving (s)                     0.00172901
time/training (s)                   1.9694
time/epoch (s)                      2.44852
time/total (s)                   1159.28
Epoch                             471
-----------------------------  ---------------
2019-04-23 01:32:54.149752 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 472 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.29788
trainer/QF2 Loss                    1.29235
trainer/Policy Loss                35.4518
trainer/Q1 Predictions Mean       -33.5459
trainer/Q1 Predictions Std         39.6869
trainer/Q1 Predictions Max         -6.54903
trainer/Q1 Predictions Min       -145.651
trainer/Q2 Predictions Mean       -33.5598
trainer/Q2 Predictions Std         39.6597
trainer/Q2 Predictions Max         -6.50494
trainer/Q2 Predictions Min       -145.59
trainer/Q Targets Mean            -33.6264
trainer/Q Targets Std              40.0459
trainer/Q Targets Max              -0.134969
trainer/Q Targets Min            -145.441
trainer/Log Pis Mean                2.05783
trainer/Log Pis Std                 1.08811
trainer/Log Pis Max                 4.52359
trainer/Log Pis Min                -2.03015
trainer/Policy mu Mean             -0.0485009
trainer/Policy mu Std               0.372745
trainer/Policy mu Max               2.25968
trainer/Policy mu Min              -2.49472
trainer/Policy log std Mean        -2.32961
trainer/Policy log std Std          0.330809
trainer/Policy log std Max         -0.739544
trainer/Policy log std Min         -3.04316
trainer/Alpha                       0.063233
trainer/Alpha Loss                  0.159672
exploration/num steps total    236700
exploration/num paths total      2367
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.977131
exploration/Rewards Std             1.2663
exploration/Rewards Max            -0.0166759
exploration/Rewards Min           -10.9443
exploration/Returns Mean          -97.7131
exploration/Returns Std            74.142
exploration/Returns Max           -18.6431
exploration/Returns Min          -215.041
exploration/Actions Mean           -0.0184222
exploration/Actions Std             0.236624
exploration/Actions Max             0.995598
exploration/Actions Min            -0.998282
exploration/Num Paths               5
exploration/Average Returns       -97.7131
evaluation/num steps total     709500
evaluation/num paths total       7095
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.993059
evaluation/Rewards Std              1.18494
evaluation/Rewards Max             -0.0279701
evaluation/Rewards Min             -8.85717
evaluation/Returns Mean           -99.3059
evaluation/Returns Std             79.6739
evaluation/Returns Max             -7.10517
evaluation/Returns Min           -274.758
evaluation/Actions Mean             0.00852658
evaluation/Actions Std              0.183076
evaluation/Actions Max              0.99787
evaluation/Actions Min             -0.998478
evaluation/Num Paths               15
evaluation/Average Returns        -99.3059
time/data storing (s)               0.00269945
time/evaluation sampling (s)        0.324642
time/exploration sampling (s)       0.140034
time/logging (s)                    0.00478624
time/saving (s)                     0.00193938
time/training (s)                   1.97748
time/epoch (s)                      2.45158
time/total (s)                   1161.73
Epoch                             472
-----------------------------  ---------------
2019-04-23 01:32:56.631537 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 473 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                  175.13
trainer/QF2 Loss                  176.166
trainer/Policy Loss                35.402
trainer/Q1 Predictions Mean       -33.3558
trainer/Q1 Predictions Std         33.8608
trainer/Q1 Predictions Max         -6.46753
trainer/Q1 Predictions Min       -135.905
trainer/Q2 Predictions Mean       -33.3214
trainer/Q2 Predictions Std         33.8506
trainer/Q2 Predictions Max         -6.45987
trainer/Q2 Predictions Min       -136.087
trainer/Q Targets Mean            -32.3248
trainer/Q Targets Std              32.5914
trainer/Q Targets Max              -2.7889
trainer/Q Targets Min            -136.531
trainer/Log Pis Mean                2.13981
trainer/Log Pis Std                 1.0851
trainer/Log Pis Max                 5.06454
trainer/Log Pis Min                -1.82814
trainer/Policy mu Mean              0.000597752
trainer/Policy mu Std               0.403746
trainer/Policy mu Max               2.68198
trainer/Policy mu Min              -2.66357
trainer/Policy log std Mean        -2.33729
trainer/Policy log std Std          0.379306
trainer/Policy log std Max         -0.547806
trainer/Policy log std Min         -3.12318
trainer/Alpha                       0.0604404
trainer/Alpha Loss                  0.392337
exploration/num steps total    237200
exploration/num paths total      2372
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.53084
exploration/Rewards Std             1.1255
exploration/Rewards Max            -0.0221661
exploration/Rewards Min            -7.36961
exploration/Returns Mean         -153.084
exploration/Returns Std            91.6399
exploration/Returns Max           -41.9588
exploration/Returns Min          -319.299
exploration/Actions Mean           -0.0165371
exploration/Actions Std             0.2322
exploration/Actions Max             0.986788
exploration/Actions Min            -0.999057
exploration/Num Paths               5
exploration/Average Returns      -153.084
evaluation/num steps total     711000
evaluation/num paths total       7110
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.927777
evaluation/Rewards Std              1.25138
evaluation/Rewards Max             -0.0249901
evaluation/Rewards Min             -9.27812
evaluation/Returns Mean           -92.7777
evaluation/Returns Std             78.9075
evaluation/Returns Max            -13.957
evaluation/Returns Min           -331.789
evaluation/Actions Mean            -0.00551029
evaluation/Actions Std              0.196059
evaluation/Actions Max              0.995948
evaluation/Actions Min             -0.999685
evaluation/Num Paths               15
evaluation/Average Returns        -92.7777
time/data storing (s)               0.00259295
time/evaluation sampling (s)        0.328831
time/exploration sampling (s)       0.143469
time/logging (s)                    0.00358774
time/saving (s)                     0.00191566
time/training (s)                   1.98904
time/epoch (s)                      2.46944
time/total (s)                   1164.21
Epoch                             473
-----------------------------  ----------------
2019-04-23 01:32:59.110707 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 474 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.12403
trainer/QF2 Loss                    1.17254
trainer/Policy Loss                39.6326
trainer/Q1 Predictions Mean       -37.6721
trainer/Q1 Predictions Std         35.4348
trainer/Q1 Predictions Max         -6.54536
trainer/Q1 Predictions Min       -136.408
trainer/Q2 Predictions Mean       -37.6615
trainer/Q2 Predictions Std         35.4148
trainer/Q2 Predictions Max         -6.55323
trainer/Q2 Predictions Min       -136.299
trainer/Q Targets Mean            -37.8657
trainer/Q Targets Std              35.8156
trainer/Q Targets Max              -0.0746184
trainer/Q Targets Min            -137.113
trainer/Log Pis Mean                2.06755
trainer/Log Pis Std                 1.11991
trainer/Log Pis Max                 4.78867
trainer/Log Pis Min                -1.54013
trainer/Policy mu Mean             -0.0483572
trainer/Policy mu Std               0.429648
trainer/Policy mu Max               3.27978
trainer/Policy mu Min              -2.85871
trainer/Policy log std Mean        -2.27445
trainer/Policy log std Std          0.385008
trainer/Policy log std Max         -0.315728
trainer/Policy log std Min         -3.01407
trainer/Alpha                       0.0625714
trainer/Alpha Loss                  0.187203
exploration/num steps total    237700
exploration/num paths total      2377
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.788128
exploration/Rewards Std             1.44539
exploration/Rewards Max            -0.00470679
exploration/Rewards Min           -10.5741
exploration/Returns Mean          -78.8128
exploration/Returns Std            37.3321
exploration/Returns Max           -52.7357
exploration/Returns Min          -150.958
exploration/Actions Mean            0.0307905
exploration/Actions Std             0.262763
exploration/Actions Max             0.999929
exploration/Actions Min            -0.99457
exploration/Num Paths               5
exploration/Average Returns       -78.8128
evaluation/num steps total     712500
evaluation/num paths total       7125
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.509322
evaluation/Rewards Std              0.87298
evaluation/Rewards Max             -0.0102991
evaluation/Rewards Min             -9.83855
evaluation/Returns Mean           -50.9322
evaluation/Returns Std             62.5976
evaluation/Returns Max             -5.16304
evaluation/Returns Min           -199.164
evaluation/Actions Mean             0.00870889
evaluation/Actions Std              0.149443
evaluation/Actions Max              0.999537
evaluation/Actions Min             -0.992797
evaluation/Num Paths               15
evaluation/Average Returns        -50.9322
time/data storing (s)               0.00282803
time/evaluation sampling (s)        0.331013
time/exploration sampling (s)       0.139867
time/logging (s)                    0.00477694
time/saving (s)                     0.00195798
time/training (s)                   1.98927
time/epoch (s)                      2.46971
time/total (s)                   1166.68
Epoch                             474
-----------------------------  ---------------
2019-04-23 01:33:01.593498 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 475 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.616779
trainer/QF2 Loss                    0.684022
trainer/Policy Loss                42.514
trainer/Q1 Predictions Mean       -40.3687
trainer/Q1 Predictions Std         40.1731
trainer/Q1 Predictions Max         -6.68424
trainer/Q1 Predictions Min       -140.49
trainer/Q2 Predictions Mean       -40.3473
trainer/Q2 Predictions Std         40.1053
trainer/Q2 Predictions Max         -6.68102
trainer/Q2 Predictions Min       -139.908
trainer/Q Targets Mean            -40.6948
trainer/Q Targets Std              40.634
trainer/Q Targets Max              -6.49328
trainer/Q Targets Min            -141.149
trainer/Log Pis Mean                2.2732
trainer/Log Pis Std                 1.30377
trainer/Log Pis Max                11.259
trainer/Log Pis Min                -1.74779
trainer/Policy mu Mean             -0.0704988
trainer/Policy mu Std               0.515355
trainer/Policy mu Max               3.65316
trainer/Policy mu Min              -3.4956
trainer/Policy log std Mean        -2.28537
trainer/Policy log std Std          0.384607
trainer/Policy log std Max         -0.428184
trainer/Policy log std Min         -3.19509
trainer/Alpha                       0.0622457
trainer/Alpha Loss                  0.758628
exploration/num steps total    238200
exploration/num paths total      2382
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.52838
exploration/Rewards Std             1.51551
exploration/Rewards Max            -0.013913
exploration/Rewards Min           -11.8708
exploration/Returns Mean         -152.838
exploration/Returns Std           113.911
exploration/Returns Max           -23.0477
exploration/Returns Min          -353.98
exploration/Actions Mean            0.0120239
exploration/Actions Std             0.231843
exploration/Actions Max             0.998632
exploration/Actions Min            -0.996091
exploration/Num Paths               5
exploration/Average Returns      -152.838
evaluation/num steps total     714000
evaluation/num paths total       7140
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.713606
evaluation/Rewards Std              1.29187
evaluation/Rewards Max             -0.0157655
evaluation/Rewards Min            -10.5292
evaluation/Returns Mean           -71.3606
evaluation/Returns Std             86.4018
evaluation/Returns Max             -9.33846
evaluation/Returns Min           -338.534
evaluation/Actions Mean            -0.00182815
evaluation/Actions Std              0.195524
evaluation/Actions Max              0.998165
evaluation/Actions Min             -0.999667
evaluation/Num Paths               15
evaluation/Average Returns        -71.3606
time/data storing (s)               0.00281806
time/evaluation sampling (s)        0.330937
time/exploration sampling (s)       0.140598
time/logging (s)                    0.00493886
time/saving (s)                     0.00231874
time/training (s)                   1.99001
time/epoch (s)                      2.47162
time/total (s)                   1169.16
Epoch                             475
-----------------------------  ---------------
2019-04-23 01:33:04.059655 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 476 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   53.5436
trainer/QF2 Loss                   53.9875
trainer/Policy Loss                39.9193
trainer/Q1 Predictions Mean       -37.8893
trainer/Q1 Predictions Std         37.4271
trainer/Q1 Predictions Max         -6.65734
trainer/Q1 Predictions Min       -138.153
trainer/Q2 Predictions Mean       -37.913
trainer/Q2 Predictions Std         37.4151
trainer/Q2 Predictions Max         -6.59338
trainer/Q2 Predictions Min       -138.027
trainer/Q Targets Mean            -37.0589
trainer/Q Targets Std              37.4289
trainer/Q Targets Max              -1.17213
trainer/Q Targets Min            -138.288
trainer/Log Pis Mean                2.12825
trainer/Log Pis Std                 1.17115
trainer/Log Pis Max                 6.99953
trainer/Log Pis Min                -1.1277
trainer/Policy mu Mean              0.0550471
trainer/Policy mu Std               0.535936
trainer/Policy mu Max               3.115
trainer/Policy mu Min              -2.91558
trainer/Policy log std Mean        -2.27119
trainer/Policy log std Std          0.397259
trainer/Policy log std Max         -0.576477
trainer/Policy log std Min         -2.82903
trainer/Alpha                       0.0621453
trainer/Alpha Loss                  0.356336
exploration/num steps total    238700
exploration/num paths total      2387
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.848696
exploration/Rewards Std             1.13851
exploration/Rewards Max            -0.00443803
exploration/Rewards Min            -9.44444
exploration/Returns Mean          -84.8696
exploration/Returns Std            47.6459
exploration/Returns Max           -17.4836
exploration/Returns Min          -138.172
exploration/Actions Mean           -0.00493303
exploration/Actions Std             0.24337
exploration/Actions Max             0.998147
exploration/Actions Min            -0.999204
exploration/Num Paths               5
exploration/Average Returns       -84.8696
evaluation/num steps total     715500
evaluation/num paths total       7155
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.871514
evaluation/Rewards Std              1.0146
evaluation/Rewards Max             -0.0159303
evaluation/Rewards Min            -10.9762
evaluation/Returns Mean           -87.1514
evaluation/Returns Std             75.3505
evaluation/Returns Max             -8.29554
evaluation/Returns Min           -237.202
evaluation/Actions Mean             0.00886573
evaluation/Actions Std              0.164906
evaluation/Actions Max              0.997983
evaluation/Actions Min             -0.996844
evaluation/Num Paths               15
evaluation/Average Returns        -87.1514
time/data storing (s)               0.00282275
time/evaluation sampling (s)        0.321665
time/exploration sampling (s)       0.134535
time/logging (s)                    0.00476589
time/saving (s)                     0.00194356
time/training (s)                   1.99023
time/epoch (s)                      2.45596
time/total (s)                   1171.62
Epoch                             476
-----------------------------  ---------------
2019-04-23 01:33:06.511953 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 477 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.211018
trainer/QF2 Loss                    0.203878
trainer/Policy Loss                39.5351
trainer/Q1 Predictions Mean       -37.5114
trainer/Q1 Predictions Std         35.8692
trainer/Q1 Predictions Max         -6.73384
trainer/Q1 Predictions Min       -140.367
trainer/Q2 Predictions Mean       -37.5038
trainer/Q2 Predictions Std         35.8405
trainer/Q2 Predictions Max         -6.72895
trainer/Q2 Predictions Min       -139.721
trainer/Q Targets Mean            -37.4689
trainer/Q Targets Std              35.8275
trainer/Q Targets Max              -6.52281
trainer/Q Targets Min            -138.765
trainer/Log Pis Mean                2.11115
trainer/Log Pis Std                 1.51597
trainer/Log Pis Max                 9.53987
trainer/Log Pis Min                -0.907199
trainer/Policy mu Mean              0.0194122
trainer/Policy mu Std               0.603409
trainer/Policy mu Max               4.15636
trainer/Policy mu Min              -3.43243
trainer/Policy log std Mean        -2.22895
trainer/Policy log std Std          0.434198
trainer/Policy log std Max         -0.13783
trainer/Policy log std Min         -3.12811
trainer/Alpha                       0.0629607
trainer/Alpha Loss                  0.307347
exploration/num steps total    239200
exploration/num paths total      2392
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.934742
exploration/Rewards Std             1.48708
exploration/Rewards Max            -0.0125699
exploration/Rewards Min           -10.9829
exploration/Returns Mean          -93.4742
exploration/Returns Std            71.8665
exploration/Returns Max           -17.3411
exploration/Returns Min          -230.423
exploration/Actions Mean            0.0109539
exploration/Actions Std             0.238995
exploration/Actions Max             0.99982
exploration/Actions Min            -0.999719
exploration/Num Paths               5
exploration/Average Returns       -93.4742
evaluation/num steps total     717000
evaluation/num paths total       7170
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.908911
evaluation/Rewards Std              1.20615
evaluation/Rewards Max             -0.0461053
evaluation/Rewards Min             -8.92979
evaluation/Returns Mean           -90.8911
evaluation/Returns Std             90.7649
evaluation/Returns Max             -8.59928
evaluation/Returns Min           -313.945
evaluation/Actions Mean             0.0134252
evaluation/Actions Std              0.174001
evaluation/Actions Max              0.998226
evaluation/Actions Min             -0.999121
evaluation/Num Paths               15
evaluation/Average Returns        -90.8911
time/data storing (s)               0.00274396
time/evaluation sampling (s)        0.331617
time/exploration sampling (s)       0.135795
time/logging (s)                    0.00477597
time/saving (s)                     0.00192545
time/training (s)                   1.96434
time/epoch (s)                      2.4412
time/total (s)                   1174.06
Epoch                             477
-----------------------------  ---------------
2019-04-23 01:33:08.988786 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 478 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   79.7988
trainer/QF2 Loss                   80.3902
trainer/Policy Loss                41.5202
trainer/Q1 Predictions Mean       -39.5298
trainer/Q1 Predictions Std         41.3889
trainer/Q1 Predictions Max         -6.42706
trainer/Q1 Predictions Min       -138.018
trainer/Q2 Predictions Mean       -39.5259
trainer/Q2 Predictions Std         41.4179
trainer/Q2 Predictions Max         -6.37873
trainer/Q2 Predictions Min       -137.904
trainer/Q Targets Mean            -38.6617
trainer/Q Targets Std              41.7328
trainer/Q Targets Max              -0.634367
trainer/Q Targets Min            -138.942
trainer/Log Pis Mean                2.04511
trainer/Log Pis Std                 0.962813
trainer/Log Pis Max                 3.48629
trainer/Log Pis Min                -1.31898
trainer/Policy mu Mean             -0.0366947
trainer/Policy mu Std               0.283465
trainer/Policy mu Max               0.804313
trainer/Policy mu Min              -2.21471
trainer/Policy log std Mean        -2.31952
trainer/Policy log std Std          0.274651
trainer/Policy log std Max         -0.8943
trainer/Policy log std Min         -2.99735
trainer/Alpha                       0.0637984
trainer/Alpha Loss                  0.12414
exploration/num steps total    239700
exploration/num paths total      2397
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.593083
exploration/Rewards Std             0.827672
exploration/Rewards Max            -0.0057188
exploration/Rewards Min            -7.41559
exploration/Returns Mean          -59.3083
exploration/Returns Std            29.9966
exploration/Returns Max           -21.5478
exploration/Returns Min          -104.606
exploration/Actions Mean           -0.00763567
exploration/Actions Std             0.202291
exploration/Actions Max             0.998185
exploration/Actions Min            -0.997305
exploration/Num Paths               5
exploration/Average Returns       -59.3083
evaluation/num steps total     718500
evaluation/num paths total       7185
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.526704
evaluation/Rewards Std              0.984164
evaluation/Rewards Max             -0.0146561
evaluation/Rewards Min             -9.75371
evaluation/Returns Mean           -52.6704
evaluation/Returns Std             52.4438
evaluation/Returns Max             -6.71739
evaluation/Returns Min           -204.367
evaluation/Actions Mean             0.00491811
evaluation/Actions Std              0.176765
evaluation/Actions Max              0.996919
evaluation/Actions Min             -0.998845
evaluation/Num Paths               15
evaluation/Average Returns        -52.6704
time/data storing (s)               0.00260769
time/evaluation sampling (s)        0.33186
time/exploration sampling (s)       0.137891
time/logging (s)                    0.00477676
time/saving (s)                     0.00196104
time/training (s)                   1.98647
time/epoch (s)                      2.46557
time/total (s)                   1176.53
Epoch                             478
-----------------------------  ---------------
2019-04-23 01:33:11.450414 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 479 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   18.3112
trainer/QF2 Loss                   18.247
trainer/Policy Loss                39.4624
trainer/Q1 Predictions Mean       -37.4965
trainer/Q1 Predictions Std         38.5575
trainer/Q1 Predictions Max         -6.38385
trainer/Q1 Predictions Min       -144.348
trainer/Q2 Predictions Mean       -37.4828
trainer/Q2 Predictions Std         38.547
trainer/Q2 Predictions Max         -6.43221
trainer/Q2 Predictions Min       -144.25
trainer/Q Targets Mean            -37.2265
trainer/Q Targets Std              38.8521
trainer/Q Targets Max              -0.919354
trainer/Q Targets Min            -143.936
trainer/Log Pis Mean                2.0504
trainer/Log Pis Std                 1.3859
trainer/Log Pis Max                 9.40586
trainer/Log Pis Min                -2.2431
trainer/Policy mu Mean              0.0544113
trainer/Policy mu Std               0.585352
trainer/Policy mu Max               3.5813
trainer/Policy mu Min              -1.99629
trainer/Policy log std Mean        -2.24429
trainer/Policy log std Std          0.424185
trainer/Policy log std Max         -0.380518
trainer/Policy log std Min         -2.99042
trainer/Alpha                       0.0660039
trainer/Alpha Loss                  0.137001
exploration/num steps total    240200
exploration/num paths total      2402
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.06916
exploration/Rewards Std             1.32547
exploration/Rewards Max            -0.00343683
exploration/Rewards Min            -8.76901
exploration/Returns Mean         -106.916
exploration/Returns Std            99.9743
exploration/Returns Max           -22.6692
exploration/Returns Min          -288.054
exploration/Actions Mean           -0.00736969
exploration/Actions Std             0.221217
exploration/Actions Max             0.998077
exploration/Actions Min            -0.997088
exploration/Num Paths               5
exploration/Average Returns      -106.916
evaluation/num steps total     720000
evaluation/num paths total       7200
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.855494
evaluation/Rewards Std              1.17023
evaluation/Rewards Max             -0.0436974
evaluation/Rewards Min             -9.82719
evaluation/Returns Mean           -85.5494
evaluation/Returns Std             65.7798
evaluation/Returns Max            -19.2239
evaluation/Returns Min           -211.653
evaluation/Actions Mean            -0.0119431
evaluation/Actions Std              0.199995
evaluation/Actions Max              0.997122
evaluation/Actions Min             -0.999688
evaluation/Num Paths               15
evaluation/Average Returns        -85.5494
time/data storing (s)               0.00256235
time/evaluation sampling (s)        0.323861
time/exploration sampling (s)       0.139556
time/logging (s)                    0.0048081
time/saving (s)                     0.00194364
time/training (s)                   1.97889
time/epoch (s)                      2.45162
time/total (s)                   1178.99
Epoch                             479
-----------------------------  ---------------
2019-04-23 01:33:13.971773 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 480 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   23.73
trainer/QF2 Loss                   23.4524
trainer/Policy Loss                40.6907
trainer/Q1 Predictions Mean       -38.7463
trainer/Q1 Predictions Std         37.9291
trainer/Q1 Predictions Max         -6.54264
trainer/Q1 Predictions Min       -139.232
trainer/Q2 Predictions Mean       -38.7357
trainer/Q2 Predictions Std         37.9123
trainer/Q2 Predictions Max         -6.5772
trainer/Q2 Predictions Min       -139.194
trainer/Q Targets Mean            -38.3594
trainer/Q Targets Std              38.0801
trainer/Q Targets Max              -0.972441
trainer/Q Targets Min            -139.713
trainer/Log Pis Mean                2.05926
trainer/Log Pis Std                 1.02268
trainer/Log Pis Max                 5.15219
trainer/Log Pis Min                -0.730652
trainer/Policy mu Mean             -0.0840289
trainer/Policy mu Std               0.526651
trainer/Policy mu Max               2.74281
trainer/Policy mu Min              -3.99778
trainer/Policy log std Mean        -2.24534
trainer/Policy log std Std          0.383975
trainer/Policy log std Max         -0.386808
trainer/Policy log std Min         -3.01718
trainer/Alpha                       0.0657091
trainer/Alpha Loss                  0.161345
exploration/num steps total    240700
exploration/num paths total      2407
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.390624
exploration/Rewards Std             0.880729
exploration/Rewards Max            -0.022148
exploration/Rewards Min            -7.57917
exploration/Returns Mean          -39.0624
exploration/Returns Std             9.29472
exploration/Returns Max           -22.5258
exploration/Returns Min           -50.4458
exploration/Actions Mean            0.011536
exploration/Actions Std             0.219634
exploration/Actions Max             0.997565
exploration/Actions Min            -0.999349
exploration/Num Paths               5
exploration/Average Returns       -39.0624
evaluation/num steps total     721500
evaluation/num paths total       7215
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.16051
evaluation/Rewards Std              1.44685
evaluation/Rewards Max             -0.0424764
evaluation/Rewards Min             -9.53206
evaluation/Returns Mean          -116.051
evaluation/Returns Std            116.703
evaluation/Returns Max             -8.42403
evaluation/Returns Min           -289.641
evaluation/Actions Mean            -0.00204848
evaluation/Actions Std              0.178894
evaluation/Actions Max              0.997351
evaluation/Actions Min             -0.997097
evaluation/Num Paths               15
evaluation/Average Returns       -116.051
time/data storing (s)               0.00264095
time/evaluation sampling (s)        0.336222
time/exploration sampling (s)       0.168247
time/logging (s)                    0.00480107
time/saving (s)                     0.0101105
time/training (s)                   1.9881
time/epoch (s)                      2.51012
time/total (s)                   1181.5
Epoch                             480
-----------------------------  ---------------
2019-04-23 01:33:16.453861 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 481 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                  183.03
trainer/QF2 Loss                  183.575
trainer/Policy Loss                37.4893
trainer/Q1 Predictions Mean       -35.5498
trainer/Q1 Predictions Std         40.8208
trainer/Q1 Predictions Max         -6.64056
trainer/Q1 Predictions Min       -166.77
trainer/Q2 Predictions Mean       -35.5611
trainer/Q2 Predictions Std         40.9373
trainer/Q2 Predictions Max         -6.57701
trainer/Q2 Predictions Min       -169.849
trainer/Q Targets Mean            -34.3402
trainer/Q Targets Std              39.7979
trainer/Q Targets Max              -2.86535
trainer/Q Targets Min            -169.49
trainer/Log Pis Mean                2.03813
trainer/Log Pis Std                 1.30763
trainer/Log Pis Max                 7.38244
trainer/Log Pis Min                -3.13912
trainer/Policy mu Mean             -0.0325992
trainer/Policy mu Std               0.537714
trainer/Policy mu Max               2.86049
trainer/Policy mu Min              -3.32121
trainer/Policy log std Mean        -2.2839
trainer/Policy log std Std          0.41981
trainer/Policy log std Max          0.0637556
trainer/Policy log std Min         -3.11677
trainer/Alpha                       0.0664349
trainer/Alpha Loss                  0.103378
exploration/num steps total    241200
exploration/num paths total      2412
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.554802
exploration/Rewards Std             1.07791
exploration/Rewards Max            -0.00199881
exploration/Rewards Min            -8.99217
exploration/Returns Mean          -55.4802
exploration/Returns Std            32.4582
exploration/Returns Max           -19.1912
exploration/Returns Min          -114.736
exploration/Actions Mean           -0.00428827
exploration/Actions Std             0.232001
exploration/Actions Max             0.997777
exploration/Actions Min            -0.998055
exploration/Num Paths               5
exploration/Average Returns       -55.4802
evaluation/num steps total     723000
evaluation/num paths total       7230
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.607117
evaluation/Rewards Std              0.904881
evaluation/Rewards Max             -0.02729
evaluation/Rewards Min             -7.93717
evaluation/Returns Mean           -60.7117
evaluation/Returns Std             46.5099
evaluation/Returns Max             -4.07432
evaluation/Returns Min           -200.854
evaluation/Actions Mean            -0.0010902
evaluation/Actions Std              0.16564
evaluation/Actions Max              0.997502
evaluation/Actions Min             -0.999432
evaluation/Num Paths               15
evaluation/Average Returns        -60.7117
time/data storing (s)               0.00259615
time/evaluation sampling (s)        0.329573
time/exploration sampling (s)       0.138257
time/logging (s)                    0.0048135
time/saving (s)                     0.0019279
time/training (s)                   1.99359
time/epoch (s)                      2.47076
time/total (s)                   1183.98
Epoch                             481
-----------------------------  ---------------
2019-04-23 01:33:18.927584 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 482 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.541703
trainer/QF2 Loss                    0.426139
trainer/Policy Loss                47.1637
trainer/Q1 Predictions Mean       -45.0551
trainer/Q1 Predictions Std         45.3817
trainer/Q1 Predictions Max         -6.44644
trainer/Q1 Predictions Min       -164.191
trainer/Q2 Predictions Mean       -45.0463
trainer/Q2 Predictions Std         45.4124
trainer/Q2 Predictions Max         -6.45429
trainer/Q2 Predictions Min       -166.486
trainer/Q Targets Mean            -45.3652
trainer/Q Targets Std              45.7911
trainer/Q Targets Max              -6.54859
trainer/Q Targets Min            -169.402
trainer/Log Pis Mean                2.19445
trainer/Log Pis Std                 1.41046
trainer/Log Pis Max                 8.24331
trainer/Log Pis Min                -1.08951
trainer/Policy mu Mean              0.0107189
trainer/Policy mu Std               0.625158
trainer/Policy mu Max               2.95826
trainer/Policy mu Min              -3.08877
trainer/Policy log std Mean        -2.23858
trainer/Policy log std Std          0.437515
trainer/Policy log std Max          0.0100812
trainer/Policy log std Min         -3.16552
trainer/Alpha                       0.0652134
trainer/Alpha Loss                  0.530883
exploration/num steps total    241700
exploration/num paths total      2417
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.948504
exploration/Rewards Std             0.782076
exploration/Rewards Max            -0.00205697
exploration/Rewards Min            -6.12693
exploration/Returns Mean          -94.8504
exploration/Returns Std            64.2159
exploration/Returns Max           -19.6062
exploration/Returns Min          -178.208
exploration/Actions Mean           -0.00511032
exploration/Actions Std             0.18727
exploration/Actions Max             0.973132
exploration/Actions Min            -0.99359
exploration/Num Paths               5
exploration/Average Returns       -94.8504
evaluation/num steps total     724500
evaluation/num paths total       7245
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.955423
evaluation/Rewards Std              1.28902
evaluation/Rewards Max             -0.0268797
evaluation/Rewards Min             -9.73163
evaluation/Returns Mean           -95.5423
evaluation/Returns Std            105.329
evaluation/Returns Max            -15.4488
evaluation/Returns Min           -335.918
evaluation/Actions Mean            -0.00241731
evaluation/Actions Std              0.1769
evaluation/Actions Max              0.998272
evaluation/Actions Min             -0.999098
evaluation/Num Paths               15
evaluation/Average Returns        -95.5423
time/data storing (s)               0.00288673
time/evaluation sampling (s)        0.333914
time/exploration sampling (s)       0.135681
time/logging (s)                    0.004839
time/saving (s)                     0.00193613
time/training (s)                   1.98436
time/epoch (s)                      2.46362
time/total (s)                   1186.44
Epoch                             482
-----------------------------  ---------------
2019-04-23 01:33:21.407306 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 483 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    9.24468
trainer/QF2 Loss                    8.69843
trainer/Policy Loss                46.4286
trainer/Q1 Predictions Mean       -44.3813
trainer/Q1 Predictions Std         40.5771
trainer/Q1 Predictions Max         -6.51954
trainer/Q1 Predictions Min       -160.412
trainer/Q2 Predictions Mean       -44.4161
trainer/Q2 Predictions Std         40.6938
trainer/Q2 Predictions Max         -6.47356
trainer/Q2 Predictions Min       -164.002
trainer/Q Targets Mean            -44.447
trainer/Q Targets Std              41.2425
trainer/Q Targets Max              -0.563058
trainer/Q Targets Min            -167.502
trainer/Log Pis Mean                2.13172
trainer/Log Pis Std                 1.05689
trainer/Log Pis Max                 7.35322
trainer/Log Pis Min                -1.07906
trainer/Policy mu Mean             -0.0282465
trainer/Policy mu Std               0.556211
trainer/Policy mu Max               3.13238
trainer/Policy mu Min              -2.94276
trainer/Policy log std Mean        -2.24171
trainer/Policy log std Std          0.424615
trainer/Policy log std Max         -0.475639
trainer/Policy log std Min         -2.96077
trainer/Alpha                       0.0638057
trainer/Alpha Loss                  0.362466
exploration/num steps total    242200
exploration/num paths total      2422
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.1156
exploration/Rewards Std             0.937273
exploration/Rewards Max            -0.0129717
exploration/Rewards Min            -7.43287
exploration/Returns Mean         -111.56
exploration/Returns Std            56.842
exploration/Returns Max           -20.1548
exploration/Returns Min          -195.173
exploration/Actions Mean            0.00980888
exploration/Actions Std             0.227599
exploration/Actions Max             0.996523
exploration/Actions Min            -0.990878
exploration/Num Paths               5
exploration/Average Returns      -111.56
evaluation/num steps total     726000
evaluation/num paths total       7260
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.679852
evaluation/Rewards Std              1.14517
evaluation/Rewards Max             -0.00285667
evaluation/Rewards Min             -9.47059
evaluation/Returns Mean           -67.9852
evaluation/Returns Std             73.6086
evaluation/Returns Max             -6.35896
evaluation/Returns Min           -290.042
evaluation/Actions Mean            -0.00948673
evaluation/Actions Std              0.19457
evaluation/Actions Max              0.997737
evaluation/Actions Min             -0.99848
evaluation/Num Paths               15
evaluation/Average Returns        -67.9852
time/data storing (s)               0.00287938
time/evaluation sampling (s)        0.328747
time/exploration sampling (s)       0.140919
time/logging (s)                    0.00484589
time/saving (s)                     0.00192515
time/training (s)                   1.98912
time/epoch (s)                      2.46843
time/total (s)                   1188.92
Epoch                             483
-----------------------------  ---------------
2019-04-23 01:33:23.868551 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 484 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                  182.763
trainer/QF2 Loss                  183.038
trainer/Policy Loss                44.1075
trainer/Q1 Predictions Mean       -42.0651
trainer/Q1 Predictions Std         39.8222
trainer/Q1 Predictions Max         -6.50663
trainer/Q1 Predictions Min       -138.848
trainer/Q2 Predictions Mean       -42.0833
trainer/Q2 Predictions Std         39.8278
trainer/Q2 Predictions Max         -6.44575
trainer/Q2 Predictions Min       -138.875
trainer/Q Targets Mean            -41.2324
trainer/Q Targets Std              39.1765
trainer/Q Targets Max              -2.60133
trainer/Q Targets Min            -140.25
trainer/Log Pis Mean                2.07916
trainer/Log Pis Std                 1.13116
trainer/Log Pis Max                 6.27301
trainer/Log Pis Min                -0.378965
trainer/Policy mu Mean             -0.053913
trainer/Policy mu Std               0.484369
trainer/Policy mu Max               2.36201
trainer/Policy mu Min              -2.89495
trainer/Policy log std Mean        -2.24639
trainer/Policy log std Std          0.377374
trainer/Policy log std Max         -0.510045
trainer/Policy log std Min         -3.15684
trainer/Alpha                       0.0635012
trainer/Alpha Loss                  0.218227
exploration/num steps total    242700
exploration/num paths total      2427
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.753271
exploration/Rewards Std             1.03238
exploration/Rewards Max            -0.0374691
exploration/Rewards Min            -8.9851
exploration/Returns Mean          -75.3271
exploration/Returns Std            18.486
exploration/Returns Max           -47.8332
exploration/Returns Min           -97.9714
exploration/Actions Mean            0.0195327
exploration/Actions Std             0.248931
exploration/Actions Max             0.999334
exploration/Actions Min            -0.996971
exploration/Num Paths               5
exploration/Average Returns       -75.3271
evaluation/num steps total     727500
evaluation/num paths total       7275
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.603158
evaluation/Rewards Std              1.21718
evaluation/Rewards Max             -0.0187286
evaluation/Rewards Min             -9.33581
evaluation/Returns Mean           -60.3158
evaluation/Returns Std             68.9473
evaluation/Returns Max             -6.59062
evaluation/Returns Min           -258.516
evaluation/Actions Mean            -0.00205271
evaluation/Actions Std              0.202232
evaluation/Actions Max              0.999653
evaluation/Actions Min             -0.999297
evaluation/Num Paths               15
evaluation/Average Returns        -60.3158
time/data storing (s)               0.00261079
time/evaluation sampling (s)        0.325995
time/exploration sampling (s)       0.140934
time/logging (s)                    0.00476923
time/saving (s)                     0.0016357
time/training (s)                   1.97526
time/epoch (s)                      2.45121
time/total (s)                   1191.37
Epoch                             484
-----------------------------  ---------------
2019-04-23 01:33:26.347822 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 485 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.845235
trainer/QF2 Loss                    0.809147
trainer/Policy Loss                39.4483
trainer/Q1 Predictions Mean       -37.4902
trainer/Q1 Predictions Std         39.3338
trainer/Q1 Predictions Max         -6.59887
trainer/Q1 Predictions Min       -154.793
trainer/Q2 Predictions Mean       -37.5278
trainer/Q2 Predictions Std         39.3597
trainer/Q2 Predictions Max         -6.56055
trainer/Q2 Predictions Min       -155.075
trainer/Q Targets Mean            -38.0239
trainer/Q Targets Std              39.8294
trainer/Q Targets Max              -6.55803
trainer/Q Targets Min            -154.927
trainer/Log Pis Mean                1.94965
trainer/Log Pis Std                 1.25065
trainer/Log Pis Max                 5.37301
trainer/Log Pis Min                -3.33848
trainer/Policy mu Mean              0.0139396
trainer/Policy mu Std               0.586249
trainer/Policy mu Max               2.93111
trainer/Policy mu Min              -2.83648
trainer/Policy log std Mean        -2.20784
trainer/Policy log std Std          0.408676
trainer/Policy log std Max         -0.620294
trainer/Policy log std Min         -3.09459
trainer/Alpha                       0.064183
trainer/Alpha Loss                 -0.138262
exploration/num steps total    243200
exploration/num paths total      2432
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.508912
exploration/Rewards Std             1.00258
exploration/Rewards Max            -0.00805226
exploration/Rewards Min            -9.25372
exploration/Returns Mean          -50.8912
exploration/Returns Std            40.3334
exploration/Returns Max           -20.8898
exploration/Returns Min          -129.997
exploration/Actions Mean            0.0120494
exploration/Actions Std             0.238249
exploration/Actions Max             0.998327
exploration/Actions Min            -0.999115
exploration/Num Paths               5
exploration/Average Returns       -50.8912
evaluation/num steps total     729000
evaluation/num paths total       7290
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.19086
evaluation/Rewards Std              0.98778
evaluation/Rewards Max             -0.0128526
evaluation/Rewards Min             -9.61077
evaluation/Returns Mean          -119.086
evaluation/Returns Std             77.2744
evaluation/Returns Max             -7.09697
evaluation/Returns Min           -293.26
evaluation/Actions Mean             0.0106667
evaluation/Actions Std              0.159083
evaluation/Actions Max              0.998057
evaluation/Actions Min             -0.99898
evaluation/Num Paths               15
evaluation/Average Returns       -119.086
time/data storing (s)               0.00265088
time/evaluation sampling (s)        0.33207
time/exploration sampling (s)       0.138166
time/logging (s)                    0.00484596
time/saving (s)                     0.00188828
time/training (s)                   1.98861
time/epoch (s)                      2.46823
time/total (s)                   1193.84
Epoch                             485
-----------------------------  ---------------
2019-04-23 01:33:28.815510 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 486 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.461
trainer/QF2 Loss                    0.466312
trainer/Policy Loss                41.6527
trainer/Q1 Predictions Mean       -39.9164
trainer/Q1 Predictions Std         36.8458
trainer/Q1 Predictions Max         -6.40668
trainer/Q1 Predictions Min       -138.058
trainer/Q2 Predictions Mean       -39.9115
trainer/Q2 Predictions Std         36.8641
trainer/Q2 Predictions Max         -6.37435
trainer/Q2 Predictions Min       -137.777
trainer/Q Targets Mean            -40.3581
trainer/Q Targets Std              37.2728
trainer/Q Targets Max              -6.50093
trainer/Q Targets Min            -139.195
trainer/Log Pis Mean                1.79735
trainer/Log Pis Std                 1.07396
trainer/Log Pis Max                 3.9454
trainer/Log Pis Min                -1.90054
trainer/Policy mu Mean              0.00678549
trainer/Policy mu Std               0.235396
trainer/Policy mu Max               0.483164
trainer/Policy mu Min              -1.53093
trainer/Policy log std Mean        -2.33266
trainer/Policy log std Std          0.290188
trainer/Policy log std Max         -1.18308
trainer/Policy log std Min         -3.26146
trainer/Alpha                       0.0630055
trainer/Alpha Loss                 -0.560184
exploration/num steps total    243700
exploration/num paths total      2437
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.23532
exploration/Rewards Std             1.18128
exploration/Rewards Max            -0.0254436
exploration/Rewards Min            -8.96594
exploration/Returns Mean         -123.532
exploration/Returns Std            61.8852
exploration/Returns Max           -35.4411
exploration/Returns Min          -196.865
exploration/Actions Mean           -0.0142226
exploration/Actions Std             0.222185
exploration/Actions Max             0.997959
exploration/Actions Min            -0.999595
exploration/Num Paths               5
exploration/Average Returns      -123.532
evaluation/num steps total     730500
evaluation/num paths total       7305
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.607188
evaluation/Rewards Std              0.929414
evaluation/Rewards Max             -0.0192975
evaluation/Rewards Min             -9.91125
evaluation/Returns Mean           -60.7188
evaluation/Returns Std             44.6131
evaluation/Returns Max            -13.9236
evaluation/Returns Min           -179.928
evaluation/Actions Mean             0.0109739
evaluation/Actions Std              0.185913
evaluation/Actions Max              0.999472
evaluation/Actions Min             -0.997473
evaluation/Num Paths               15
evaluation/Average Returns        -60.7188
time/data storing (s)               0.0026795
time/evaluation sampling (s)        0.321503
time/exploration sampling (s)       0.140245
time/logging (s)                    0.00476862
time/saving (s)                     0.00193086
time/training (s)                   1.98513
time/epoch (s)                      2.45626
time/total (s)                   1196.3
Epoch                             486
-----------------------------  ---------------
2019-04-23 01:33:31.271808 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 487 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.403729
trainer/QF2 Loss                    0.441249
trainer/Policy Loss                41.7302
trainer/Q1 Predictions Mean       -39.8764
trainer/Q1 Predictions Std         40.4397
trainer/Q1 Predictions Max         -6.42164
trainer/Q1 Predictions Min       -137.004
trainer/Q2 Predictions Mean       -39.859
trainer/Q2 Predictions Std         40.4355
trainer/Q2 Predictions Max         -6.41987
trainer/Q2 Predictions Min       -137.153
trainer/Q Targets Mean            -40.155
trainer/Q Targets Std              40.8914
trainer/Q Targets Max              -6.45092
trainer/Q Targets Min            -139.568
trainer/Log Pis Mean                1.961
trainer/Log Pis Std                 1.06342
trainer/Log Pis Max                 4.12011
trainer/Log Pis Min                -2.38366
trainer/Policy mu Mean             -0.0289182
trainer/Policy mu Std               0.349779
trainer/Policy mu Max               2.90233
trainer/Policy mu Min              -2.31762
trainer/Policy log std Mean        -2.29931
trainer/Policy log std Std          0.314867
trainer/Policy log std Max         -0.840337
trainer/Policy log std Min         -3.23482
trainer/Alpha                       0.0620033
trainer/Alpha Loss                 -0.108456
exploration/num steps total    244200
exploration/num paths total      2442
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.15176
exploration/Rewards Std             1.43266
exploration/Rewards Max            -0.00924724
exploration/Rewards Min           -10.0145
exploration/Returns Mean         -115.176
exploration/Returns Std           117.45
exploration/Returns Max           -13.0755
exploration/Returns Min          -320.41
exploration/Actions Mean           -0.0387052
exploration/Actions Std             0.241754
exploration/Actions Max             0.990389
exploration/Actions Min            -0.999002
exploration/Num Paths               5
exploration/Average Returns      -115.176
evaluation/num steps total     732000
evaluation/num paths total       7320
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.01043
evaluation/Rewards Std              1.37318
evaluation/Rewards Max             -0.0205187
evaluation/Rewards Min            -11.1719
evaluation/Returns Mean          -101.043
evaluation/Returns Std             97.5392
evaluation/Returns Max            -24.6685
evaluation/Returns Min           -317.737
evaluation/Actions Mean             0.0137951
evaluation/Actions Std              0.195422
evaluation/Actions Max              0.999089
evaluation/Actions Min             -0.997488
evaluation/Num Paths               15
evaluation/Average Returns       -101.043
time/data storing (s)               0.00270167
time/evaluation sampling (s)        0.329897
time/exploration sampling (s)       0.141321
time/logging (s)                    0.00476175
time/saving (s)                     0.00193818
time/training (s)                   1.96514
time/epoch (s)                      2.44576
time/total (s)                   1198.76
Epoch                             487
-----------------------------  ---------------
2019-04-23 01:33:33.805811 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 488 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   71.5587
trainer/QF2 Loss                   71.3218
trainer/Policy Loss                35.924
trainer/Q1 Predictions Mean       -34.1517
trainer/Q1 Predictions Std         35.7799
trainer/Q1 Predictions Max         -6.52811
trainer/Q1 Predictions Min       -137.499
trainer/Q2 Predictions Mean       -34.1447
trainer/Q2 Predictions Std         35.8199
trainer/Q2 Predictions Max         -6.53462
trainer/Q2 Predictions Min       -137.538
trainer/Q Targets Mean            -33.6309
trainer/Q Targets Std              36.134
trainer/Q Targets Max              -0.113883
trainer/Q Targets Min            -139.468
trainer/Log Pis Mean                1.8355
trainer/Log Pis Std                 1.12116
trainer/Log Pis Max                 5.56432
trainer/Log Pis Min                -1.01525
trainer/Policy mu Mean             -0.0259659
trainer/Policy mu Std               0.462966
trainer/Policy mu Max               3.29335
trainer/Policy mu Min              -2.77929
trainer/Policy log std Mean        -2.21101
trainer/Policy log std Std          0.343278
trainer/Policy log std Max         -0.439091
trainer/Policy log std Min         -2.95671
trainer/Alpha                       0.0616312
trainer/Alpha Loss                 -0.458372
exploration/num steps total    244700
exploration/num paths total      2447
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.28393
exploration/Rewards Std             1.59042
exploration/Rewards Max            -0.0205335
exploration/Rewards Min            -8.58967
exploration/Returns Mean         -128.393
exploration/Returns Std           139.693
exploration/Returns Max           -22.5956
exploration/Returns Min          -402.416
exploration/Actions Mean           -0.0286492
exploration/Actions Std             0.242404
exploration/Actions Max             0.794915
exploration/Actions Min            -0.997291
exploration/Num Paths               5
exploration/Average Returns      -128.393
evaluation/num steps total     733500
evaluation/num paths total       7335
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.740569
evaluation/Rewards Std              1.07381
evaluation/Rewards Max             -0.0266943
evaluation/Rewards Min            -11.356
evaluation/Returns Mean           -74.0569
evaluation/Returns Std             58.1985
evaluation/Returns Max            -15.9023
evaluation/Returns Min           -214.888
evaluation/Actions Mean            -0.00448482
evaluation/Actions Std              0.180569
evaluation/Actions Max              0.99825
evaluation/Actions Min             -0.998608
evaluation/Num Paths               15
evaluation/Average Returns        -74.0569
time/data storing (s)               0.00319405
time/evaluation sampling (s)        0.360359
time/exploration sampling (s)       0.175533
time/logging (s)                    0.00477639
time/saving (s)                     0.00194649
time/training (s)                   1.9777
time/epoch (s)                      2.52351
time/total (s)                   1201.28
Epoch                             488
-----------------------------  ---------------
2019-04-23 01:33:36.312691 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 489 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   71.433
trainer/QF2 Loss                   71.6838
trainer/Policy Loss                41.9134
trainer/Q1 Predictions Mean       -39.8359
trainer/Q1 Predictions Std         38.2844
trainer/Q1 Predictions Max         -6.44425
trainer/Q1 Predictions Min       -140.28
trainer/Q2 Predictions Mean       -39.8075
trainer/Q2 Predictions Std         38.2698
trainer/Q2 Predictions Max         -6.4296
trainer/Q2 Predictions Min       -139.763
trainer/Q Targets Mean            -39.5446
trainer/Q Targets Std              38.8902
trainer/Q Targets Max              -0.158687
trainer/Q Targets Min            -142.097
trainer/Log Pis Mean                2.1424
trainer/Log Pis Std                 1.46104
trainer/Log Pis Max                10.2552
trainer/Log Pis Min                -0.10783
trainer/Policy mu Mean              0.0302172
trainer/Policy mu Std               0.664758
trainer/Policy mu Max               3.55098
trainer/Policy mu Min              -3.69687
trainer/Policy log std Mean        -2.14306
trainer/Policy log std Std          0.43292
trainer/Policy log std Max         -0.33405
trainer/Policy log std Min         -3.06115
trainer/Alpha                       0.0604246
trainer/Alpha Loss                  0.399621
exploration/num steps total    245200
exploration/num paths total      2452
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.04317
exploration/Rewards Std             1.43379
exploration/Rewards Max            -0.0145078
exploration/Rewards Min            -9.92474
exploration/Returns Mean         -104.317
exploration/Returns Std           114.265
exploration/Returns Max           -18.851
exploration/Returns Min          -326.577
exploration/Actions Mean           -0.00537248
exploration/Actions Std             0.216882
exploration/Actions Max             0.998772
exploration/Actions Min            -0.99546
exploration/Num Paths               5
exploration/Average Returns      -104.317
evaluation/num steps total     735000
evaluation/num paths total       7350
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.07853
evaluation/Rewards Std              1.34415
evaluation/Rewards Max             -0.0208586
evaluation/Rewards Min             -9.89582
evaluation/Returns Mean          -107.853
evaluation/Returns Std             92.3543
evaluation/Returns Max            -12.7594
evaluation/Returns Min           -310.743
evaluation/Actions Mean            -0.00503538
evaluation/Actions Std              0.184107
evaluation/Actions Max              0.998709
evaluation/Actions Min             -0.999261
evaluation/Num Paths               15
evaluation/Average Returns       -107.853
time/data storing (s)               0.00276156
time/evaluation sampling (s)        0.320284
time/exploration sampling (s)       0.141867
time/logging (s)                    0.00479447
time/saving (s)                     0.00155877
time/training (s)                   2.0242
time/epoch (s)                      2.49547
time/total (s)                   1203.78
Epoch                             489
-----------------------------  ---------------
2019-04-23 01:33:38.824471 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 490 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   37.7037
trainer/QF2 Loss                   37.9505
trainer/Policy Loss                37.0674
trainer/Q1 Predictions Mean       -34.917
trainer/Q1 Predictions Std         36.5832
trainer/Q1 Predictions Max         -6.41434
trainer/Q1 Predictions Min       -141.345
trainer/Q2 Predictions Mean       -34.9477
trainer/Q2 Predictions Std         36.6475
trainer/Q2 Predictions Max         -6.37824
trainer/Q2 Predictions Min       -141.832
trainer/Q Targets Mean            -34.4278
trainer/Q Targets Std              36.9456
trainer/Q Targets Max              -0.212917
trainer/Q Targets Min            -141.143
trainer/Log Pis Mean                2.17906
trainer/Log Pis Std                 1.23959
trainer/Log Pis Max                 7.44224
trainer/Log Pis Min                -2.42608
trainer/Policy mu Mean             -0.0311821
trainer/Policy mu Std               0.569203
trainer/Policy mu Max               2.77225
trainer/Policy mu Min              -3.15338
trainer/Policy log std Mean        -2.26559
trainer/Policy log std Std          0.452026
trainer/Policy log std Max         -0.12813
trainer/Policy log std Min         -3.25051
trainer/Alpha                       0.0604974
trainer/Alpha Loss                  0.502341
exploration/num steps total    245700
exploration/num paths total      2457
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.570952
exploration/Rewards Std             0.97022
exploration/Rewards Max            -0.00681923
exploration/Rewards Min            -7.65789
exploration/Returns Mean          -57.0952
exploration/Returns Std            20.0488
exploration/Returns Max           -35.8832
exploration/Returns Min           -86.1706
exploration/Actions Mean            0.0154113
exploration/Actions Std             0.230902
exploration/Actions Max             0.998697
exploration/Actions Min            -0.994677
exploration/Num Paths               5
exploration/Average Returns       -57.0952
evaluation/num steps total     736500
evaluation/num paths total       7365
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.902879
evaluation/Rewards Std              1.15044
evaluation/Rewards Max             -0.0413499
evaluation/Rewards Min             -9.57454
evaluation/Returns Mean           -90.2879
evaluation/Returns Std             78.23
evaluation/Returns Max            -12.0272
evaluation/Returns Min           -302.5
evaluation/Actions Mean            -0.0152007
evaluation/Actions Std              0.175857
evaluation/Actions Max              0.994815
evaluation/Actions Min             -0.999577
evaluation/Num Paths               15
evaluation/Average Returns        -90.2879
time/data storing (s)               0.00265034
time/evaluation sampling (s)        0.325804
time/exploration sampling (s)       0.146549
time/logging (s)                    0.00476558
time/saving (s)                     0.00192056
time/training (s)                   2.01861
time/epoch (s)                      2.5003
time/total (s)                   1206.29
Epoch                             490
-----------------------------  ---------------
2019-04-23 01:33:41.304523 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 491 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                  112.052
trainer/QF2 Loss                  110.804
trainer/Policy Loss                37.9401
trainer/Q1 Predictions Mean       -36.2587
trainer/Q1 Predictions Std         37.5395
trainer/Q1 Predictions Max         -6.32882
trainer/Q1 Predictions Min       -139.347
trainer/Q2 Predictions Mean       -36.2373
trainer/Q2 Predictions Std         37.4873
trainer/Q2 Predictions Max         -6.35729
trainer/Q2 Predictions Min       -139.533
trainer/Q Targets Mean            -34.7689
trainer/Q Targets Std              37.6522
trainer/Q Targets Max              -0.0453656
trainer/Q Targets Min            -139.117
trainer/Log Pis Mean                1.80725
trainer/Log Pis Std                 1.1927
trainer/Log Pis Max                 4.31407
trainer/Log Pis Min                -5.69261
trainer/Policy mu Mean             -0.0640077
trainer/Policy mu Std               0.281761
trainer/Policy mu Max               2.06899
trainer/Policy mu Min              -1.44595
trainer/Policy log std Mean        -2.26576
trainer/Policy log std Std          0.328074
trainer/Policy log std Max         -0.762988
trainer/Policy log std Min         -3.28628
trainer/Alpha                       0.0623037
trainer/Alpha Loss                 -0.534996
exploration/num steps total    246200
exploration/num paths total      2462
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -2.14224
exploration/Rewards Std             0.79043
exploration/Rewards Max            -0.775846
exploration/Rewards Min            -7.84775
exploration/Returns Mean         -214.224
exploration/Returns Std            70.6494
exploration/Returns Max          -125.635
exploration/Returns Min          -304.351
exploration/Actions Mean            0.00369815
exploration/Actions Std             0.190874
exploration/Actions Max             0.962789
exploration/Actions Min            -0.990058
exploration/Num Paths               5
exploration/Average Returns      -214.224
evaluation/num steps total     738000
evaluation/num paths total       7380
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.10567
evaluation/Rewards Std              1.27428
evaluation/Rewards Max             -0.00752506
evaluation/Rewards Min            -10.2484
evaluation/Returns Mean          -110.567
evaluation/Returns Std             92.8988
evaluation/Returns Max             -7.47358
evaluation/Returns Min           -312.818
evaluation/Actions Mean            -0.00856601
evaluation/Actions Std              0.177947
evaluation/Actions Max              0.999607
evaluation/Actions Min             -0.999812
evaluation/Num Paths               15
evaluation/Average Returns       -110.567
time/data storing (s)               0.00281874
time/evaluation sampling (s)        0.331254
time/exploration sampling (s)       0.140413
time/logging (s)                    0.00435437
time/saving (s)                     0.00191589
time/training (s)                   1.9875
time/epoch (s)                      2.46825
time/total (s)                   1208.76
Epoch                             491
-----------------------------  ---------------
2019-04-23 01:33:43.768279 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 492 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.208214
trainer/QF2 Loss                    0.261088
trainer/Policy Loss                44.0062
trainer/Q1 Predictions Mean       -41.9292
trainer/Q1 Predictions Std         40.4833
trainer/Q1 Predictions Max         -6.33099
trainer/Q1 Predictions Min       -138.423
trainer/Q2 Predictions Mean       -41.9112
trainer/Q2 Predictions Std         40.4485
trainer/Q2 Predictions Max         -6.34017
trainer/Q2 Predictions Min       -138.399
trainer/Q Targets Mean            -41.969
trainer/Q Targets Std              40.6278
trainer/Q Targets Max              -6.50812
trainer/Q Targets Min            -138.959
trainer/Log Pis Mean                2.29048
trainer/Log Pis Std                 0.968028
trainer/Log Pis Max                 5.73104
trainer/Log Pis Min                -1.10379
trainer/Policy mu Mean             -0.106091
trainer/Policy mu Std               0.511598
trainer/Policy mu Max               3.02284
trainer/Policy mu Min              -3.09316
trainer/Policy log std Mean        -2.2744
trainer/Policy log std Std          0.412511
trainer/Policy log std Max         -0.433427
trainer/Policy log std Min         -3.2884
trainer/Alpha                       0.0620798
trainer/Alpha Loss                  0.807322
exploration/num steps total    246700
exploration/num paths total      2467
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.847422
exploration/Rewards Std             1.05194
exploration/Rewards Max            -0.012957
exploration/Rewards Min           -10.5142
exploration/Returns Mean          -84.7422
exploration/Returns Std            65.234
exploration/Returns Max           -12.1159
exploration/Returns Min          -193.185
exploration/Actions Mean           -0.000218915
exploration/Actions Std             0.186394
exploration/Actions Max             0.997786
exploration/Actions Min            -0.998944
exploration/Num Paths               5
exploration/Average Returns       -84.7422
evaluation/num steps total     739500
evaluation/num paths total       7395
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.985942
evaluation/Rewards Std              1.25649
evaluation/Rewards Max             -0.0493896
evaluation/Rewards Min            -10.8898
evaluation/Returns Mean           -98.5942
evaluation/Returns Std             98.3461
evaluation/Returns Max             -7.74078
evaluation/Returns Min           -311.129
evaluation/Actions Mean            -0.00780869
evaluation/Actions Std              0.168717
evaluation/Actions Max              0.991429
evaluation/Actions Min             -0.998424
evaluation/Num Paths               15
evaluation/Average Returns        -98.5942
time/data storing (s)               0.00340666
time/evaluation sampling (s)        0.317738
time/exploration sampling (s)       0.143264
time/logging (s)                    0.0047608
time/saving (s)                     0.00974416
time/training (s)                   1.97407
time/epoch (s)                      2.45299
time/total (s)                   1211.22
Epoch                             492
-----------------------------  ----------------
2019-04-23 01:33:46.210118 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 493 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   49.6164
trainer/QF2 Loss                   50.0477
trainer/Policy Loss                39.5464
trainer/Q1 Predictions Mean       -37.6659
trainer/Q1 Predictions Std         37.335
trainer/Q1 Predictions Max         -6.79811
trainer/Q1 Predictions Min       -137.491
trainer/Q2 Predictions Mean       -37.6653
trainer/Q2 Predictions Std         37.3298
trainer/Q2 Predictions Max         -6.69812
trainer/Q2 Predictions Min       -137.51
trainer/Q Targets Mean            -37.2706
trainer/Q Targets Std              37.6285
trainer/Q Targets Max              -1.77594
trainer/Q Targets Min            -139.343
trainer/Log Pis Mean                2.08598
trainer/Log Pis Std                 1.00968
trainer/Log Pis Max                 5.29783
trainer/Log Pis Min                -2.90847
trainer/Policy mu Mean             -0.054139
trainer/Policy mu Std               0.412016
trainer/Policy mu Max               2.94956
trainer/Policy mu Min              -1.53043
trainer/Policy log std Mean        -2.24755
trainer/Policy log std Std          0.358054
trainer/Policy log std Max         -0.726278
trainer/Policy log std Min         -3.08506
trainer/Alpha                       0.0620105
trainer/Alpha Loss                  0.239052
exploration/num steps total    247200
exploration/num paths total      2472
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.525889
exploration/Rewards Std             1.18574
exploration/Rewards Max            -0.0136936
exploration/Rewards Min            -8.25935
exploration/Returns Mean          -52.5889
exploration/Returns Std            16.9846
exploration/Returns Max           -23.6986
exploration/Returns Min           -75.8212
exploration/Actions Mean           -0.00816401
exploration/Actions Std             0.245614
exploration/Actions Max             0.999098
exploration/Actions Min            -0.999833
exploration/Num Paths               5
exploration/Average Returns       -52.5889
evaluation/num steps total     741000
evaluation/num paths total       7410
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.913222
evaluation/Rewards Std              1.13266
evaluation/Rewards Max             -0.0118373
evaluation/Rewards Min            -10.4492
evaluation/Returns Mean           -91.3222
evaluation/Returns Std             57.7608
evaluation/Returns Max             -9.49556
evaluation/Returns Min           -200.046
evaluation/Actions Mean             0.00829237
evaluation/Actions Std              0.189605
evaluation/Actions Max              0.999455
evaluation/Actions Min             -0.999508
evaluation/Num Paths               15
evaluation/Average Returns        -91.3222
time/data storing (s)               0.00260759
time/evaluation sampling (s)        0.32058
time/exploration sampling (s)       0.137803
time/logging (s)                    0.00476724
time/saving (s)                     0.00192809
time/training (s)                   1.96279
time/epoch (s)                      2.43048
time/total (s)                   1213.65
Epoch                             493
-----------------------------  ---------------
2019-04-23 01:33:48.656645 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 494 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.822355
trainer/QF2 Loss                    0.846866
trainer/Policy Loss                43.4743
trainer/Q1 Predictions Mean       -41.5932
trainer/Q1 Predictions Std         39.046
trainer/Q1 Predictions Max         -6.48104
trainer/Q1 Predictions Min       -141.197
trainer/Q2 Predictions Mean       -41.5668
trainer/Q2 Predictions Std         39.0417
trainer/Q2 Predictions Max         -6.43545
trainer/Q2 Predictions Min       -140.894
trainer/Q Targets Mean            -42.1493
trainer/Q Targets Std              39.6311
trainer/Q Targets Max              -6.46692
trainer/Q Targets Min            -143.57
trainer/Log Pis Mean                2.01059
trainer/Log Pis Std                 1.33288
trainer/Log Pis Max                 7.11627
trainer/Log Pis Min                -2.38235
trainer/Policy mu Mean              0.0242417
trainer/Policy mu Std               0.601557
trainer/Policy mu Max               3.34198
trainer/Policy mu Min              -3.06757
trainer/Policy log std Mean        -2.22803
trainer/Policy log std Std          0.44814
trainer/Policy log std Max         -0.418884
trainer/Policy log std Min         -3.15477
trainer/Alpha                       0.0602855
trainer/Alpha Loss                  0.0297329
exploration/num steps total    247700
exploration/num paths total      2477
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.735941
exploration/Rewards Std             1.18939
exploration/Rewards Max            -0.0110086
exploration/Rewards Min            -8.23365
exploration/Returns Mean          -73.5941
exploration/Returns Std            51.6972
exploration/Returns Max           -39.3943
exploration/Returns Min          -176.488
exploration/Actions Mean            0.0047067
exploration/Actions Std             0.236501
exploration/Actions Max             0.998108
exploration/Actions Min            -0.999718
exploration/Num Paths               5
exploration/Average Returns       -73.5941
evaluation/num steps total     742500
evaluation/num paths total       7425
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.606276
evaluation/Rewards Std              1.05947
evaluation/Rewards Max             -0.0336385
evaluation/Rewards Min             -8.21313
evaluation/Returns Mean           -60.6276
evaluation/Returns Std             69.2063
evaluation/Returns Max            -10.8584
evaluation/Returns Min           -300.986
evaluation/Actions Mean            -0.0166431
evaluation/Actions Std              0.177897
evaluation/Actions Max              0.997658
evaluation/Actions Min             -0.99891
evaluation/Num Paths               15
evaluation/Average Returns        -60.6276
time/data storing (s)               0.00274796
time/evaluation sampling (s)        0.32356
time/exploration sampling (s)       0.134663
time/logging (s)                    0.00475975
time/saving (s)                     0.00191206
time/training (s)                   1.96747
time/epoch (s)                      2.43511
time/total (s)                   1216.09
Epoch                             494
-----------------------------  ---------------
2019-04-23 01:33:51.091342 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 495 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.469087
trainer/QF2 Loss                    0.536514
trainer/Policy Loss                37.685
trainer/Q1 Predictions Mean       -36.0536
trainer/Q1 Predictions Std         38.0445
trainer/Q1 Predictions Max         -6.63364
trainer/Q1 Predictions Min       -138.774
trainer/Q2 Predictions Mean       -36.0217
trainer/Q2 Predictions Std         38.0378
trainer/Q2 Predictions Max         -6.59745
trainer/Q2 Predictions Min       -138.383
trainer/Q Targets Mean            -36.4315
trainer/Q Targets Std              38.4489
trainer/Q Targets Max              -6.62788
trainer/Q Targets Min            -140.648
trainer/Log Pis Mean                1.7425
trainer/Log Pis Std                 1.29914
trainer/Log Pis Max                 7.47598
trainer/Log Pis Min                -2.93352
trainer/Policy mu Mean             -0.0464369
trainer/Policy mu Std               0.441189
trainer/Policy mu Max               2.56441
trainer/Policy mu Min              -2.07677
trainer/Policy log std Mean        -2.21861
trainer/Policy log std Std          0.373617
trainer/Policy log std Max         -0.749628
trainer/Policy log std Min         -3.04751
trainer/Alpha                       0.0628332
trainer/Alpha Loss                 -0.712568
exploration/num steps total    248200
exploration/num paths total      2482
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.44049
exploration/Rewards Std             1.31058
exploration/Rewards Max            -0.00969359
exploration/Rewards Min            -9.78669
exploration/Returns Mean         -144.049
exploration/Returns Std            95.28
exploration/Returns Max           -26.7235
exploration/Returns Min          -308.151
exploration/Actions Mean           -0.00132214
exploration/Actions Std             0.209574
exploration/Actions Max             0.998674
exploration/Actions Min            -0.997773
exploration/Num Paths               5
exploration/Average Returns      -144.049
evaluation/num steps total     744000
evaluation/num paths total       7440
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.529324
evaluation/Rewards Std              0.903269
evaluation/Rewards Max             -0.017807
evaluation/Rewards Min             -8.63932
evaluation/Returns Mean           -52.9324
evaluation/Returns Std             41.7938
evaluation/Returns Max            -12.9512
evaluation/Returns Min           -178.835
evaluation/Actions Mean             0.0197074
evaluation/Actions Std              0.171918
evaluation/Actions Max              0.997953
evaluation/Actions Min             -0.997061
evaluation/Num Paths               15
evaluation/Average Returns        -52.9324
time/data storing (s)               0.00273409
time/evaluation sampling (s)        0.315936
time/exploration sampling (s)       0.136365
time/logging (s)                    0.00480358
time/saving (s)                     0.00194319
time/training (s)                   1.96154
time/epoch (s)                      2.42332
time/total (s)                   1218.52
Epoch                             495
-----------------------------  ---------------
2019-04-23 01:33:53.522735 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 496 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.341795
trainer/QF2 Loss                    0.382147
trainer/Policy Loss                38.0932
trainer/Q1 Predictions Mean       -36.074
trainer/Q1 Predictions Std         37.0905
trainer/Q1 Predictions Max         -6.39286
trainer/Q1 Predictions Min       -135.819
trainer/Q2 Predictions Mean       -36.0598
trainer/Q2 Predictions Std         37.0523
trainer/Q2 Predictions Max         -6.41056
trainer/Q2 Predictions Min       -135.612
trainer/Q Targets Mean            -36.3798
trainer/Q Targets Std              37.4739
trainer/Q Targets Max              -6.41576
trainer/Q Targets Min            -137.17
trainer/Log Pis Mean                2.08821
trainer/Log Pis Std                 0.900323
trainer/Log Pis Max                 4.11985
trainer/Log Pis Min                -1.34489
trainer/Policy mu Mean             -0.0285749
trainer/Policy mu Std               0.369972
trainer/Policy mu Max               2.46486
trainer/Policy mu Min              -1.78326
trainer/Policy log std Mean        -2.29666
trainer/Policy log std Std          0.333696
trainer/Policy log std Max         -0.613152
trainer/Policy log std Min         -3.20607
trainer/Alpha                       0.0642263
trainer/Alpha Loss                  0.242172
exploration/num steps total    248700
exploration/num paths total      2487
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.832683
exploration/Rewards Std             0.83784
exploration/Rewards Max            -0.0132714
exploration/Rewards Min            -7.00868
exploration/Returns Mean          -83.2683
exploration/Returns Std            45.3694
exploration/Returns Max           -43.1199
exploration/Returns Min          -153.4
exploration/Actions Mean            0.000807396
exploration/Actions Std             0.220565
exploration/Actions Max             0.999186
exploration/Actions Min            -0.997083
exploration/Num Paths               5
exploration/Average Returns       -83.2683
evaluation/num steps total     745500
evaluation/num paths total       7455
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.832607
evaluation/Rewards Std              1.22763
evaluation/Rewards Max             -0.0133327
evaluation/Rewards Min            -10.0375
evaluation/Returns Mean           -83.2607
evaluation/Returns Std             69.1205
evaluation/Returns Max            -11.7218
evaluation/Returns Min           -284.201
evaluation/Actions Mean             0.00342003
evaluation/Actions Std              0.186779
evaluation/Actions Max              0.998826
evaluation/Actions Min             -0.998876
evaluation/Num Paths               15
evaluation/Average Returns        -83.2607
time/data storing (s)               0.00274649
time/evaluation sampling (s)        0.314655
time/exploration sampling (s)       0.14192
time/logging (s)                    0.00472392
time/saving (s)                     0.00190757
time/training (s)                   1.95385
time/epoch (s)                      2.41981
time/total (s)                   1220.95
Epoch                             496
-----------------------------  ----------------
2019-04-23 01:33:55.965821 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 497 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.331046
trainer/QF2 Loss                    0.301773
trainer/Policy Loss                37.5098
trainer/Q1 Predictions Mean       -35.4532
trainer/Q1 Predictions Std         40.7355
trainer/Q1 Predictions Max         -6.29756
trainer/Q1 Predictions Min       -137.05
trainer/Q2 Predictions Mean       -35.4786
trainer/Q2 Predictions Std         40.758
trainer/Q2 Predictions Max         -6.32564
trainer/Q2 Predictions Min       -136.975
trainer/Q Targets Mean            -35.7071
trainer/Q Targets Std              40.876
trainer/Q Targets Max              -6.39513
trainer/Q Targets Min            -137.765
trainer/Log Pis Mean                2.10065
trainer/Log Pis Std                 1.09128
trainer/Log Pis Max                 7.55998
trainer/Log Pis Min                -0.00291288
trainer/Policy mu Mean             -0.0291745
trainer/Policy mu Std               0.67617
trainer/Policy mu Max               3.30343
trainer/Policy mu Min              -3.37145
trainer/Policy log std Mean        -2.17952
trainer/Policy log std Std          0.482689
trainer/Policy log std Max         -0.367851
trainer/Policy log std Min         -3.07017
trainer/Alpha                       0.0624327
trainer/Alpha Loss                  0.279145
exploration/num steps total    249200
exploration/num paths total      2492
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.605866
exploration/Rewards Std             1.09713
exploration/Rewards Max            -0.00699732
exploration/Rewards Min            -9.28314
exploration/Returns Mean          -60.5866
exploration/Returns Std            42.0742
exploration/Returns Max           -12.0493
exploration/Returns Min          -111.367
exploration/Actions Mean            0.00725367
exploration/Actions Std             0.214156
exploration/Actions Max             0.999615
exploration/Actions Min            -0.998767
exploration/Num Paths               5
exploration/Average Returns       -60.5866
evaluation/num steps total     747000
evaluation/num paths total       7470
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.607601
evaluation/Rewards Std              1.03963
evaluation/Rewards Max             -0.0152297
evaluation/Rewards Min             -8.64639
evaluation/Returns Mean           -60.7601
evaluation/Returns Std             73.6479
evaluation/Returns Max            -13.6694
evaluation/Returns Min           -269.625
evaluation/Actions Mean             0.00302734
evaluation/Actions Std              0.179936
evaluation/Actions Max              0.998127
evaluation/Actions Min             -0.997936
evaluation/Num Paths               15
evaluation/Average Returns        -60.7601
time/data storing (s)               0.00280238
time/evaluation sampling (s)        0.322539
time/exploration sampling (s)       0.137799
time/logging (s)                    0.00482201
time/saving (s)                     0.0019517
time/training (s)                   1.96182
time/epoch (s)                      2.43173
time/total (s)                   1223.38
Epoch                             497
-----------------------------  ---------------
2019-04-23 01:33:58.408595 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 498 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.04589
trainer/QF2 Loss                    1.04325
trainer/Policy Loss                38.7696
trainer/Q1 Predictions Mean       -37.099
trainer/Q1 Predictions Std         37.2805
trainer/Q1 Predictions Max         -6.53346
trainer/Q1 Predictions Min       -137.385
trainer/Q2 Predictions Mean       -37.0752
trainer/Q2 Predictions Std         37.2575
trainer/Q2 Predictions Max         -6.4866
trainer/Q2 Predictions Min       -136.883
trainer/Q Targets Mean            -37.2439
trainer/Q Targets Std              37.5736
trainer/Q Targets Max              -0.0732395
trainer/Q Targets Min            -137.972
trainer/Log Pis Mean                1.7332
trainer/Log Pis Std                 1.08666
trainer/Log Pis Max                 4.64277
trainer/Log Pis Min                -2.15124
trainer/Policy mu Mean             -0.0166663
trainer/Policy mu Std               0.372517
trainer/Policy mu Max               2.8814
trainer/Policy mu Min              -2.72308
trainer/Policy log std Mean        -2.28218
trainer/Policy log std Std          0.355416
trainer/Policy log std Max         -0.286796
trainer/Policy log std Min         -3.12656
trainer/Alpha                       0.0635347
trainer/Alpha Loss                 -0.735366
exploration/num steps total    249700
exploration/num paths total      2497
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.01
exploration/Rewards Std             1.12108
exploration/Rewards Max            -0.00564276
exploration/Rewards Min            -8.57518
exploration/Returns Mean         -101
exploration/Returns Std            68.0729
exploration/Returns Max           -13.3827
exploration/Returns Min          -176.991
exploration/Actions Mean            0.00900083
exploration/Actions Std             0.221485
exploration/Actions Max             0.99948
exploration/Actions Min            -0.999436
exploration/Num Paths               5
exploration/Average Returns      -101
evaluation/num steps total     748500
evaluation/num paths total       7485
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.551818
evaluation/Rewards Std              1.08553
evaluation/Rewards Max             -0.0106989
evaluation/Rewards Min             -9.35551
evaluation/Returns Mean           -55.1818
evaluation/Returns Std             67.079
evaluation/Returns Max             -4.57358
evaluation/Returns Min           -195.351
evaluation/Actions Mean             0.0046496
evaluation/Actions Std              0.1652
evaluation/Actions Max              0.997922
evaluation/Actions Min             -0.997794
evaluation/Num Paths               15
evaluation/Average Returns        -55.1818
time/data storing (s)               0.00293096
time/evaluation sampling (s)        0.316653
time/exploration sampling (s)       0.140988
time/logging (s)                    0.00475911
time/saving (s)                     0.00194282
time/training (s)                   1.9639
time/epoch (s)                      2.43117
time/total (s)                   1225.82
Epoch                             498
-----------------------------  ---------------
2019-04-23 01:34:00.850704 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 499 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.377647
trainer/QF2 Loss                    0.365711
trainer/Policy Loss                37.7031
trainer/Q1 Predictions Mean       -35.8278
trainer/Q1 Predictions Std         38.3054
trainer/Q1 Predictions Max         -6.11168
trainer/Q1 Predictions Min       -135.794
trainer/Q2 Predictions Mean       -35.8233
trainer/Q2 Predictions Std         38.3061
trainer/Q2 Predictions Max         -6.16049
trainer/Q2 Predictions Min       -135.838
trainer/Q Targets Mean            -36.1805
trainer/Q Targets Std              38.5868
trainer/Q Targets Max              -6.36342
trainer/Q Targets Min            -136.946
trainer/Log Pis Mean                1.88827
trainer/Log Pis Std                 1.35207
trainer/Log Pis Max                 5.37482
trainer/Log Pis Min                -6.2661
trainer/Policy mu Mean             -0.0205973
trainer/Policy mu Std               0.605905
trainer/Policy mu Max               3.25662
trainer/Policy mu Min              -2.88683
trainer/Policy log std Mean        -2.11379
trainer/Policy log std Std          0.442282
trainer/Policy log std Max         -0.0989667
trainer/Policy log std Min         -2.83295
trainer/Alpha                       0.0663679
trainer/Alpha Loss                 -0.303035
exploration/num steps total    250200
exploration/num paths total      2502
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.38535
exploration/Rewards Std             1.24766
exploration/Rewards Max            -0.0194478
exploration/Rewards Min            -8.32342
exploration/Returns Mean         -138.535
exploration/Returns Std            81.4129
exploration/Returns Max           -38.6492
exploration/Returns Min          -214.397
exploration/Actions Mean           -0.0263912
exploration/Actions Std             0.240392
exploration/Actions Max             0.999459
exploration/Actions Min            -0.997781
exploration/Num Paths               5
exploration/Average Returns      -138.535
evaluation/num steps total     750000
evaluation/num paths total       7500
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.06164
evaluation/Rewards Std              1.18475
evaluation/Rewards Max             -0.0172805
evaluation/Rewards Min            -10.0688
evaluation/Returns Mean          -106.164
evaluation/Returns Std             94.8766
evaluation/Returns Max            -10.9334
evaluation/Returns Min           -287.469
evaluation/Actions Mean            -0.00915404
evaluation/Actions Std              0.158456
evaluation/Actions Max              0.998011
evaluation/Actions Min             -0.998103
evaluation/Num Paths               15
evaluation/Average Returns       -106.164
time/data storing (s)               0.00258422
time/evaluation sampling (s)        0.320559
time/exploration sampling (s)       0.136617
time/logging (s)                    0.00500353
time/saving (s)                     0.00192171
time/training (s)                   1.96551
time/epoch (s)                      2.43219
time/total (s)                   1228.25
Epoch                             499
-----------------------------  ---------------
2019-04-23 01:34:03.297800 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 500 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                  185.522
trainer/QF2 Loss                  183.632
trainer/Policy Loss                38.4603
trainer/Q1 Predictions Mean       -36.5761
trainer/Q1 Predictions Std         37.9374
trainer/Q1 Predictions Max         -6.39825
trainer/Q1 Predictions Min       -138.562
trainer/Q2 Predictions Mean       -36.5325
trainer/Q2 Predictions Std         37.9245
trainer/Q2 Predictions Max         -6.36014
trainer/Q2 Predictions Min       -138.338
trainer/Q Targets Mean            -35.2874
trainer/Q Targets Std              37.1672
trainer/Q Targets Max              -0.693965
trainer/Q Targets Min            -139.438
trainer/Log Pis Mean                1.97708
trainer/Log Pis Std                 1.23334
trainer/Log Pis Max                 4.78667
trainer/Log Pis Min                -2.46372
trainer/Policy mu Mean             -0.0160647
trainer/Policy mu Std               0.403696
trainer/Policy mu Max               2.59273
trainer/Policy mu Min              -2.17978
trainer/Policy log std Mean        -2.32654
trainer/Policy log std Std          0.399637
trainer/Policy log std Max         -0.545698
trainer/Policy log std Min         -3.1945
trainer/Alpha                       0.0666926
trainer/Alpha Loss                 -0.062059
exploration/num steps total    250700
exploration/num paths total      2507
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.530425
exploration/Rewards Std             0.955446
exploration/Rewards Max            -0.00699624
exploration/Rewards Min            -8.58824
exploration/Returns Mean          -53.0425
exploration/Returns Std            14.3113
exploration/Returns Max           -35.5112
exploration/Returns Min           -79.2839
exploration/Actions Mean            0.0146545
exploration/Actions Std             0.224829
exploration/Actions Max             0.998425
exploration/Actions Min            -0.998296
exploration/Num Paths               5
exploration/Average Returns       -53.0425
evaluation/num steps total     751500
evaluation/num paths total       7515
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.666063
evaluation/Rewards Std              1.0108
evaluation/Rewards Max             -0.0364296
evaluation/Rewards Min            -11.7451
evaluation/Returns Mean           -66.6063
evaluation/Returns Std             50.1005
evaluation/Returns Max            -12.4334
evaluation/Returns Min           -171.242
evaluation/Actions Mean             0.00768333
evaluation/Actions Std              0.183826
evaluation/Actions Max              0.998384
evaluation/Actions Min             -0.998546
evaluation/Num Paths               15
evaluation/Average Returns        -66.6063
time/data storing (s)               0.0025799
time/evaluation sampling (s)        0.316668
time/exploration sampling (s)       0.135028
time/logging (s)                    0.00380596
time/saving (s)                     0.00182204
time/training (s)                   1.97401
time/epoch (s)                      2.43392
time/total (s)                   1230.69
Epoch                             500
-----------------------------  ---------------
2019-04-23 01:34:05.727358 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 501 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   72.2892
trainer/QF2 Loss                   72.8217
trainer/Policy Loss                38.216
trainer/Q1 Predictions Mean       -36.2092
trainer/Q1 Predictions Std         35.3937
trainer/Q1 Predictions Max         -6.30751
trainer/Q1 Predictions Min       -133.942
trainer/Q2 Predictions Mean       -36.1933
trainer/Q2 Predictions Std         35.371
trainer/Q2 Predictions Max         -6.31848
trainer/Q2 Predictions Min       -133.874
trainer/Q Targets Mean            -35.9627
trainer/Q Targets Std              35.8955
trainer/Q Targets Max              -0.289789
trainer/Q Targets Min            -137.099
trainer/Log Pis Mean                2.04134
trainer/Log Pis Std                 1.27101
trainer/Log Pis Max                 8.94598
trainer/Log Pis Min                -1.29043
trainer/Policy mu Mean             -0.0393132
trainer/Policy mu Std               0.575697
trainer/Policy mu Max               3.1215
trainer/Policy mu Min              -2.9535
trainer/Policy log std Mean        -2.20741
trainer/Policy log std Std          0.385858
trainer/Policy log std Max         -0.40456
trainer/Policy log std Min         -2.86691
trainer/Alpha                       0.0689891
trainer/Alpha Loss                  0.110528
exploration/num steps total    251200
exploration/num paths total      2512
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.746896
exploration/Rewards Std             1.13422
exploration/Rewards Max            -0.00753313
exploration/Rewards Min            -8.73928
exploration/Returns Mean          -74.6896
exploration/Returns Std            59.9523
exploration/Returns Max           -16.549
exploration/Returns Min          -188.42
exploration/Actions Mean            0.0276112
exploration/Actions Std             0.218765
exploration/Actions Max             0.998147
exploration/Actions Min            -0.96069
exploration/Num Paths               5
exploration/Average Returns       -74.6896
evaluation/num steps total     753000
evaluation/num paths total       7530
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.671215
evaluation/Rewards Std              1.1984
evaluation/Rewards Max             -0.0313951
evaluation/Rewards Min            -10.1792
evaluation/Returns Mean           -67.1215
evaluation/Returns Std             51.5245
evaluation/Returns Max             -8.64554
evaluation/Returns Min           -184.226
evaluation/Actions Mean             0.0124408
evaluation/Actions Std              0.201143
evaluation/Actions Max              0.998866
evaluation/Actions Min             -0.998893
evaluation/Num Paths               15
evaluation/Average Returns        -67.1215
time/data storing (s)               0.00283152
time/evaluation sampling (s)        0.312716
time/exploration sampling (s)       0.136011
time/logging (s)                    0.00477919
time/saving (s)                     0.00192364
time/training (s)                   1.96098
time/epoch (s)                      2.41924
time/total (s)                   1233.12
Epoch                             501
-----------------------------  ---------------
2019-04-23 01:34:08.160059 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 502 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.794028
trainer/QF2 Loss                    0.810609
trainer/Policy Loss                33.385
trainer/Q1 Predictions Mean       -31.5831
trainer/Q1 Predictions Std         36.4119
trainer/Q1 Predictions Max         -6.2957
trainer/Q1 Predictions Min       -139.319
trainer/Q2 Predictions Mean       -31.5541
trainer/Q2 Predictions Std         36.3919
trainer/Q2 Predictions Max         -6.36515
trainer/Q2 Predictions Min       -138.391
trainer/Q Targets Mean            -31.7627
trainer/Q Targets Std              36.7211
trainer/Q Targets Max              -0.166415
trainer/Q Targets Min            -138.425
trainer/Log Pis Mean                1.84707
trainer/Log Pis Std                 1.31558
trainer/Log Pis Max                 5.40887
trainer/Log Pis Min                -2.30981
trainer/Policy mu Mean             -0.00918858
trainer/Policy mu Std               0.371591
trainer/Policy mu Max               2.83122
trainer/Policy mu Min              -1.63045
trainer/Policy log std Mean        -2.27601
trainer/Policy log std Std          0.341954
trainer/Policy log std Max         -0.568199
trainer/Policy log std Min         -3.00346
trainer/Alpha                       0.0683023
trainer/Alpha Loss                 -0.410428
exploration/num steps total    251700
exploration/num paths total      2517
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.546176
exploration/Rewards Std             1.14482
exploration/Rewards Max            -0.000830371
exploration/Rewards Min           -10.2313
exploration/Returns Mean          -54.6176
exploration/Returns Std            34.0588
exploration/Returns Max           -20.3333
exploration/Returns Min          -116.185
exploration/Actions Mean           -0.0282856
exploration/Actions Std             0.237078
exploration/Actions Max             0.992699
exploration/Actions Min            -0.999768
exploration/Num Paths               5
exploration/Average Returns       -54.6176
evaluation/num steps total     754500
evaluation/num paths total       7545
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.906091
evaluation/Rewards Std              1.24817
evaluation/Rewards Max             -0.0170418
evaluation/Rewards Min             -9.77752
evaluation/Returns Mean           -90.6091
evaluation/Returns Std             89.1524
evaluation/Returns Max            -16.6496
evaluation/Returns Min           -304.652
evaluation/Actions Mean            -0.000720767
evaluation/Actions Std              0.199455
evaluation/Actions Max              0.997379
evaluation/Actions Min             -0.997934
evaluation/Num Paths               15
evaluation/Average Returns        -90.6091
time/data storing (s)               0.00269312
time/evaluation sampling (s)        0.32134
time/exploration sampling (s)       0.135781
time/logging (s)                    0.00477882
time/saving (s)                     0.00192542
time/training (s)                   1.95473
time/epoch (s)                      2.42125
time/total (s)                   1235.54
Epoch                             502
-----------------------------  ----------------
2019-04-23 01:34:10.615116 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 503 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    8.70773
trainer/QF2 Loss                    8.69534
trainer/Policy Loss                35.8428
trainer/Q1 Predictions Mean       -33.996
trainer/Q1 Predictions Std         34.6213
trainer/Q1 Predictions Max         -6.34047
trainer/Q1 Predictions Min       -135.686
trainer/Q2 Predictions Mean       -34.0021
trainer/Q2 Predictions Std         34.627
trainer/Q2 Predictions Max         -6.32052
trainer/Q2 Predictions Min       -135.193
trainer/Q Targets Mean            -34.1662
trainer/Q Targets Std              35.2814
trainer/Q Targets Max              -0.51298
trainer/Q Targets Min            -137.17
trainer/Log Pis Mean                1.94654
trainer/Log Pis Std                 1.24653
trainer/Log Pis Max                 6.1818
trainer/Log Pis Min                -2.13422
trainer/Policy mu Mean             -0.0872661
trainer/Policy mu Std               0.597759
trainer/Policy mu Max               2.88206
trainer/Policy mu Min              -3.05448
trainer/Policy log std Mean        -2.1771
trainer/Policy log std Std          0.458372
trainer/Policy log std Max         -0.404786
trainer/Policy log std Min         -3.14722
trainer/Alpha                       0.0695221
trainer/Alpha Loss                 -0.142537
exploration/num steps total    252200
exploration/num paths total      2522
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.527294
exploration/Rewards Std             0.943995
exploration/Rewards Max            -0.0104421
exploration/Rewards Min            -7.82578
exploration/Returns Mean          -52.7294
exploration/Returns Std            35.2338
exploration/Returns Max           -19.4338
exploration/Returns Min          -119.741
exploration/Actions Mean            0.0196776
exploration/Actions Std             0.22673
exploration/Actions Max             0.999908
exploration/Actions Min            -0.982494
exploration/Num Paths               5
exploration/Average Returns       -52.7294
evaluation/num steps total     756000
evaluation/num paths total       7560
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.377113
evaluation/Rewards Std              0.748419
evaluation/Rewards Max             -0.0270251
evaluation/Rewards Min             -8.47643
evaluation/Returns Mean           -37.7113
evaluation/Returns Std             22.2299
evaluation/Returns Max             -5.02485
evaluation/Returns Min            -83.1091
evaluation/Actions Mean             0.00489179
evaluation/Actions Std              0.16184
evaluation/Actions Max              0.997061
evaluation/Actions Min             -0.998004
evaluation/Num Paths               15
evaluation/Average Returns        -37.7113
time/data storing (s)               0.00267639
time/evaluation sampling (s)        0.32171
time/exploration sampling (s)       0.136735
time/logging (s)                    0.00480536
time/saving (s)                     0.00156087
time/training (s)                   1.97786
time/epoch (s)                      2.44535
time/total (s)                   1237.99
Epoch                             503
-----------------------------  ---------------
2019-04-23 01:34:13.080173 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 504 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                  176.665
trainer/QF2 Loss                  176.951
trainer/Policy Loss                44.5697
trainer/Q1 Predictions Mean       -42.7854
trainer/Q1 Predictions Std         43.5564
trainer/Q1 Predictions Max         -6.4289
trainer/Q1 Predictions Min       -136.983
trainer/Q2 Predictions Mean       -42.7932
trainer/Q2 Predictions Std         43.5859
trainer/Q2 Predictions Max         -6.42016
trainer/Q2 Predictions Min       -136.41
trainer/Q Targets Mean            -41.5225
trainer/Q Targets Std              42.954
trainer/Q Targets Max              -0.190542
trainer/Q Targets Min            -137.411
trainer/Log Pis Mean                1.89498
trainer/Log Pis Std                 1.45838
trainer/Log Pis Max                 5.98685
trainer/Log Pis Min                -7.96083
trainer/Policy mu Mean             -0.0669798
trainer/Policy mu Std               0.338904
trainer/Policy mu Max               2.09551
trainer/Policy mu Min              -2.92458
trainer/Policy log std Mean        -2.30962
trainer/Policy log std Std          0.302474
trainer/Policy log std Max         -0.757592
trainer/Policy log std Min         -2.91969
trainer/Alpha                       0.0688654
trainer/Alpha Loss                 -0.280991
exploration/num steps total    252700
exploration/num paths total      2527
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.09189
exploration/Rewards Std             1.16479
exploration/Rewards Max            -0.0096446
exploration/Rewards Min            -4.99904
exploration/Returns Mean         -109.189
exploration/Returns Std           109.478
exploration/Returns Max           -21.3495
exploration/Returns Min          -294.208
exploration/Actions Mean            0.00882755
exploration/Actions Std             0.194813
exploration/Actions Max             0.996817
exploration/Actions Min            -0.998092
exploration/Num Paths               5
exploration/Average Returns      -109.189
evaluation/num steps total     757500
evaluation/num paths total       7575
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.06473
evaluation/Rewards Std              1.25024
evaluation/Rewards Max             -0.00709505
evaluation/Rewards Min            -10.4183
evaluation/Returns Mean          -106.473
evaluation/Returns Std             87.4762
evaluation/Returns Max             -5.86939
evaluation/Returns Min           -312.289
evaluation/Actions Mean            -0.00889438
evaluation/Actions Std              0.182802
evaluation/Actions Max              0.998237
evaluation/Actions Min             -0.998374
evaluation/Num Paths               15
evaluation/Average Returns       -106.473
time/data storing (s)               0.00266776
time/evaluation sampling (s)        0.318659
time/exploration sampling (s)       0.135234
time/logging (s)                    0.00474318
time/saving (s)                     0.0102001
time/training (s)                   1.98197
time/epoch (s)                      2.45347
time/total (s)                   1240.45
Epoch                             504
-----------------------------  ---------------
2019-04-23 01:34:15.515628 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 505 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.37968
trainer/QF2 Loss                    0.438338
trainer/Policy Loss                40.4244
trainer/Q1 Predictions Mean       -38.5706
trainer/Q1 Predictions Std         39.5429
trainer/Q1 Predictions Max         -6.35581
trainer/Q1 Predictions Min       -138.665
trainer/Q2 Predictions Mean       -38.567
trainer/Q2 Predictions Std         39.5029
trainer/Q2 Predictions Max         -6.36048
trainer/Q2 Predictions Min       -137.997
trainer/Q Targets Mean            -38.8541
trainer/Q Targets Std              39.8622
trainer/Q Targets Max              -6.28281
trainer/Q Targets Min            -140.871
trainer/Log Pis Mean                1.92562
trainer/Log Pis Std                 1.2206
trainer/Log Pis Max                 4.35463
trainer/Log Pis Min                -2.21422
trainer/Policy mu Mean             -0.0374768
trainer/Policy mu Std               0.425101
trainer/Policy mu Max               2.81517
trainer/Policy mu Min              -2.46799
trainer/Policy log std Mean        -2.28374
trainer/Policy log std Std          0.407455
trainer/Policy log std Max         -0.565465
trainer/Policy log std Min         -3.12057
trainer/Alpha                       0.0678921
trainer/Alpha Loss                 -0.200078
exploration/num steps total    253200
exploration/num paths total      2532
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.814306
exploration/Rewards Std             1.0427
exploration/Rewards Max            -0.00912897
exploration/Rewards Min            -9.52584
exploration/Returns Mean          -81.4306
exploration/Returns Std            50.8059
exploration/Returns Max           -31.4507
exploration/Returns Min          -179.522
exploration/Actions Mean           -0.0183144
exploration/Actions Std             0.214274
exploration/Actions Max             0.998736
exploration/Actions Min            -0.998962
exploration/Num Paths               5
exploration/Average Returns       -81.4306
evaluation/num steps total     759000
evaluation/num paths total       7590
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.776572
evaluation/Rewards Std              1.04551
evaluation/Rewards Max             -0.0136525
evaluation/Rewards Min            -10.2406
evaluation/Returns Mean           -77.6572
evaluation/Returns Std             57.2927
evaluation/Returns Max             -7.67703
evaluation/Returns Min           -170.382
evaluation/Actions Mean             0.00103848
evaluation/Actions Std              0.17757
evaluation/Actions Max              0.99855
evaluation/Actions Min             -0.99936
evaluation/Num Paths               15
evaluation/Average Returns        -77.6572
time/data storing (s)               0.00276654
time/evaluation sampling (s)        0.319787
time/exploration sampling (s)       0.136341
time/logging (s)                    0.00475531
time/saving (s)                     0.00192387
time/training (s)                   1.95823
time/epoch (s)                      2.4238
time/total (s)                   1242.88
Epoch                             505
-----------------------------  ---------------
2019-04-23 01:34:17.929189 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 506 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.379711
trainer/QF2 Loss                    0.402198
trainer/Policy Loss                35.0479
trainer/Q1 Predictions Mean       -33.0462
trainer/Q1 Predictions Std         35.6922
trainer/Q1 Predictions Max         -6.32196
trainer/Q1 Predictions Min       -135.032
trainer/Q2 Predictions Mean       -33.0553
trainer/Q2 Predictions Std         35.6934
trainer/Q2 Predictions Max         -6.36465
trainer/Q2 Predictions Min       -134.871
trainer/Q Targets Mean            -33.218
trainer/Q Targets Std              35.9743
trainer/Q Targets Max              -6.2965
trainer/Q Targets Min            -136.96
trainer/Log Pis Mean                2.07356
trainer/Log Pis Std                 1.3975
trainer/Log Pis Max                 8.63319
trainer/Log Pis Min                -4.37422
trainer/Policy mu Mean             -0.0690626
trainer/Policy mu Std               0.461077
trainer/Policy mu Max               2.63672
trainer/Policy mu Min              -3.79108
trainer/Policy log std Mean        -2.2733
trainer/Policy log std Std          0.342883
trainer/Policy log std Max         -0.373874
trainer/Policy log std Min         -3.21472
trainer/Alpha                       0.0700305
trainer/Alpha Loss                  0.19559
exploration/num steps total    253700
exploration/num paths total      2537
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.663386
exploration/Rewards Std             0.843326
exploration/Rewards Max            -0.0122552
exploration/Rewards Min            -8.13762
exploration/Returns Mean          -66.3386
exploration/Returns Std            59.9527
exploration/Returns Max           -11.579
exploration/Returns Min          -157.896
exploration/Actions Mean            0.00281912
exploration/Actions Std             0.169467
exploration/Actions Max             0.998373
exploration/Actions Min            -0.989347
exploration/Num Paths               5
exploration/Average Returns       -66.3386
evaluation/num steps total     760500
evaluation/num paths total       7605
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.652471
evaluation/Rewards Std              1.09512
evaluation/Rewards Max             -0.00257362
evaluation/Rewards Min            -10.1668
evaluation/Returns Mean           -65.2471
evaluation/Returns Std             50.7729
evaluation/Returns Max             -5.75425
evaluation/Returns Min           -177.689
evaluation/Actions Mean             0.00414933
evaluation/Actions Std              0.190024
evaluation/Actions Max              0.998471
evaluation/Actions Min             -0.998486
evaluation/Num Paths               15
evaluation/Average Returns        -65.2471
time/data storing (s)               0.00259258
time/evaluation sampling (s)        0.31666
time/exploration sampling (s)       0.136651
time/logging (s)                    0.00396884
time/saving (s)                     0.00192527
time/training (s)                   1.93945
time/epoch (s)                      2.40124
time/total (s)                   1245.28
Epoch                             506
-----------------------------  ---------------
2019-04-23 01:34:20.378868 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 507 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.759826
trainer/QF2 Loss                    0.769129
trainer/Policy Loss                36.708
trainer/Q1 Predictions Mean       -34.7411
trainer/Q1 Predictions Std         35.9708
trainer/Q1 Predictions Max         -6.4778
trainer/Q1 Predictions Min       -134.56
trainer/Q2 Predictions Mean       -34.7419
trainer/Q2 Predictions Std         35.9612
trainer/Q2 Predictions Max         -6.5302
trainer/Q2 Predictions Min       -134.067
trainer/Q Targets Mean            -35.2527
trainer/Q Targets Std              36.4991
trainer/Q Targets Max              -6.41898
trainer/Q Targets Min            -135.821
trainer/Log Pis Mean                2.02787
trainer/Log Pis Std                 1.2262
trainer/Log Pis Max                 7.2497
trainer/Log Pis Min                -1.63669
trainer/Policy mu Mean             -0.0142348
trainer/Policy mu Std               0.569761
trainer/Policy mu Max               3.69905
trainer/Policy mu Min              -2.02858
trainer/Policy log std Mean        -2.19595
trainer/Policy log std Std          0.426489
trainer/Policy log std Max         -0.519936
trainer/Policy log std Min         -3.2347
trainer/Alpha                       0.0690523
trainer/Alpha Loss                  0.0744921
exploration/num steps total    254200
exploration/num paths total      2542
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.691986
exploration/Rewards Std             1.09133
exploration/Rewards Max            -0.0124434
exploration/Rewards Min            -8.58884
exploration/Returns Mean          -69.1986
exploration/Returns Std            53.2952
exploration/Returns Max           -31.4424
exploration/Returns Min          -174.072
exploration/Actions Mean           -0.0260415
exploration/Actions Std             0.225512
exploration/Actions Max             0.997471
exploration/Actions Min            -0.998378
exploration/Num Paths               5
exploration/Average Returns       -69.1986
evaluation/num steps total     762000
evaluation/num paths total       7620
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.06168
evaluation/Rewards Std              1.30369
evaluation/Rewards Max             -0.0528325
evaluation/Rewards Min            -11.1896
evaluation/Returns Mean          -106.168
evaluation/Returns Std             73.3962
evaluation/Returns Max            -28.2912
evaluation/Returns Min           -277.255
evaluation/Actions Mean             0.0188626
evaluation/Actions Std              0.200922
evaluation/Actions Max              0.999392
evaluation/Actions Min             -0.997544
evaluation/Num Paths               15
evaluation/Average Returns       -106.168
time/data storing (s)               0.00253117
time/evaluation sampling (s)        0.312799
time/exploration sampling (s)       0.136432
time/logging (s)                    0.00480305
time/saving (s)                     0.00193514
time/training (s)                   1.98034
time/epoch (s)                      2.43884
time/total (s)                   1247.73
Epoch                             507
-----------------------------  ---------------
2019-04-23 01:34:22.821409 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 508 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   72.7644
trainer/QF2 Loss                   72.8651
trainer/Policy Loss                36.6014
trainer/Q1 Predictions Mean       -34.9221
trainer/Q1 Predictions Std         37.2171
trainer/Q1 Predictions Max         -6.23646
trainer/Q1 Predictions Min       -134.656
trainer/Q2 Predictions Mean       -34.8971
trainer/Q2 Predictions Std         37.2309
trainer/Q2 Predictions Max         -6.20827
trainer/Q2 Predictions Min       -134.751
trainer/Q Targets Mean            -34.19
trainer/Q Targets Std              37.1342
trainer/Q Targets Max              -1.69981
trainer/Q Targets Min            -134.788
trainer/Log Pis Mean                1.74029
trainer/Log Pis Std                 1.1813
trainer/Log Pis Max                 4.03771
trainer/Log Pis Min                -2.29153
trainer/Policy mu Mean             -0.0249313
trainer/Policy mu Std               0.3678
trainer/Policy mu Max               2.17965
trainer/Policy mu Min              -2.8534
trainer/Policy log std Mean        -2.25789
trainer/Policy log std Std          0.356673
trainer/Policy log std Max         -0.486585
trainer/Policy log std Min         -3.14902
trainer/Alpha                       0.0693134
trainer/Alpha Loss                 -0.693189
exploration/num steps total    254700
exploration/num paths total      2547
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.899645
exploration/Rewards Std             1.13671
exploration/Rewards Max            -0.0206618
exploration/Rewards Min           -10.6
exploration/Returns Mean          -89.9645
exploration/Returns Std            43.971
exploration/Returns Max           -25.5111
exploration/Returns Min          -161.544
exploration/Actions Mean           -0.00676959
exploration/Actions Std             0.238284
exploration/Actions Max             0.9966
exploration/Actions Min            -0.999313
exploration/Num Paths               5
exploration/Average Returns       -89.9645
evaluation/num steps total     763500
evaluation/num paths total       7635
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.76391
evaluation/Rewards Std              1.10729
evaluation/Rewards Max             -0.0350876
evaluation/Rewards Min            -10.5243
evaluation/Returns Mean           -76.391
evaluation/Returns Std             76.4282
evaluation/Returns Max            -10.9963
evaluation/Returns Min           -296.351
evaluation/Actions Mean            -0.00631947
evaluation/Actions Std              0.1823
evaluation/Actions Max              0.999323
evaluation/Actions Min             -0.995598
evaluation/Num Paths               15
evaluation/Average Returns        -76.391
time/data storing (s)               0.0027566
time/evaluation sampling (s)        0.309032
time/exploration sampling (s)       0.136804
time/logging (s)                    0.00477183
time/saving (s)                     0.00193007
time/training (s)                   1.97659
time/epoch (s)                      2.43188
time/total (s)                   1250.16
Epoch                             508
-----------------------------  ---------------
2019-04-23 01:34:25.289277 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 509 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                   72.2004
trainer/QF2 Loss                   72.1736
trainer/Policy Loss                38.3575
trainer/Q1 Predictions Mean       -36.5017
trainer/Q1 Predictions Std         37.6679
trainer/Q1 Predictions Max         -6.16155
trainer/Q1 Predictions Min       -132.165
trainer/Q2 Predictions Mean       -36.4959
trainer/Q2 Predictions Std         37.6729
trainer/Q2 Predictions Max         -6.21713
trainer/Q2 Predictions Min       -132.258
trainer/Q Targets Mean            -36.1825
trainer/Q Targets Std              38.1163
trainer/Q Targets Max              -0.308461
trainer/Q Targets Min            -134.29
trainer/Log Pis Mean                1.89363
trainer/Log Pis Std                 1.07093
trainer/Log Pis Max                 7.3771
trainer/Log Pis Min                -1.94703
trainer/Policy mu Mean              0.02131
trainer/Policy mu Std               0.386312
trainer/Policy mu Max               3.28633
trainer/Policy mu Min              -2.11203
trainer/Policy log std Mean        -2.25836
trainer/Policy log std Std          0.313281
trainer/Policy log std Max         -0.576728
trainer/Policy log std Min         -3.0417
trainer/Alpha                       0.0681036
trainer/Alpha Loss                 -0.285741
exploration/num steps total    255200
exploration/num paths total      2552
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.518446
exploration/Rewards Std             0.722613
exploration/Rewards Max            -0.0229242
exploration/Rewards Min            -6.07819
exploration/Returns Mean          -51.8446
exploration/Returns Std            43.1506
exploration/Returns Max           -27.4245
exploration/Returns Min          -137.996
exploration/Actions Mean            0.000670352
exploration/Actions Std             0.2046
exploration/Actions Max             0.999684
exploration/Actions Min            -0.99816
exploration/Num Paths               5
exploration/Average Returns       -51.8446
evaluation/num steps total     765000
evaluation/num paths total       7650
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.775417
evaluation/Rewards Std              1.07647
evaluation/Rewards Max             -0.0192046
evaluation/Rewards Min            -11.0273
evaluation/Returns Mean           -77.5417
evaluation/Returns Std             83.6167
evaluation/Returns Max             -7.02015
evaluation/Returns Min           -320.084
evaluation/Actions Mean             0.0053372
evaluation/Actions Std              0.167744
evaluation/Actions Max              0.999135
evaluation/Actions Min             -0.997419
evaluation/Num Paths               15
evaluation/Average Returns        -77.5417
time/data storing (s)               0.00259304
time/evaluation sampling (s)        0.321099
time/exploration sampling (s)       0.138329
time/logging (s)                    0.00483708
time/saving (s)                     0.00191609
time/training (s)                   1.98834
time/epoch (s)                      2.45711
time/total (s)                   1252.62
Epoch                             509
-----------------------------  ----------------
2019-04-23 01:34:27.710888 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 510 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   53.2695
trainer/QF2 Loss                   53.3054
trainer/Policy Loss                40.5448
trainer/Q1 Predictions Mean       -38.7512
trainer/Q1 Predictions Std         37.9823
trainer/Q1 Predictions Max         -6.38375
trainer/Q1 Predictions Min       -149.052
trainer/Q2 Predictions Mean       -38.7144
trainer/Q2 Predictions Std         37.9253
trainer/Q2 Predictions Max         -6.34043
trainer/Q2 Predictions Min       -146.294
trainer/Q Targets Mean            -38.084
trainer/Q Targets Std              38.8744
trainer/Q Targets Max              -0.199401
trainer/Q Targets Min            -150.446
trainer/Log Pis Mean                1.86757
trainer/Log Pis Std                 1.14836
trainer/Log Pis Max                 4.92384
trainer/Log Pis Min                -1.72024
trainer/Policy mu Mean             -0.0619166
trainer/Policy mu Std               0.428001
trainer/Policy mu Max               2.65268
trainer/Policy mu Min              -2.79107
trainer/Policy log std Mean        -2.26161
trainer/Policy log std Std          0.377747
trainer/Policy log std Max         -0.656014
trainer/Policy log std Min         -3.16977
trainer/Alpha                       0.0684676
trainer/Alpha Loss                 -0.355114
exploration/num steps total    255700
exploration/num paths total      2557
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.99772
exploration/Rewards Std             1.34628
exploration/Rewards Max            -0.0242479
exploration/Rewards Min            -9.60649
exploration/Returns Mean          -99.772
exploration/Returns Std           105.477
exploration/Returns Max           -21.2226
exploration/Returns Min          -304.167
exploration/Actions Mean           -0.0121611
exploration/Actions Std             0.221652
exploration/Actions Max             0.997822
exploration/Actions Min            -0.998638
exploration/Num Paths               5
exploration/Average Returns       -99.772
evaluation/num steps total     766500
evaluation/num paths total       7665
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.867309
evaluation/Rewards Std              1.15678
evaluation/Rewards Max             -0.0133557
evaluation/Rewards Min             -9.7982
evaluation/Returns Mean           -86.7309
evaluation/Returns Std             62.342
evaluation/Returns Max             -8.43953
evaluation/Returns Min           -192.721
evaluation/Actions Mean             0.00325137
evaluation/Actions Std              0.182341
evaluation/Actions Max              0.998518
evaluation/Actions Min             -0.999053
evaluation/Num Paths               15
evaluation/Average Returns        -86.7309
time/data storing (s)               0.00281939
time/evaluation sampling (s)        0.322317
time/exploration sampling (s)       0.138437
time/logging (s)                    0.00427244
time/saving (s)                     0.00153961
time/training (s)                   1.94051
time/epoch (s)                      2.4099
time/total (s)                   1255.04
Epoch                             510
-----------------------------  ---------------
2019-04-23 01:34:30.167569 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 511 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.06535
trainer/QF2 Loss                    1.10401
trainer/Policy Loss                42.9339
trainer/Q1 Predictions Mean       -41.104
trainer/Q1 Predictions Std         38.6324
trainer/Q1 Predictions Max         -6.36388
trainer/Q1 Predictions Min       -132.647
trainer/Q2 Predictions Mean       -41.063
trainer/Q2 Predictions Std         38.5981
trainer/Q2 Predictions Max         -6.41249
trainer/Q2 Predictions Min       -132.752
trainer/Q Targets Mean            -41.3169
trainer/Q Targets Std              39.049
trainer/Q Targets Max              -0.158953
trainer/Q Targets Min            -134.115
trainer/Log Pis Mean                2.014
trainer/Log Pis Std                 1.31324
trainer/Log Pis Max                 8.91173
trainer/Log Pis Min                -1.83008
trainer/Policy mu Mean             -0.0676056
trainer/Policy mu Std               0.551004
trainer/Policy mu Max               3.21328
trainer/Policy mu Min              -2.58312
trainer/Policy log std Mean        -2.1488
trainer/Policy log std Std          0.422493
trainer/Policy log std Max         -0.469244
trainer/Policy log std Min         -3.16646
trainer/Alpha                       0.0690613
trainer/Alpha Loss                  0.037425
exploration/num steps total    256200
exploration/num paths total      2562
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.914757
exploration/Rewards Std             1.1725
exploration/Rewards Max            -0.0139344
exploration/Rewards Min            -9.43342
exploration/Returns Mean          -91.4757
exploration/Returns Std            55.3668
exploration/Returns Max           -41.1635
exploration/Returns Min          -195.945
exploration/Actions Mean           -0.0168691
exploration/Actions Std             0.224256
exploration/Actions Max             0.988915
exploration/Actions Min            -0.999843
exploration/Num Paths               5
exploration/Average Returns       -91.4757
evaluation/num steps total     768000
evaluation/num paths total       7680
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.918225
evaluation/Rewards Std              1.40242
evaluation/Rewards Max             -0.0380084
evaluation/Rewards Min            -10.995
evaluation/Returns Mean           -91.8225
evaluation/Returns Std            100.033
evaluation/Returns Max             -7.99556
evaluation/Returns Min           -301.307
evaluation/Actions Mean            -0.000765254
evaluation/Actions Std              0.189854
evaluation/Actions Max              0.999164
evaluation/Actions Min             -0.997997
evaluation/Num Paths               15
evaluation/Average Returns        -91.8225
time/data storing (s)               0.00263425
time/evaluation sampling (s)        0.31989
time/exploration sampling (s)       0.135735
time/logging (s)                    0.00452514
time/saving (s)                     0.00196179
time/training (s)                   1.98143
time/epoch (s)                      2.44618
time/total (s)                   1257.49
Epoch                             511
-----------------------------  ----------------
2019-04-23 01:34:32.599744 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 512 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.531374
trainer/QF2 Loss                    0.472559
trainer/Policy Loss                37.5524
trainer/Q1 Predictions Mean       -35.3957
trainer/Q1 Predictions Std         36.6519
trainer/Q1 Predictions Max         -6.14009
trainer/Q1 Predictions Min       -140.21
trainer/Q2 Predictions Mean       -35.4506
trainer/Q2 Predictions Std         36.654
trainer/Q2 Predictions Max         -6.10503
trainer/Q2 Predictions Min       -140.497
trainer/Q Targets Mean            -35.806
trainer/Q Targets Std              37.0199
trainer/Q Targets Max              -6.28485
trainer/Q Targets Min            -139.701
trainer/Log Pis Mean                2.15734
trainer/Log Pis Std                 0.883781
trainer/Log Pis Max                 5.35053
trainer/Log Pis Min                -0.0195932
trainer/Policy mu Mean             -0.00489712
trainer/Policy mu Std               0.532426
trainer/Policy mu Max               2.08528
trainer/Policy mu Min              -2.98173
trainer/Policy log std Mean        -2.22301
trainer/Policy log std Std          0.44573
trainer/Policy log std Max         -0.424872
trainer/Policy log std Min         -3.25547
trainer/Alpha                       0.0668513
trainer/Alpha Loss                  0.42567
exploration/num steps total    256700
exploration/num paths total      2567
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.835547
exploration/Rewards Std             1.33601
exploration/Rewards Max            -0.0040539
exploration/Rewards Min            -7.32275
exploration/Returns Mean          -83.5547
exploration/Returns Std           109.513
exploration/Returns Max           -16.1247
exploration/Returns Min          -301.818
exploration/Actions Mean           -0.013645
exploration/Actions Std             0.213732
exploration/Actions Max             0.998128
exploration/Actions Min            -0.999212
exploration/Num Paths               5
exploration/Average Returns       -83.5547
evaluation/num steps total     769500
evaluation/num paths total       7695
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.08663
evaluation/Rewards Std              1.44842
evaluation/Rewards Max             -0.0271601
evaluation/Rewards Min            -10.5421
evaluation/Returns Mean          -108.663
evaluation/Returns Std            105.709
evaluation/Returns Max            -10.1434
evaluation/Returns Min           -320.91
evaluation/Actions Mean            -0.00410622
evaluation/Actions Std              0.192699
evaluation/Actions Max              0.999255
evaluation/Actions Min             -0.998129
evaluation/Num Paths               15
evaluation/Average Returns       -108.663
time/data storing (s)               0.00273956
time/evaluation sampling (s)        0.319339
time/exploration sampling (s)       0.136207
time/logging (s)                    0.00356374
time/saving (s)                     0.00166977
time/training (s)                   1.95702
time/epoch (s)                      2.42054
time/total (s)                   1259.91
Epoch                             512
-----------------------------  ---------------
2019-04-23 01:34:35.035336 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 513 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.59078
trainer/QF2 Loss                    1.76058
trainer/Policy Loss                40.5071
trainer/Q1 Predictions Mean       -38.6943
trainer/Q1 Predictions Std         36.2245
trainer/Q1 Predictions Max         -6.52889
trainer/Q1 Predictions Min       -133.539
trainer/Q2 Predictions Mean       -38.6112
trainer/Q2 Predictions Std         36.1646
trainer/Q2 Predictions Max         -6.53493
trainer/Q2 Predictions Min       -133.039
trainer/Q Targets Mean            -39.0049
trainer/Q Targets Std              36.7741
trainer/Q Targets Max              -0.0282567
trainer/Q Targets Min            -135.085
trainer/Log Pis Mean                2.01656
trainer/Log Pis Std                 1.16103
trainer/Log Pis Max                 7.48295
trainer/Log Pis Min                -1.49956
trainer/Policy mu Mean             -0.0131614
trainer/Policy mu Std               0.577126
trainer/Policy mu Max               2.92519
trainer/Policy mu Min              -2.61126
trainer/Policy log std Mean        -2.19862
trainer/Policy log std Std          0.444227
trainer/Policy log std Max         -0.225076
trainer/Policy log std Min         -3.08102
trainer/Alpha                       0.0718561
trainer/Alpha Loss                  0.0435985
exploration/num steps total    257200
exploration/num paths total      2572
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.34643
exploration/Rewards Std             1.48583
exploration/Rewards Max            -0.00628469
exploration/Rewards Min            -9.00238
exploration/Returns Mean         -134.643
exploration/Returns Std           113.178
exploration/Returns Max           -26.848
exploration/Returns Min          -275.593
exploration/Actions Mean           -0.000478395
exploration/Actions Std             0.231481
exploration/Actions Max             0.999555
exploration/Actions Min            -0.997718
exploration/Num Paths               5
exploration/Average Returns      -134.643
evaluation/num steps total     771000
evaluation/num paths total       7710
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.872367
evaluation/Rewards Std              1.25907
evaluation/Rewards Max             -0.0754265
evaluation/Rewards Min            -10.8314
evaluation/Returns Mean           -87.2367
evaluation/Returns Std             69.2058
evaluation/Returns Max            -10.3023
evaluation/Returns Min           -276.424
evaluation/Actions Mean            -0.00093627
evaluation/Actions Std              0.203837
evaluation/Actions Max              0.999458
evaluation/Actions Min             -0.996986
evaluation/Num Paths               15
evaluation/Average Returns        -87.2367
time/data storing (s)               0.00282396
time/evaluation sampling (s)        0.323434
time/exploration sampling (s)       0.135988
time/logging (s)                    0.00483404
time/saving (s)                     0.00194511
time/training (s)                   1.95859
time/epoch (s)                      2.42762
time/total (s)                   1262.34
Epoch                             513
-----------------------------  ----------------
2019-04-23 01:34:37.477386 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 514 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.732801
trainer/QF2 Loss                    0.733301
trainer/Policy Loss                41.5075
trainer/Q1 Predictions Mean       -39.344
trainer/Q1 Predictions Std         34.7417
trainer/Q1 Predictions Max         -6.3557
trainer/Q1 Predictions Min       -137.412
trainer/Q2 Predictions Mean       -39.3634
trainer/Q2 Predictions Std         34.7644
trainer/Q2 Predictions Max         -6.31325
trainer/Q2 Predictions Min       -136.89
trainer/Q Targets Mean            -39.4679
trainer/Q Targets Std              34.8982
trainer/Q Targets Max              -0.0544462
trainer/Q Targets Min            -136.284
trainer/Log Pis Mean                2.21349
trainer/Log Pis Std                 1.19514
trainer/Log Pis Max                 7.00054
trainer/Log Pis Min                -1.63292
trainer/Policy mu Mean             -0.0322748
trainer/Policy mu Std               0.501406
trainer/Policy mu Max               2.72873
trainer/Policy mu Min              -2.74071
trainer/Policy log std Mean        -2.25223
trainer/Policy log std Std          0.45075
trainer/Policy log std Max         -0.508368
trainer/Policy log std Min         -3.16925
trainer/Alpha                       0.0718679
trainer/Alpha Loss                  0.562109
exploration/num steps total    257700
exploration/num paths total      2577
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.60172
exploration/Rewards Std             0.965514
exploration/Rewards Max            -0.341694
exploration/Rewards Min            -8.25986
exploration/Returns Mean         -160.172
exploration/Returns Std            62.7122
exploration/Returns Max          -100.447
exploration/Returns Min          -274.501
exploration/Actions Mean            0.0202232
exploration/Actions Std             0.211073
exploration/Actions Max             0.997387
exploration/Actions Min            -0.97996
exploration/Num Paths               5
exploration/Average Returns      -160.172
evaluation/num steps total     772500
evaluation/num paths total       7725
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.725781
evaluation/Rewards Std              1.13189
evaluation/Rewards Max             -0.00545223
evaluation/Rewards Min             -9.72881
evaluation/Returns Mean           -72.5781
evaluation/Returns Std             84.2504
evaluation/Returns Max             -5.41258
evaluation/Returns Min           -274.55
evaluation/Actions Mean             0.00251467
evaluation/Actions Std              0.158974
evaluation/Actions Max              0.999308
evaluation/Actions Min             -0.996289
evaluation/Num Paths               15
evaluation/Average Returns        -72.5781
time/data storing (s)               0.00257806
time/evaluation sampling (s)        0.314275
time/exploration sampling (s)       0.135332
time/logging (s)                    0.00482926
time/saving (s)                     0.00201122
time/training (s)                   1.97128
time/epoch (s)                      2.4303
time/total (s)                   1264.78
Epoch                             514
-----------------------------  ---------------
2019-04-23 01:34:39.887325 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 515 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   72.2553
trainer/QF2 Loss                   72.3198
trainer/Policy Loss                38.9745
trainer/Q1 Predictions Mean       -37.0722
trainer/Q1 Predictions Std         37.5911
trainer/Q1 Predictions Max         -6.25367
trainer/Q1 Predictions Min       -146.863
trainer/Q2 Predictions Mean       -37.1127
trainer/Q2 Predictions Std         37.6531
trainer/Q2 Predictions Max         -6.1274
trainer/Q2 Predictions Min       -149.587
trainer/Q Targets Mean            -37.2623
trainer/Q Targets Std              38.6915
trainer/Q Targets Max              -2.05682
trainer/Q Targets Min            -153.13
trainer/Log Pis Mean                1.9448
trainer/Log Pis Std                 1.37355
trainer/Log Pis Max                 5.90343
trainer/Log Pis Min                -2.94876
trainer/Policy mu Mean             -0.107848
trainer/Policy mu Std               0.592967
trainer/Policy mu Max               2.45835
trainer/Policy mu Min              -3.12349
trainer/Policy log std Mean        -2.19506
trainer/Policy log std Std          0.484311
trainer/Policy log std Max         -0.508605
trainer/Policy log std Min         -3.15141
trainer/Alpha                       0.0714743
trainer/Alpha Loss                 -0.145649
exploration/num steps total    258200
exploration/num paths total      2582
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.796818
exploration/Rewards Std             1.19636
exploration/Rewards Max            -0.0116401
exploration/Rewards Min            -7.31199
exploration/Returns Mean          -79.6818
exploration/Returns Std            96.8886
exploration/Returns Max           -19.0546
exploration/Returns Min          -272.506
exploration/Actions Mean            0.0257243
exploration/Actions Std             0.216997
exploration/Actions Max             0.998263
exploration/Actions Min            -0.987284
exploration/Num Paths               5
exploration/Average Returns       -79.6818
evaluation/num steps total     774000
evaluation/num paths total       7740
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.807387
evaluation/Rewards Std              1.07188
evaluation/Rewards Max             -0.0420747
evaluation/Rewards Min             -9.57203
evaluation/Returns Mean           -80.7387
evaluation/Returns Std             61.1542
evaluation/Returns Max            -11.632
evaluation/Returns Min           -269.057
evaluation/Actions Mean            -0.00453289
evaluation/Actions Std              0.176519
evaluation/Actions Max              0.999252
evaluation/Actions Min             -0.996725
evaluation/Num Paths               15
evaluation/Average Returns        -80.7387
time/data storing (s)               0.00271232
time/evaluation sampling (s)        0.315054
time/exploration sampling (s)       0.134334
time/logging (s)                    0.0047846
time/saving (s)                     0.00194741
time/training (s)                   1.93931
time/epoch (s)                      2.39814
time/total (s)                   1267.18
Epoch                             515
-----------------------------  ---------------
2019-04-23 01:34:42.370228 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 516 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.04724
trainer/QF2 Loss                    1.19233
trainer/Policy Loss                41.4017
trainer/Q1 Predictions Mean       -39.3665
trainer/Q1 Predictions Std         38.7725
trainer/Q1 Predictions Max         -6.27442
trainer/Q1 Predictions Min       -135.524
trainer/Q2 Predictions Mean       -39.3171
trainer/Q2 Predictions Std         38.7776
trainer/Q2 Predictions Max         -6.24642
trainer/Q2 Predictions Min       -135.101
trainer/Q Targets Mean            -39.7102
trainer/Q Targets Std              39.1096
trainer/Q Targets Max              -0.301665
trainer/Q Targets Min            -136.889
trainer/Log Pis Mean                2.11083
trainer/Log Pis Std                 0.94631
trainer/Log Pis Max                 5.27452
trainer/Log Pis Min                -0.575613
trainer/Policy mu Mean              0.0104925
trainer/Policy mu Std               0.463958
trainer/Policy mu Max               2.21531
trainer/Policy mu Min              -2.88847
trainer/Policy log std Mean        -2.24828
trainer/Policy log std Std          0.413137
trainer/Policy log std Max         -0.696134
trainer/Policy log std Min         -3.21183
trainer/Alpha                       0.0688298
trainer/Alpha Loss                  0.29658
exploration/num steps total    258700
exploration/num paths total      2587
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.52781
exploration/Rewards Std             1.23062
exploration/Rewards Max            -0.00528775
exploration/Rewards Min            -9.38995
exploration/Returns Mean         -152.781
exploration/Returns Std            81.8518
exploration/Returns Max           -50.71
exploration/Returns Min          -289.767
exploration/Actions Mean            0.00730395
exploration/Actions Std             0.232303
exploration/Actions Max             0.999616
exploration/Actions Min            -0.995338
exploration/Num Paths               5
exploration/Average Returns      -152.781
evaluation/num steps total     775500
evaluation/num paths total       7755
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.730856
evaluation/Rewards Std              1.28851
evaluation/Rewards Max             -0.0168099
evaluation/Rewards Min            -11.7496
evaluation/Returns Mean           -73.0856
evaluation/Returns Std             85.4579
evaluation/Returns Max             -7.96078
evaluation/Returns Min           -282.955
evaluation/Actions Mean             0.00378336
evaluation/Actions Std              0.183195
evaluation/Actions Max              0.999466
evaluation/Actions Min             -0.995963
evaluation/Num Paths               15
evaluation/Average Returns        -73.0856
time/data storing (s)               0.00280342
time/evaluation sampling (s)        0.319814
time/exploration sampling (s)       0.137076
time/logging (s)                    0.00479503
time/saving (s)                     0.0101682
time/training (s)                   1.99652
time/epoch (s)                      2.47117
time/total (s)                   1269.66
Epoch                             516
-----------------------------  ---------------
2019-04-23 01:34:44.814613 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 517 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.185686
trainer/QF2 Loss                    0.226999
trainer/Policy Loss                40.7508
trainer/Q1 Predictions Mean       -38.6721
trainer/Q1 Predictions Std         39.7317
trainer/Q1 Predictions Max         -6.43085
trainer/Q1 Predictions Min       -139.067
trainer/Q2 Predictions Mean       -38.7004
trainer/Q2 Predictions Std         39.7852
trainer/Q2 Predictions Max         -6.37524
trainer/Q2 Predictions Min       -139.479
trainer/Q Targets Mean            -38.7629
trainer/Q Targets Std              39.6622
trainer/Q Targets Max              -6.42737
trainer/Q Targets Min            -138.661
trainer/Log Pis Mean                2.10639
trainer/Log Pis Std                 1.44096
trainer/Log Pis Max                 9.95216
trainer/Log Pis Min                -2.67755
trainer/Policy mu Mean             -0.00776923
trainer/Policy mu Std               0.597935
trainer/Policy mu Max               3.23063
trainer/Policy mu Min              -3.38745
trainer/Policy log std Mean        -2.25172
trainer/Policy log std Std          0.467367
trainer/Policy log std Max         -0.0421346
trainer/Policy log std Min         -3.25776
trainer/Alpha                       0.0671815
trainer/Alpha Loss                  0.287286
exploration/num steps total    259200
exploration/num paths total      2592
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.31343
exploration/Rewards Std             1.35566
exploration/Rewards Max            -0.0347945
exploration/Rewards Min           -10.7967
exploration/Returns Mean         -131.343
exploration/Returns Std           104.626
exploration/Returns Max           -36.4286
exploration/Returns Min          -327.487
exploration/Actions Mean           -0.0141627
exploration/Actions Std             0.239836
exploration/Actions Max             0.990224
exploration/Actions Min            -0.999038
exploration/Num Paths               5
exploration/Average Returns      -131.343
evaluation/num steps total     777000
evaluation/num paths total       7770
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.721631
evaluation/Rewards Std              0.798838
evaluation/Rewards Max             -0.0152103
evaluation/Rewards Min             -7.6128
evaluation/Returns Mean           -72.1631
evaluation/Returns Std             43.7555
evaluation/Returns Max             -6.39549
evaluation/Returns Min           -164.426
evaluation/Actions Mean             0.00554239
evaluation/Actions Std              0.170287
evaluation/Actions Max              0.998691
evaluation/Actions Min             -0.998412
evaluation/Num Paths               15
evaluation/Average Returns        -72.1631
time/data storing (s)               0.0027402
time/evaluation sampling (s)        0.320024
time/exploration sampling (s)       0.137902
time/logging (s)                    0.00400738
time/saving (s)                     0.00157046
time/training (s)                   1.96583
time/epoch (s)                      2.43207
time/total (s)                   1272.09
Epoch                             517
-----------------------------  ---------------
2019-04-23 01:34:47.257936 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 518 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.229948
trainer/QF2 Loss                    0.208096
trainer/Policy Loss                37.6944
trainer/Q1 Predictions Mean       -35.6865
trainer/Q1 Predictions Std         38.4387
trainer/Q1 Predictions Max         -6.12162
trainer/Q1 Predictions Min       -141.098
trainer/Q2 Predictions Mean       -35.6895
trainer/Q2 Predictions Std         38.3995
trainer/Q2 Predictions Max         -6.02311
trainer/Q2 Predictions Min       -140.263
trainer/Q Targets Mean            -35.7047
trainer/Q Targets Std              38.4429
trainer/Q Targets Max              -6.31107
trainer/Q Targets Min            -140.815
trainer/Log Pis Mean                2.13928
trainer/Log Pis Std                 1.20731
trainer/Log Pis Max                 5.64517
trainer/Log Pis Min                -1.86053
trainer/Policy mu Mean             -0.0480611
trainer/Policy mu Std               0.621343
trainer/Policy mu Max               2.82076
trainer/Policy mu Min              -3.42282
trainer/Policy log std Mean        -2.19848
trainer/Policy log std Std          0.491846
trainer/Policy log std Max         -0.405781
trainer/Policy log std Min         -3.19204
trainer/Alpha                       0.0704157
trainer/Alpha Loss                  0.369564
exploration/num steps total    259700
exploration/num paths total      2597
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.729665
exploration/Rewards Std             1.086
exploration/Rewards Max            -0.0029139
exploration/Rewards Min           -11.2277
exploration/Returns Mean          -72.9665
exploration/Returns Std            59.1814
exploration/Returns Max           -19.6979
exploration/Returns Min          -160.637
exploration/Actions Mean           -0.0148065
exploration/Actions Std             0.220271
exploration/Actions Max             0.999684
exploration/Actions Min            -0.998175
exploration/Num Paths               5
exploration/Average Returns       -72.9665
evaluation/num steps total     778500
evaluation/num paths total       7785
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.842014
evaluation/Rewards Std              0.971902
evaluation/Rewards Max             -0.00160392
evaluation/Rewards Min             -7.82919
evaluation/Returns Mean           -84.2014
evaluation/Returns Std             59.0512
evaluation/Returns Max             -7.3899
evaluation/Returns Min           -165.011
evaluation/Actions Mean            -0.00953324
evaluation/Actions Std              0.181897
evaluation/Actions Max              0.998489
evaluation/Actions Min             -0.999539
evaluation/Num Paths               15
evaluation/Average Returns        -84.2014
time/data storing (s)               0.00273148
time/evaluation sampling (s)        0.319372
time/exploration sampling (s)       0.13492
time/logging (s)                    0.00485512
time/saving (s)                     0.00191956
time/training (s)                   1.96912
time/epoch (s)                      2.43292
time/total (s)                   1274.53
Epoch                             518
-----------------------------  ---------------
2019-04-23 01:34:49.683716 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 519 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    8.03232
trainer/QF2 Loss                    8.22525
trainer/Policy Loss                44.1068
trainer/Q1 Predictions Mean       -42.2057
trainer/Q1 Predictions Std         44.1252
trainer/Q1 Predictions Max         -6.26753
trainer/Q1 Predictions Min       -142.404
trainer/Q2 Predictions Mean       -42.1912
trainer/Q2 Predictions Std         44.1028
trainer/Q2 Predictions Max         -6.2433
trainer/Q2 Predictions Min       -141.299
trainer/Q Targets Mean            -42.1912
trainer/Q Targets Std              44.3795
trainer/Q Targets Max              -0.426773
trainer/Q Targets Min            -140.919
trainer/Log Pis Mean                1.9828
trainer/Log Pis Std                 1.06151
trainer/Log Pis Max                 4.75732
trainer/Log Pis Min                -2.16574
trainer/Policy mu Mean              0.0046039
trainer/Policy mu Std               0.357956
trainer/Policy mu Max               2.3122
trainer/Policy mu Min              -1.60447
trainer/Policy log std Mean        -2.2885
trainer/Policy log std Std          0.411799
trainer/Policy log std Max         -0.681908
trainer/Policy log std Min         -3.28153
trainer/Alpha                       0.071176
trainer/Alpha Loss                 -0.0454505
exploration/num steps total    260200
exploration/num paths total      2602
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.880225
exploration/Rewards Std             1.13197
exploration/Rewards Max            -0.0106423
exploration/Rewards Min            -9.63116
exploration/Returns Mean          -88.0225
exploration/Returns Std            38.5093
exploration/Returns Max           -39.9675
exploration/Returns Min          -139.522
exploration/Actions Mean            0.0136988
exploration/Actions Std             0.24507
exploration/Actions Max             0.999644
exploration/Actions Min            -0.994975
exploration/Num Paths               5
exploration/Average Returns       -88.0225
evaluation/num steps total     780000
evaluation/num paths total       7800
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.78438
evaluation/Rewards Std              1.16092
evaluation/Rewards Max             -0.0502639
evaluation/Rewards Min            -10.6445
evaluation/Returns Mean           -78.438
evaluation/Returns Std             73.5901
evaluation/Returns Max             -6.64603
evaluation/Returns Min           -293.946
evaluation/Actions Mean            -0.0140355
evaluation/Actions Std              0.175372
evaluation/Actions Max              0.998648
evaluation/Actions Min             -0.997859
evaluation/Num Paths               15
evaluation/Average Returns        -78.438
time/data storing (s)               0.00275482
time/evaluation sampling (s)        0.317881
time/exploration sampling (s)       0.139247
time/logging (s)                    0.00475552
time/saving (s)                     0.00192619
time/training (s)                   1.94737
time/epoch (s)                      2.41394
time/total (s)                   1276.95
Epoch                             519
-----------------------------  ---------------
2019-04-23 01:34:52.140841 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 520 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   24.0601
trainer/QF2 Loss                   23.9807
trainer/Policy Loss                36.7168
trainer/Q1 Predictions Mean       -34.7865
trainer/Q1 Predictions Std         36.4959
trainer/Q1 Predictions Max         -6.31182
trainer/Q1 Predictions Min       -135.516
trainer/Q2 Predictions Mean       -34.8118
trainer/Q2 Predictions Std         36.5194
trainer/Q2 Predictions Max         -6.2753
trainer/Q2 Predictions Min       -135.709
trainer/Q Targets Mean            -34.8337
trainer/Q Targets Std              37.3108
trainer/Q Targets Max              -0.111406
trainer/Q Targets Min            -137.647
trainer/Log Pis Mean                2.00226
trainer/Log Pis Std                 0.960213
trainer/Log Pis Max                 4.23269
trainer/Log Pis Min                -0.842355
trainer/Policy mu Mean             -0.0511177
trainer/Policy mu Std               0.371941
trainer/Policy mu Max               2.87595
trainer/Policy mu Min              -2.87276
trainer/Policy log std Mean        -2.32957
trainer/Policy log std Std          0.359089
trainer/Policy log std Max         -0.601304
trainer/Policy log std Min         -3.19813
trainer/Alpha                       0.0728484
trainer/Alpha Loss                  0.00592679
exploration/num steps total    260700
exploration/num paths total      2607
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.527442
exploration/Rewards Std             0.913286
exploration/Rewards Max            -0.0148176
exploration/Rewards Min            -8.85214
exploration/Returns Mean          -52.7442
exploration/Returns Std            29.4643
exploration/Returns Max           -20.5001
exploration/Returns Min           -94.0381
exploration/Actions Mean           -0.0157498
exploration/Actions Std             0.212844
exploration/Actions Max             0.998229
exploration/Actions Min            -0.999537
exploration/Num Paths               5
exploration/Average Returns       -52.7442
evaluation/num steps total     781500
evaluation/num paths total       7815
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.511905
evaluation/Rewards Std              1.07937
evaluation/Rewards Max             -0.0175583
evaluation/Rewards Min             -9.24601
evaluation/Returns Mean           -51.1905
evaluation/Returns Std             26.7972
evaluation/Returns Max            -10.6832
evaluation/Returns Min           -109.885
evaluation/Actions Mean             0.00492653
evaluation/Actions Std              0.198994
evaluation/Actions Max              0.998603
evaluation/Actions Min             -0.997926
evaluation/Num Paths               15
evaluation/Average Returns        -51.1905
time/data storing (s)               0.00263852
time/evaluation sampling (s)        0.322462
time/exploration sampling (s)       0.139494
time/logging (s)                    0.00420855
time/saving (s)                     0.00155777
time/training (s)                   1.97533
time/epoch (s)                      2.44569
time/total (s)                   1279.4
Epoch                             520
-----------------------------  ---------------
2019-04-23 01:34:54.575838 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 521 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.0947
trainer/QF2 Loss                    1.07936
trainer/Policy Loss                36.3226
trainer/Q1 Predictions Mean       -34.4808
trainer/Q1 Predictions Std         35.8078
trainer/Q1 Predictions Max         -6.37727
trainer/Q1 Predictions Min       -134.327
trainer/Q2 Predictions Mean       -34.4738
trainer/Q2 Predictions Std         35.8243
trainer/Q2 Predictions Max         -6.33476
trainer/Q2 Predictions Min       -134.368
trainer/Q Targets Mean            -35.1495
trainer/Q Targets Std              36.5778
trainer/Q Targets Max              -6.39075
trainer/Q Targets Min            -136.784
trainer/Log Pis Mean                1.93923
trainer/Log Pis Std                 0.906651
trainer/Log Pis Max                 4.064
trainer/Log Pis Min                -1.26595
trainer/Policy mu Mean             -0.0261839
trainer/Policy mu Std               0.309543
trainer/Policy mu Max               2.10496
trainer/Policy mu Min              -1.09388
trainer/Policy log std Mean        -2.26681
trainer/Policy log std Std          0.339752
trainer/Policy log std Max         -0.59435
trainer/Policy log std Min         -3.08863
trainer/Alpha                       0.0758766
trainer/Alpha Loss                 -0.1567
exploration/num steps total    261200
exploration/num paths total      2612
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.11518
exploration/Rewards Std             1.55655
exploration/Rewards Max            -0.0193851
exploration/Rewards Min            -8.85426
exploration/Returns Mean         -111.518
exploration/Returns Std            91.7726
exploration/Returns Max           -49.0843
exploration/Returns Min          -288.848
exploration/Actions Mean            0.00669533
exploration/Actions Std             0.239446
exploration/Actions Max             0.999968
exploration/Actions Min            -0.999375
exploration/Num Paths               5
exploration/Average Returns      -111.518
evaluation/num steps total     783000
evaluation/num paths total       7830
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.12121
evaluation/Rewards Std              1.43472
evaluation/Rewards Max             -0.0134229
evaluation/Rewards Min            -11.1824
evaluation/Returns Mean          -112.121
evaluation/Returns Std            100.359
evaluation/Returns Max             -4.69125
evaluation/Returns Min           -310.234
evaluation/Actions Mean             0.0160284
evaluation/Actions Std              0.184366
evaluation/Actions Max              0.999144
evaluation/Actions Min             -0.996245
evaluation/Num Paths               15
evaluation/Average Returns       -112.121
time/data storing (s)               0.00274178
time/evaluation sampling (s)        0.323108
time/exploration sampling (s)       0.136346
time/logging (s)                    0.00477897
time/saving (s)                     0.00195099
time/training (s)                   1.95638
time/epoch (s)                      2.42531
time/total (s)                   1281.83
Epoch                             521
-----------------------------  ---------------
2019-04-23 01:34:57.049089 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 522 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.38014
trainer/QF2 Loss                    1.38525
trainer/Policy Loss                37.5991
trainer/Q1 Predictions Mean       -35.4911
trainer/Q1 Predictions Std         32.6559
trainer/Q1 Predictions Max         -6.45066
trainer/Q1 Predictions Min       -136.589
trainer/Q2 Predictions Mean       -35.4747
trainer/Q2 Predictions Std         32.6473
trainer/Q2 Predictions Max         -6.38549
trainer/Q2 Predictions Min       -135.991
trainer/Q Targets Mean            -35.6428
trainer/Q Targets Std              33.0564
trainer/Q Targets Max              -0.141231
trainer/Q Targets Min            -137.275
trainer/Log Pis Mean                2.22492
trainer/Log Pis Std                 1.33775
trainer/Log Pis Max                 9.32403
trainer/Log Pis Min                -2.26519
trainer/Policy mu Mean             -0.0280257
trainer/Policy mu Std               0.49222
trainer/Policy mu Max               3.51792
trainer/Policy mu Min              -2.35796
trainer/Policy log std Mean        -2.31932
trainer/Policy log std Std          0.426255
trainer/Policy log std Max         -0.0991649
trainer/Policy log std Min         -3.24849
trainer/Alpha                       0.0746435
trainer/Alpha Loss                  0.583696
exploration/num steps total    261700
exploration/num paths total      2617
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.533766
exploration/Rewards Std             1.20238
exploration/Rewards Max            -0.0129971
exploration/Rewards Min           -10.1828
exploration/Returns Mean          -53.3766
exploration/Returns Std            33.7365
exploration/Returns Max           -22.6127
exploration/Returns Min          -115.842
exploration/Actions Mean           -0.018539
exploration/Actions Std             0.232066
exploration/Actions Max             0.999738
exploration/Actions Min            -0.999194
exploration/Num Paths               5
exploration/Average Returns       -53.3766
evaluation/num steps total     784500
evaluation/num paths total       7845
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.831584
evaluation/Rewards Std              1.13681
evaluation/Rewards Max             -0.0774109
evaluation/Rewards Min             -9.42427
evaluation/Returns Mean           -83.1584
evaluation/Returns Std             71.8954
evaluation/Returns Max             -8.37677
evaluation/Returns Min           -297.195
evaluation/Actions Mean             0.00109795
evaluation/Actions Std              0.185025
evaluation/Actions Max              0.998777
evaluation/Actions Min             -0.997029
evaluation/Num Paths               15
evaluation/Average Returns        -83.1584
time/data storing (s)               0.00288028
time/evaluation sampling (s)        0.318489
time/exploration sampling (s)       0.151721
time/logging (s)                    0.00421575
time/saving (s)                     0.00194394
time/training (s)                   1.98146
time/epoch (s)                      2.46071
time/total (s)                   1284.29
Epoch                             522
-----------------------------  ---------------
2019-04-23 01:34:59.484181 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 523 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   62.3839
trainer/QF2 Loss                   62.5907
trainer/Policy Loss                41.2778
trainer/Q1 Predictions Mean       -39.4781
trainer/Q1 Predictions Std         36.1819
trainer/Q1 Predictions Max         -6.43828
trainer/Q1 Predictions Min       -137.325
trainer/Q2 Predictions Mean       -39.5017
trainer/Q2 Predictions Std         36.1475
trainer/Q2 Predictions Max         -6.40636
trainer/Q2 Predictions Min       -136.243
trainer/Q Targets Mean            -38.8026
trainer/Q Targets Std              36.9803
trainer/Q Targets Max              -0.028371
trainer/Q Targets Min            -138.8
trainer/Log Pis Mean                1.90447
trainer/Log Pis Std                 1.31392
trainer/Log Pis Max                 9.7263
trainer/Log Pis Min                -2.25208
trainer/Policy mu Mean             -0.100701
trainer/Policy mu Std               0.511199
trainer/Policy mu Max               2.71591
trainer/Policy mu Min              -3.49896
trainer/Policy log std Mean        -2.23608
trainer/Policy log std Std          0.406306
trainer/Policy log std Max         -0.519047
trainer/Policy log std Min         -3.16847
trainer/Alpha                       0.0759657
trainer/Alpha Loss                 -0.246233
exploration/num steps total    262200
exploration/num paths total      2622
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.02551
exploration/Rewards Std             1.17503
exploration/Rewards Max            -0.0135314
exploration/Rewards Min            -9.12183
exploration/Returns Mean         -102.551
exploration/Returns Std            55.3587
exploration/Returns Max           -36.0266
exploration/Returns Min          -171.068
exploration/Actions Mean            0.0136102
exploration/Actions Std             0.243052
exploration/Actions Max             0.998103
exploration/Actions Min            -0.999071
exploration/Num Paths               5
exploration/Average Returns      -102.551
evaluation/num steps total     786000
evaluation/num paths total       7860
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.24826
evaluation/Rewards Std              1.20818
evaluation/Rewards Max             -0.0403905
evaluation/Rewards Min             -8.60502
evaluation/Returns Mean          -124.826
evaluation/Returns Std             94.6791
evaluation/Returns Max            -11.0237
evaluation/Returns Min           -298.591
evaluation/Actions Mean             0.00275885
evaluation/Actions Std              0.18052
evaluation/Actions Max              0.997941
evaluation/Actions Min             -0.998502
evaluation/Num Paths               15
evaluation/Average Returns       -124.826
time/data storing (s)               0.00259357
time/evaluation sampling (s)        0.323006
time/exploration sampling (s)       0.135743
time/logging (s)                    0.00354994
time/saving (s)                     0.00194485
time/training (s)                   1.95581
time/epoch (s)                      2.42264
time/total (s)                   1286.72
Epoch                             523
-----------------------------  ---------------
2019-04-23 01:35:01.926728 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 524 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   38.7538
trainer/QF2 Loss                   38.8892
trainer/Policy Loss                34.4429
trainer/Q1 Predictions Mean       -32.5911
trainer/Q1 Predictions Std         38.8856
trainer/Q1 Predictions Max         -6.39295
trainer/Q1 Predictions Min       -147.506
trainer/Q2 Predictions Mean       -32.5723
trainer/Q2 Predictions Std         38.8833
trainer/Q2 Predictions Max         -6.38966
trainer/Q2 Predictions Min       -148.09
trainer/Q Targets Mean            -32.3663
trainer/Q Targets Std              39.3795
trainer/Q Targets Max              -1.77594
trainer/Q Targets Min            -147.716
trainer/Log Pis Mean                1.95972
trainer/Log Pis Std                 1.07684
trainer/Log Pis Max                 6.11004
trainer/Log Pis Min                -2.10812
trainer/Policy mu Mean             -0.113908
trainer/Policy mu Std               0.514271
trainer/Policy mu Max               2.13178
trainer/Policy mu Min              -2.9253
trainer/Policy log std Mean        -2.16794
trainer/Policy log std Std          0.406413
trainer/Policy log std Max         -0.689594
trainer/Policy log std Min         -3.04491
trainer/Alpha                       0.0752016
trainer/Alpha Loss                 -0.104217
exploration/num steps total    262700
exploration/num paths total      2627
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.20801
exploration/Rewards Std             1.38419
exploration/Rewards Max            -0.0089614
exploration/Rewards Min            -9.62161
exploration/Returns Mean         -120.801
exploration/Returns Std            92.1617
exploration/Returns Max           -24.2627
exploration/Returns Min          -284.622
exploration/Actions Mean            0.00668973
exploration/Actions Std             0.237384
exploration/Actions Max             0.998123
exploration/Actions Min            -0.998942
exploration/Num Paths               5
exploration/Average Returns      -120.801
evaluation/num steps total     787500
evaluation/num paths total       7875
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.601213
evaluation/Rewards Std              1.11539
evaluation/Rewards Max             -0.00725027
evaluation/Rewards Min            -11.4343
evaluation/Returns Mean           -60.1213
evaluation/Returns Std             68.6861
evaluation/Returns Max             -6.84757
evaluation/Returns Min           -282.919
evaluation/Actions Mean             0.00743404
evaluation/Actions Std              0.17489
evaluation/Actions Max              0.997701
evaluation/Actions Min             -0.998611
evaluation/Num Paths               15
evaluation/Average Returns        -60.1213
time/data storing (s)               0.00275461
time/evaluation sampling (s)        0.322313
time/exploration sampling (s)       0.135696
time/logging (s)                    0.00478885
time/saving (s)                     0.00192447
time/training (s)                   1.96496
time/epoch (s)                      2.43244
time/total (s)                   1289.16
Epoch                             524
-----------------------------  ---------------
2019-04-23 01:35:04.370452 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 525 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                  178.942
trainer/QF2 Loss                  176.289
trainer/Policy Loss                39.0482
trainer/Q1 Predictions Mean       -37.4905
trainer/Q1 Predictions Std         36.7289
trainer/Q1 Predictions Max         -6.43617
trainer/Q1 Predictions Min       -136.325
trainer/Q2 Predictions Mean       -37.4496
trainer/Q2 Predictions Std         36.6546
trainer/Q2 Predictions Max         -6.46272
trainer/Q2 Predictions Min       -135.262
trainer/Q Targets Mean            -36.7189
trainer/Q Targets Std              36.2231
trainer/Q Targets Max              -0.395754
trainer/Q Targets Min            -137.653
trainer/Log Pis Mean                1.65263
trainer/Log Pis Std                 1.27011
trainer/Log Pis Max                 3.71786
trainer/Log Pis Min                -3.24971
trainer/Policy mu Mean             -0.0172877
trainer/Policy mu Std               0.286923
trainer/Policy mu Max               0.972002
trainer/Policy mu Min              -2.39763
trainer/Policy log std Mean        -2.28395
trainer/Policy log std Std          0.340548
trainer/Policy log std Max         -0.655215
trainer/Policy log std Min         -3.25307
trainer/Alpha                       0.0738929
trainer/Alpha Loss                 -0.904934
exploration/num steps total    263200
exploration/num paths total      2632
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.752837
exploration/Rewards Std             0.86912
exploration/Rewards Max            -0.0146483
exploration/Rewards Min            -7.82478
exploration/Returns Mean          -75.2837
exploration/Returns Std            43.6322
exploration/Returns Max           -17.3723
exploration/Returns Min          -148.706
exploration/Actions Mean            0.00231
exploration/Actions Std             0.189189
exploration/Actions Max             0.998723
exploration/Actions Min            -0.997721
exploration/Num Paths               5
exploration/Average Returns       -75.2837
evaluation/num steps total     789000
evaluation/num paths total       7890
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.899783
evaluation/Rewards Std              1.17583
evaluation/Rewards Max             -0.0235226
evaluation/Rewards Min            -11.104
evaluation/Returns Mean           -89.9783
evaluation/Returns Std             80.1527
evaluation/Returns Max             -6.5416
evaluation/Returns Min           -281.624
evaluation/Actions Mean             0.00240645
evaluation/Actions Std              0.174324
evaluation/Actions Max              0.997919
evaluation/Actions Min             -0.997628
evaluation/Num Paths               15
evaluation/Average Returns        -89.9783
time/data storing (s)               0.00255728
time/evaluation sampling (s)        0.31825
time/exploration sampling (s)       0.136462
time/logging (s)                    0.00479909
time/saving (s)                     0.00193242
time/training (s)                   1.96785
time/epoch (s)                      2.43185
time/total (s)                   1291.59
Epoch                             525
-----------------------------  ---------------
2019-04-23 01:35:06.823249 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 526 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                  195.53
trainer/QF2 Loss                  196.544
trainer/Policy Loss                35.3311
trainer/Q1 Predictions Mean       -33.3995
trainer/Q1 Predictions Std         34.387
trainer/Q1 Predictions Max         -6.55761
trainer/Q1 Predictions Min       -140.691
trainer/Q2 Predictions Mean       -33.3825
trainer/Q2 Predictions Std         34.3691
trainer/Q2 Predictions Max         -6.61651
trainer/Q2 Predictions Min       -139.69
trainer/Q Targets Mean            -31.708
trainer/Q Targets Std              33.1645
trainer/Q Targets Max              -0.854014
trainer/Q Targets Min            -140.518
trainer/Log Pis Mean                2.05501
trainer/Log Pis Std                 1.09961
trainer/Log Pis Max                 5.16047
trainer/Log Pis Min                -2.64892
trainer/Policy mu Mean             -0.0602584
trainer/Policy mu Std               0.439014
trainer/Policy mu Max               2.26215
trainer/Policy mu Min              -3.43312
trainer/Policy log std Mean        -2.29682
trainer/Policy log std Std          0.401056
trainer/Policy log std Max         -0.498267
trainer/Policy log std Min         -3.29683
trainer/Alpha                       0.0763351
trainer/Alpha Loss                  0.141522
exploration/num steps total    263700
exploration/num paths total      2637
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.690638
exploration/Rewards Std             0.724286
exploration/Rewards Max            -0.0127896
exploration/Rewards Min            -6.95073
exploration/Returns Mean          -69.0638
exploration/Returns Std            54.4591
exploration/Returns Max           -14.7924
exploration/Returns Min          -163.675
exploration/Actions Mean            0.00365381
exploration/Actions Std             0.17583
exploration/Actions Max             0.995151
exploration/Actions Min            -0.99724
exploration/Num Paths               5
exploration/Average Returns       -69.0638
evaluation/num steps total     790500
evaluation/num paths total       7905
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.673134
evaluation/Rewards Std              0.882803
evaluation/Rewards Max             -0.0128623
evaluation/Rewards Min             -9.21344
evaluation/Returns Mean           -67.3134
evaluation/Returns Std             47.4432
evaluation/Returns Max             -9.55857
evaluation/Returns Min           -154.72
evaluation/Actions Mean             0.00254827
evaluation/Actions Std              0.174361
evaluation/Actions Max              0.99736
evaluation/Actions Min             -0.996905
evaluation/Num Paths               15
evaluation/Average Returns        -67.3134
time/data storing (s)               0.00269053
time/evaluation sampling (s)        0.314983
time/exploration sampling (s)       0.138466
time/logging (s)                    0.00353193
time/saving (s)                     0.00190139
time/training (s)                   1.97821
time/epoch (s)                      2.43978
time/total (s)                   1294.04
Epoch                             526
-----------------------------  ---------------
2019-04-23 01:35:09.264353 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 527 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   75.1421
trainer/QF2 Loss                   75.1794
trainer/Policy Loss                34.0581
trainer/Q1 Predictions Mean       -32.0709
trainer/Q1 Predictions Std         34.606
trainer/Q1 Predictions Max         -6.46762
trainer/Q1 Predictions Min       -134.497
trainer/Q2 Predictions Mean       -32.1122
trainer/Q2 Predictions Std         34.639
trainer/Q2 Predictions Max         -6.4832
trainer/Q2 Predictions Min       -134.459
trainer/Q Targets Mean            -31.2678
trainer/Q Targets Std              35.1393
trainer/Q Targets Max              -1.27009
trainer/Q Targets Min            -136.658
trainer/Log Pis Mean                2.04985
trainer/Log Pis Std                 1.31259
trainer/Log Pis Max                 8.88985
trainer/Log Pis Min                -1.6424
trainer/Policy mu Mean             -0.00838194
trainer/Policy mu Std               0.573662
trainer/Policy mu Max               2.9531
trainer/Policy mu Min              -3.14829
trainer/Policy log std Mean        -2.22356
trainer/Policy log std Std          0.432955
trainer/Policy log std Max         -0.503008
trainer/Policy log std Min         -3.0811
trainer/Alpha                       0.0776082
trainer/Alpha Loss                  0.127424
exploration/num steps total    264200
exploration/num paths total      2642
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.90514
exploration/Rewards Std             1.20701
exploration/Rewards Max            -0.00566529
exploration/Rewards Min            -6.18539
exploration/Returns Mean          -90.514
exploration/Returns Std           109.922
exploration/Returns Max           -19.8435
exploration/Returns Min          -305.233
exploration/Actions Mean           -0.00216858
exploration/Actions Std             0.206128
exploration/Actions Max             0.990084
exploration/Actions Min            -0.999033
exploration/Num Paths               5
exploration/Average Returns       -90.514
evaluation/num steps total     792000
evaluation/num paths total       7920
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.688936
evaluation/Rewards Std              1.23953
evaluation/Rewards Max             -0.018755
evaluation/Rewards Min            -10.6036
evaluation/Returns Mean           -68.8936
evaluation/Returns Std             82.0075
evaluation/Returns Max            -10.1365
evaluation/Returns Min           -304.716
evaluation/Actions Mean             0.00553768
evaluation/Actions Std              0.184111
evaluation/Actions Max              0.998008
evaluation/Actions Min             -0.996839
evaluation/Num Paths               15
evaluation/Average Returns        -68.8936
time/data storing (s)               0.0026107
time/evaluation sampling (s)        0.317363
time/exploration sampling (s)       0.136096
time/logging (s)                    0.00481774
time/saving (s)                     0.00192664
time/training (s)                   1.96833
time/epoch (s)                      2.43114
time/total (s)                   1296.47
Epoch                             527
-----------------------------  ---------------
2019-04-23 01:35:11.696487 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 528 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.29181
trainer/QF2 Loss                    0.314704
trainer/Policy Loss                35.8199
trainer/Q1 Predictions Mean       -33.8172
trainer/Q1 Predictions Std         37.4614
trainer/Q1 Predictions Max         -6.44346
trainer/Q1 Predictions Min       -141.03
trainer/Q2 Predictions Mean       -33.8075
trainer/Q2 Predictions Std         37.4482
trainer/Q2 Predictions Max         -6.44276
trainer/Q2 Predictions Min       -140.63
trainer/Q Targets Mean            -34.1982
trainer/Q Targets Std              37.6643
trainer/Q Targets Max              -6.59282
trainer/Q Targets Min            -141.942
trainer/Log Pis Mean                2.11255
trainer/Log Pis Std                 1.24929
trainer/Log Pis Max                 4.101
trainer/Log Pis Min                -5.92583
trainer/Policy mu Mean             -0.0426145
trainer/Policy mu Std               0.383084
trainer/Policy mu Max               1.96598
trainer/Policy mu Min              -2.63253
trainer/Policy log std Mean        -2.32828
trainer/Policy log std Std          0.380241
trainer/Policy log std Max         -0.445893
trainer/Policy log std Min         -3.09093
trainer/Alpha                       0.0774603
trainer/Alpha Loss                  0.287919
exploration/num steps total    264700
exploration/num paths total      2647
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.312588
exploration/Rewards Std             0.801202
exploration/Rewards Max            -0.00681471
exploration/Rewards Min            -8.36344
exploration/Returns Mean          -31.2588
exploration/Returns Std            11.7662
exploration/Returns Max           -20.1132
exploration/Returns Min           -52.4628
exploration/Actions Mean            0.000963887
exploration/Actions Std             0.207467
exploration/Actions Max             0.998702
exploration/Actions Min            -0.998263
exploration/Num Paths               5
exploration/Average Returns       -31.2588
evaluation/num steps total     793500
evaluation/num paths total       7935
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.691978
evaluation/Rewards Std              0.968981
evaluation/Rewards Max             -0.0250998
evaluation/Rewards Min             -8.85488
evaluation/Returns Mean           -69.1978
evaluation/Returns Std             47.7459
evaluation/Returns Max            -13.035
evaluation/Returns Min           -156.223
evaluation/Actions Mean            -0.00765568
evaluation/Actions Std              0.184043
evaluation/Actions Max              0.998419
evaluation/Actions Min             -0.997449
evaluation/Num Paths               15
evaluation/Average Returns        -69.1978
time/data storing (s)               0.00258729
time/evaluation sampling (s)        0.321712
time/exploration sampling (s)       0.136573
time/logging (s)                    0.00474634
time/saving (s)                     0.0015316
time/training (s)                   1.95344
time/epoch (s)                      2.42059
time/total (s)                   1298.9
Epoch                             528
-----------------------------  ----------------
2019-04-23 01:35:14.175476 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 529 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    2.23589
trainer/QF2 Loss                    2.16123
trainer/Policy Loss                42.7508
trainer/Q1 Predictions Mean       -40.9383
trainer/Q1 Predictions Std         39.7082
trainer/Q1 Predictions Max         -6.7438
trainer/Q1 Predictions Min       -146.322
trainer/Q2 Predictions Mean       -40.9827
trainer/Q2 Predictions Std         39.7904
trainer/Q2 Predictions Max         -6.75458
trainer/Q2 Predictions Min       -149.026
trainer/Q Targets Mean            -41.1491
trainer/Q Targets Std              40.2886
trainer/Q Targets Max              -0.127486
trainer/Q Targets Min            -149.364
trainer/Log Pis Mean                1.89066
trainer/Log Pis Std                 1.02175
trainer/Log Pis Max                 4.88325
trainer/Log Pis Min                -1.49442
trainer/Policy mu Mean             -0.0417734
trainer/Policy mu Std               0.496356
trainer/Policy mu Max               2.91018
trainer/Policy mu Min              -2.53695
trainer/Policy log std Mean        -2.1985
trainer/Policy log std Std          0.392597
trainer/Policy log std Max         -0.443152
trainer/Policy log std Min         -3.00759
trainer/Alpha                       0.0793751
trainer/Alpha Loss                 -0.277019
exploration/num steps total    265200
exploration/num paths total      2652
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.426561
exploration/Rewards Std             0.803238
exploration/Rewards Max            -0.00963468
exploration/Rewards Min            -7.55233
exploration/Returns Mean          -42.6561
exploration/Returns Std            14.0173
exploration/Returns Max           -24.5646
exploration/Returns Min           -66.718
exploration/Actions Mean           -0.0016616
exploration/Actions Std             0.225734
exploration/Actions Max             0.99892
exploration/Actions Min            -0.999436
exploration/Num Paths               5
exploration/Average Returns       -42.6561
evaluation/num steps total     795000
evaluation/num paths total       7950
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.942059
evaluation/Rewards Std              1.2589
evaluation/Rewards Max             -0.0280371
evaluation/Rewards Min            -10.675
evaluation/Returns Mean           -94.2059
evaluation/Returns Std             82.2757
evaluation/Returns Max            -15.2926
evaluation/Returns Min           -287.353
evaluation/Actions Mean             0.00358243
evaluation/Actions Std              0.183969
evaluation/Actions Max              0.998027
evaluation/Actions Min             -0.994956
evaluation/Num Paths               15
evaluation/Average Returns        -94.2059
time/data storing (s)               0.00272521
time/evaluation sampling (s)        0.349742
time/exploration sampling (s)       0.137355
time/logging (s)                    0.00482362
time/saving (s)                     0.00993987
time/training (s)                   1.96388
time/epoch (s)                      2.46847
time/total (s)                   1301.37
Epoch                             529
-----------------------------  ---------------
2019-04-23 01:35:16.630415 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 530 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.321208
trainer/QF2 Loss                    0.327393
trainer/Policy Loss                40.5098
trainer/Q1 Predictions Mean       -38.6841
trainer/Q1 Predictions Std         38.123
trainer/Q1 Predictions Max         -6.67343
trainer/Q1 Predictions Min       -137.155
trainer/Q2 Predictions Mean       -38.6882
trainer/Q2 Predictions Std         38.1017
trainer/Q2 Predictions Max         -6.72283
trainer/Q2 Predictions Min       -136.726
trainer/Q Targets Mean            -39.0706
trainer/Q Targets Std              38.3086
trainer/Q Targets Max              -6.68385
trainer/Q Targets Min            -137.567
trainer/Log Pis Mean                1.98854
trainer/Log Pis Std                 0.981432
trainer/Log Pis Max                 5.97729
trainer/Log Pis Min                -0.958603
trainer/Policy mu Mean             -0.0575172
trainer/Policy mu Std               0.443202
trainer/Policy mu Max               2.95117
trainer/Policy mu Min              -1.92765
trainer/Policy log std Mean        -2.24976
trainer/Policy log std Std          0.33332
trainer/Policy log std Max         -0.742025
trainer/Policy log std Min         -3.16486
trainer/Alpha                       0.0771605
trainer/Alpha Loss                 -0.029348
exploration/num steps total    265700
exploration/num paths total      2657
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.818887
exploration/Rewards Std             0.821937
exploration/Rewards Max            -0.00943353
exploration/Rewards Min            -8.77798
exploration/Returns Mean          -81.8887
exploration/Returns Std            40.3487
exploration/Returns Max           -25.142
exploration/Returns Min          -147.357
exploration/Actions Mean            0.00813277
exploration/Actions Std             0.199104
exploration/Actions Max             0.998031
exploration/Actions Min            -0.99885
exploration/Num Paths               5
exploration/Average Returns       -81.8887
evaluation/num steps total     796500
evaluation/num paths total       7965
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.710727
evaluation/Rewards Std              1.14728
evaluation/Rewards Max             -0.00935232
evaluation/Rewards Min            -10.4282
evaluation/Returns Mean           -71.0727
evaluation/Returns Std             50.8474
evaluation/Returns Max             -9.39946
evaluation/Returns Min           -166.831
evaluation/Actions Mean             0.00214326
evaluation/Actions Std              0.203303
evaluation/Actions Max              0.997705
evaluation/Actions Min             -0.99747
evaluation/Num Paths               15
evaluation/Average Returns        -71.0727
time/data storing (s)               0.00274264
time/evaluation sampling (s)        0.31909
time/exploration sampling (s)       0.137105
time/logging (s)                    0.00404803
time/saving (s)                     0.00193054
time/training (s)                   1.97737
time/epoch (s)                      2.44229
time/total (s)                   1303.82
Epoch                             530
-----------------------------  ---------------
2019-04-23 01:35:19.062158 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 531 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.401916
trainer/QF2 Loss                    0.335082
trainer/Policy Loss                37.7201
trainer/Q1 Predictions Mean       -35.9244
trainer/Q1 Predictions Std         39.3454
trainer/Q1 Predictions Max         -6.54049
trainer/Q1 Predictions Min       -152.029
trainer/Q2 Predictions Mean       -35.9368
trainer/Q2 Predictions Std         39.4159
trainer/Q2 Predictions Max         -6.55363
trainer/Q2 Predictions Min       -153.941
trainer/Q Targets Mean            -36.2568
trainer/Q Targets Std              39.7995
trainer/Q Targets Max              -6.54781
trainer/Q Targets Min            -154.295
trainer/Log Pis Mean                1.83605
trainer/Log Pis Std                 1.31785
trainer/Log Pis Max                 5.72375
trainer/Log Pis Min                -2.10286
trainer/Policy mu Mean             -0.055288
trainer/Policy mu Std               0.441643
trainer/Policy mu Max               3.16307
trainer/Policy mu Min              -2.98913
trainer/Policy log std Mean        -2.28978
trainer/Policy log std Std          0.377428
trainer/Policy log std Max         -0.429103
trainer/Policy log std Min         -2.9528
trainer/Alpha                       0.0771815
trainer/Alpha Loss                 -0.41995
exploration/num steps total    266200
exploration/num paths total      2662
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.564738
exploration/Rewards Std             1.1197
exploration/Rewards Max            -0.0117908
exploration/Rewards Min            -9.91107
exploration/Returns Mean          -56.4738
exploration/Returns Std            28.5559
exploration/Returns Max           -19.0472
exploration/Returns Min          -105.636
exploration/Actions Mean            0.0104987
exploration/Actions Std             0.238718
exploration/Actions Max             0.999758
exploration/Actions Min            -0.99816
exploration/Num Paths               5
exploration/Average Returns       -56.4738
evaluation/num steps total     798000
evaluation/num paths total       7980
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.748227
evaluation/Rewards Std              1.11897
evaluation/Rewards Max             -0.0139648
evaluation/Rewards Min            -11.6045
evaluation/Returns Mean           -74.8227
evaluation/Returns Std             61.7849
evaluation/Returns Max             -4.93742
evaluation/Returns Min           -165.629
evaluation/Actions Mean            -0.00461131
evaluation/Actions Std              0.18627
evaluation/Actions Max              0.9974
evaluation/Actions Min             -0.999232
evaluation/Num Paths               15
evaluation/Average Returns        -74.8227
time/data storing (s)               0.00269249
time/evaluation sampling (s)        0.323763
time/exploration sampling (s)       0.136431
time/logging (s)                    0.00482671
time/saving (s)                     0.0019395
time/training (s)                   1.95138
time/epoch (s)                      2.42103
time/total (s)                   1306.24
Epoch                             531
-----------------------------  ---------------
2019-04-23 01:35:21.503650 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 532 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    7.6896
trainer/QF2 Loss                    7.57374
trainer/Policy Loss                36.873
trainer/Q1 Predictions Mean       -35.0542
trainer/Q1 Predictions Std         34.1642
trainer/Q1 Predictions Max         -6.58591
trainer/Q1 Predictions Min       -135.836
trainer/Q2 Predictions Mean       -35.0415
trainer/Q2 Predictions Std         34.1279
trainer/Q2 Predictions Max         -6.55637
trainer/Q2 Predictions Min       -135.224
trainer/Q Targets Mean            -34.8147
trainer/Q Targets Std              34.5657
trainer/Q Targets Max              -0.0375368
trainer/Q Targets Min            -136.217
trainer/Log Pis Mean                1.89935
trainer/Log Pis Std                 0.924933
trainer/Log Pis Max                 3.94053
trainer/Log Pis Min                -0.591876
trainer/Policy mu Mean              0.0342337
trainer/Policy mu Std               0.442512
trainer/Policy mu Max               2.43124
trainer/Policy mu Min              -1.24086
trainer/Policy log std Mean        -2.23774
trainer/Policy log std Std          0.392935
trainer/Policy log std Max         -0.68035
trainer/Policy log std Min         -3.07779
trainer/Alpha                       0.0743251
trainer/Alpha Loss                 -0.261608
exploration/num steps total    266700
exploration/num paths total      2667
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.852734
exploration/Rewards Std             0.901255
exploration/Rewards Max            -0.0125082
exploration/Rewards Min            -9.0289
exploration/Returns Mean          -85.2734
exploration/Returns Std            41.7071
exploration/Returns Max           -31.2742
exploration/Returns Min          -154.079
exploration/Actions Mean            0.013798
exploration/Actions Std             0.221724
exploration/Actions Max             0.998709
exploration/Actions Min            -0.997471
exploration/Num Paths               5
exploration/Average Returns       -85.2734
evaluation/num steps total     799500
evaluation/num paths total       7995
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.684944
evaluation/Rewards Std              1.1265
evaluation/Rewards Max             -0.0191663
evaluation/Rewards Min            -10.3332
evaluation/Returns Mean           -68.4944
evaluation/Returns Std             65.7938
evaluation/Returns Max             -3.78175
evaluation/Returns Min           -277.011
evaluation/Actions Mean             0.0101278
evaluation/Actions Std              0.175359
evaluation/Actions Max              0.998499
evaluation/Actions Min             -0.995135
evaluation/Num Paths               15
evaluation/Average Returns        -68.4944
time/data storing (s)               0.00273427
time/evaluation sampling (s)        0.319584
time/exploration sampling (s)       0.139132
time/logging (s)                    0.00480509
time/saving (s)                     0.00156523
time/training (s)                   1.9617
time/epoch (s)                      2.42952
time/total (s)                   1308.68
Epoch                             532
-----------------------------  ---------------
2019-04-23 01:35:23.960219 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 533 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.95753
trainer/QF2 Loss                    2.05636
trainer/Policy Loss                32.6451
trainer/Q1 Predictions Mean       -30.8299
trainer/Q1 Predictions Std         35.38
trainer/Q1 Predictions Max         -6.39339
trainer/Q1 Predictions Min       -133.402
trainer/Q2 Predictions Mean       -30.808
trainer/Q2 Predictions Std         35.3399
trainer/Q2 Predictions Max         -6.31597
trainer/Q2 Predictions Min       -133.23
trainer/Q Targets Mean            -31.1188
trainer/Q Targets Std              36.2496
trainer/Q Targets Max              -0.39687
trainer/Q Targets Min            -134.789
trainer/Log Pis Mean                1.9176
trainer/Log Pis Std                 1.14218
trainer/Log Pis Max                 5.49674
trainer/Log Pis Min                -1.03034
trainer/Policy mu Mean             -0.020102
trainer/Policy mu Std               0.438868
trainer/Policy mu Max               2.84032
trainer/Policy mu Min              -3.13175
trainer/Policy log std Mean        -2.28242
trainer/Policy log std Std          0.337948
trainer/Policy log std Max         -0.560257
trainer/Policy log std Min         -2.97471
trainer/Alpha                       0.0758445
trainer/Alpha Loss                 -0.212531
exploration/num steps total    267200
exploration/num paths total      2672
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.14946
exploration/Rewards Std             1.50016
exploration/Rewards Max            -0.0131439
exploration/Rewards Min           -11.3331
exploration/Returns Mean         -114.946
exploration/Returns Std            92.8051
exploration/Returns Max           -18.0083
exploration/Returns Min          -284.856
exploration/Actions Mean            0.0034175
exploration/Actions Std             0.23254
exploration/Actions Max             0.997662
exploration/Actions Min            -0.995819
exploration/Num Paths               5
exploration/Average Returns      -114.946
evaluation/num steps total     801000
evaluation/num paths total       8010
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.629565
evaluation/Rewards Std              1.15053
evaluation/Rewards Max             -0.00926058
evaluation/Rewards Min             -9.5905
evaluation/Returns Mean           -62.9565
evaluation/Returns Std             71.4288
evaluation/Returns Max             -9.1978
evaluation/Returns Min           -288.095
evaluation/Actions Mean            -0.000929666
evaluation/Actions Std              0.186926
evaluation/Actions Max              0.995906
evaluation/Actions Min             -0.998113
evaluation/Num Paths               15
evaluation/Average Returns        -62.9565
time/data storing (s)               0.00266048
time/evaluation sampling (s)        0.326404
time/exploration sampling (s)       0.134349
time/logging (s)                    0.00477377
time/saving (s)                     0.00191835
time/training (s)                   1.97487
time/epoch (s)                      2.44498
time/total (s)                   1311.13
Epoch                             533
-----------------------------  ----------------
2019-04-23 01:35:26.359332 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 534 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.384796
trainer/QF2 Loss                    0.339354
trainer/Policy Loss                39.3573
trainer/Q1 Predictions Mean       -37.4995
trainer/Q1 Predictions Std         37.5868
trainer/Q1 Predictions Max         -6.54935
trainer/Q1 Predictions Min       -141.127
trainer/Q2 Predictions Mean       -37.5309
trainer/Q2 Predictions Std         37.6173
trainer/Q2 Predictions Max         -6.54547
trainer/Q2 Predictions Min       -141.858
trainer/Q Targets Mean            -37.9128
trainer/Q Targets Std              37.8921
trainer/Q Targets Max              -6.50412
trainer/Q Targets Min            -141.827
trainer/Log Pis Mean                1.95224
trainer/Log Pis Std                 1.08045
trainer/Log Pis Max                 6.50079
trainer/Log Pis Min                -0.854537
trainer/Policy mu Mean             -0.0475877
trainer/Policy mu Std               0.425573
trainer/Policy mu Max               3.18505
trainer/Policy mu Min              -2.021
trainer/Policy log std Mean        -2.26912
trainer/Policy log std Std          0.384409
trainer/Policy log std Max         -0.484155
trainer/Policy log std Min         -2.94289
trainer/Alpha                       0.0771086
trainer/Alpha Loss                 -0.122394
exploration/num steps total    267700
exploration/num paths total      2677
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.09393
exploration/Rewards Std             1.16832
exploration/Rewards Max            -0.0103432
exploration/Rewards Min            -8.29332
exploration/Returns Mean         -109.393
exploration/Returns Std            98.4364
exploration/Returns Max           -13.9908
exploration/Returns Min          -282.332
exploration/Actions Mean           -0.0222779
exploration/Actions Std             0.193585
exploration/Actions Max             0.851085
exploration/Actions Min            -0.996782
exploration/Num Paths               5
exploration/Average Returns      -109.393
evaluation/num steps total     802500
evaluation/num paths total       8025
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.836713
evaluation/Rewards Std              1.16808
evaluation/Rewards Max             -0.0175107
evaluation/Rewards Min             -7.55413
evaluation/Returns Mean           -83.6713
evaluation/Returns Std             96.6051
evaluation/Returns Max             -4.04454
evaluation/Returns Min           -288.667
evaluation/Actions Mean            -0.0207782
evaluation/Actions Std              0.165111
evaluation/Actions Max              0.994405
evaluation/Actions Min             -0.995234
evaluation/Num Paths               15
evaluation/Average Returns        -83.6713
time/data storing (s)               0.00273053
time/evaluation sampling (s)        0.319807
time/exploration sampling (s)       0.137496
time/logging (s)                    0.00477445
time/saving (s)                     0.00196137
time/training (s)                   1.92033
time/epoch (s)                      2.38709
time/total (s)                   1313.52
Epoch                             534
-----------------------------  ---------------
2019-04-23 01:35:28.799237 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 535 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.14549
trainer/QF2 Loss                    1.09063
trainer/Policy Loss                36.0544
trainer/Q1 Predictions Mean       -34.0371
trainer/Q1 Predictions Std         36.4239
trainer/Q1 Predictions Max         -6.37058
trainer/Q1 Predictions Min       -142.031
trainer/Q2 Predictions Mean       -34.0966
trainer/Q2 Predictions Std         36.4959
trainer/Q2 Predictions Max         -6.33903
trainer/Q2 Predictions Min       -142.734
trainer/Q Targets Mean            -34.2178
trainer/Q Targets Std              36.7704
trainer/Q Targets Max              -0.132148
trainer/Q Targets Min            -142.509
trainer/Log Pis Mean                1.98775
trainer/Log Pis Std                 0.883099
trainer/Log Pis Max                 3.90088
trainer/Log Pis Min                 0.1569
trainer/Policy mu Mean             -0.0183396
trainer/Policy mu Std               0.389954
trainer/Policy mu Max               2.38824
trainer/Policy mu Min              -2.37061
trainer/Policy log std Mean        -2.2667
trainer/Policy log std Std          0.396121
trainer/Policy log std Max         -0.505795
trainer/Policy log std Min         -3.02906
trainer/Alpha                       0.0763637
trainer/Alpha Loss                 -0.0315181
exploration/num steps total    268200
exploration/num paths total      2682
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.14065
exploration/Rewards Std             1.24825
exploration/Rewards Max            -0.0119409
exploration/Rewards Min            -8.34135
exploration/Returns Mean         -114.065
exploration/Returns Std           100.956
exploration/Returns Max           -19.7042
exploration/Returns Min          -300.799
exploration/Actions Mean           -0.0189245
exploration/Actions Std             0.214088
exploration/Actions Max             0.998262
exploration/Actions Min            -0.989055
exploration/Num Paths               5
exploration/Average Returns      -114.065
evaluation/num steps total     804000
evaluation/num paths total       8040
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.708922
evaluation/Rewards Std              1.25672
evaluation/Rewards Max             -0.00997287
evaluation/Rewards Min            -12.0918
evaluation/Returns Mean           -70.8922
evaluation/Returns Std             89.3026
evaluation/Returns Max             -5.7172
evaluation/Returns Min           -293.609
evaluation/Actions Mean             0.01055
evaluation/Actions Std              0.18564
evaluation/Actions Max              0.999319
evaluation/Actions Min             -0.993706
evaluation/Num Paths               15
evaluation/Average Returns        -70.8922
time/data storing (s)               0.0027727
time/evaluation sampling (s)        0.316808
time/exploration sampling (s)       0.13699
time/logging (s)                    0.0047682
time/saving (s)                     0.00194923
time/training (s)                   1.96451
time/epoch (s)                      2.4278
time/total (s)                   1315.95
Epoch                             535
-----------------------------  ---------------
2019-04-23 01:35:31.244931 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 536 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.279665
trainer/QF2 Loss                    0.219646
trainer/Policy Loss                37.5942
trainer/Q1 Predictions Mean       -35.5735
trainer/Q1 Predictions Std         31.7238
trainer/Q1 Predictions Max         -6.55204
trainer/Q1 Predictions Min       -138.67
trainer/Q2 Predictions Mean       -35.5637
trainer/Q2 Predictions Std         31.7171
trainer/Q2 Predictions Max         -6.5646
trainer/Q2 Predictions Min       -138.007
trainer/Q Targets Mean            -35.8493
trainer/Q Targets Std              31.9599
trainer/Q Targets Max              -6.73071
trainer/Q Targets Min            -138.06
trainer/Log Pis Mean                2.11181
trainer/Log Pis Std                 1.05233
trainer/Log Pis Max                 5.03262
trainer/Log Pis Min                -1.78137
trainer/Policy mu Mean             -0.0933109
trainer/Policy mu Std               0.432747
trainer/Policy mu Max               0.854361
trainer/Policy mu Min              -2.80537
trainer/Policy log std Mean        -2.3417
trainer/Policy log std Std          0.411199
trainer/Policy log std Max         -0.529449
trainer/Policy log std Min         -3.17192
trainer/Alpha                       0.0765328
trainer/Alpha Loss                  0.287369
exploration/num steps total    268700
exploration/num paths total      2687
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.739633
exploration/Rewards Std             0.917643
exploration/Rewards Max            -0.0136435
exploration/Rewards Min            -7.96944
exploration/Returns Mean          -73.9633
exploration/Returns Std            45.5552
exploration/Returns Max           -22.4041
exploration/Returns Min          -154.56
exploration/Actions Mean            0.00874767
exploration/Actions Std             0.215583
exploration/Actions Max             0.997668
exploration/Actions Min            -0.999853
exploration/Num Paths               5
exploration/Average Returns       -73.9633
evaluation/num steps total     805500
evaluation/num paths total       8055
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.84711
evaluation/Rewards Std              1.18435
evaluation/Rewards Max             -0.02337
evaluation/Rewards Min             -9.0571
evaluation/Returns Mean           -84.711
evaluation/Returns Std             96.3262
evaluation/Returns Max             -7.69821
evaluation/Returns Min           -308.927
evaluation/Actions Mean            -0.00933131
evaluation/Actions Std              0.159183
evaluation/Actions Max              0.996785
evaluation/Actions Min             -0.998173
evaluation/Num Paths               15
evaluation/Average Returns        -84.711
time/data storing (s)               0.00271119
time/evaluation sampling (s)        0.322528
time/exploration sampling (s)       0.140093
time/logging (s)                    0.00476297
time/saving (s)                     0.00153796
time/training (s)                   1.96216
time/epoch (s)                      2.43379
time/total (s)                   1318.39
Epoch                             536
-----------------------------  ---------------
2019-04-23 01:35:33.685805 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 537 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.281458
trainer/QF2 Loss                    0.351978
trainer/Policy Loss                33.283
trainer/Q1 Predictions Mean       -31.4144
trainer/Q1 Predictions Std         33.0488
trainer/Q1 Predictions Max         -6.64495
trainer/Q1 Predictions Min       -135.945
trainer/Q2 Predictions Mean       -31.3828
trainer/Q2 Predictions Std         33.0041
trainer/Q2 Predictions Max         -6.66569
trainer/Q2 Predictions Min       -135.589
trainer/Q Targets Mean            -31.7327
trainer/Q Targets Std              33.3804
trainer/Q Targets Max              -6.63874
trainer/Q Targets Min            -138.114
trainer/Log Pis Mean                1.95212
trainer/Log Pis Std                 1.10352
trainer/Log Pis Max                 4.84679
trainer/Log Pis Min                -3.43781
trainer/Policy mu Mean             -0.0126952
trainer/Policy mu Std               0.432773
trainer/Policy mu Max               2.75632
trainer/Policy mu Min              -2.42132
trainer/Policy log std Mean        -2.22504
trainer/Policy log std Std          0.385575
trainer/Policy log std Max         -0.49287
trainer/Policy log std Min         -3.01449
trainer/Alpha                       0.0735108
trainer/Alpha Loss                 -0.124989
exploration/num steps total    269200
exploration/num paths total      2692
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.520191
exploration/Rewards Std             0.434617
exploration/Rewards Max            -0.025913
exploration/Rewards Min            -6.44816
exploration/Returns Mean          -52.0191
exploration/Returns Std            21.6197
exploration/Returns Max           -16.5505
exploration/Returns Min           -82.1693
exploration/Actions Mean            0.00222986
exploration/Actions Std             0.157916
exploration/Actions Max             0.994781
exploration/Actions Min            -0.99891
exploration/Num Paths               5
exploration/Average Returns       -52.0191
evaluation/num steps total     807000
evaluation/num paths total       8070
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.598302
evaluation/Rewards Std              1.03271
evaluation/Rewards Max             -0.0161015
evaluation/Rewards Min             -9.96409
evaluation/Returns Mean           -59.8302
evaluation/Returns Std             42.4143
evaluation/Returns Max             -9.66668
evaluation/Returns Min           -166.265
evaluation/Actions Mean            -0.0105934
evaluation/Actions Std              0.19396
evaluation/Actions Max              0.995459
evaluation/Actions Min             -0.998643
evaluation/Num Paths               15
evaluation/Average Returns        -59.8302
time/data storing (s)               0.00254814
time/evaluation sampling (s)        0.316311
time/exploration sampling (s)       0.136066
time/logging (s)                    0.00476912
time/saving (s)                     0.00195366
time/training (s)                   1.96748
time/epoch (s)                      2.42913
time/total (s)                   1320.82
Epoch                             537
-----------------------------  ---------------
2019-04-23 01:35:36.127208 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 538 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.877993
trainer/QF2 Loss                    0.891893
trainer/Policy Loss                35.3825
trainer/Q1 Predictions Mean       -33.5159
trainer/Q1 Predictions Std         33.7755
trainer/Q1 Predictions Max         -6.56753
trainer/Q1 Predictions Min       -134.994
trainer/Q2 Predictions Mean       -33.5052
trainer/Q2 Predictions Std         33.7579
trainer/Q2 Predictions Max         -6.57596
trainer/Q2 Predictions Min       -134.92
trainer/Q Targets Mean            -33.68
trainer/Q Targets Std              34.158
trainer/Q Targets Max              -0.129774
trainer/Q Targets Min            -136.792
trainer/Log Pis Mean                1.93062
trainer/Log Pis Std                 1.15381
trainer/Log Pis Max                 3.82639
trainer/Log Pis Min                -2.18266
trainer/Policy mu Mean              0.00190335
trainer/Policy mu Std               0.331784
trainer/Policy mu Max               3.01516
trainer/Policy mu Min              -0.802469
trainer/Policy log std Mean        -2.34887
trainer/Policy log std Std          0.337428
trainer/Policy log std Max         -0.811957
trainer/Policy log std Min         -3.10714
trainer/Alpha                       0.0755963
trainer/Alpha Loss                 -0.179164
exploration/num steps total    269700
exploration/num paths total      2697
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.03527
exploration/Rewards Std             1.27739
exploration/Rewards Max            -0.0185787
exploration/Rewards Min           -10.4915
exploration/Returns Mean         -103.527
exploration/Returns Std            57.6844
exploration/Returns Max           -22.1611
exploration/Returns Min          -173.573
exploration/Actions Mean            0.0123309
exploration/Actions Std             0.240914
exploration/Actions Max             0.999095
exploration/Actions Min            -0.999046
exploration/Num Paths               5
exploration/Average Returns      -103.527
evaluation/num steps total     808500
evaluation/num paths total       8085
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.26245
evaluation/Rewards Std              1.20014
evaluation/Rewards Max             -0.0104229
evaluation/Rewards Min             -8.43447
evaluation/Returns Mean          -126.245
evaluation/Returns Std            101.139
evaluation/Returns Max             -8.14353
evaluation/Returns Min           -298.627
evaluation/Actions Mean            -0.0143514
evaluation/Actions Std              0.170054
evaluation/Actions Max              0.980192
evaluation/Actions Min             -0.998206
evaluation/Num Paths               15
evaluation/Average Returns       -126.245
time/data storing (s)               0.0026624
time/evaluation sampling (s)        0.320805
time/exploration sampling (s)       0.138115
time/logging (s)                    0.00476446
time/saving (s)                     0.00193852
time/training (s)                   1.96113
time/epoch (s)                      2.42942
time/total (s)                   1323.26
Epoch                             538
-----------------------------  ---------------
2019-04-23 01:35:38.545517 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 539 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.28364
trainer/QF2 Loss                    0.374947
trainer/Policy Loss                43.8012
trainer/Q1 Predictions Mean       -42.0091
trainer/Q1 Predictions Std         39.5807
trainer/Q1 Predictions Max         -6.60932
trainer/Q1 Predictions Min       -138.671
trainer/Q2 Predictions Mean       -41.9924
trainer/Q2 Predictions Std         39.5113
trainer/Q2 Predictions Max         -6.58093
trainer/Q2 Predictions Min       -137.691
trainer/Q Targets Mean            -42.2527
trainer/Q Targets Std              39.9332
trainer/Q Targets Max              -6.6009
trainer/Q Targets Min            -139.957
trainer/Log Pis Mean                1.88552
trainer/Log Pis Std                 1.2184
trainer/Log Pis Max                 7.14074
trainer/Log Pis Min                -2.20936
trainer/Policy mu Mean             -0.0448515
trainer/Policy mu Std               0.536399
trainer/Policy mu Max               3.20614
trainer/Policy mu Min              -2.30861
trainer/Policy log std Mean        -2.16189
trainer/Policy log std Std          0.461523
trainer/Policy log std Max         -0.416151
trainer/Policy log std Min         -3.0342
trainer/Alpha                       0.0761421
trainer/Alpha Loss                 -0.294798
exploration/num steps total    270200
exploration/num paths total      2702
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.40814
exploration/Rewards Std             0.895322
exploration/Rewards Max            -0.00899235
exploration/Rewards Min            -8.60332
exploration/Returns Mean          -40.814
exploration/Returns Std            10.2372
exploration/Returns Max           -22.6721
exploration/Returns Min           -50.6444
exploration/Actions Mean           -0.0113784
exploration/Actions Std             0.209544
exploration/Actions Max             0.991329
exploration/Actions Min            -0.99909
exploration/Num Paths               5
exploration/Average Returns       -40.814
evaluation/num steps total     810000
evaluation/num paths total       8100
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.960288
evaluation/Rewards Std              1.27965
evaluation/Rewards Max             -0.0189854
evaluation/Rewards Min             -8.59854
evaluation/Returns Mean           -96.0288
evaluation/Returns Std            112.806
evaluation/Returns Max            -12.5422
evaluation/Returns Min           -310.358
evaluation/Actions Mean            -0.00584653
evaluation/Actions Std              0.166595
evaluation/Actions Max              0.995505
evaluation/Actions Min             -0.995477
evaluation/Num Paths               15
evaluation/Average Returns        -96.0288
time/data storing (s)               0.00270862
time/evaluation sampling (s)        0.3239
time/exploration sampling (s)       0.136258
time/logging (s)                    0.00485322
time/saving (s)                     0.00192086
time/training (s)                   1.93668
time/epoch (s)                      2.40632
time/total (s)                   1325.67
Epoch                             539
-----------------------------  ---------------
2019-04-23 01:35:41.002454 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 540 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   36.2777
trainer/QF2 Loss                   36.3913
trainer/Policy Loss                35.4779
trainer/Q1 Predictions Mean       -33.6228
trainer/Q1 Predictions Std         36.528
trainer/Q1 Predictions Max         -6.68062
trainer/Q1 Predictions Min       -135.228
trainer/Q2 Predictions Mean       -33.6604
trainer/Q2 Predictions Std         36.5592
trainer/Q2 Predictions Max         -6.67418
trainer/Q2 Predictions Min       -135.125
trainer/Q Targets Mean            -32.8573
trainer/Q Targets Std              36.7755
trainer/Q Targets Max              -0.930939
trainer/Q Targets Min            -134.984
trainer/Log Pis Mean                1.93612
trainer/Log Pis Std                 1.17363
trainer/Log Pis Max                 8.60772
trainer/Log Pis Min                -1.65392
trainer/Policy mu Mean             -0.0359695
trainer/Policy mu Std               0.35398
trainer/Policy mu Max               1.32163
trainer/Policy mu Min              -2.79587
trainer/Policy log std Mean        -2.26634
trainer/Policy log std Std          0.304853
trainer/Policy log std Max         -0.746297
trainer/Policy log std Min         -2.92011
trainer/Alpha                       0.0751427
trainer/Alpha Loss                 -0.165335
exploration/num steps total    270700
exploration/num paths total      2707
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.535514
exploration/Rewards Std             0.884442
exploration/Rewards Max            -0.00917864
exploration/Rewards Min            -9.28001
exploration/Returns Mean          -53.5514
exploration/Returns Std            28.1193
exploration/Returns Max           -15.2297
exploration/Returns Min           -93.0994
exploration/Actions Mean            0.0159018
exploration/Actions Std             0.216327
exploration/Actions Max             0.996863
exploration/Actions Min            -0.997307
exploration/Num Paths               5
exploration/Average Returns       -53.5514
evaluation/num steps total     811500
evaluation/num paths total       8115
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.737978
evaluation/Rewards Std              1.2264
evaluation/Rewards Max             -0.0251087
evaluation/Rewards Min            -11.1184
evaluation/Returns Mean           -73.7978
evaluation/Returns Std             76.7094
evaluation/Returns Max             -7.40133
evaluation/Returns Min           -323.202
evaluation/Actions Mean             0.00218464
evaluation/Actions Std              0.182175
evaluation/Actions Max              0.999176
evaluation/Actions Min             -0.99673
evaluation/Num Paths               15
evaluation/Average Returns        -73.7978
time/data storing (s)               0.00284023
time/evaluation sampling (s)        0.312295
time/exploration sampling (s)       0.138193
time/logging (s)                    0.00479328
time/saving (s)                     0.00192081
time/training (s)                   1.98485
time/epoch (s)                      2.4449
time/total (s)                   1328.12
Epoch                             540
-----------------------------  ---------------
2019-04-23 01:35:43.458803 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 541 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.48602
trainer/QF2 Loss                    1.49946
trainer/Policy Loss                38.1287
trainer/Q1 Predictions Mean       -36.2846
trainer/Q1 Predictions Std         34.2894
trainer/Q1 Predictions Max         -6.59266
trainer/Q1 Predictions Min       -132.945
trainer/Q2 Predictions Mean       -36.2751
trainer/Q2 Predictions Std         34.284
trainer/Q2 Predictions Max         -6.63381
trainer/Q2 Predictions Min       -132.681
trainer/Q Targets Mean            -36.5367
trainer/Q Targets Std              34.8771
trainer/Q Targets Max              -0.187446
trainer/Q Targets Min            -135.346
trainer/Log Pis Mean                1.93918
trainer/Log Pis Std                 1.16637
trainer/Log Pis Max                 4.27049
trainer/Log Pis Min                -1.8012
trainer/Policy mu Mean              0.0173058
trainer/Policy mu Std               0.357894
trainer/Policy mu Max               2.75398
trainer/Policy mu Min              -1.90048
trainer/Policy log std Mean        -2.27486
trainer/Policy log std Std          0.43364
trainer/Policy log std Max         -0.743033
trainer/Policy log std Min         -3.21772
trainer/Alpha                       0.0710163
trainer/Alpha Loss                 -0.160854
exploration/num steps total    271200
exploration/num paths total      2712
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.592468
exploration/Rewards Std             0.979292
exploration/Rewards Max            -0.00826336
exploration/Rewards Min            -7.2163
exploration/Returns Mean          -59.2468
exploration/Returns Std            53.1618
exploration/Returns Max           -16.4662
exploration/Returns Min          -163.602
exploration/Actions Mean           -0.0120374
exploration/Actions Std             0.215152
exploration/Actions Max             0.998314
exploration/Actions Min            -0.999655
exploration/Num Paths               5
exploration/Average Returns       -59.2468
evaluation/num steps total     813000
evaluation/num paths total       8130
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.598739
evaluation/Rewards Std              1.29039
evaluation/Rewards Max             -0.0133713
evaluation/Rewards Min             -9.51932
evaluation/Returns Mean           -59.8739
evaluation/Returns Std             71.2513
evaluation/Returns Max             -2.90734
evaluation/Returns Min           -307.628
evaluation/Actions Mean             0.000632668
evaluation/Actions Std              0.191837
evaluation/Actions Max              0.997268
evaluation/Actions Min             -0.997942
evaluation/Num Paths               15
evaluation/Average Returns        -59.8739
time/data storing (s)               0.00263833
time/evaluation sampling (s)        0.315626
time/exploration sampling (s)       0.135411
time/logging (s)                    0.00352805
time/saving (s)                     0.00160792
time/training (s)                   1.98432
time/epoch (s)                      2.44313
time/total (s)                   1330.56
Epoch                             541
-----------------------------  ----------------
2019-04-23 01:35:45.916829 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 542 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   20.9824
trainer/QF2 Loss                   20.8519
trainer/Policy Loss                39.2688
trainer/Q1 Predictions Mean       -37.3482
trainer/Q1 Predictions Std         37.157
trainer/Q1 Predictions Max         -6.74564
trainer/Q1 Predictions Min       -132.962
trainer/Q2 Predictions Mean       -37.3333
trainer/Q2 Predictions Std         37.1893
trainer/Q2 Predictions Max         -6.69869
trainer/Q2 Predictions Min       -132.788
trainer/Q Targets Mean            -37.3677
trainer/Q Targets Std              38.1644
trainer/Q Targets Max              -0.134414
trainer/Q Targets Min            -134.837
trainer/Log Pis Mean                1.98843
trainer/Log Pis Std                 1.49923
trainer/Log Pis Max                 8.69677
trainer/Log Pis Min                -7.02778
trainer/Policy mu Mean              0.00397975
trainer/Policy mu Std               0.595997
trainer/Policy mu Max               3.45162
trainer/Policy mu Min              -3.31204
trainer/Policy log std Mean        -2.20031
trainer/Policy log std Std          0.430024
trainer/Policy log std Max         -0.223079
trainer/Policy log std Min         -3.07454
trainer/Alpha                       0.0718067
trainer/Alpha Loss                 -0.030467
exploration/num steps total    271700
exploration/num paths total      2717
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.796186
exploration/Rewards Std             0.80705
exploration/Rewards Max            -0.0195618
exploration/Rewards Min            -6.85116
exploration/Returns Mean          -79.6186
exploration/Returns Std            50.9883
exploration/Returns Max           -24.4315
exploration/Returns Min          -161.426
exploration/Actions Mean            0.0108198
exploration/Actions Std             0.218702
exploration/Actions Max             0.998795
exploration/Actions Min            -0.995168
exploration/Num Paths               5
exploration/Average Returns       -79.6186
evaluation/num steps total     814500
evaluation/num paths total       8145
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.867848
evaluation/Rewards Std              1.28168
evaluation/Rewards Max             -0.0175069
evaluation/Rewards Min            -10.0392
evaluation/Returns Mean           -86.7848
evaluation/Returns Std             84.8056
evaluation/Returns Max             -3.61651
evaluation/Returns Min           -293.385
evaluation/Actions Mean             0.00922668
evaluation/Actions Std              0.189676
evaluation/Actions Max              0.999052
evaluation/Actions Min             -0.99462
evaluation/Num Paths               15
evaluation/Average Returns        -86.7848
time/data storing (s)               0.00288618
time/evaluation sampling (s)        0.329375
time/exploration sampling (s)       0.136117
time/logging (s)                    0.0047629
time/saving (s)                     0.0019273
time/training (s)                   1.97325
time/epoch (s)                      2.44832
time/total (s)                   1333.02
Epoch                             542
-----------------------------  ---------------
2019-04-23 01:35:48.328768 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 543 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    2.32169
trainer/QF2 Loss                    2.4115
trainer/Policy Loss                38.9208
trainer/Q1 Predictions Mean       -37.0843
trainer/Q1 Predictions Std         37.7462
trainer/Q1 Predictions Max         -6.74419
trainer/Q1 Predictions Min       -150.057
trainer/Q2 Predictions Mean       -37.0589
trainer/Q2 Predictions Std         37.7024
trainer/Q2 Predictions Max         -6.74246
trainer/Q2 Predictions Min       -149.701
trainer/Q Targets Mean            -37.3781
trainer/Q Targets Std              38.3726
trainer/Q Targets Max              -0.11509
trainer/Q Targets Min            -152.929
trainer/Log Pis Mean                1.92706
trainer/Log Pis Std                 1.22134
trainer/Log Pis Max                 7.15393
trainer/Log Pis Min                -1.39903
trainer/Policy mu Mean             -0.0111809
trainer/Policy mu Std               0.477841
trainer/Policy mu Max               2.52059
trainer/Policy mu Min              -2.81197
trainer/Policy log std Mean        -2.25259
trainer/Policy log std Std          0.463443
trainer/Policy log std Max         -0.435895
trainer/Policy log std Min         -3.1119
trainer/Alpha                       0.0702826
trainer/Alpha Loss                 -0.193671
exploration/num steps total    272200
exploration/num paths total      2722
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.586582
exploration/Rewards Std             1.00613
exploration/Rewards Max            -0.00636808
exploration/Rewards Min            -8.48935
exploration/Returns Mean          -58.6582
exploration/Returns Std            21.7335
exploration/Returns Max           -20.5791
exploration/Returns Min           -76.2282
exploration/Actions Mean           -0.0212782
exploration/Actions Std             0.232389
exploration/Actions Max             0.99676
exploration/Actions Min            -0.998668
exploration/Num Paths               5
exploration/Average Returns       -58.6582
evaluation/num steps total     816000
evaluation/num paths total       8160
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.757889
evaluation/Rewards Std              1.07393
evaluation/Rewards Max             -0.0153891
evaluation/Rewards Min            -11.3076
evaluation/Returns Mean           -75.7889
evaluation/Returns Std             64.8113
evaluation/Returns Max             -3.69936
evaluation/Returns Min           -199.19
evaluation/Actions Mean            -0.00283884
evaluation/Actions Std              0.178043
evaluation/Actions Max              0.99591
evaluation/Actions Min             -0.997218
evaluation/Num Paths               15
evaluation/Average Returns        -75.7889
time/data storing (s)               0.00259089
time/evaluation sampling (s)        0.322897
time/exploration sampling (s)       0.135605
time/logging (s)                    0.00354136
time/saving (s)                     0.00154879
time/training (s)                   1.93409
time/epoch (s)                      2.40027
time/total (s)                   1335.42
Epoch                             543
-----------------------------  ---------------
2019-04-23 01:35:50.757778 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 544 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.42793
trainer/QF2 Loss                    1.48538
trainer/Policy Loss                41.2429
trainer/Q1 Predictions Mean       -39.5028
trainer/Q1 Predictions Std         38.1533
trainer/Q1 Predictions Max         -6.65385
trainer/Q1 Predictions Min       -137.961
trainer/Q2 Predictions Mean       -39.4561
trainer/Q2 Predictions Std         38.1287
trainer/Q2 Predictions Max         -6.62646
trainer/Q2 Predictions Min       -137.495
trainer/Q Targets Mean            -40.0766
trainer/Q Targets Std              38.8808
trainer/Q Targets Max              -0.100917
trainer/Q Targets Min            -138.565
trainer/Log Pis Mean                1.82792
trainer/Log Pis Std                 1.13606
trainer/Log Pis Max                 4.27595
trainer/Log Pis Min                -1.98812
trainer/Policy mu Mean             -0.0266429
trainer/Policy mu Std               0.43238
trainer/Policy mu Max               3.30558
trainer/Policy mu Min              -1.98205
trainer/Policy log std Mean        -2.28405
trainer/Policy log std Std          0.424739
trainer/Policy log std Max         -0.61457
trainer/Policy log std Min         -3.11557
trainer/Alpha                       0.0717632
trainer/Alpha Loss                 -0.453305
exploration/num steps total    272700
exploration/num paths total      2727
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.70887
exploration/Rewards Std             1.13486
exploration/Rewards Max            -0.00821658
exploration/Rewards Min            -5.85144
exploration/Returns Mean          -70.887
exploration/Returns Std           106.091
exploration/Returns Max           -12.2832
exploration/Returns Min          -282.627
exploration/Actions Mean           -0.00587709
exploration/Actions Std             0.180901
exploration/Actions Max             0.99785
exploration/Actions Min            -0.985786
exploration/Num Paths               5
exploration/Average Returns       -70.887
evaluation/num steps total     817500
evaluation/num paths total       8175
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.563212
evaluation/Rewards Std              1.15644
evaluation/Rewards Max             -0.0117948
evaluation/Rewards Min            -10.7897
evaluation/Returns Mean           -56.3212
evaluation/Returns Std             66.5209
evaluation/Returns Max             -6.29692
evaluation/Returns Min           -280.126
evaluation/Actions Mean             0.0136423
evaluation/Actions Std              0.182342
evaluation/Actions Max              0.999
evaluation/Actions Min             -0.992982
evaluation/Num Paths               15
evaluation/Average Returns        -56.3212
time/data storing (s)               0.0027073
time/evaluation sampling (s)        0.323315
time/exploration sampling (s)       0.13778
time/logging (s)                    0.00490961
time/saving (s)                     0.00155456
time/training (s)                   1.94951
time/epoch (s)                      2.41978
time/total (s)                   1337.85
Epoch                             544
-----------------------------  ---------------
2019-04-23 01:35:53.182909 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 545 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   19.1821
trainer/QF2 Loss                   18.9109
trainer/Policy Loss                36.1632
trainer/Q1 Predictions Mean       -34.1567
trainer/Q1 Predictions Std         32.7846
trainer/Q1 Predictions Max         -6.80444
trainer/Q1 Predictions Min       -134.817
trainer/Q2 Predictions Mean       -34.1543
trainer/Q2 Predictions Std         32.79
trainer/Q2 Predictions Max         -6.79367
trainer/Q2 Predictions Min       -134.849
trainer/Q Targets Mean            -34.0365
trainer/Q Targets Std              33.3004
trainer/Q Targets Max              -0.0517088
trainer/Q Targets Min            -135.257
trainer/Log Pis Mean                2.11441
trainer/Log Pis Std                 1.10308
trainer/Log Pis Max                 5.37902
trainer/Log Pis Min                -1.4672
trainer/Policy mu Mean              0.00949063
trainer/Policy mu Std               0.46561
trainer/Policy mu Max               3.4887
trainer/Policy mu Min              -2.69922
trainer/Policy log std Mean        -2.30472
trainer/Policy log std Std          0.422757
trainer/Policy log std Max         -0.236454
trainer/Policy log std Min         -3.11462
trainer/Alpha                       0.0739382
trainer/Alpha Loss                  0.297982
exploration/num steps total    273200
exploration/num paths total      2732
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.753586
exploration/Rewards Std             1.0225
exploration/Rewards Max            -0.018672
exploration/Rewards Min            -9.9566
exploration/Returns Mean          -75.3586
exploration/Returns Std            28.9532
exploration/Returns Max           -30.6367
exploration/Returns Min          -116.56
exploration/Actions Mean            0.0142698
exploration/Actions Std             0.223275
exploration/Actions Max             0.99937
exploration/Actions Min            -0.993232
exploration/Num Paths               5
exploration/Average Returns       -75.3586
evaluation/num steps total     819000
evaluation/num paths total       8190
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.860455
evaluation/Rewards Std              1.10132
evaluation/Rewards Max             -0.00541295
evaluation/Rewards Min             -9.7553
evaluation/Returns Mean           -86.0455
evaluation/Returns Std             78.1801
evaluation/Returns Max             -5.96454
evaluation/Returns Min           -274.941
evaluation/Actions Mean             0.00964301
evaluation/Actions Std              0.175651
evaluation/Actions Max              0.998949
evaluation/Actions Min             -0.998212
evaluation/Num Paths               15
evaluation/Average Returns        -86.0455
time/data storing (s)               0.00255931
time/evaluation sampling (s)        0.325091
time/exploration sampling (s)       0.1375
time/logging (s)                    0.0047642
time/saving (s)                     0.00194849
time/training (s)                   1.94241
time/epoch (s)                      2.41427
time/total (s)                   1340.26
Epoch                             545
-----------------------------  ---------------
2019-04-23 01:35:55.635864 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 546 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                   40.1608
trainer/QF2 Loss                   40.7246
trainer/Policy Loss                32.3516
trainer/Q1 Predictions Mean       -30.5818
trainer/Q1 Predictions Std         32.1195
trainer/Q1 Predictions Max         -6.78565
trainer/Q1 Predictions Min       -134.832
trainer/Q2 Predictions Mean       -30.5911
trainer/Q2 Predictions Std         32.116
trainer/Q2 Predictions Max         -6.75158
trainer/Q2 Predictions Min       -134.024
trainer/Q Targets Mean            -30.7542
trainer/Q Targets Std              32.919
trainer/Q Targets Max              -1.26722
trainer/Q Targets Min            -136.834
trainer/Log Pis Mean                1.78967
trainer/Log Pis Std                 1.2967
trainer/Log Pis Max                 5.88646
trainer/Log Pis Min                -2.30901
trainer/Policy mu Mean             -0.00433132
trainer/Policy mu Std               0.507388
trainer/Policy mu Max               2.8152
trainer/Policy mu Min              -1.90609
trainer/Policy log std Mean        -2.21295
trainer/Policy log std Std          0.450982
trainer/Policy log std Max         -0.536639
trainer/Policy log std Min         -3.13864
trainer/Alpha                       0.0730841
trainer/Alpha Loss                 -0.550276
exploration/num steps total    273700
exploration/num paths total      2737
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.02466
exploration/Rewards Std             0.903128
exploration/Rewards Max            -0.0390511
exploration/Rewards Min            -7.63217
exploration/Returns Mean         -102.466
exploration/Returns Std            55.8844
exploration/Returns Max           -32.763
exploration/Returns Min          -172.514
exploration/Actions Mean            0.000193199
exploration/Actions Std             0.225079
exploration/Actions Max             0.995255
exploration/Actions Min            -0.998211
exploration/Num Paths               5
exploration/Average Returns      -102.466
evaluation/num steps total     820500
evaluation/num paths total       8205
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.693491
evaluation/Rewards Std              1.27849
evaluation/Rewards Max             -0.0064814
evaluation/Rewards Min            -10.5458
evaluation/Returns Mean           -69.3491
evaluation/Returns Std             92.2499
evaluation/Returns Max            -17.264
evaluation/Returns Min           -312.095
evaluation/Actions Mean             0.00239493
evaluation/Actions Std              0.179268
evaluation/Actions Max              0.997358
evaluation/Actions Min             -0.994036
evaluation/Num Paths               15
evaluation/Average Returns        -69.3491
time/data storing (s)               0.00260429
time/evaluation sampling (s)        0.321239
time/exploration sampling (s)       0.136119
time/logging (s)                    0.00479664
time/saving (s)                     0.00196087
time/training (s)                   1.9762
time/epoch (s)                      2.44292
time/total (s)                   1342.71
Epoch                             546
-----------------------------  ----------------
2019-04-23 01:35:58.083835 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 547 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.2669
trainer/QF2 Loss                    1.27522
trainer/Policy Loss                41.091
trainer/Q1 Predictions Mean       -39.1668
trainer/Q1 Predictions Std         38.2707
trainer/Q1 Predictions Max         -6.52892
trainer/Q1 Predictions Min       -132.789
trainer/Q2 Predictions Mean       -39.1805
trainer/Q2 Predictions Std         38.2809
trainer/Q2 Predictions Max         -6.52689
trainer/Q2 Predictions Min       -132.805
trainer/Q Targets Mean            -39.8223
trainer/Q Targets Std              39.0478
trainer/Q Targets Max              -6.6381
trainer/Q Targets Min            -136.026
trainer/Log Pis Mean                1.93436
trainer/Log Pis Std                 1.34797
trainer/Log Pis Max                 6.20214
trainer/Log Pis Min                -2.85788
trainer/Policy mu Mean             -0.0509124
trainer/Policy mu Std               0.555222
trainer/Policy mu Max               3.0517
trainer/Policy mu Min              -3.06466
trainer/Policy log std Mean        -2.16167
trainer/Policy log std Std          0.471682
trainer/Policy log std Max         -0.369462
trainer/Policy log std Min         -3.16575
trainer/Alpha                       0.0741419
trainer/Alpha Loss                 -0.170758
exploration/num steps total    274200
exploration/num paths total      2742
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.30071
exploration/Rewards Std             1.31925
exploration/Rewards Max            -0.00212452
exploration/Rewards Min            -9.9668
exploration/Returns Mean         -130.071
exploration/Returns Std            86.5734
exploration/Returns Max           -40.3614
exploration/Returns Min          -278.955
exploration/Actions Mean            0.00343953
exploration/Actions Std             0.230059
exploration/Actions Max             0.998782
exploration/Actions Min            -0.998237
exploration/Num Paths               5
exploration/Average Returns      -130.071
evaluation/num steps total     822000
evaluation/num paths total       8220
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.581802
evaluation/Rewards Std              1.17243
evaluation/Rewards Max             -0.0114964
evaluation/Rewards Min             -9.87955
evaluation/Returns Mean           -58.1802
evaluation/Returns Std             71.7331
evaluation/Returns Max            -11.5598
evaluation/Returns Min           -290.808
evaluation/Actions Mean             0.00717063
evaluation/Actions Std              0.19269
evaluation/Actions Max              0.998144
evaluation/Actions Min             -0.996321
evaluation/Num Paths               15
evaluation/Average Returns        -58.1802
time/data storing (s)               0.00259929
time/evaluation sampling (s)        0.316979
time/exploration sampling (s)       0.138936
time/logging (s)                    0.00471355
time/saving (s)                     0.00154778
time/training (s)                   1.97119
time/epoch (s)                      2.43597
time/total (s)                   1345.15
Epoch                             547
-----------------------------  ---------------
2019-04-23 01:36:00.503898 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 548 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   13.8098
trainer/QF2 Loss                   13.7908
trainer/Policy Loss                37.3258
trainer/Q1 Predictions Mean       -35.4124
trainer/Q1 Predictions Std         33.8488
trainer/Q1 Predictions Max         -6.80222
trainer/Q1 Predictions Min       -134.546
trainer/Q2 Predictions Mean       -35.4052
trainer/Q2 Predictions Std         33.8526
trainer/Q2 Predictions Max         -6.77036
trainer/Q2 Predictions Min       -134.539
trainer/Q Targets Mean            -35.3686
trainer/Q Targets Std              34.3318
trainer/Q Targets Max              -0.705142
trainer/Q Targets Min            -135.355
trainer/Log Pis Mean                2.052
trainer/Log Pis Std                 0.897075
trainer/Log Pis Max                 4.27302
trainer/Log Pis Min                -0.61607
trainer/Policy mu Mean             -0.0356957
trainer/Policy mu Std               0.287156
trainer/Policy mu Max               0.956532
trainer/Policy mu Min              -2.26352
trainer/Policy log std Mean        -2.29815
trainer/Policy log std Std          0.37179
trainer/Policy log std Max         -0.887758
trainer/Policy log std Min         -3.18323
trainer/Alpha                       0.0742689
trainer/Alpha Loss                  0.135215
exploration/num steps total    274700
exploration/num paths total      2747
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.567053
exploration/Rewards Std             0.841876
exploration/Rewards Max            -0.00551534
exploration/Rewards Min            -8.67437
exploration/Returns Mean          -56.7053
exploration/Returns Std            44.7736
exploration/Returns Max           -17.5099
exploration/Returns Min          -139.572
exploration/Actions Mean           -0.0193719
exploration/Actions Std             0.180238
exploration/Actions Max             0.86737
exploration/Actions Min            -0.998906
exploration/Num Paths               5
exploration/Average Returns       -56.7053
evaluation/num steps total     823500
evaluation/num paths total       8235
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.486173
evaluation/Rewards Std              0.921721
evaluation/Rewards Max             -0.0139308
evaluation/Rewards Min             -9.43489
evaluation/Returns Mean           -48.6173
evaluation/Returns Std             37.0068
evaluation/Returns Max             -5.48295
evaluation/Returns Min           -141.154
evaluation/Actions Mean             0.0109088
evaluation/Actions Std              0.177674
evaluation/Actions Max              0.998505
evaluation/Actions Min             -0.993512
evaluation/Num Paths               15
evaluation/Average Returns        -48.6173
time/data storing (s)               0.00342303
time/evaluation sampling (s)        0.321747
time/exploration sampling (s)       0.135406
time/logging (s)                    0.00482739
time/saving (s)                     0.00192277
time/training (s)                   1.94061
time/epoch (s)                      2.40794
time/total (s)                   1347.56
Epoch                             548
-----------------------------  ---------------
2019-04-23 01:36:02.953769 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 549 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                   54.3682
trainer/QF2 Loss                   53.9397
trainer/Policy Loss                37.2636
trainer/Q1 Predictions Mean       -35.4774
trainer/Q1 Predictions Std         34.9082
trainer/Q1 Predictions Max         -6.65182
trainer/Q1 Predictions Min       -135.834
trainer/Q2 Predictions Mean       -35.4744
trainer/Q2 Predictions Std         34.9018
trainer/Q2 Predictions Max         -6.65708
trainer/Q2 Predictions Min       -135.556
trainer/Q Targets Mean            -34.6361
trainer/Q Targets Std              34.9254
trainer/Q Targets Max              -0.0934942
trainer/Q Targets Min            -136.638
trainer/Log Pis Mean                1.88718
trainer/Log Pis Std                 1.06237
trainer/Log Pis Max                 3.91093
trainer/Log Pis Min                -1.96635
trainer/Policy mu Mean             -0.0560184
trainer/Policy mu Std               0.297846
trainer/Policy mu Max               0.779994
trainer/Policy mu Min              -1.87499
trainer/Policy log std Mean        -2.23014
trainer/Policy log std Std          0.358267
trainer/Policy log std Max         -0.811982
trainer/Policy log std Min         -3.08757
trainer/Alpha                       0.0728737
trainer/Alpha Loss                 -0.295449
exploration/num steps total    275200
exploration/num paths total      2752
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.12776
exploration/Rewards Std             1.28525
exploration/Rewards Max            -0.0254626
exploration/Rewards Min            -9.44974
exploration/Returns Mean         -112.776
exploration/Returns Std           101.009
exploration/Returns Max           -17.3886
exploration/Returns Min          -298.661
exploration/Actions Mean           -0.0130612
exploration/Actions Std             0.219865
exploration/Actions Max             0.997735
exploration/Actions Min            -0.998018
exploration/Num Paths               5
exploration/Average Returns      -112.776
evaluation/num steps total     825000
evaluation/num paths total       8250
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.03307
evaluation/Rewards Std              1.15692
evaluation/Rewards Max             -0.03325
evaluation/Rewards Min             -9.73075
evaluation/Returns Mean          -103.307
evaluation/Returns Std             78.0021
evaluation/Returns Max             -5.94793
evaluation/Returns Min           -295.581
evaluation/Actions Mean            -0.000946959
evaluation/Actions Std              0.179581
evaluation/Actions Max              0.998744
evaluation/Actions Min             -0.994409
evaluation/Num Paths               15
evaluation/Average Returns       -103.307
time/data storing (s)               0.00273936
time/evaluation sampling (s)        0.315521
time/exploration sampling (s)       0.135739
time/logging (s)                    0.0047992
time/saving (s)                     0.00193092
time/training (s)                   1.97843
time/epoch (s)                      2.43916
time/total (s)                   1350.01
Epoch                             549
-----------------------------  ----------------
2019-04-23 01:36:05.400870 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 550 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    7.0953
trainer/QF2 Loss                    6.9819
trainer/Policy Loss                30.0408
trainer/Q1 Predictions Mean       -28.0822
trainer/Q1 Predictions Std         26.7375
trainer/Q1 Predictions Max         -6.69188
trainer/Q1 Predictions Min       -132.851
trainer/Q2 Predictions Mean       -28.0849
trainer/Q2 Predictions Std         26.7622
trainer/Q2 Predictions Max         -6.70482
trainer/Q2 Predictions Min       -132.776
trainer/Q Targets Mean            -28.0178
trainer/Q Targets Std              27.212
trainer/Q Targets Max              -0.257941
trainer/Q Targets Min            -134.066
trainer/Log Pis Mean                2.03623
trainer/Log Pis Std                 1.30931
trainer/Log Pis Max                 5.23194
trainer/Log Pis Min                -1.30156
trainer/Policy mu Mean              0.0220038
trainer/Policy mu Std               0.503504
trainer/Policy mu Max               2.95418
trainer/Policy mu Min              -2.0636
trainer/Policy log std Mean        -2.26358
trainer/Policy log std Std          0.480778
trainer/Policy log std Max         -0.544836
trainer/Policy log std Min         -3.18455
trainer/Alpha                       0.0702012
trainer/Alpha Loss                  0.0962272
exploration/num steps total    275700
exploration/num paths total      2757
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.54385
exploration/Rewards Std             1.01213
exploration/Rewards Max            -0.0058043
exploration/Rewards Min            -8.17368
exploration/Returns Mean          -54.385
exploration/Returns Std            41.8775
exploration/Returns Max           -28.2709
exploration/Returns Min          -137.524
exploration/Actions Mean            0.003117
exploration/Actions Std             0.229655
exploration/Actions Max             0.998463
exploration/Actions Min            -0.99688
exploration/Num Paths               5
exploration/Average Returns       -54.385
evaluation/num steps total     826500
evaluation/num paths total       8265
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.737304
evaluation/Rewards Std              1.1673
evaluation/Rewards Max             -0.00909773
evaluation/Rewards Min            -10.7032
evaluation/Returns Mean           -73.7304
evaluation/Returns Std             45.8739
evaluation/Returns Max             -3.57845
evaluation/Returns Min           -147.244
evaluation/Actions Mean            -0.00836038
evaluation/Actions Std              0.18916
evaluation/Actions Max              0.997951
evaluation/Actions Min             -0.99863
evaluation/Num Paths               15
evaluation/Average Returns        -73.7304
time/data storing (s)               0.00258162
time/evaluation sampling (s)        0.318291
time/exploration sampling (s)       0.137574
time/logging (s)                    0.00479439
time/saving (s)                     0.00191943
time/training (s)                   1.97009
time/epoch (s)                      2.43525
time/total (s)                   1352.45
Epoch                             550
-----------------------------  ---------------
2019-04-23 01:36:07.824611 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 551 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    2.18856
trainer/QF2 Loss                    2.22569
trainer/Policy Loss                34.8898
trainer/Q1 Predictions Mean       -32.9507
trainer/Q1 Predictions Std         38.2216
trainer/Q1 Predictions Max         -6.79892
trainer/Q1 Predictions Min       -135.344
trainer/Q2 Predictions Mean       -32.9413
trainer/Q2 Predictions Std         38.2014
trainer/Q2 Predictions Max         -6.76529
trainer/Q2 Predictions Min       -134.923
trainer/Q Targets Mean            -33.4673
trainer/Q Targets Std              39.0978
trainer/Q Targets Max              -0.350497
trainer/Q Targets Min            -137.568
trainer/Log Pis Mean                2.02959
trainer/Log Pis Std                 1.0513
trainer/Log Pis Max                 4.32355
trainer/Log Pis Min                -1.16735
trainer/Policy mu Mean             -0.0486217
trainer/Policy mu Std               0.375388
trainer/Policy mu Max               2.243
trainer/Policy mu Min              -2.65565
trainer/Policy log std Mean        -2.26778
trainer/Policy log std Std          0.368252
trainer/Policy log std Max         -0.618562
trainer/Policy log std Min         -3.1676
trainer/Alpha                       0.0727828
trainer/Alpha Loss                  0.0775223
exploration/num steps total    276200
exploration/num paths total      2762
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.969129
exploration/Rewards Std             1.2106
exploration/Rewards Max            -0.00546093
exploration/Rewards Min            -6.70344
exploration/Returns Mean          -96.9129
exploration/Returns Std            97.119
exploration/Returns Max           -28.2948
exploration/Returns Min          -285.972
exploration/Actions Mean            0.00985874
exploration/Actions Std             0.206639
exploration/Actions Max             0.999652
exploration/Actions Min            -0.994698
exploration/Num Paths               5
exploration/Average Returns       -96.9129
evaluation/num steps total     828000
evaluation/num paths total       8280
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.749573
evaluation/Rewards Std              1.23202
evaluation/Rewards Max             -0.0406538
evaluation/Rewards Min            -10.2779
evaluation/Returns Mean           -74.9573
evaluation/Returns Std             72.1587
evaluation/Returns Max             -8.22645
evaluation/Returns Min           -303.885
evaluation/Actions Mean             0.0238619
evaluation/Actions Std              0.19302
evaluation/Actions Max              0.998571
evaluation/Actions Min             -0.992394
evaluation/Num Paths               15
evaluation/Average Returns        -74.9573
time/data storing (s)               0.00254985
time/evaluation sampling (s)        0.322613
time/exploration sampling (s)       0.134536
time/logging (s)                    0.00475756
time/saving (s)                     0.00190677
time/training (s)                   1.94524
time/epoch (s)                      2.4116
time/total (s)                   1354.86
Epoch                             551
-----------------------------  ---------------
2019-04-23 01:36:10.229735 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 552 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.864998
trainer/QF2 Loss                    0.879236
trainer/Policy Loss                39.4004
trainer/Q1 Predictions Mean       -37.3961
trainer/Q1 Predictions Std         36.0388
trainer/Q1 Predictions Max         -6.84691
trainer/Q1 Predictions Min       -133.365
trainer/Q2 Predictions Mean       -37.409
trainer/Q2 Predictions Std         36.0594
trainer/Q2 Predictions Max         -6.83853
trainer/Q2 Predictions Min       -133.151
trainer/Q Targets Mean            -37.5104
trainer/Q Targets Std              36.3949
trainer/Q Targets Max              -0.203077
trainer/Q Targets Min            -134.778
trainer/Log Pis Mean                2.08319
trainer/Log Pis Std                 1.3441
trainer/Log Pis Max                 5.09899
trainer/Log Pis Min                -3.52373
trainer/Policy mu Mean             -0.0406319
trainer/Policy mu Std               0.352668
trainer/Policy mu Max               2.99268
trainer/Policy mu Min              -2.58478
trainer/Policy log std Mean        -2.36351
trainer/Policy log std Std          0.391598
trainer/Policy log std Max         -0.657192
trainer/Policy log std Min         -3.20807
trainer/Alpha                       0.0744477
trainer/Alpha Loss                  0.216107
exploration/num steps total    276700
exploration/num paths total      2767
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.12934
exploration/Rewards Std             1.23236
exploration/Rewards Max            -0.0147059
exploration/Rewards Min            -9.30856
exploration/Returns Mean         -112.934
exploration/Returns Std            97.8218
exploration/Returns Max           -25.5961
exploration/Returns Min          -292.314
exploration/Actions Mean            0.0177613
exploration/Actions Std             0.20507
exploration/Actions Max             0.998714
exploration/Actions Min            -0.978805
exploration/Num Paths               5
exploration/Average Returns      -112.934
evaluation/num steps total     829500
evaluation/num paths total       8295
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.781307
evaluation/Rewards Std              1.29398
evaluation/Rewards Max             -0.0113138
evaluation/Rewards Min            -10.6799
evaluation/Returns Mean           -78.1307
evaluation/Returns Std             72.1151
evaluation/Returns Max            -15.9845
evaluation/Returns Min           -297.403
evaluation/Actions Mean             0.0138578
evaluation/Actions Std              0.194619
evaluation/Actions Max              0.998232
evaluation/Actions Min             -0.993689
evaluation/Num Paths               15
evaluation/Average Returns        -78.1307
time/data storing (s)               0.00265507
time/evaluation sampling (s)        0.319823
time/exploration sampling (s)       0.136994
time/logging (s)                    0.00481929
time/saving (s)                     0.00191081
time/training (s)                   1.92824
time/epoch (s)                      2.39444
time/total (s)                   1357.26
Epoch                             552
-----------------------------  ---------------
2019-04-23 01:36:12.712141 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 553 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   52.6038
trainer/QF2 Loss                   52.5666
trainer/Policy Loss                40.8622
trainer/Q1 Predictions Mean       -38.8706
trainer/Q1 Predictions Std         37.2393
trainer/Q1 Predictions Max         -6.77332
trainer/Q1 Predictions Min       -133.938
trainer/Q2 Predictions Mean       -38.8508
trainer/Q2 Predictions Std         37.2365
trainer/Q2 Predictions Max         -6.81223
trainer/Q2 Predictions Min       -133.711
trainer/Q Targets Mean            -38.3697
trainer/Q Targets Std              37.7719
trainer/Q Targets Max              -0.174472
trainer/Q Targets Min            -135.679
trainer/Log Pis Mean                2.11384
trainer/Log Pis Std                 1.22878
trainer/Log Pis Max                 6.59137
trainer/Log Pis Min                -3.49315
trainer/Policy mu Mean             -0.0327911
trainer/Policy mu Std               0.506632
trainer/Policy mu Max               3.78983
trainer/Policy mu Min              -3.00416
trainer/Policy log std Mean        -2.27299
trainer/Policy log std Std          0.411103
trainer/Policy log std Max         -0.41853
trainer/Policy log std Min         -3.18407
trainer/Alpha                       0.0748532
trainer/Alpha Loss                  0.295096
exploration/num steps total    277200
exploration/num paths total      2772
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.438131
exploration/Rewards Std             0.673646
exploration/Rewards Max            -0.0164353
exploration/Rewards Min            -7.32621
exploration/Returns Mean          -43.8131
exploration/Returns Std            25.359
exploration/Returns Max           -16.1323
exploration/Returns Min           -83.7224
exploration/Actions Mean           -0.00369406
exploration/Actions Std             0.190411
exploration/Actions Max             0.993629
exploration/Actions Min            -0.992085
exploration/Num Paths               5
exploration/Average Returns       -43.8131
evaluation/num steps total     831000
evaluation/num paths total       8310
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.435371
evaluation/Rewards Std              1.03737
evaluation/Rewards Max             -0.0132784
evaluation/Rewards Min            -10.7644
evaluation/Returns Mean           -43.5371
evaluation/Returns Std             32.5075
evaluation/Returns Max             -9.25265
evaluation/Returns Min           -121.571
evaluation/Actions Mean            -0.0065232
evaluation/Actions Std              0.182836
evaluation/Actions Max              0.999028
evaluation/Actions Min             -0.997629
evaluation/Num Paths               15
evaluation/Average Returns        -43.5371
time/data storing (s)               0.00257133
time/evaluation sampling (s)        0.316939
time/exploration sampling (s)       0.135434
time/logging (s)                    0.00480424
time/saving (s)                     0.00192392
time/training (s)                   2.00857
time/epoch (s)                      2.47025
time/total (s)                   1359.73
Epoch                             553
-----------------------------  ---------------
2019-04-23 01:36:15.156249 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 554 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                  182.275
trainer/QF2 Loss                  182.545
trainer/Policy Loss                31.2385
trainer/Q1 Predictions Mean       -29.3148
trainer/Q1 Predictions Std         32.0905
trainer/Q1 Predictions Max         -6.67677
trainer/Q1 Predictions Min       -131.733
trainer/Q2 Predictions Mean       -29.3425
trainer/Q2 Predictions Std         32.0663
trainer/Q2 Predictions Max         -6.6567
trainer/Q2 Predictions Min       -131.588
trainer/Q Targets Mean            -27.7169
trainer/Q Targets Std              30.9152
trainer/Q Targets Max              -0.12342
trainer/Q Targets Min            -132.994
trainer/Log Pis Mean                1.96622
trainer/Log Pis Std                 1.27634
trainer/Log Pis Max                 8.21476
trainer/Log Pis Min                -1.61775
trainer/Policy mu Mean              0.00313326
trainer/Policy mu Std               0.430688
trainer/Policy mu Max               2.94365
trainer/Policy mu Min              -1.74709
trainer/Policy log std Mean        -2.279
trainer/Policy log std Std          0.402065
trainer/Policy log std Max         -0.552569
trainer/Policy log std Min         -3.10605
trainer/Alpha                       0.0757102
trainer/Alpha Loss                 -0.0871745
exploration/num steps total    277700
exploration/num paths total      2777
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.737246
exploration/Rewards Std             1.13924
exploration/Rewards Max            -0.0100078
exploration/Rewards Min            -9.87399
exploration/Returns Mean          -73.7246
exploration/Returns Std            25.9234
exploration/Returns Max           -31.7914
exploration/Returns Min           -98.4818
exploration/Actions Mean            0.0273604
exploration/Actions Std             0.248931
exploration/Actions Max             0.999648
exploration/Actions Min            -0.994073
exploration/Num Paths               5
exploration/Average Returns       -73.7246
evaluation/num steps total     832500
evaluation/num paths total       8325
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.740363
evaluation/Rewards Std              1.05404
evaluation/Rewards Max             -0.00943806
evaluation/Rewards Min            -10.0465
evaluation/Returns Mean           -74.0363
evaluation/Returns Std             70.6373
evaluation/Returns Max             -7.01012
evaluation/Returns Min           -281.236
evaluation/Actions Mean            -0.0030003
evaluation/Actions Std              0.17084
evaluation/Actions Max              0.997871
evaluation/Actions Min             -0.997796
evaluation/Num Paths               15
evaluation/Average Returns        -74.0363
time/data storing (s)               0.00266311
time/evaluation sampling (s)        0.330496
time/exploration sampling (s)       0.137668
time/logging (s)                    0.00486351
time/saving (s)                     0.00197829
time/training (s)                   1.95537
time/epoch (s)                      2.43304
time/total (s)                   1362.17
Epoch                             554
-----------------------------  ---------------
2019-04-23 01:36:17.627907 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 555 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.124451
trainer/QF2 Loss                    0.112806
trainer/Policy Loss                33.5154
trainer/Q1 Predictions Mean       -31.5781
trainer/Q1 Predictions Std         34.8915
trainer/Q1 Predictions Max         -6.70727
trainer/Q1 Predictions Min       -132.195
trainer/Q2 Predictions Mean       -31.619
trainer/Q2 Predictions Std         34.9124
trainer/Q2 Predictions Max         -6.70139
trainer/Q2 Predictions Min       -132.213
trainer/Q Targets Mean            -31.7266
trainer/Q Targets Std              35.0693
trainer/Q Targets Max              -6.77953
trainer/Q Targets Min            -132.403
trainer/Log Pis Mean                2.00481
trainer/Log Pis Std                 1.16102
trainer/Log Pis Max                 4.94405
trainer/Log Pis Min                -1.94336
trainer/Policy mu Mean             -0.0415144
trainer/Policy mu Std               0.348938
trainer/Policy mu Max               2.11589
trainer/Policy mu Min              -2.42971
trainer/Policy log std Mean        -2.31226
trainer/Policy log std Std          0.366762
trainer/Policy log std Max         -0.715244
trainer/Policy log std Min         -3.20172
trainer/Alpha                       0.0800234
trainer/Alpha Loss                  0.0121433
exploration/num steps total    278200
exploration/num paths total      2782
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.650551
exploration/Rewards Std             0.887771
exploration/Rewards Max            -0.0143844
exploration/Rewards Min            -8.90117
exploration/Returns Mean          -65.0551
exploration/Returns Std            56.0847
exploration/Returns Max           -18.294
exploration/Returns Min          -165.337
exploration/Actions Mean            0.0117318
exploration/Actions Std             0.194572
exploration/Actions Max             0.997991
exploration/Actions Min            -0.987484
exploration/Num Paths               5
exploration/Average Returns       -65.0551
evaluation/num steps total     834000
evaluation/num paths total       8340
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.766952
evaluation/Rewards Std              1.34935
evaluation/Rewards Max             -0.00280866
evaluation/Rewards Min            -10.9932
evaluation/Returns Mean           -76.6952
evaluation/Returns Std             82.0774
evaluation/Returns Max             -4.56264
evaluation/Returns Min           -265.761
evaluation/Actions Mean             0.00744465
evaluation/Actions Std              0.197318
evaluation/Actions Max              0.99828
evaluation/Actions Min             -0.998535
evaluation/Num Paths               15
evaluation/Average Returns        -76.6952
time/data storing (s)               0.0027113
time/evaluation sampling (s)        0.319656
time/exploration sampling (s)       0.137025
time/logging (s)                    0.00475945
time/saving (s)                     0.00158315
time/training (s)                   1.99408
time/epoch (s)                      2.45982
time/total (s)                   1364.63
Epoch                             555
-----------------------------  ---------------
2019-04-23 01:36:20.061100 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 556 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.782479
trainer/QF2 Loss                    0.886183
trainer/Policy Loss                28.4216
trainer/Q1 Predictions Mean       -26.4177
trainer/Q1 Predictions Std         27.1686
trainer/Q1 Predictions Max         -6.65982
trainer/Q1 Predictions Min       -133.306
trainer/Q2 Predictions Mean       -26.4525
trainer/Q2 Predictions Std         27.212
trainer/Q2 Predictions Max         -6.66857
trainer/Q2 Predictions Min       -133.778
trainer/Q Targets Mean            -26.4046
trainer/Q Targets Std              27.1848
trainer/Q Targets Max              -0.111171
trainer/Q Targets Min            -133.002
trainer/Log Pis Mean                2.0555
trainer/Log Pis Std                 1.18917
trainer/Log Pis Max                 7.43953
trainer/Log Pis Min                -1.12794
trainer/Policy mu Mean             -0.0220853
trainer/Policy mu Std               0.536262
trainer/Policy mu Max               2.99522
trainer/Policy mu Min              -3.17128
trainer/Policy log std Mean        -2.221
trainer/Policy log std Std          0.414061
trainer/Policy log std Max         -0.601845
trainer/Policy log std Min         -3.00001
trainer/Alpha                       0.0796466
trainer/Alpha Loss                  0.140426
exploration/num steps total    278700
exploration/num paths total      2787
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.817314
exploration/Rewards Std             1.04834
exploration/Rewards Max            -0.00542083
exploration/Rewards Min           -10.959
exploration/Returns Mean          -81.7314
exploration/Returns Std            41.9978
exploration/Returns Max           -26.0349
exploration/Returns Min          -136.711
exploration/Actions Mean           -0.0240745
exploration/Actions Std             0.230973
exploration/Actions Max             0.997345
exploration/Actions Min            -0.995677
exploration/Num Paths               5
exploration/Average Returns       -81.7314
evaluation/num steps total     835500
evaluation/num paths total       8355
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.438289
evaluation/Rewards Std              1.0597
evaluation/Rewards Max             -0.0162693
evaluation/Rewards Min            -10.1583
evaluation/Returns Mean           -43.8289
evaluation/Returns Std             32.4436
evaluation/Returns Max             -5.19177
evaluation/Returns Min           -108.985
evaluation/Actions Mean            -0.00681321
evaluation/Actions Std              0.184178
evaluation/Actions Max              0.995504
evaluation/Actions Min             -0.997284
evaluation/Num Paths               15
evaluation/Average Returns        -43.8289
time/data storing (s)               0.00264803
time/evaluation sampling (s)        0.319649
time/exploration sampling (s)       0.136657
time/logging (s)                    0.00501653
time/saving (s)                     0.00179912
time/training (s)                   1.95601
time/epoch (s)                      2.42178
time/total (s)                   1367.06
Epoch                             556
-----------------------------  ---------------
2019-04-23 01:36:22.495403 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 557 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.11624
trainer/QF2 Loss                    0.128201
trainer/Policy Loss                33.126
trainer/Q1 Predictions Mean       -31.1151
trainer/Q1 Predictions Std         31.7796
trainer/Q1 Predictions Max         -6.90534
trainer/Q1 Predictions Min       -134.566
trainer/Q2 Predictions Mean       -31.0908
trainer/Q2 Predictions Std         31.7356
trainer/Q2 Predictions Max         -6.85217
trainer/Q2 Predictions Min       -134.371
trainer/Q Targets Mean            -31.1902
trainer/Q Targets Std              31.8322
trainer/Q Targets Max              -6.82346
trainer/Q Targets Min            -134.037
trainer/Log Pis Mean                2.04743
trainer/Log Pis Std                 1.21546
trainer/Log Pis Max                 7.26558
trainer/Log Pis Min                -1.53995
trainer/Policy mu Mean             -0.0245098
trainer/Policy mu Std               0.570032
trainer/Policy mu Max               2.65126
trainer/Policy mu Min              -2.8253
trainer/Policy log std Mean        -2.21174
trainer/Policy log std Std          0.466061
trainer/Policy log std Max         -0.478156
trainer/Policy log std Min         -3.0793
trainer/Alpha                       0.0802759
trainer/Alpha Loss                  0.11963
exploration/num steps total    279200
exploration/num paths total      2792
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.10595
exploration/Rewards Std             1.27813
exploration/Rewards Max            -0.0035732
exploration/Rewards Min            -8.61576
exploration/Returns Mean         -110.595
exploration/Returns Std            80.2207
exploration/Returns Max           -40.5502
exploration/Returns Min          -267.24
exploration/Actions Mean            0.025604
exploration/Actions Std             0.220133
exploration/Actions Max             0.999496
exploration/Actions Min            -0.998525
exploration/Num Paths               5
exploration/Average Returns      -110.595
evaluation/num steps total     837000
evaluation/num paths total       8370
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.555456
evaluation/Rewards Std              0.897459
evaluation/Rewards Max             -0.0251012
evaluation/Rewards Min             -9.04679
evaluation/Returns Mean           -55.5456
evaluation/Returns Std             28.6297
evaluation/Returns Max            -13.228
evaluation/Returns Min           -110.812
evaluation/Actions Mean            -0.00415519
evaluation/Actions Std              0.182254
evaluation/Actions Max              0.998721
evaluation/Actions Min             -0.995289
evaluation/Num Paths               15
evaluation/Average Returns        -55.5456
time/data storing (s)               0.00270515
time/evaluation sampling (s)        0.321388
time/exploration sampling (s)       0.136055
time/logging (s)                    0.00477211
time/saving (s)                     0.00192491
time/training (s)                   1.9552
time/epoch (s)                      2.42204
time/total (s)                   1369.49
Epoch                             557
-----------------------------  ---------------
2019-04-23 01:36:25.145437 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 558 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.61218
trainer/QF2 Loss                    1.61517
trainer/Policy Loss                33.3628
trainer/Q1 Predictions Mean       -31.2655
trainer/Q1 Predictions Std         33.8637
trainer/Q1 Predictions Max         -6.8749
trainer/Q1 Predictions Min       -144.216
trainer/Q2 Predictions Mean       -31.2742
trainer/Q2 Predictions Std         33.8742
trainer/Q2 Predictions Max         -6.84603
trainer/Q2 Predictions Min       -144.04
trainer/Q Targets Mean            -31.6113
trainer/Q Targets Std              34.3355
trainer/Q Targets Max              -0.447548
trainer/Q Targets Min            -143.781
trainer/Log Pis Mean                2.1946
trainer/Log Pis Std                 1.1485
trainer/Log Pis Max                 7.88457
trainer/Log Pis Min                -0.402439
trainer/Policy mu Mean             -0.0447919
trainer/Policy mu Std               0.561102
trainer/Policy mu Max               3.0044
trainer/Policy mu Min              -3.34716
trainer/Policy log std Mean        -2.2351
trainer/Policy log std Std          0.449065
trainer/Policy log std Max         -0.417742
trainer/Policy log std Min         -3.05229
trainer/Alpha                       0.0793107
trainer/Alpha Loss                  0.493176
exploration/num steps total    279700
exploration/num paths total      2797
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.28597
exploration/Rewards Std             0.799067
exploration/Rewards Max            -0.00467949
exploration/Rewards Min            -8.78648
exploration/Returns Mean          -28.597
exploration/Returns Std            15.1046
exploration/Returns Max           -13.6094
exploration/Returns Min           -56.8712
exploration/Actions Mean           -0.00838823
exploration/Actions Std             0.194776
exploration/Actions Max             0.996456
exploration/Actions Min            -0.999159
exploration/Num Paths               5
exploration/Average Returns       -28.597
evaluation/num steps total     838500
evaluation/num paths total       8385
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.834308
evaluation/Rewards Std              1.19518
evaluation/Rewards Max             -0.0132771
evaluation/Rewards Min             -9.62472
evaluation/Returns Mean           -83.4308
evaluation/Returns Std             94.2897
evaluation/Returns Max            -14.5102
evaluation/Returns Min           -296.549
evaluation/Actions Mean             0.00389018
evaluation/Actions Std              0.164702
evaluation/Actions Max              0.998937
evaluation/Actions Min             -0.994513
evaluation/Num Paths               15
evaluation/Average Returns        -83.4308
time/data storing (s)               0.00436126
time/evaluation sampling (s)        0.326683
time/exploration sampling (s)       0.157652
time/logging (s)                    0.00454417
time/saving (s)                     0.00195878
time/training (s)                   2.14292
time/epoch (s)                      2.63812
time/total (s)                   1372.13
Epoch                             558
-----------------------------  ---------------
2019-04-23 01:36:27.665243 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 559 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.361194
trainer/QF2 Loss                    0.356916
trainer/Policy Loss                39.7686
trainer/Q1 Predictions Mean       -37.7802
trainer/Q1 Predictions Std         38.9574
trainer/Q1 Predictions Max         -6.8943
trainer/Q1 Predictions Min       -135.505
trainer/Q2 Predictions Mean       -37.7879
trainer/Q2 Predictions Std         38.9248
trainer/Q2 Predictions Max         -6.83529
trainer/Q2 Predictions Min       -135.301
trainer/Q Targets Mean            -38.0981
trainer/Q Targets Std              38.9848
trainer/Q Targets Max              -6.87966
trainer/Q Targets Min            -135.256
trainer/Log Pis Mean                2.03801
trainer/Log Pis Std                 1.09174
trainer/Log Pis Max                 4.41358
trainer/Log Pis Min                -2.96327
trainer/Policy mu Mean              0.00652804
trainer/Policy mu Std               0.280253
trainer/Policy mu Max               2.39317
trainer/Policy mu Min              -2.41575
trainer/Policy log std Mean        -2.33062
trainer/Policy log std Std          0.356288
trainer/Policy log std Max         -0.650117
trainer/Policy log std Min         -3.11804
trainer/Alpha                       0.0773404
trainer/Alpha Loss                  0.0972749
exploration/num steps total    280200
exploration/num paths total      2802
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.485347
exploration/Rewards Std             0.849452
exploration/Rewards Max            -0.0105018
exploration/Rewards Min            -7.03658
exploration/Returns Mean          -48.5347
exploration/Returns Std            22.1953
exploration/Returns Max           -23.1469
exploration/Returns Min           -79.4903
exploration/Actions Mean           -0.00899987
exploration/Actions Std             0.222144
exploration/Actions Max             0.997787
exploration/Actions Min            -0.994509
exploration/Num Paths               5
exploration/Average Returns       -48.5347
evaluation/num steps total     840000
evaluation/num paths total       8400
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.550937
evaluation/Rewards Std              1.15967
evaluation/Rewards Max             -0.0249513
evaluation/Rewards Min            -10.077
evaluation/Returns Mean           -55.0937
evaluation/Returns Std             67.1197
evaluation/Returns Max             -3.96308
evaluation/Returns Min           -293.909
evaluation/Actions Mean            -0.000616902
evaluation/Actions Std              0.182575
evaluation/Actions Max              0.998588
evaluation/Actions Min             -0.994284
evaluation/Num Paths               15
evaluation/Average Returns        -55.0937
time/data storing (s)               0.00324699
time/evaluation sampling (s)        0.325124
time/exploration sampling (s)       0.183586
time/logging (s)                    0.00351782
time/saving (s)                     0.0015727
time/training (s)                   1.99042
time/epoch (s)                      2.50747
time/total (s)                   1374.64
Epoch                             559
-----------------------------  ----------------
2019-04-23 01:36:30.113506 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 560 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.224982
trainer/QF2 Loss                    0.21922
trainer/Policy Loss                33.9146
trainer/Q1 Predictions Mean       -31.8809
trainer/Q1 Predictions Std         32.3533
trainer/Q1 Predictions Max         -6.78964
trainer/Q1 Predictions Min       -135.782
trainer/Q2 Predictions Mean       -31.8936
trainer/Q2 Predictions Std         32.3512
trainer/Q2 Predictions Max         -6.75314
trainer/Q2 Predictions Min       -135.541
trainer/Q Targets Mean            -32.1847
trainer/Q Targets Std              32.5207
trainer/Q Targets Max              -6.84242
trainer/Q Targets Min            -134.669
trainer/Log Pis Mean                2.13985
trainer/Log Pis Std                 1.05943
trainer/Log Pis Max                 5.27974
trainer/Log Pis Min                -1.96733
trainer/Policy mu Mean              0.00294486
trainer/Policy mu Std               0.465245
trainer/Policy mu Max               2.70962
trainer/Policy mu Min              -2.4721
trainer/Policy log std Mean        -2.29713
trainer/Policy log std Std          0.44862
trainer/Policy log std Max         -0.420265
trainer/Policy log std Min         -3.14139
trainer/Alpha                       0.0781241
trainer/Alpha Loss                  0.356551
exploration/num steps total    280700
exploration/num paths total      2807
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.819834
exploration/Rewards Std             1.31584
exploration/Rewards Max            -0.0213424
exploration/Rewards Min           -10.5567
exploration/Returns Mean          -81.9834
exploration/Returns Std            37.7335
exploration/Returns Max           -38.04
exploration/Returns Min          -147.601
exploration/Actions Mean            0.00619184
exploration/Actions Std             0.241878
exploration/Actions Max             0.998215
exploration/Actions Min            -0.994484
exploration/Num Paths               5
exploration/Average Returns       -81.9834
evaluation/num steps total     841500
evaluation/num paths total       8415
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.511171
evaluation/Rewards Std              1.02474
evaluation/Rewards Max             -0.015065
evaluation/Rewards Min            -11.0362
evaluation/Returns Mean           -51.1171
evaluation/Returns Std             35.5523
evaluation/Returns Max             -8.83226
evaluation/Returns Min           -150.028
evaluation/Actions Mean             0.0104
evaluation/Actions Std              0.179822
evaluation/Actions Max              0.999243
evaluation/Actions Min             -0.996176
evaluation/Num Paths               15
evaluation/Average Returns        -51.1171
time/data storing (s)               0.00295435
time/evaluation sampling (s)        0.322693
time/exploration sampling (s)       0.136988
time/logging (s)                    0.00478265
time/saving (s)                     0.00193028
time/training (s)                   1.96832
time/epoch (s)                      2.43766
time/total (s)                   1377.08
Epoch                             560
-----------------------------  ---------------
2019-04-23 01:36:32.563964 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 561 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.47653
trainer/QF2 Loss                    0.278553
trainer/Policy Loss                34.5941
trainer/Q1 Predictions Mean       -32.6035
trainer/Q1 Predictions Std         38.4663
trainer/Q1 Predictions Max         -6.90972
trainer/Q1 Predictions Min       -155.843
trainer/Q2 Predictions Mean       -32.6318
trainer/Q2 Predictions Std         38.5855
trainer/Q2 Predictions Max         -6.8747
trainer/Q2 Predictions Min       -159.145
trainer/Q Targets Mean            -32.9569
trainer/Q Targets Std              38.9235
trainer/Q Targets Max              -6.87378
trainer/Q Targets Min            -160.348
trainer/Log Pis Mean                2.00735
trainer/Log Pis Std                 1.1306
trainer/Log Pis Max                 5.90066
trainer/Log Pis Min                -1.30879
trainer/Policy mu Mean             -0.0428639
trainer/Policy mu Std               0.422545
trainer/Policy mu Max               1.83226
trainer/Policy mu Min              -2.63439
trainer/Policy log std Mean        -2.2571
trainer/Policy log std Std          0.381367
trainer/Policy log std Max         -0.550735
trainer/Policy log std Min         -3.11248
trainer/Alpha                       0.0787361
trainer/Alpha Loss                  0.0186822
exploration/num steps total    281200
exploration/num paths total      2812
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.402982
exploration/Rewards Std             0.997655
exploration/Rewards Max            -0.00205919
exploration/Rewards Min            -9.67221
exploration/Returns Mean          -40.2982
exploration/Returns Std            15.3266
exploration/Returns Max           -26.9372
exploration/Returns Min           -69.7176
exploration/Actions Mean            0.0177109
exploration/Actions Std             0.242469
exploration/Actions Max             0.99974
exploration/Actions Min            -0.995585
exploration/Num Paths               5
exploration/Average Returns       -40.2982
evaluation/num steps total     843000
evaluation/num paths total       8430
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.7495
evaluation/Rewards Std              1.04661
evaluation/Rewards Max             -0.0769188
evaluation/Rewards Min            -11.7955
evaluation/Returns Mean           -74.95
evaluation/Returns Std             41.123
evaluation/Returns Max            -15.8207
evaluation/Returns Min           -156.916
evaluation/Actions Mean             0.000811618
evaluation/Actions Std              0.184891
evaluation/Actions Max              0.999073
evaluation/Actions Min             -0.997739
evaluation/Num Paths               15
evaluation/Average Returns        -74.95
time/data storing (s)               0.00267447
time/evaluation sampling (s)        0.317067
time/exploration sampling (s)       0.136111
time/logging (s)                    0.00477859
time/saving (s)                     0.00192878
time/training (s)                   1.97675
time/epoch (s)                      2.43931
time/total (s)                   1379.53
Epoch                             561
-----------------------------  ----------------
2019-04-23 01:36:35.025417 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 562 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.937835
trainer/QF2 Loss                    0.904359
trainer/Policy Loss                33.848
trainer/Q1 Predictions Mean       -31.9958
trainer/Q1 Predictions Std         39.4971
trainer/Q1 Predictions Max         -6.79278
trainer/Q1 Predictions Min       -134.647
trainer/Q2 Predictions Mean       -32.0121
trainer/Q2 Predictions Std         39.4934
trainer/Q2 Predictions Max         -6.84649
trainer/Q2 Predictions Min       -134.28
trainer/Q Targets Mean            -31.9148
trainer/Q Targets Std              39.7532
trainer/Q Targets Max              -0.0718772
trainer/Q Targets Min            -135.093
trainer/Log Pis Mean                1.86691
trainer/Log Pis Std                 1.59304
trainer/Log Pis Max                 7.66801
trainer/Log Pis Min                -5.49471
trainer/Policy mu Mean              0.0670377
trainer/Policy mu Std               0.464184
trainer/Policy mu Max               3.6634
trainer/Policy mu Min              -2.64073
trainer/Policy log std Mean        -2.24033
trainer/Policy log std Std          0.389612
trainer/Policy log std Max         -0.288629
trainer/Policy log std Min         -3.17284
trainer/Alpha                       0.0777972
trainer/Alpha Loss                 -0.339858
exploration/num steps total    281700
exploration/num paths total      2817
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.891759
exploration/Rewards Std             1.26646
exploration/Rewards Max            -0.0223442
exploration/Rewards Min            -7.57775
exploration/Returns Mean          -89.1759
exploration/Returns Std           103.756
exploration/Returns Max           -28.9034
exploration/Returns Min          -296.013
exploration/Actions Mean           -0.00851982
exploration/Actions Std             0.213357
exploration/Actions Max             0.999244
exploration/Actions Min            -0.998244
exploration/Num Paths               5
exploration/Average Returns       -89.1759
evaluation/num steps total     844500
evaluation/num paths total       8445
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.526347
evaluation/Rewards Std              0.978031
evaluation/Rewards Max             -0.0084942
evaluation/Rewards Min            -11.0256
evaluation/Returns Mean           -52.6347
evaluation/Returns Std             32.1087
evaluation/Returns Max            -10.7802
evaluation/Returns Min           -144.031
evaluation/Actions Mean             0.00292503
evaluation/Actions Std              0.185124
evaluation/Actions Max              0.998786
evaluation/Actions Min             -0.996783
evaluation/Num Paths               15
evaluation/Average Returns        -52.6347
time/data storing (s)               0.00275429
time/evaluation sampling (s)        0.317811
time/exploration sampling (s)       0.137356
time/logging (s)                    0.00480559
time/saving (s)                     0.00192133
time/training (s)                   1.98508
time/epoch (s)                      2.44973
time/total (s)                   1381.98
Epoch                             562
-----------------------------  ---------------
2019-04-23 01:36:37.490615 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 563 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.177387
trainer/QF2 Loss                    0.161564
trainer/Policy Loss                35.4482
trainer/Q1 Predictions Mean       -33.5611
trainer/Q1 Predictions Std         33.407
trainer/Q1 Predictions Max         -6.79307
trainer/Q1 Predictions Min       -133.773
trainer/Q2 Predictions Mean       -33.5719
trainer/Q2 Predictions Std         33.4221
trainer/Q2 Predictions Max         -6.81743
trainer/Q2 Predictions Min       -133.923
trainer/Q Targets Mean            -33.8178
trainer/Q Targets Std              33.5955
trainer/Q Targets Max              -6.86153
trainer/Q Targets Min            -134.837
trainer/Log Pis Mean                1.92236
trainer/Log Pis Std                 0.970602
trainer/Log Pis Max                 5.07606
trainer/Log Pis Min                -1.04304
trainer/Policy mu Mean             -0.0102015
trainer/Policy mu Std               0.291068
trainer/Policy mu Max               1.48021
trainer/Policy mu Min              -2.44114
trainer/Policy log std Mean        -2.304
trainer/Policy log std Std          0.322096
trainer/Policy log std Max         -0.718596
trainer/Policy log std Min         -2.97147
trainer/Alpha                       0.0784219
trainer/Alpha Loss                 -0.197646
exploration/num steps total    282200
exploration/num paths total      2822
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.861552
exploration/Rewards Std             1.32982
exploration/Rewards Max            -0.0042378
exploration/Rewards Min            -7.82831
exploration/Returns Mean          -86.1552
exploration/Returns Std            96.8292
exploration/Returns Max           -21.5296
exploration/Returns Min          -278.58
exploration/Actions Mean            0.0203995
exploration/Actions Std             0.238679
exploration/Actions Max             0.998966
exploration/Actions Min            -0.993304
exploration/Num Paths               5
exploration/Average Returns       -86.1552
evaluation/num steps total     846000
evaluation/num paths total       8460
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.646995
evaluation/Rewards Std              1.21089
evaluation/Rewards Max             -0.00265834
evaluation/Rewards Min            -10.9777
evaluation/Returns Mean           -64.6995
evaluation/Returns Std             66.1374
evaluation/Returns Max             -5.43721
evaluation/Returns Min           -284.71
evaluation/Actions Mean             0.00414686
evaluation/Actions Std              0.178853
evaluation/Actions Max              0.998952
evaluation/Actions Min             -0.997614
evaluation/Num Paths               15
evaluation/Average Returns        -64.6995
time/data storing (s)               0.00264885
time/evaluation sampling (s)        0.325516
time/exploration sampling (s)       0.135564
time/logging (s)                    0.00490946
time/saving (s)                     0.00193721
time/training (s)                   1.98241
time/epoch (s)                      2.45298
time/total (s)                   1384.44
Epoch                             563
-----------------------------  ---------------
2019-04-23 01:36:39.934589 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 564 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    2.03906
trainer/QF2 Loss                    2.00899
trainer/Policy Loss                35.043
trainer/Q1 Predictions Mean       -33.0292
trainer/Q1 Predictions Std         34.9943
trainer/Q1 Predictions Max         -6.79826
trainer/Q1 Predictions Min       -132.771
trainer/Q2 Predictions Mean       -33.038
trainer/Q2 Predictions Std         34.9954
trainer/Q2 Predictions Max         -6.75394
trainer/Q2 Predictions Min       -132.243
trainer/Q Targets Mean            -33.7377
trainer/Q Targets Std              35.8971
trainer/Q Targets Max              -0.149006
trainer/Q Targets Min            -135.442
trainer/Log Pis Mean                2.0775
trainer/Log Pis Std                 1.05576
trainer/Log Pis Max                 6.38717
trainer/Log Pis Min                -1.92435
trainer/Policy mu Mean             -0.0126372
trainer/Policy mu Std               0.297224
trainer/Policy mu Max               2.32852
trainer/Policy mu Min              -2.42123
trainer/Policy log std Mean        -2.29762
trainer/Policy log std Std          0.307569
trainer/Policy log std Max         -0.843056
trainer/Policy log std Min         -3.03396
trainer/Alpha                       0.0815553
trainer/Alpha Loss                  0.19427
exploration/num steps total    282700
exploration/num paths total      2827
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.589525
exploration/Rewards Std             1.27617
exploration/Rewards Max            -0.0114764
exploration/Rewards Min           -10.2484
exploration/Returns Mean          -58.9525
exploration/Returns Std            16.1733
exploration/Returns Max           -37.779
exploration/Returns Min           -82.3886
exploration/Actions Mean            0.0152467
exploration/Actions Std             0.252791
exploration/Actions Max             0.999753
exploration/Actions Min            -0.999241
exploration/Num Paths               5
exploration/Average Returns       -58.9525
evaluation/num steps total     847500
evaluation/num paths total       8475
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.539151
evaluation/Rewards Std              1.18434
evaluation/Rewards Max             -0.0150482
evaluation/Rewards Min            -11.2623
evaluation/Returns Mean           -53.9151
evaluation/Returns Std             62.6064
evaluation/Returns Max             -9.06235
evaluation/Returns Min           -274.672
evaluation/Actions Mean            -0.014079
evaluation/Actions Std              0.181572
evaluation/Actions Max              0.993695
evaluation/Actions Min             -0.99813
evaluation/Num Paths               15
evaluation/Average Returns        -53.9151
time/data storing (s)               0.00253131
time/evaluation sampling (s)        0.322935
time/exploration sampling (s)       0.137956
time/logging (s)                    0.00424344
time/saving (s)                     0.00194057
time/training (s)                   1.96126
time/epoch (s)                      2.43087
time/total (s)                   1386.87
Epoch                             564
-----------------------------  ---------------
2019-04-23 01:36:42.390901 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 565 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.179574
trainer/QF2 Loss                    0.186162
trainer/Policy Loss                34.4874
trainer/Q1 Predictions Mean       -32.7432
trainer/Q1 Predictions Std         30.7639
trainer/Q1 Predictions Max         -6.91919
trainer/Q1 Predictions Min       -133.856
trainer/Q2 Predictions Mean       -32.7298
trainer/Q2 Predictions Std         30.748
trainer/Q2 Predictions Max         -6.88423
trainer/Q2 Predictions Min       -133.708
trainer/Q Targets Mean            -32.9657
trainer/Q Targets Std              30.9894
trainer/Q Targets Max              -6.84662
trainer/Q Targets Min            -134.809
trainer/Log Pis Mean                1.85755
trainer/Log Pis Std                 1.07229
trainer/Log Pis Max                 4.33277
trainer/Log Pis Min                -1.93769
trainer/Policy mu Mean             -0.0185894
trainer/Policy mu Std               0.326446
trainer/Policy mu Max               2.23016
trainer/Policy mu Min              -2.61643
trainer/Policy log std Mean        -2.30907
trainer/Policy log std Std          0.389077
trainer/Policy log std Max         -0.502863
trainer/Policy log std Min         -2.98482
trainer/Alpha                       0.0822435
trainer/Alpha Loss                 -0.355821
exploration/num steps total    283200
exploration/num paths total      2832
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.662368
exploration/Rewards Std             1.37664
exploration/Rewards Max            -0.0126985
exploration/Rewards Min            -9.89695
exploration/Returns Mean          -66.2368
exploration/Returns Std            20.4966
exploration/Returns Max           -33.9066
exploration/Returns Min           -92.9839
exploration/Actions Mean            0.0276999
exploration/Actions Std             0.256443
exploration/Actions Max             0.999433
exploration/Actions Min            -0.996347
exploration/Num Paths               5
exploration/Average Returns       -66.2368
evaluation/num steps total     849000
evaluation/num paths total       8490
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.841761
evaluation/Rewards Std              1.17777
evaluation/Rewards Max             -0.0343253
evaluation/Rewards Min             -9.47812
evaluation/Returns Mean           -84.1761
evaluation/Returns Std             96.4212
evaluation/Returns Max            -12.2808
evaluation/Returns Min           -281.996
evaluation/Actions Mean            -0.0143062
evaluation/Actions Std              0.170349
evaluation/Actions Max              0.997411
evaluation/Actions Min             -0.995717
evaluation/Num Paths               15
evaluation/Average Returns        -84.1761
time/data storing (s)               0.00258272
time/evaluation sampling (s)        0.318397
time/exploration sampling (s)       0.132975
time/logging (s)                    0.00459594
time/saving (s)                     0.00193278
time/training (s)                   1.98362
time/epoch (s)                      2.4441
time/total (s)                   1389.32
Epoch                             565
-----------------------------  ---------------
2019-04-23 01:36:44.846132 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 566 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   31.8391
trainer/QF2 Loss                   31.7746
trainer/Policy Loss                33.2341
trainer/Q1 Predictions Mean       -31.144
trainer/Q1 Predictions Std         35.1587
trainer/Q1 Predictions Max         -7.02853
trainer/Q1 Predictions Min       -135.3
trainer/Q2 Predictions Mean       -31.1879
trainer/Q2 Predictions Std         35.1971
trainer/Q2 Predictions Max         -7.01928
trainer/Q2 Predictions Min       -135.05
trainer/Q Targets Mean            -30.8337
trainer/Q Targets Std              35.399
trainer/Q Targets Max              -0.97154
trainer/Q Targets Min            -135.321
trainer/Log Pis Mean                2.12509
trainer/Log Pis Std                 1.2791
trainer/Log Pis Max                 8.30625
trainer/Log Pis Min                -1.69002
trainer/Policy mu Mean              0.0430103
trainer/Policy mu Std               0.558871
trainer/Policy mu Max               3.4815
trainer/Policy mu Min              -2.26455
trainer/Policy log std Mean        -2.21213
trainer/Policy log std Std          0.407462
trainer/Policy log std Max         -0.643641
trainer/Policy log std Min         -3.02092
trainer/Alpha                       0.0809371
trainer/Alpha Loss                  0.314475
exploration/num steps total    283700
exploration/num paths total      2837
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.04032
exploration/Rewards Std             1.45977
exploration/Rewards Max            -0.011097
exploration/Rewards Min            -9.33556
exploration/Returns Mean         -104.032
exploration/Returns Std            84.1574
exploration/Returns Max           -44.9327
exploration/Returns Min          -270.352
exploration/Actions Mean           -0.00890144
exploration/Actions Std             0.219771
exploration/Actions Max             0.999114
exploration/Actions Min            -0.99981
exploration/Num Paths               5
exploration/Average Returns      -104.032
evaluation/num steps total     850500
evaluation/num paths total       8505
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.981062
evaluation/Rewards Std              1.10741
evaluation/Rewards Max             -0.0395623
evaluation/Rewards Min             -8.71318
evaluation/Returns Mean           -98.1062
evaluation/Returns Std             78.7466
evaluation/Returns Max             -8.79331
evaluation/Returns Min           -266.011
evaluation/Actions Mean             0.00112241
evaluation/Actions Std              0.170988
evaluation/Actions Max              0.999138
evaluation/Actions Min             -0.998015
evaluation/Num Paths               15
evaluation/Average Returns        -98.1062
time/data storing (s)               0.00269853
time/evaluation sampling (s)        0.316269
time/exploration sampling (s)       0.140194
time/logging (s)                    0.00483212
time/saving (s)                     0.00200252
time/training (s)                   1.97692
time/epoch (s)                      2.44291
time/total (s)                   1391.77
Epoch                             566
-----------------------------  ---------------
2019-04-23 01:36:47.290781 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 567 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                   48.8835
trainer/QF2 Loss                   48.6623
trainer/Policy Loss                36.5844
trainer/Q1 Predictions Mean       -34.9008
trainer/Q1 Predictions Std         38.4157
trainer/Q1 Predictions Max         -6.9401
trainer/Q1 Predictions Min       -134.221
trainer/Q2 Predictions Mean       -34.8904
trainer/Q2 Predictions Std         38.4154
trainer/Q2 Predictions Max         -6.83779
trainer/Q2 Predictions Min       -133.753
trainer/Q Targets Mean            -34.6193
trainer/Q Targets Std              38.8565
trainer/Q Targets Max              -1.66573
trainer/Q Targets Min            -136.033
trainer/Log Pis Mean                1.69044
trainer/Log Pis Std                 1.44064
trainer/Log Pis Max                 6.08417
trainer/Log Pis Min                -3.64973
trainer/Policy mu Mean             -0.0112931
trainer/Policy mu Std               0.442958
trainer/Policy mu Max               3.36959
trainer/Policy mu Min              -2.40133
trainer/Policy log std Mean        -2.24652
trainer/Policy log std Std          0.362037
trainer/Policy log std Max         -0.745101
trainer/Policy log std Min         -2.98483
trainer/Alpha                       0.0787996
trainer/Alpha Loss                 -0.786526
exploration/num steps total    284200
exploration/num paths total      2842
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.61504
exploration/Rewards Std             1.08146
exploration/Rewards Max            -0.000514635
exploration/Rewards Min            -7.94174
exploration/Returns Mean          -61.504
exploration/Returns Std            50.4629
exploration/Returns Max           -22.0844
exploration/Returns Min          -160.27
exploration/Actions Mean            0.0205341
exploration/Actions Std             0.225011
exploration/Actions Max             0.999234
exploration/Actions Min            -0.998702
exploration/Num Paths               5
exploration/Average Returns       -61.504
evaluation/num steps total     852000
evaluation/num paths total       8520
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.656122
evaluation/Rewards Std              1.16871
evaluation/Rewards Max             -0.012545
evaluation/Rewards Min            -10.4413
evaluation/Returns Mean           -65.6122
evaluation/Returns Std             69.2702
evaluation/Returns Max             -6.44239
evaluation/Returns Min           -294.684
evaluation/Actions Mean             0.00182174
evaluation/Actions Std              0.193903
evaluation/Actions Max              0.996752
evaluation/Actions Min             -0.99666
evaluation/Num Paths               15
evaluation/Average Returns        -65.6122
time/data storing (s)               0.00259039
time/evaluation sampling (s)        0.317183
time/exploration sampling (s)       0.13655
time/logging (s)                    0.00382373
time/saving (s)                     0.00191194
time/training (s)                   1.96981
time/epoch (s)                      2.43187
time/total (s)                   1394.21
Epoch                             567
-----------------------------  ----------------
2019-04-23 01:36:49.716521 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 568 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    3.07754
trainer/QF2 Loss                    3.07548
trainer/Policy Loss                32.5451
trainer/Q1 Predictions Mean       -30.5173
trainer/Q1 Predictions Std         28.1646
trainer/Q1 Predictions Max         -7.04902
trainer/Q1 Predictions Min       -134.153
trainer/Q2 Predictions Mean       -30.5147
trainer/Q2 Predictions Std         28.1445
trainer/Q2 Predictions Max         -7.00804
trainer/Q2 Predictions Min       -133.703
trainer/Q Targets Mean            -30.5206
trainer/Q Targets Std              28.7435
trainer/Q Targets Max              -0.110396
trainer/Q Targets Min            -135.069
trainer/Log Pis Mean                2.10718
trainer/Log Pis Std                 1.22859
trainer/Log Pis Max                 6.10448
trainer/Log Pis Min                -1.88588
trainer/Policy mu Mean              0.00315874
trainer/Policy mu Std               0.462161
trainer/Policy mu Max               2.50998
trainer/Policy mu Min              -2.47187
trainer/Policy log std Mean        -2.26018
trainer/Policy log std Std          0.417183
trainer/Policy log std Max         -0.509731
trainer/Policy log std Min         -3.00997
trainer/Alpha                       0.0799791
trainer/Alpha Loss                  0.270735
exploration/num steps total    284700
exploration/num paths total      2847
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.406284
exploration/Rewards Std             0.663613
exploration/Rewards Max            -0.00511799
exploration/Rewards Min            -7.35179
exploration/Returns Mean          -40.6284
exploration/Returns Std            14.79
exploration/Returns Max           -21.0216
exploration/Returns Min           -65.2683
exploration/Actions Mean            0.011731
exploration/Actions Std             0.180474
exploration/Actions Max             0.996156
exploration/Actions Min            -0.931101
exploration/Num Paths               5
exploration/Average Returns       -40.6284
evaluation/num steps total     853500
evaluation/num paths total       8535
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.632167
evaluation/Rewards Std              0.980637
evaluation/Rewards Max             -0.0265029
evaluation/Rewards Min             -9.93834
evaluation/Returns Mean           -63.2167
evaluation/Returns Std             46.0692
evaluation/Returns Max             -4.61885
evaluation/Returns Min           -165.106
evaluation/Actions Mean             0.000464117
evaluation/Actions Std              0.177017
evaluation/Actions Max              0.996349
evaluation/Actions Min             -0.997394
evaluation/Num Paths               15
evaluation/Average Returns        -63.2167
time/data storing (s)               0.00281452
time/evaluation sampling (s)        0.31981
time/exploration sampling (s)       0.135262
time/logging (s)                    0.00480723
time/saving (s)                     0.00192591
time/training (s)                   1.95273
time/epoch (s)                      2.41735
time/total (s)                   1396.63
Epoch                             568
-----------------------------  ----------------
2019-04-23 01:36:52.171275 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 569 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   13.8835
trainer/QF2 Loss                   13.9154
trainer/Policy Loss                32.5042
trainer/Q1 Predictions Mean       -30.6752
trainer/Q1 Predictions Std         31.0014
trainer/Q1 Predictions Max         -7.08203
trainer/Q1 Predictions Min       -132.482
trainer/Q2 Predictions Mean       -30.6982
trainer/Q2 Predictions Std         31.1038
trainer/Q2 Predictions Max         -7.03871
trainer/Q2 Predictions Min       -133.327
trainer/Q Targets Mean            -30.6329
trainer/Q Targets Std              31.541
trainer/Q Targets Max              -1.45068
trainer/Q Targets Min            -134.192
trainer/Log Pis Mean                1.89433
trainer/Log Pis Std                 1.34802
trainer/Log Pis Max                 6.60241
trainer/Log Pis Min                -1.69941
trainer/Policy mu Mean             -0.0488651
trainer/Policy mu Std               0.502173
trainer/Policy mu Max               2.4713
trainer/Policy mu Min              -2.8598
trainer/Policy log std Mean        -2.21602
trainer/Policy log std Std          0.398764
trainer/Policy log std Max         -0.746569
trainer/Policy log std Min         -3.03162
trainer/Alpha                       0.0817789
trainer/Alpha Loss                 -0.26457
exploration/num steps total    285200
exploration/num paths total      2852
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.674686
exploration/Rewards Std             0.887556
exploration/Rewards Max            -0.0669767
exploration/Rewards Min            -7.33329
exploration/Returns Mean          -67.4686
exploration/Returns Std            19.8763
exploration/Returns Max           -48.9773
exploration/Returns Min          -104.222
exploration/Actions Mean           -0.00302593
exploration/Actions Std             0.217209
exploration/Actions Max             0.989635
exploration/Actions Min            -0.998997
exploration/Num Paths               5
exploration/Average Returns       -67.4686
evaluation/num steps total     855000
evaluation/num paths total       8550
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.492669
evaluation/Rewards Std              1.02823
evaluation/Rewards Max             -0.019664
evaluation/Rewards Min            -10.0981
evaluation/Returns Mean           -49.2669
evaluation/Returns Std             36.9224
evaluation/Returns Max             -7.83554
evaluation/Returns Min           -147.612
evaluation/Actions Mean             0.00713054
evaluation/Actions Std              0.183067
evaluation/Actions Max              0.999065
evaluation/Actions Min             -0.995437
evaluation/Num Paths               15
evaluation/Average Returns        -49.2669
time/data storing (s)               0.00263827
time/evaluation sampling (s)        0.326136
time/exploration sampling (s)       0.137206
time/logging (s)                    0.00353566
time/saving (s)                     0.00193754
time/training (s)                   1.96954
time/epoch (s)                      2.44099
time/total (s)                   1399.07
Epoch                             569
-----------------------------  ---------------
2019-04-23 01:36:54.638335 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 570 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   29.9883
trainer/QF2 Loss                   30.0159
trainer/Policy Loss                29.8562
trainer/Q1 Predictions Mean       -27.8634
trainer/Q1 Predictions Std         24.8529
trainer/Q1 Predictions Max         -7.03292
trainer/Q1 Predictions Min       -129.919
trainer/Q2 Predictions Mean       -27.864
trainer/Q2 Predictions Std         24.8398
trainer/Q2 Predictions Max         -7.04555
trainer/Q2 Predictions Min       -129.938
trainer/Q Targets Mean            -27.565
trainer/Q Targets Std              25.0958
trainer/Q Targets Max              -0.743676
trainer/Q Targets Min            -132.49
trainer/Log Pis Mean                2.09599
trainer/Log Pis Std                 1.24566
trainer/Log Pis Max                 6.35223
trainer/Log Pis Min                -3.42816
trainer/Policy mu Mean             -0.0115759
trainer/Policy mu Std               0.430212
trainer/Policy mu Max               2.62398
trainer/Policy mu Min              -2.76328
trainer/Policy log std Mean        -2.27788
trainer/Policy log std Std          0.371641
trainer/Policy log std Max         -0.651749
trainer/Policy log std Min         -3.02328
trainer/Alpha                       0.0800779
trainer/Alpha Loss                  0.242353
exploration/num steps total    285700
exploration/num paths total      2857
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.16678
exploration/Rewards Std             1.67169
exploration/Rewards Max            -0.00187454
exploration/Rewards Min           -11.7232
exploration/Returns Mean         -116.678
exploration/Returns Std           108.728
exploration/Returns Max           -33.0299
exploration/Returns Min          -326.763
exploration/Actions Mean            0.0109037
exploration/Actions Std             0.256819
exploration/Actions Max             0.999124
exploration/Actions Min            -0.998028
exploration/Num Paths               5
exploration/Average Returns      -116.678
evaluation/num steps total     856500
evaluation/num paths total       8565
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.655652
evaluation/Rewards Std              1.17523
evaluation/Rewards Max             -0.0234914
evaluation/Rewards Min            -10.7552
evaluation/Returns Mean           -65.5652
evaluation/Returns Std             77.2925
evaluation/Returns Max            -15.7187
evaluation/Returns Min           -334.059
evaluation/Actions Mean             0.0109346
evaluation/Actions Std              0.185636
evaluation/Actions Max              0.995383
evaluation/Actions Min             -0.995702
evaluation/Num Paths               15
evaluation/Average Returns        -65.5652
time/data storing (s)               0.00269949
time/evaluation sampling (s)        0.315506
time/exploration sampling (s)       0.137006
time/logging (s)                    0.00476549
time/saving (s)                     0.00192739
time/training (s)                   1.99448
time/epoch (s)                      2.45639
time/total (s)                   1401.53
Epoch                             570
-----------------------------  ---------------
2019-04-23 01:36:57.090420 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 571 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.457503
trainer/QF2 Loss                    0.472405
trainer/Policy Loss                42.7362
trainer/Q1 Predictions Mean       -41.0115
trainer/Q1 Predictions Std         40.0635
trainer/Q1 Predictions Max         -7.10255
trainer/Q1 Predictions Min       -138.035
trainer/Q2 Predictions Mean       -41.0074
trainer/Q2 Predictions Std         40.0511
trainer/Q2 Predictions Max         -7.22243
trainer/Q2 Predictions Min       -137.323
trainer/Q Targets Mean            -41.3131
trainer/Q Targets Std              40.4617
trainer/Q Targets Max              -7.31198
trainer/Q Targets Min            -137.513
trainer/Log Pis Mean                1.81448
trainer/Log Pis Std                 1.55984
trainer/Log Pis Max                 8.17158
trainer/Log Pis Min                -4.848
trainer/Policy mu Mean             -0.0671053
trainer/Policy mu Std               0.58736
trainer/Policy mu Max               2.74596
trainer/Policy mu Min              -3.00888
trainer/Policy log std Mean        -2.23965
trainer/Policy log std Std          0.417262
trainer/Policy log std Max         -0.587929
trainer/Policy log std Min         -3.01545
trainer/Alpha                       0.0806765
trainer/Alpha Loss                 -0.467021
exploration/num steps total    286200
exploration/num paths total      2862
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.457986
exploration/Rewards Std             1.13234
exploration/Rewards Max            -0.0147411
exploration/Rewards Min            -9.40288
exploration/Returns Mean          -45.7986
exploration/Returns Std            17.5209
exploration/Returns Max           -22.6776
exploration/Returns Min           -69.156
exploration/Actions Mean           -0.00244316
exploration/Actions Std             0.245189
exploration/Actions Max             0.998992
exploration/Actions Min            -0.996321
exploration/Num Paths               5
exploration/Average Returns       -45.7986
evaluation/num steps total     858000
evaluation/num paths total       8580
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.665231
evaluation/Rewards Std              1.16695
evaluation/Rewards Max             -0.0352202
evaluation/Rewards Min             -9.56674
evaluation/Returns Mean           -66.5231
evaluation/Returns Std             73.1764
evaluation/Returns Max             -8.70134
evaluation/Returns Min           -311.46
evaluation/Actions Mean             0.00388936
evaluation/Actions Std              0.180623
evaluation/Actions Max              0.999468
evaluation/Actions Min             -0.996605
evaluation/Num Paths               15
evaluation/Average Returns        -66.5231
time/data storing (s)               0.00274081
time/evaluation sampling (s)        0.316779
time/exploration sampling (s)       0.144564
time/logging (s)                    0.00475694
time/saving (s)                     0.0019236
time/training (s)                   1.96895
time/epoch (s)                      2.43971
time/total (s)                   1403.98
Epoch                             571
-----------------------------  ---------------
2019-04-23 01:36:59.542738 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 572 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.45971
trainer/QF2 Loss                    1.4555
trainer/Policy Loss                36.8193
trainer/Q1 Predictions Mean       -34.9888
trainer/Q1 Predictions Std         36.3993
trainer/Q1 Predictions Max         -6.91451
trainer/Q1 Predictions Min       -133.113
trainer/Q2 Predictions Mean       -35.002
trainer/Q2 Predictions Std         36.3932
trainer/Q2 Predictions Max         -7.01421
trainer/Q2 Predictions Min       -133.729
trainer/Q Targets Mean            -34.9722
trainer/Q Targets Std              36.6285
trainer/Q Targets Max              -0.311831
trainer/Q Targets Min            -134.383
trainer/Log Pis Mean                1.92054
trainer/Log Pis Std                 1.08163
trainer/Log Pis Max                 4.06665
trainer/Log Pis Min                -2.79253
trainer/Policy mu Mean             -0.0679137
trainer/Policy mu Std               0.33508
trainer/Policy mu Max               0.996998
trainer/Policy mu Min              -2.6959
trainer/Policy log std Mean        -2.29909
trainer/Policy log std Std          0.323268
trainer/Policy log std Max         -0.677827
trainer/Policy log std Min         -3.00516
trainer/Alpha                       0.0801161
trainer/Alpha Loss                 -0.200581
exploration/num steps total    286700
exploration/num paths total      2867
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.815333
exploration/Rewards Std             1.01491
exploration/Rewards Max            -0.0144987
exploration/Rewards Min            -9.26523
exploration/Returns Mean          -81.5333
exploration/Returns Std            49.1443
exploration/Returns Max           -21.6724
exploration/Returns Min          -167.588
exploration/Actions Mean            0.00869939
exploration/Actions Std             0.213539
exploration/Actions Max             0.998107
exploration/Actions Min            -0.998474
exploration/Num Paths               5
exploration/Average Returns       -81.5333
evaluation/num steps total     859500
evaluation/num paths total       8595
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.621476
evaluation/Rewards Std              0.996202
evaluation/Rewards Max             -0.0324089
evaluation/Rewards Min            -10.3218
evaluation/Returns Mean           -62.1476
evaluation/Returns Std             41.001
evaluation/Returns Max            -15.1855
evaluation/Returns Min           -137.069
evaluation/Actions Mean             0.00591991
evaluation/Actions Std              0.183658
evaluation/Actions Max              0.997535
evaluation/Actions Min             -0.998976
evaluation/Num Paths               15
evaluation/Average Returns        -62.1476
time/data storing (s)               0.00313225
time/evaluation sampling (s)        0.324299
time/exploration sampling (s)       0.148721
time/logging (s)                    0.00477933
time/saving (s)                     0.00191346
time/training (s)                   1.95863
time/epoch (s)                      2.44148
time/total (s)                   1406.42
Epoch                             572
-----------------------------  ---------------
2019-04-23 01:37:02.006050 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 573 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.175939
trainer/QF2 Loss                    0.133905
trainer/Policy Loss                37.9871
trainer/Q1 Predictions Mean       -36.0321
trainer/Q1 Predictions Std         37.4778
trainer/Q1 Predictions Max         -7.07025
trainer/Q1 Predictions Min       -140.751
trainer/Q2 Predictions Mean       -36.0516
trainer/Q2 Predictions Std         37.5183
trainer/Q2 Predictions Max         -7.06308
trainer/Q2 Predictions Min       -142.55
trainer/Q Targets Mean            -36.2019
trainer/Q Targets Std              37.5675
trainer/Q Targets Max              -6.99641
trainer/Q Targets Min            -142.676
trainer/Log Pis Mean                2.04227
trainer/Log Pis Std                 0.930236
trainer/Log Pis Max                 3.59274
trainer/Log Pis Min                -0.72602
trainer/Policy mu Mean             -0.064489
trainer/Policy mu Std               0.347801
trainer/Policy mu Max               0.813774
trainer/Policy mu Min              -2.62966
trainer/Policy log std Mean        -2.32362
trainer/Policy log std Std          0.357199
trainer/Policy log std Max         -0.774466
trainer/Policy log std Min         -2.91813
trainer/Alpha                       0.0792216
trainer/Alpha Loss                  0.107164
exploration/num steps total    287200
exploration/num paths total      2872
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.773697
exploration/Rewards Std             1.2875
exploration/Rewards Max            -0.00944596
exploration/Rewards Min            -9.36751
exploration/Returns Mean          -77.3697
exploration/Returns Std            52.3915
exploration/Returns Max           -32.8465
exploration/Returns Min          -177.595
exploration/Actions Mean           -0.00788999
exploration/Actions Std             0.232716
exploration/Actions Max             0.997847
exploration/Actions Min            -0.998902
exploration/Num Paths               5
exploration/Average Returns       -77.3697
evaluation/num steps total     861000
evaluation/num paths total       8610
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.780896
evaluation/Rewards Std              1.18781
evaluation/Rewards Max             -0.0174278
evaluation/Rewards Min             -9.70906
evaluation/Returns Mean           -78.0896
evaluation/Returns Std             80.1473
evaluation/Returns Max             -8.9968
evaluation/Returns Min           -312.678
evaluation/Actions Mean             0.00797694
evaluation/Actions Std              0.18855
evaluation/Actions Max              0.998437
evaluation/Actions Min             -0.994975
evaluation/Num Paths               15
evaluation/Average Returns        -78.0896
time/data storing (s)               0.0028435
time/evaluation sampling (s)        0.319038
time/exploration sampling (s)       0.138145
time/logging (s)                    0.00480078
time/saving (s)                     0.00195449
time/training (s)                   1.98399
time/epoch (s)                      2.45078
time/total (s)                   1408.88
Epoch                             573
-----------------------------  ---------------
2019-04-23 01:37:04.445711 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 574 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   13.8274
trainer/QF2 Loss                   13.8568
trainer/Policy Loss                35.9704
trainer/Q1 Predictions Mean       -33.9532
trainer/Q1 Predictions Std         32.2793
trainer/Q1 Predictions Max         -7.0363
trainer/Q1 Predictions Min       -132.391
trainer/Q2 Predictions Mean       -33.9434
trainer/Q2 Predictions Std         32.3086
trainer/Q2 Predictions Max         -7.01068
trainer/Q2 Predictions Min       -132.17
trainer/Q Targets Mean            -33.6989
trainer/Q Targets Std              32.4711
trainer/Q Targets Max              -0.830291
trainer/Q Targets Min            -131.789
trainer/Log Pis Mean                2.14272
trainer/Log Pis Std                 1.1205
trainer/Log Pis Max                 4.64838
trainer/Log Pis Min                -2.87499
trainer/Policy mu Mean             -0.0138912
trainer/Policy mu Std               0.270826
trainer/Policy mu Max               2.56386
trainer/Policy mu Min              -0.62282
trainer/Policy log std Mean        -2.35261
trainer/Policy log std Std          0.339091
trainer/Policy log std Max         -0.803699
trainer/Policy log std Min         -2.94222
trainer/Alpha                       0.0793008
trainer/Alpha Loss                  0.361719
exploration/num steps total    287700
exploration/num paths total      2877
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.00697
exploration/Rewards Std             1.36856
exploration/Rewards Max            -0.0201589
exploration/Rewards Min            -9.5318
exploration/Returns Mean         -100.697
exploration/Returns Std           100.091
exploration/Returns Max           -25.7687
exploration/Returns Min          -296.116
exploration/Actions Mean            0.00114599
exploration/Actions Std             0.221215
exploration/Actions Max             0.998086
exploration/Actions Min            -0.999092
exploration/Num Paths               5
exploration/Average Returns      -100.697
evaluation/num steps total     862500
evaluation/num paths total       8625
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.560415
evaluation/Rewards Std              1.07118
evaluation/Rewards Max             -0.00314552
evaluation/Rewards Min             -8.92206
evaluation/Returns Mean           -56.0415
evaluation/Returns Std             72.9315
evaluation/Returns Max             -1.23489
evaluation/Returns Min           -299.093
evaluation/Actions Mean            -0.00904442
evaluation/Actions Std              0.174887
evaluation/Actions Max              0.998343
evaluation/Actions Min             -0.997478
evaluation/Num Paths               15
evaluation/Average Returns        -56.0415
time/data storing (s)               0.00264297
time/evaluation sampling (s)        0.323005
time/exploration sampling (s)       0.141081
time/logging (s)                    0.00478772
time/saving (s)                     0.00196871
time/training (s)                   1.95365
time/epoch (s)                      2.42714
time/total (s)                   1411.31
Epoch                             574
-----------------------------  ---------------
2019-04-23 01:37:06.888982 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 575 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.32644
trainer/QF2 Loss                    1.34472
trainer/Policy Loss                36.0393
trainer/Q1 Predictions Mean       -34.2122
trainer/Q1 Predictions Std         34.8228
trainer/Q1 Predictions Max         -6.94435
trainer/Q1 Predictions Min       -130.407
trainer/Q2 Predictions Mean       -34.1902
trainer/Q2 Predictions Std         34.803
trainer/Q2 Predictions Max         -6.93161
trainer/Q2 Predictions Min       -130.138
trainer/Q Targets Mean            -34.8905
trainer/Q Targets Std              35.5693
trainer/Q Targets Max              -7.13157
trainer/Q Targets Min            -132.444
trainer/Log Pis Mean                1.94667
trainer/Log Pis Std                 1.16941
trainer/Log Pis Max                 3.69294
trainer/Log Pis Min                -2.90218
trainer/Policy mu Mean             -0.0200087
trainer/Policy mu Std               0.324299
trainer/Policy mu Max               2.25697
trainer/Policy mu Min              -2.12417
trainer/Policy log std Mean        -2.33512
trainer/Policy log std Std          0.378325
trainer/Policy log std Max         -0.58613
trainer/Policy log std Min         -2.95914
trainer/Alpha                       0.0786251
trainer/Alpha Loss                 -0.13563
exploration/num steps total    288200
exploration/num paths total      2882
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.14638
exploration/Rewards Std             1.72402
exploration/Rewards Max            -0.0112784
exploration/Rewards Min           -11.7072
exploration/Returns Mean         -114.638
exploration/Returns Std           104.844
exploration/Returns Max           -22.9523
exploration/Returns Min          -320.013
exploration/Actions Mean           -0.000748155
exploration/Actions Std             0.253365
exploration/Actions Max             0.999699
exploration/Actions Min            -0.997551
exploration/Num Paths               5
exploration/Average Returns      -114.638
evaluation/num steps total     864000
evaluation/num paths total       8640
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.724948
evaluation/Rewards Std              1.26673
evaluation/Rewards Max             -0.0103429
evaluation/Rewards Min            -10.3762
evaluation/Returns Mean           -72.4948
evaluation/Returns Std             89.3241
evaluation/Returns Max             -3.40785
evaluation/Returns Min           -294.301
evaluation/Actions Mean            -0.0138738
evaluation/Actions Std              0.175741
evaluation/Actions Max              0.998717
evaluation/Actions Min             -0.998162
evaluation/Num Paths               15
evaluation/Average Returns        -72.4948
time/data storing (s)               0.00271451
time/evaluation sampling (s)        0.319111
time/exploration sampling (s)       0.135744
time/logging (s)                    0.00482421
time/saving (s)                     0.00191998
time/training (s)                   1.96657
time/epoch (s)                      2.43089
time/total (s)                   1413.75
Epoch                             575
-----------------------------  ----------------
2019-04-23 01:37:09.331308 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 576 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   28.0223
trainer/QF2 Loss                   28.0322
trainer/Policy Loss                31.4466
trainer/Q1 Predictions Mean       -29.3361
trainer/Q1 Predictions Std         28.9941
trainer/Q1 Predictions Max         -6.99834
trainer/Q1 Predictions Min       -136.534
trainer/Q2 Predictions Mean       -29.3166
trainer/Q2 Predictions Std         28.9493
trainer/Q2 Predictions Max         -6.95734
trainer/Q2 Predictions Min       -135.395
trainer/Q Targets Mean            -28.9094
trainer/Q Targets Std              29.0481
trainer/Q Targets Max              -0.966147
trainer/Q Targets Min            -134.289
trainer/Log Pis Mean                2.25351
trainer/Log Pis Std                 1.0568
trainer/Log Pis Max                 5.22753
trainer/Log Pis Min                -3.49772
trainer/Policy mu Mean             -0.0463709
trainer/Policy mu Std               0.462449
trainer/Policy mu Max               2.76576
trainer/Policy mu Min              -2.70708
trainer/Policy log std Mean        -2.24348
trainer/Policy log std Std          0.388121
trainer/Policy log std Max         -0.624591
trainer/Policy log std Min         -2.80436
trainer/Alpha                       0.0810483
trainer/Alpha Loss                  0.637037
exploration/num steps total    288700
exploration/num paths total      2887
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.653166
exploration/Rewards Std             1.19776
exploration/Rewards Max            -0.00783643
exploration/Rewards Min           -10.0713
exploration/Returns Mean          -65.3166
exploration/Returns Std            41.9965
exploration/Returns Max           -16.4162
exploration/Returns Min          -139.364
exploration/Actions Mean           -0.0307579
exploration/Actions Std             0.219779
exploration/Actions Max             0.982262
exploration/Actions Min            -0.997868
exploration/Num Paths               5
exploration/Average Returns       -65.3166
evaluation/num steps total     865500
evaluation/num paths total       8655
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.804738
evaluation/Rewards Std              1.23431
evaluation/Rewards Max             -0.0187826
evaluation/Rewards Min             -9.70379
evaluation/Returns Mean           -80.4738
evaluation/Returns Std             76.7769
evaluation/Returns Max             -3.96809
evaluation/Returns Min           -297.205
evaluation/Actions Mean            -0.00028141
evaluation/Actions Std              0.197006
evaluation/Actions Max              0.994772
evaluation/Actions Min             -0.996859
evaluation/Num Paths               15
evaluation/Average Returns        -80.4738
time/data storing (s)               0.00271931
time/evaluation sampling (s)        0.315563
time/exploration sampling (s)       0.135456
time/logging (s)                    0.0047912
time/saving (s)                     0.00194668
time/training (s)                   1.96921
time/epoch (s)                      2.42969
time/total (s)                   1416.18
Epoch                             576
-----------------------------  ---------------
2019-04-23 01:37:11.816469 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 577 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   16.3052
trainer/QF2 Loss                   16.6867
trainer/Policy Loss                34.0696
trainer/Q1 Predictions Mean       -32.1778
trainer/Q1 Predictions Std         31.759
trainer/Q1 Predictions Max         -6.91508
trainer/Q1 Predictions Min       -129.745
trainer/Q2 Predictions Mean       -32.178
trainer/Q2 Predictions Std         31.7471
trainer/Q2 Predictions Max         -6.88659
trainer/Q2 Predictions Min       -129.58
trainer/Q Targets Mean            -32.211
trainer/Q Targets Std              32.3515
trainer/Q Targets Max              -1.25855
trainer/Q Targets Min            -132.148
trainer/Log Pis Mean                1.91461
trainer/Log Pis Std                 1.52639
trainer/Log Pis Max                 9.83454
trainer/Log Pis Min                -4.34691
trainer/Policy mu Mean              0.00682082
trainer/Policy mu Std               0.515415
trainer/Policy mu Max               3.47689
trainer/Policy mu Min              -2.51769
trainer/Policy log std Mean        -2.27998
trainer/Policy log std Std          0.379635
trainer/Policy log std Max         -0.262508
trainer/Policy log std Min         -2.78927
trainer/Alpha                       0.0815048
trainer/Alpha Loss                 -0.214072
exploration/num steps total    289200
exploration/num paths total      2892
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.516354
exploration/Rewards Std             1.03411
exploration/Rewards Max            -0.0109596
exploration/Rewards Min            -9.77087
exploration/Returns Mean          -51.6354
exploration/Returns Std            21.1579
exploration/Returns Max           -15.7572
exploration/Returns Min           -80.5939
exploration/Actions Mean            0.0121646
exploration/Actions Std             0.214163
exploration/Actions Max             0.998965
exploration/Actions Min            -0.999506
exploration/Num Paths               5
exploration/Average Returns       -51.6354
evaluation/num steps total     867000
evaluation/num paths total       8670
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.717449
evaluation/Rewards Std              1.09414
evaluation/Rewards Max             -0.0125711
evaluation/Rewards Min            -11.0029
evaluation/Returns Mean           -71.7449
evaluation/Returns Std             34.5007
evaluation/Returns Max            -23.0145
evaluation/Returns Min           -146.796
evaluation/Actions Mean            -0.0140012
evaluation/Actions Std              0.195135
evaluation/Actions Max              0.99798
evaluation/Actions Min             -0.998516
evaluation/Num Paths               15
evaluation/Average Returns        -71.7449
time/data storing (s)               0.00272085
time/evaluation sampling (s)        0.323992
time/exploration sampling (s)       0.135254
time/logging (s)                    0.00486331
time/saving (s)                     0.0177041
time/training (s)                   1.9883
time/epoch (s)                      2.47283
time/total (s)                   1418.66
Epoch                             577
-----------------------------  ---------------
2019-04-23 01:37:14.284485 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 578 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.4368
trainer/QF2 Loss                    1.35194
trainer/Policy Loss                32.3592
trainer/Q1 Predictions Mean       -30.2955
trainer/Q1 Predictions Std         33.7066
trainer/Q1 Predictions Max         -7.16983
trainer/Q1 Predictions Min       -128.271
trainer/Q2 Predictions Mean       -30.3482
trainer/Q2 Predictions Std         33.6924
trainer/Q2 Predictions Max         -7.1255
trainer/Q2 Predictions Min       -128.285
trainer/Q Targets Mean            -31.0062
trainer/Q Targets Std              34.5907
trainer/Q Targets Max              -7.09907
trainer/Q Targets Min            -131.696
trainer/Log Pis Mean                2.07244
trainer/Log Pis Std                 0.919724
trainer/Log Pis Max                 5.76787
trainer/Log Pis Min                -0.424955
trainer/Policy mu Mean             -0.0186946
trainer/Policy mu Std               0.374617
trainer/Policy mu Max               3.10075
trainer/Policy mu Min              -2.41964
trainer/Policy log std Mean        -2.30773
trainer/Policy log std Std          0.322339
trainer/Policy log std Max         -0.652158
trainer/Policy log std Min         -2.82039
trainer/Alpha                       0.0798943
trainer/Alpha Loss                  0.183053
exploration/num steps total    289700
exploration/num paths total      2897
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.544879
exploration/Rewards Std             0.929206
exploration/Rewards Max            -0.00689675
exploration/Rewards Min            -9.86499
exploration/Returns Mean          -54.4879
exploration/Returns Std            39.3806
exploration/Returns Max           -20.3596
exploration/Returns Min          -127.311
exploration/Actions Mean            0.00662735
exploration/Actions Std             0.218181
exploration/Actions Max             0.99697
exploration/Actions Min            -0.998774
exploration/Num Paths               5
exploration/Average Returns       -54.4879
evaluation/num steps total     868500
evaluation/num paths total       8685
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.693222
evaluation/Rewards Std              1.22238
evaluation/Rewards Max             -0.00937858
evaluation/Rewards Min            -10.0036
evaluation/Returns Mean           -69.3222
evaluation/Returns Std             70.3546
evaluation/Returns Max            -16.4458
evaluation/Returns Min           -284.675
evaluation/Actions Mean             0.0208574
evaluation/Actions Std              0.190324
evaluation/Actions Max              0.998864
evaluation/Actions Min             -0.996405
evaluation/Num Paths               15
evaluation/Average Returns        -69.3222
time/data storing (s)               0.00299381
time/evaluation sampling (s)        0.321484
time/exploration sampling (s)       0.134163
time/logging (s)                    0.00476637
time/saving (s)                     0.00999179
time/training (s)                   1.98097
time/epoch (s)                      2.45437
time/total (s)                   1421.12
Epoch                             578
-----------------------------  ---------------
2019-04-23 01:37:16.738845 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 579 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.724435
trainer/QF2 Loss                    0.747401
trainer/Policy Loss                39.1203
trainer/Q1 Predictions Mean       -36.9817
trainer/Q1 Predictions Std         36.5718
trainer/Q1 Predictions Max         -7.08595
trainer/Q1 Predictions Min       -136.228
trainer/Q2 Predictions Mean       -36.9721
trainer/Q2 Predictions Std         36.5314
trainer/Q2 Predictions Max         -7.06832
trainer/Q2 Predictions Min       -135.721
trainer/Q Targets Mean            -37.5178
trainer/Q Targets Std              37.108
trainer/Q Targets Max              -7.06886
trainer/Q Targets Min            -138.224
trainer/Log Pis Mean                2.19846
trainer/Log Pis Std                 0.954063
trainer/Log Pis Max                 4.34574
trainer/Log Pis Min                -2.70394
trainer/Policy mu Mean             -0.0495305
trainer/Policy mu Std               0.422262
trainer/Policy mu Max               2.4484
trainer/Policy mu Min              -2.23299
trainer/Policy log std Mean        -2.33863
trainer/Policy log std Std          0.400403
trainer/Policy log std Max         -0.636915
trainer/Policy log std Min         -2.8434
trainer/Alpha                       0.0820821
trainer/Alpha Loss                  0.496173
exploration/num steps total    290200
exploration/num paths total      2902
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.373056
exploration/Rewards Std             0.934829
exploration/Rewards Max            -0.0198099
exploration/Rewards Min           -10.8486
exploration/Returns Mean          -37.3056
exploration/Returns Std            15.8287
exploration/Returns Max           -20.2661
exploration/Returns Min           -67.2016
exploration/Actions Mean            0.00852584
exploration/Actions Std             0.220486
exploration/Actions Max             0.998119
exploration/Actions Min            -0.994929
exploration/Num Paths               5
exploration/Average Returns       -37.3056
evaluation/num steps total     870000
evaluation/num paths total       8700
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.706382
evaluation/Rewards Std              1.07735
evaluation/Rewards Max             -0.0429464
evaluation/Rewards Min             -9.18769
evaluation/Returns Mean           -70.6382
evaluation/Returns Std             73.66
evaluation/Returns Max             -7.61679
evaluation/Returns Min           -300.188
evaluation/Actions Mean             0.00268693
evaluation/Actions Std              0.17945
evaluation/Actions Max              0.9967
evaluation/Actions Min             -0.993971
evaluation/Num Paths               15
evaluation/Average Returns        -70.6382
time/data storing (s)               0.00264153
time/evaluation sampling (s)        0.318574
time/exploration sampling (s)       0.135722
time/logging (s)                    0.00487012
time/saving (s)                     0.00193206
time/training (s)                   1.97808
time/epoch (s)                      2.44182
time/total (s)                   1423.56
Epoch                             579
-----------------------------  ---------------
2019-04-23 01:37:19.184118 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 580 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                  319.307
trainer/QF2 Loss                  320.358
trainer/Policy Loss                34.5778
trainer/Q1 Predictions Mean       -32.7257
trainer/Q1 Predictions Std         33.819
trainer/Q1 Predictions Max         -7.08799
trainer/Q1 Predictions Min       -129.496
trainer/Q2 Predictions Mean       -32.7264
trainer/Q2 Predictions Std         33.8211
trainer/Q2 Predictions Max         -7.10468
trainer/Q2 Predictions Min       -129.803
trainer/Q Targets Mean            -30.6233
trainer/Q Targets Std              31.6059
trainer/Q Targets Max              -2.94089
trainer/Q Targets Min            -131.593
trainer/Log Pis Mean                1.87132
trainer/Log Pis Std                 1.20216
trainer/Log Pis Max                 6.30976
trainer/Log Pis Min                -2.38438
trainer/Policy mu Mean             -0.0449383
trainer/Policy mu Std               0.500429
trainer/Policy mu Max               2.52299
trainer/Policy mu Min              -2.73759
trainer/Policy log std Mean        -2.26803
trainer/Policy log std Std          0.423849
trainer/Policy log std Max         -0.491305
trainer/Policy log std Min         -2.80655
trainer/Alpha                       0.0830223
trainer/Alpha Loss                 -0.320218
exploration/num steps total    290700
exploration/num paths total      2907
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.840033
exploration/Rewards Std             1.24563
exploration/Rewards Max            -0.00344456
exploration/Rewards Min            -7.65575
exploration/Returns Mean          -84.0033
exploration/Returns Std           102.074
exploration/Returns Max           -17.8029
exploration/Returns Min          -286.706
exploration/Actions Mean           -0.0125475
exploration/Actions Std             0.214561
exploration/Actions Max             0.998308
exploration/Actions Min            -0.996015
exploration/Num Paths               5
exploration/Average Returns       -84.0033
evaluation/num steps total     871500
evaluation/num paths total       8715
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.740401
evaluation/Rewards Std              1.32025
evaluation/Rewards Max             -0.00302896
evaluation/Rewards Min             -9.44634
evaluation/Returns Mean           -74.0401
evaluation/Returns Std             82.9278
evaluation/Returns Max            -11.4104
evaluation/Returns Min           -277.719
evaluation/Actions Mean             0.012087
evaluation/Actions Std              0.200071
evaluation/Actions Max              0.998096
evaluation/Actions Min             -0.99808
evaluation/Num Paths               15
evaluation/Average Returns        -74.0401
time/data storing (s)               0.00269821
time/evaluation sampling (s)        0.314684
time/exploration sampling (s)       0.139585
time/logging (s)                    0.00481793
time/saving (s)                     0.00191227
time/training (s)                   1.97076
time/epoch (s)                      2.43446
time/total (s)                   1426
Epoch                             580
-----------------------------  ---------------
2019-04-23 01:37:21.621951 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 581 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   13.3205
trainer/QF2 Loss                   13.4078
trainer/Policy Loss                32.9767
trainer/Q1 Predictions Mean       -31.1107
trainer/Q1 Predictions Std         35.0151
trainer/Q1 Predictions Max         -7.18769
trainer/Q1 Predictions Min       -136.228
trainer/Q2 Predictions Mean       -31.135
trainer/Q2 Predictions Std         34.9781
trainer/Q2 Predictions Max         -7.23184
trainer/Q2 Predictions Min       -135.656
trainer/Q Targets Mean            -31.267
trainer/Q Targets Std              35.9419
trainer/Q Targets Max              -0.12342
trainer/Q Targets Min            -138.616
trainer/Log Pis Mean                1.90227
trainer/Log Pis Std                 1.12106
trainer/Log Pis Max                 4.53882
trainer/Log Pis Min                -1.33796
trainer/Policy mu Mean             -0.0334488
trainer/Policy mu Std               0.317674
trainer/Policy mu Max               2.66955
trainer/Policy mu Min              -2.31295
trainer/Policy log std Mean        -2.2974
trainer/Policy log std Std          0.289862
trainer/Policy log std Max         -0.920847
trainer/Policy log std Min         -2.91429
trainer/Alpha                       0.0833672
trainer/Alpha Loss                 -0.242802
exploration/num steps total    291200
exploration/num paths total      2912
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.54732
exploration/Rewards Std             1.44574
exploration/Rewards Max            -0.0163116
exploration/Rewards Min            -8.21457
exploration/Returns Mean         -154.732
exploration/Returns Std           111.737
exploration/Returns Max           -50.362
exploration/Returns Min          -300.355
exploration/Actions Mean           -0.00779589
exploration/Actions Std             0.215388
exploration/Actions Max             0.997498
exploration/Actions Min            -0.99949
exploration/Num Paths               5
exploration/Average Returns      -154.732
evaluation/num steps total     873000
evaluation/num paths total       8730
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.747051
evaluation/Rewards Std              1.18109
evaluation/Rewards Max             -0.0240306
evaluation/Rewards Min            -10.4685
evaluation/Returns Mean           -74.7051
evaluation/Returns Std             69.4127
evaluation/Returns Max            -14.2338
evaluation/Returns Min           -281.709
evaluation/Actions Mean             0.00581777
evaluation/Actions Std              0.193696
evaluation/Actions Max              0.998114
evaluation/Actions Min             -0.998551
evaluation/Num Paths               15
evaluation/Average Returns        -74.7051
time/data storing (s)               0.00281722
time/evaluation sampling (s)        0.321238
time/exploration sampling (s)       0.137767
time/logging (s)                    0.00478923
time/saving (s)                     0.00202872
time/training (s)                   1.95653
time/epoch (s)                      2.42517
time/total (s)                   1428.43
Epoch                             581
-----------------------------  ---------------
2019-04-23 01:37:24.092540 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 582 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.26312
trainer/QF2 Loss                    1.24482
trainer/Policy Loss                37.0171
trainer/Q1 Predictions Mean       -35.0208
trainer/Q1 Predictions Std         34.0882
trainer/Q1 Predictions Max         -7.09796
trainer/Q1 Predictions Min       -133.769
trainer/Q2 Predictions Mean       -35.0436
trainer/Q2 Predictions Std         34.0665
trainer/Q2 Predictions Max         -7.16098
trainer/Q2 Predictions Min       -133.548
trainer/Q Targets Mean            -35.159
trainer/Q Targets Std              34.4898
trainer/Q Targets Max              -0.258385
trainer/Q Targets Min            -133.535
trainer/Log Pis Mean                2.03925
trainer/Log Pis Std                 1.00935
trainer/Log Pis Max                 5.35029
trainer/Log Pis Min                -1.60149
trainer/Policy mu Mean             -0.0377503
trainer/Policy mu Std               0.320751
trainer/Policy mu Max               2.27302
trainer/Policy mu Min              -2.74859
trainer/Policy log std Mean        -2.32013
trainer/Policy log std Std          0.325689
trainer/Policy log std Max         -0.422792
trainer/Policy log std Min         -2.76658
trainer/Alpha                       0.0835554
trainer/Alpha Loss                  0.0974237
exploration/num steps total    291700
exploration/num paths total      2917
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.792226
exploration/Rewards Std             0.977291
exploration/Rewards Max            -0.00477658
exploration/Rewards Min            -9.18618
exploration/Returns Mean          -79.2226
exploration/Returns Std            48.2338
exploration/Returns Max           -17.447
exploration/Returns Min          -132.52
exploration/Actions Mean            0.0119552
exploration/Actions Std             0.180862
exploration/Actions Max             0.999957
exploration/Actions Min            -0.97882
exploration/Num Paths               5
exploration/Average Returns       -79.2226
evaluation/num steps total     874500
evaluation/num paths total       8745
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.452181
evaluation/Rewards Std              1.00782
evaluation/Rewards Max             -0.0241989
evaluation/Rewards Min            -10.7306
evaluation/Returns Mean           -45.2181
evaluation/Returns Std             31.5758
evaluation/Returns Max             -7.89216
evaluation/Returns Min           -125.334
evaluation/Actions Mean            -0.00229987
evaluation/Actions Std              0.181135
evaluation/Actions Max              0.99792
evaluation/Actions Min             -0.995293
evaluation/Num Paths               15
evaluation/Average Returns        -45.2181
time/data storing (s)               0.00273498
time/evaluation sampling (s)        0.327093
time/exploration sampling (s)       0.137983
time/logging (s)                    0.00510896
time/saving (s)                     0.0019691
time/training (s)                   1.9835
time/epoch (s)                      2.45839
time/total (s)                   1430.89
Epoch                             582
-----------------------------  ---------------
2019-04-23 01:37:26.546394 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 583 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.244118
trainer/QF2 Loss                    0.207544
trainer/Policy Loss                34.958
trainer/Q1 Predictions Mean       -32.7942
trainer/Q1 Predictions Std         35.1864
trainer/Q1 Predictions Max         -7.16197
trainer/Q1 Predictions Min       -131.384
trainer/Q2 Predictions Mean       -32.84
trainer/Q2 Predictions Std         35.2316
trainer/Q2 Predictions Max         -7.1531
trainer/Q2 Predictions Min       -131.856
trainer/Q Targets Mean            -32.808
trainer/Q Targets Std              35.2799
trainer/Q Targets Max              -7.14282
trainer/Q Targets Min            -131.972
trainer/Log Pis Mean                2.17409
trainer/Log Pis Std                 1.27123
trainer/Log Pis Max                 5.89293
trainer/Log Pis Min                -3.24523
trainer/Policy mu Mean             -0.00893808
trainer/Policy mu Std               0.545466
trainer/Policy mu Max               2.52901
trainer/Policy mu Min              -2.90179
trainer/Policy log std Mean        -2.30079
trainer/Policy log std Std          0.417137
trainer/Policy log std Max         -0.715967
trainer/Policy log std Min         -2.81987
trainer/Alpha                       0.0822131
trainer/Alpha Loss                  0.434978
exploration/num steps total    292200
exploration/num paths total      2922
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.972759
exploration/Rewards Std             1.2862
exploration/Rewards Max            -0.00945325
exploration/Rewards Min            -7.18383
exploration/Returns Mean          -97.2759
exploration/Returns Std            99.7691
exploration/Returns Max           -39.9711
exploration/Returns Min          -296.022
exploration/Actions Mean           -0.0212941
exploration/Actions Std             0.213311
exploration/Actions Max             0.998992
exploration/Actions Min            -0.998682
exploration/Num Paths               5
exploration/Average Returns       -97.2759
evaluation/num steps total     876000
evaluation/num paths total       8760
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.52783
evaluation/Rewards Std              0.936177
evaluation/Rewards Max             -0.0228785
evaluation/Rewards Min            -10.1197
evaluation/Returns Mean           -52.783
evaluation/Returns Std             47.5148
evaluation/Returns Max             -8.05827
evaluation/Returns Min           -152.043
evaluation/Actions Mean             0.00244196
evaluation/Actions Std              0.171293
evaluation/Actions Max              0.999151
evaluation/Actions Min             -0.995935
evaluation/Num Paths               15
evaluation/Average Returns        -52.783
time/data storing (s)               0.00272429
time/evaluation sampling (s)        0.324547
time/exploration sampling (s)       0.138866
time/logging (s)                    0.00485111
time/saving (s)                     0.00195984
time/training (s)                   1.96735
time/epoch (s)                      2.4403
time/total (s)                   1433.34
Epoch                             583
-----------------------------  ---------------
2019-04-23 01:37:28.990695 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 584 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.877705
trainer/QF2 Loss                    0.860286
trainer/Policy Loss                38.6918
trainer/Q1 Predictions Mean       -36.6149
trainer/Q1 Predictions Std         35.1617
trainer/Q1 Predictions Max         -7.24489
trainer/Q1 Predictions Min       -131.828
trainer/Q2 Predictions Mean       -36.5981
trainer/Q2 Predictions Std         35.1503
trainer/Q2 Predictions Max         -7.20077
trainer/Q2 Predictions Min       -131.73
trainer/Q Targets Mean            -36.6197
trainer/Q Targets Std              35.363
trainer/Q Targets Max              -0.143747
trainer/Q Targets Min            -132.594
trainer/Log Pis Mean                2.19349
trainer/Log Pis Std                 1.32616
trainer/Log Pis Max                 9.27829
trainer/Log Pis Min                -2.7235
trainer/Policy mu Mean             -0.0165205
trainer/Policy mu Std               0.52011
trainer/Policy mu Max               3.45392
trainer/Policy mu Min              -2.29514
trainer/Policy log std Mean        -2.32241
trainer/Policy log std Std          0.434066
trainer/Policy log std Max         -0.366672
trainer/Policy log std Min         -2.90896
trainer/Alpha                       0.0838113
trainer/Alpha Loss                  0.479731
exploration/num steps total    292700
exploration/num paths total      2927
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.13268
exploration/Rewards Std             1.18077
exploration/Rewards Max            -0.0264946
exploration/Rewards Min            -8.56504
exploration/Returns Mean         -113.268
exploration/Returns Std            93.4374
exploration/Returns Max           -25.2598
exploration/Returns Min          -284.179
exploration/Actions Mean            0.00778264
exploration/Actions Std             0.19979
exploration/Actions Max             0.998555
exploration/Actions Min            -0.998495
exploration/Num Paths               5
exploration/Average Returns      -113.268
evaluation/num steps total     877500
evaluation/num paths total       8775
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.465646
evaluation/Rewards Std              1.16793
evaluation/Rewards Max             -0.0219982
evaluation/Rewards Min            -10.2991
evaluation/Returns Mean           -46.5646
evaluation/Returns Std             35.924
evaluation/Returns Max             -6.16
evaluation/Returns Min           -159.314
evaluation/Actions Mean             0.0170876
evaluation/Actions Std              0.184151
evaluation/Actions Max              0.99941
evaluation/Actions Min             -0.997618
evaluation/Num Paths               15
evaluation/Average Returns        -46.5646
time/data storing (s)               0.00276767
time/evaluation sampling (s)        0.322256
time/exploration sampling (s)       0.134016
time/logging (s)                    0.00484391
time/saving (s)                     0.00180286
time/training (s)                   1.96762
time/epoch (s)                      2.43331
time/total (s)                   1435.78
Epoch                             584
-----------------------------  ---------------
2019-04-23 01:37:31.436707 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 585 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.229193
trainer/QF2 Loss                    0.231778
trainer/Policy Loss                37.61
trainer/Q1 Predictions Mean       -35.7076
trainer/Q1 Predictions Std         39.3903
trainer/Q1 Predictions Max         -7.22073
trainer/Q1 Predictions Min       -132.021
trainer/Q2 Predictions Mean       -35.6876
trainer/Q2 Predictions Std         39.3579
trainer/Q2 Predictions Max         -7.21929
trainer/Q2 Predictions Min       -131.74
trainer/Q Targets Mean            -35.9314
trainer/Q Targets Std              39.4882
trainer/Q Targets Max              -7.24309
trainer/Q Targets Min            -132.277
trainer/Log Pis Mean                1.95149
trainer/Log Pis Std                 0.985517
trainer/Log Pis Max                 4.82322
trainer/Log Pis Min                -0.647727
trainer/Policy mu Mean             -0.00303905
trainer/Policy mu Std               0.420885
trainer/Policy mu Max               3.0948
trainer/Policy mu Min              -2.41302
trainer/Policy log std Mean        -2.24833
trainer/Policy log std Std          0.371285
trainer/Policy log std Max         -0.377725
trainer/Policy log std Min         -2.95206
trainer/Alpha                       0.0836403
trainer/Alpha Loss                 -0.120359
exploration/num steps total    293200
exploration/num paths total      2932
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.423927
exploration/Rewards Std             0.926577
exploration/Rewards Max            -0.0126058
exploration/Rewards Min            -8.97329
exploration/Returns Mean          -42.3927
exploration/Returns Std            26.1098
exploration/Returns Max           -18.4232
exploration/Returns Min           -91.1601
exploration/Actions Mean            0.0120379
exploration/Actions Std             0.21993
exploration/Actions Max             0.998843
exploration/Actions Min            -0.996865
exploration/Num Paths               5
exploration/Average Returns       -42.3927
evaluation/num steps total     879000
evaluation/num paths total       8790
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.677563
evaluation/Rewards Std              1.20436
evaluation/Rewards Max             -0.0331107
evaluation/Rewards Min             -9.3842
evaluation/Returns Mean           -67.7563
evaluation/Returns Std             89.6695
evaluation/Returns Max             -8.52151
evaluation/Returns Min           -290.724
evaluation/Actions Mean             0.00867256
evaluation/Actions Std              0.172818
evaluation/Actions Max              0.998973
evaluation/Actions Min             -0.997798
evaluation/Num Paths               15
evaluation/Average Returns        -67.7563
time/data storing (s)               0.00274959
time/evaluation sampling (s)        0.32532
time/exploration sampling (s)       0.137267
time/logging (s)                    0.00477042
time/saving (s)                     0.00154954
time/training (s)                   1.96297
time/epoch (s)                      2.43462
time/total (s)                   1438.21
Epoch                             585
-----------------------------  ---------------
2019-04-23 01:37:33.878957 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 586 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   13.2319
trainer/QF2 Loss                   13.2837
trainer/Policy Loss                28.8361
trainer/Q1 Predictions Mean       -27.1532
trainer/Q1 Predictions Std         33.9496
trainer/Q1 Predictions Max         -7.18177
trainer/Q1 Predictions Min       -133.241
trainer/Q2 Predictions Mean       -27.1665
trainer/Q2 Predictions Std         33.9399
trainer/Q2 Predictions Max         -7.15922
trainer/Q2 Predictions Min       -132.877
trainer/Q Targets Mean            -26.8958
trainer/Q Targets Std              34.1181
trainer/Q Targets Max              -0.803366
trainer/Q Targets Min            -133.695
trainer/Log Pis Mean                1.69545
trainer/Log Pis Std                 1.28698
trainer/Log Pis Max                 3.61208
trainer/Log Pis Min                -2.35383
trainer/Policy mu Mean             -0.00742587
trainer/Policy mu Std               0.282632
trainer/Policy mu Max               1.77881
trainer/Policy mu Min              -2.63411
trainer/Policy log std Mean        -2.28569
trainer/Policy log std Std          0.305841
trainer/Policy log std Max         -0.670094
trainer/Policy log std Min         -2.84358
trainer/Alpha                       0.0840257
trainer/Alpha Loss                 -0.754224
exploration/num steps total    293700
exploration/num paths total      2937
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.440166
exploration/Rewards Std             1.14404
exploration/Rewards Max            -0.00577778
exploration/Rewards Min            -9.07754
exploration/Returns Mean          -44.0166
exploration/Returns Std            10.8123
exploration/Returns Max           -32.8267
exploration/Returns Min           -59.5313
exploration/Actions Mean            0.0117594
exploration/Actions Std             0.230981
exploration/Actions Max             0.998596
exploration/Actions Min            -0.996955
exploration/Num Paths               5
exploration/Average Returns       -44.0166
evaluation/num steps total     880500
evaluation/num paths total       8805
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.720159
evaluation/Rewards Std              1.24104
evaluation/Rewards Max             -0.0433144
evaluation/Rewards Min            -11.6717
evaluation/Returns Mean           -72.0159
evaluation/Returns Std             64.7301
evaluation/Returns Max            -26.0002
evaluation/Returns Min           -296.292
evaluation/Actions Mean            -0.00800214
evaluation/Actions Std              0.202476
evaluation/Actions Max              0.997947
evaluation/Actions Min             -0.99927
evaluation/Num Paths               15
evaluation/Average Returns        -72.0159
time/data storing (s)               0.0026416
time/evaluation sampling (s)        0.319705
time/exploration sampling (s)       0.142988
time/logging (s)                    0.00414049
time/saving (s)                     0.00193907
time/training (s)                   1.95737
time/epoch (s)                      2.42879
time/total (s)                   1440.65
Epoch                             586
-----------------------------  ---------------
2019-04-23 01:37:36.341001 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 587 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.86038
trainer/QF2 Loss                    1.74747
trainer/Policy Loss                35.0774
trainer/Q1 Predictions Mean       -33.1217
trainer/Q1 Predictions Std         35.9749
trainer/Q1 Predictions Max         -7.42172
trainer/Q1 Predictions Min       -156.867
trainer/Q2 Predictions Mean       -33.154
trainer/Q2 Predictions Std         36.0297
trainer/Q2 Predictions Max         -7.38721
trainer/Q2 Predictions Min       -159.905
trainer/Q Targets Mean            -33.254
trainer/Q Targets Std              36.422
trainer/Q Targets Max              -0.0863109
trainer/Q Targets Min            -161.192
trainer/Log Pis Mean                1.94997
trainer/Log Pis Std                 1.29374
trainer/Log Pis Max                 7.2027
trainer/Log Pis Min                -1.5089
trainer/Policy mu Mean             -0.0466405
trainer/Policy mu Std               0.531712
trainer/Policy mu Max               2.82285
trainer/Policy mu Min              -3.04393
trainer/Policy log std Mean        -2.22504
trainer/Policy log std Std          0.41085
trainer/Policy log std Max         -0.0826846
trainer/Policy log std Min         -2.80679
trainer/Alpha                       0.0809248
trainer/Alpha Loss                 -0.125785
exploration/num steps total    294200
exploration/num paths total      2942
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.00108
exploration/Rewards Std             1.14473
exploration/Rewards Max            -0.0188211
exploration/Rewards Min            -7.75807
exploration/Returns Mean         -100.108
exploration/Returns Std            96.0128
exploration/Returns Max           -21.3572
exploration/Returns Min          -287.006
exploration/Actions Mean           -0.020121
exploration/Actions Std             0.16126
exploration/Actions Max             0.74194
exploration/Actions Min            -0.998465
exploration/Num Paths               5
exploration/Average Returns      -100.108
evaluation/num steps total     882000
evaluation/num paths total       8820
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.69125
evaluation/Rewards Std              1.21818
evaluation/Rewards Max             -0.0025647
evaluation/Rewards Min            -10.0168
evaluation/Returns Mean           -69.125
evaluation/Returns Std             71.4454
evaluation/Returns Max             -6.41845
evaluation/Returns Min           -292.16
evaluation/Actions Mean             0.0147402
evaluation/Actions Std              0.200708
evaluation/Actions Max              0.998958
evaluation/Actions Min             -0.996925
evaluation/Num Paths               15
evaluation/Average Returns        -69.125
time/data storing (s)               0.00267577
time/evaluation sampling (s)        0.317555
time/exploration sampling (s)       0.13909
time/logging (s)                    0.00360571
time/saving (s)                     0.00192861
time/training (s)                   1.98424
time/epoch (s)                      2.4491
time/total (s)                   1443.1
Epoch                             587
-----------------------------  ---------------
2019-04-23 01:37:38.763952 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 588 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.1438
trainer/QF2 Loss                    1.16625
trainer/Policy Loss                37.2312
trainer/Q1 Predictions Mean       -35.1507
trainer/Q1 Predictions Std         39.2213
trainer/Q1 Predictions Max         -7.34903
trainer/Q1 Predictions Min       -134.345
trainer/Q2 Predictions Mean       -35.19
trainer/Q2 Predictions Std         39.2416
trainer/Q2 Predictions Max         -7.32145
trainer/Q2 Predictions Min       -134.277
trainer/Q Targets Mean            -34.968
trainer/Q Targets Std              39.2075
trainer/Q Targets Max              -0.224466
trainer/Q Targets Min            -134.049
trainer/Log Pis Mean                2.12179
trainer/Log Pis Std                 1.15586
trainer/Log Pis Max                 6.83288
trainer/Log Pis Min                -1.31759
trainer/Policy mu Mean             -0.0556826
trainer/Policy mu Std               0.465168
trainer/Policy mu Max               2.14685
trainer/Policy mu Min              -2.8645
trainer/Policy log std Mean        -2.25505
trainer/Policy log std Std          0.401232
trainer/Policy log std Max         -0.529984
trainer/Policy log std Min         -2.80622
trainer/Alpha                       0.0821805
trainer/Alpha Loss                  0.304343
exploration/num steps total    294700
exploration/num paths total      2947
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.831545
exploration/Rewards Std             1.09384
exploration/Rewards Max            -0.00746858
exploration/Rewards Min            -5.28509
exploration/Returns Mean          -83.1545
exploration/Returns Std           100.848
exploration/Returns Max           -23.7665
exploration/Returns Min          -284.425
exploration/Actions Mean           -0.00704281
exploration/Actions Std             0.187926
exploration/Actions Max             0.997455
exploration/Actions Min            -0.969202
exploration/Num Paths               5
exploration/Average Returns       -83.1545
evaluation/num steps total     883500
evaluation/num paths total       8835
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.551662
evaluation/Rewards Std              0.945828
evaluation/Rewards Max             -0.010392
evaluation/Rewards Min             -8.1675
evaluation/Returns Mean           -55.1662
evaluation/Returns Std             71.32
evaluation/Returns Max             -2.58377
evaluation/Returns Min           -280.418
evaluation/Actions Mean            -0.00573645
evaluation/Actions Std              0.14818
evaluation/Actions Max              0.998467
evaluation/Actions Min             -0.997614
evaluation/Num Paths               15
evaluation/Average Returns        -55.1662
time/data storing (s)               0.00258109
time/evaluation sampling (s)        0.32236
time/exploration sampling (s)       0.136631
time/logging (s)                    0.00481831
time/saving (s)                     0.00198704
time/training (s)                   1.94372
time/epoch (s)                      2.4121
time/total (s)                   1445.52
Epoch                             588
-----------------------------  ---------------
2019-04-23 01:37:41.199140 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 589 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.25109
trainer/QF2 Loss                    1.31094
trainer/Policy Loss                35.2721
trainer/Q1 Predictions Mean       -33.2923
trainer/Q1 Predictions Std         33.981
trainer/Q1 Predictions Max         -7.45264
trainer/Q1 Predictions Min       -131.22
trainer/Q2 Predictions Mean       -33.2948
trainer/Q2 Predictions Std         33.9533
trainer/Q2 Predictions Max         -7.43749
trainer/Q2 Predictions Min       -131.306
trainer/Q Targets Mean            -33.9977
trainer/Q Targets Std              34.7985
trainer/Q Targets Max              -7.40463
trainer/Q Targets Min            -134.624
trainer/Log Pis Mean                2.05219
trainer/Log Pis Std                 1.18279
trainer/Log Pis Max                 6.32931
trainer/Log Pis Min                -2.36295
trainer/Policy mu Mean             -0.0349206
trainer/Policy mu Std               0.386844
trainer/Policy mu Max               2.20365
trainer/Policy mu Min              -2.51128
trainer/Policy log std Mean        -2.3072
trainer/Policy log std Std          0.339289
trainer/Policy log std Max         -0.795827
trainer/Policy log std Min         -2.89471
trainer/Alpha                       0.0806575
trainer/Alpha Loss                  0.131389
exploration/num steps total    295200
exploration/num paths total      2952
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.971123
exploration/Rewards Std             1.34507
exploration/Rewards Max            -0.0132274
exploration/Rewards Min            -9.01978
exploration/Returns Mean          -97.1123
exploration/Returns Std            92.6737
exploration/Returns Max           -33.3768
exploration/Returns Min          -281.183
exploration/Actions Mean            0.0069086
exploration/Actions Std             0.214439
exploration/Actions Max             0.998747
exploration/Actions Min            -0.999259
exploration/Num Paths               5
exploration/Average Returns       -97.1123
evaluation/num steps total     885000
evaluation/num paths total       8850
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.705298
evaluation/Rewards Std              1.11375
evaluation/Rewards Max             -0.0162456
evaluation/Rewards Min             -9.38044
evaluation/Returns Mean           -70.5298
evaluation/Returns Std             69.147
evaluation/Returns Max             -7.79729
evaluation/Returns Min           -295.387
evaluation/Actions Mean             0.00178441
evaluation/Actions Std              0.171401
evaluation/Actions Max              0.997877
evaluation/Actions Min             -0.99737
evaluation/Num Paths               15
evaluation/Average Returns        -70.5298
time/data storing (s)               0.00266885
time/evaluation sampling (s)        0.321785
time/exploration sampling (s)       0.135364
time/logging (s)                    0.00475466
time/saving (s)                     0.0019635
time/training (s)                   1.95695
time/epoch (s)                      2.42349
time/total (s)                   1447.94
Epoch                             589
-----------------------------  ---------------
2019-04-23 01:37:43.675005 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 590 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                  181.214
trainer/QF2 Loss                  183.015
trainer/Policy Loss                33.3939
trainer/Q1 Predictions Mean       -31.2932
trainer/Q1 Predictions Std         36.2888
trainer/Q1 Predictions Max         -7.46585
trainer/Q1 Predictions Min       -133.053
trainer/Q2 Predictions Mean       -31.3097
trainer/Q2 Predictions Std         36.2723
trainer/Q2 Predictions Max         -7.37228
trainer/Q2 Predictions Min       -133.07
trainer/Q Targets Mean            -29.8137
trainer/Q Targets Std              35.4692
trainer/Q Targets Max              -0.224466
trainer/Q Targets Min            -133.816
trainer/Log Pis Mean                2.15054
trainer/Log Pis Std                 0.902794
trainer/Log Pis Max                 3.59389
trainer/Log Pis Min                -0.874164
trainer/Policy mu Mean             -0.0299091
trainer/Policy mu Std               0.209484
trainer/Policy mu Max               0.598635
trainer/Policy mu Min              -1.53257
trainer/Policy log std Mean        -2.37158
trainer/Policy log std Std          0.264678
trainer/Policy log std Max         -1.14607
trainer/Policy log std Min         -2.94295
trainer/Alpha                       0.0816077
trainer/Alpha Loss                  0.377226
exploration/num steps total    295700
exploration/num paths total      2957
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.38934
exploration/Rewards Std             1.42757
exploration/Rewards Max            -0.0175538
exploration/Rewards Min            -9.61074
exploration/Returns Mean         -138.934
exploration/Returns Std           116.195
exploration/Returns Max           -17.6174
exploration/Returns Min          -281.032
exploration/Actions Mean           -0.00732864
exploration/Actions Std             0.180452
exploration/Actions Max             0.98838
exploration/Actions Min            -0.998711
exploration/Num Paths               5
exploration/Average Returns      -138.934
evaluation/num steps total     886500
evaluation/num paths total       8865
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.669242
evaluation/Rewards Std              1.11983
evaluation/Rewards Max             -0.00755031
evaluation/Rewards Min             -9.22441
evaluation/Returns Mean           -66.9242
evaluation/Returns Std             72.3981
evaluation/Returns Max             -6.92428
evaluation/Returns Min           -292.518
evaluation/Actions Mean             0.00503358
evaluation/Actions Std              0.183527
evaluation/Actions Max              0.99695
evaluation/Actions Min             -0.992422
evaluation/Num Paths               15
evaluation/Average Returns        -66.9242
time/data storing (s)               0.00272833
time/evaluation sampling (s)        0.316018
time/exploration sampling (s)       0.136053
time/logging (s)                    0.00481872
time/saving (s)                     0.001588
time/training (s)                   2.00274
time/epoch (s)                      2.46394
time/total (s)                   1450.41
Epoch                             590
-----------------------------  ---------------
2019-04-23 01:37:46.111433 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 591 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   25.9106
trainer/QF2 Loss                   25.9213
trainer/Policy Loss                32.835
trainer/Q1 Predictions Mean       -31.0042
trainer/Q1 Predictions Std         31.4034
trainer/Q1 Predictions Max         -7.54262
trainer/Q1 Predictions Min       -135.906
trainer/Q2 Predictions Mean       -30.9921
trainer/Q2 Predictions Std         31.3594
trainer/Q2 Predictions Max         -7.55497
trainer/Q2 Predictions Min       -135.553
trainer/Q Targets Mean            -30.688
trainer/Q Targets Std              31.6059
trainer/Q Targets Max              -1.27884
trainer/Q Targets Min            -134.955
trainer/Log Pis Mean                1.86882
trainer/Log Pis Std                 1.29525
trainer/Log Pis Max                 6.98712
trainer/Log Pis Min                -2.29316
trainer/Policy mu Mean             -0.0763548
trainer/Policy mu Std               0.468631
trainer/Policy mu Max               2.15537
trainer/Policy mu Min              -2.75877
trainer/Policy log std Mean        -2.26376
trainer/Policy log std Std          0.392123
trainer/Policy log std Max         -0.637347
trainer/Policy log std Min         -2.89428
trainer/Alpha                       0.0801725
trainer/Alpha Loss                 -0.331021
exploration/num steps total    296200
exploration/num paths total      2962
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.501985
exploration/Rewards Std             1.12287
exploration/Rewards Max            -0.00195456
exploration/Rewards Min           -10.9337
exploration/Returns Mean          -50.1985
exploration/Returns Std            23.3252
exploration/Returns Max           -19.6547
exploration/Returns Min           -83.5677
exploration/Actions Mean           -0.0159973
exploration/Actions Std             0.221514
exploration/Actions Max             0.99845
exploration/Actions Min            -0.998383
exploration/Num Paths               5
exploration/Average Returns       -50.1985
evaluation/num steps total     888000
evaluation/num paths total       8880
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.507988
evaluation/Rewards Std              1.09583
evaluation/Rewards Max             -0.00758412
evaluation/Rewards Min             -9.89183
evaluation/Returns Mean           -50.7988
evaluation/Returns Std             34.3532
evaluation/Returns Max             -2.57731
evaluation/Returns Min           -144.86
evaluation/Actions Mean             0.00979843
evaluation/Actions Std              0.195227
evaluation/Actions Max              0.995144
evaluation/Actions Min             -0.999366
evaluation/Num Paths               15
evaluation/Average Returns        -50.7988
time/data storing (s)               0.0027143
time/evaluation sampling (s)        0.31835
time/exploration sampling (s)       0.139226
time/logging (s)                    0.00359654
time/saving (s)                     0.00156761
time/training (s)                   1.95705
time/epoch (s)                      2.42251
time/total (s)                   1452.84
Epoch                             591
-----------------------------  ---------------
2019-04-23 01:37:48.533800 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 592 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.202609
trainer/QF2 Loss                    0.151487
trainer/Policy Loss                32.3536
trainer/Q1 Predictions Mean       -30.6281
trainer/Q1 Predictions Std         32.3729
trainer/Q1 Predictions Max         -7.49777
trainer/Q1 Predictions Min       -135.036
trainer/Q2 Predictions Mean       -30.6233
trainer/Q2 Predictions Std         32.3426
trainer/Q2 Predictions Max         -7.51079
trainer/Q2 Predictions Min       -134.948
trainer/Q Targets Mean            -30.7072
trainer/Q Targets Std              32.5327
trainer/Q Targets Max              -7.50337
trainer/Q Targets Min            -135.64
trainer/Log Pis Mean                1.81912
trainer/Log Pis Std                 1.07729
trainer/Log Pis Max                 3.54814
trainer/Log Pis Min                -2.37854
trainer/Policy mu Mean             -0.0362217
trainer/Policy mu Std               0.178479
trainer/Policy mu Max               0.473598
trainer/Policy mu Min              -0.890553
trainer/Policy log std Mean        -2.32959
trainer/Policy log std Std          0.220891
trainer/Policy log std Max         -1.85181
trainer/Policy log std Min         -2.81355
trainer/Alpha                       0.0829186
trainer/Alpha Loss                 -0.450365
exploration/num steps total    296700
exploration/num paths total      2967
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.469374
exploration/Rewards Std             1.12489
exploration/Rewards Max            -0.00919972
exploration/Rewards Min           -10.3906
exploration/Returns Mean          -46.9374
exploration/Returns Std            17.5576
exploration/Returns Max           -22.9761
exploration/Returns Min           -69.5189
exploration/Actions Mean           -0.015866
exploration/Actions Std             0.224247
exploration/Actions Max             0.997124
exploration/Actions Min            -0.999141
exploration/Num Paths               5
exploration/Average Returns       -46.9374
evaluation/num steps total     889500
evaluation/num paths total       8895
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.739773
evaluation/Rewards Std              1.21767
evaluation/Rewards Max             -0.00974399
evaluation/Rewards Min            -10.6395
evaluation/Returns Mean           -73.9773
evaluation/Returns Std             70.4098
evaluation/Returns Max            -11.2784
evaluation/Returns Min           -270.278
evaluation/Actions Mean             0.0124433
evaluation/Actions Std              0.182207
evaluation/Actions Max              0.999427
evaluation/Actions Min             -0.99053
evaluation/Num Paths               15
evaluation/Average Returns        -73.9773
time/data storing (s)               0.0025608
time/evaluation sampling (s)        0.321555
time/exploration sampling (s)       0.135083
time/logging (s)                    0.00482333
time/saving (s)                     0.00196046
time/training (s)                   1.945
time/epoch (s)                      2.41099
time/total (s)                   1455.26
Epoch                             592
-----------------------------  ---------------
2019-04-23 01:37:50.997705 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 593 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.167782
trainer/QF2 Loss                    0.168455
trainer/Policy Loss                37.0571
trainer/Q1 Predictions Mean       -34.9465
trainer/Q1 Predictions Std         34.5929
trainer/Q1 Predictions Max         -7.71009
trainer/Q1 Predictions Min       -134.897
trainer/Q2 Predictions Mean       -34.9637
trainer/Q2 Predictions Std         34.5984
trainer/Q2 Predictions Max         -7.70176
trainer/Q2 Predictions Min       -134.86
trainer/Q Targets Mean            -35.1635
trainer/Q Targets Std              34.7473
trainer/Q Targets Max              -7.52213
trainer/Q Targets Min            -135.746
trainer/Log Pis Mean                2.1849
trainer/Log Pis Std                 0.99696
trainer/Log Pis Max                 5.52371
trainer/Log Pis Min                -1.80788
trainer/Policy mu Mean             -0.0369889
trainer/Policy mu Std               0.313941
trainer/Policy mu Max               2.41594
trainer/Policy mu Min              -2.84047
trainer/Policy log std Mean        -2.3926
trainer/Policy log std Std          0.312304
trainer/Policy log std Max         -0.516736
trainer/Policy log std Min         -2.84008
trainer/Alpha                       0.0838321
trainer/Alpha Loss                  0.458382
exploration/num steps total    297200
exploration/num paths total      2972
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.567014
exploration/Rewards Std             1.3528
exploration/Rewards Max            -0.00288296
exploration/Rewards Min            -9.58049
exploration/Returns Mean          -56.7014
exploration/Returns Std            10.2795
exploration/Returns Max           -43.6666
exploration/Returns Min           -71.3276
exploration/Actions Mean            0.0457262
exploration/Actions Std             0.246711
exploration/Actions Max             0.998668
exploration/Actions Min            -0.992708
exploration/Num Paths               5
exploration/Average Returns       -56.7014
evaluation/num steps total     891000
evaluation/num paths total       8910
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.557706
evaluation/Rewards Std              1.15136
evaluation/Rewards Max             -0.00947367
evaluation/Rewards Min            -11.3712
evaluation/Returns Mean           -55.7706
evaluation/Returns Std             75.8729
evaluation/Returns Max             -5.09908
evaluation/Returns Min           -288.36
evaluation/Actions Mean            -0.00174221
evaluation/Actions Std              0.163569
evaluation/Actions Max              0.997318
evaluation/Actions Min             -0.994379
evaluation/Num Paths               15
evaluation/Average Returns        -55.7706
time/data storing (s)               0.00267762
time/evaluation sampling (s)        0.317555
time/exploration sampling (s)       0.140154
time/logging (s)                    0.00479607
time/saving (s)                     0.00192917
time/training (s)                   1.98401
time/epoch (s)                      2.45112
time/total (s)                   1457.71
Epoch                             593
-----------------------------  ---------------
2019-04-23 01:37:53.468586 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 594 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.85502
trainer/QF2 Loss                    0.803521
trainer/Policy Loss                35.7945
trainer/Q1 Predictions Mean       -33.8845
trainer/Q1 Predictions Std         35.8416
trainer/Q1 Predictions Max         -7.44846
trainer/Q1 Predictions Min       -137.676
trainer/Q2 Predictions Mean       -33.9135
trainer/Q2 Predictions Std         35.8622
trainer/Q2 Predictions Max         -7.42423
trainer/Q2 Predictions Min       -136.929
trainer/Q Targets Mean            -34.4476
trainer/Q Targets Std              36.4908
trainer/Q Targets Max              -7.58085
trainer/Q Targets Min            -140.071
trainer/Log Pis Mean                1.97095
trainer/Log Pis Std                 1.20395
trainer/Log Pis Max                 7.02305
trainer/Log Pis Min                -3.3759
trainer/Policy mu Mean             -0.0124844
trainer/Policy mu Std               0.385961
trainer/Policy mu Max               3.69351
trainer/Policy mu Min              -2.43753
trainer/Policy log std Mean        -2.29869
trainer/Policy log std Std          0.324031
trainer/Policy log std Max         -0.44677
trainer/Policy log std Min         -2.93526
trainer/Alpha                       0.0830778
trainer/Alpha Loss                 -0.0722802
exploration/num steps total    297700
exploration/num paths total      2977
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.717618
exploration/Rewards Std             0.915415
exploration/Rewards Max            -0.0104709
exploration/Rewards Min            -9.11049
exploration/Returns Mean          -71.7618
exploration/Returns Std            39.778
exploration/Returns Max           -27.3501
exploration/Returns Min          -146.356
exploration/Actions Mean            0.00892507
exploration/Actions Std             0.195366
exploration/Actions Max             0.98889
exploration/Actions Min            -0.998091
exploration/Num Paths               5
exploration/Average Returns       -71.7618
evaluation/num steps total     892500
evaluation/num paths total       8925
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.414024
evaluation/Rewards Std              0.847513
evaluation/Rewards Max             -0.0147724
evaluation/Rewards Min             -9.64878
evaluation/Returns Mean           -41.4024
evaluation/Returns Std             25.7834
evaluation/Returns Max            -10.0089
evaluation/Returns Min            -85.5367
evaluation/Actions Mean            -0.00311023
evaluation/Actions Std              0.174637
evaluation/Actions Max              0.998211
evaluation/Actions Min             -0.994311
evaluation/Num Paths               15
evaluation/Average Returns        -41.4024
time/data storing (s)               0.00267164
time/evaluation sampling (s)        0.323643
time/exploration sampling (s)       0.137312
time/logging (s)                    0.0036437
time/saving (s)                     0.00190467
time/training (s)                   1.98796
time/epoch (s)                      2.45714
time/total (s)                   1460.17
Epoch                             594
-----------------------------  ---------------
2019-04-23 01:37:55.925106 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 595 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.21347
trainer/QF2 Loss                    1.23561
trainer/Policy Loss                38.1941
trainer/Q1 Predictions Mean       -36.2699
trainer/Q1 Predictions Std         37.0731
trainer/Q1 Predictions Max         -7.46545
trainer/Q1 Predictions Min       -134.795
trainer/Q2 Predictions Mean       -36.2788
trainer/Q2 Predictions Std         37.09
trainer/Q2 Predictions Max         -7.42168
trainer/Q2 Predictions Min       -134.86
trainer/Q Targets Mean            -36.4605
trainer/Q Targets Std              37.3263
trainer/Q Targets Max              -0.135296
trainer/Q Targets Min            -135.473
trainer/Log Pis Mean                1.97495
trainer/Log Pis Std                 1.07919
trainer/Log Pis Max                 4.13076
trainer/Log Pis Min                -1.8345
trainer/Policy mu Mean              0.0077349
trainer/Policy mu Std               0.463388
trainer/Policy mu Max               3.39408
trainer/Policy mu Min              -2.61487
trainer/Policy log std Mean        -2.35164
trainer/Policy log std Std          0.380976
trainer/Policy log std Max         -0.728186
trainer/Policy log std Min         -2.95483
trainer/Alpha                       0.0815282
trainer/Alpha Loss                 -0.062802
exploration/num steps total    298200
exploration/num paths total      2982
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.347051
exploration/Rewards Std             0.664327
exploration/Rewards Max            -0.0125817
exploration/Rewards Min            -8.01624
exploration/Returns Mean          -34.7051
exploration/Returns Std            14.2907
exploration/Returns Max           -15.6803
exploration/Returns Min           -57.278
exploration/Actions Mean            0.0319106
exploration/Actions Std             0.203163
exploration/Actions Max             0.998007
exploration/Actions Min            -0.924195
exploration/Num Paths               5
exploration/Average Returns       -34.7051
evaluation/num steps total     894000
evaluation/num paths total       8940
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.718391
evaluation/Rewards Std              1.17139
evaluation/Rewards Max             -0.00559669
evaluation/Rewards Min            -10.2813
evaluation/Returns Mean           -71.8391
evaluation/Returns Std             70.3048
evaluation/Returns Max             -5.07991
evaluation/Returns Min           -286.059
evaluation/Actions Mean             0.00935038
evaluation/Actions Std              0.191239
evaluation/Actions Max              0.99744
evaluation/Actions Min             -0.996638
evaluation/Num Paths               15
evaluation/Average Returns        -71.8391
time/data storing (s)               0.00260463
time/evaluation sampling (s)        0.318945
time/exploration sampling (s)       0.138962
time/logging (s)                    0.0048262
time/saving (s)                     0.00196064
time/training (s)                   1.97767
time/epoch (s)                      2.44497
time/total (s)                   1462.62
Epoch                             595
-----------------------------  ---------------
2019-04-23 01:37:58.357770 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 596 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                  186.778
trainer/QF2 Loss                  184.373
trainer/Policy Loss                31.6518
trainer/Q1 Predictions Mean       -29.8889
trainer/Q1 Predictions Std         34.8407
trainer/Q1 Predictions Max         -7.50157
trainer/Q1 Predictions Min       -139.479
trainer/Q2 Predictions Mean       -29.8571
trainer/Q2 Predictions Std         34.7879
trainer/Q2 Predictions Max         -7.52041
trainer/Q2 Predictions Min       -138.596
trainer/Q Targets Mean            -28.6845
trainer/Q Targets Std              33.7533
trainer/Q Targets Max              -0.19208
trainer/Q Targets Min            -135.962
trainer/Log Pis Mean                1.82562
trainer/Log Pis Std                 1.26071
trainer/Log Pis Max                 6.55534
trainer/Log Pis Min                -2.88854
trainer/Policy mu Mean             -0.0799767
trainer/Policy mu Std               0.394903
trainer/Policy mu Max               1.79369
trainer/Policy mu Min              -3.17971
trainer/Policy log std Mean        -2.25354
trainer/Policy log std Std          0.345945
trainer/Policy log std Max         -0.670359
trainer/Policy log std Min         -2.79882
trainer/Alpha                       0.0827848
trainer/Alpha Loss                 -0.434487
exploration/num steps total    298700
exploration/num paths total      2987
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.491555
exploration/Rewards Std             0.878813
exploration/Rewards Max            -0.00270793
exploration/Rewards Min            -9.41739
exploration/Returns Mean          -49.1555
exploration/Returns Std            41.5342
exploration/Returns Max           -14.5327
exploration/Returns Min          -122.958
exploration/Actions Mean            0.0128013
exploration/Actions Std             0.170127
exploration/Actions Max             0.999725
exploration/Actions Min            -0.97547
exploration/Num Paths               5
exploration/Average Returns       -49.1555
evaluation/num steps total     895500
evaluation/num paths total       8955
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.540012
evaluation/Rewards Std              1.08208
evaluation/Rewards Max             -0.023819
evaluation/Rewards Min            -10.2736
evaluation/Returns Mean           -54.0012
evaluation/Returns Std             43.505
evaluation/Returns Max             -4.11835
evaluation/Returns Min           -145.623
evaluation/Actions Mean             0.00477611
evaluation/Actions Std              0.186913
evaluation/Actions Max              0.998512
evaluation/Actions Min             -0.997227
evaluation/Num Paths               15
evaluation/Average Returns        -54.0012
time/data storing (s)               0.00272678
time/evaluation sampling (s)        0.321106
time/exploration sampling (s)       0.138766
time/logging (s)                    0.00482543
time/saving (s)                     0.00193649
time/training (s)                   1.9506
time/epoch (s)                      2.41996
time/total (s)                   1465.05
Epoch                             596
-----------------------------  ---------------
2019-04-23 01:38:00.789359 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 597 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.770777
trainer/QF2 Loss                    0.753798
trainer/Policy Loss                32.3907
trainer/Q1 Predictions Mean       -30.5579
trainer/Q1 Predictions Std         32.3962
trainer/Q1 Predictions Max         -7.48936
trainer/Q1 Predictions Min       -146.664
trainer/Q2 Predictions Mean       -30.58
trainer/Q2 Predictions Std         32.3767
trainer/Q2 Predictions Max         -7.51584
trainer/Q2 Predictions Min       -145.707
trainer/Q Targets Mean            -30.5651
trainer/Q Targets Std              32.5761
trainer/Q Targets Max              -0.141285
trainer/Q Targets Min            -146.358
trainer/Log Pis Mean                1.87591
trainer/Log Pis Std                 1.27385
trainer/Log Pis Max                 4.29067
trainer/Log Pis Min                -1.79182
trainer/Policy mu Mean             -0.0595321
trainer/Policy mu Std               0.322444
trainer/Policy mu Max               1.13865
trainer/Policy mu Min              -2.72899
trainer/Policy log std Mean        -2.33123
trainer/Policy log std Std          0.322322
trainer/Policy log std Max         -0.728385
trainer/Policy log std Min         -2.87614
trainer/Alpha                       0.0815893
trainer/Alpha Loss                 -0.31097
exploration/num steps total    299200
exploration/num paths total      2992
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.914806
exploration/Rewards Std             1.43447
exploration/Rewards Max            -0.0138671
exploration/Rewards Min           -10.081
exploration/Returns Mean          -91.4806
exploration/Returns Std           105.589
exploration/Returns Max           -20.3211
exploration/Returns Min          -301.104
exploration/Actions Mean            0.00383153
exploration/Actions Std             0.216052
exploration/Actions Max             0.998712
exploration/Actions Min            -0.993114
exploration/Num Paths               5
exploration/Average Returns       -91.4806
evaluation/num steps total     897000
evaluation/num paths total       8970
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.808918
evaluation/Rewards Std              1.23884
evaluation/Rewards Max             -0.00924879
evaluation/Rewards Min             -9.42565
evaluation/Returns Mean           -80.8918
evaluation/Returns Std             91.6898
evaluation/Returns Max            -14.2811
evaluation/Returns Min           -308.925
evaluation/Actions Mean            -0.00270984
evaluation/Actions Std              0.171263
evaluation/Actions Max              0.995772
evaluation/Actions Min             -0.99714
evaluation/Num Paths               15
evaluation/Average Returns        -80.8918
time/data storing (s)               0.00268309
time/evaluation sampling (s)        0.318459
time/exploration sampling (s)       0.134422
time/logging (s)                    0.00481093
time/saving (s)                     0.00191317
time/training (s)                   1.95663
time/epoch (s)                      2.41891
time/total (s)                   1467.47
Epoch                             597
-----------------------------  ---------------
2019-04-23 01:38:03.260398 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 598 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   50.1801
trainer/QF2 Loss                   50.2221
trainer/Policy Loss                34.4286
trainer/Q1 Predictions Mean       -32.5885
trainer/Q1 Predictions Std         34.6453
trainer/Q1 Predictions Max         -7.39341
trainer/Q1 Predictions Min       -131.793
trainer/Q2 Predictions Mean       -32.5802
trainer/Q2 Predictions Std         34.6412
trainer/Q2 Predictions Max         -7.40189
trainer/Q2 Predictions Min       -131.71
trainer/Q Targets Mean            -32.3234
trainer/Q Targets Std              35.4036
trainer/Q Targets Max              -0.278745
trainer/Q Targets Min            -135.567
trainer/Log Pis Mean                1.90787
trainer/Log Pis Std                 1.33714
trainer/Log Pis Max                 7.72076
trainer/Log Pis Min                -1.83402
trainer/Policy mu Mean              0.0091393
trainer/Policy mu Std               0.445638
trainer/Policy mu Max               2.82935
trainer/Policy mu Min              -2.70862
trainer/Policy log std Mean        -2.2736
trainer/Policy log std Std          0.400048
trainer/Policy log std Max         -0.648892
trainer/Policy log std Min         -2.88257
trainer/Alpha                       0.0821426
trainer/Alpha Loss                 -0.230271
exploration/num steps total    299700
exploration/num paths total      2997
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.797319
exploration/Rewards Std             1.21415
exploration/Rewards Max            -0.00559219
exploration/Rewards Min            -9.75044
exploration/Returns Mean          -79.7319
exploration/Returns Std            38.0924
exploration/Returns Max           -40.9215
exploration/Returns Min          -141.938
exploration/Actions Mean            0.0109384
exploration/Actions Std             0.218876
exploration/Actions Max             0.99955
exploration/Actions Min            -0.998718
exploration/Num Paths               5
exploration/Average Returns       -79.7319
evaluation/num steps total     898500
evaluation/num paths total       8985
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.579861
evaluation/Rewards Std              1.14395
evaluation/Rewards Max             -0.0196787
evaluation/Rewards Min            -10.2535
evaluation/Returns Mean           -57.9861
evaluation/Returns Std             41.1075
evaluation/Returns Max            -10.6111
evaluation/Returns Min           -152.002
evaluation/Actions Mean             0.0206841
evaluation/Actions Std              0.201096
evaluation/Actions Max              0.99937
evaluation/Actions Min             -0.996662
evaluation/Num Paths               15
evaluation/Average Returns        -57.9861
time/data storing (s)               0.00261359
time/evaluation sampling (s)        0.319613
time/exploration sampling (s)       0.135525
time/logging (s)                    0.00413133
time/saving (s)                     0.00191895
time/training (s)                   1.99381
time/epoch (s)                      2.45762
time/total (s)                   1469.93
Epoch                             598
-----------------------------  ---------------
2019-04-23 01:38:05.693895 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 599 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    9.65105
trainer/QF2 Loss                    9.40165
trainer/Policy Loss                34.7125
trainer/Q1 Predictions Mean       -32.8562
trainer/Q1 Predictions Std         34.4818
trainer/Q1 Predictions Max         -7.4575
trainer/Q1 Predictions Min       -138.577
trainer/Q2 Predictions Mean       -32.8799
trainer/Q2 Predictions Std         34.4857
trainer/Q2 Predictions Max         -7.42966
trainer/Q2 Predictions Min       -138.23
trainer/Q Targets Mean            -32.7414
trainer/Q Targets Std              34.7069
trainer/Q Targets Max              -0.852778
trainer/Q Targets Min            -138.722
trainer/Log Pis Mean                1.93955
trainer/Log Pis Std                 1.15198
trainer/Log Pis Max                 3.67207
trainer/Log Pis Min                -2.31005
trainer/Policy mu Mean             -0.0412604
trainer/Policy mu Std               0.240366
trainer/Policy mu Max               0.661802
trainer/Policy mu Min              -1.74146
trainer/Policy log std Mean        -2.35727
trainer/Policy log std Std          0.309196
trainer/Policy log std Max         -0.846651
trainer/Policy log std Min         -2.88775
trainer/Alpha                       0.0839276
trainer/Alpha Loss                 -0.149799
exploration/num steps total    300200
exploration/num paths total      3002
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.481878
exploration/Rewards Std             1.30634
exploration/Rewards Max            -0.00549137
exploration/Rewards Min           -10.5612
exploration/Returns Mean          -48.1878
exploration/Returns Std            21.9151
exploration/Returns Max           -16.4496
exploration/Returns Min           -76.4156
exploration/Actions Mean            0.035695
exploration/Actions Std             0.249653
exploration/Actions Max             0.999947
exploration/Actions Min            -0.996553
exploration/Num Paths               5
exploration/Average Returns       -48.1878
evaluation/num steps total     900000
evaluation/num paths total       9000
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.706426
evaluation/Rewards Std              1.26878
evaluation/Rewards Max             -0.0142111
evaluation/Rewards Min             -9.49576
evaluation/Returns Mean           -70.6426
evaluation/Returns Std             85.5443
evaluation/Returns Max             -7.49587
evaluation/Returns Min           -290.428
evaluation/Actions Mean             0.00553079
evaluation/Actions Std              0.19338
evaluation/Actions Max              0.999499
evaluation/Actions Min             -0.995017
evaluation/Num Paths               15
evaluation/Average Returns        -70.6426
time/data storing (s)               0.00253827
time/evaluation sampling (s)        0.325948
time/exploration sampling (s)       0.136377
time/logging (s)                    0.00477551
time/saving (s)                     0.00194224
time/training (s)                   1.9516
time/epoch (s)                      2.42318
time/total (s)                   1472.36
Epoch                             599
-----------------------------  ---------------
2019-04-23 01:38:08.138512 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 600 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.853831
trainer/QF2 Loss                    0.840418
trainer/Policy Loss                25.2485
trainer/Q1 Predictions Mean       -23.2869
trainer/Q1 Predictions Std         23.756
trainer/Q1 Predictions Max         -7.44508
trainer/Q1 Predictions Min       -134.106
trainer/Q2 Predictions Mean       -23.3055
trainer/Q2 Predictions Std         23.7744
trainer/Q2 Predictions Max         -7.45816
trainer/Q2 Predictions Min       -134.221
trainer/Q Targets Mean            -23.3748
trainer/Q Targets Std              24.0322
trainer/Q Targets Max              -0.153288
trainer/Q Targets Min            -134.77
trainer/Log Pis Mean                1.93237
trainer/Log Pis Std                 1.03795
trainer/Log Pis Max                 5.0464
trainer/Log Pis Min                -1.53152
trainer/Policy mu Mean             -0.0362806
trainer/Policy mu Std               0.488278
trainer/Policy mu Max               2.26257
trainer/Policy mu Min              -2.79
trainer/Policy log std Mean        -2.24039
trainer/Policy log std Std          0.395814
trainer/Policy log std Max         -0.594759
trainer/Policy log std Min         -2.91307
trainer/Alpha                       0.0842944
trainer/Alpha Loss                 -0.167266
exploration/num steps total    300700
exploration/num paths total      3007
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.537791
exploration/Rewards Std             0.812941
exploration/Rewards Max            -0.0163598
exploration/Rewards Min            -8.51082
exploration/Returns Mean          -53.7791
exploration/Returns Std            21.8562
exploration/Returns Max           -28.7756
exploration/Returns Min           -83.9087
exploration/Actions Mean            0.00628531
exploration/Actions Std             0.216278
exploration/Actions Max             0.991881
exploration/Actions Min            -0.997748
exploration/Num Paths               5
exploration/Average Returns       -53.7791
evaluation/num steps total     901500
evaluation/num paths total       9015
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.734966
evaluation/Rewards Std              1.20114
evaluation/Rewards Max             -0.018667
evaluation/Rewards Min            -11.3342
evaluation/Returns Mean           -73.4966
evaluation/Returns Std             64.1982
evaluation/Returns Max             -8.21395
evaluation/Returns Min           -281.671
evaluation/Actions Mean             0.00978378
evaluation/Actions Std              0.193909
evaluation/Actions Max              0.996343
evaluation/Actions Min             -0.995532
evaluation/Num Paths               15
evaluation/Average Returns        -73.4966
time/data storing (s)               0.00260682
time/evaluation sampling (s)        0.31599
time/exploration sampling (s)       0.138171
time/logging (s)                    0.00448151
time/saving (s)                     0.0019281
time/training (s)                   1.96841
time/epoch (s)                      2.43158
time/total (s)                   1474.8
Epoch                             600
-----------------------------  ---------------
2019-04-23 01:38:10.583571 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 601 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   52.4328
trainer/QF2 Loss                   52.4729
trainer/Policy Loss                36.8863
trainer/Q1 Predictions Mean       -34.8996
trainer/Q1 Predictions Std         35.4901
trainer/Q1 Predictions Max         -7.12422
trainer/Q1 Predictions Min       -132.365
trainer/Q2 Predictions Mean       -34.8953
trainer/Q2 Predictions Std         35.4917
trainer/Q2 Predictions Max         -7.13842
trainer/Q2 Predictions Min       -132.356
trainer/Q Targets Mean            -34.2831
trainer/Q Targets Std              36.45
trainer/Q Targets Max              -0.181408
trainer/Q Targets Min            -135.246
trainer/Log Pis Mean                2.09808
trainer/Log Pis Std                 0.969569
trainer/Log Pis Max                 4.92
trainer/Log Pis Min                -1.5131
trainer/Policy mu Mean             -0.0811672
trainer/Policy mu Std               0.397867
trainer/Policy mu Max               0.618238
trainer/Policy mu Min              -2.80551
trainer/Policy log std Mean        -2.31847
trainer/Policy log std Std          0.356066
trainer/Policy log std Max         -0.508741
trainer/Policy log std Min         -2.84253
trainer/Alpha                       0.0836062
trainer/Alpha Loss                  0.243417
exploration/num steps total    301200
exploration/num paths total      3012
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.78569
exploration/Rewards Std             1.11576
exploration/Rewards Max            -0.0052501
exploration/Rewards Min            -6.7221
exploration/Returns Mean          -78.569
exploration/Returns Std           101.696
exploration/Returns Max           -15.3491
exploration/Returns Min          -279.603
exploration/Actions Mean           -0.0139415
exploration/Actions Std             0.172592
exploration/Actions Max             0.891936
exploration/Actions Min            -0.998815
exploration/Num Paths               5
exploration/Average Returns       -78.569
evaluation/num steps total     903000
evaluation/num paths total       9030
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.800019
evaluation/Rewards Std              1.09502
evaluation/Rewards Max             -0.0403733
evaluation/Rewards Min             -8.63497
evaluation/Returns Mean           -80.0019
evaluation/Returns Std             88.4452
evaluation/Returns Max            -13.1914
evaluation/Returns Min           -298.116
evaluation/Actions Mean            -0.00130642
evaluation/Actions Std              0.168011
evaluation/Actions Max              0.996507
evaluation/Actions Min             -0.994168
evaluation/Num Paths               15
evaluation/Average Returns        -80.0019
time/data storing (s)               0.00268371
time/evaluation sampling (s)        0.315933
time/exploration sampling (s)       0.139636
time/logging (s)                    0.0048251
time/saving (s)                     0.00191581
time/training (s)                   1.96868
time/epoch (s)                      2.43367
time/total (s)                   1477.23
Epoch                             601
-----------------------------  ---------------
2019-04-23 01:38:13.063182 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 602 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.36005
trainer/QF2 Loss                    1.26797
trainer/Policy Loss                34.4994
trainer/Q1 Predictions Mean       -32.4476
trainer/Q1 Predictions Std         36.3084
trainer/Q1 Predictions Max         -7.39156
trainer/Q1 Predictions Min       -133.434
trainer/Q2 Predictions Mean       -32.5167
trainer/Q2 Predictions Std         36.3166
trainer/Q2 Predictions Max         -7.4188
trainer/Q2 Predictions Min       -133.417
trainer/Q Targets Mean            -32.9908
trainer/Q Targets Std              36.9515
trainer/Q Targets Max              -0.0554
trainer/Q Targets Min            -135.352
trainer/Log Pis Mean                2.04219
trainer/Log Pis Std                 1.05851
trainer/Log Pis Max                 4.60118
trainer/Log Pis Min                -1.42097
trainer/Policy mu Mean             -0.00910474
trainer/Policy mu Std               0.3816
trainer/Policy mu Max               2.86321
trainer/Policy mu Min              -2.78458
trainer/Policy log std Mean        -2.28839
trainer/Policy log std Std          0.349423
trainer/Policy log std Max         -0.592914
trainer/Policy log std Min         -2.83117
trainer/Alpha                       0.0837033
trainer/Alpha Loss                  0.104645
exploration/num steps total    301700
exploration/num paths total      3017
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.719048
exploration/Rewards Std             0.976203
exploration/Rewards Max            -0.00974785
exploration/Rewards Min           -10.5734
exploration/Returns Mean          -71.9048
exploration/Returns Std            31.901
exploration/Returns Max           -29.4709
exploration/Returns Min          -126.928
exploration/Actions Mean            0.0201882
exploration/Actions Std             0.202974
exploration/Actions Max             0.999603
exploration/Actions Min            -0.961398
exploration/Num Paths               5
exploration/Average Returns       -71.9048
evaluation/num steps total     904500
evaluation/num paths total       9045
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.687316
evaluation/Rewards Std              1.22554
evaluation/Rewards Max             -0.0280424
evaluation/Rewards Min            -10.2431
evaluation/Returns Mean           -68.7316
evaluation/Returns Std             67.8906
evaluation/Returns Max            -10.7168
evaluation/Returns Min           -278.377
evaluation/Actions Mean            -0.00716108
evaluation/Actions Std              0.180802
evaluation/Actions Max              0.99877
evaluation/Actions Min             -0.997704
evaluation/Num Paths               15
evaluation/Average Returns        -68.7316
time/data storing (s)               0.00279501
time/evaluation sampling (s)        0.319231
time/exploration sampling (s)       0.138129
time/logging (s)                    0.00399365
time/saving (s)                     0.0017676
time/training (s)                   2.00032
time/epoch (s)                      2.46624
time/total (s)                   1479.7
Epoch                             602
-----------------------------  ---------------
2019-04-23 01:38:15.500657 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 603 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.223131
trainer/QF2 Loss                    0.177153
trainer/Policy Loss                39.0339
trainer/Q1 Predictions Mean       -37.1604
trainer/Q1 Predictions Std         38.0293
trainer/Q1 Predictions Max         -7.38087
trainer/Q1 Predictions Min       -134.632
trainer/Q2 Predictions Mean       -37.1681
trainer/Q2 Predictions Std         38.0306
trainer/Q2 Predictions Max         -7.38787
trainer/Q2 Predictions Min       -134.787
trainer/Q Targets Mean            -37.3156
trainer/Q Targets Std              38.2814
trainer/Q Targets Max              -7.33623
trainer/Q Targets Min            -136.177
trainer/Log Pis Mean                1.99415
trainer/Log Pis Std                 1.10212
trainer/Log Pis Max                 4.7267
trainer/Log Pis Min                -2.53025
trainer/Policy mu Mean              0.014069
trainer/Policy mu Std               0.441248
trainer/Policy mu Max               3.24833
trainer/Policy mu Min              -1.63542
trainer/Policy log std Mean        -2.28524
trainer/Policy log std Std          0.389601
trainer/Policy log std Max         -0.278982
trainer/Policy log std Min         -2.94355
trainer/Alpha                       0.0831407
trainer/Alpha Loss                 -0.0145404
exploration/num steps total    302200
exploration/num paths total      3022
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.558446
exploration/Rewards Std             0.909593
exploration/Rewards Max            -0.0062425
exploration/Rewards Min            -8.29316
exploration/Returns Mean          -55.8446
exploration/Returns Std            38.7924
exploration/Returns Max           -19.7235
exploration/Returns Min          -129.616
exploration/Actions Mean           -0.000570917
exploration/Actions Std             0.200455
exploration/Actions Max             0.998987
exploration/Actions Min            -0.988432
exploration/Num Paths               5
exploration/Average Returns       -55.8446
evaluation/num steps total     906000
evaluation/num paths total       9060
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.419534
evaluation/Rewards Std              0.884913
evaluation/Rewards Max             -0.0117371
evaluation/Rewards Min             -8.21209
evaluation/Returns Mean           -41.9534
evaluation/Returns Std             20.122
evaluation/Returns Max            -10.5201
evaluation/Returns Min            -86.3113
evaluation/Actions Mean             0.00482382
evaluation/Actions Std              0.171721
evaluation/Actions Max              0.9976
evaluation/Actions Min             -0.997719
evaluation/Num Paths               15
evaluation/Average Returns        -41.9534
time/data storing (s)               0.00259876
time/evaluation sampling (s)        0.312606
time/exploration sampling (s)       0.135253
time/logging (s)                    0.00478445
time/saving (s)                     0.00196299
time/training (s)                   1.96812
time/epoch (s)                      2.42533
time/total (s)                   1482.13
Epoch                             603
-----------------------------  ----------------
2019-04-23 01:38:17.943675 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 604 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   47.372
trainer/QF2 Loss                   47.3262
trainer/Policy Loss                33.4694
trainer/Q1 Predictions Mean       -31.64
trainer/Q1 Predictions Std         34.192
trainer/Q1 Predictions Max         -7.18722
trainer/Q1 Predictions Min       -133.407
trainer/Q2 Predictions Mean       -31.6275
trainer/Q2 Predictions Std         34.2081
trainer/Q2 Predictions Max         -7.2025
trainer/Q2 Predictions Min       -133.393
trainer/Q Targets Mean            -31.2456
trainer/Q Targets Std              34.5473
trainer/Q Targets Max              -1.38583
trainer/Q Targets Min            -135.226
trainer/Log Pis Mean                1.89643
trainer/Log Pis Std                 1.3524
trainer/Log Pis Max                 6.54546
trainer/Log Pis Min                -2.49992
trainer/Policy mu Mean             -0.0407302
trainer/Policy mu Std               0.448031
trainer/Policy mu Max               2.73764
trainer/Policy mu Min              -3.0912
trainer/Policy log std Mean        -2.27136
trainer/Policy log std Std          0.364786
trainer/Policy log std Max         -0.669093
trainer/Policy log std Min         -2.91685
trainer/Alpha                       0.0837572
trainer/Alpha Loss                 -0.256848
exploration/num steps total    302700
exploration/num paths total      3027
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.483623
exploration/Rewards Std             0.843733
exploration/Rewards Max            -0.0119931
exploration/Rewards Min            -8.23401
exploration/Returns Mean          -48.3623
exploration/Returns Std            27.2017
exploration/Returns Max           -15.7222
exploration/Returns Min           -91.7276
exploration/Actions Mean           -0.0220393
exploration/Actions Std             0.208677
exploration/Actions Max             0.985991
exploration/Actions Min            -0.999383
exploration/Num Paths               5
exploration/Average Returns       -48.3623
evaluation/num steps total     907500
evaluation/num paths total       9075
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.594684
evaluation/Rewards Std              1.19322
evaluation/Rewards Max             -0.0141438
evaluation/Rewards Min             -9.72004
evaluation/Returns Mean           -59.4684
evaluation/Returns Std             67.2306
evaluation/Returns Max             -8.89832
evaluation/Returns Min           -268.184
evaluation/Actions Mean             0.0216357
evaluation/Actions Std              0.187453
evaluation/Actions Max              0.997964
evaluation/Actions Min             -0.998928
evaluation/Num Paths               15
evaluation/Average Returns        -59.4684
time/data storing (s)               0.00282782
time/evaluation sampling (s)        0.319762
time/exploration sampling (s)       0.136941
time/logging (s)                    0.00475264
time/saving (s)                     0.00156091
time/training (s)                   1.96435
time/epoch (s)                      2.43019
time/total (s)                   1484.57
Epoch                             604
-----------------------------  ---------------
2019-04-23 01:38:20.405439 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 605 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.81366
trainer/QF2 Loss                    0.742684
trainer/Policy Loss                33.2983
trainer/Q1 Predictions Mean       -31.3268
trainer/Q1 Predictions Std         35.0743
trainer/Q1 Predictions Max         -7.25575
trainer/Q1 Predictions Min       -138.679
trainer/Q2 Predictions Mean       -31.3716
trainer/Q2 Predictions Std         35.1248
trainer/Q2 Predictions Max         -7.24813
trainer/Q2 Predictions Min       -138.482
trainer/Q Targets Mean            -31.4788
trainer/Q Targets Std              35.5255
trainer/Q Targets Max              -0.129674
trainer/Q Targets Min            -139.525
trainer/Log Pis Mean                1.98449
trainer/Log Pis Std                 1.087
trainer/Log Pis Max                 5.87781
trainer/Log Pis Min                -1.41043
trainer/Policy mu Mean             -0.0101498
trainer/Policy mu Std               0.409733
trainer/Policy mu Max               3.35877
trainer/Policy mu Min              -2.14762
trainer/Policy log std Mean        -2.27803
trainer/Policy log std Std          0.322036
trainer/Policy log std Max         -0.84308
trainer/Policy log std Min         -2.78209
trainer/Alpha                       0.0803947
trainer/Alpha Loss                 -0.0391018
exploration/num steps total    303200
exploration/num paths total      3032
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.915617
exploration/Rewards Std             1.3089
exploration/Rewards Max            -0.0197684
exploration/Rewards Min            -8.38729
exploration/Returns Mean          -91.5617
exploration/Returns Std           110.483
exploration/Returns Max           -26.0059
exploration/Returns Min          -312.05
exploration/Actions Mean           -0.0174845
exploration/Actions Std             0.183315
exploration/Actions Max             0.981803
exploration/Actions Min            -0.997134
exploration/Num Paths               5
exploration/Average Returns       -91.5617
evaluation/num steps total     909000
evaluation/num paths total       9090
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.692123
evaluation/Rewards Std              1.20032
evaluation/Rewards Max             -0.0100944
evaluation/Rewards Min             -8.80115
evaluation/Returns Mean           -69.2123
evaluation/Returns Std             92.3618
evaluation/Returns Max            -10.0163
evaluation/Returns Min           -304.678
evaluation/Actions Mean            -0.00896352
evaluation/Actions Std              0.176528
evaluation/Actions Max              0.998517
evaluation/Actions Min             -0.995732
evaluation/Num Paths               15
evaluation/Average Returns        -69.2123
time/data storing (s)               0.00274964
time/evaluation sampling (s)        0.315209
time/exploration sampling (s)       0.135831
time/logging (s)                    0.00481867
time/saving (s)                     0.00192976
time/training (s)                   1.98851
time/epoch (s)                      2.44905
time/total (s)                   1487.02
Epoch                             605
-----------------------------  ---------------
2019-04-23 01:38:22.873061 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 606 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                  167.398
trainer/QF2 Loss                  167.606
trainer/Policy Loss                26.6262
trainer/Q1 Predictions Mean       -24.8063
trainer/Q1 Predictions Std         25.1231
trainer/Q1 Predictions Max         -7.22584
trainer/Q1 Predictions Min       -132.814
trainer/Q2 Predictions Mean       -24.801
trainer/Q2 Predictions Std         25.0994
trainer/Q2 Predictions Max         -7.20476
trainer/Q2 Predictions Min       -132.483
trainer/Q Targets Mean            -23.8827
trainer/Q Targets Std              23.1188
trainer/Q Targets Max              -2.7889
trainer/Q Targets Min            -134.123
trainer/Log Pis Mean                1.85031
trainer/Log Pis Std                 1.01017
trainer/Log Pis Max                 4.82641
trainer/Log Pis Min                -2.15533
trainer/Policy mu Mean              0.0245929
trainer/Policy mu Std               0.340166
trainer/Policy mu Max               2.35076
trainer/Policy mu Min              -2.12987
trainer/Policy log std Mean        -2.25999
trainer/Policy log std Std          0.306456
trainer/Policy log std Max         -0.679139
trainer/Policy log std Min         -2.9212
trainer/Alpha                       0.0777952
trainer/Alpha Loss                 -0.382271
exploration/num steps total    303700
exploration/num paths total      3037
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.419251
exploration/Rewards Std             0.947952
exploration/Rewards Max            -0.00770598
exploration/Rewards Min            -9.80999
exploration/Returns Mean          -41.9251
exploration/Returns Std            20.145
exploration/Returns Max           -16.7795
exploration/Returns Min           -69.8116
exploration/Actions Mean           -0.00436006
exploration/Actions Std             0.215627
exploration/Actions Max             0.995358
exploration/Actions Min            -0.999347
exploration/Num Paths               5
exploration/Average Returns       -41.9251
evaluation/num steps total     910500
evaluation/num paths total       9105
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.839001
evaluation/Rewards Std              1.1714
evaluation/Rewards Max             -0.0102293
evaluation/Rewards Min            -10.4157
evaluation/Returns Mean           -83.9001
evaluation/Returns Std             73.4845
evaluation/Returns Max             -5.76748
evaluation/Returns Min           -301.354
evaluation/Actions Mean             0.00119823
evaluation/Actions Std              0.186756
evaluation/Actions Max              0.998902
evaluation/Actions Min             -0.998086
evaluation/Num Paths               15
evaluation/Average Returns        -83.9001
time/data storing (s)               0.00257579
time/evaluation sampling (s)        0.319086
time/exploration sampling (s)       0.135525
time/logging (s)                    0.00480583
time/saving (s)                     0.00191579
time/training (s)                   1.99079
time/epoch (s)                      2.4547
time/total (s)                   1489.48
Epoch                             606
-----------------------------  ---------------
2019-04-23 01:38:25.326112 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 607 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                   15.2826
trainer/QF2 Loss                   15.3361
trainer/Policy Loss                37.7161
trainer/Q1 Predictions Mean       -35.673
trainer/Q1 Predictions Std         35.2433
trainer/Q1 Predictions Max         -7.38432
trainer/Q1 Predictions Min       -135.257
trainer/Q2 Predictions Mean       -35.6777
trainer/Q2 Predictions Std         35.2455
trainer/Q2 Predictions Max         -7.43977
trainer/Q2 Predictions Min       -135.091
trainer/Q Targets Mean            -35.4623
trainer/Q Targets Std              35.6363
trainer/Q Targets Max              -0.837368
trainer/Q Targets Min            -136.134
trainer/Log Pis Mean                2.17323
trainer/Log Pis Std                 0.908503
trainer/Log Pis Max                 3.99887
trainer/Log Pis Min                -0.332386
trainer/Policy mu Mean             -0.0504142
trainer/Policy mu Std               0.203147
trainer/Policy mu Max               1.43842
trainer/Policy mu Min              -0.753532
trainer/Policy log std Mean        -2.39998
trainer/Policy log std Std          0.294031
trainer/Policy log std Max         -1.21195
trainer/Policy log std Min         -2.98636
trainer/Alpha                       0.0787186
trainer/Alpha Loss                  0.44034
exploration/num steps total    304200
exploration/num paths total      3042
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.5423
exploration/Rewards Std             1.19161
exploration/Rewards Max            -0.000519368
exploration/Rewards Min            -9.49969
exploration/Returns Mean          -54.23
exploration/Returns Std            24.5373
exploration/Returns Max           -31.1095
exploration/Returns Min           -99.7923
exploration/Actions Mean            0.0036794
exploration/Actions Std             0.249495
exploration/Actions Max             0.998997
exploration/Actions Min            -0.997103
exploration/Num Paths               5
exploration/Average Returns       -54.23
evaluation/num steps total     912000
evaluation/num paths total       9120
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.593185
evaluation/Rewards Std              1.19218
evaluation/Rewards Max             -0.0321188
evaluation/Rewards Min            -10.4321
evaluation/Returns Mean           -59.3185
evaluation/Returns Std             69.7621
evaluation/Returns Max             -9.40997
evaluation/Returns Min           -309.769
evaluation/Actions Mean            -0.00535837
evaluation/Actions Std              0.181868
evaluation/Actions Max              0.995461
evaluation/Actions Min             -0.999593
evaluation/Num Paths               15
evaluation/Average Returns        -59.3185
time/data storing (s)               0.00259014
time/evaluation sampling (s)        0.320904
time/exploration sampling (s)       0.138884
time/logging (s)                    0.00503666
time/saving (s)                     0.00196006
time/training (s)                   1.97103
time/epoch (s)                      2.44041
time/total (s)                   1491.93
Epoch                             607
-----------------------------  ----------------
2019-04-23 01:38:27.787420 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 608 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.221723
trainer/QF2 Loss                    0.189409
trainer/Policy Loss                36.4882
trainer/Q1 Predictions Mean       -34.482
trainer/Q1 Predictions Std         32.9407
trainer/Q1 Predictions Max         -7.12655
trainer/Q1 Predictions Min       -143.357
trainer/Q2 Predictions Mean       -34.4839
trainer/Q2 Predictions Std         32.9555
trainer/Q2 Predictions Max         -7.14895
trainer/Q2 Predictions Min       -143.35
trainer/Q Targets Mean            -34.6619
trainer/Q Targets Std              33.1092
trainer/Q Targets Max              -7.26957
trainer/Q Targets Min            -143.473
trainer/Log Pis Mean                2.10702
trainer/Log Pis Std                 0.985479
trainer/Log Pis Max                 4.26492
trainer/Log Pis Min                -0.921088
trainer/Policy mu Mean             -0.0664984
trainer/Policy mu Std               0.367993
trainer/Policy mu Max               2.85626
trainer/Policy mu Min              -2.82592
trainer/Policy log std Mean        -2.34751
trainer/Policy log std Std          0.338717
trainer/Policy log std Max         -0.190615
trainer/Policy log std Min         -2.97776
trainer/Alpha                       0.0825102
trainer/Alpha Loss                  0.267002
exploration/num steps total    304700
exploration/num paths total      3047
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.375161
exploration/Rewards Std             0.691896
exploration/Rewards Max            -0.0164519
exploration/Rewards Min            -7.1467
exploration/Returns Mean          -37.5161
exploration/Returns Std            10.918
exploration/Returns Max           -20.803
exploration/Returns Min           -50.6056
exploration/Actions Mean           -0.00809009
exploration/Actions Std             0.203395
exploration/Actions Max             0.995904
exploration/Actions Min            -0.997065
exploration/Num Paths               5
exploration/Average Returns       -37.5161
evaluation/num steps total     913500
evaluation/num paths total       9135
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.332014
evaluation/Rewards Std              0.98625
evaluation/Rewards Max             -0.0189534
evaluation/Rewards Min            -10.3518
evaluation/Returns Mean           -33.2014
evaluation/Returns Std             16.9947
evaluation/Returns Max            -13.0925
evaluation/Returns Min            -73.9374
evaluation/Actions Mean             0.00432861
evaluation/Actions Std              0.19207
evaluation/Actions Max              0.998358
evaluation/Actions Min             -0.996018
evaluation/Num Paths               15
evaluation/Average Returns        -33.2014
time/data storing (s)               0.00265188
time/evaluation sampling (s)        0.31855
time/exploration sampling (s)       0.133797
time/logging (s)                    0.00478216
time/saving (s)                     0.00193227
time/training (s)                   1.98644
time/epoch (s)                      2.44816
time/total (s)                   1494.38
Epoch                             608
-----------------------------  ---------------
2019-04-23 01:38:30.255374 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 609 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.228875
trainer/QF2 Loss                    0.242705
trainer/Policy Loss                35.4677
trainer/Q1 Predictions Mean       -33.3661
trainer/Q1 Predictions Std         34.1786
trainer/Q1 Predictions Max         -7.33886
trainer/Q1 Predictions Min       -133.131
trainer/Q2 Predictions Mean       -33.3614
trainer/Q2 Predictions Std         34.1561
trainer/Q2 Predictions Max         -7.31654
trainer/Q2 Predictions Min       -132.976
trainer/Q Targets Mean            -33.606
trainer/Q Targets Std              34.4428
trainer/Q Targets Max              -7.27085
trainer/Q Targets Min            -134.369
trainer/Log Pis Mean                2.1351
trainer/Log Pis Std                 0.915305
trainer/Log Pis Max                 4.73105
trainer/Log Pis Min                -0.205856
trainer/Policy mu Mean             -0.0541592
trainer/Policy mu Std               0.449447
trainer/Policy mu Max               2.31029
trainer/Policy mu Min              -2.84236
trainer/Policy log std Mean        -2.27793
trainer/Policy log std Std          0.382071
trainer/Policy log std Max         -0.421903
trainer/Policy log std Min         -2.8115
trainer/Alpha                       0.0857789
trainer/Alpha Loss                  0.331813
exploration/num steps total    305200
exploration/num paths total      3052
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.915675
exploration/Rewards Std             1.16576
exploration/Rewards Max            -0.0111744
exploration/Rewards Min            -7.09272
exploration/Returns Mean          -91.5675
exploration/Returns Std            94.0484
exploration/Returns Max           -19.6266
exploration/Returns Min          -276.683
exploration/Actions Mean           -0.0288413
exploration/Actions Std             0.196981
exploration/Actions Max             0.826738
exploration/Actions Min            -0.999041
exploration/Num Paths               5
exploration/Average Returns       -91.5675
evaluation/num steps total     915000
evaluation/num paths total       9150
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.324395
evaluation/Rewards Std              0.810215
evaluation/Rewards Max             -0.00532709
evaluation/Rewards Min             -8.69398
evaluation/Returns Mean           -32.4395
evaluation/Returns Std             21.9361
evaluation/Returns Max            -10.5432
evaluation/Returns Min            -88.7563
evaluation/Actions Mean            -0.00390397
evaluation/Actions Std              0.166171
evaluation/Actions Max              0.997806
evaluation/Actions Min             -0.997555
evaluation/Num Paths               15
evaluation/Average Returns        -32.4395
time/data storing (s)               0.00275791
time/evaluation sampling (s)        0.318307
time/exploration sampling (s)       0.139481
time/logging (s)                    0.00481068
time/saving (s)                     0.00154474
time/training (s)                   1.98828
time/epoch (s)                      2.45518
time/total (s)                   1496.84
Epoch                             609
-----------------------------  ---------------
2019-04-23 01:38:32.733215 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 610 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.193459
trainer/QF2 Loss                    0.208648
trainer/Policy Loss                37.5116
trainer/Q1 Predictions Mean       -35.6807
trainer/Q1 Predictions Std         37.8081
trainer/Q1 Predictions Max         -7.32463
trainer/Q1 Predictions Min       -133.324
trainer/Q2 Predictions Mean       -35.6911
trainer/Q2 Predictions Std         37.7773
trainer/Q2 Predictions Max         -7.29451
trainer/Q2 Predictions Min       -132.881
trainer/Q Targets Mean            -35.9268
trainer/Q Targets Std              38.0849
trainer/Q Targets Max              -7.42966
trainer/Q Targets Min            -134.079
trainer/Log Pis Mean                1.89055
trainer/Log Pis Std                 1.17575
trainer/Log Pis Max                 3.73111
trainer/Log Pis Min                -1.67664
trainer/Policy mu Mean             -0.0542748
trainer/Policy mu Std               0.33866
trainer/Policy mu Max               2.01606
trainer/Policy mu Min              -2.37585
trainer/Policy log std Mean        -2.31957
trainer/Policy log std Std          0.320365
trainer/Policy log std Max         -0.739833
trainer/Policy log std Min         -2.85781
trainer/Alpha                       0.0860798
trainer/Alpha Loss                 -0.268425
exploration/num steps total    305700
exploration/num paths total      3057
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.368439
exploration/Rewards Std             0.887205
exploration/Rewards Max            -0.0127473
exploration/Rewards Min            -8.52332
exploration/Returns Mean          -36.8439
exploration/Returns Std            11.3904
exploration/Returns Max           -27.6756
exploration/Returns Min           -56.9949
exploration/Actions Mean            0.00825503
exploration/Actions Std             0.218909
exploration/Actions Max             0.996811
exploration/Actions Min            -0.997631
exploration/Num Paths               5
exploration/Average Returns       -36.8439
evaluation/num steps total     916500
evaluation/num paths total       9165
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.738256
evaluation/Rewards Std              1.41232
evaluation/Rewards Max             -0.00242123
evaluation/Rewards Min            -10.2162
evaluation/Returns Mean           -73.8256
evaluation/Returns Std             85.5009
evaluation/Returns Max             -7.36443
evaluation/Returns Min           -292.638
evaluation/Actions Mean             0.00232181
evaluation/Actions Std              0.201613
evaluation/Actions Max              0.998672
evaluation/Actions Min             -0.998894
evaluation/Num Paths               15
evaluation/Average Returns        -73.8256
time/data storing (s)               0.00275275
time/evaluation sampling (s)        0.319504
time/exploration sampling (s)       0.136074
time/logging (s)                    0.00486108
time/saving (s)                     0.00194228
time/training (s)                   2.00071
time/epoch (s)                      2.46584
time/total (s)                   1499.31
Epoch                             610
-----------------------------  ---------------
2019-04-23 01:38:35.186550 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 611 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.25991
trainer/QF2 Loss                    1.24883
trainer/Policy Loss                31.3351
trainer/Q1 Predictions Mean       -29.5016
trainer/Q1 Predictions Std         30.5773
trainer/Q1 Predictions Max         -7.22382
trainer/Q1 Predictions Min       -132.663
trainer/Q2 Predictions Mean       -29.5188
trainer/Q2 Predictions Std         30.5716
trainer/Q2 Predictions Max         -7.23948
trainer/Q2 Predictions Min       -132.599
trainer/Q Targets Mean            -29.9202
trainer/Q Targets Std              31.1428
trainer/Q Targets Max              -0.120853
trainer/Q Targets Min            -134.767
trainer/Log Pis Mean                1.87258
trainer/Log Pis Std                 1.28292
trainer/Log Pis Max                 3.65215
trainer/Log Pis Min                -2.83546
trainer/Policy mu Mean              0.00703086
trainer/Policy mu Std               0.349446
trainer/Policy mu Max               2.2743
trainer/Policy mu Min              -2.74771
trainer/Policy log std Mean        -2.29929
trainer/Policy log std Std          0.331116
trainer/Policy log std Max         -0.566886
trainer/Policy log std Min         -2.87777
trainer/Alpha                       0.0854823
trainer/Alpha Loss                 -0.313374
exploration/num steps total    306200
exploration/num paths total      3062
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.392192
exploration/Rewards Std             0.526395
exploration/Rewards Max            -0.00965715
exploration/Rewards Min            -5.40878
exploration/Returns Mean          -39.2192
exploration/Returns Std            20.7448
exploration/Returns Max           -17.9742
exploration/Returns Min           -65.7146
exploration/Actions Mean           -0.0091509
exploration/Actions Std             0.181146
exploration/Actions Max             0.998544
exploration/Actions Min            -0.993453
exploration/Num Paths               5
exploration/Average Returns       -39.2192
evaluation/num steps total     918000
evaluation/num paths total       9180
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.457693
evaluation/Rewards Std              0.97551
evaluation/Rewards Max             -0.00952761
evaluation/Rewards Min             -9.21201
evaluation/Returns Mean           -45.7693
evaluation/Returns Std             43.8466
evaluation/Returns Max             -8.9272
evaluation/Returns Min           -157.491
evaluation/Actions Mean             0.00481809
evaluation/Actions Std              0.173253
evaluation/Actions Max              0.996349
evaluation/Actions Min             -0.997852
evaluation/Num Paths               15
evaluation/Average Returns        -45.7693
time/data storing (s)               0.00281412
time/evaluation sampling (s)        0.318274
time/exploration sampling (s)       0.136474
time/logging (s)                    0.00480143
time/saving (s)                     0.00194176
time/training (s)                   1.97596
time/epoch (s)                      2.44027
time/total (s)                   1501.75
Epoch                             611
-----------------------------  ---------------
2019-04-23 01:38:37.642231 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 612 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.366896
trainer/QF2 Loss                    0.368499
trainer/Policy Loss                31.6153
trainer/Q1 Predictions Mean       -30.1472
trainer/Q1 Predictions Std         31.3852
trainer/Q1 Predictions Max         -7.29741
trainer/Q1 Predictions Min       -141.275
trainer/Q2 Predictions Mean       -30.1118
trainer/Q2 Predictions Std         31.3661
trainer/Q2 Predictions Max         -7.17415
trainer/Q2 Predictions Min       -140.55
trainer/Q Targets Mean            -30.5048
trainer/Q Targets Std              31.6933
trainer/Q Targets Max              -7.31093
trainer/Q Targets Min            -140.775
trainer/Log Pis Mean                1.53553
trainer/Log Pis Std                 1.46247
trainer/Log Pis Max                 4.37863
trainer/Log Pis Min                -5.57083
trainer/Policy mu Mean             -0.0614384
trainer/Policy mu Std               0.371949
trainer/Policy mu Max               0.538036
trainer/Policy mu Min              -2.23441
trainer/Policy log std Mean        -2.22109
trainer/Policy log std Std          0.363473
trainer/Policy log std Max         -0.601369
trainer/Policy log std Min         -2.82474
trainer/Alpha                       0.0839
trainer/Alpha Loss                 -1.15091
exploration/num steps total    306700
exploration/num paths total      3067
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.421986
exploration/Rewards Std             0.75711
exploration/Rewards Max            -0.0199682
exploration/Rewards Min            -6.23884
exploration/Returns Mean          -42.1986
exploration/Returns Std            19.2074
exploration/Returns Max           -25.7909
exploration/Returns Min           -78.1955
exploration/Actions Mean           -0.00459
exploration/Actions Std             0.223346
exploration/Actions Max             0.9991
exploration/Actions Min            -0.999027
exploration/Num Paths               5
exploration/Average Returns       -42.1986
evaluation/num steps total     919500
evaluation/num paths total       9195
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.599658
evaluation/Rewards Std              1.15131
evaluation/Rewards Max             -0.0106411
evaluation/Rewards Min             -9.97915
evaluation/Returns Mean           -59.9658
evaluation/Returns Std             61.1485
evaluation/Returns Max             -4.47794
evaluation/Returns Min           -250.761
evaluation/Actions Mean            -0.00215125
evaluation/Actions Std              0.183782
evaluation/Actions Max              0.997084
evaluation/Actions Min             -0.996027
evaluation/Num Paths               15
evaluation/Average Returns        -59.9658
time/data storing (s)               0.00266275
time/evaluation sampling (s)        0.323717
time/exploration sampling (s)       0.133687
time/logging (s)                    0.00479077
time/saving (s)                     0.00190182
time/training (s)                   1.97704
time/epoch (s)                      2.4438
time/total (s)                   1504.2
Epoch                             612
-----------------------------  ---------------
2019-04-23 01:38:40.087566 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 613 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                  215.502
trainer/QF2 Loss                  215.296
trainer/Policy Loss                32.5395
trainer/Q1 Predictions Mean       -30.8548
trainer/Q1 Predictions Std         35.2698
trainer/Q1 Predictions Max         -7.3871
trainer/Q1 Predictions Min       -142.704
trainer/Q2 Predictions Mean       -30.8206
trainer/Q2 Predictions Std         35.2449
trainer/Q2 Predictions Max         -7.45559
trainer/Q2 Predictions Min       -141.543
trainer/Q Targets Mean            -29.0881
trainer/Q Targets Std              34.3166
trainer/Q Targets Max              -0.643534
trainer/Q Targets Min            -141.832
trainer/Log Pis Mean                1.78939
trainer/Log Pis Std                 1.21719
trainer/Log Pis Max                 3.74778
trainer/Log Pis Min                -2.41925
trainer/Policy mu Mean             -0.0417352
trainer/Policy mu Std               0.391444
trainer/Policy mu Max               2.137
trainer/Policy mu Min              -2.8053
trainer/Policy log std Mean        -2.27636
trainer/Policy log std Std          0.35637
trainer/Policy log std Max         -0.351406
trainer/Policy log std Min         -2.82561
trainer/Alpha                       0.0861041
trainer/Alpha Loss                 -0.516458
exploration/num steps total    307200
exploration/num paths total      3072
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.293687
exploration/Rewards Std             0.893836
exploration/Rewards Max            -0.00712325
exploration/Rewards Min            -9.80221
exploration/Returns Mean          -29.3687
exploration/Returns Std            17.4506
exploration/Returns Max           -14.435
exploration/Returns Min           -60.0685
exploration/Actions Mean           -0.0185216
exploration/Actions Std             0.192582
exploration/Actions Max             0.999333
exploration/Actions Min            -0.999207
exploration/Num Paths               5
exploration/Average Returns       -29.3687
evaluation/num steps total     921000
evaluation/num paths total       9210
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.99767
evaluation/Rewards Std              1.35586
evaluation/Rewards Max             -0.0110018
evaluation/Rewards Min            -10.4817
evaluation/Returns Mean           -99.767
evaluation/Returns Std            101.572
evaluation/Returns Max             -5.16927
evaluation/Returns Min           -303.07
evaluation/Actions Mean             0.00652107
evaluation/Actions Std              0.195107
evaluation/Actions Max              0.996899
evaluation/Actions Min             -0.997671
evaluation/Num Paths               15
evaluation/Average Returns        -99.767
time/data storing (s)               0.00279966
time/evaluation sampling (s)        0.317509
time/exploration sampling (s)       0.140645
time/logging (s)                    0.00477998
time/saving (s)                     0.00192859
time/training (s)                   1.96472
time/epoch (s)                      2.43238
time/total (s)                   1506.64
Epoch                             613
-----------------------------  ---------------
2019-04-23 01:38:42.580998 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 614 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.482372
trainer/QF2 Loss                    0.495032
trainer/Policy Loss                33.0608
trainer/Q1 Predictions Mean       -31.1202
trainer/Q1 Predictions Std         35.711
trainer/Q1 Predictions Max         -7.34504
trainer/Q1 Predictions Min       -132.137
trainer/Q2 Predictions Mean       -31.1276
trainer/Q2 Predictions Std         35.6949
trainer/Q2 Predictions Max         -7.38468
trainer/Q2 Predictions Min       -132.03
trainer/Q Targets Mean            -31.5092
trainer/Q Targets Std              36.1521
trainer/Q Targets Max              -7.49671
trainer/Q Targets Min            -134.041
trainer/Log Pis Mean                1.95043
trainer/Log Pis Std                 1.15
trainer/Log Pis Max                 5.16715
trainer/Log Pis Min                -1.9997
trainer/Policy mu Mean             -0.0391336
trainer/Policy mu Std               0.389222
trainer/Policy mu Max               2.54174
trainer/Policy mu Min              -2.79161
trainer/Policy log std Mean        -2.27125
trainer/Policy log std Std          0.341503
trainer/Policy log std Max         -0.43702
trainer/Policy log std Min         -2.79614
trainer/Alpha                       0.0845445
trainer/Alpha Loss                 -0.122455
exploration/num steps total    307700
exploration/num paths total      3077
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.484336
exploration/Rewards Std             1.16499
exploration/Rewards Max            -0.00861005
exploration/Rewards Min            -9.4893
exploration/Returns Mean          -48.4336
exploration/Returns Std            25.7095
exploration/Returns Max           -20.2887
exploration/Returns Min           -89.5853
exploration/Actions Mean            0.0251852
exploration/Actions Std             0.226869
exploration/Actions Max             0.998393
exploration/Actions Min            -0.999079
exploration/Num Paths               5
exploration/Average Returns       -48.4336
evaluation/num steps total     922500
evaluation/num paths total       9225
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.03474
evaluation/Rewards Std              1.26489
evaluation/Rewards Max             -0.0113859
evaluation/Rewards Min            -10.0068
evaluation/Returns Mean          -103.474
evaluation/Returns Std            104.758
evaluation/Returns Max             -3.47476
evaluation/Returns Min           -303.945
evaluation/Actions Mean            -0.0131323
evaluation/Actions Std              0.166959
evaluation/Actions Max              0.998841
evaluation/Actions Min             -0.994669
evaluation/Num Paths               15
evaluation/Average Returns       -103.474
time/data storing (s)               0.00283798
time/evaluation sampling (s)        0.319181
time/exploration sampling (s)       0.133949
time/logging (s)                    0.00476244
time/saving (s)                     0.0104032
time/training (s)                   2.00913
time/epoch (s)                      2.48026
time/total (s)                   1509.12
Epoch                             614
-----------------------------  ---------------
2019-04-23 01:38:44.999793 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 615 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.75678
trainer/QF2 Loss                    1.82157
trainer/Policy Loss                33.5264
trainer/Q1 Predictions Mean       -31.464
trainer/Q1 Predictions Std         35.6687
trainer/Q1 Predictions Max         -7.10299
trainer/Q1 Predictions Min       -133.613
trainer/Q2 Predictions Mean       -31.431
trainer/Q2 Predictions Std         35.6326
trainer/Q2 Predictions Max         -7.07981
trainer/Q2 Predictions Min       -132.74
trainer/Q Targets Mean            -32.1178
trainer/Q Targets Std              36.462
trainer/Q Targets Max              -0.0554
trainer/Q Targets Min            -135.386
trainer/Log Pis Mean                2.12601
trainer/Log Pis Std                 1.20462
trainer/Log Pis Max                 7.91299
trainer/Log Pis Min                -2.88906
trainer/Policy mu Mean              0.0159578
trainer/Policy mu Std               0.381605
trainer/Policy mu Max               2.80532
trainer/Policy mu Min              -2.90618
trainer/Policy log std Mean        -2.35837
trainer/Policy log std Std          0.325298
trainer/Policy log std Max         -0.53911
trainer/Policy log std Min         -2.83946
trainer/Alpha                       0.0842911
trainer/Alpha Loss                  0.311683
exploration/num steps total    308200
exploration/num paths total      3082
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.969652
exploration/Rewards Std             1.2581
exploration/Rewards Max            -0.00914028
exploration/Rewards Min            -8.23017
exploration/Returns Mean          -96.9652
exploration/Returns Std           100.753
exploration/Returns Max           -25.5644
exploration/Returns Min          -290.854
exploration/Actions Mean            0.0197121
exploration/Actions Std             0.214865
exploration/Actions Max             0.999153
exploration/Actions Min            -0.959282
exploration/Num Paths               5
exploration/Average Returns       -96.9652
evaluation/num steps total     924000
evaluation/num paths total       9240
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.505625
evaluation/Rewards Std              1.02498
evaluation/Rewards Max             -0.0288602
evaluation/Rewards Min            -10.0197
evaluation/Returns Mean           -50.5625
evaluation/Returns Std             33.9301
evaluation/Returns Max            -13.8296
evaluation/Returns Min           -129.659
evaluation/Actions Mean            -0.0062768
evaluation/Actions Std              0.181108
evaluation/Actions Max              0.996676
evaluation/Actions Min             -0.999308
evaluation/Num Paths               15
evaluation/Average Returns        -50.5625
time/data storing (s)               0.00257989
time/evaluation sampling (s)        0.318126
time/exploration sampling (s)       0.136204
time/logging (s)                    0.00476881
time/saving (s)                     0.0019354
time/training (s)                   1.94226
time/epoch (s)                      2.40588
time/total (s)                   1511.53
Epoch                             615
-----------------------------  ---------------
2019-04-23 01:38:47.438129 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 616 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.375241
trainer/QF2 Loss                    0.394375
trainer/Policy Loss                37.0305
trainer/Q1 Predictions Mean       -35.1305
trainer/Q1 Predictions Std         38.4757
trainer/Q1 Predictions Max         -7.27116
trainer/Q1 Predictions Min       -132.449
trainer/Q2 Predictions Mean       -35.1268
trainer/Q2 Predictions Std         38.4804
trainer/Q2 Predictions Max         -7.39649
trainer/Q2 Predictions Min       -132.504
trainer/Q Targets Mean            -35.1857
trainer/Q Targets Std              38.7401
trainer/Q Targets Max              -7.28694
trainer/Q Targets Min            -134.16
trainer/Log Pis Mean                1.90038
trainer/Log Pis Std                 1.00479
trainer/Log Pis Max                 4.64172
trainer/Log Pis Min                -1.05078
trainer/Policy mu Mean             -0.00629135
trainer/Policy mu Std               0.393908
trainer/Policy mu Max               2.33138
trainer/Policy mu Min              -2.73042
trainer/Policy log std Mean        -2.31733
trainer/Policy log std Std          0.338528
trainer/Policy log std Max         -0.577596
trainer/Policy log std Min         -2.93607
trainer/Alpha                       0.0826235
trainer/Alpha Loss                 -0.248388
exploration/num steps total    308700
exploration/num paths total      3087
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.60646
exploration/Rewards Std             1.09744
exploration/Rewards Max            -0.018267
exploration/Rewards Min           -10.5371
exploration/Returns Mean          -60.646
exploration/Returns Std            20.0589
exploration/Returns Max           -32.648
exploration/Returns Min           -95.1153
exploration/Actions Mean           -0.0282546
exploration/Actions Std             0.203291
exploration/Actions Max             0.987756
exploration/Actions Min            -0.999782
exploration/Num Paths               5
exploration/Average Returns       -60.646
evaluation/num steps total     925500
evaluation/num paths total       9255
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.436502
evaluation/Rewards Std              0.939891
evaluation/Rewards Max             -0.0311312
evaluation/Rewards Min            -11.0891
evaluation/Returns Mean           -43.6502
evaluation/Returns Std             23.1939
evaluation/Returns Max             -9.02872
evaluation/Returns Min            -87.0909
evaluation/Actions Mean            -0.00704016
evaluation/Actions Std              0.164506
evaluation/Actions Max              0.997528
evaluation/Actions Min             -0.998023
evaluation/Num Paths               15
evaluation/Average Returns        -43.6502
time/data storing (s)               0.0028536
time/evaluation sampling (s)        0.322697
time/exploration sampling (s)       0.138755
time/logging (s)                    0.00389304
time/saving (s)                     0.00152988
time/training (s)                   1.95478
time/epoch (s)                      2.4245
time/total (s)                   1513.96
Epoch                             616
-----------------------------  ---------------
2019-04-23 01:38:49.872171 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 617 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    2.72941
trainer/QF2 Loss                    2.77177
trainer/Policy Loss                28.8119
trainer/Q1 Predictions Mean       -27.0917
trainer/Q1 Predictions Std         31.6552
trainer/Q1 Predictions Max         -7.29653
trainer/Q1 Predictions Min       -132.755
trainer/Q2 Predictions Mean       -27.1006
trainer/Q2 Predictions Std         31.6469
trainer/Q2 Predictions Max         -7.28066
trainer/Q2 Predictions Min       -132.749
trainer/Q Targets Mean            -26.8354
trainer/Q Targets Std              31.9474
trainer/Q Targets Max              -0.134414
trainer/Q Targets Min            -133.023
trainer/Log Pis Mean                1.7275
trainer/Log Pis Std                 1.21439
trainer/Log Pis Max                 3.96936
trainer/Log Pis Min                -3.12911
trainer/Policy mu Mean             -0.00169081
trainer/Policy mu Std               0.375939
trainer/Policy mu Max               2.5624
trainer/Policy mu Min              -2.58266
trainer/Policy log std Mean        -2.26471
trainer/Policy log std Std          0.332872
trainer/Policy log std Max         -0.653067
trainer/Policy log std Min         -2.78356
trainer/Alpha                       0.0814827
trainer/Alpha Loss                 -0.683204
exploration/num steps total    309200
exploration/num paths total      3092
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.09411
exploration/Rewards Std             1.47721
exploration/Rewards Max            -0.00838825
exploration/Rewards Min            -9.38269
exploration/Returns Mean         -109.411
exploration/Returns Std            88.1532
exploration/Returns Max           -34.7429
exploration/Returns Min          -281.864
exploration/Actions Mean           -0.0293334
exploration/Actions Std             0.232057
exploration/Actions Max             0.996636
exploration/Actions Min            -0.999658
exploration/Num Paths               5
exploration/Average Returns      -109.411
evaluation/num steps total     927000
evaluation/num paths total       9270
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.339697
evaluation/Rewards Std              0.881755
evaluation/Rewards Max             -0.01889
evaluation/Rewards Min            -10.0574
evaluation/Returns Mean           -33.9697
evaluation/Returns Std             24.1121
evaluation/Returns Max             -8.17707
evaluation/Returns Min            -86.771
evaluation/Actions Mean             0.00292527
evaluation/Actions Std              0.164067
evaluation/Actions Max              0.997903
evaluation/Actions Min             -0.994252
evaluation/Num Paths               15
evaluation/Average Returns        -33.9697
time/data storing (s)               0.0026089
time/evaluation sampling (s)        0.320884
time/exploration sampling (s)       0.136936
time/logging (s)                    0.00481329
time/saving (s)                     0.00194685
time/training (s)                   1.95477
time/epoch (s)                      2.42196
time/total (s)                   1516.39
Epoch                             617
-----------------------------  ---------------
2019-04-23 01:38:52.325101 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 618 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                   45.1236
trainer/QF2 Loss                   45.3097
trainer/Policy Loss                37.889
trainer/Q1 Predictions Mean       -36.089
trainer/Q1 Predictions Std         37.2962
trainer/Q1 Predictions Max         -7.47
trainer/Q1 Predictions Min       -138.176
trainer/Q2 Predictions Mean       -36.0698
trainer/Q2 Predictions Std         37.2684
trainer/Q2 Predictions Max         -7.46919
trainer/Q2 Predictions Min       -137.059
trainer/Q Targets Mean            -35.7543
trainer/Q Targets Std              37.5246
trainer/Q Targets Max              -1.83317
trainer/Q Targets Min            -139.148
trainer/Log Pis Mean                1.8752
trainer/Log Pis Std                 1.23686
trainer/Log Pis Max                 5.47705
trainer/Log Pis Min                -2.43741
trainer/Policy mu Mean             -0.0603864
trainer/Policy mu Std               0.539825
trainer/Policy mu Max               2.77465
trainer/Policy mu Min              -2.93981
trainer/Policy log std Mean        -2.23827
trainer/Policy log std Std          0.419329
trainer/Policy log std Max         -0.61348
trainer/Policy log std Min         -2.90028
trainer/Alpha                       0.081362
trainer/Alpha Loss                 -0.3131
exploration/num steps total    309700
exploration/num paths total      3097
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.336541
exploration/Rewards Std             0.573715
exploration/Rewards Max            -0.0163673
exploration/Rewards Min            -6.83409
exploration/Returns Mean          -33.6541
exploration/Returns Std            17.5625
exploration/Returns Max           -17.0171
exploration/Returns Min           -63.6576
exploration/Actions Mean            0.00627197
exploration/Actions Std             0.174249
exploration/Actions Max             0.996124
exploration/Actions Min            -0.996974
exploration/Num Paths               5
exploration/Average Returns       -33.6541
evaluation/num steps total     928500
evaluation/num paths total       9285
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.42329
evaluation/Rewards Std              1.01735
evaluation/Rewards Max             -0.000883579
evaluation/Rewards Min            -10.3802
evaluation/Returns Mean           -42.329
evaluation/Returns Std             25.8288
evaluation/Returns Max            -11.2185
evaluation/Returns Min            -90.639
evaluation/Actions Mean             0.00284618
evaluation/Actions Std              0.182106
evaluation/Actions Max              0.998734
evaluation/Actions Min             -0.998573
evaluation/Num Paths               15
evaluation/Average Returns        -42.329
time/data storing (s)               0.0026402
time/evaluation sampling (s)        0.332665
time/exploration sampling (s)       0.137859
time/logging (s)                    0.00481396
time/saving (s)                     0.0019011
time/training (s)                   1.96066
time/epoch (s)                      2.44054
time/total (s)                   1518.83
Epoch                             618
-----------------------------  ----------------
2019-04-23 01:38:54.773775 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 619 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.217837
trainer/QF2 Loss                    0.221303
trainer/Policy Loss                32.8231
trainer/Q1 Predictions Mean       -30.678
trainer/Q1 Predictions Std         31.9671
trainer/Q1 Predictions Max         -7.30761
trainer/Q1 Predictions Min       -133.795
trainer/Q2 Predictions Mean       -30.6818
trainer/Q2 Predictions Std         31.9795
trainer/Q2 Predictions Max         -7.34481
trainer/Q2 Predictions Min       -133.669
trainer/Q Targets Mean            -30.85
trainer/Q Targets Std              32.1635
trainer/Q Targets Max              -7.37345
trainer/Q Targets Min            -134.527
trainer/Log Pis Mean                2.19419
trainer/Log Pis Std                 1.40419
trainer/Log Pis Max                 8.43964
trainer/Log Pis Min                -1.22968
trainer/Policy mu Mean              0.0846475
trainer/Policy mu Std               0.610977
trainer/Policy mu Max               3.20637
trainer/Policy mu Min              -2.73909
trainer/Policy log std Mean        -2.29078
trainer/Policy log std Std          0.441554
trainer/Policy log std Max         -0.581445
trainer/Policy log std Min         -2.9643
trainer/Alpha                       0.0815525
trainer/Alpha Loss                  0.486749
exploration/num steps total    310200
exploration/num paths total      3102
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.845868
exploration/Rewards Std             1.32786
exploration/Rewards Max            -0.0123691
exploration/Rewards Min            -9.41045
exploration/Returns Mean          -84.5868
exploration/Returns Std            97.3033
exploration/Returns Max           -20.6263
exploration/Returns Min          -275.19
exploration/Actions Mean           -0.0228239
exploration/Actions Std             0.199531
exploration/Actions Max             0.978929
exploration/Actions Min            -0.998543
exploration/Num Paths               5
exploration/Average Returns       -84.5868
evaluation/num steps total     930000
evaluation/num paths total       9300
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.740945
evaluation/Rewards Std              1.18598
evaluation/Rewards Max             -0.0243179
evaluation/Rewards Min            -10.4912
evaluation/Returns Mean           -74.0945
evaluation/Returns Std             68.8504
evaluation/Returns Max             -4.8712
evaluation/Returns Min           -283.451
evaluation/Actions Mean            -0.000862468
evaluation/Actions Std              0.191997
evaluation/Actions Max              0.998746
evaluation/Actions Min             -0.99864
evaluation/Num Paths               15
evaluation/Average Returns        -74.0945
time/data storing (s)               0.0027357
time/evaluation sampling (s)        0.326087
time/exploration sampling (s)       0.137998
time/logging (s)                    0.00479458
time/saving (s)                     0.00154449
time/training (s)                   1.96216
time/epoch (s)                      2.43532
time/total (s)                   1521.27
Epoch                             619
-----------------------------  ----------------
2019-04-23 01:38:57.253201 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 620 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.18734
trainer/QF2 Loss                    1.27375
trainer/Policy Loss                30.9213
trainer/Q1 Predictions Mean       -28.9938
trainer/Q1 Predictions Std         32.2442
trainer/Q1 Predictions Max         -7.41889
trainer/Q1 Predictions Min       -137.054
trainer/Q2 Predictions Mean       -28.9804
trainer/Q2 Predictions Std         32.2474
trainer/Q2 Predictions Max         -7.45772
trainer/Q2 Predictions Min       -137.661
trainer/Q Targets Mean            -29.2694
trainer/Q Targets Std              32.7061
trainer/Q Targets Max              -0.247064
trainer/Q Targets Min            -138.243
trainer/Log Pis Mean                2.00576
trainer/Log Pis Std                 1.10894
trainer/Log Pis Max                 5.75224
trainer/Log Pis Min                -1.77002
trainer/Policy mu Mean             -0.0545637
trainer/Policy mu Std               0.452813
trainer/Policy mu Max               2.91525
trainer/Policy mu Min              -2.93365
trainer/Policy log std Mean        -2.26776
trainer/Policy log std Std          0.343274
trainer/Policy log std Max         -0.282241
trainer/Policy log std Min         -2.83831
trainer/Alpha                       0.0822624
trainer/Alpha Loss                  0.0143812
exploration/num steps total    310700
exploration/num paths total      3107
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.901492
exploration/Rewards Std             1.43094
exploration/Rewards Max            -0.00681439
exploration/Rewards Min            -9.16584
exploration/Returns Mean          -90.1492
exploration/Returns Std           102.874
exploration/Returns Max           -20.4704
exploration/Returns Min          -293.331
exploration/Actions Mean           -0.00287029
exploration/Actions Std             0.21842
exploration/Actions Max             0.999679
exploration/Actions Min            -0.998094
exploration/Num Paths               5
exploration/Average Returns       -90.1492
evaluation/num steps total     931500
evaluation/num paths total       9315
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.471937
evaluation/Rewards Std              0.854553
evaluation/Rewards Max             -0.0101045
evaluation/Rewards Min             -8.73062
evaluation/Returns Mean           -47.1937
evaluation/Returns Std             32.3085
evaluation/Returns Max             -6.75873
evaluation/Returns Min           -143.978
evaluation/Actions Mean            -0.00928328
evaluation/Actions Std              0.162566
evaluation/Actions Max              0.99788
evaluation/Actions Min             -0.99882
evaluation/Num Paths               15
evaluation/Average Returns        -47.1937
time/data storing (s)               0.00278311
time/evaluation sampling (s)        0.327522
time/exploration sampling (s)       0.135792
time/logging (s)                    0.00424166
time/saving (s)                     0.00154034
time/training (s)                   1.99382
time/epoch (s)                      2.4657
time/total (s)                   1523.74
Epoch                             620
-----------------------------  ---------------
2019-04-23 01:38:59.701934 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 621 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    2.65835
trainer/QF2 Loss                    2.65946
trainer/Policy Loss                36.9674
trainer/Q1 Predictions Mean       -35.0376
trainer/Q1 Predictions Std         40.6147
trainer/Q1 Predictions Max         -7.50354
trainer/Q1 Predictions Min       -133.671
trainer/Q2 Predictions Mean       -35.0367
trainer/Q2 Predictions Std         40.616
trainer/Q2 Predictions Max         -7.43213
trainer/Q2 Predictions Min       -133.549
trainer/Q Targets Mean            -35.2625
trainer/Q Targets Std              41.132
trainer/Q Targets Max              -0.318871
trainer/Q Targets Min            -134.799
trainer/Log Pis Mean                1.9564
trainer/Log Pis Std                 1.1435
trainer/Log Pis Max                 4.92235
trainer/Log Pis Min                -2.37551
trainer/Policy mu Mean              0.00217363
trainer/Policy mu Std               0.375506
trainer/Policy mu Max               3.25561
trainer/Policy mu Min              -2.59669
trainer/Policy log std Mean        -2.29014
trainer/Policy log std Std          0.322904
trainer/Policy log std Max         -0.225045
trainer/Policy log std Min         -2.72919
trainer/Alpha                       0.0820391
trainer/Alpha Loss                 -0.109017
exploration/num steps total    311200
exploration/num paths total      3112
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.340296
exploration/Rewards Std             0.802748
exploration/Rewards Max            -0.00263793
exploration/Rewards Min            -8.34841
exploration/Returns Mean          -34.0296
exploration/Returns Std            13.9849
exploration/Returns Max           -16.0443
exploration/Returns Min           -53.6561
exploration/Actions Mean            0.00674846
exploration/Actions Std             0.189921
exploration/Actions Max             0.997329
exploration/Actions Min            -0.995676
exploration/Num Paths               5
exploration/Average Returns       -34.0296
evaluation/num steps total     933000
evaluation/num paths total       9330
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.59747
evaluation/Rewards Std              1.11161
evaluation/Rewards Max             -0.0192494
evaluation/Rewards Min             -8.78534
evaluation/Returns Mean           -59.747
evaluation/Returns Std             70.9267
evaluation/Returns Max             -7.20376
evaluation/Returns Min           -309.735
evaluation/Actions Mean             0.000940204
evaluation/Actions Std              0.177798
evaluation/Actions Max              0.997439
evaluation/Actions Min             -0.99544
evaluation/Num Paths               15
evaluation/Average Returns        -59.747
time/data storing (s)               0.00270595
time/evaluation sampling (s)        0.317269
time/exploration sampling (s)       0.139146
time/logging (s)                    0.00402952
time/saving (s)                     0.00157305
time/training (s)                   1.97078
time/epoch (s)                      2.4355
time/total (s)                   1526.18
Epoch                             621
-----------------------------  ----------------
2019-04-23 01:39:02.154928 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 622 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.288903
trainer/QF2 Loss                    0.191998
trainer/Policy Loss                33.4747
trainer/Q1 Predictions Mean       -31.6389
trainer/Q1 Predictions Std         35.4823
trainer/Q1 Predictions Max         -7.38561
trainer/Q1 Predictions Min       -136.023
trainer/Q2 Predictions Mean       -31.6318
trainer/Q2 Predictions Std         35.5256
trainer/Q2 Predictions Max         -7.2903
trainer/Q2 Predictions Min       -136.318
trainer/Q Targets Mean            -31.8549
trainer/Q Targets Std              35.4935
trainer/Q Targets Max              -7.37609
trainer/Q Targets Min            -136.045
trainer/Log Pis Mean                1.84726
trainer/Log Pis Std                 1.39228
trainer/Log Pis Max                 9.96687
trainer/Log Pis Min                -2.02708
trainer/Policy mu Mean              0.0274496
trainer/Policy mu Std               0.495401
trainer/Policy mu Max               4.0858
trainer/Policy mu Min              -2.71139
trainer/Policy log std Mean        -2.29276
trainer/Policy log std Std          0.388374
trainer/Policy log std Max         -0.0330037
trainer/Policy log std Min         -2.91941
trainer/Alpha                       0.0811424
trainer/Alpha Loss                 -0.383605
exploration/num steps total    311700
exploration/num paths total      3117
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.971787
exploration/Rewards Std             1.1072
exploration/Rewards Max            -0.0131635
exploration/Rewards Min            -7.46957
exploration/Returns Mean          -97.1787
exploration/Returns Std            94.6813
exploration/Returns Max           -25.4487
exploration/Returns Min          -279.851
exploration/Actions Mean            0.0133826
exploration/Actions Std             0.187033
exploration/Actions Max             0.999671
exploration/Actions Min            -0.997033
exploration/Num Paths               5
exploration/Average Returns       -97.1787
evaluation/num steps total     934500
evaluation/num paths total       9345
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.730489
evaluation/Rewards Std              1.16333
evaluation/Rewards Max             -0.0106567
evaluation/Rewards Min             -9.81685
evaluation/Returns Mean           -73.0489
evaluation/Returns Std             77.4397
evaluation/Returns Max             -4.58126
evaluation/Returns Min           -309.7
evaluation/Actions Mean            -0.00607768
evaluation/Actions Std              0.184262
evaluation/Actions Max              0.996156
evaluation/Actions Min             -0.997287
evaluation/Num Paths               15
evaluation/Average Returns        -73.0489
time/data storing (s)               0.00257627
time/evaluation sampling (s)        0.317762
time/exploration sampling (s)       0.143197
time/logging (s)                    0.00367259
time/saving (s)                     0.0019233
time/training (s)                   1.97058
time/epoch (s)                      2.43971
time/total (s)                   1528.63
Epoch                             622
-----------------------------  ---------------
2019-04-23 01:39:04.609679 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 623 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.353186
trainer/QF2 Loss                    0.345252
trainer/Policy Loss                36.5564
trainer/Q1 Predictions Mean       -34.5847
trainer/Q1 Predictions Std         32.0839
trainer/Q1 Predictions Max         -7.35959
trainer/Q1 Predictions Min       -139.275
trainer/Q2 Predictions Mean       -34.5798
trainer/Q2 Predictions Std         32.0666
trainer/Q2 Predictions Max         -7.354
trainer/Q2 Predictions Min       -138.044
trainer/Q Targets Mean            -34.8823
trainer/Q Targets Std              32.2588
trainer/Q Targets Max              -7.25778
trainer/Q Targets Min            -139.844
trainer/Log Pis Mean                2.0562
trainer/Log Pis Std                 1.14837
trainer/Log Pis Max                 5.317
trainer/Log Pis Min                -0.837869
trainer/Policy mu Mean             -0.00348473
trainer/Policy mu Std               0.427302
trainer/Policy mu Max               2.69332
trainer/Policy mu Min              -2.79179
trainer/Policy log std Mean        -2.34912
trainer/Policy log std Std          0.370159
trainer/Policy log std Max         -0.577004
trainer/Policy log std Min         -2.83581
trainer/Alpha                       0.0810275
trainer/Alpha Loss                  0.14122
exploration/num steps total    312200
exploration/num paths total      3122
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.567133
exploration/Rewards Std             1.2257
exploration/Rewards Max            -0.0127543
exploration/Rewards Min           -11.1833
exploration/Returns Mean          -56.7133
exploration/Returns Std            28.7934
exploration/Returns Max           -20.8291
exploration/Returns Min          -103.702
exploration/Actions Mean           -0.00893343
exploration/Actions Std             0.234897
exploration/Actions Max             0.999114
exploration/Actions Min            -0.998517
exploration/Num Paths               5
exploration/Average Returns       -56.7133
evaluation/num steps total     936000
evaluation/num paths total       9360
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.407447
evaluation/Rewards Std              0.937683
evaluation/Rewards Max             -0.00520945
evaluation/Rewards Min             -9.66459
evaluation/Returns Mean           -40.7447
evaluation/Returns Std             35.3371
evaluation/Returns Max             -9.37874
evaluation/Returns Min           -148.43
evaluation/Actions Mean            -0.000624367
evaluation/Actions Std              0.178087
evaluation/Actions Max              0.999213
evaluation/Actions Min             -0.997357
evaluation/Num Paths               15
evaluation/Average Returns        -40.7447
time/data storing (s)               0.00257482
time/evaluation sampling (s)        0.318507
time/exploration sampling (s)       0.134738
time/logging (s)                    0.00481229
time/saving (s)                     0.00198753
time/training (s)                   1.9804
time/epoch (s)                      2.44302
time/total (s)                   1531.08
Epoch                             623
-----------------------------  ----------------
2019-04-23 01:39:07.071016 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 624 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.146432
trainer/QF2 Loss                    0.15391
trainer/Policy Loss                34.2603
trainer/Q1 Predictions Mean       -32.3432
trainer/Q1 Predictions Std         36.2512
trainer/Q1 Predictions Max         -7.18493
trainer/Q1 Predictions Min       -135.487
trainer/Q2 Predictions Mean       -32.3617
trainer/Q2 Predictions Std         36.277
trainer/Q2 Predictions Max         -7.12442
trainer/Q2 Predictions Min       -135.353
trainer/Q Targets Mean            -32.4947
trainer/Q Targets Std              36.4117
trainer/Q Targets Max              -7.34101
trainer/Q Targets Min            -136.389
trainer/Log Pis Mean                1.96621
trainer/Log Pis Std                 1.20467
trainer/Log Pis Max                 4.61576
trainer/Log Pis Min                -3.59958
trainer/Policy mu Mean             -0.0539821
trainer/Policy mu Std               0.495109
trainer/Policy mu Max               1.72922
trainer/Policy mu Min              -3.61101
trainer/Policy log std Mean        -2.24468
trainer/Policy log std Std          0.364174
trainer/Policy log std Max         -0.244939
trainer/Policy log std Min         -2.90013
trainer/Alpha                       0.0806756
trainer/Alpha Loss                 -0.0850684
exploration/num steps total    312700
exploration/num paths total      3127
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.564597
exploration/Rewards Std             1.04465
exploration/Rewards Max            -0.0201406
exploration/Rewards Min            -9.15564
exploration/Returns Mean          -56.4597
exploration/Returns Std            28.7234
exploration/Returns Max           -23.2965
exploration/Returns Min          -108.178
exploration/Actions Mean            0.0197371
exploration/Actions Std             0.222926
exploration/Actions Max             0.999641
exploration/Actions Min            -0.999243
exploration/Num Paths               5
exploration/Average Returns       -56.4597
evaluation/num steps total     937500
evaluation/num paths total       9375
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.905114
evaluation/Rewards Std              1.40076
evaluation/Rewards Max             -0.0189053
evaluation/Rewards Min             -9.83193
evaluation/Returns Mean           -90.5114
evaluation/Returns Std            112.277
evaluation/Returns Max             -8.58586
evaluation/Returns Min           -309.153
evaluation/Actions Mean             0.00933277
evaluation/Actions Std              0.169284
evaluation/Actions Max              0.998916
evaluation/Actions Min             -0.994088
evaluation/Num Paths               15
evaluation/Average Returns        -90.5114
time/data storing (s)               0.00266161
time/evaluation sampling (s)        0.322562
time/exploration sampling (s)       0.140193
time/logging (s)                    0.00477275
time/saving (s)                     0.00189894
time/training (s)                   1.97618
time/epoch (s)                      2.44827
time/total (s)                   1533.53
Epoch                             624
-----------------------------  ---------------
2019-04-23 01:39:09.522360 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 625 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                  169.611
trainer/QF2 Loss                  168.518
trainer/Policy Loss                41.6723
trainer/Q1 Predictions Mean       -39.7542
trainer/Q1 Predictions Std         41.6997
trainer/Q1 Predictions Max         -7.337
trainer/Q1 Predictions Min       -156.378
trainer/Q2 Predictions Mean       -39.721
trainer/Q2 Predictions Std         41.6145
trainer/Q2 Predictions Max         -7.27255
trainer/Q2 Predictions Min       -154.359
trainer/Q Targets Mean            -38.9333
trainer/Q Targets Std              41.4404
trainer/Q Targets Max              -2.98226
trainer/Q Targets Min            -158.67
trainer/Log Pis Mean                1.976
trainer/Log Pis Std                 1.02139
trainer/Log Pis Max                 4.29141
trainer/Log Pis Min                -2.15634
trainer/Policy mu Mean             -0.013545
trainer/Policy mu Std               0.390151
trainer/Policy mu Max               2.93713
trainer/Policy mu Min              -2.27553
trainer/Policy log std Mean        -2.29644
trainer/Policy log std Std          0.351637
trainer/Policy log std Max         -0.536526
trainer/Policy log std Min         -2.871
trainer/Alpha                       0.0799667
trainer/Alpha Loss                 -0.0606256
exploration/num steps total    313200
exploration/num paths total      3132
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.469517
exploration/Rewards Std             0.997728
exploration/Rewards Max            -0.00401725
exploration/Rewards Min            -8.83265
exploration/Returns Mean          -46.9517
exploration/Returns Std            26.0676
exploration/Returns Max           -20.4903
exploration/Returns Min           -91.7459
exploration/Actions Mean           -0.0102824
exploration/Actions Std             0.227835
exploration/Actions Max             0.999394
exploration/Actions Min            -0.998244
exploration/Num Paths               5
exploration/Average Returns       -46.9517
evaluation/num steps total     939000
evaluation/num paths total       9390
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.885798
evaluation/Rewards Std              1.4401
evaluation/Rewards Max             -0.00316767
evaluation/Rewards Min            -10.066
evaluation/Returns Mean           -88.5798
evaluation/Returns Std             92.8499
evaluation/Returns Max             -3.52906
evaluation/Returns Min           -319.243
evaluation/Actions Mean             0.0025817
evaluation/Actions Std              0.196266
evaluation/Actions Max              0.999109
evaluation/Actions Min             -0.99659
evaluation/Num Paths               15
evaluation/Average Returns        -88.5798
time/data storing (s)               0.0026759
time/evaluation sampling (s)        0.315729
time/exploration sampling (s)       0.137602
time/logging (s)                    0.00354462
time/saving (s)                     0.00194146
time/training (s)                   1.9765
time/epoch (s)                      2.43799
time/total (s)                   1535.97
Epoch                             625
-----------------------------  ---------------
2019-04-23 01:39:11.981217 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 626 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.899431
trainer/QF2 Loss                    0.958708
trainer/Policy Loss                31.247
trainer/Q1 Predictions Mean       -29.3076
trainer/Q1 Predictions Std         33.545
trainer/Q1 Predictions Max         -7.3841
trainer/Q1 Predictions Min       -157.718
trainer/Q2 Predictions Mean       -29.3173
trainer/Q2 Predictions Std         33.4838
trainer/Q2 Predictions Max         -7.34068
trainer/Q2 Predictions Min       -156.167
trainer/Q Targets Mean            -29.3936
trainer/Q Targets Std              33.861
trainer/Q Targets Max              -0.202835
trainer/Q Targets Min            -157.996
trainer/Log Pis Mean                1.95678
trainer/Log Pis Std                 1.24585
trainer/Log Pis Max                 5.574
trainer/Log Pis Min                -3.03458
trainer/Policy mu Mean              0.0661333
trainer/Policy mu Std               0.576691
trainer/Policy mu Max               3.0363
trainer/Policy mu Min              -2.41259
trainer/Policy log std Mean        -2.24144
trainer/Policy log std Std          0.432421
trainer/Policy log std Max         -0.620622
trainer/Policy log std Min         -2.9389
trainer/Alpha                       0.0804143
trainer/Alpha Loss                 -0.108936
exploration/num steps total    313700
exploration/num paths total      3137
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.01128
exploration/Rewards Std             1.6805
exploration/Rewards Max            -0.00463071
exploration/Rewards Min           -10.1572
exploration/Returns Mean         -101.128
exploration/Returns Std           115.373
exploration/Returns Max           -29.8533
exploration/Returns Min          -330.768
exploration/Actions Mean           -0.00485483
exploration/Actions Std             0.239932
exploration/Actions Max             0.999475
exploration/Actions Min            -0.997133
exploration/Num Paths               5
exploration/Average Returns      -101.128
evaluation/num steps total     940500
evaluation/num paths total       9405
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.58182
evaluation/Rewards Std              1.16002
evaluation/Rewards Max             -0.0241953
evaluation/Rewards Min             -9.97594
evaluation/Returns Mean           -58.182
evaluation/Returns Std             72.4859
evaluation/Returns Max             -5.56711
evaluation/Returns Min           -299.113
evaluation/Actions Mean             0.0112204
evaluation/Actions Std              0.184366
evaluation/Actions Max              0.998605
evaluation/Actions Min             -0.996237
evaluation/Num Paths               15
evaluation/Average Returns        -58.182
time/data storing (s)               0.00261148
time/evaluation sampling (s)        0.320196
time/exploration sampling (s)       0.134307
time/logging (s)                    0.00480088
time/saving (s)                     0.00531017
time/training (s)                   1.9808
time/epoch (s)                      2.44803
time/total (s)                   1538.42
Epoch                             626
-----------------------------  ---------------
2019-04-23 01:39:14.438275 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 627 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.45319
trainer/QF2 Loss                    1.4931
trainer/Policy Loss                28.5349
trainer/Q1 Predictions Mean       -26.6592
trainer/Q1 Predictions Std         31.8561
trainer/Q1 Predictions Max         -7.36985
trainer/Q1 Predictions Min       -136.095
trainer/Q2 Predictions Mean       -26.6548
trainer/Q2 Predictions Std         31.8258
trainer/Q2 Predictions Max         -7.35723
trainer/Q2 Predictions Min       -135.848
trainer/Q Targets Mean            -26.6876
trainer/Q Targets Std              32.1401
trainer/Q Targets Max              -0.207555
trainer/Q Targets Min            -136.822
trainer/Log Pis Mean                1.95019
trainer/Log Pis Std                 1.23507
trainer/Log Pis Max                 6.75444
trainer/Log Pis Min                -1.92722
trainer/Policy mu Mean             -0.0418086
trainer/Policy mu Std               0.496088
trainer/Policy mu Max               2.55322
trainer/Policy mu Min              -2.89348
trainer/Policy log std Mean        -2.26738
trainer/Policy log std Std          0.407283
trainer/Policy log std Max         -0.588605
trainer/Policy log std Min         -2.93883
trainer/Alpha                       0.0822904
trainer/Alpha Loss                 -0.124411
exploration/num steps total    314200
exploration/num paths total      3142
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.728386
exploration/Rewards Std             1.14218
exploration/Rewards Max            -0.0164646
exploration/Rewards Min            -9.03031
exploration/Returns Mean          -72.8386
exploration/Returns Std            40.9246
exploration/Returns Max           -36.4238
exploration/Returns Min          -146.581
exploration/Actions Mean            0.0295871
exploration/Actions Std             0.232083
exploration/Actions Max             0.999731
exploration/Actions Min            -0.992625
exploration/Num Paths               5
exploration/Average Returns       -72.8386
evaluation/num steps total     942000
evaluation/num paths total       9420
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.753202
evaluation/Rewards Std              1.06192
evaluation/Rewards Max             -0.0404464
evaluation/Rewards Min            -10.375
evaluation/Returns Mean           -75.3202
evaluation/Returns Std             46.322
evaluation/Returns Max            -14.7307
evaluation/Returns Min           -171.927
evaluation/Actions Mean             0.000267743
evaluation/Actions Std              0.183238
evaluation/Actions Max              0.99894
evaluation/Actions Min             -0.995759
evaluation/Num Paths               15
evaluation/Average Returns        -75.3202
time/data storing (s)               0.00280114
time/evaluation sampling (s)        0.316812
time/exploration sampling (s)       0.136969
time/logging (s)                    0.00377431
time/saving (s)                     0.00156985
time/training (s)                   1.9811
time/epoch (s)                      2.44302
time/total (s)                   1540.87
Epoch                             627
-----------------------------  ----------------
2019-04-23 01:39:16.887825 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 628 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.23903
trainer/QF2 Loss                    0.222668
trainer/Policy Loss                28.7111
trainer/Q1 Predictions Mean       -26.8465
trainer/Q1 Predictions Std         26.0074
trainer/Q1 Predictions Max         -7.42386
trainer/Q1 Predictions Min       -135.664
trainer/Q2 Predictions Mean       -26.8269
trainer/Q2 Predictions Std         26.0238
trainer/Q2 Predictions Max         -7.38868
trainer/Q2 Predictions Min       -135.368
trainer/Q Targets Mean            -27.095
trainer/Q Targets Std              26.3319
trainer/Q Targets Max              -7.42516
trainer/Q Targets Min            -136.544
trainer/Log Pis Mean                1.92244
trainer/Log Pis Std                 0.933225
trainer/Log Pis Max                 4.15197
trainer/Log Pis Min                -1.07354
trainer/Policy mu Mean              0.0568611
trainer/Policy mu Std               0.435552
trainer/Policy mu Max               3.26656
trainer/Policy mu Min              -1.95152
trainer/Policy log std Mean        -2.3006
trainer/Policy log std Std          0.369968
trainer/Policy log std Max         -0.605624
trainer/Policy log std Min         -2.99776
trainer/Alpha                       0.081285
trainer/Alpha Loss                 -0.194649
exploration/num steps total    314700
exploration/num paths total      3147
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.632664
exploration/Rewards Std             1.18544
exploration/Rewards Max            -0.0123514
exploration/Rewards Min           -10.017
exploration/Returns Mean          -63.2664
exploration/Returns Std            45.0072
exploration/Returns Max           -24.667
exploration/Returns Min          -146.841
exploration/Actions Mean            0.0197141
exploration/Actions Std             0.227321
exploration/Actions Max             0.997382
exploration/Actions Min            -0.996426
exploration/Num Paths               5
exploration/Average Returns       -63.2664
evaluation/num steps total     943500
evaluation/num paths total       9435
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.859934
evaluation/Rewards Std              1.31206
evaluation/Rewards Max             -0.0253901
evaluation/Rewards Min            -10.0472
evaluation/Returns Mean           -85.9934
evaluation/Returns Std             86.0554
evaluation/Returns Max            -10.528
evaluation/Returns Min           -291.018
evaluation/Actions Mean            -0.00977278
evaluation/Actions Std              0.18502
evaluation/Actions Max              0.997337
evaluation/Actions Min             -0.999093
evaluation/Num Paths               15
evaluation/Average Returns        -85.9934
time/data storing (s)               0.00274534
time/evaluation sampling (s)        0.313318
time/exploration sampling (s)       0.136694
time/logging (s)                    0.00481116
time/saving (s)                     0.00190681
time/training (s)                   1.97924
time/epoch (s)                      2.43872
time/total (s)                   1543.31
Epoch                             628
-----------------------------  ---------------
2019-04-23 01:39:19.342265 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 629 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                   14.6541
trainer/QF2 Loss                   14.4142
trainer/Policy Loss                22.4577
trainer/Q1 Predictions Mean       -20.622
trainer/Q1 Predictions Std         21.525
trainer/Q1 Predictions Max         -7.28679
trainer/Q1 Predictions Min       -136.856
trainer/Q2 Predictions Mean       -20.5977
trainer/Q2 Predictions Std         21.4859
trainer/Q2 Predictions Max         -7.28613
trainer/Q2 Predictions Min       -136.37
trainer/Q Targets Mean            -20.205
trainer/Q Targets Std              21.6438
trainer/Q Targets Max              -0.544354
trainer/Q Targets Min            -136.809
trainer/Log Pis Mean                1.86592
trainer/Log Pis Std                 1.38821
trainer/Log Pis Max                 6.50451
trainer/Log Pis Min                -2.98094
trainer/Policy mu Mean             -0.0308899
trainer/Policy mu Std               0.466111
trainer/Policy mu Max               2.93224
trainer/Policy mu Min              -2.92926
trainer/Policy log std Mean        -2.20629
trainer/Policy log std Std          0.39583
trainer/Policy log std Max         -0.392109
trainer/Policy log std Min         -2.89098
trainer/Alpha                       0.0808031
trainer/Alpha Loss                 -0.337296
exploration/num steps total    315200
exploration/num paths total      3152
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.779125
exploration/Rewards Std             0.846025
exploration/Rewards Max            -0.00385796
exploration/Rewards Min            -7.63551
exploration/Returns Mean          -77.9125
exploration/Returns Std            17.0476
exploration/Returns Max           -47.74
exploration/Returns Min           -94.7936
exploration/Actions Mean            0.000574315
exploration/Actions Std             0.206579
exploration/Actions Max             0.999854
exploration/Actions Min            -0.998459
exploration/Num Paths               5
exploration/Average Returns       -77.9125
evaluation/num steps total     945000
evaluation/num paths total       9450
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.570477
evaluation/Rewards Std              0.914101
evaluation/Rewards Max             -0.0508103
evaluation/Rewards Min             -8.55742
evaluation/Returns Mean           -57.0477
evaluation/Returns Std             34.1174
evaluation/Returns Max            -12.4194
evaluation/Returns Min           -120.224
evaluation/Actions Mean            -0.00414355
evaluation/Actions Std              0.179802
evaluation/Actions Max              0.997643
evaluation/Actions Min             -0.996213
evaluation/Num Paths               15
evaluation/Average Returns        -57.0477
time/data storing (s)               0.00270873
time/evaluation sampling (s)        0.317234
time/exploration sampling (s)       0.137013
time/logging (s)                    0.00484915
time/saving (s)                     0.00197182
time/training (s)                   1.9776
time/epoch (s)                      2.44138
time/total (s)                   1545.76
Epoch                             629
-----------------------------  ----------------
2019-04-23 01:39:21.787749 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 630 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.16107
trainer/QF2 Loss                    1.23642
trainer/Policy Loss                34.276
trainer/Q1 Predictions Mean       -32.2188
trainer/Q1 Predictions Std         36.1968
trainer/Q1 Predictions Max         -7.20389
trainer/Q1 Predictions Min       -137.122
trainer/Q2 Predictions Mean       -32.2437
trainer/Q2 Predictions Std         36.1853
trainer/Q2 Predictions Max         -7.21815
trainer/Q2 Predictions Min       -136.646
trainer/Q Targets Mean            -32.3009
trainer/Q Targets Std              36.4907
trainer/Q Targets Max              -0.201605
trainer/Q Targets Min            -137.789
trainer/Log Pis Mean                2.08639
trainer/Log Pis Std                 1.14354
trainer/Log Pis Max                 6.6243
trainer/Log Pis Min                -1.73281
trainer/Policy mu Mean             -0.00580379
trainer/Policy mu Std               0.49815
trainer/Policy mu Max               2.99422
trainer/Policy mu Min              -2.10908
trainer/Policy log std Mean        -2.25693
trainer/Policy log std Std          0.414361
trainer/Policy log std Max         -0.156586
trainer/Policy log std Min         -2.83331
trainer/Alpha                       0.0813187
trainer/Alpha Loss                  0.216786
exploration/num steps total    315700
exploration/num paths total      3157
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.589933
exploration/Rewards Std             1.5317
exploration/Rewards Max            -0.0171295
exploration/Rewards Min           -11.0178
exploration/Returns Mean          -58.9933
exploration/Returns Std            20.9869
exploration/Returns Max           -24.8131
exploration/Returns Min           -85.8974
exploration/Actions Mean            0.00729455
exploration/Actions Std             0.264381
exploration/Actions Max             0.999161
exploration/Actions Min            -0.999658
exploration/Num Paths               5
exploration/Average Returns       -58.9933
evaluation/num steps total     946500
evaluation/num paths total       9465
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.83845
evaluation/Rewards Std              1.41419
evaluation/Rewards Max             -0.0158209
evaluation/Rewards Min            -11.2615
evaluation/Returns Mean           -83.845
evaluation/Returns Std             88.0306
evaluation/Returns Max            -14.0466
evaluation/Returns Min           -307.903
evaluation/Actions Mean             0.0129289
evaluation/Actions Std              0.199302
evaluation/Actions Max              0.998661
evaluation/Actions Min             -0.997039
evaluation/Num Paths               15
evaluation/Average Returns        -83.845
time/data storing (s)               0.00339589
time/evaluation sampling (s)        0.312965
time/exploration sampling (s)       0.140359
time/logging (s)                    0.00520149
time/saving (s)                     0.00200887
time/training (s)                   1.96922
time/epoch (s)                      2.43316
time/total (s)                   1548.2
Epoch                             630
-----------------------------  ---------------
2019-04-23 01:39:24.260273 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 631 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.187189
trainer/QF2 Loss                    0.194093
trainer/Policy Loss                29.8425
trainer/Q1 Predictions Mean       -27.9201
trainer/Q1 Predictions Std         30.6931
trainer/Q1 Predictions Max         -7.43048
trainer/Q1 Predictions Min       -136.743
trainer/Q2 Predictions Mean       -27.9177
trainer/Q2 Predictions Std         30.67
trainer/Q2 Predictions Max         -7.45675
trainer/Q2 Predictions Min       -136.682
trainer/Q Targets Mean            -28.2312
trainer/Q Targets Std              30.848
trainer/Q Targets Max              -7.48022
trainer/Q Targets Min            -137.436
trainer/Log Pis Mean                1.99553
trainer/Log Pis Std                 1.17766
trainer/Log Pis Max                 3.87486
trainer/Log Pis Min                -4.64766
trainer/Policy mu Mean              0.0367701
trainer/Policy mu Std               0.413797
trainer/Policy mu Max               3.18687
trainer/Policy mu Min              -1.75589
trainer/Policy log std Mean        -2.25876
trainer/Policy log std Std          0.36508
trainer/Policy log std Max         -0.655302
trainer/Policy log std Min         -2.93275
trainer/Alpha                       0.0818332
trainer/Alpha Loss                 -0.011201
exploration/num steps total    316200
exploration/num paths total      3162
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.660193
exploration/Rewards Std             1.07464
exploration/Rewards Max            -0.00892076
exploration/Rewards Min           -10.1294
exploration/Returns Mean          -66.0193
exploration/Returns Std            34.0977
exploration/Returns Max           -24.7455
exploration/Returns Min          -126.961
exploration/Actions Mean            0.0261962
exploration/Actions Std             0.231326
exploration/Actions Max             0.999093
exploration/Actions Min            -0.997817
exploration/Num Paths               5
exploration/Average Returns       -66.0193
evaluation/num steps total     948000
evaluation/num paths total       9480
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.513185
evaluation/Rewards Std              1.07073
evaluation/Rewards Max             -0.0395558
evaluation/Rewards Min            -11.4181
evaluation/Returns Mean           -51.3185
evaluation/Returns Std             33.5168
evaluation/Returns Max             -4.95744
evaluation/Returns Min           -119.806
evaluation/Actions Mean             0.00849032
evaluation/Actions Std              0.189056
evaluation/Actions Max              0.999031
evaluation/Actions Min             -0.995474
evaluation/Num Paths               15
evaluation/Average Returns        -51.3185
time/data storing (s)               0.00259563
time/evaluation sampling (s)        0.320992
time/exploration sampling (s)       0.138455
time/logging (s)                    0.00481234
time/saving (s)                     0.00192553
time/training (s)                   1.98971
time/epoch (s)                      2.45849
time/total (s)                   1550.66
Epoch                             631
-----------------------------  ---------------
2019-04-23 01:39:26.718526 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 632 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.96796
trainer/QF2 Loss                    2.10383
trainer/Policy Loss                37.0381
trainer/Q1 Predictions Mean       -34.8566
trainer/Q1 Predictions Std         36.174
trainer/Q1 Predictions Max         -7.57402
trainer/Q1 Predictions Min       -155.651
trainer/Q2 Predictions Mean       -34.8777
trainer/Q2 Predictions Std         36.1192
trainer/Q2 Predictions Max         -7.5907
trainer/Q2 Predictions Min       -153.726
trainer/Q Targets Mean            -34.909
trainer/Q Targets Std              36.4561
trainer/Q Targets Max              -0.191407
trainer/Q Targets Min            -156.705
trainer/Log Pis Mean                2.28842
trainer/Log Pis Std                 1.0689
trainer/Log Pis Max                 6.56376
trainer/Log Pis Min                -0.8728
trainer/Policy mu Mean              0.0222946
trainer/Policy mu Std               0.622432
trainer/Policy mu Max               2.7914
trainer/Policy mu Min              -3.13348
trainer/Policy log std Mean        -2.24285
trainer/Policy log std Std          0.446328
trainer/Policy log std Max         -0.516548
trainer/Policy log std Min         -2.96532
trainer/Alpha                       0.0807054
trainer/Alpha Loss                  0.72596
exploration/num steps total    316700
exploration/num paths total      3167
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.04779
exploration/Rewards Std             1.02566
exploration/Rewards Max            -0.0110288
exploration/Rewards Min            -5.59757
exploration/Returns Mean         -104.779
exploration/Returns Std            91.3536
exploration/Returns Max           -17.6851
exploration/Returns Min          -267.001
exploration/Actions Mean            0.00276068
exploration/Actions Std             0.169898
exploration/Actions Max             0.998948
exploration/Actions Min            -0.99245
exploration/Num Paths               5
exploration/Average Returns      -104.779
evaluation/num steps total     949500
evaluation/num paths total       9495
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.578211
evaluation/Rewards Std              1.03721
evaluation/Rewards Max             -0.00373122
evaluation/Rewards Min             -6.35855
evaluation/Returns Mean           -57.8211
evaluation/Returns Std             85.6138
evaluation/Returns Max             -5.00342
evaluation/Returns Min           -272.156
evaluation/Actions Mean             0.00802567
evaluation/Actions Std              0.152967
evaluation/Actions Max              0.995139
evaluation/Actions Min             -0.997975
evaluation/Num Paths               15
evaluation/Average Returns        -57.8211
time/data storing (s)               0.00261202
time/evaluation sampling (s)        0.31876
time/exploration sampling (s)       0.135038
time/logging (s)                    0.00485249
time/saving (s)                     0.0019315
time/training (s)                   1.98194
time/epoch (s)                      2.44514
time/total (s)                   1553.11
Epoch                             632
-----------------------------  ---------------
2019-04-23 01:39:29.231521 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 633 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    4.99844
trainer/QF2 Loss                    5.18268
trainer/Policy Loss                30.5427
trainer/Q1 Predictions Mean       -28.3849
trainer/Q1 Predictions Std         29.9133
trainer/Q1 Predictions Max         -7.44964
trainer/Q1 Predictions Min       -137.067
trainer/Q2 Predictions Mean       -28.3959
trainer/Q2 Predictions Std         29.9347
trainer/Q2 Predictions Max         -7.48177
trainer/Q2 Predictions Min       -137.094
trainer/Q Targets Mean            -28.2378
trainer/Q Targets Std              30.3434
trainer/Q Targets Max              -0.132553
trainer/Q Targets Min            -138.08
trainer/Log Pis Mean                2.1992
trainer/Log Pis Std                 1.00432
trainer/Log Pis Max                 6.4259
trainer/Log Pis Min                -0.583895
trainer/Policy mu Mean             -0.0476544
trainer/Policy mu Std               0.422275
trainer/Policy mu Max               2.53194
trainer/Policy mu Min              -3.1436
trainer/Policy log std Mean        -2.37604
trainer/Policy log std Std          0.361445
trainer/Policy log std Max         -0.600502
trainer/Policy log std Min         -2.89156
trainer/Alpha                       0.0817873
trainer/Alpha Loss                  0.498766
exploration/num steps total    317200
exploration/num paths total      3172
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.868442
exploration/Rewards Std             1.31607
exploration/Rewards Max            -0.0069179
exploration/Rewards Min            -8.88601
exploration/Returns Mean          -86.8442
exploration/Returns Std            99.878
exploration/Returns Max           -17.2387
exploration/Returns Min          -283.354
exploration/Actions Mean           -0.0198176
exploration/Actions Std             0.192497
exploration/Actions Max             0.948713
exploration/Actions Min            -0.999371
exploration/Num Paths               5
exploration/Average Returns       -86.8442
evaluation/num steps total     951000
evaluation/num paths total       9510
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.644024
evaluation/Rewards Std              1.20701
evaluation/Rewards Max             -0.0144065
evaluation/Rewards Min            -10.0497
evaluation/Returns Mean           -64.4024
evaluation/Returns Std             67.2742
evaluation/Returns Max             -6.5238
evaluation/Returns Min           -288.466
evaluation/Actions Mean             0.0256971
evaluation/Actions Std              0.174716
evaluation/Actions Max              0.999063
evaluation/Actions Min             -0.982045
evaluation/Num Paths               15
evaluation/Average Returns        -64.4024
time/data storing (s)               0.002636
time/evaluation sampling (s)        0.319959
time/exploration sampling (s)       0.138387
time/logging (s)                    0.00493921
time/saving (s)                     0.00195362
time/training (s)                   2.03206
time/epoch (s)                      2.49993
time/total (s)                   1555.61
Epoch                             633
-----------------------------  ---------------
2019-04-23 01:39:31.684249 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 634 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   56.6068
trainer/QF2 Loss                   56.3931
trainer/Policy Loss                29.631
trainer/Q1 Predictions Mean       -27.7481
trainer/Q1 Predictions Std         31.7344
trainer/Q1 Predictions Max         -7.42432
trainer/Q1 Predictions Min       -141.088
trainer/Q2 Predictions Mean       -27.7663
trainer/Q2 Predictions Std         31.7766
trainer/Q2 Predictions Max         -7.51321
trainer/Q2 Predictions Min       -141.254
trainer/Q Targets Mean            -26.7264
trainer/Q Targets Std              31.7775
trainer/Q Targets Max              -0.57297
trainer/Q Targets Min            -142.082
trainer/Log Pis Mean                1.94868
trainer/Log Pis Std                 1.12047
trainer/Log Pis Max                 5.40348
trainer/Log Pis Min                -2.30418
trainer/Policy mu Mean             -0.0196155
trainer/Policy mu Std               0.380028
trainer/Policy mu Max               2.39825
trainer/Policy mu Min              -2.17842
trainer/Policy log std Mean        -2.26582
trainer/Policy log std Std          0.347142
trainer/Policy log std Max         -0.782021
trainer/Policy log std Min         -2.87319
trainer/Alpha                       0.0832056
trainer/Alpha Loss                 -0.127594
exploration/num steps total    317700
exploration/num paths total      3177
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.537194
exploration/Rewards Std             0.760001
exploration/Rewards Max            -0.0115733
exploration/Rewards Min            -6.82492
exploration/Returns Mean          -53.7194
exploration/Returns Std            28.2182
exploration/Returns Max           -18.3016
exploration/Returns Min           -91.8127
exploration/Actions Mean            0.00155905
exploration/Actions Std             0.203841
exploration/Actions Max             0.991131
exploration/Actions Min            -0.998757
exploration/Num Paths               5
exploration/Average Returns       -53.7194
evaluation/num steps total     952500
evaluation/num paths total       9525
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.665778
evaluation/Rewards Std              1.11994
evaluation/Rewards Max             -0.0335142
evaluation/Rewards Min            -11.8615
evaluation/Returns Mean           -66.5778
evaluation/Returns Std             46.0508
evaluation/Returns Max            -17.6066
evaluation/Returns Min           -163.353
evaluation/Actions Mean             0.00188754
evaluation/Actions Std              0.195086
evaluation/Actions Max              0.99651
evaluation/Actions Min             -0.997645
evaluation/Num Paths               15
evaluation/Average Returns        -66.5778
time/data storing (s)               0.00269036
time/evaluation sampling (s)        0.327143
time/exploration sampling (s)       0.138304
time/logging (s)                    0.00446271
time/saving (s)                     0.00190517
time/training (s)                   1.96456
time/epoch (s)                      2.43906
time/total (s)                   1558.06
Epoch                             634
-----------------------------  ---------------
2019-04-23 01:39:34.196652 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 635 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.33428
trainer/QF2 Loss                    1.35414
trainer/Policy Loss                26.4014
trainer/Q1 Predictions Mean       -24.6931
trainer/Q1 Predictions Std         26.144
trainer/Q1 Predictions Max         -7.43498
trainer/Q1 Predictions Min       -136.773
trainer/Q2 Predictions Mean       -24.6846
trainer/Q2 Predictions Std         26.1454
trainer/Q2 Predictions Max         -7.46102
trainer/Q2 Predictions Min       -136.808
trainer/Q Targets Mean            -24.7009
trainer/Q Targets Std              26.2633
trainer/Q Targets Max              -0.385177
trainer/Q Targets Min            -137.299
trainer/Log Pis Mean                1.79194
trainer/Log Pis Std                 1.44286
trainer/Log Pis Max                 6.77337
trainer/Log Pis Min                -5.10068
trainer/Policy mu Mean             -0.0167135
trainer/Policy mu Std               0.443066
trainer/Policy mu Max               2.80422
trainer/Policy mu Min              -2.6354
trainer/Policy log std Mean        -2.26109
trainer/Policy log std Std          0.37819
trainer/Policy log std Max         -0.499855
trainer/Policy log std Min         -2.90928
trainer/Alpha                       0.0838157
trainer/Alpha Loss                 -0.515836
exploration/num steps total    318200
exploration/num paths total      3182
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.692267
exploration/Rewards Std             0.760557
exploration/Rewards Max            -0.155739
exploration/Rewards Min            -9.11772
exploration/Returns Mean          -69.2267
exploration/Returns Std             9.9485
exploration/Returns Max           -55.6688
exploration/Returns Min           -84.5672
exploration/Actions Mean           -0.0194143
exploration/Actions Std             0.195821
exploration/Actions Max             0.99061
exploration/Actions Min            -0.99928
exploration/Num Paths               5
exploration/Average Returns       -69.2267
evaluation/num steps total     954000
evaluation/num paths total       9540
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.715756
evaluation/Rewards Std              1.18395
evaluation/Rewards Max             -0.0183931
evaluation/Rewards Min             -8.78083
evaluation/Returns Mean           -71.5756
evaluation/Returns Std             85.4903
evaluation/Returns Max             -9.71998
evaluation/Returns Min           -282.39
evaluation/Actions Mean             0.0015386
evaluation/Actions Std              0.172787
evaluation/Actions Max              0.997716
evaluation/Actions Min             -0.994154
evaluation/Num Paths               15
evaluation/Average Returns        -71.5756
time/data storing (s)               0.00282647
time/evaluation sampling (s)        0.325354
time/exploration sampling (s)       0.138415
time/logging (s)                    0.00482746
time/saving (s)                     0.00193847
time/training (s)                   2.02917
time/epoch (s)                      2.50253
time/total (s)                   1560.56
Epoch                             635
-----------------------------  ---------------
2019-04-23 01:39:36.667972 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 636 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.125436
trainer/QF2 Loss                    0.151029
trainer/Policy Loss                33.0117
trainer/Q1 Predictions Mean       -31.0533
trainer/Q1 Predictions Std         37.3909
trainer/Q1 Predictions Max         -7.49569
trainer/Q1 Predictions Min       -138.173
trainer/Q2 Predictions Mean       -31.033
trainer/Q2 Predictions Std         37.3974
trainer/Q2 Predictions Max         -7.51873
trainer/Q2 Predictions Min       -138.117
trainer/Q Targets Mean            -31.2299
trainer/Q Targets Std              37.5349
trainer/Q Targets Max              -7.52863
trainer/Q Targets Min            -138.785
trainer/Log Pis Mean                2.02248
trainer/Log Pis Std                 1.15422
trainer/Log Pis Max                 5.00924
trainer/Log Pis Min                -2.40306
trainer/Policy mu Mean             -0.0397677
trainer/Policy mu Std               0.42249
trainer/Policy mu Max               2.29009
trainer/Policy mu Min              -3.19868
trainer/Policy log std Mean        -2.2677
trainer/Policy log std Std          0.355124
trainer/Policy log std Max         -0.523414
trainer/Policy log std Min         -2.89101
trainer/Alpha                       0.0850312
trainer/Alpha Loss                  0.055407
exploration/num steps total    318700
exploration/num paths total      3187
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.851755
exploration/Rewards Std             1.21175
exploration/Rewards Max            -0.0138044
exploration/Rewards Min            -8.51027
exploration/Returns Mean          -85.1755
exploration/Returns Std            90.8903
exploration/Returns Max           -19.5768
exploration/Returns Min          -265.059
exploration/Actions Mean            0.0170903
exploration/Actions Std             0.189702
exploration/Actions Max             0.997981
exploration/Actions Min            -0.997174
exploration/Num Paths               5
exploration/Average Returns       -85.1755
evaluation/num steps total     955500
evaluation/num paths total       9555
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.923184
evaluation/Rewards Std              1.25467
evaluation/Rewards Max             -0.0133069
evaluation/Rewards Min            -10.1135
evaluation/Returns Mean           -92.3184
evaluation/Returns Std             83.6991
evaluation/Returns Max            -14.3987
evaluation/Returns Min           -296.027
evaluation/Actions Mean            -0.0047418
evaluation/Actions Std              0.182345
evaluation/Actions Max              0.996099
evaluation/Actions Min             -0.997442
evaluation/Num Paths               15
evaluation/Average Returns        -92.3184
time/data storing (s)               0.00285958
time/evaluation sampling (s)        0.31937
time/exploration sampling (s)       0.137204
time/logging (s)                    0.00475661
time/saving (s)                     0.00192205
time/training (s)                   1.99166
time/epoch (s)                      2.45778
time/total (s)                   1563.03
Epoch                             636
-----------------------------  ---------------
2019-04-23 01:39:39.124188 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 637 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    7.1766
trainer/QF2 Loss                    7.20476
trainer/Policy Loss                25.0109
trainer/Q1 Predictions Mean       -23.2081
trainer/Q1 Predictions Std         27.1171
trainer/Q1 Predictions Max         -7.4672
trainer/Q1 Predictions Min       -135.718
trainer/Q2 Predictions Mean       -23.2245
trainer/Q2 Predictions Std         27.1058
trainer/Q2 Predictions Max         -7.49163
trainer/Q2 Predictions Min       -135.588
trainer/Q Targets Mean            -23.2865
trainer/Q Targets Std              27.7177
trainer/Q Targets Max              -0.459029
trainer/Q Targets Min            -138.242
trainer/Log Pis Mean                1.82058
trainer/Log Pis Std                 1.11575
trainer/Log Pis Max                 4.78347
trainer/Log Pis Min                -1.2033
trainer/Policy mu Mean              0.0258561
trainer/Policy mu Std               0.476636
trainer/Policy mu Max               2.7976
trainer/Policy mu Min              -2.26407
trainer/Policy log std Mean        -2.24999
trainer/Policy log std Std          0.373746
trainer/Policy log std Max         -0.61132
trainer/Policy log std Min         -2.85559
trainer/Alpha                       0.0859071
trainer/Alpha Loss                 -0.440377
exploration/num steps total    319200
exploration/num paths total      3192
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.625439
exploration/Rewards Std             1.21405
exploration/Rewards Max            -0.014693
exploration/Rewards Min            -9.7855
exploration/Returns Mean          -62.5439
exploration/Returns Std            48.4402
exploration/Returns Max           -19.2506
exploration/Returns Min          -154.28
exploration/Actions Mean            0.0140487
exploration/Actions Std             0.216243
exploration/Actions Max             0.999371
exploration/Actions Min            -0.997328
exploration/Num Paths               5
exploration/Average Returns       -62.5439
evaluation/num steps total     957000
evaluation/num paths total       9570
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.585085
evaluation/Rewards Std              1.02383
evaluation/Rewards Max             -0.0879404
evaluation/Rewards Min             -9.79224
evaluation/Returns Mean           -58.5085
evaluation/Returns Std             35.5849
evaluation/Returns Max            -21.7686
evaluation/Returns Min           -156.887
evaluation/Actions Mean            -0.00515397
evaluation/Actions Std              0.183163
evaluation/Actions Max              0.998492
evaluation/Actions Min             -0.996196
evaluation/Num Paths               15
evaluation/Average Returns        -58.5085
time/data storing (s)               0.00272286
time/evaluation sampling (s)        0.317832
time/exploration sampling (s)       0.13615
time/logging (s)                    0.00473526
time/saving (s)                     0.00191526
time/training (s)                   1.97974
time/epoch (s)                      2.44309
time/total (s)                   1565.47
Epoch                             637
-----------------------------  ---------------
2019-04-23 01:39:41.589712 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 638 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.21774
trainer/QF2 Loss                    1.07114
trainer/Policy Loss                37.5311
trainer/Q1 Predictions Mean       -35.5807
trainer/Q1 Predictions Std         41.593
trainer/Q1 Predictions Max         -7.50634
trainer/Q1 Predictions Min       -143.736
trainer/Q2 Predictions Mean       -35.568
trainer/Q2 Predictions Std         41.636
trainer/Q2 Predictions Max         -7.5211
trainer/Q2 Predictions Min       -143.986
trainer/Q Targets Mean            -36.1526
trainer/Q Targets Std              42.3679
trainer/Q Targets Max              -7.63368
trainer/Q Targets Min            -144.21
trainer/Log Pis Mean                1.9852
trainer/Log Pis Std                 1.29833
trainer/Log Pis Max                 5.68736
trainer/Log Pis Min                -3.22289
trainer/Policy mu Mean             -0.023397
trainer/Policy mu Std               0.607592
trainer/Policy mu Max               3.96954
trainer/Policy mu Min              -2.97577
trainer/Policy log std Mean        -2.23421
trainer/Policy log std Std          0.430746
trainer/Policy log std Max         -0.306045
trainer/Policy log std Min         -2.88514
trainer/Alpha                       0.0855433
trainer/Alpha Loss                 -0.0363985
exploration/num steps total    319700
exploration/num paths total      3197
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.969409
exploration/Rewards Std             1.12855
exploration/Rewards Max            -0.0306831
exploration/Rewards Min            -9.27289
exploration/Returns Mean          -96.9409
exploration/Returns Std            36.487
exploration/Returns Max           -50.6981
exploration/Returns Min          -145.444
exploration/Actions Mean            0.00152499
exploration/Actions Std             0.206514
exploration/Actions Max             0.996079
exploration/Actions Min            -0.998988
exploration/Num Paths               5
exploration/Average Returns       -96.9409
evaluation/num steps total     958500
evaluation/num paths total       9585
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.262217
evaluation/Rewards Std              0.833398
evaluation/Rewards Max             -0.00976471
evaluation/Rewards Min             -9.96956
evaluation/Returns Mean           -26.2217
evaluation/Returns Std             15.4975
evaluation/Returns Max             -7.22729
evaluation/Returns Min            -60.5617
evaluation/Actions Mean             0.00112354
evaluation/Actions Std              0.174315
evaluation/Actions Max              0.997597
evaluation/Actions Min             -0.996509
evaluation/Num Paths               15
evaluation/Average Returns        -26.2217
time/data storing (s)               0.00272408
time/evaluation sampling (s)        0.318092
time/exploration sampling (s)       0.136289
time/logging (s)                    0.00482744
time/saving (s)                     0.00193589
time/training (s)                   1.9886
time/epoch (s)                      2.45247
time/total (s)                   1567.93
Epoch                             638
-----------------------------  ---------------
2019-04-23 01:39:44.081164 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 639 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   12.8847
trainer/QF2 Loss                   12.7626
trainer/Policy Loss                27.6806
trainer/Q1 Predictions Mean       -25.6672
trainer/Q1 Predictions Std         27.1108
trainer/Q1 Predictions Max         -7.56985
trainer/Q1 Predictions Min       -135.65
trainer/Q2 Predictions Mean       -25.6723
trainer/Q2 Predictions Std         27.1083
trainer/Q2 Predictions Max         -7.58028
trainer/Q2 Predictions Min       -135.547
trainer/Q Targets Mean            -25.7861
trainer/Q Targets Std              27.5302
trainer/Q Targets Max              -0.473495
trainer/Q Targets Min            -137.06
trainer/Log Pis Mean                2.05866
trainer/Log Pis Std                 1.16062
trainer/Log Pis Max                 5.72405
trainer/Log Pis Min                -3.42217
trainer/Policy mu Mean             -0.0188621
trainer/Policy mu Std               0.417751
trainer/Policy mu Max               2.35004
trainer/Policy mu Min              -2.57045
trainer/Policy log std Mean        -2.30574
trainer/Policy log std Std          0.384564
trainer/Policy log std Max         -0.572884
trainer/Policy log std Min         -2.88201
trainer/Alpha                       0.0875701
trainer/Alpha Loss                  0.142844
exploration/num steps total    320200
exploration/num paths total      3202
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.582379
exploration/Rewards Std             1.29632
exploration/Rewards Max            -0.00854637
exploration/Rewards Min            -9.80146
exploration/Returns Mean          -58.2379
exploration/Returns Std            28.1722
exploration/Returns Max           -24.0063
exploration/Returns Min          -105.215
exploration/Actions Mean           -0.0257871
exploration/Actions Std             0.231826
exploration/Actions Max             0.99768
exploration/Actions Min            -0.999423
exploration/Num Paths               5
exploration/Average Returns       -58.2379
evaluation/num steps total     960000
evaluation/num paths total       9600
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.732986
evaluation/Rewards Std              1.0829
evaluation/Rewards Max             -0.0301028
evaluation/Rewards Min             -8.57603
evaluation/Returns Mean           -73.2986
evaluation/Returns Std             82.7411
evaluation/Returns Max             -9.53627
evaluation/Returns Min           -268.144
evaluation/Actions Mean             0.00617414
evaluation/Actions Std              0.156775
evaluation/Actions Max              0.997724
evaluation/Actions Min             -0.990823
evaluation/Num Paths               15
evaluation/Average Returns        -73.2986
time/data storing (s)               0.00263967
time/evaluation sampling (s)        0.344366
time/exploration sampling (s)       0.137613
time/logging (s)                    0.00479491
time/saving (s)                     0.00947803
time/training (s)                   1.97927
time/epoch (s)                      2.47816
time/total (s)                   1570.41
Epoch                             639
-----------------------------  ---------------
2019-04-23 01:39:46.543375 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 640 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   26.7
trainer/QF2 Loss                   26.7534
trainer/Policy Loss                26.8436
trainer/Q1 Predictions Mean       -24.9286
trainer/Q1 Predictions Std         26.1526
trainer/Q1 Predictions Max         -7.38966
trainer/Q1 Predictions Min       -134.706
trainer/Q2 Predictions Mean       -24.9345
trainer/Q2 Predictions Std         26.1731
trainer/Q2 Predictions Max         -7.45429
trainer/Q2 Predictions Min       -134.657
trainer/Q Targets Mean            -24.6981
trainer/Q Targets Std              26.7516
trainer/Q Targets Max              -0.741353
trainer/Q Targets Min            -136.546
trainer/Log Pis Mean                1.94002
trainer/Log Pis Std                 1.16559
trainer/Log Pis Max                 5.05012
trainer/Log Pis Min                -3.48981
trainer/Policy mu Mean             -0.0642139
trainer/Policy mu Std               0.361825
trainer/Policy mu Max               0.713391
trainer/Policy mu Min              -2.68404
trainer/Policy log std Mean        -2.28543
trainer/Policy log std Std          0.321293
trainer/Policy log std Max         -0.671582
trainer/Policy log std Min         -2.87271
trainer/Alpha                       0.0856795
trainer/Alpha Loss                 -0.147376
exploration/num steps total    320700
exploration/num paths total      3207
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.80993
exploration/Rewards Std             1.34639
exploration/Rewards Max            -0.0229031
exploration/Rewards Min            -9.11795
exploration/Returns Mean          -80.993
exploration/Returns Std            38.8
exploration/Returns Max           -47.887
exploration/Returns Min          -152.677
exploration/Actions Mean           -0.0125793
exploration/Actions Std             0.246883
exploration/Actions Max             0.998793
exploration/Actions Min            -0.999296
exploration/Num Paths               5
exploration/Average Returns       -80.993
evaluation/num steps total     961500
evaluation/num paths total       9615
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.579659
evaluation/Rewards Std              1.17515
evaluation/Rewards Max             -0.0226049
evaluation/Rewards Min             -9.98207
evaluation/Returns Mean           -57.9659
evaluation/Returns Std             63.6189
evaluation/Returns Max             -9.36942
evaluation/Returns Min           -273.157
evaluation/Actions Mean             0.00768857
evaluation/Actions Std              0.193995
evaluation/Actions Max              0.997544
evaluation/Actions Min             -0.998501
evaluation/Num Paths               15
evaluation/Average Returns        -57.9659
time/data storing (s)               0.00268972
time/evaluation sampling (s)        0.318058
time/exploration sampling (s)       0.138076
time/logging (s)                    0.00477204
time/saving (s)                     0.00194833
time/training (s)                   1.98325
time/epoch (s)                      2.44879
time/total (s)                   1572.87
Epoch                             640
-----------------------------  ---------------
2019-04-23 01:39:48.991771 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 641 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    2.00653
trainer/QF2 Loss                    1.95976
trainer/Policy Loss                29.703
trainer/Q1 Predictions Mean       -27.8318
trainer/Q1 Predictions Std         32.9856
trainer/Q1 Predictions Max         -7.59461
trainer/Q1 Predictions Min       -142.533
trainer/Q2 Predictions Mean       -27.8178
trainer/Q2 Predictions Std         33.0015
trainer/Q2 Predictions Max         -7.65853
trainer/Q2 Predictions Min       -142.043
trainer/Q Targets Mean            -27.585
trainer/Q Targets Std              32.9013
trainer/Q Targets Max              -0.0770776
trainer/Q Targets Min            -140.622
trainer/Log Pis Mean                1.87809
trainer/Log Pis Std                 1.48081
trainer/Log Pis Max                 6.76486
trainer/Log Pis Min                -5.72183
trainer/Policy mu Mean             -0.0864435
trainer/Policy mu Std               0.498446
trainer/Policy mu Max               2.56388
trainer/Policy mu Min              -3.66435
trainer/Policy log std Mean        -2.27134
trainer/Policy log std Std          0.384789
trainer/Policy log std Max         -0.342178
trainer/Policy log std Min         -2.91957
trainer/Alpha                       0.0850495
trainer/Alpha Loss                 -0.300456
exploration/num steps total    321200
exploration/num paths total      3212
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.923106
exploration/Rewards Std             1.312
exploration/Rewards Max            -0.023022
exploration/Rewards Min            -7.31473
exploration/Returns Mean          -92.3106
exploration/Returns Std           110.022
exploration/Returns Max           -18.5356
exploration/Returns Min          -310.986
exploration/Actions Mean           -0.0253246
exploration/Actions Std             0.209672
exploration/Actions Max             0.986853
exploration/Actions Min            -0.998767
exploration/Num Paths               5
exploration/Average Returns       -92.3106
evaluation/num steps total     963000
evaluation/num paths total       9630
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.902201
evaluation/Rewards Std              1.46129
evaluation/Rewards Max             -0.0276193
evaluation/Rewards Min            -10.8365
evaluation/Returns Mean           -90.2201
evaluation/Returns Std            100.39
evaluation/Returns Max            -12.0126
evaluation/Returns Min           -327.704
evaluation/Actions Mean             0.00868529
evaluation/Actions Std              0.187474
evaluation/Actions Max              0.998974
evaluation/Actions Min             -0.996528
evaluation/Num Paths               15
evaluation/Average Returns        -90.2201
time/data storing (s)               0.00257582
time/evaluation sampling (s)        0.315366
time/exploration sampling (s)       0.137608
time/logging (s)                    0.00383792
time/saving (s)                     0.00193761
time/training (s)                   1.97289
time/epoch (s)                      2.43422
time/total (s)                   1575.31
Epoch                             641
-----------------------------  ---------------
2019-04-23 01:39:51.450769 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 642 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                   14.6744
trainer/QF2 Loss                   14.5121
trainer/Policy Loss                39.1183
trainer/Q1 Predictions Mean       -37.121
trainer/Q1 Predictions Std         42.3425
trainer/Q1 Predictions Max         -7.66478
trainer/Q1 Predictions Min       -139.744
trainer/Q2 Predictions Mean       -37.1776
trainer/Q2 Predictions Std         42.3549
trainer/Q2 Predictions Max         -7.71465
trainer/Q2 Predictions Min       -140.277
trainer/Q Targets Mean            -36.9869
trainer/Q Targets Std              42.7207
trainer/Q Targets Max              -0.695133
trainer/Q Targets Min            -140.628
trainer/Log Pis Mean                2.01847
trainer/Log Pis Std                 1.0966
trainer/Log Pis Max                 5.14559
trainer/Log Pis Min                -1.06361
trainer/Policy mu Mean              0.0147294
trainer/Policy mu Std               0.398247
trainer/Policy mu Max               2.9474
trainer/Policy mu Min              -1.66613
trainer/Policy log std Mean        -2.33321
trainer/Policy log std Std          0.367051
trainer/Policy log std Max         -0.595721
trainer/Policy log std Min         -2.92347
trainer/Alpha                       0.0853631
trainer/Alpha Loss                  0.0454473
exploration/num steps total    321700
exploration/num paths total      3217
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.265277
exploration/Rewards Std             0.578822
exploration/Rewards Max            -0.0063821
exploration/Rewards Min            -6.67035
exploration/Returns Mean          -26.5277
exploration/Returns Std             7.72491
exploration/Returns Max           -17.6261
exploration/Returns Min           -38.9219
exploration/Actions Mean            0.00549202
exploration/Actions Std             0.191035
exploration/Actions Max             0.996532
exploration/Actions Min            -0.993708
exploration/Num Paths               5
exploration/Average Returns       -26.5277
evaluation/num steps total     964500
evaluation/num paths total       9645
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.389046
evaluation/Rewards Std              0.739985
evaluation/Rewards Max             -0.019724
evaluation/Rewards Min             -7.24128
evaluation/Returns Mean           -38.9046
evaluation/Returns Std             37.6253
evaluation/Returns Max             -8.79418
evaluation/Returns Min           -152.557
evaluation/Actions Mean             0.000305762
evaluation/Actions Std              0.158803
evaluation/Actions Max              0.994533
evaluation/Actions Min             -0.995796
evaluation/Num Paths               15
evaluation/Average Returns        -38.9046
time/data storing (s)               0.00271663
time/evaluation sampling (s)        0.313222
time/exploration sampling (s)       0.137102
time/logging (s)                    0.00477514
time/saving (s)                     0.00194485
time/training (s)                   1.98735
time/epoch (s)                      2.44711
time/total (s)                   1577.76
Epoch                             642
-----------------------------  ----------------
2019-04-23 01:39:53.925075 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 643 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.816802
trainer/QF2 Loss                    0.943914
trainer/Policy Loss                28.203
trainer/Q1 Predictions Mean       -26.1704
trainer/Q1 Predictions Std         31.7508
trainer/Q1 Predictions Max         -7.61455
trainer/Q1 Predictions Min       -140.414
trainer/Q2 Predictions Mean       -26.1702
trainer/Q2 Predictions Std         31.7168
trainer/Q2 Predictions Max         -7.57472
trainer/Q2 Predictions Min       -138.735
trainer/Q Targets Mean            -26.3021
trainer/Q Targets Std              31.9549
trainer/Q Targets Max              -0.190983
trainer/Q Targets Min            -139.352
trainer/Log Pis Mean                2.07347
trainer/Log Pis Std                 1.01393
trainer/Log Pis Max                 5.86322
trainer/Log Pis Min                -1.06365
trainer/Policy mu Mean             -0.0303452
trainer/Policy mu Std               0.438959
trainer/Policy mu Max               2.07649
trainer/Policy mu Min              -2.97799
trainer/Policy log std Mean        -2.27717
trainer/Policy log std Std          0.364621
trainer/Policy log std Max         -0.544136
trainer/Policy log std Min         -2.95654
trainer/Alpha                       0.0856913
trainer/Alpha Loss                  0.180526
exploration/num steps total    322200
exploration/num paths total      3222
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.306297
exploration/Rewards Std             0.722726
exploration/Rewards Max            -0.0105177
exploration/Rewards Min            -7.62239
exploration/Returns Mean          -30.6297
exploration/Returns Std             9.75686
exploration/Returns Max           -18.3363
exploration/Returns Min           -41.9762
exploration/Actions Mean            0.00761059
exploration/Actions Std             0.204437
exploration/Actions Max             0.995082
exploration/Actions Min            -0.992532
exploration/Num Paths               5
exploration/Average Returns       -30.6297
evaluation/num steps total     966000
evaluation/num paths total       9660
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.419253
evaluation/Rewards Std              0.913254
evaluation/Rewards Max             -0.0242252
evaluation/Rewards Min             -8.99699
evaluation/Returns Mean           -41.9253
evaluation/Returns Std             34.3033
evaluation/Returns Max             -8.30699
evaluation/Returns Min           -128.805
evaluation/Actions Mean            -0.00514869
evaluation/Actions Std              0.181729
evaluation/Actions Max              0.992334
evaluation/Actions Min             -0.997493
evaluation/Num Paths               15
evaluation/Average Returns        -41.9253
time/data storing (s)               0.00260787
time/evaluation sampling (s)        0.322884
time/exploration sampling (s)       0.138265
time/logging (s)                    0.00485476
time/saving (s)                     0.00153931
time/training (s)                   1.991
time/epoch (s)                      2.46115
time/total (s)                   1580.22
Epoch                             643
-----------------------------  ---------------
2019-04-23 01:39:56.379609 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 644 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.921122
trainer/QF2 Loss                    0.912044
trainer/Policy Loss                27.46
trainer/Q1 Predictions Mean       -25.551
trainer/Q1 Predictions Std         27.67
trainer/Q1 Predictions Max         -7.71201
trainer/Q1 Predictions Min       -132.678
trainer/Q2 Predictions Mean       -25.6124
trainer/Q2 Predictions Std         27.685
trainer/Q2 Predictions Max         -7.66853
trainer/Q2 Predictions Min       -132.726
trainer/Q Targets Mean            -25.7881
trainer/Q Targets Std              28.1383
trainer/Q Targets Max              -0.4209
trainer/Q Targets Min            -134.469
trainer/Log Pis Mean                1.94628
trainer/Log Pis Std                 1.33583
trainer/Log Pis Max                 4.56963
trainer/Log Pis Min                -3.65192
trainer/Policy mu Mean             -0.000199187
trainer/Policy mu Std               0.360929
trainer/Policy mu Max               2.38699
trainer/Policy mu Min              -3.02123
trainer/Policy log std Mean        -2.29399
trainer/Policy log std Std          0.330944
trainer/Policy log std Max         -0.606796
trainer/Policy log std Min         -2.99237
trainer/Alpha                       0.0848871
trainer/Alpha Loss                 -0.132491
exploration/num steps total    322700
exploration/num paths total      3227
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.483487
exploration/Rewards Std             1.00028
exploration/Rewards Max            -0.00858436
exploration/Rewards Min           -10.54
exploration/Returns Mean          -48.3487
exploration/Returns Std            41.2119
exploration/Returns Max           -22.9109
exploration/Returns Min          -130.012
exploration/Actions Mean            0.0309446
exploration/Actions Std             0.225843
exploration/Actions Max             0.997793
exploration/Actions Min            -0.826983
exploration/Num Paths               5
exploration/Average Returns       -48.3487
evaluation/num steps total     967500
evaluation/num paths total       9675
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.853764
evaluation/Rewards Std              1.24893
evaluation/Rewards Max             -0.0283552
evaluation/Rewards Min            -10.9597
evaluation/Returns Mean           -85.3764
evaluation/Returns Std             90.3129
evaluation/Returns Max            -16.3116
evaluation/Returns Min           -297.233
evaluation/Actions Mean            -0.00590876
evaluation/Actions Std              0.180396
evaluation/Actions Max              0.996117
evaluation/Actions Min             -0.998755
evaluation/Num Paths               15
evaluation/Average Returns        -85.3764
time/data storing (s)               0.00270912
time/evaluation sampling (s)        0.317074
time/exploration sampling (s)       0.138352
time/logging (s)                    0.00479395
time/saving (s)                     0.00191833
time/training (s)                   1.97727
time/epoch (s)                      2.44212
time/total (s)                   1582.67
Epoch                             644
-----------------------------  ----------------
2019-04-23 01:39:58.800405 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 645 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.199296
trainer/QF2 Loss                    0.120621
trainer/Policy Loss                32.0803
trainer/Q1 Predictions Mean       -30.1068
trainer/Q1 Predictions Std         34.6678
trainer/Q1 Predictions Max         -7.63715
trainer/Q1 Predictions Min       -139.813
trainer/Q2 Predictions Mean       -30.0744
trainer/Q2 Predictions Std         34.6163
trainer/Q2 Predictions Max         -7.56826
trainer/Q2 Predictions Min       -138.353
trainer/Q Targets Mean            -30.1782
trainer/Q Targets Std              34.642
trainer/Q Targets Max              -7.65216
trainer/Q Targets Min            -136.923
trainer/Log Pis Mean                2.07919
trainer/Log Pis Std                 1.11343
trainer/Log Pis Max                 6.1407
trainer/Log Pis Min                -1.52944
trainer/Policy mu Mean             -0.0464852
trainer/Policy mu Std               0.360673
trainer/Policy mu Max               2.25464
trainer/Policy mu Min              -2.92781
trainer/Policy log std Mean        -2.31916
trainer/Policy log std Std          0.304216
trainer/Policy log std Max         -0.578368
trainer/Policy log std Min         -2.79793
trainer/Alpha                       0.0848573
trainer/Alpha Loss                  0.19536
exploration/num steps total    323200
exploration/num paths total      3232
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.36079
exploration/Rewards Std             1.42205
exploration/Rewards Max            -0.022936
exploration/Rewards Min            -9.84964
exploration/Returns Mean         -136.079
exploration/Returns Std            97.2356
exploration/Returns Max           -31.6416
exploration/Returns Min          -312.715
exploration/Actions Mean           -0.0107104
exploration/Actions Std             0.243754
exploration/Actions Max             0.999139
exploration/Actions Min            -0.998233
exploration/Num Paths               5
exploration/Average Returns      -136.079
evaluation/num steps total     969000
evaluation/num paths total       9690
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.04327
evaluation/Rewards Std              1.45093
evaluation/Rewards Max             -0.00427082
evaluation/Rewards Min             -9.28446
evaluation/Returns Mean          -104.327
evaluation/Returns Std            114.292
evaluation/Returns Max             -7.22414
evaluation/Returns Min           -331.178
evaluation/Actions Mean            -0.0107594
evaluation/Actions Std              0.182296
evaluation/Actions Max              0.998819
evaluation/Actions Min             -0.997959
evaluation/Num Paths               15
evaluation/Average Returns       -104.327
time/data storing (s)               0.00257529
time/evaluation sampling (s)        0.318376
time/exploration sampling (s)       0.136095
time/logging (s)                    0.00475945
time/saving (s)                     0.00200794
time/training (s)                   1.94369
time/epoch (s)                      2.4075
time/total (s)                   1585.08
Epoch                             645
-----------------------------  ---------------
2019-04-23 01:40:01.258819 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 646 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    2.031
trainer/QF2 Loss                    2.03193
trainer/Policy Loss                32.2103
trainer/Q1 Predictions Mean       -30.345
trainer/Q1 Predictions Std         35.7391
trainer/Q1 Predictions Max         -7.69287
trainer/Q1 Predictions Min       -133.74
trainer/Q2 Predictions Mean       -30.31
trainer/Q2 Predictions Std         35.7145
trainer/Q2 Predictions Max         -7.68057
trainer/Q2 Predictions Min       -133.258
trainer/Q Targets Mean            -30.2534
trainer/Q Targets Std              35.9266
trainer/Q Targets Max              -0.102151
trainer/Q Targets Min            -133.479
trainer/Log Pis Mean                1.8988
trainer/Log Pis Std                 1.03074
trainer/Log Pis Max                 3.66046
trainer/Log Pis Min                -1.63743
trainer/Policy mu Mean             -0.0172501
trainer/Policy mu Std               0.389849
trainer/Policy mu Max               2.42589
trainer/Policy mu Min              -2.58121
trainer/Policy log std Mean        -2.29737
trainer/Policy log std Std          0.358422
trainer/Policy log std Max         -0.542721
trainer/Policy log std Min         -2.8978
trainer/Alpha                       0.0853958
trainer/Alpha Loss                 -0.248982
exploration/num steps total    323700
exploration/num paths total      3237
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.41724
exploration/Rewards Std             1.12196
exploration/Rewards Max            -0.0145832
exploration/Rewards Min            -9.29602
exploration/Returns Mean          -41.724
exploration/Returns Std            14.4294
exploration/Returns Max           -20.694
exploration/Returns Min           -64.279
exploration/Actions Mean            0.0096725
exploration/Actions Std             0.223444
exploration/Actions Max             0.99725
exploration/Actions Min            -0.998806
exploration/Num Paths               5
exploration/Average Returns       -41.724
evaluation/num steps total     970500
evaluation/num paths total       9705
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.611542
evaluation/Rewards Std              1.01776
evaluation/Rewards Max             -0.0370782
evaluation/Rewards Min             -8.66775
evaluation/Returns Mean           -61.1542
evaluation/Returns Std             75.3484
evaluation/Returns Max             -8.35775
evaluation/Returns Min           -297.472
evaluation/Actions Mean            -0.00360718
evaluation/Actions Std              0.165764
evaluation/Actions Max              0.997208
evaluation/Actions Min             -0.996888
evaluation/Num Paths               15
evaluation/Average Returns        -61.1542
time/data storing (s)               0.00283355
time/evaluation sampling (s)        0.326109
time/exploration sampling (s)       0.136909
time/logging (s)                    0.00453927
time/saving (s)                     0.00193997
time/training (s)                   1.97248
time/epoch (s)                      2.44481
time/total (s)                   1587.53
Epoch                             646
-----------------------------  ---------------
2019-04-23 01:40:03.737160 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 647 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.141487
trainer/QF2 Loss                    0.152778
trainer/Policy Loss                36.9905
trainer/Q1 Predictions Mean       -35.0965
trainer/Q1 Predictions Std         40.2158
trainer/Q1 Predictions Max         -7.73645
trainer/Q1 Predictions Min       -135.513
trainer/Q2 Predictions Mean       -35.0932
trainer/Q2 Predictions Std         40.2224
trainer/Q2 Predictions Max         -7.80781
trainer/Q2 Predictions Min       -134.775
trainer/Q Targets Mean            -35.1034
trainer/Q Targets Std              40.1351
trainer/Q Targets Max              -7.69735
trainer/Q Targets Min            -134.612
trainer/Log Pis Mean                1.98083
trainer/Log Pis Std                 1.15453
trainer/Log Pis Max                 3.96757
trainer/Log Pis Min                -1.61926
trainer/Policy mu Mean             -0.0114568
trainer/Policy mu Std               0.35455
trainer/Policy mu Max               2.62921
trainer/Policy mu Min              -2.39731
trainer/Policy log std Mean        -2.33783
trainer/Policy log std Std          0.313306
trainer/Policy log std Max         -0.810351
trainer/Policy log std Min         -2.9798
trainer/Alpha                       0.0873942
trainer/Alpha Loss                 -0.0467171
exploration/num steps total    324200
exploration/num paths total      3242
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.474265
exploration/Rewards Std             0.987384
exploration/Rewards Max            -0.0183595
exploration/Rewards Min           -11.0514
exploration/Returns Mean          -47.4265
exploration/Returns Std            25.2999
exploration/Returns Max           -17.0276
exploration/Returns Min           -86.3791
exploration/Actions Mean            0.0250071
exploration/Actions Std             0.207653
exploration/Actions Max             0.996467
exploration/Actions Min            -0.980805
exploration/Num Paths               5
exploration/Average Returns       -47.4265
evaluation/num steps total     972000
evaluation/num paths total       9720
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.569459
evaluation/Rewards Std              1.09457
evaluation/Rewards Max             -0.00816185
evaluation/Rewards Min             -9.0466
evaluation/Returns Mean           -56.9459
evaluation/Returns Std             41.8306
evaluation/Returns Max            -16.1453
evaluation/Returns Min           -164.053
evaluation/Actions Mean            -0.00405176
evaluation/Actions Std              0.196435
evaluation/Actions Max              0.997906
evaluation/Actions Min             -0.998799
evaluation/Num Paths               15
evaluation/Average Returns        -56.9459
time/data storing (s)               0.00274175
time/evaluation sampling (s)        0.315783
time/exploration sampling (s)       0.137557
time/logging (s)                    0.00353403
time/saving (s)                     0.00186672
time/training (s)                   2.00253
time/epoch (s)                      2.46402
time/total (s)                   1590
Epoch                             647
-----------------------------  ---------------
2019-04-23 01:40:06.200146 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 648 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.40865
trainer/QF2 Loss                    1.43394
trainer/Policy Loss                30.0659
trainer/Q1 Predictions Mean       -28.0198
trainer/Q1 Predictions Std         34.3036
trainer/Q1 Predictions Max         -7.77657
trainer/Q1 Predictions Min       -134.72
trainer/Q2 Predictions Mean       -27.9914
trainer/Q2 Predictions Std         34.2531
trainer/Q2 Predictions Max         -7.80379
trainer/Q2 Predictions Min       -134.426
trainer/Q Targets Mean            -27.9028
trainer/Q Targets Std              34.3869
trainer/Q Targets Max              -0.0705549
trainer/Q Targets Min            -134.531
trainer/Log Pis Mean                2.14601
trainer/Log Pis Std                 1.09952
trainer/Log Pis Max                 4.50875
trainer/Log Pis Min                -2.16161
trainer/Policy mu Mean             -0.0561842
trainer/Policy mu Std               0.426183
trainer/Policy mu Max               2.46831
trainer/Policy mu Min              -2.83584
trainer/Policy log std Mean        -2.24486
trainer/Policy log std Std          0.383972
trainer/Policy log std Max         -0.448667
trainer/Policy log std Min         -2.84702
trainer/Alpha                       0.0862102
trainer/Alpha Loss                  0.357874
exploration/num steps total    324700
exploration/num paths total      3247
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.90115
exploration/Rewards Std             1.1781
exploration/Rewards Max            -0.00569145
exploration/Rewards Min            -7.26727
exploration/Returns Mean          -90.115
exploration/Returns Std           100.74
exploration/Returns Max           -13.6168
exploration/Returns Min          -282.489
exploration/Actions Mean            0.0181121
exploration/Actions Std             0.192295
exploration/Actions Max             0.995383
exploration/Actions Min            -0.964147
exploration/Num Paths               5
exploration/Average Returns       -90.115
evaluation/num steps total     973500
evaluation/num paths total       9735
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.63621
evaluation/Rewards Std              1.29561
evaluation/Rewards Max             -0.0166446
evaluation/Rewards Min            -10.1729
evaluation/Returns Mean           -63.621
evaluation/Returns Std             66.8527
evaluation/Returns Max             -6.25659
evaluation/Returns Min           -302.653
evaluation/Actions Mean            -0.00378902
evaluation/Actions Std              0.190055
evaluation/Actions Max              0.998792
evaluation/Actions Min             -0.996265
evaluation/Num Paths               15
evaluation/Average Returns        -63.621
time/data storing (s)               0.00260853
time/evaluation sampling (s)        0.31888
time/exploration sampling (s)       0.137344
time/logging (s)                    0.00480117
time/saving (s)                     0.00154448
time/training (s)                   1.98647
time/epoch (s)                      2.45165
time/total (s)                   1592.45
Epoch                             648
-----------------------------  ---------------
2019-04-23 01:40:08.648568 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 649 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.49491
trainer/QF2 Loss                    0.485892
trainer/Policy Loss                31.8338
trainer/Q1 Predictions Mean       -29.7826
trainer/Q1 Predictions Std         34.0686
trainer/Q1 Predictions Max         -7.71197
trainer/Q1 Predictions Min       -132.653
trainer/Q2 Predictions Mean       -29.7945
trainer/Q2 Predictions Std         34.0503
trainer/Q2 Predictions Max         -7.6657
trainer/Q2 Predictions Min       -132.341
trainer/Q Targets Mean            -30.0647
trainer/Q Targets Std              34.5514
trainer/Q Targets Max              -7.73776
trainer/Q Targets Min            -134.05
trainer/Log Pis Mean                2.03805
trainer/Log Pis Std                 1.14496
trainer/Log Pis Max                 4.87355
trainer/Log Pis Min                -1.29399
trainer/Policy mu Mean             -0.0405395
trainer/Policy mu Std               0.503294
trainer/Policy mu Max               2.79754
trainer/Policy mu Min              -2.84275
trainer/Policy log std Mean        -2.25913
trainer/Policy log std Std          0.434346
trainer/Policy log std Max         -0.416322
trainer/Policy log std Min         -3.09412
trainer/Alpha                       0.0851205
trainer/Alpha Loss                  0.0937446
exploration/num steps total    325200
exploration/num paths total      3252
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.523916
exploration/Rewards Std             1.00587
exploration/Rewards Max            -0.0165014
exploration/Rewards Min            -8.76611
exploration/Returns Mean          -52.3916
exploration/Returns Std            22.3011
exploration/Returns Max           -17.8767
exploration/Returns Min           -86.9181
exploration/Actions Mean            0.0190288
exploration/Actions Std             0.218662
exploration/Actions Max             0.998753
exploration/Actions Min            -0.995279
exploration/Num Paths               5
exploration/Average Returns       -52.3916
evaluation/num steps total     975000
evaluation/num paths total       9750
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.780834
evaluation/Rewards Std              1.14574
evaluation/Rewards Max             -0.022419
evaluation/Rewards Min             -9.35352
evaluation/Returns Mean           -78.0834
evaluation/Returns Std             72.1251
evaluation/Returns Max             -7.87699
evaluation/Returns Min           -307.288
evaluation/Actions Mean            -0.000248298
evaluation/Actions Std              0.182624
evaluation/Actions Max              0.996598
evaluation/Actions Min             -0.995423
evaluation/Num Paths               15
evaluation/Average Returns        -78.0834
time/data storing (s)               0.00268185
time/evaluation sampling (s)        0.316368
time/exploration sampling (s)       0.13572
time/logging (s)                    0.00478569
time/saving (s)                     0.00195699
time/training (s)                   1.97556
time/epoch (s)                      2.43707
time/total (s)                   1594.9
Epoch                             649
-----------------------------  ----------------
2019-04-23 01:40:11.090230 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 650 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.00621
trainer/QF2 Loss                    1.04693
trainer/Policy Loss                34.3154
trainer/Q1 Predictions Mean       -32.3826
trainer/Q1 Predictions Std         35.7878
trainer/Q1 Predictions Max         -7.50753
trainer/Q1 Predictions Min       -131.794
trainer/Q2 Predictions Mean       -32.3799
trainer/Q2 Predictions Std         35.7822
trainer/Q2 Predictions Max         -7.56532
trainer/Q2 Predictions Min       -131.906
trainer/Q Targets Mean            -32.606
trainer/Q Targets Std              36.2728
trainer/Q Targets Max              -0.161268
trainer/Q Targets Min            -133.377
trainer/Log Pis Mean                2.01792
trainer/Log Pis Std                 1.23304
trainer/Log Pis Max                 6.9802
trainer/Log Pis Min                -2.05935
trainer/Policy mu Mean             -0.0507424
trainer/Policy mu Std               0.464686
trainer/Policy mu Max               3.07773
trainer/Policy mu Min              -3.08322
trainer/Policy log std Mean        -2.308
trainer/Policy log std Std          0.35091
trainer/Policy log std Max         -0.626351
trainer/Policy log std Min         -2.841
trainer/Alpha                       0.0854407
trainer/Alpha Loss                  0.0440863
exploration/num steps total    325700
exploration/num paths total      3257
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.267904
exploration/Rewards Std             0.223942
exploration/Rewards Max            -0.00861944
exploration/Rewards Min            -2.82099
exploration/Returns Mean          -26.7904
exploration/Returns Std            10.3081
exploration/Returns Max           -17.051
exploration/Returns Min           -45.2853
exploration/Actions Mean           -0.000576512
exploration/Actions Std             0.161365
exploration/Actions Max             0.977045
exploration/Actions Min            -0.937275
exploration/Num Paths               5
exploration/Average Returns       -26.7904
evaluation/num steps total     976500
evaluation/num paths total       9765
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.72537
evaluation/Rewards Std              1.36632
evaluation/Rewards Max             -0.0161997
evaluation/Rewards Min            -10.0853
evaluation/Returns Mean           -72.537
evaluation/Returns Std             94.4969
evaluation/Returns Max            -11.2534
evaluation/Returns Min           -317.259
evaluation/Actions Mean            -0.0198541
evaluation/Actions Std              0.190571
evaluation/Actions Max              0.994092
evaluation/Actions Min             -0.996415
evaluation/Num Paths               15
evaluation/Average Returns        -72.537
time/data storing (s)               0.00262951
time/evaluation sampling (s)        0.317457
time/exploration sampling (s)       0.136152
time/logging (s)                    0.00480624
time/saving (s)                     0.00193574
time/training (s)                   1.96714
time/epoch (s)                      2.43012
time/total (s)                   1597.33
Epoch                             650
-----------------------------  ----------------
2019-04-23 01:40:13.581532 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 651 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                  198.391
trainer/QF2 Loss                  197.932
trainer/Policy Loss                33.3637
trainer/Q1 Predictions Mean       -31.4321
trainer/Q1 Predictions Std         34.4949
trainer/Q1 Predictions Max         -7.36765
trainer/Q1 Predictions Min       -136.815
trainer/Q2 Predictions Mean       -31.4422
trainer/Q2 Predictions Std         34.4979
trainer/Q2 Predictions Max         -7.32911
trainer/Q2 Predictions Min       -136.737
trainer/Q Targets Mean            -29.9833
trainer/Q Targets Std              33.9
trainer/Q Targets Max              -0.199311
trainer/Q Targets Min            -140.304
trainer/Log Pis Mean                1.98734
trainer/Log Pis Std                 1.15432
trainer/Log Pis Max                 5.49344
trainer/Log Pis Min                -2.40748
trainer/Policy mu Mean             -0.0155184
trainer/Policy mu Std               0.371358
trainer/Policy mu Max               2.30044
trainer/Policy mu Min              -2.55105
trainer/Policy log std Mean        -2.26717
trainer/Policy log std Std          0.356286
trainer/Policy log std Max         -0.561829
trainer/Policy log std Min         -2.80426
trainer/Alpha                       0.0852288
trainer/Alpha Loss                 -0.0311794
exploration/num steps total    326200
exploration/num paths total      3262
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.03036
exploration/Rewards Std             1.55828
exploration/Rewards Max            -0.0136906
exploration/Rewards Min            -9.79992
exploration/Returns Mean         -103.036
exploration/Returns Std           108.556
exploration/Returns Max           -20.0886
exploration/Returns Min          -317.342
exploration/Actions Mean           -0.00372172
exploration/Actions Std             0.224352
exploration/Actions Max             0.999191
exploration/Actions Min            -0.99586
exploration/Num Paths               5
exploration/Average Returns      -103.036
evaluation/num steps total     978000
evaluation/num paths total       9780
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.780159
evaluation/Rewards Std              1.25622
evaluation/Rewards Max             -0.00345242
evaluation/Rewards Min            -11.6891
evaluation/Returns Mean           -78.0159
evaluation/Returns Std             68.5374
evaluation/Returns Max             -9.77936
evaluation/Returns Min           -280.73
evaluation/Actions Mean             0.00150702
evaluation/Actions Std              0.1935
evaluation/Actions Max              0.998354
evaluation/Actions Min             -0.997334
evaluation/Num Paths               15
evaluation/Average Returns        -78.0159
time/data storing (s)               0.00269023
time/evaluation sampling (s)        0.318191
time/exploration sampling (s)       0.134388
time/logging (s)                    0.00480357
time/saving (s)                     0.0095865
time/training (s)                   2.00821
time/epoch (s)                      2.47787
time/total (s)                   1599.81
Epoch                             651
-----------------------------  ---------------
2019-04-23 01:40:16.037442 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 652 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.377431
trainer/QF2 Loss                    0.381911
trainer/Policy Loss                31.2669
trainer/Q1 Predictions Mean       -29.3565
trainer/Q1 Predictions Std         33.6855
trainer/Q1 Predictions Max         -7.6262
trainer/Q1 Predictions Min       -130.452
trainer/Q2 Predictions Mean       -29.3686
trainer/Q2 Predictions Std         33.6947
trainer/Q2 Predictions Max         -7.71421
trainer/Q2 Predictions Min       -130.451
trainer/Q Targets Mean            -29.6475
trainer/Q Targets Std              34.1503
trainer/Q Targets Max              -7.7526
trainer/Q Targets Min            -132.425
trainer/Log Pis Mean                1.9216
trainer/Log Pis Std                 1.11157
trainer/Log Pis Max                 6.00997
trainer/Log Pis Min                -1.63273
trainer/Policy mu Mean              0.0447161
trainer/Policy mu Std               0.470075
trainer/Policy mu Max               2.93169
trainer/Policy mu Min              -2.61913
trainer/Policy log std Mean        -2.25733
trainer/Policy log std Std          0.358304
trainer/Policy log std Max         -0.607887
trainer/Policy log std Min         -2.90074
trainer/Alpha                       0.0832387
trainer/Alpha Loss                 -0.194896
exploration/num steps total    326700
exploration/num paths total      3267
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.412318
exploration/Rewards Std             0.984321
exploration/Rewards Max            -0.00468995
exploration/Rewards Min            -9.7937
exploration/Returns Mean          -41.2318
exploration/Returns Std            15.1639
exploration/Returns Max           -23.8546
exploration/Returns Min           -67.2692
exploration/Actions Mean            0.0308303
exploration/Actions Std             0.217546
exploration/Actions Max             0.999308
exploration/Actions Min            -0.995598
exploration/Num Paths               5
exploration/Average Returns       -41.2318
evaluation/num steps total     979500
evaluation/num paths total       9795
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.71363
evaluation/Rewards Std              1.08922
evaluation/Rewards Max             -0.014716
evaluation/Rewards Min             -8.56763
evaluation/Returns Mean           -71.363
evaluation/Returns Std             75.1147
evaluation/Returns Max             -4.59825
evaluation/Returns Min           -289.132
evaluation/Actions Mean             0.00555874
evaluation/Actions Std              0.160104
evaluation/Actions Max              0.998586
evaluation/Actions Min             -0.997298
evaluation/Num Paths               15
evaluation/Average Returns        -71.363
time/data storing (s)               0.00335198
time/evaluation sampling (s)        0.315733
time/exploration sampling (s)       0.136914
time/logging (s)                    0.00484853
time/saving (s)                     0.00193906
time/training (s)                   1.97981
time/epoch (s)                      2.4426
time/total (s)                   1602.26
Epoch                             652
-----------------------------  ---------------
2019-04-23 01:40:18.503875 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 653 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    2.1422
trainer/QF2 Loss                    2.21385
trainer/Policy Loss                31.9016
trainer/Q1 Predictions Mean       -29.8933
trainer/Q1 Predictions Std         32.5021
trainer/Q1 Predictions Max         -7.75084
trainer/Q1 Predictions Min       -133.55
trainer/Q2 Predictions Mean       -29.8957
trainer/Q2 Predictions Std         32.4929
trainer/Q2 Predictions Max         -7.72461
trainer/Q2 Predictions Min       -133.182
trainer/Q Targets Mean            -29.9817
trainer/Q Targets Std              32.8221
trainer/Q Targets Max              -0.299546
trainer/Q Targets Min            -134.637
trainer/Log Pis Mean                2.06874
trainer/Log Pis Std                 1.03112
trainer/Log Pis Max                 5.88096
trainer/Log Pis Min                -1.38562
trainer/Policy mu Mean             -0.00438949
trainer/Policy mu Std               0.416507
trainer/Policy mu Max               2.48502
trainer/Policy mu Min              -3.04748
trainer/Policy log std Mean        -2.30284
trainer/Policy log std Std          0.353945
trainer/Policy log std Max         -0.641885
trainer/Policy log std Min         -2.81698
trainer/Alpha                       0.0830007
trainer/Alpha Loss                  0.171084
exploration/num steps total    327200
exploration/num paths total      3272
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.479552
exploration/Rewards Std             1.31643
exploration/Rewards Max            -0.00807575
exploration/Rewards Min           -10.2853
exploration/Returns Mean          -47.9552
exploration/Returns Std            15.9981
exploration/Returns Max           -28.3521
exploration/Returns Min           -70.355
exploration/Actions Mean            0.0129007
exploration/Actions Std             0.246195
exploration/Actions Max             0.998012
exploration/Actions Min            -0.998976
exploration/Num Paths               5
exploration/Average Returns       -47.9552
evaluation/num steps total     981000
evaluation/num paths total       9810
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.517326
evaluation/Rewards Std              1.11458
evaluation/Rewards Max             -0.0138791
evaluation/Rewards Min             -9.80134
evaluation/Returns Mean           -51.7326
evaluation/Returns Std             43.708
evaluation/Returns Max             -3.59744
evaluation/Returns Min           -162.68
evaluation/Actions Mean            -0.00383954
evaluation/Actions Std              0.186586
evaluation/Actions Max              0.998085
evaluation/Actions Min             -0.998686
evaluation/Num Paths               15
evaluation/Average Returns        -51.7326
time/data storing (s)               0.00274237
time/evaluation sampling (s)        0.314958
time/exploration sampling (s)       0.136386
time/logging (s)                    0.00475281
time/saving (s)                     0.00195254
time/training (s)                   1.99299
time/epoch (s)                      2.45378
time/total (s)                   1604.72
Epoch                             653
-----------------------------  ---------------
2019-04-23 01:40:20.953048 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 654 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    2.44665
trainer/QF2 Loss                    2.45315
trainer/Policy Loss                29.633
trainer/Q1 Predictions Mean       -27.7024
trainer/Q1 Predictions Std         32.7229
trainer/Q1 Predictions Max         -7.50948
trainer/Q1 Predictions Min       -136.156
trainer/Q2 Predictions Mean       -27.7305
trainer/Q2 Predictions Std         32.7366
trainer/Q2 Predictions Max         -7.59314
trainer/Q2 Predictions Min       -136.932
trainer/Q Targets Mean            -27.7461
trainer/Q Targets Std              33.1727
trainer/Q Targets Max              -0.06193
trainer/Q Targets Min            -136.816
trainer/Log Pis Mean                1.99022
trainer/Log Pis Std                 1.10042
trainer/Log Pis Max                 6.6112
trainer/Log Pis Min                -1.8163
trainer/Policy mu Mean              0.00409016
trainer/Policy mu Std               0.399386
trainer/Policy mu Max               3.0421
trainer/Policy mu Min              -2.64028
trainer/Policy log std Mean        -2.29676
trainer/Policy log std Std          0.324078
trainer/Policy log std Max         -0.722942
trainer/Policy log std Min         -2.95039
trainer/Alpha                       0.0849692
trainer/Alpha Loss                 -0.024107
exploration/num steps total    327700
exploration/num paths total      3277
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.471694
exploration/Rewards Std             1.0779
exploration/Rewards Max            -0.0137209
exploration/Rewards Min            -9.87239
exploration/Returns Mean          -47.1694
exploration/Returns Std            15.7616
exploration/Returns Max           -29.8045
exploration/Returns Min           -75.7072
exploration/Actions Mean           -0.0315376
exploration/Actions Std             0.220765
exploration/Actions Max             0.983304
exploration/Actions Min            -0.998686
exploration/Num Paths               5
exploration/Average Returns       -47.1694
evaluation/num steps total     982500
evaluation/num paths total       9825
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.603449
evaluation/Rewards Std              1.00604
evaluation/Rewards Max             -0.0194518
evaluation/Rewards Min             -8.74484
evaluation/Returns Mean           -60.3449
evaluation/Returns Std             68.2649
evaluation/Returns Max             -7.63524
evaluation/Returns Min           -284.485
evaluation/Actions Mean             0.00595191
evaluation/Actions Std              0.166204
evaluation/Actions Max              0.998075
evaluation/Actions Min             -0.994276
evaluation/Num Paths               15
evaluation/Average Returns        -60.3449
time/data storing (s)               0.00269095
time/evaluation sampling (s)        0.317096
time/exploration sampling (s)       0.134302
time/logging (s)                    0.00478273
time/saving (s)                     0.00193199
time/training (s)                   1.97498
time/epoch (s)                      2.43578
time/total (s)                   1607.16
Epoch                             654
-----------------------------  ---------------
2019-04-23 01:40:23.412569 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 655 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.83572
trainer/QF2 Loss                    1.69441
trainer/Policy Loss                29.5089
trainer/Q1 Predictions Mean       -27.6187
trainer/Q1 Predictions Std         28.9218
trainer/Q1 Predictions Max         -7.69014
trainer/Q1 Predictions Min       -130.693
trainer/Q2 Predictions Mean       -27.6676
trainer/Q2 Predictions Std         28.9799
trainer/Q2 Predictions Max         -7.60359
trainer/Q2 Predictions Min       -130.732
trainer/Q Targets Mean            -28.1513
trainer/Q Targets Std              29.8044
trainer/Q Targets Max              -0.246796
trainer/Q Targets Min            -134.393
trainer/Log Pis Mean                1.88438
trainer/Log Pis Std                 1.02808
trainer/Log Pis Max                 3.38088
trainer/Log Pis Min                -1.06008
trainer/Policy mu Mean              0.0103394
trainer/Policy mu Std               0.276416
trainer/Policy mu Max               2.21136
trainer/Policy mu Min              -2.08936
trainer/Policy log std Mean        -2.31662
trainer/Policy log std Std          0.29754
trainer/Policy log std Max         -0.624252
trainer/Policy log std Min         -2.76745
trainer/Alpha                       0.0856505
trainer/Alpha Loss                 -0.284131
exploration/num steps total    328200
exploration/num paths total      3282
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.479103
exploration/Rewards Std             0.519338
exploration/Rewards Max            -0.00383069
exploration/Rewards Min            -4.87911
exploration/Returns Mean          -47.9103
exploration/Returns Std            25.4321
exploration/Returns Max           -18.1818
exploration/Returns Min           -84.4784
exploration/Actions Mean            0.00344637
exploration/Actions Std             0.181171
exploration/Actions Max             0.989887
exploration/Actions Min            -0.987722
exploration/Num Paths               5
exploration/Average Returns       -47.9103
evaluation/num steps total     984000
evaluation/num paths total       9840
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.819246
evaluation/Rewards Std              1.21893
evaluation/Rewards Max             -0.035208
evaluation/Rewards Min            -11.4255
evaluation/Returns Mean           -81.9246
evaluation/Returns Std             73.4608
evaluation/Returns Max             -6.84775
evaluation/Returns Min           -294.147
evaluation/Actions Mean            -5.33972e-05
evaluation/Actions Std              0.191802
evaluation/Actions Max              0.998707
evaluation/Actions Min             -0.997861
evaluation/Num Paths               15
evaluation/Average Returns        -81.9246
time/data storing (s)               0.00273556
time/evaluation sampling (s)        0.323435
time/exploration sampling (s)       0.134433
time/logging (s)                    0.0047861
time/saving (s)                     0.0019165
time/training (s)                   1.97866
time/epoch (s)                      2.44597
time/total (s)                   1609.61
Epoch                             655
-----------------------------  ----------------
2019-04-23 01:40:25.855091 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 656 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    4.89279
trainer/QF2 Loss                    4.94943
trainer/Policy Loss                29.8969
trainer/Q1 Predictions Mean       -27.8982
trainer/Q1 Predictions Std         29.8969
trainer/Q1 Predictions Max         -7.72108
trainer/Q1 Predictions Min       -134.397
trainer/Q2 Predictions Mean       -27.9081
trainer/Q2 Predictions Std         29.8296
trainer/Q2 Predictions Max         -7.68279
trainer/Q2 Predictions Min       -134.112
trainer/Q Targets Mean            -27.8352
trainer/Q Targets Std              30.2679
trainer/Q Targets Max              -0.295493
trainer/Q Targets Min            -135.851
trainer/Log Pis Mean                2.07843
trainer/Log Pis Std                 1.0837
trainer/Log Pis Max                 5.67462
trainer/Log Pis Min                -1.43008
trainer/Policy mu Mean              0.0175132
trainer/Policy mu Std               0.426556
trainer/Policy mu Max               3.17567
trainer/Policy mu Min              -1.99515
trainer/Policy log std Mean        -2.27458
trainer/Policy log std Std          0.327005
trainer/Policy log std Max         -0.575033
trainer/Policy log std Min         -2.9607
trainer/Alpha                       0.0840361
trainer/Alpha Loss                  0.194226
exploration/num steps total    328700
exploration/num paths total      3287
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.993124
exploration/Rewards Std             1.28418
exploration/Rewards Max            -0.0420001
exploration/Rewards Min            -9.54987
exploration/Returns Mean          -99.3124
exploration/Returns Std            97.1681
exploration/Returns Max           -23.1282
exploration/Returns Min          -291.159
exploration/Actions Mean            0.00806498
exploration/Actions Std             0.196962
exploration/Actions Max             0.99703
exploration/Actions Min            -0.997484
exploration/Num Paths               5
exploration/Average Returns       -99.3124
evaluation/num steps total     985500
evaluation/num paths total       9855
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.783844
evaluation/Rewards Std              1.13636
evaluation/Rewards Max             -0.0364112
evaluation/Rewards Min            -10.7063
evaluation/Returns Mean           -78.3844
evaluation/Returns Std             85.9011
evaluation/Returns Max             -8.34945
evaluation/Returns Min           -288.057
evaluation/Actions Mean             0.00522487
evaluation/Actions Std              0.15313
evaluation/Actions Max              0.997074
evaluation/Actions Min             -0.991374
evaluation/Num Paths               15
evaluation/Average Returns        -78.3844
time/data storing (s)               0.00275688
time/evaluation sampling (s)        0.321281
time/exploration sampling (s)       0.136399
time/logging (s)                    0.00476865
time/saving (s)                     0.00156848
time/training (s)                   1.96222
time/epoch (s)                      2.42899
time/total (s)                   1612.04
Epoch                             656
-----------------------------  ---------------
2019-04-23 01:40:28.320253 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 657 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    4.54651
trainer/QF2 Loss                    4.4532
trainer/Policy Loss                30.9133
trainer/Q1 Predictions Mean       -28.9534
trainer/Q1 Predictions Std         33.0605
trainer/Q1 Predictions Max         -7.8099
trainer/Q1 Predictions Min       -139.202
trainer/Q2 Predictions Mean       -28.9303
trainer/Q2 Predictions Std         32.9952
trainer/Q2 Predictions Max         -7.85644
trainer/Q2 Predictions Min       -138.574
trainer/Q Targets Mean            -28.8268
trainer/Q Targets Std              33.3129
trainer/Q Targets Max              -0.303411
trainer/Q Targets Min            -140.708
trainer/Log Pis Mean                1.99078
trainer/Log Pis Std                 1.02808
trainer/Log Pis Max                 5.02734
trainer/Log Pis Min                -1.13069
trainer/Policy mu Mean              0.0787261
trainer/Policy mu Std               0.502454
trainer/Policy mu Max               2.83058
trainer/Policy mu Min              -2.04493
trainer/Policy log std Mean        -2.27621
trainer/Policy log std Std          0.423348
trainer/Policy log std Max         -0.611861
trainer/Policy log std Min         -3.07378
trainer/Alpha                       0.0851822
trainer/Alpha Loss                 -0.0227016
exploration/num steps total    329200
exploration/num paths total      3292
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.989369
exploration/Rewards Std             1.60909
exploration/Rewards Max            -0.0174941
exploration/Rewards Min           -10.1666
exploration/Returns Mean          -98.9369
exploration/Returns Std           114.688
exploration/Returns Max           -24.1046
exploration/Returns Min          -325.655
exploration/Actions Mean           -0.0144133
exploration/Actions Std             0.226487
exploration/Actions Max             0.993665
exploration/Actions Min            -0.998083
exploration/Num Paths               5
exploration/Average Returns       -98.9369
evaluation/num steps total     987000
evaluation/num paths total       9870
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.742932
evaluation/Rewards Std              1.18142
evaluation/Rewards Max             -0.0167084
evaluation/Rewards Min             -8.35429
evaluation/Returns Mean           -74.2932
evaluation/Returns Std             96.5434
evaluation/Returns Max            -10.8054
evaluation/Returns Min           -307.587
evaluation/Actions Mean            -0.00627976
evaluation/Actions Std              0.161703
evaluation/Actions Max              0.995006
evaluation/Actions Min             -0.995653
evaluation/Num Paths               15
evaluation/Average Returns        -74.2932
time/data storing (s)               0.00274557
time/evaluation sampling (s)        0.325861
time/exploration sampling (s)       0.140673
time/logging (s)                    0.00416752
time/saving (s)                     0.00194065
time/training (s)                   1.97685
time/epoch (s)                      2.45224
time/total (s)                   1614.5
Epoch                             657
-----------------------------  ---------------
2019-04-23 01:40:30.781660 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 658 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.170925
trainer/QF2 Loss                    0.171712
trainer/Policy Loss                28.6316
trainer/Q1 Predictions Mean       -26.7026
trainer/Q1 Predictions Std         32.2414
trainer/Q1 Predictions Max         -7.67256
trainer/Q1 Predictions Min       -143.447
trainer/Q2 Predictions Mean       -26.7039
trainer/Q2 Predictions Std         32.2672
trainer/Q2 Predictions Max         -7.71477
trainer/Q2 Predictions Min       -143.4
trainer/Q Targets Mean            -26.7742
trainer/Q Targets Std              32.2867
trainer/Q Targets Max              -7.76235
trainer/Q Targets Min            -143.532
trainer/Log Pis Mean                1.94375
trainer/Log Pis Std                 1.15023
trainer/Log Pis Max                 4.88826
trainer/Log Pis Min                -1.73301
trainer/Policy mu Mean             -0.0611042
trainer/Policy mu Std               0.48977
trainer/Policy mu Max               2.37088
trainer/Policy mu Min              -3.19841
trainer/Policy log std Mean        -2.27181
trainer/Policy log std Std          0.405855
trainer/Policy log std Max         -0.374009
trainer/Policy log std Min         -3.00313
trainer/Alpha                       0.0873923
trainer/Alpha Loss                 -0.137101
exploration/num steps total    329700
exploration/num paths total      3297
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.924599
exploration/Rewards Std             1.21144
exploration/Rewards Max            -0.00839101
exploration/Rewards Min            -6.82814
exploration/Returns Mean          -92.4599
exploration/Returns Std           116.005
exploration/Returns Max           -15.5585
exploration/Returns Min          -318.652
exploration/Actions Mean           -0.0141277
exploration/Actions Std             0.184228
exploration/Actions Max             0.959939
exploration/Actions Min            -0.997979
exploration/Num Paths               5
exploration/Average Returns       -92.4599
evaluation/num steps total     988500
evaluation/num paths total       9885
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.840742
evaluation/Rewards Std              1.28807
evaluation/Rewards Max             -0.00533759
evaluation/Rewards Min            -10.1088
evaluation/Returns Mean           -84.0742
evaluation/Returns Std             95.7225
evaluation/Returns Max            -10.2868
evaluation/Returns Min           -314.617
evaluation/Actions Mean            -0.0041957
evaluation/Actions Std              0.176744
evaluation/Actions Max              0.99527
evaluation/Actions Min             -0.997802
evaluation/Num Paths               15
evaluation/Average Returns        -84.0742
time/data storing (s)               0.00303446
time/evaluation sampling (s)        0.318015
time/exploration sampling (s)       0.135626
time/logging (s)                    0.00476977
time/saving (s)                     0.00194219
time/training (s)                   1.98524
time/epoch (s)                      2.44862
time/total (s)                   1616.95
Epoch                             658
-----------------------------  ---------------
2019-04-23 01:40:33.227640 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 659 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.07556
trainer/QF2 Loss                    1.10092
trainer/Policy Loss                27.6629
trainer/Q1 Predictions Mean       -25.6881
trainer/Q1 Predictions Std         30.4574
trainer/Q1 Predictions Max         -7.60496
trainer/Q1 Predictions Min       -134.359
trainer/Q2 Predictions Mean       -25.6932
trainer/Q2 Predictions Std         30.5099
trainer/Q2 Predictions Max         -7.66646
trainer/Q2 Predictions Min       -134.315
trainer/Q Targets Mean            -25.999
trainer/Q Targets Std              30.9046
trainer/Q Targets Max              -0.134828
trainer/Q Targets Min            -136.614
trainer/Log Pis Mean                1.9822
trainer/Log Pis Std                 1.32687
trainer/Log Pis Max                 6.29129
trainer/Log Pis Min                -6.10172
trainer/Policy mu Mean              0.00786051
trainer/Policy mu Std               0.474581
trainer/Policy mu Max               2.85111
trainer/Policy mu Min              -2.56002
trainer/Policy log std Mean        -2.25154
trainer/Policy log std Std          0.365459
trainer/Policy log std Max         -0.366799
trainer/Policy log std Min         -3.0049
trainer/Alpha                       0.0871117
trainer/Alpha Loss                 -0.0434334
exploration/num steps total    330200
exploration/num paths total      3302
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.974604
exploration/Rewards Std             1.27475
exploration/Rewards Max            -0.0170995
exploration/Rewards Min            -8.8713
exploration/Returns Mean          -97.4604
exploration/Returns Std            96.0147
exploration/Returns Max           -27.8324
exploration/Returns Min          -284.382
exploration/Actions Mean            0.000438139
exploration/Actions Std             0.220898
exploration/Actions Max             0.998728
exploration/Actions Min            -0.997418
exploration/Num Paths               5
exploration/Average Returns       -97.4604
evaluation/num steps total     990000
evaluation/num paths total       9900
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.12955
evaluation/Rewards Std              1.38797
evaluation/Rewards Max             -0.0239289
evaluation/Rewards Min            -11.2146
evaluation/Returns Mean          -112.955
evaluation/Returns Std            108.25
evaluation/Returns Max            -12.1272
evaluation/Returns Min           -293.711
evaluation/Actions Mean            -0.00751574
evaluation/Actions Std              0.180723
evaluation/Actions Max              0.994292
evaluation/Actions Min             -0.997062
evaluation/Num Paths               15
evaluation/Average Returns       -112.955
time/data storing (s)               0.00264461
time/evaluation sampling (s)        0.319543
time/exploration sampling (s)       0.135237
time/logging (s)                    0.00478503
time/saving (s)                     0.00193613
time/training (s)                   1.96836
time/epoch (s)                      2.4325
time/total (s)                   1619.39
Epoch                             659
-----------------------------  ----------------
2019-04-23 01:40:35.679495 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 660 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.455638
trainer/QF2 Loss                    0.562602
trainer/Policy Loss                30.6211
trainer/Q1 Predictions Mean       -28.4497
trainer/Q1 Predictions Std         34.0502
trainer/Q1 Predictions Max         -7.75527
trainer/Q1 Predictions Min       -149.168
trainer/Q2 Predictions Mean       -28.4155
trainer/Q2 Predictions Std         33.9838
trainer/Q2 Predictions Max         -7.76383
trainer/Q2 Predictions Min       -146.881
trainer/Q Targets Mean            -28.7609
trainer/Q Targets Std              34.5509
trainer/Q Targets Max              -7.7778
trainer/Q Targets Min            -150.28
trainer/Log Pis Mean                2.20686
trainer/Log Pis Std                 1.17598
trainer/Log Pis Max                 6.46872
trainer/Log Pis Min                -1.82397
trainer/Policy mu Mean             -0.0461468
trainer/Policy mu Std               0.544117
trainer/Policy mu Max               2.50437
trainer/Policy mu Min              -3.0495
trainer/Policy log std Mean        -2.26328
trainer/Policy log std Std          0.423937
trainer/Policy log std Max         -0.510665
trainer/Policy log std Min         -3.07189
trainer/Alpha                       0.0871794
trainer/Alpha Loss                  0.50474
exploration/num steps total    330700
exploration/num paths total      3307
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.396022
exploration/Rewards Std             0.919177
exploration/Rewards Max            -0.0065452
exploration/Rewards Min            -8.16074
exploration/Returns Mean          -39.6022
exploration/Returns Std            10.0812
exploration/Returns Max           -22.6871
exploration/Returns Min           -51.213
exploration/Actions Mean            0.00911878
exploration/Actions Std             0.218836
exploration/Actions Max             0.997711
exploration/Actions Min            -0.999346
exploration/Num Paths               5
exploration/Average Returns       -39.6022
evaluation/num steps total     991500
evaluation/num paths total       9915
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.932167
evaluation/Rewards Std              1.19099
evaluation/Rewards Max             -0.0147931
evaluation/Rewards Min             -8.54835
evaluation/Returns Mean           -93.2167
evaluation/Returns Std             92.2402
evaluation/Returns Max            -11.209
evaluation/Returns Min           -292.913
evaluation/Actions Mean            -0.001381
evaluation/Actions Std              0.185076
evaluation/Actions Max              0.994486
evaluation/Actions Min             -0.994689
evaluation/Num Paths               15
evaluation/Average Returns        -93.2167
time/data storing (s)               0.00276908
time/evaluation sampling (s)        0.320154
time/exploration sampling (s)       0.136622
time/logging (s)                    0.00476134
time/saving (s)                     0.00192655
time/training (s)                   1.97209
time/epoch (s)                      2.43833
time/total (s)                   1621.83
Epoch                             660
-----------------------------  ---------------
2019-04-23 01:40:38.111358 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 661 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.595817
trainer/QF2 Loss                    0.51009
trainer/Policy Loss                32.5795
trainer/Q1 Predictions Mean       -30.4485
trainer/Q1 Predictions Std         33.73
trainer/Q1 Predictions Max         -7.94347
trainer/Q1 Predictions Min       -132.716
trainer/Q2 Predictions Mean       -30.5103
trainer/Q2 Predictions Std         33.7711
trainer/Q2 Predictions Max         -7.83708
trainer/Q2 Predictions Min       -132.836
trainer/Q Targets Mean            -30.719
trainer/Q Targets Std              34.3342
trainer/Q Targets Max              -7.81108
trainer/Q Targets Min            -134.842
trainer/Log Pis Mean                2.1455
trainer/Log Pis Std                 1.07006
trainer/Log Pis Max                 4.64846
trainer/Log Pis Min                -1.28334
trainer/Policy mu Mean              0.00433435
trainer/Policy mu Std               0.343107
trainer/Policy mu Max               3.45225
trainer/Policy mu Min              -1.94829
trainer/Policy log std Mean        -2.36488
trainer/Policy log std Std          0.320881
trainer/Policy log std Max         -0.643817
trainer/Policy log std Min         -3.14418
trainer/Alpha                       0.0869544
trainer/Alpha Loss                  0.355379
exploration/num steps total    331200
exploration/num paths total      3312
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.75696
exploration/Rewards Std             1.18398
exploration/Rewards Max            -0.00318127
exploration/Rewards Min            -9.48108
exploration/Returns Mean          -75.696
exploration/Returns Std            41.0665
exploration/Returns Max           -36.8792
exploration/Returns Min          -141.322
exploration/Actions Mean            0.0164898
exploration/Actions Std             0.222205
exploration/Actions Max             0.998915
exploration/Actions Min            -0.998732
exploration/Num Paths               5
exploration/Average Returns       -75.696
evaluation/num steps total     993000
evaluation/num paths total       9930
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.686996
evaluation/Rewards Std              1.20483
evaluation/Rewards Max             -0.0214636
evaluation/Rewards Min            -11.0503
evaluation/Returns Mean           -68.6996
evaluation/Returns Std             80.472
evaluation/Returns Max            -11.7554
evaluation/Returns Min           -342.367
evaluation/Actions Mean            -0.00342263
evaluation/Actions Std              0.187534
evaluation/Actions Max              0.998429
evaluation/Actions Min             -0.997453
evaluation/Num Paths               15
evaluation/Average Returns        -68.6996
time/data storing (s)               0.00278131
time/evaluation sampling (s)        0.315476
time/exploration sampling (s)       0.141183
time/logging (s)                    0.00353814
time/saving (s)                     0.00197014
time/training (s)                   1.95228
time/epoch (s)                      2.41723
time/total (s)                   1624.25
Epoch                             661
-----------------------------  ---------------
2019-04-23 01:40:40.550561 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 662 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.169075
trainer/QF2 Loss                    0.0925833
trainer/Policy Loss                26.9133
trainer/Q1 Predictions Mean       -24.6604
trainer/Q1 Predictions Std         27.3109
trainer/Q1 Predictions Max         -7.73434
trainer/Q1 Predictions Min       -135.851
trainer/Q2 Predictions Mean       -24.6791
trainer/Q2 Predictions Std         27.2954
trainer/Q2 Predictions Max         -7.76786
trainer/Q2 Predictions Min       -135.837
trainer/Q Targets Mean            -24.8166
trainer/Q Targets Std              27.3883
trainer/Q Targets Max              -7.82202
trainer/Q Targets Min            -136.44
trainer/Log Pis Mean                2.24406
trainer/Log Pis Std                 1.11451
trainer/Log Pis Max                 5.94355
trainer/Log Pis Min                -0.772106
trainer/Policy mu Mean              0.0402448
trainer/Policy mu Std               0.483022
trainer/Policy mu Max               3.05349
trainer/Policy mu Min              -2.87036
trainer/Policy log std Mean        -2.3204
trainer/Policy log std Std          0.417593
trainer/Policy log std Max         -0.472405
trainer/Policy log std Min         -3.14349
trainer/Alpha                       0.0874062
trainer/Alpha Loss                  0.594838
exploration/num steps total    331700
exploration/num paths total      3317
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.13954
exploration/Rewards Std             1.67231
exploration/Rewards Max            -0.00297539
exploration/Rewards Min           -10.7528
exploration/Returns Mean         -113.954
exploration/Returns Std           108.163
exploration/Returns Max           -26.1461
exploration/Returns Min          -326.623
exploration/Actions Mean            0.0188137
exploration/Actions Std             0.252988
exploration/Actions Max             0.999673
exploration/Actions Min            -0.997861
exploration/Num Paths               5
exploration/Average Returns      -113.954
evaluation/num steps total     994500
evaluation/num paths total       9945
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.687085
evaluation/Rewards Std              1.21148
evaluation/Rewards Max             -0.00801872
evaluation/Rewards Min            -10.9008
evaluation/Returns Mean           -68.7085
evaluation/Returns Std             80.1842
evaluation/Returns Max             -5.72228
evaluation/Returns Min           -324.206
evaluation/Actions Mean             0.000123181
evaluation/Actions Std              0.179411
evaluation/Actions Max              0.998045
evaluation/Actions Min             -0.997051
evaluation/Num Paths               15
evaluation/Average Returns        -68.7085
time/data storing (s)               0.00272432
time/evaluation sampling (s)        0.321953
time/exploration sampling (s)       0.135366
time/logging (s)                    0.00478429
time/saving (s)                     0.00156153
time/training (s)                   1.96115
time/epoch (s)                      2.42754
time/total (s)                   1626.68
Epoch                             662
-----------------------------  ----------------
2019-04-23 01:40:43.047665 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 663 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.56971
trainer/QF2 Loss                    0.632992
trainer/Policy Loss                33.9393
trainer/Q1 Predictions Mean       -31.8381
trainer/Q1 Predictions Std         37.3621
trainer/Q1 Predictions Max         -7.46687
trainer/Q1 Predictions Min       -134.025
trainer/Q2 Predictions Mean       -31.8237
trainer/Q2 Predictions Std         37.3184
trainer/Q2 Predictions Max         -7.50255
trainer/Q2 Predictions Min       -133.812
trainer/Q Targets Mean            -32.2956
trainer/Q Targets Std              37.8742
trainer/Q Targets Max              -7.82024
trainer/Q Targets Min            -136.223
trainer/Log Pis Mean                2.14696
trainer/Log Pis Std                 1.01453
trainer/Log Pis Max                 4.99934
trainer/Log Pis Min                -0.634463
trainer/Policy mu Mean             -0.0311517
trainer/Policy mu Std               0.340709
trainer/Policy mu Max               2.14995
trainer/Policy mu Min              -2.5479
trainer/Policy log std Mean        -2.3754
trainer/Policy log std Std          0.346821
trainer/Policy log std Max         -0.598835
trainer/Policy log std Min         -3.24856
trainer/Alpha                       0.0876365
trainer/Alpha Loss                  0.35781
exploration/num steps total    332200
exploration/num paths total      3322
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.04202
exploration/Rewards Std             1.66484
exploration/Rewards Max            -0.0169348
exploration/Rewards Min           -10.4045
exploration/Returns Mean         -104.202
exploration/Returns Std            98.0994
exploration/Returns Max           -47.6444
exploration/Returns Min          -300.077
exploration/Actions Mean            0.0401207
exploration/Actions Std             0.254346
exploration/Actions Max             0.998669
exploration/Actions Min            -0.995561
exploration/Num Paths               5
exploration/Average Returns      -104.202
evaluation/num steps total     996000
evaluation/num paths total       9960
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.540364
evaluation/Rewards Std              1.11048
evaluation/Rewards Max             -0.0119004
evaluation/Rewards Min             -9.09052
evaluation/Returns Mean           -54.0364
evaluation/Returns Std             70.2065
evaluation/Returns Max             -8.73976
evaluation/Returns Min           -304.73
evaluation/Actions Mean             0.00239233
evaluation/Actions Std              0.18027
evaluation/Actions Max              0.997631
evaluation/Actions Min             -0.996721
evaluation/Num Paths               15
evaluation/Average Returns        -54.0364
time/data storing (s)               0.00272233
time/evaluation sampling (s)        0.313718
time/exploration sampling (s)       0.138209
time/logging (s)                    0.0047966
time/saving (s)                     0.010985
time/training (s)                   2.01307
time/epoch (s)                      2.4835
time/total (s)                   1629.17
Epoch                             663
-----------------------------  ---------------
2019-04-23 01:40:45.504969 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 664 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    3.7679
trainer/QF2 Loss                    3.8489
trainer/Policy Loss                29.5334
trainer/Q1 Predictions Mean       -27.3304
trainer/Q1 Predictions Std         34.7407
trainer/Q1 Predictions Max         -7.73682
trainer/Q1 Predictions Min       -143.122
trainer/Q2 Predictions Mean       -27.3034
trainer/Q2 Predictions Std         34.7036
trainer/Q2 Predictions Max         -7.74825
trainer/Q2 Predictions Min       -141.697
trainer/Q Targets Mean            -27.2289
trainer/Q Targets Std              35.0226
trainer/Q Targets Max              -0.283304
trainer/Q Targets Min            -144.076
trainer/Log Pis Mean                2.23059
trainer/Log Pis Std                 1.10939
trainer/Log Pis Max                 6.32522
trainer/Log Pis Min                -0.976555
trainer/Policy mu Mean             -0.045617
trainer/Policy mu Std               0.528736
trainer/Policy mu Max               2.62238
trainer/Policy mu Min              -2.80048
trainer/Policy log std Mean        -2.29737
trainer/Policy log std Std          0.442968
trainer/Policy log std Max         -0.545985
trainer/Policy log std Min         -3.22165
trainer/Alpha                       0.0893144
trainer/Alpha Loss                  0.557037
exploration/num steps total    332700
exploration/num paths total      3327
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.20826
exploration/Rewards Std             1.35733
exploration/Rewards Max            -0.0376495
exploration/Rewards Min            -9.00271
exploration/Returns Mean         -120.826
exploration/Returns Std           100.921
exploration/Returns Max           -25.4629
exploration/Returns Min          -299.36
exploration/Actions Mean           -0.0356895
exploration/Actions Std             0.195967
exploration/Actions Max             0.740217
exploration/Actions Min            -0.998433
exploration/Num Paths               5
exploration/Average Returns      -120.826
evaluation/num steps total     997500
evaluation/num paths total       9975
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.681417
evaluation/Rewards Std              1.10823
evaluation/Rewards Max             -0.0300606
evaluation/Rewards Min             -8.11127
evaluation/Returns Mean           -68.1417
evaluation/Returns Std             94.4016
evaluation/Returns Max             -7.48618
evaluation/Returns Min           -313.917
evaluation/Actions Mean            -0.0153021
evaluation/Actions Std              0.153012
evaluation/Actions Max              0.994344
evaluation/Actions Min             -0.997947
evaluation/Num Paths               15
evaluation/Average Returns        -68.1417
time/data storing (s)               0.00254479
time/evaluation sampling (s)        0.318022
time/exploration sampling (s)       0.135065
time/logging (s)                    0.00477049
time/saving (s)                     0.00193446
time/training (s)                   1.98299
time/epoch (s)                      2.44533
time/total (s)                   1631.62
Epoch                             664
-----------------------------  ---------------
2019-04-23 01:40:47.957360 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 665 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0862807
trainer/QF2 Loss                    0.124914
trainer/Policy Loss                31.5918
trainer/Q1 Predictions Mean       -29.3732
trainer/Q1 Predictions Std         34.1402
trainer/Q1 Predictions Max         -7.80162
trainer/Q1 Predictions Min       -137.039
trainer/Q2 Predictions Mean       -29.3919
trainer/Q2 Predictions Std         34.1562
trainer/Q2 Predictions Max         -7.89891
trainer/Q2 Predictions Min       -137.063
trainer/Q Targets Mean            -29.3903
trainer/Q Targets Std              34.0787
trainer/Q Targets Max              -7.80961
trainer/Q Targets Min            -136.918
trainer/Log Pis Mean                2.26521
trainer/Log Pis Std                 1.33382
trainer/Log Pis Max                 8.29117
trainer/Log Pis Min                -1.12399
trainer/Policy mu Mean             -0.0542938
trainer/Policy mu Std               0.544
trainer/Policy mu Max               3.434
trainer/Policy mu Min              -3.78444
trainer/Policy log std Mean        -2.28507
trainer/Policy log std Std          0.420622
trainer/Policy log std Max         -0.254331
trainer/Policy log std Min         -3.21224
trainer/Alpha                       0.0902427
trainer/Alpha Loss                  0.637909
exploration/num steps total    333200
exploration/num paths total      3332
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.47752
exploration/Rewards Std             1.22294
exploration/Rewards Max            -0.0168504
exploration/Rewards Min            -9.64102
exploration/Returns Mean          -47.752
exploration/Returns Std            14.3635
exploration/Returns Max           -30.3362
exploration/Returns Min           -65.2973
exploration/Actions Mean           -0.0050869
exploration/Actions Std             0.242425
exploration/Actions Max             0.999235
exploration/Actions Min            -0.996531
exploration/Num Paths               5
exploration/Average Returns       -47.752
evaluation/num steps total     999000
evaluation/num paths total       9990
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.777712
evaluation/Rewards Std              1.27569
evaluation/Rewards Max             -0.0101005
evaluation/Rewards Min             -8.38279
evaluation/Returns Mean           -77.7712
evaluation/Returns Std             88.7249
evaluation/Returns Max             -4.59883
evaluation/Returns Min           -292.167
evaluation/Actions Mean            -0.0139005
evaluation/Actions Std              0.179315
evaluation/Actions Max              0.995285
evaluation/Actions Min             -0.994232
evaluation/Num Paths               15
evaluation/Average Returns        -77.7712
time/data storing (s)               0.00258681
time/evaluation sampling (s)        0.318145
time/exploration sampling (s)       0.139175
time/logging (s)                    0.00480647
time/saving (s)                     0.00194491
time/training (s)                   1.97405
time/epoch (s)                      2.44071
time/total (s)                   1634.06
Epoch                             665
-----------------------------  ---------------
2019-04-23 01:40:50.414791 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 666 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   12.8626
trainer/QF2 Loss                   12.8541
trainer/Policy Loss                30.2089
trainer/Q1 Predictions Mean       -28.4809
trainer/Q1 Predictions Std         33.2394
trainer/Q1 Predictions Max         -7.91806
trainer/Q1 Predictions Min       -138.617
trainer/Q2 Predictions Mean       -28.4591
trainer/Q2 Predictions Std         33.2214
trainer/Q2 Predictions Max         -7.97727
trainer/Q2 Predictions Min       -138.907
trainer/Q Targets Mean            -28.1996
trainer/Q Targets Std              33.3518
trainer/Q Targets Max              -0.665476
trainer/Q Targets Min            -138.417
trainer/Log Pis Mean                1.77829
trainer/Log Pis Std                 1.22565
trainer/Log Pis Max                 4.27824
trainer/Log Pis Min                -2.80751
trainer/Policy mu Mean              0.0124953
trainer/Policy mu Std               0.326174
trainer/Policy mu Max               2.42996
trainer/Policy mu Min              -2.3747
trainer/Policy log std Mean        -2.29423
trainer/Policy log std Std          0.329037
trainer/Policy log std Max         -0.661587
trainer/Policy log std Min         -3.08627
trainer/Alpha                       0.0883857
trainer/Alpha Loss                 -0.537853
exploration/num steps total    333700
exploration/num paths total      3337
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.604295
exploration/Rewards Std             1.38805
exploration/Rewards Max            -0.0123173
exploration/Rewards Min           -10.3514
exploration/Returns Mean          -60.4295
exploration/Returns Std            32.0902
exploration/Returns Max           -24.6108
exploration/Returns Min          -118.298
exploration/Actions Mean           -0.0130903
exploration/Actions Std             0.247506
exploration/Actions Max             0.998789
exploration/Actions Min            -0.999727
exploration/Num Paths               5
exploration/Average Returns       -60.4295
evaluation/num steps total          1.0005e+06
evaluation/num paths total      10005
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.830488
evaluation/Rewards Std              1.2752
evaluation/Rewards Max             -0.00880976
evaluation/Rewards Min             -9.78068
evaluation/Returns Mean           -83.0488
evaluation/Returns Std             70.9913
evaluation/Returns Max             -6.3631
evaluation/Returns Min           -276.741
evaluation/Actions Mean            -0.00580878
evaluation/Actions Std              0.19716
evaluation/Actions Max              0.999068
evaluation/Actions Min             -0.996231
evaluation/Num Paths               15
evaluation/Average Returns        -83.0488
time/data storing (s)               0.0026293
time/evaluation sampling (s)        0.324232
time/exploration sampling (s)       0.136161
time/logging (s)                    0.00477201
time/saving (s)                     0.00189625
time/training (s)                   1.97602
time/epoch (s)                      2.44571
time/total (s)                   1636.51
Epoch                             666
-----------------------------  ---------------
2019-04-23 01:40:52.896713 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 667 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   43.5909
trainer/QF2 Loss                   43.3924
trainer/Policy Loss                27.1598
trainer/Q1 Predictions Mean       -25.1705
trainer/Q1 Predictions Std         27.7924
trainer/Q1 Predictions Max         -7.87206
trainer/Q1 Predictions Min       -135.423
trainer/Q2 Predictions Mean       -25.1468
trainer/Q2 Predictions Std         27.7664
trainer/Q2 Predictions Max         -7.84335
trainer/Q2 Predictions Min       -135.258
trainer/Q Targets Mean            -24.331
trainer/Q Targets Std              28.322
trainer/Q Targets Max              -0.0944233
trainer/Q Targets Min            -137.125
trainer/Log Pis Mean                2.04175
trainer/Log Pis Std                 0.993123
trainer/Log Pis Max                 4.47845
trainer/Log Pis Min                -1.46073
trainer/Policy mu Mean             -0.00995842
trainer/Policy mu Std               0.470089
trainer/Policy mu Max               2.80099
trainer/Policy mu Min              -2.9263
trainer/Policy log std Mean        -2.25596
trainer/Policy log std Std          0.384038
trainer/Policy log std Max         -0.509667
trainer/Policy log std Min         -2.96781
trainer/Alpha                       0.0895772
trainer/Alpha Loss                  0.100745
exploration/num steps total    334200
exploration/num paths total      3342
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.860363
exploration/Rewards Std             1.38316
exploration/Rewards Max            -0.0149151
exploration/Rewards Min           -11.6682
exploration/Returns Mean          -86.0363
exploration/Returns Std            99.7971
exploration/Returns Max           -22.1262
exploration/Returns Min          -282.594
exploration/Actions Mean            0.0121082
exploration/Actions Std             0.208022
exploration/Actions Max             0.999082
exploration/Actions Min            -0.995876
exploration/Num Paths               5
exploration/Average Returns       -86.0363
evaluation/num steps total          1.002e+06
evaluation/num paths total      10020
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.610129
evaluation/Rewards Std              1.18257
evaluation/Rewards Max             -0.023741
evaluation/Rewards Min             -9.02206
evaluation/Returns Mean           -61.0129
evaluation/Returns Std             61.5867
evaluation/Returns Max            -22.8745
evaluation/Returns Min           -282.346
evaluation/Actions Mean            -0.00444656
evaluation/Actions Std              0.191627
evaluation/Actions Max              0.997798
evaluation/Actions Min             -0.99707
evaluation/Num Paths               15
evaluation/Average Returns        -61.0129
time/data storing (s)               0.00257526
time/evaluation sampling (s)        0.315879
time/exploration sampling (s)       0.136146
time/logging (s)                    0.0048124
time/saving (s)                     0.00194987
time/training (s)                   2.00688
time/epoch (s)                      2.46825
time/total (s)                   1638.99
Epoch                             667
-----------------------------  ---------------
2019-04-23 01:40:55.346390 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 668 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                  185.178
trainer/QF2 Loss                  183.069
trainer/Policy Loss                31.9887
trainer/Q1 Predictions Mean       -29.9469
trainer/Q1 Predictions Std         37.7689
trainer/Q1 Predictions Max         -7.67631
trainer/Q1 Predictions Min       -139.095
trainer/Q2 Predictions Mean       -29.9254
trainer/Q2 Predictions Std         37.7739
trainer/Q2 Predictions Max         -7.76289
trainer/Q2 Predictions Min       -138.76
trainer/Q Targets Mean            -28.6801
trainer/Q Targets Std              36.3242
trainer/Q Targets Max              -0.0939949
trainer/Q Targets Min            -138.226
trainer/Log Pis Mean                2.13835
trainer/Log Pis Std                 1.11525
trainer/Log Pis Max                 4.10629
trainer/Log Pis Min                -2.82866
trainer/Policy mu Mean              0.0368864
trainer/Policy mu Std               0.322463
trainer/Policy mu Max               2.28933
trainer/Policy mu Min              -2.81563
trainer/Policy log std Mean        -2.36361
trainer/Policy log std Std          0.363854
trainer/Policy log std Max         -0.675801
trainer/Policy log std Min         -3.1114
trainer/Alpha                       0.0902792
trainer/Alpha Loss                  0.33271
exploration/num steps total    334700
exploration/num paths total      3347
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.636636
exploration/Rewards Std             0.932722
exploration/Rewards Max            -0.0229743
exploration/Rewards Min            -8.73285
exploration/Returns Mean          -63.6636
exploration/Returns Std            24.7793
exploration/Returns Max           -24.6268
exploration/Returns Min           -96.3645
exploration/Actions Mean            0.0150181
exploration/Actions Std             0.194004
exploration/Actions Max             0.998464
exploration/Actions Min            -0.997633
exploration/Num Paths               5
exploration/Average Returns       -63.6636
evaluation/num steps total          1.0035e+06
evaluation/num paths total      10035
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.635587
evaluation/Rewards Std              1.18752
evaluation/Rewards Max             -0.0262077
evaluation/Rewards Min            -10.8367
evaluation/Returns Mean           -63.5587
evaluation/Returns Std             86.1882
evaluation/Returns Max             -9.63348
evaluation/Returns Min           -280.841
evaluation/Actions Mean             0.00560262
evaluation/Actions Std              0.172639
evaluation/Actions Max              0.997901
evaluation/Actions Min             -0.99444
evaluation/Num Paths               15
evaluation/Average Returns        -63.5587
time/data storing (s)               0.00259271
time/evaluation sampling (s)        0.320736
time/exploration sampling (s)       0.13582
time/logging (s)                    0.00351709
time/saving (s)                     0.0015819
time/training (s)                   1.97049
time/epoch (s)                      2.43474
time/total (s)                   1641.43
Epoch                             668
-----------------------------  ---------------
2019-04-23 01:40:57.793293 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 669 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    4.13682
trainer/QF2 Loss                    3.93665
trainer/Policy Loss                36.7307
trainer/Q1 Predictions Mean       -34.8536
trainer/Q1 Predictions Std         42.0006
trainer/Q1 Predictions Max         -7.81701
trainer/Q1 Predictions Min       -157.246
trainer/Q2 Predictions Mean       -34.8298
trainer/Q2 Predictions Std         42.0937
trainer/Q2 Predictions Max         -7.84528
trainer/Q2 Predictions Min       -159.127
trainer/Q Targets Mean            -34.7013
trainer/Q Targets Std              42.5314
trainer/Q Targets Max              -0.18784
trainer/Q Targets Min            -158.986
trainer/Log Pis Mean                1.90798
trainer/Log Pis Std                 1.42062
trainer/Log Pis Max                 7.52594
trainer/Log Pis Min                -2.59828
trainer/Policy mu Mean             -0.00295985
trainer/Policy mu Std               0.568488
trainer/Policy mu Max               2.56739
trainer/Policy mu Min              -2.78139
trainer/Policy log std Mean        -2.22667
trainer/Policy log std Std          0.434701
trainer/Policy log std Max         -0.466543
trainer/Policy log std Min         -3.08649
trainer/Alpha                       0.0909521
trainer/Alpha Loss                 -0.220603
exploration/num steps total    335200
exploration/num paths total      3352
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.432431
exploration/Rewards Std             0.97631
exploration/Rewards Max            -0.0130577
exploration/Rewards Min            -9.78911
exploration/Returns Mean          -43.2431
exploration/Returns Std            21.2794
exploration/Returns Max           -21.192
exploration/Returns Min           -74.4
exploration/Actions Mean            0.00251974
exploration/Actions Std             0.223205
exploration/Actions Max             0.996935
exploration/Actions Min            -0.996784
exploration/Num Paths               5
exploration/Average Returns       -43.2431
evaluation/num steps total          1.005e+06
evaluation/num paths total      10050
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.426939
evaluation/Rewards Std              0.689444
evaluation/Rewards Max             -0.012683
evaluation/Rewards Min             -6.77033
evaluation/Returns Mean           -42.6939
evaluation/Returns Std             43.9242
evaluation/Returns Max             -6.94063
evaluation/Returns Min           -150.035
evaluation/Actions Mean             0.0032831
evaluation/Actions Std              0.146629
evaluation/Actions Max              0.994073
evaluation/Actions Min             -0.994699
evaluation/Num Paths               15
evaluation/Average Returns        -42.6939
time/data storing (s)               0.00271614
time/evaluation sampling (s)        0.314378
time/exploration sampling (s)       0.137373
time/logging (s)                    0.00480265
time/saving (s)                     0.00193373
time/training (s)                   1.97475
time/epoch (s)                      2.43595
time/total (s)                   1643.87
Epoch                             669
-----------------------------  ---------------
2019-04-23 01:41:00.248943 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 670 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.861382
trainer/QF2 Loss                    0.834362
trainer/Policy Loss                26.836
trainer/Q1 Predictions Mean       -24.8316
trainer/Q1 Predictions Std         30.8713
trainer/Q1 Predictions Max         -7.91503
trainer/Q1 Predictions Min       -132.947
trainer/Q2 Predictions Mean       -24.796
trainer/Q2 Predictions Std         30.8908
trainer/Q2 Predictions Max         -7.79101
trainer/Q2 Predictions Min       -132.642
trainer/Q Targets Mean            -25.2415
trainer/Q Targets Std              31.6355
trainer/Q Targets Max              -7.91931
trainer/Q Targets Min            -136.442
trainer/Log Pis Mean                2.0354
trainer/Log Pis Std                 1.07963
trainer/Log Pis Max                 5.81581
trainer/Log Pis Min                -1.77312
trainer/Policy mu Mean             -0.00737424
trainer/Policy mu Std               0.305181
trainer/Policy mu Max               2.40655
trainer/Policy mu Min              -2.96528
trainer/Policy log std Mean        -2.31484
trainer/Policy log std Std          0.278389
trainer/Policy log std Max         -0.791716
trainer/Policy log std Min         -2.89756
trainer/Alpha                       0.0918965
trainer/Alpha Loss                  0.0845078
exploration/num steps total    335700
exploration/num paths total      3357
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.955815
exploration/Rewards Std             1.59262
exploration/Rewards Max            -0.011925
exploration/Rewards Min           -10.0654
exploration/Returns Mean          -95.5815
exploration/Returns Std           101
exploration/Returns Max           -17.3933
exploration/Returns Min          -295.126
exploration/Actions Mean           -0.0289575
exploration/Actions Std             0.221456
exploration/Actions Max             0.987484
exploration/Actions Min            -0.998305
exploration/Num Paths               5
exploration/Average Returns       -95.5815
evaluation/num steps total          1.0065e+06
evaluation/num paths total      10065
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.609228
evaluation/Rewards Std              1.14626
evaluation/Rewards Max             -0.00578885
evaluation/Rewards Min            -10.6527
evaluation/Returns Mean           -60.9228
evaluation/Returns Std             50.7531
evaluation/Returns Max             -6.01739
evaluation/Returns Min           -164.595
evaluation/Actions Mean             0.00442803
evaluation/Actions Std              0.192712
evaluation/Actions Max              0.99801
evaluation/Actions Min             -0.997057
evaluation/Num Paths               15
evaluation/Average Returns        -60.9228
time/data storing (s)               0.00259474
time/evaluation sampling (s)        0.31907
time/exploration sampling (s)       0.134485
time/logging (s)                    0.0047691
time/saving (s)                     0.00192745
time/training (s)                   1.97921
time/epoch (s)                      2.44206
time/total (s)                   1646.31
Epoch                             670
-----------------------------  ---------------
2019-04-23 01:41:02.713037 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 671 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.40023
trainer/QF2 Loss                    1.40318
trainer/Policy Loss                29.5615
trainer/Q1 Predictions Mean       -27.4786
trainer/Q1 Predictions Std         34.0367
trainer/Q1 Predictions Max         -7.98096
trainer/Q1 Predictions Min       -134.069
trainer/Q2 Predictions Mean       -27.4763
trainer/Q2 Predictions Std         34.0359
trainer/Q2 Predictions Max         -7.98445
trainer/Q2 Predictions Min       -133.882
trainer/Q Targets Mean            -27.6662
trainer/Q Targets Std              34.5031
trainer/Q Targets Max              -0.246804
trainer/Q Targets Min            -135.216
trainer/Log Pis Mean                2.06513
trainer/Log Pis Std                 1.02184
trainer/Log Pis Max                 4.21912
trainer/Log Pis Min                -2.33202
trainer/Policy mu Mean              0.040858
trainer/Policy mu Std               0.516003
trainer/Policy mu Max               2.87547
trainer/Policy mu Min              -3.14767
trainer/Policy log std Mean        -2.2918
trainer/Policy log std Std          0.431757
trainer/Policy log std Max         -0.414955
trainer/Policy log std Min         -3.13035
trainer/Alpha                       0.0921621
trainer/Alpha Loss                  0.155283
exploration/num steps total    336200
exploration/num paths total      3362
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.43085
exploration/Rewards Std             0.949441
exploration/Rewards Max            -0.00477961
exploration/Rewards Min            -9.63706
exploration/Returns Mean          -43.085
exploration/Returns Std            17.2263
exploration/Returns Max           -18.6987
exploration/Returns Min           -63.4294
exploration/Actions Mean            0.0217928
exploration/Actions Std             0.218192
exploration/Actions Max             0.999347
exploration/Actions Min            -0.999221
exploration/Num Paths               5
exploration/Average Returns       -43.085
evaluation/num steps total          1.008e+06
evaluation/num paths total      10080
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.737257
evaluation/Rewards Std              1.15311
evaluation/Rewards Max             -0.00319534
evaluation/Rewards Min             -8.96964
evaluation/Returns Mean           -73.7257
evaluation/Returns Std             74.8444
evaluation/Returns Max             -9.10428
evaluation/Returns Min           -266.942
evaluation/Actions Mean            -1.63231e-05
evaluation/Actions Std              0.176303
evaluation/Actions Max              0.997939
evaluation/Actions Min             -0.996636
evaluation/Num Paths               15
evaluation/Average Returns        -73.7257
time/data storing (s)               0.00283742
time/evaluation sampling (s)        0.319825
time/exploration sampling (s)       0.139641
time/logging (s)                    0.00439382
time/saving (s)                     0.00195325
time/training (s)                   1.98154
time/epoch (s)                      2.4502
time/total (s)                   1648.77
Epoch                             671
-----------------------------  ----------------
2019-04-23 01:41:05.180234 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 672 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    2.33156
trainer/QF2 Loss                    2.35803
trainer/Policy Loss                37.7212
trainer/Q1 Predictions Mean       -35.7969
trainer/Q1 Predictions Std         41.2909
trainer/Q1 Predictions Max         -7.94273
trainer/Q1 Predictions Min       -138.055
trainer/Q2 Predictions Mean       -35.7886
trainer/Q2 Predictions Std         41.2424
trainer/Q2 Predictions Max         -7.98689
trainer/Q2 Predictions Min       -137.92
trainer/Q Targets Mean            -35.8928
trainer/Q Targets Std              41.6584
trainer/Q Targets Max              -0.0584997
trainer/Q Targets Min            -137.119
trainer/Log Pis Mean                2.05281
trainer/Log Pis Std                 0.874188
trainer/Log Pis Max                 3.76583
trainer/Log Pis Min                -1.27399
trainer/Policy mu Mean             -0.0244107
trainer/Policy mu Std               0.322921
trainer/Policy mu Max               1.98289
trainer/Policy mu Min              -2.32087
trainer/Policy log std Mean        -2.26557
trainer/Policy log std Std          0.356962
trainer/Policy log std Max         -0.638893
trainer/Policy log std Min         -3.11823
trainer/Alpha                       0.0907582
trainer/Alpha Loss                  0.126713
exploration/num steps total    336700
exploration/num paths total      3367
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.43111
exploration/Rewards Std             1.01582
exploration/Rewards Max            -0.00982461
exploration/Rewards Min            -9.32732
exploration/Returns Mean          -43.111
exploration/Returns Std            18.0458
exploration/Returns Max           -16.1088
exploration/Returns Min           -72.8208
exploration/Actions Mean            0.0246771
exploration/Actions Std             0.19924
exploration/Actions Max             0.998509
exploration/Actions Min            -0.993721
exploration/Num Paths               5
exploration/Average Returns       -43.111
evaluation/num steps total          1.0095e+06
evaluation/num paths total      10095
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.950879
evaluation/Rewards Std              1.4234
evaluation/Rewards Max             -0.0475359
evaluation/Rewards Min            -11.3964
evaluation/Returns Mean           -95.0879
evaluation/Returns Std             90.3307
evaluation/Returns Max             -8.73229
evaluation/Returns Min           -286.514
evaluation/Actions Mean             0.00612683
evaluation/Actions Std              0.20264
evaluation/Actions Max              0.996741
evaluation/Actions Min             -0.998587
evaluation/Num Paths               15
evaluation/Average Returns        -95.0879
time/data storing (s)               0.00278045
time/evaluation sampling (s)        0.318616
time/exploration sampling (s)       0.136763
time/logging (s)                    0.00480741
time/saving (s)                     0.00155143
time/training (s)                   1.9898
time/epoch (s)                      2.45432
time/total (s)                   1651.23
Epoch                             672
-----------------------------  ---------------
2019-04-23 01:41:07.666042 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 673 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.104875
trainer/QF2 Loss                    0.0941576
trainer/Policy Loss                23.9339
trainer/Q1 Predictions Mean       -22.0881
trainer/Q1 Predictions Std         26.7449
trainer/Q1 Predictions Max         -7.86652
trainer/Q1 Predictions Min       -136.414
trainer/Q2 Predictions Mean       -22.0947
trainer/Q2 Predictions Std         26.7687
trainer/Q2 Predictions Max         -7.86887
trainer/Q2 Predictions Min       -136.274
trainer/Q Targets Mean            -22.2317
trainer/Q Targets Std              26.8069
trainer/Q Targets Max              -7.90257
trainer/Q Targets Min            -136.342
trainer/Log Pis Mean                1.86616
trainer/Log Pis Std                 1.31312
trainer/Log Pis Max                 6.20085
trainer/Log Pis Min                -3.49324
trainer/Policy mu Mean              0.0217054
trainer/Policy mu Std               0.355714
trainer/Policy mu Max               3.22309
trainer/Policy mu Min              -2.75505
trainer/Policy log std Mean        -2.3055
trainer/Policy log std Std          0.34539
trainer/Policy log std Max         -0.474822
trainer/Policy log std Min         -3.02859
trainer/Alpha                       0.0906167
trainer/Alpha Loss                 -0.321366
exploration/num steps total    337200
exploration/num paths total      3372
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.882228
exploration/Rewards Std             1.1559
exploration/Rewards Max            -0.0162118
exploration/Rewards Min            -8.51321
exploration/Returns Mean          -88.2228
exploration/Returns Std            85.74
exploration/Returns Max           -29.5919
exploration/Returns Min          -258.365
exploration/Actions Mean           -0.0240599
exploration/Actions Std             0.197522
exploration/Actions Max             0.990692
exploration/Actions Min            -0.999565
exploration/Num Paths               5
exploration/Average Returns       -88.2228
evaluation/num steps total          1.011e+06
evaluation/num paths total      10110
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.15386
evaluation/Rewards Std              1.44395
evaluation/Rewards Max             -0.0252437
evaluation/Rewards Min            -10.6489
evaluation/Returns Mean          -115.386
evaluation/Returns Std             86.2866
evaluation/Returns Max            -17.6472
evaluation/Returns Min           -280.736
evaluation/Actions Mean            -0.00870912
evaluation/Actions Std              0.201482
evaluation/Actions Max              0.998217
evaluation/Actions Min             -0.996985
evaluation/Num Paths               15
evaluation/Average Returns       -115.386
time/data storing (s)               0.00277241
time/evaluation sampling (s)        0.326537
time/exploration sampling (s)       0.137515
time/logging (s)                    0.00394107
time/saving (s)                     0.00192278
time/training (s)                   1.99868
time/epoch (s)                      2.47137
time/total (s)                   1653.7
Epoch                             673
-----------------------------  ---------------
2019-04-23 01:41:10.134283 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 674 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.703826
trainer/QF2 Loss                    0.689791
trainer/Policy Loss                33.3351
trainer/Q1 Predictions Mean       -31.2523
trainer/Q1 Predictions Std         38.3098
trainer/Q1 Predictions Max         -7.66652
trainer/Q1 Predictions Min       -134.376
trainer/Q2 Predictions Mean       -31.2437
trainer/Q2 Predictions Std         38.3292
trainer/Q2 Predictions Max         -7.70578
trainer/Q2 Predictions Min       -134.57
trainer/Q Targets Mean            -31.3018
trainer/Q Targets Std              38.4073
trainer/Q Targets Max              -0.102184
trainer/Q Targets Min            -134.904
trainer/Log Pis Mean                2.18923
trainer/Log Pis Std                 1.19821
trainer/Log Pis Max                 5.24759
trainer/Log Pis Min                -3.51352
trainer/Policy mu Mean              0.0165695
trainer/Policy mu Std               0.450385
trainer/Policy mu Max               2.50467
trainer/Policy mu Min              -2.78805
trainer/Policy log std Mean        -2.31063
trainer/Policy log std Std          0.423921
trainer/Policy log std Max         -0.62371
trainer/Policy log std Min         -3.14925
trainer/Alpha                       0.0886386
trainer/Alpha Loss                  0.458554
exploration/num steps total    337700
exploration/num paths total      3377
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.0645
exploration/Rewards Std             1.26371
exploration/Rewards Max            -0.00474165
exploration/Rewards Min            -8.58103
exploration/Returns Mean         -106.45
exploration/Returns Std            85.073
exploration/Returns Max           -34.0008
exploration/Returns Min          -267.774
exploration/Actions Mean            0.0243769
exploration/Actions Std             0.218596
exploration/Actions Max             0.999803
exploration/Actions Min            -0.99318
exploration/Num Paths               5
exploration/Average Returns      -106.45
evaluation/num steps total          1.0125e+06
evaluation/num paths total      10125
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.805809
evaluation/Rewards Std              1.23107
evaluation/Rewards Max             -0.0131767
evaluation/Rewards Min            -10.4065
evaluation/Returns Mean           -80.5809
evaluation/Returns Std             77.4389
evaluation/Returns Max            -14.8313
evaluation/Returns Min           -281.842
evaluation/Actions Mean            -0.0041512
evaluation/Actions Std              0.180408
evaluation/Actions Max              0.997481
evaluation/Actions Min             -0.996677
evaluation/Num Paths               15
evaluation/Average Returns        -80.5809
time/data storing (s)               0.00274717
time/evaluation sampling (s)        0.317953
time/exploration sampling (s)       0.137826
time/logging (s)                    0.00479459
time/saving (s)                     0.00193981
time/training (s)                   1.9902
time/epoch (s)                      2.45546
time/total (s)                   1656.16
Epoch                             674
-----------------------------  ---------------
2019-04-23 01:41:12.598582 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 675 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.15622
trainer/QF2 Loss                    1.25943
trainer/Policy Loss                26.5623
trainer/Q1 Predictions Mean       -24.5831
trainer/Q1 Predictions Std         30.1164
trainer/Q1 Predictions Max         -7.70188
trainer/Q1 Predictions Min       -133.009
trainer/Q2 Predictions Mean       -24.5462
trainer/Q2 Predictions Std         30.046
trainer/Q2 Predictions Max         -7.74441
trainer/Q2 Predictions Min       -132.807
trainer/Q Targets Mean            -24.744
trainer/Q Targets Std              30.4362
trainer/Q Targets Max              -0.181304
trainer/Q Targets Min            -133.514
trainer/Log Pis Mean                2.05158
trainer/Log Pis Std                 0.963045
trainer/Log Pis Max                 3.60111
trainer/Log Pis Min                -1.27701
trainer/Policy mu Mean              0.00146546
trainer/Policy mu Std               0.320129
trainer/Policy mu Max               2.50917
trainer/Policy mu Min              -2.84461
trainer/Policy log std Mean        -2.32506
trainer/Policy log std Std          0.284498
trainer/Policy log std Max         -0.684969
trainer/Policy log std Min         -2.99615
trainer/Alpha                       0.0881266
trainer/Alpha Loss                  0.125289
exploration/num steps total    338200
exploration/num paths total      3382
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.355169
exploration/Rewards Std             0.808271
exploration/Rewards Max            -0.0110189
exploration/Rewards Min            -7.69613
exploration/Returns Mean          -35.5169
exploration/Returns Std            14.9473
exploration/Returns Max           -19.8744
exploration/Returns Min           -54.1973
exploration/Actions Mean            0.0172597
exploration/Actions Std             0.204832
exploration/Actions Max             0.999973
exploration/Actions Min            -0.99193
exploration/Num Paths               5
exploration/Average Returns       -35.5169
evaluation/num steps total          1.014e+06
evaluation/num paths total      10140
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.922601
evaluation/Rewards Std              1.35326
evaluation/Rewards Max             -0.00849862
evaluation/Rewards Min            -11.8099
evaluation/Returns Mean           -92.2601
evaluation/Returns Std             85.968
evaluation/Returns Max            -16.6598
evaluation/Returns Min           -272.878
evaluation/Actions Mean             0.00751652
evaluation/Actions Std              0.189397
evaluation/Actions Max              0.999336
evaluation/Actions Min             -0.997062
evaluation/Num Paths               15
evaluation/Average Returns        -92.2601
time/data storing (s)               0.00261965
time/evaluation sampling (s)        0.320766
time/exploration sampling (s)       0.136131
time/logging (s)                    0.00479402
time/saving (s)                     0.00997409
time/training (s)                   1.97635
time/epoch (s)                      2.45064
time/total (s)                   1658.62
Epoch                             675
-----------------------------  ---------------
2019-04-23 01:41:15.035755 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 676 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    2.5691
trainer/QF2 Loss                    2.6013
trainer/Policy Loss                30.6637
trainer/Q1 Predictions Mean       -28.6521
trainer/Q1 Predictions Std         30.4982
trainer/Q1 Predictions Max         -7.66251
trainer/Q1 Predictions Min       -143.02
trainer/Q2 Predictions Mean       -28.6662
trainer/Q2 Predictions Std         30.5042
trainer/Q2 Predictions Max         -7.75606
trainer/Q2 Predictions Min       -143.241
trainer/Q Targets Mean            -28.3778
trainer/Q Targets Std              30.6191
trainer/Q Targets Max              -0.0887761
trainer/Q Targets Min            -143.118
trainer/Log Pis Mean                2.07811
trainer/Log Pis Std                 1.03725
trainer/Log Pis Max                 4.38059
trainer/Log Pis Min                -1.63072
trainer/Policy mu Mean             -0.0328896
trainer/Policy mu Std               0.432902
trainer/Policy mu Max               2.477
trainer/Policy mu Min              -2.5611
trainer/Policy log std Mean        -2.28795
trainer/Policy log std Std          0.388152
trainer/Policy log std Max         -0.479279
trainer/Policy log std Min         -2.90894
trainer/Alpha                       0.0900191
trainer/Alpha Loss                  0.188085
exploration/num steps total    338700
exploration/num paths total      3387
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.03965
exploration/Rewards Std             1.07799
exploration/Rewards Max            -0.0245793
exploration/Rewards Min            -7.48764
exploration/Returns Mean         -103.965
exploration/Returns Std            82.6954
exploration/Returns Max           -18.8904
exploration/Returns Min          -241.891
exploration/Actions Mean            0.012067
exploration/Actions Std             0.178402
exploration/Actions Max             0.997399
exploration/Actions Min            -0.97544
exploration/Num Paths               5
exploration/Average Returns      -103.965
evaluation/num steps total          1.0155e+06
evaluation/num paths total      10155
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.549344
evaluation/Rewards Std              1.00752
evaluation/Rewards Max             -0.00593221
evaluation/Rewards Min             -8.80708
evaluation/Returns Mean           -54.9344
evaluation/Returns Std             66.2463
evaluation/Returns Max             -5.05638
evaluation/Returns Min           -263.54
evaluation/Actions Mean             0.0047146
evaluation/Actions Std              0.163886
evaluation/Actions Max              0.995753
evaluation/Actions Min             -0.994264
evaluation/Num Paths               15
evaluation/Average Returns        -54.9344
time/data storing (s)               0.00315751
time/evaluation sampling (s)        0.31806
time/exploration sampling (s)       0.136588
time/logging (s)                    0.00475538
time/saving (s)                     0.00157014
time/training (s)                   1.95938
time/epoch (s)                      2.42351
time/total (s)                   1661.05
Epoch                             676
-----------------------------  ---------------
2019-04-23 01:41:17.483964 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 677 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    6.58814
trainer/QF2 Loss                    6.55445
trainer/Policy Loss                30.6648
trainer/Q1 Predictions Mean       -28.7255
trainer/Q1 Predictions Std         35.1806
trainer/Q1 Predictions Max         -7.6191
trainer/Q1 Predictions Min       -132.818
trainer/Q2 Predictions Mean       -28.7327
trainer/Q2 Predictions Std         35.1819
trainer/Q2 Predictions Max         -7.7297
trainer/Q2 Predictions Min       -132.821
trainer/Q Targets Mean            -28.3934
trainer/Q Targets Std              35.5392
trainer/Q Targets Max              -0.162153
trainer/Q Targets Min            -132.816
trainer/Log Pis Mean                2.08448
trainer/Log Pis Std                 1.33147
trainer/Log Pis Max                 5.36268
trainer/Log Pis Min                -4.28251
trainer/Policy mu Mean              0.0014258
trainer/Policy mu Std               0.444139
trainer/Policy mu Max               2.98096
trainer/Policy mu Min              -2.84215
trainer/Policy log std Mean        -2.29567
trainer/Policy log std Std          0.383999
trainer/Policy log std Max         -0.455387
trainer/Policy log std Min         -2.97093
trainer/Alpha                       0.09172
trainer/Alpha Loss                  0.201835
exploration/num steps total    339200
exploration/num paths total      3392
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.51649
exploration/Rewards Std             1.01003
exploration/Rewards Max            -0.000535143
exploration/Rewards Min            -8.81893
exploration/Returns Mean          -51.649
exploration/Returns Std            14.5962
exploration/Returns Max           -34.3125
exploration/Returns Min           -70.2274
exploration/Actions Mean            0.0261282
exploration/Actions Std             0.225954
exploration/Actions Max             0.997781
exploration/Actions Min            -0.996073
exploration/Num Paths               5
exploration/Average Returns       -51.649
evaluation/num steps total          1.017e+06
evaluation/num paths total      10170
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.535225
evaluation/Rewards Std              1.19658
evaluation/Rewards Max             -0.00314991
evaluation/Rewards Min            -11.0479
evaluation/Returns Mean           -53.5225
evaluation/Returns Std             56.4443
evaluation/Returns Max            -16.9362
evaluation/Returns Min           -245.165
evaluation/Actions Mean             0.00990745
evaluation/Actions Std              0.200484
evaluation/Actions Max              0.997594
evaluation/Actions Min             -0.996734
evaluation/Num Paths               15
evaluation/Average Returns        -53.5225
time/data storing (s)               0.00260933
time/evaluation sampling (s)        0.314456
time/exploration sampling (s)       0.13889
time/logging (s)                    0.00478264
time/saving (s)                     0.00154973
time/training (s)                   1.97295
time/epoch (s)                      2.43524
time/total (s)                   1663.48
Epoch                             677
-----------------------------  ----------------
2019-04-23 01:41:19.924569 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 678 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.24183
trainer/QF2 Loss                    1.24186
trainer/Policy Loss                27.6061
trainer/Q1 Predictions Mean       -25.7942
trainer/Q1 Predictions Std         29.8707
trainer/Q1 Predictions Max         -7.54324
trainer/Q1 Predictions Min       -129.011
trainer/Q2 Predictions Mean       -25.7475
trainer/Q2 Predictions Std         29.8718
trainer/Q2 Predictions Max         -7.51208
trainer/Q2 Predictions Min       -128.542
trainer/Q Targets Mean            -26.1773
trainer/Q Targets Std              30.5267
trainer/Q Targets Max              -0.17888
trainer/Q Targets Min            -131.203
trainer/Log Pis Mean                1.90486
trainer/Log Pis Std                 1.40726
trainer/Log Pis Max                 7.48227
trainer/Log Pis Min                -2.28039
trainer/Policy mu Mean              0.0791881
trainer/Policy mu Std               0.504918
trainer/Policy mu Max               3.33214
trainer/Policy mu Min              -1.56259
trainer/Policy log std Mean        -2.23002
trainer/Policy log std Std          0.409146
trainer/Policy log std Max         -0.615495
trainer/Policy log std Min         -2.92009
trainer/Alpha                       0.0909348
trainer/Alpha Loss                 -0.228109
exploration/num steps total    339700
exploration/num paths total      3397
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.833709
exploration/Rewards Std             1.09484
exploration/Rewards Max            -0.00884385
exploration/Rewards Min            -8.57168
exploration/Returns Mean          -83.3709
exploration/Returns Std            77.8507
exploration/Returns Max           -19.0282
exploration/Returns Min          -231.536
exploration/Actions Mean           -0.0105707
exploration/Actions Std             0.203549
exploration/Actions Max             0.99857
exploration/Actions Min            -0.998152
exploration/Num Paths               5
exploration/Average Returns       -83.3709
evaluation/num steps total          1.0185e+06
evaluation/num paths total      10185
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.963495
evaluation/Rewards Std              1.37006
evaluation/Rewards Max             -0.0483621
evaluation/Rewards Min            -10.9345
evaluation/Returns Mean           -96.3495
evaluation/Returns Std             78.3048
evaluation/Returns Max             -9.73617
evaluation/Returns Min           -242.95
evaluation/Actions Mean            -0.0138799
evaluation/Actions Std              0.203568
evaluation/Actions Max              0.993323
evaluation/Actions Min             -0.998077
evaluation/Num Paths               15
evaluation/Average Returns        -96.3495
time/data storing (s)               0.0026042
time/evaluation sampling (s)        0.3155
time/exploration sampling (s)       0.135731
time/logging (s)                    0.00482308
time/saving (s)                     0.00195711
time/training (s)                   1.96741
time/epoch (s)                      2.42802
time/total (s)                   1665.92
Epoch                             678
-----------------------------  ---------------
2019-04-23 01:41:22.391355 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 679 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.35697
trainer/QF2 Loss                    1.35744
trainer/Policy Loss                31.0003
trainer/Q1 Predictions Mean       -29.0426
trainer/Q1 Predictions Std         32.8261
trainer/Q1 Predictions Max         -7.40201
trainer/Q1 Predictions Min       -139.318
trainer/Q2 Predictions Mean       -29.0436
trainer/Q2 Predictions Std         32.8014
trainer/Q2 Predictions Max         -7.54144
trainer/Q2 Predictions Min       -139.255
trainer/Q Targets Mean            -29.2781
trainer/Q Targets Std              33.1256
trainer/Q Targets Max              -0.266513
trainer/Q Targets Min            -139.151
trainer/Log Pis Mean                2.03045
trainer/Log Pis Std                 1.14476
trainer/Log Pis Max                 6.4882
trainer/Log Pis Min                -0.878747
trainer/Policy mu Mean              0.0524819
trainer/Policy mu Std               0.501054
trainer/Policy mu Max               2.83769
trainer/Policy mu Min              -2.38136
trainer/Policy log std Mean        -2.31315
trainer/Policy log std Std          0.382058
trainer/Policy log std Max         -0.632024
trainer/Policy log std Min         -2.97525
trainer/Alpha                       0.0894701
trainer/Alpha Loss                  0.073492
exploration/num steps total    340200
exploration/num paths total      3402
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.17125
exploration/Rewards Std             1.31323
exploration/Rewards Max            -0.0339709
exploration/Rewards Min           -10.4026
exploration/Returns Mean         -117.125
exploration/Returns Std            73.052
exploration/Returns Max           -36.5859
exploration/Returns Min          -230.432
exploration/Actions Mean           -0.00468402
exploration/Actions Std             0.241712
exploration/Actions Max             0.99584
exploration/Actions Min            -0.997743
exploration/Num Paths               5
exploration/Average Returns      -117.125
evaluation/num steps total          1.02e+06
evaluation/num paths total      10200
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.352158
evaluation/Rewards Std              0.910586
evaluation/Rewards Max             -0.0278736
evaluation/Rewards Min             -9.24781
evaluation/Returns Mean           -35.2158
evaluation/Returns Std             18.2151
evaluation/Returns Max             -7.15145
evaluation/Returns Min            -67.3039
evaluation/Actions Mean            -0.00646942
evaluation/Actions Std              0.174629
evaluation/Actions Max              0.993537
evaluation/Actions Min             -0.998042
evaluation/Num Paths               15
evaluation/Average Returns        -35.2158
time/data storing (s)               0.00260265
time/evaluation sampling (s)        0.326505
time/exploration sampling (s)       0.135786
time/logging (s)                    0.00480354
time/saving (s)                     0.00193385
time/training (s)                   1.98328
time/epoch (s)                      2.45492
time/total (s)                   1668.38
Epoch                             679
-----------------------------  ---------------
2019-04-23 01:41:24.837754 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 680 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.55255
trainer/QF2 Loss                    1.28705
trainer/Policy Loss                32.3444
trainer/Q1 Predictions Mean       -30.396
trainer/Q1 Predictions Std         34.1729
trainer/Q1 Predictions Max         -7.59383
trainer/Q1 Predictions Min       -126.904
trainer/Q2 Predictions Mean       -30.4785
trainer/Q2 Predictions Std         34.2433
trainer/Q2 Predictions Max         -7.55373
trainer/Q2 Predictions Min       -127.119
trainer/Q Targets Mean            -30.8615
trainer/Q Targets Std              34.8818
trainer/Q Targets Max              -0.482006
trainer/Q Targets Min            -129.444
trainer/Log Pis Mean                1.97798
trainer/Log Pis Std                 1.21288
trainer/Log Pis Max                 4.09769
trainer/Log Pis Min                -2.29559
trainer/Policy mu Mean             -0.0360403
trainer/Policy mu Std               0.416357
trainer/Policy mu Max               2.69249
trainer/Policy mu Min              -2.63471
trainer/Policy log std Mean        -2.32406
trainer/Policy log std Std          0.377924
trainer/Policy log std Max         -0.60268
trainer/Policy log std Min         -3.07767
trainer/Alpha                       0.0885085
trainer/Alpha Loss                 -0.0533972
exploration/num steps total    340700
exploration/num paths total      3407
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.509227
exploration/Rewards Std             0.922185
exploration/Rewards Max            -0.0246304
exploration/Rewards Min            -8.07286
exploration/Returns Mean          -50.9227
exploration/Returns Std            26.0554
exploration/Returns Max           -28.8691
exploration/Returns Min          -101.248
exploration/Actions Mean           -0.00180544
exploration/Actions Std             0.207143
exploration/Actions Max             0.998125
exploration/Actions Min            -0.999756
exploration/Num Paths               5
exploration/Average Returns       -50.9227
evaluation/num steps total          1.0215e+06
evaluation/num paths total      10215
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.741446
evaluation/Rewards Std              1.28017
evaluation/Rewards Max             -0.0192957
evaluation/Rewards Min            -10.9294
evaluation/Returns Mean           -74.1446
evaluation/Returns Std             80.4141
evaluation/Returns Max            -10.1825
evaluation/Returns Min           -273.937
evaluation/Actions Mean            -0.00341309
evaluation/Actions Std              0.187422
evaluation/Actions Max              0.998893
evaluation/Actions Min             -0.998796
evaluation/Num Paths               15
evaluation/Average Returns        -74.1446
time/data storing (s)               0.00268588
time/evaluation sampling (s)        0.317753
time/exploration sampling (s)       0.138335
time/logging (s)                    0.00437886
time/saving (s)                     0.00190568
time/training (s)                   1.96782
time/epoch (s)                      2.43288
time/total (s)                   1670.81
Epoch                             680
-----------------------------  ---------------
2019-04-23 01:41:27.286560 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 681 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.42625
trainer/QF2 Loss                    1.50011
trainer/Policy Loss                27.4521
trainer/Q1 Predictions Mean       -25.6055
trainer/Q1 Predictions Std         30.8888
trainer/Q1 Predictions Max         -7.34014
trainer/Q1 Predictions Min       -127.962
trainer/Q2 Predictions Mean       -25.5345
trainer/Q2 Predictions Std         30.8505
trainer/Q2 Predictions Max         -7.41737
trainer/Q2 Predictions Min       -127.525
trainer/Q Targets Mean            -25.7372
trainer/Q Targets Std              31.3123
trainer/Q Targets Max              -0.209899
trainer/Q Targets Min            -129.408
trainer/Log Pis Mean                1.91087
trainer/Log Pis Std                 1.38665
trainer/Log Pis Max                 6.89605
trainer/Log Pis Min                -2.37503
trainer/Policy mu Mean              0.00142171
trainer/Policy mu Std               0.633
trainer/Policy mu Max               3.18195
trainer/Policy mu Min              -2.83253
trainer/Policy log std Mean        -2.2578
trainer/Policy log std Std          0.464704
trainer/Policy log std Max         -0.320993
trainer/Policy log std Min         -3.05946
trainer/Alpha                       0.089394
trainer/Alpha Loss                 -0.215222
exploration/num steps total    341200
exploration/num paths total      3412
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.281621
exploration/Rewards Std             0.597748
exploration/Rewards Max            -0.00828066
exploration/Rewards Min            -5.93762
exploration/Returns Mean          -28.1621
exploration/Returns Std             8.23677
exploration/Returns Max           -16.1696
exploration/Returns Min           -39.2174
exploration/Actions Mean            0.0178474
exploration/Actions Std             0.204981
exploration/Actions Max             0.999143
exploration/Actions Min            -0.990305
exploration/Num Paths               5
exploration/Average Returns       -28.1621
evaluation/num steps total          1.023e+06
evaluation/num paths total      10230
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.855756
evaluation/Rewards Std              1.20954
evaluation/Rewards Max             -0.0292835
evaluation/Rewards Min             -8.88606
evaluation/Returns Mean           -85.5756
evaluation/Returns Std             90.1321
evaluation/Returns Max             -6.56473
evaluation/Returns Min           -272.149
evaluation/Actions Mean            -0.00309724
evaluation/Actions Std              0.179395
evaluation/Actions Max              0.996595
evaluation/Actions Min             -0.994743
evaluation/Num Paths               15
evaluation/Average Returns        -85.5756
time/data storing (s)               0.0027179
time/evaluation sampling (s)        0.320007
time/exploration sampling (s)       0.134331
time/logging (s)                    0.00476445
time/saving (s)                     0.00193284
time/training (s)                   1.97175
time/epoch (s)                      2.4355
time/total (s)                   1673.25
Epoch                             681
-----------------------------  ---------------
2019-04-23 01:41:29.742497 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 682 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.95695
trainer/QF2 Loss                    1.88586
trainer/Policy Loss                22.5247
trainer/Q1 Predictions Mean       -20.6933
trainer/Q1 Predictions Std         23.3615
trainer/Q1 Predictions Max         -7.7166
trainer/Q1 Predictions Min       -129.127
trainer/Q2 Predictions Mean       -20.657
trainer/Q2 Predictions Std         23.3249
trainer/Q2 Predictions Max         -7.84474
trainer/Q2 Predictions Min       -128.91
trainer/Q Targets Mean            -20.6408
trainer/Q Targets Std              23.3433
trainer/Q Targets Max              -0.57297
trainer/Q Targets Min            -128.293
trainer/Log Pis Mean                2.00102
trainer/Log Pis Std                 1.28589
trainer/Log Pis Max                 5.90823
trainer/Log Pis Min                -2.47633
trainer/Policy mu Mean             -0.0384006
trainer/Policy mu Std               0.407827
trainer/Policy mu Max               2.98437
trainer/Policy mu Min              -2.6055
trainer/Policy log std Mean        -2.30791
trainer/Policy log std Std          0.363684
trainer/Policy log std Max         -0.611662
trainer/Policy log std Min         -3.06001
trainer/Alpha                       0.0883353
trainer/Alpha Loss                  0.00246705
exploration/num steps total    341700
exploration/num paths total      3417
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.83638
exploration/Rewards Std             1.10871
exploration/Rewards Max            -0.00551202
exploration/Rewards Min            -8.05555
exploration/Returns Mean          -83.638
exploration/Returns Std            79.3742
exploration/Returns Max           -18.1173
exploration/Returns Min          -237.355
exploration/Actions Mean           -0.0120048
exploration/Actions Std             0.203326
exploration/Actions Max             0.996514
exploration/Actions Min            -0.996937
exploration/Num Paths               5
exploration/Average Returns       -83.638
evaluation/num steps total          1.0245e+06
evaluation/num paths total      10245
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.404608
evaluation/Rewards Std              1.03168
evaluation/Rewards Max             -0.00322157
evaluation/Rewards Min            -10.429
evaluation/Returns Mean           -40.4608
evaluation/Returns Std             36.7997
evaluation/Returns Max             -1.62259
evaluation/Returns Min           -149.864
evaluation/Actions Mean            -0.0029636
evaluation/Actions Std              0.177191
evaluation/Actions Max              0.998532
evaluation/Actions Min             -0.998141
evaluation/Num Paths               15
evaluation/Average Returns        -40.4608
time/data storing (s)               0.00269859
time/evaluation sampling (s)        0.314153
time/exploration sampling (s)       0.138533
time/logging (s)                    0.00486388
time/saving (s)                     0.0019356
time/training (s)                   1.98012
time/epoch (s)                      2.44231
time/total (s)                   1675.7
Epoch                             682
-----------------------------  ---------------
2019-04-23 01:41:32.212322 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 683 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.763275
trainer/QF2 Loss                    0.777058
trainer/Policy Loss                23.4822
trainer/Q1 Predictions Mean       -21.6971
trainer/Q1 Predictions Std         24.9
trainer/Q1 Predictions Max         -7.72448
trainer/Q1 Predictions Min       -126.036
trainer/Q2 Predictions Mean       -21.6721
trainer/Q2 Predictions Std         24.8838
trainer/Q2 Predictions Max         -7.82736
trainer/Q2 Predictions Min       -125.934
trainer/Q Targets Mean            -21.6884
trainer/Q Targets Std              24.9404
trainer/Q Targets Max              -0.109848
trainer/Q Targets Min            -125.918
trainer/Log Pis Mean                1.86564
trainer/Log Pis Std                 1.20994
trainer/Log Pis Max                 4.17809
trainer/Log Pis Min                -3.11123
trainer/Policy mu Mean             -0.0436252
trainer/Policy mu Std               0.329243
trainer/Policy mu Max               2.43567
trainer/Policy mu Min              -2.56217
trainer/Policy log std Mean        -2.32674
trainer/Policy log std Std          0.368811
trainer/Policy log std Max         -0.615642
trainer/Policy log std Min         -3.21475
trainer/Alpha                       0.0884534
trainer/Alpha Loss                 -0.325854
exploration/num steps total    342200
exploration/num paths total      3422
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.354379
exploration/Rewards Std             0.759664
exploration/Rewards Max            -0.0100327
exploration/Rewards Min            -7.57937
exploration/Returns Mean          -35.4379
exploration/Returns Std            13.1015
exploration/Returns Max           -15.8801
exploration/Returns Min           -50.9829
exploration/Actions Mean            0.00339774
exploration/Actions Std             0.206763
exploration/Actions Max             0.998915
exploration/Actions Min            -0.996874
exploration/Num Paths               5
exploration/Average Returns       -35.4379
evaluation/num steps total          1.026e+06
evaluation/num paths total      10260
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.53897
evaluation/Rewards Std              1.18496
evaluation/Rewards Max             -0.00797115
evaluation/Rewards Min            -10.7039
evaluation/Returns Mean           -53.897
evaluation/Returns Std             59.8014
evaluation/Returns Max             -2.84852
evaluation/Returns Min           -264.406
evaluation/Actions Mean            -0.00294505
evaluation/Actions Std              0.189809
evaluation/Actions Max              0.998727
evaluation/Actions Min             -0.996232
evaluation/Num Paths               15
evaluation/Average Returns        -53.897
time/data storing (s)               0.00277008
time/evaluation sampling (s)        0.320074
time/exploration sampling (s)       0.141724
time/logging (s)                    0.00476464
time/saving (s)                     0.00191939
time/training (s)                   1.98465
time/epoch (s)                      2.4559
time/total (s)                   1678.16
Epoch                             683
-----------------------------  ---------------
2019-04-23 01:41:34.681083 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 684 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.10745
trainer/QF2 Loss                    0.117578
trainer/Policy Loss                27.111
trainer/Q1 Predictions Mean       -25.2448
trainer/Q1 Predictions Std         28.768
trainer/Q1 Predictions Max         -7.4764
trainer/Q1 Predictions Min       -124.742
trainer/Q2 Predictions Mean       -25.2378
trainer/Q2 Predictions Std         28.7526
trainer/Q2 Predictions Max         -7.5723
trainer/Q2 Predictions Min       -124.947
trainer/Q Targets Mean            -25.4083
trainer/Q Targets Std              28.7375
trainer/Q Targets Max              -7.6882
trainer/Q Targets Min            -124.412
trainer/Log Pis Mean                1.91255
trainer/Log Pis Std                 1.11453
trainer/Log Pis Max                 4.90258
trainer/Log Pis Min                -1.98841
trainer/Policy mu Mean             -0.017596
trainer/Policy mu Std               0.402717
trainer/Policy mu Max               2.93324
trainer/Policy mu Min              -2.8284
trainer/Policy log std Mean        -2.30908
trainer/Policy log std Std          0.369682
trainer/Policy log std Max         -0.522555
trainer/Policy log std Min         -3.00526
trainer/Alpha                       0.0891742
trainer/Alpha Loss                 -0.211392
exploration/num steps total    342700
exploration/num paths total      3427
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.996206
exploration/Rewards Std             1.29998
exploration/Rewards Max            -0.0229719
exploration/Rewards Min           -11.4943
exploration/Returns Mean          -99.6206
exploration/Returns Std            93.606
exploration/Returns Max           -28.1559
exploration/Returns Min          -279.249
exploration/Actions Mean           -0.0157247
exploration/Actions Std             0.198995
exploration/Actions Max             0.999387
exploration/Actions Min            -0.998837
exploration/Num Paths               5
exploration/Average Returns       -99.6206
evaluation/num steps total          1.0275e+06
evaluation/num paths total      10275
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.496737
evaluation/Rewards Std              1.1409
evaluation/Rewards Max             -0.00483733
evaluation/Rewards Min            -11.7501
evaluation/Returns Mean           -49.6737
evaluation/Returns Std             34.8333
evaluation/Returns Max            -12.1649
evaluation/Returns Min           -124.759
evaluation/Actions Mean             0.0192647
evaluation/Actions Std              0.202327
evaluation/Actions Max              0.998991
evaluation/Actions Min             -0.996585
evaluation/Num Paths               15
evaluation/Average Returns        -49.6737
time/data storing (s)               0.00277978
time/evaluation sampling (s)        0.318486
time/exploration sampling (s)       0.136906
time/logging (s)                    0.00479283
time/saving (s)                     0.00194421
time/training (s)                   1.99341
time/epoch (s)                      2.45831
time/total (s)                   1680.62
Epoch                             684
-----------------------------  ---------------
2019-04-23 01:41:37.220040 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 685 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.797749
trainer/QF2 Loss                    0.823424
trainer/Policy Loss                23.5798
trainer/Q1 Predictions Mean       -21.6638
trainer/Q1 Predictions Std         27.7792
trainer/Q1 Predictions Max         -7.35252
trainer/Q1 Predictions Min       -127.868
trainer/Q2 Predictions Mean       -21.635
trainer/Q2 Predictions Std         27.7327
trainer/Q2 Predictions Max         -7.51396
trainer/Q2 Predictions Min       -127.26
trainer/Q Targets Mean            -21.7721
trainer/Q Targets Std              28.0085
trainer/Q Targets Max              -0.106976
trainer/Q Targets Min            -128.802
trainer/Log Pis Mean                2.01282
trainer/Log Pis Std                 1.24869
trainer/Log Pis Max                 7.12344
trainer/Log Pis Min                -2.3347
trainer/Policy mu Mean             -0.0149272
trainer/Policy mu Std               0.419678
trainer/Policy mu Max               2.73498
trainer/Policy mu Min              -3.07089
trainer/Policy log std Mean        -2.34094
trainer/Policy log std Std          0.368896
trainer/Policy log std Max         -0.663553
trainer/Policy log std Min         -3.09177
trainer/Alpha                       0.0896532
trainer/Alpha Loss                  0.0309119
exploration/num steps total    343200
exploration/num paths total      3432
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.381125
exploration/Rewards Std             0.813769
exploration/Rewards Max            -0.00581298
exploration/Rewards Min            -9.24828
exploration/Returns Mean          -38.1125
exploration/Returns Std            16.3119
exploration/Returns Max           -18.9168
exploration/Returns Min           -55.5133
exploration/Actions Mean           -0.00979311
exploration/Actions Std             0.193888
exploration/Actions Max             0.989153
exploration/Actions Min            -0.998072
exploration/Num Paths               5
exploration/Average Returns       -38.1125
evaluation/num steps total          1.029e+06
evaluation/num paths total      10290
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.663014
evaluation/Rewards Std              1.19691
evaluation/Rewards Max             -0.0246006
evaluation/Rewards Min             -9.92486
evaluation/Returns Mean           -66.3014
evaluation/Returns Std             78.5354
evaluation/Returns Max             -6.4465
evaluation/Returns Min           -262.257
evaluation/Actions Mean            -0.00548425
evaluation/Actions Std              0.168448
evaluation/Actions Max              0.996878
evaluation/Actions Min             -0.997131
evaluation/Num Paths               15
evaluation/Average Returns        -66.3014
time/data storing (s)               0.00270351
time/evaluation sampling (s)        0.343736
time/exploration sampling (s)       0.146605
time/logging (s)                    0.00352631
time/saving (s)                     0.00192678
time/training (s)                   2.02542
time/epoch (s)                      2.52391
time/total (s)                   1683.15
Epoch                             685
-----------------------------  ---------------
2019-04-23 01:41:40.088721 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 686 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    2.01745
trainer/QF2 Loss                    1.88376
trainer/Policy Loss                29.3024
trainer/Q1 Predictions Mean       -27.3628
trainer/Q1 Predictions Std         32.377
trainer/Q1 Predictions Max         -7.49932
trainer/Q1 Predictions Min       -120.906
trainer/Q2 Predictions Mean       -27.329
trainer/Q2 Predictions Std         32.4161
trainer/Q2 Predictions Max         -7.39133
trainer/Q2 Predictions Min       -121.356
trainer/Q Targets Mean            -27.6107
trainer/Q Targets Std              33.1223
trainer/Q Targets Max              -0.117393
trainer/Q Targets Min            -123.926
trainer/Log Pis Mean                2.0417
trainer/Log Pis Std                 1.34237
trainer/Log Pis Max                 6.33355
trainer/Log Pis Min                -1.71169
trainer/Policy mu Mean             -0.00984054
trainer/Policy mu Std               0.566361
trainer/Policy mu Max               2.70253
trainer/Policy mu Min              -2.88288
trainer/Policy log std Mean        -2.22292
trainer/Policy log std Std          0.426515
trainer/Policy log std Max         -0.500871
trainer/Policy log std Min         -3.11628
trainer/Alpha                       0.0884097
trainer/Alpha Loss                  0.101156
exploration/num steps total    343700
exploration/num paths total      3437
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.668457
exploration/Rewards Std             0.69158
exploration/Rewards Max            -0.0271699
exploration/Rewards Min            -6.73724
exploration/Returns Mean          -66.8457
exploration/Returns Std            36.2584
exploration/Returns Max           -18.9113
exploration/Returns Min          -126.864
exploration/Actions Mean           -0.004271
exploration/Actions Std             0.188512
exploration/Actions Max             0.989759
exploration/Actions Min            -0.998813
exploration/Num Paths               5
exploration/Average Returns       -66.8457
evaluation/num steps total          1.0305e+06
evaluation/num paths total      10305
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.529488
evaluation/Rewards Std              0.960981
evaluation/Rewards Max             -0.0455491
evaluation/Rewards Min            -10.0701
evaluation/Returns Mean           -52.9488
evaluation/Returns Std             38.767
evaluation/Returns Max            -19.1478
evaluation/Returns Min           -145.072
evaluation/Actions Mean             0.00740689
evaluation/Actions Std              0.180168
evaluation/Actions Max              0.997725
evaluation/Actions Min             -0.997244
evaluation/Num Paths               15
evaluation/Average Returns        -52.9488
time/data storing (s)               0.00310824
time/evaluation sampling (s)        0.329859
time/exploration sampling (s)       0.151289
time/logging (s)                    0.00481366
time/saving (s)                     0.00196262
time/training (s)                   2.36566
time/epoch (s)                      2.85669
time/total (s)                   1686.01
Epoch                             686
-----------------------------  ---------------
2019-04-23 01:41:42.607748 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 687 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   14.8297
trainer/QF2 Loss                   14.885
trainer/Policy Loss                26.6554
trainer/Q1 Predictions Mean       -24.7712
trainer/Q1 Predictions Std         28.4226
trainer/Q1 Predictions Max         -7.6161
trainer/Q1 Predictions Min       -121.579
trainer/Q2 Predictions Mean       -24.7888
trainer/Q2 Predictions Std         28.4358
trainer/Q2 Predictions Max         -7.52412
trainer/Q2 Predictions Min       -121.454
trainer/Q Targets Mean            -24.3807
trainer/Q Targets Std              28.9202
trainer/Q Targets Max              -0.257916
trainer/Q Targets Min            -122.441
trainer/Log Pis Mean                1.90301
trainer/Log Pis Std                 1.03135
trainer/Log Pis Max                 4.77596
trainer/Log Pis Min                -1.44138
trainer/Policy mu Mean             -0.041964
trainer/Policy mu Std               0.322361
trainer/Policy mu Max               2.12217
trainer/Policy mu Min              -2.93875
trainer/Policy log std Mean        -2.30729
trainer/Policy log std Std          0.312273
trainer/Policy log std Max         -0.721997
trainer/Policy log std Min         -3.04256
trainer/Alpha                       0.0883325
trainer/Alpha Loss                 -0.235348
exploration/num steps total    344200
exploration/num paths total      3442
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.02952
exploration/Rewards Std             1.29061
exploration/Rewards Max            -0.00744493
exploration/Rewards Min            -8.76418
exploration/Returns Mean         -102.952
exploration/Returns Std            88.1608
exploration/Returns Max           -36.9571
exploration/Returns Min          -273.49
exploration/Actions Mean            0.0155798
exploration/Actions Std             0.226825
exploration/Actions Max             0.999022
exploration/Actions Min            -0.99838
exploration/Num Paths               5
exploration/Average Returns      -102.952
evaluation/num steps total          1.032e+06
evaluation/num paths total      10320
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.473255
evaluation/Rewards Std              1.05648
evaluation/Rewards Max             -0.0134371
evaluation/Rewards Min             -9.63705
evaluation/Returns Mean           -47.3255
evaluation/Returns Std             63.9235
evaluation/Returns Max             -9.1832
evaluation/Returns Min           -281.576
evaluation/Actions Mean             0.00372943
evaluation/Actions Std              0.174091
evaluation/Actions Max              0.994186
evaluation/Actions Min             -0.995548
evaluation/Num Paths               15
evaluation/Average Returns        -47.3255
time/data storing (s)               0.00291024
time/evaluation sampling (s)        0.331025
time/exploration sampling (s)       0.149772
time/logging (s)                    0.00480964
time/saving (s)                     0.0102917
time/training (s)                   2.00618
time/epoch (s)                      2.50499
time/total (s)                   1688.52
Epoch                             687
-----------------------------  ---------------
2019-04-23 01:41:45.123612 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 688 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    7.78095
trainer/QF2 Loss                    7.7854
trainer/Policy Loss                28.0469
trainer/Q1 Predictions Mean       -26.1911
trainer/Q1 Predictions Std         29.1477
trainer/Q1 Predictions Max         -7.52994
trainer/Q1 Predictions Min       -140.004
trainer/Q2 Predictions Mean       -26.1539
trainer/Q2 Predictions Std         29.1692
trainer/Q2 Predictions Max         -7.5787
trainer/Q2 Predictions Min       -139.748
trainer/Q Targets Mean            -26.1693
trainer/Q Targets Std              29.6429
trainer/Q Targets Max              -0.355107
trainer/Q Targets Min            -141.28
trainer/Log Pis Mean                1.96196
trainer/Log Pis Std                 1.03198
trainer/Log Pis Max                 4.17487
trainer/Log Pis Min                -2.28339
trainer/Policy mu Mean             -0.0787611
trainer/Policy mu Std               0.363749
trainer/Policy mu Max               0.663749
trainer/Policy mu Min              -2.6909
trainer/Policy log std Mean        -2.31951
trainer/Policy log std Std          0.338897
trainer/Policy log std Max         -0.647554
trainer/Policy log std Min         -2.96251
trainer/Alpha                       0.0887724
trainer/Alpha Loss                 -0.0921313
exploration/num steps total    344700
exploration/num paths total      3447
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.753043
exploration/Rewards Std             1.09482
exploration/Rewards Max            -0.0098158
exploration/Rewards Min            -7.19291
exploration/Returns Mean          -75.3043
exploration/Returns Std            93.4841
exploration/Returns Max           -16.9771
exploration/Returns Min          -260.873
exploration/Actions Mean           -0.0160127
exploration/Actions Std             0.188824
exploration/Actions Max             0.951056
exploration/Actions Min            -0.997259
exploration/Num Paths               5
exploration/Average Returns       -75.3043
evaluation/num steps total          1.0335e+06
evaluation/num paths total      10335
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.69996
evaluation/Rewards Std              1.28438
evaluation/Rewards Max             -0.0233582
evaluation/Rewards Min            -10.4033
evaluation/Returns Mean           -69.996
evaluation/Returns Std             40.9449
evaluation/Returns Max            -13.4599
evaluation/Returns Min           -145.13
evaluation/Actions Mean             0.00634848
evaluation/Actions Std              0.204705
evaluation/Actions Max              0.998444
evaluation/Actions Min             -0.99889
evaluation/Num Paths               15
evaluation/Average Returns        -69.996
time/data storing (s)               0.00271168
time/evaluation sampling (s)        0.32949
time/exploration sampling (s)       0.142864
time/logging (s)                    0.00479251
time/saving (s)                     0.0019552
time/training (s)                   2.02016
time/epoch (s)                      2.50198
time/total (s)                   1691.03
Epoch                             688
-----------------------------  ---------------
2019-04-23 01:41:47.619837 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 689 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.16078
trainer/QF2 Loss                    1.13435
trainer/Policy Loss                29.8469
trainer/Q1 Predictions Mean       -27.9961
trainer/Q1 Predictions Std         34.1592
trainer/Q1 Predictions Max         -7.56605
trainer/Q1 Predictions Min       -121.563
trainer/Q2 Predictions Mean       -27.9982
trainer/Q2 Predictions Std         34.1908
trainer/Q2 Predictions Max         -7.72099
trainer/Q2 Predictions Min       -121.631
trainer/Q Targets Mean            -28.2921
trainer/Q Targets Std              34.63
trainer/Q Targets Max              -0.177251
trainer/Q Targets Min            -122.746
trainer/Log Pis Mean                1.90033
trainer/Log Pis Std                 1.08259
trainer/Log Pis Max                 3.60556
trainer/Log Pis Min                -2.67124
trainer/Policy mu Mean             -0.026414
trainer/Policy mu Std               0.238691
trainer/Policy mu Max               1.06623
trainer/Policy mu Min              -2.22902
trainer/Policy log std Mean        -2.29938
trainer/Policy log std Std          0.295068
trainer/Policy log std Max         -0.724183
trainer/Policy log std Min         -2.94913
trainer/Alpha                       0.0887292
trainer/Alpha Loss                 -0.241401
exploration/num steps total    345200
exploration/num paths total      3452
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.77642
exploration/Rewards Std             1.01331
exploration/Rewards Max            -0.020993
exploration/Rewards Min            -7.52736
exploration/Returns Mean          -77.642
exploration/Returns Std            29.699
exploration/Returns Max           -49.5392
exploration/Returns Min          -125.043
exploration/Actions Mean           -0.0177985
exploration/Actions Std             0.213588
exploration/Actions Max             0.991091
exploration/Actions Min            -0.999548
exploration/Num Paths               5
exploration/Average Returns       -77.642
evaluation/num steps total          1.035e+06
evaluation/num paths total      10350
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.628611
evaluation/Rewards Std              1.14496
evaluation/Rewards Max             -0.028829
evaluation/Rewards Min            -10.6721
evaluation/Returns Mean           -62.8611
evaluation/Returns Std             62.9298
evaluation/Returns Max            -15.2698
evaluation/Returns Min           -266.285
evaluation/Actions Mean             0.00462637
evaluation/Actions Std              0.18844
evaluation/Actions Max              0.998295
evaluation/Actions Min             -0.996135
evaluation/Num Paths               15
evaluation/Average Returns        -62.8611
time/data storing (s)               0.00277464
time/evaluation sampling (s)        0.331143
time/exploration sampling (s)       0.14407
time/logging (s)                    0.00357692
time/saving (s)                     0.00168526
time/training (s)                   1.99832
time/epoch (s)                      2.48157
time/total (s)                   1693.51
Epoch                             689
-----------------------------  ---------------
2019-04-23 01:41:50.133338 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 690 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.552962
trainer/QF2 Loss                    0.543419
trainer/Policy Loss                26.698
trainer/Q1 Predictions Mean       -24.6316
trainer/Q1 Predictions Std         27.789
trainer/Q1 Predictions Max         -7.51127
trainer/Q1 Predictions Min       -121.326
trainer/Q2 Predictions Mean       -24.6332
trainer/Q2 Predictions Std         27.8184
trainer/Q2 Predictions Max         -7.52933
trainer/Q2 Predictions Min       -121.817
trainer/Q Targets Mean            -25.0386
trainer/Q Targets Std              28.3423
trainer/Q Targets Max              -7.6981
trainer/Q Targets Min            -124.484
trainer/Log Pis Mean                2.08586
trainer/Log Pis Std                 1.03966
trainer/Log Pis Max                 6.7066
trainer/Log Pis Min                -0.550805
trainer/Policy mu Mean             -0.0165878
trainer/Policy mu Std               0.40596
trainer/Policy mu Max               2.01354
trainer/Policy mu Min              -3.01767
trainer/Policy log std Mean        -2.28911
trainer/Policy log std Std          0.340645
trainer/Policy log std Max         -0.754274
trainer/Policy log std Min         -2.95499
trainer/Alpha                       0.0859263
trainer/Alpha Loss                  0.210708
exploration/num steps total    345700
exploration/num paths total      3457
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.35009
exploration/Rewards Std             0.917005
exploration/Rewards Max            -0.00996777
exploration/Rewards Min            -8.95401
exploration/Returns Mean          -35.009
exploration/Returns Std            11.9935
exploration/Returns Max           -17.9718
exploration/Returns Min           -51.811
exploration/Actions Mean           -0.0274332
exploration/Actions Std             0.22626
exploration/Actions Max             0.989138
exploration/Actions Min            -0.997926
exploration/Num Paths               5
exploration/Average Returns       -35.009
evaluation/num steps total          1.0365e+06
evaluation/num paths total      10365
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.554879
evaluation/Rewards Std              1.06441
evaluation/Rewards Max             -0.0285952
evaluation/Rewards Min             -8.86528
evaluation/Returns Mean           -55.4879
evaluation/Returns Std             64.6802
evaluation/Returns Max             -9.2794
evaluation/Returns Min           -271.312
evaluation/Actions Mean            -0.0204686
evaluation/Actions Std              0.180638
evaluation/Actions Max              0.996195
evaluation/Actions Min             -0.997151
evaluation/Num Paths               15
evaluation/Average Returns        -55.4879
time/data storing (s)               0.00275248
time/evaluation sampling (s)        0.330978
time/exploration sampling (s)       0.161155
time/logging (s)                    0.00479098
time/saving (s)                     0.00192644
time/training (s)                   1.99977
time/epoch (s)                      2.50137
time/total (s)                   1696.02
Epoch                             690
-----------------------------  ---------------
2019-04-23 01:41:52.608208 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 691 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.16591
trainer/QF2 Loss                    1.23406
trainer/Policy Loss                26.6511
trainer/Q1 Predictions Mean       -24.7563
trainer/Q1 Predictions Std         28.5861
trainer/Q1 Predictions Max         -7.74479
trainer/Q1 Predictions Min       -126.882
trainer/Q2 Predictions Mean       -24.7728
trainer/Q2 Predictions Std         28.641
trainer/Q2 Predictions Max         -7.90847
trainer/Q2 Predictions Min       -128.618
trainer/Q Targets Mean            -24.6511
trainer/Q Targets Std              28.6483
trainer/Q Targets Max              -0.305838
trainer/Q Targets Min            -127.286
trainer/Log Pis Mean                1.92937
trainer/Log Pis Std                 1.0245
trainer/Log Pis Max                 5.4307
trainer/Log Pis Min                -1.56334
trainer/Policy mu Mean             -0.0386425
trainer/Policy mu Std               0.293264
trainer/Policy mu Max               1.97891
trainer/Policy mu Min              -3.01972
trainer/Policy log std Mean        -2.34619
trainer/Policy log std Std          0.263095
trainer/Policy log std Max         -0.831152
trainer/Policy log std Min         -3.01379
trainer/Alpha                       0.0846439
trainer/Alpha Loss                 -0.174405
exploration/num steps total    346200
exploration/num paths total      3462
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.417364
exploration/Rewards Std             1.06632
exploration/Rewards Max            -0.00990435
exploration/Rewards Min           -10.142
exploration/Returns Mean          -41.7364
exploration/Returns Std            21.2651
exploration/Returns Max           -15.6745
exploration/Returns Min           -67.5064
exploration/Actions Mean            0.011279
exploration/Actions Std             0.215138
exploration/Actions Max             0.996375
exploration/Actions Min            -0.99802
exploration/Num Paths               5
exploration/Average Returns       -41.7364
evaluation/num steps total          1.038e+06
evaluation/num paths total      10380
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.780758
evaluation/Rewards Std              1.38704
evaluation/Rewards Max             -0.0147545
evaluation/Rewards Min            -11.4369
evaluation/Returns Mean           -78.0758
evaluation/Returns Std             78.9658
evaluation/Returns Max            -10.8097
evaluation/Returns Min           -279.945
evaluation/Actions Mean            -0.00603911
evaluation/Actions Std              0.202994
evaluation/Actions Max              0.998521
evaluation/Actions Min             -0.996421
evaluation/Num Paths               15
evaluation/Average Returns        -78.0758
time/data storing (s)               0.002544
time/evaluation sampling (s)        0.334537
time/exploration sampling (s)       0.137902
time/logging (s)                    0.00482167
time/saving (s)                     0.00197535
time/training (s)                   1.97921
time/epoch (s)                      2.46099
time/total (s)                   1698.49
Epoch                             691
-----------------------------  ---------------
2019-04-23 01:41:55.140469 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 692 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.36074
trainer/QF2 Loss                    1.36912
trainer/Policy Loss                26.799
trainer/Q1 Predictions Mean       -24.9728
trainer/Q1 Predictions Std         29.4216
trainer/Q1 Predictions Max         -7.5438
trainer/Q1 Predictions Min       -119.583
trainer/Q2 Predictions Mean       -24.9609
trainer/Q2 Predictions Std         29.4078
trainer/Q2 Predictions Max         -7.51771
trainer/Q2 Predictions Min       -119.628
trainer/Q Targets Mean            -25.2631
trainer/Q Targets Std              30.1286
trainer/Q Targets Max              -0.083032
trainer/Q Targets Min            -122.285
trainer/Log Pis Mean                1.86297
trainer/Log Pis Std                 1.25015
trainer/Log Pis Max                 4.76619
trainer/Log Pis Min                -2.29267
trainer/Policy mu Mean              0.0047842
trainer/Policy mu Std               0.447952
trainer/Policy mu Max               2.91625
trainer/Policy mu Min              -2.80447
trainer/Policy log std Mean        -2.31137
trainer/Policy log std Std          0.397446
trainer/Policy log std Max         -0.479129
trainer/Policy log std Min         -2.9629
trainer/Alpha                       0.0829269
trainer/Alpha Loss                 -0.341161
exploration/num steps total    346700
exploration/num paths total      3467
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.571664
exploration/Rewards Std             1.0491
exploration/Rewards Max            -0.00486898
exploration/Rewards Min            -9.35397
exploration/Returns Mean          -57.1664
exploration/Returns Std            37.3625
exploration/Returns Max           -20.4303
exploration/Returns Min          -128.204
exploration/Actions Mean            0.0206738
exploration/Actions Std             0.227682
exploration/Actions Max             0.99809
exploration/Actions Min            -0.999623
exploration/Num Paths               5
exploration/Average Returns       -57.1664
evaluation/num steps total          1.0395e+06
evaluation/num paths total      10395
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.582835
evaluation/Rewards Std              1.03029
evaluation/Rewards Max             -0.0369649
evaluation/Rewards Min             -8.44919
evaluation/Returns Mean           -58.2835
evaluation/Returns Std             59.7145
evaluation/Returns Max            -19.1048
evaluation/Returns Min           -251.591
evaluation/Actions Mean            -0.000515384
evaluation/Actions Std              0.18813
evaluation/Actions Max              0.995923
evaluation/Actions Min             -0.996291
evaluation/Num Paths               15
evaluation/Average Returns        -58.2835
time/data storing (s)               0.00276281
time/evaluation sampling (s)        0.332507
time/exploration sampling (s)       0.138913
time/logging (s)                    0.00480738
time/saving (s)                     0.011699
time/training (s)                   2.02753
time/epoch (s)                      2.51822
time/total (s)                   1701.01
Epoch                             692
-----------------------------  ----------------
2019-04-23 01:41:57.638174 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 693 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                  145.014
trainer/QF2 Loss                  145.789
trainer/Policy Loss                24.6917
trainer/Q1 Predictions Mean       -22.7181
trainer/Q1 Predictions Std         27.7541
trainer/Q1 Predictions Max         -7.67631
trainer/Q1 Predictions Min       -122.903
trainer/Q2 Predictions Mean       -22.7245
trainer/Q2 Predictions Std         27.7183
trainer/Q2 Predictions Max         -7.68569
trainer/Q2 Predictions Min       -123.22
trainer/Q Targets Mean            -21.4822
trainer/Q Targets Std              26.1268
trainer/Q Targets Max              -0.749409
trainer/Q Targets Min            -122.604
trainer/Log Pis Mean                2.06525
trainer/Log Pis Std                 1.17876
trainer/Log Pis Max                 5.66842
trainer/Log Pis Min                -3.04256
trainer/Policy mu Mean              0.00171633
trainer/Policy mu Std               0.339327
trainer/Policy mu Max               2.90975
trainer/Policy mu Min              -1.53172
trainer/Policy log std Mean        -2.33318
trainer/Policy log std Std          0.326394
trainer/Policy log std Max         -0.714896
trainer/Policy log std Min         -2.94882
trainer/Alpha                       0.0839766
trainer/Alpha Loss                  0.161652
exploration/num steps total    347200
exploration/num paths total      3472
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.817752
exploration/Rewards Std             0.995729
exploration/Rewards Max            -0.0312712
exploration/Rewards Min            -6.87601
exploration/Returns Mean          -81.7752
exploration/Returns Std            43.9672
exploration/Returns Max           -35.3108
exploration/Returns Min          -135.538
exploration/Actions Mean           -0.0228124
exploration/Actions Std             0.211313
exploration/Actions Max             0.996692
exploration/Actions Min            -0.999685
exploration/Num Paths               5
exploration/Average Returns       -81.7752
evaluation/num steps total          1.041e+06
evaluation/num paths total      10410
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.584036
evaluation/Rewards Std              1.02297
evaluation/Rewards Max             -0.0135524
evaluation/Rewards Min            -10.0439
evaluation/Returns Mean           -58.4036
evaluation/Returns Std             39.8485
evaluation/Returns Max             -9.23695
evaluation/Returns Min           -139.305
evaluation/Actions Mean             0.0112925
evaluation/Actions Std              0.178111
evaluation/Actions Max              0.997878
evaluation/Actions Min             -0.99513
evaluation/Num Paths               15
evaluation/Average Returns        -58.4036
time/data storing (s)               0.00277088
time/evaluation sampling (s)        0.323975
time/exploration sampling (s)       0.135762
time/logging (s)                    0.00356866
time/saving (s)                     0.00193262
time/training (s)                   2.01453
time/epoch (s)                      2.48254
time/total (s)                   1703.5
Epoch                             693
-----------------------------  ---------------
2019-04-23 01:42:00.140648 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 694 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.956261
trainer/QF2 Loss                    0.958373
trainer/Policy Loss                26.7443
trainer/Q1 Predictions Mean       -24.788
trainer/Q1 Predictions Std         30.0404
trainer/Q1 Predictions Max         -7.76978
trainer/Q1 Predictions Min       -122.169
trainer/Q2 Predictions Mean       -24.8133
trainer/Q2 Predictions Std         30.0215
trainer/Q2 Predictions Max         -7.74176
trainer/Q2 Predictions Min       -121.741
trainer/Q Targets Mean            -24.7472
trainer/Q Targets Std              30.0703
trainer/Q Targets Max              -0.177251
trainer/Q Targets Min            -121.705
trainer/Log Pis Mean                2.03266
trainer/Log Pis Std                 1.29586
trainer/Log Pis Max                 6.01833
trainer/Log Pis Min                -2.07404
trainer/Policy mu Mean              0.0200929
trainer/Policy mu Std               0.472762
trainer/Policy mu Max               2.73945
trainer/Policy mu Min              -2.85077
trainer/Policy log std Mean        -2.29687
trainer/Policy log std Std          0.392052
trainer/Policy log std Max         -0.553251
trainer/Policy log std Min         -2.87215
trainer/Alpha                       0.0867414
trainer/Alpha Loss                  0.0798424
exploration/num steps total    347700
exploration/num paths total      3477
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.405583
exploration/Rewards Std             0.602588
exploration/Rewards Max            -0.00272694
exploration/Rewards Min            -6.8772
exploration/Returns Mean          -40.5583
exploration/Returns Std            16.2973
exploration/Returns Max           -21.4057
exploration/Returns Min           -69.5447
exploration/Actions Mean            0.00987289
exploration/Actions Std             0.181817
exploration/Actions Max             0.997036
exploration/Actions Min            -0.994502
exploration/Num Paths               5
exploration/Average Returns       -40.5583
evaluation/num steps total          1.0425e+06
evaluation/num paths total      10425
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.374559
evaluation/Rewards Std              1.07397
evaluation/Rewards Max             -0.00820473
evaluation/Rewards Min            -10.2793
evaluation/Returns Mean           -37.4559
evaluation/Returns Std             26.3758
evaluation/Returns Max             -2.05466
evaluation/Returns Min            -87.7727
evaluation/Actions Mean             0.00261689
evaluation/Actions Std              0.184262
evaluation/Actions Max              0.997696
evaluation/Actions Min             -0.996325
evaluation/Num Paths               15
evaluation/Average Returns        -37.4559
time/data storing (s)               0.00274033
time/evaluation sampling (s)        0.330503
time/exploration sampling (s)       0.142209
time/logging (s)                    0.00489019
time/saving (s)                     0.00192284
time/training (s)                   2.00766
time/epoch (s)                      2.48993
time/total (s)                   1705.99
Epoch                             694
-----------------------------  ---------------
2019-04-23 01:42:02.650105 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 695 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.471173
trainer/QF2 Loss                    0.48971
trainer/Policy Loss                34.1033
trainer/Q1 Predictions Mean       -32.1715
trainer/Q1 Predictions Std         36.8345
trainer/Q1 Predictions Max         -7.23311
trainer/Q1 Predictions Min       -121.741
trainer/Q2 Predictions Mean       -32.1324
trainer/Q2 Predictions Std         36.8566
trainer/Q2 Predictions Max         -7.54584
trainer/Q2 Predictions Min       -122.214
trainer/Q Targets Mean            -32.5827
trainer/Q Targets Std              37.2887
trainer/Q Targets Max              -7.5879
trainer/Q Targets Min            -123.429
trainer/Log Pis Mean                1.99832
trainer/Log Pis Std                 1.23993
trainer/Log Pis Max                 6.39327
trainer/Log Pis Min                -2.68198
trainer/Policy mu Mean             -0.031964
trainer/Policy mu Std               0.444179
trainer/Policy mu Max               2.89855
trainer/Policy mu Min              -2.85607
trainer/Policy log std Mean        -2.29058
trainer/Policy log std Std          0.358221
trainer/Policy log std Max         -0.729947
trainer/Policy log std Min         -2.88779
trainer/Alpha                       0.0868714
trainer/Alpha Loss                 -0.00410944
exploration/num steps total    348200
exploration/num paths total      3482
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.26321
exploration/Rewards Std             1.10555
exploration/Rewards Max            -0.0158497
exploration/Rewards Min            -8.63675
exploration/Returns Mean         -126.321
exploration/Returns Std            67.4042
exploration/Returns Max           -56.6846
exploration/Returns Min          -248.994
exploration/Actions Mean            0.00451743
exploration/Actions Std             0.189088
exploration/Actions Max             0.999332
exploration/Actions Min            -0.969691
exploration/Num Paths               5
exploration/Average Returns      -126.321
evaluation/num steps total          1.044e+06
evaluation/num paths total      10440
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.815562
evaluation/Rewards Std              1.22679
evaluation/Rewards Max             -0.0206548
evaluation/Rewards Min             -9.82098
evaluation/Returns Mean           -81.5562
evaluation/Returns Std             83.4662
evaluation/Returns Max            -11.4591
evaluation/Returns Min           -281.873
evaluation/Actions Mean             0.00145997
evaluation/Actions Std              0.189456
evaluation/Actions Max              0.997096
evaluation/Actions Min             -0.996039
evaluation/Num Paths               15
evaluation/Average Returns        -81.5562
time/data storing (s)               0.00277322
time/evaluation sampling (s)        0.330134
time/exploration sampling (s)       0.137791
time/logging (s)                    0.00484678
time/saving (s)                     0.00157517
time/training (s)                   2.01824
time/epoch (s)                      2.49536
time/total (s)                   1708.49
Epoch                             695
-----------------------------  ---------------
2019-04-23 01:42:05.167013 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 696 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0636109
trainer/QF2 Loss                    0.0613451
trainer/Policy Loss                27.1848
trainer/Q1 Predictions Mean       -25.1838
trainer/Q1 Predictions Std         29.6935
trainer/Q1 Predictions Max         -7.72615
trainer/Q1 Predictions Min       -123.386
trainer/Q2 Predictions Mean       -25.1987
trainer/Q2 Predictions Std         29.6587
trainer/Q2 Predictions Max         -7.71786
trainer/Q2 Predictions Min       -122.964
trainer/Q Targets Mean            -25.2229
trainer/Q Targets Std              29.6442
trainer/Q Targets Max              -7.56417
trainer/Q Targets Min            -123.302
trainer/Log Pis Mean                2.09112
trainer/Log Pis Std                 0.978104
trainer/Log Pis Max                 5.46245
trainer/Log Pis Min                -0.33904
trainer/Policy mu Mean              0.00822663
trainer/Policy mu Std               0.435119
trainer/Policy mu Max               2.23543
trainer/Policy mu Min              -2.3612
trainer/Policy log std Mean        -2.28469
trainer/Policy log std Std          0.383089
trainer/Policy log std Max         -0.636233
trainer/Policy log std Min         -2.89773
trainer/Alpha                       0.0851238
trainer/Alpha Loss                  0.224487
exploration/num steps total    348700
exploration/num paths total      3487
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.645597
exploration/Rewards Std             0.877237
exploration/Rewards Max            -0.012852
exploration/Rewards Min            -8.61793
exploration/Returns Mean          -64.5597
exploration/Returns Std            27.5323
exploration/Returns Max           -30.2366
exploration/Returns Min           -95.9834
exploration/Actions Mean           -0.00125697
exploration/Actions Std             0.192022
exploration/Actions Max             0.992032
exploration/Actions Min            -0.999761
exploration/Num Paths               5
exploration/Average Returns       -64.5597
evaluation/num steps total          1.0455e+06
evaluation/num paths total      10455
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.339364
evaluation/Rewards Std              0.887853
evaluation/Rewards Max             -0.018796
evaluation/Rewards Min            -10.1415
evaluation/Returns Mean           -33.9364
evaluation/Returns Std             29.0159
evaluation/Returns Max             -6.11755
evaluation/Returns Min           -103.096
evaluation/Actions Mean             0.00263024
evaluation/Actions Std              0.172768
evaluation/Actions Max              0.993519
evaluation/Actions Min             -0.998881
evaluation/Num Paths               15
evaluation/Average Returns        -33.9364
time/data storing (s)               0.00277313
time/evaluation sampling (s)        0.336241
time/exploration sampling (s)       0.142331
time/logging (s)                    0.00392836
time/saving (s)                     0.0019244
time/training (s)                   2.01489
time/epoch (s)                      2.50209
time/total (s)                   1711
Epoch                             696
-----------------------------  ---------------
2019-04-23 01:42:07.657120 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 697 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.984824
trainer/QF2 Loss                    0.895975
trainer/Policy Loss                30.9263
trainer/Q1 Predictions Mean       -28.8631
trainer/Q1 Predictions Std         35.0868
trainer/Q1 Predictions Max         -7.20304
trainer/Q1 Predictions Min       -121.949
trainer/Q2 Predictions Mean       -28.9269
trainer/Q2 Predictions Std         35.0911
trainer/Q2 Predictions Max         -7.20808
trainer/Q2 Predictions Min       -122.16
trainer/Q Targets Mean            -29.3787
trainer/Q Targets Std              35.8612
trainer/Q Targets Max              -7.50093
trainer/Q Targets Min            -124.696
trainer/Log Pis Mean                2.1012
trainer/Log Pis Std                 0.879202
trainer/Log Pis Max                 3.46102
trainer/Log Pis Min                -1.01829
trainer/Policy mu Mean              0.0442827
trainer/Policy mu Std               0.344686
trainer/Policy mu Max               2.8399
trainer/Policy mu Min              -1.30488
trainer/Policy log std Mean        -2.31627
trainer/Policy log std Std          0.34638
trainer/Policy log std Max         -0.546435
trainer/Policy log std Min         -2.92363
trainer/Alpha                       0.0835886
trainer/Alpha Loss                  0.251174
exploration/num steps total    349200
exploration/num paths total      3492
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.583958
exploration/Rewards Std             0.938847
exploration/Rewards Max            -0.0236464
exploration/Rewards Min            -9.71361
exploration/Returns Mean          -58.3958
exploration/Returns Std            35.802
exploration/Returns Max           -25.1012
exploration/Returns Min          -120.391
exploration/Actions Mean           -0.00322654
exploration/Actions Std             0.206324
exploration/Actions Max             0.999339
exploration/Actions Min            -0.99846
exploration/Num Paths               5
exploration/Average Returns       -58.3958
evaluation/num steps total          1.047e+06
evaluation/num paths total      10470
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.387706
evaluation/Rewards Std              1.06061
evaluation/Rewards Max             -0.00516267
evaluation/Rewards Min             -9.66566
evaluation/Returns Mean           -38.7706
evaluation/Returns Std             28.3721
evaluation/Returns Max             -5.97667
evaluation/Returns Min           -109.407
evaluation/Actions Mean             0.0106523
evaluation/Actions Std              0.185081
evaluation/Actions Max              0.998926
evaluation/Actions Min             -0.995491
evaluation/Num Paths               15
evaluation/Average Returns        -38.7706
time/data storing (s)               0.0027038
time/evaluation sampling (s)        0.331165
time/exploration sampling (s)       0.138033
time/logging (s)                    0.00455389
time/saving (s)                     0.00157933
time/training (s)                   1.99873
time/epoch (s)                      2.47676
time/total (s)                   1713.48
Epoch                             697
-----------------------------  ---------------
2019-04-23 01:42:10.158961 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 698 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    9.98817
trainer/QF2 Loss                   10.1099
trainer/Policy Loss                30.6265
trainer/Q1 Predictions Mean       -28.5941
trainer/Q1 Predictions Std         35.1739
trainer/Q1 Predictions Max         -7.25376
trainer/Q1 Predictions Min       -123.387
trainer/Q2 Predictions Mean       -28.5891
trainer/Q2 Predictions Std         35.0908
trainer/Q2 Predictions Max         -7.31791
trainer/Q2 Predictions Min       -122.856
trainer/Q Targets Mean            -28.2126
trainer/Q Targets Std              35.7705
trainer/Q Targets Max              -0.0897101
trainer/Q Targets Min            -124.388
trainer/Log Pis Mean                2.06637
trainer/Log Pis Std                 1.17549
trainer/Log Pis Max                 6.93538
trainer/Log Pis Min                -1.33965
trainer/Policy mu Mean              0.0359234
trainer/Policy mu Std               0.340125
trainer/Policy mu Max               2.83773
trainer/Policy mu Min              -0.387251
trainer/Policy log std Mean        -2.35442
trainer/Policy log std Std          0.319461
trainer/Policy log std Max         -0.732356
trainer/Policy log std Min         -2.87484
trainer/Alpha                       0.0864084
trainer/Alpha Loss                  0.162527
exploration/num steps total    349700
exploration/num paths total      3497
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.584202
exploration/Rewards Std             0.903975
exploration/Rewards Max            -0.00572233
exploration/Rewards Min            -8.74117
exploration/Returns Mean          -58.4202
exploration/Returns Std            27.8772
exploration/Returns Max           -22.2897
exploration/Returns Min          -107.77
exploration/Actions Mean            0.0132161
exploration/Actions Std             0.195518
exploration/Actions Max             0.997374
exploration/Actions Min            -0.993785
exploration/Num Paths               5
exploration/Average Returns       -58.4202
evaluation/num steps total          1.0485e+06
evaluation/num paths total      10485
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.458941
evaluation/Rewards Std              1.08647
evaluation/Rewards Max             -0.00591721
evaluation/Rewards Min            -11.4987
evaluation/Returns Mean           -45.8941
evaluation/Returns Std             41.6824
evaluation/Returns Max             -6.05379
evaluation/Returns Min           -139.3
evaluation/Actions Mean             0.0121849
evaluation/Actions Std              0.180395
evaluation/Actions Max              0.999398
evaluation/Actions Min             -0.995133
evaluation/Num Paths               15
evaluation/Average Returns        -45.8941
time/data storing (s)               0.00274511
time/evaluation sampling (s)        0.330866
time/exploration sampling (s)       0.14213
time/logging (s)                    0.00434872
time/saving (s)                     0.00193554
time/training (s)                   2.00876
time/epoch (s)                      2.49079
time/total (s)                   1715.97
Epoch                             698
-----------------------------  ---------------
2019-04-23 01:42:12.672238 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 699 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    8.87876
trainer/QF2 Loss                    8.93227
trainer/Policy Loss                25.0286
trainer/Q1 Predictions Mean       -23.0905
trainer/Q1 Predictions Std         23.8755
trainer/Q1 Predictions Max         -7.11898
trainer/Q1 Predictions Min       -124.174
trainer/Q2 Predictions Mean       -23.0811
trainer/Q2 Predictions Std         23.8578
trainer/Q2 Predictions Max         -7.31015
trainer/Q2 Predictions Min       -123.88
trainer/Q Targets Mean            -23.0383
trainer/Q Targets Std              24.0392
trainer/Q Targets Max              -0.794174
trainer/Q Targets Min            -124.098
trainer/Log Pis Mean                1.96821
trainer/Log Pis Std                 1.3461
trainer/Log Pis Max                 8.61204
trainer/Log Pis Min                -2.05612
trainer/Policy mu Mean              0.00653444
trainer/Policy mu Std               0.478311
trainer/Policy mu Max               2.81895
trainer/Policy mu Min              -2.62712
trainer/Policy log std Mean        -2.29885
trainer/Policy log std Std          0.3782
trainer/Policy log std Max         -0.612
trainer/Policy log std Min         -2.79823
trainer/Alpha                       0.0885688
trainer/Alpha Loss                 -0.077067
exploration/num steps total    350200
exploration/num paths total      3502
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.727237
exploration/Rewards Std             1.21091
exploration/Rewards Max            -0.00694001
exploration/Rewards Min           -10.6886
exploration/Returns Mean          -72.7237
exploration/Returns Std            30.248
exploration/Returns Max           -29.1693
exploration/Returns Min          -123.597
exploration/Actions Mean            0.0517446
exploration/Actions Std             0.229603
exploration/Actions Max             0.999431
exploration/Actions Min            -0.535623
exploration/Num Paths               5
exploration/Average Returns       -72.7237
evaluation/num steps total          1.05e+06
evaluation/num paths total      10500
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.751001
evaluation/Rewards Std              1.33579
evaluation/Rewards Max             -0.0112336
evaluation/Rewards Min             -9.687
evaluation/Returns Mean           -75.1001
evaluation/Returns Std             83.539
evaluation/Returns Max             -8.14497
evaluation/Returns Min           -288.889
evaluation/Actions Mean            -0.00160128
evaluation/Actions Std              0.187045
evaluation/Actions Max              0.998207
evaluation/Actions Min             -0.997803
evaluation/Num Paths               15
evaluation/Average Returns        -75.1001
time/data storing (s)               0.00263678
time/evaluation sampling (s)        0.331001
time/exploration sampling (s)       0.135723
time/logging (s)                    0.00478242
time/saving (s)                     0.00954026
time/training (s)                   2.01608
time/epoch (s)                      2.49977
time/total (s)                   1718.48
Epoch                             699
-----------------------------  ---------------
2019-04-23 01:42:15.148767 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 700 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.373753
trainer/QF2 Loss                    0.394012
trainer/Policy Loss                21.0147
trainer/Q1 Predictions Mean       -19.2925
trainer/Q1 Predictions Std         21.3943
trainer/Q1 Predictions Max         -7.15762
trainer/Q1 Predictions Min       -121.832
trainer/Q2 Predictions Mean       -19.2769
trainer/Q2 Predictions Std         21.3831
trainer/Q2 Predictions Max         -7.14428
trainer/Q2 Predictions Min       -121.552
trainer/Q Targets Mean            -19.5882
trainer/Q Targets Std              21.8718
trainer/Q Targets Max              -7.28955
trainer/Q Targets Min            -124.351
trainer/Log Pis Mean                1.68488
trainer/Log Pis Std                 1.46539
trainer/Log Pis Max                 5.28881
trainer/Log Pis Min                -6.57287
trainer/Policy mu Mean              0.00564853
trainer/Policy mu Std               0.30253
trainer/Policy mu Max               2.70479
trainer/Policy mu Min              -1.67843
trainer/Policy log std Mean        -2.26958
trainer/Policy log std Std          0.325874
trainer/Policy log std Max         -0.730557
trainer/Policy log std Min         -2.77134
trainer/Alpha                       0.088437
trainer/Alpha Loss                 -0.764291
exploration/num steps total    350700
exploration/num paths total      3507
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.585621
exploration/Rewards Std             0.953195
exploration/Rewards Max            -0.0266607
exploration/Rewards Min            -9.31121
exploration/Returns Mean          -58.5621
exploration/Returns Std            20.2133
exploration/Returns Max           -27.5463
exploration/Returns Min           -85.5205
exploration/Actions Mean           -0.000771978
exploration/Actions Std             0.204211
exploration/Actions Max             0.996987
exploration/Actions Min            -0.997997
exploration/Num Paths               5
exploration/Average Returns       -58.5621
evaluation/num steps total          1.0515e+06
evaluation/num paths total      10515
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.05368
evaluation/Rewards Std              1.48267
evaluation/Rewards Max             -0.00998585
evaluation/Rewards Min            -10.4596
evaluation/Returns Mean          -105.368
evaluation/Returns Std             90.4044
evaluation/Returns Max            -23.277
evaluation/Returns Min           -279.816
evaluation/Actions Mean             0.00801556
evaluation/Actions Std              0.197066
evaluation/Actions Max              0.997417
evaluation/Actions Min             -0.996892
evaluation/Num Paths               15
evaluation/Average Returns       -105.368
time/data storing (s)               0.00256799
time/evaluation sampling (s)        0.327617
time/exploration sampling (s)       0.138454
time/logging (s)                    0.00495464
time/saving (s)                     0.00201857
time/training (s)                   1.98795
time/epoch (s)                      2.46356
time/total (s)                   1720.94
Epoch                             700
-----------------------------  ----------------
2019-04-23 01:42:17.646120 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 701 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0897879
trainer/QF2 Loss                    0.133962
trainer/Policy Loss                23.1893
trainer/Q1 Predictions Mean       -21.366
trainer/Q1 Predictions Std         25.7655
trainer/Q1 Predictions Max         -7.15843
trainer/Q1 Predictions Min       -125.015
trainer/Q2 Predictions Mean       -21.3538
trainer/Q2 Predictions Std         25.7225
trainer/Q2 Predictions Max         -7.25429
trainer/Q2 Predictions Min       -124.988
trainer/Q Targets Mean            -21.5211
trainer/Q Targets Std              25.7944
trainer/Q Targets Max              -7.28149
trainer/Q Targets Min            -125.029
trainer/Log Pis Mean                1.88375
trainer/Log Pis Std                 1.24607
trainer/Log Pis Max                 6.13438
trainer/Log Pis Min                -1.82984
trainer/Policy mu Mean             -0.0219595
trainer/Policy mu Std               0.371233
trainer/Policy mu Max               3.06295
trainer/Policy mu Min              -2.82264
trainer/Policy log std Mean        -2.29425
trainer/Policy log std Std          0.323002
trainer/Policy log std Max         -0.488224
trainer/Policy log std Min         -2.80088
trainer/Alpha                       0.0894173
trainer/Alpha Loss                 -0.280675
exploration/num steps total    351200
exploration/num paths total      3512
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.378714
exploration/Rewards Std             0.682125
exploration/Rewards Max            -0.00308625
exploration/Rewards Min            -6.24008
exploration/Returns Mean          -37.8714
exploration/Returns Std            14.9962
exploration/Returns Max           -18.2502
exploration/Returns Min           -62.3727
exploration/Actions Mean           -0.00103481
exploration/Actions Std             0.18816
exploration/Actions Max             0.999618
exploration/Actions Min            -0.99758
exploration/Num Paths               5
exploration/Average Returns       -37.8714
evaluation/num steps total          1.053e+06
evaluation/num paths total      10530
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.632499
evaluation/Rewards Std              1.05536
evaluation/Rewards Max             -0.00846795
evaluation/Rewards Min             -9.53254
evaluation/Returns Mean           -63.2499
evaluation/Returns Std             62.82
evaluation/Returns Max             -4.93067
evaluation/Returns Min           -255.631
evaluation/Actions Mean            -0.00101854
evaluation/Actions Std              0.160266
evaluation/Actions Max              0.998421
evaluation/Actions Min             -0.994936
evaluation/Num Paths               15
evaluation/Average Returns        -63.2499
time/data storing (s)               0.00264187
time/evaluation sampling (s)        0.330745
time/exploration sampling (s)       0.134526
time/logging (s)                    0.00477622
time/saving (s)                     0.00152951
time/training (s)                   2.00871
time/epoch (s)                      2.48292
time/total (s)                   1723.43
Epoch                             701
-----------------------------  ---------------
2019-04-23 01:42:20.105004 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 702 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.09171
trainer/QF2 Loss                    1.08775
trainer/Policy Loss                26.245
trainer/Q1 Predictions Mean       -24.4548
trainer/Q1 Predictions Std         29.2059
trainer/Q1 Predictions Max         -7.17919
trainer/Q1 Predictions Min       -122.53
trainer/Q2 Predictions Mean       -24.4611
trainer/Q2 Predictions Std         29.2102
trainer/Q2 Predictions Max         -7.08418
trainer/Q2 Predictions Min       -122.619
trainer/Q Targets Mean            -24.66
trainer/Q Targets Std              29.6748
trainer/Q Targets Max              -0.185701
trainer/Q Targets Min            -124.291
trainer/Log Pis Mean                1.83348
trainer/Log Pis Std                 1.14727
trainer/Log Pis Max                 5.83193
trainer/Log Pis Min                -2.3012
trainer/Policy mu Mean              0.0222371
trainer/Policy mu Std               0.306539
trainer/Policy mu Max               2.77321
trainer/Policy mu Min              -0.776492
trainer/Policy log std Mean        -2.30367
trainer/Policy log std Std          0.304604
trainer/Policy log std Max         -0.605449
trainer/Policy log std Min         -2.77865
trainer/Alpha                       0.0901719
trainer/Alpha Loss                 -0.400643
exploration/num steps total    351700
exploration/num paths total      3517
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.651546
exploration/Rewards Std             0.628638
exploration/Rewards Max            -0.0148965
exploration/Rewards Min            -6.62798
exploration/Returns Mean          -65.1546
exploration/Returns Std            31.9224
exploration/Returns Max           -38.7984
exploration/Returns Min          -109.917
exploration/Actions Mean           -0.00211712
exploration/Actions Std             0.188298
exploration/Actions Max             0.996808
exploration/Actions Min            -0.995409
exploration/Num Paths               5
exploration/Average Returns       -65.1546
evaluation/num steps total          1.0545e+06
evaluation/num paths total      10545
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.566831
evaluation/Rewards Std              0.98482
evaluation/Rewards Max             -0.038418
evaluation/Rewards Min             -9.79085
evaluation/Returns Mean           -56.6831
evaluation/Returns Std             33.6365
evaluation/Returns Max            -18.1277
evaluation/Returns Min           -130.502
evaluation/Actions Mean             0.00608511
evaluation/Actions Std              0.168526
evaluation/Actions Max              0.997296
evaluation/Actions Min             -0.997552
evaluation/Num Paths               15
evaluation/Average Returns        -56.6831
time/data storing (s)               0.00273778
time/evaluation sampling (s)        0.332712
time/exploration sampling (s)       0.138409
time/logging (s)                    0.00479957
time/saving (s)                     0.00193038
time/training (s)                   1.96607
time/epoch (s)                      2.44666
time/total (s)                   1725.88
Epoch                             702
-----------------------------  ---------------
2019-04-23 01:42:22.608565 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 703 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.09772
trainer/QF2 Loss                    1.12392
trainer/Policy Loss                33.3018
trainer/Q1 Predictions Mean       -31.3614
trainer/Q1 Predictions Std         38.518
trainer/Q1 Predictions Max         -7.23649
trainer/Q1 Predictions Min       -124.28
trainer/Q2 Predictions Mean       -31.3598
trainer/Q2 Predictions Std         38.4889
trainer/Q2 Predictions Max         -7.38331
trainer/Q2 Predictions Min       -124.609
trainer/Q Targets Mean            -31.4469
trainer/Q Targets Std              38.7679
trainer/Q Targets Max              -0.199496
trainer/Q Targets Min            -125.038
trainer/Log Pis Mean                2.03224
trainer/Log Pis Std                 0.943062
trainer/Log Pis Max                 3.47602
trainer/Log Pis Min                -1.43161
trainer/Policy mu Mean             -0.0301949
trainer/Policy mu Std               0.193381
trainer/Policy mu Max               0.487679
trainer/Policy mu Min              -1.6041
trainer/Policy log std Mean        -2.33827
trainer/Policy log std Std          0.256545
trainer/Policy log std Max         -1.16189
trainer/Policy log std Min         -2.73491
trainer/Alpha                       0.0884987
trainer/Alpha Loss                  0.0781615
exploration/num steps total    352200
exploration/num paths total      3522
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.02631
exploration/Rewards Std             1.40063
exploration/Rewards Max            -0.0113539
exploration/Rewards Min           -10.4205
exploration/Returns Mean         -102.631
exploration/Returns Std            77.8069
exploration/Returns Max           -26.9077
exploration/Returns Min          -240.83
exploration/Actions Mean           -0.0421775
exploration/Actions Std             0.228225
exploration/Actions Max             0.963324
exploration/Actions Min            -0.999761
exploration/Num Paths               5
exploration/Average Returns      -102.631
evaluation/num steps total          1.056e+06
evaluation/num paths total      10560
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.949782
evaluation/Rewards Std              1.38863
evaluation/Rewards Max             -0.00755584
evaluation/Rewards Min            -10.9403
evaluation/Returns Mean           -94.9782
evaluation/Returns Std             78.6481
evaluation/Returns Max            -14.8682
evaluation/Returns Min           -265.117
evaluation/Actions Mean            -0.00463206
evaluation/Actions Std              0.188514
evaluation/Actions Max              0.998942
evaluation/Actions Min             -0.997775
evaluation/Num Paths               15
evaluation/Average Returns        -94.9782
time/data storing (s)               0.00277205
time/evaluation sampling (s)        0.328463
time/exploration sampling (s)       0.139715
time/logging (s)                    0.00486159
time/saving (s)                     0.00194895
time/training (s)                   2.01228
time/epoch (s)                      2.49005
time/total (s)                   1728.38
Epoch                             703
-----------------------------  ---------------
2019-04-23 01:42:25.119907 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 704 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.68042
trainer/QF2 Loss                    1.70533
trainer/Policy Loss                25.9504
trainer/Q1 Predictions Mean       -23.9469
trainer/Q1 Predictions Std         27.5601
trainer/Q1 Predictions Max         -7.38986
trainer/Q1 Predictions Min       -126.39
trainer/Q2 Predictions Mean       -23.9614
trainer/Q2 Predictions Std         27.5407
trainer/Q2 Predictions Max         -7.45886
trainer/Q2 Predictions Min       -126.48
trainer/Q Targets Mean            -23.9142
trainer/Q Targets Std              27.6212
trainer/Q Targets Max              -0.0367156
trainer/Q Targets Min            -125.793
trainer/Log Pis Mean                2.04074
trainer/Log Pis Std                 1.03152
trainer/Log Pis Max                 4.40864
trainer/Log Pis Min                -2.3839
trainer/Policy mu Mean             -0.0396697
trainer/Policy mu Std               0.384915
trainer/Policy mu Max               2.99662
trainer/Policy mu Min              -2.67521
trainer/Policy log std Mean        -2.29041
trainer/Policy log std Std          0.345149
trainer/Policy log std Max         -0.622737
trainer/Policy log std Min         -2.81007
trainer/Alpha                       0.0893126
trainer/Alpha Loss                  0.0984172
exploration/num steps total    352700
exploration/num paths total      3527
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.423659
exploration/Rewards Std             0.507016
exploration/Rewards Max            -0.0138409
exploration/Rewards Min            -4.83152
exploration/Returns Mean          -42.3659
exploration/Returns Std            33.0319
exploration/Returns Max           -12.6533
exploration/Returns Min          -106.496
exploration/Actions Mean            0.0168601
exploration/Actions Std             0.142116
exploration/Actions Max             0.994553
exploration/Actions Min            -0.404693
exploration/Num Paths               5
exploration/Average Returns       -42.3659
evaluation/num steps total          1.0575e+06
evaluation/num paths total      10575
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.405055
evaluation/Rewards Std              0.894041
evaluation/Rewards Max             -0.00198782
evaluation/Rewards Min             -9.22275
evaluation/Returns Mean           -40.5055
evaluation/Returns Std             31.1922
evaluation/Returns Max             -8.49783
evaluation/Returns Min           -131.687
evaluation/Actions Mean            -0.00879146
evaluation/Actions Std              0.172244
evaluation/Actions Max              0.994479
evaluation/Actions Min             -0.996898
evaluation/Num Paths               15
evaluation/Average Returns        -40.5055
time/data storing (s)               0.00272569
time/evaluation sampling (s)        0.321283
time/exploration sampling (s)       0.140203
time/logging (s)                    0.004793
time/saving (s)                     0.00195572
time/training (s)                   2.02616
time/epoch (s)                      2.49712
time/total (s)                   1730.88
Epoch                             704
-----------------------------  ---------------
2019-04-23 01:42:27.599281 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 705 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   34.9784
trainer/QF2 Loss                   34.7813
trainer/Policy Loss                23.3094
trainer/Q1 Predictions Mean       -21.6705
trainer/Q1 Predictions Std         24.5317
trainer/Q1 Predictions Max         -7.43038
trainer/Q1 Predictions Min       -122.16
trainer/Q2 Predictions Mean       -21.672
trainer/Q2 Predictions Std         24.522
trainer/Q2 Predictions Max         -7.39994
trainer/Q2 Predictions Min       -122.032
trainer/Q Targets Mean            -21.0876
trainer/Q Targets Std              24.3554
trainer/Q Targets Max              -1.38583
trainer/Q Targets Min            -122.321
trainer/Log Pis Mean                1.63331
trainer/Log Pis Std                 1.52439
trainer/Log Pis Max                 5.38513
trainer/Log Pis Min                -4.1164
trainer/Policy mu Mean              0.0313101
trainer/Policy mu Std               0.481318
trainer/Policy mu Max               2.84698
trainer/Policy mu Min              -2.68628
trainer/Policy log std Mean        -2.22396
trainer/Policy log std Std          0.391148
trainer/Policy log std Max         -0.52606
trainer/Policy log std Min         -2.85756
trainer/Alpha                       0.0890637
trainer/Alpha Loss                 -0.88677
exploration/num steps total    353200
exploration/num paths total      3532
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.48026
exploration/Rewards Std             1.23009
exploration/Rewards Max            -0.00275753
exploration/Rewards Min            -9.86375
exploration/Returns Mean          -48.026
exploration/Returns Std            14.5346
exploration/Returns Max           -27.6365
exploration/Returns Min           -69.1288
exploration/Actions Mean            0.00305214
exploration/Actions Std             0.245402
exploration/Actions Max             0.999441
exploration/Actions Min            -0.99897
exploration/Num Paths               5
exploration/Average Returns       -48.026
evaluation/num steps total          1.059e+06
evaluation/num paths total      10590
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.449485
evaluation/Rewards Std              1.11775
evaluation/Rewards Max             -0.0121544
evaluation/Rewards Min            -11.26
evaluation/Returns Mean           -44.9485
evaluation/Returns Std             27.8643
evaluation/Returns Max             -8.38133
evaluation/Returns Min           -106.861
evaluation/Actions Mean             0.0169237
evaluation/Actions Std              0.194285
evaluation/Actions Max              0.998912
evaluation/Actions Min             -0.996839
evaluation/Num Paths               15
evaluation/Average Returns        -44.9485
time/data storing (s)               0.00256822
time/evaluation sampling (s)        0.330357
time/exploration sampling (s)       0.136958
time/logging (s)                    0.00486114
time/saving (s)                     0.00191736
time/training (s)                   1.98875
time/epoch (s)                      2.46541
time/total (s)                   1733.35
Epoch                             705
-----------------------------  ---------------
2019-04-23 01:42:30.093826 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 706 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0911288
trainer/QF2 Loss                    0.103839
trainer/Policy Loss                30.019
trainer/Q1 Predictions Mean       -28.0615
trainer/Q1 Predictions Std         33.345
trainer/Q1 Predictions Max         -7.40229
trainer/Q1 Predictions Min       -120.881
trainer/Q2 Predictions Mean       -28.0548
trainer/Q2 Predictions Std         33.2972
trainer/Q2 Predictions Max         -7.49339
trainer/Q2 Predictions Min       -120.623
trainer/Q Targets Mean            -28.1869
trainer/Q Targets Std              33.4615
trainer/Q Targets Max              -7.34478
trainer/Q Targets Min            -120.993
trainer/Log Pis Mean                2.03871
trainer/Log Pis Std                 0.982789
trainer/Log Pis Max                 4.03096
trainer/Log Pis Min                -1.23697
trainer/Policy mu Mean             -0.0269439
trainer/Policy mu Std               0.517416
trainer/Policy mu Max               2.48171
trainer/Policy mu Min              -3.45536
trainer/Policy log std Mean        -2.30329
trainer/Policy log std Std          0.404013
trainer/Policy log std Max         -0.485486
trainer/Policy log std Min         -2.91671
trainer/Alpha                       0.0907271
trainer/Alpha Loss                  0.0929034
exploration/num steps total    353700
exploration/num paths total      3537
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.616834
exploration/Rewards Std             1.20864
exploration/Rewards Max            -0.0105728
exploration/Rewards Min           -11.0599
exploration/Returns Mean          -61.6834
exploration/Returns Std            42.6913
exploration/Returns Max           -28.5286
exploration/Returns Min          -145.019
exploration/Actions Mean            0.00380144
exploration/Actions Std             0.24103
exploration/Actions Max             0.992591
exploration/Actions Min            -0.997517
exploration/Num Paths               5
exploration/Average Returns       -61.6834
evaluation/num steps total          1.0605e+06
evaluation/num paths total      10605
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.628503
evaluation/Rewards Std              1.22285
evaluation/Rewards Max             -0.00996398
evaluation/Rewards Min            -11.8506
evaluation/Returns Mean           -62.8503
evaluation/Returns Std             55.6753
evaluation/Returns Max            -16.8253
evaluation/Returns Min           -219.17
evaluation/Actions Mean             0.00196005
evaluation/Actions Std              0.188026
evaluation/Actions Max              0.998292
evaluation/Actions Min             -0.997811
evaluation/Num Paths               15
evaluation/Average Returns        -62.8503
time/data storing (s)               0.00270323
time/evaluation sampling (s)        0.324971
time/exploration sampling (s)       0.139875
time/logging (s)                    0.00482847
time/saving (s)                     0.00154153
time/training (s)                   2.00665
time/epoch (s)                      2.48057
time/total (s)                   1735.83
Epoch                             706
-----------------------------  ---------------
2019-04-23 01:42:32.577428 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 707 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    7.32674
trainer/QF2 Loss                    7.41508
trainer/Policy Loss                26.7117
trainer/Q1 Predictions Mean       -24.9478
trainer/Q1 Predictions Std         29.7084
trainer/Q1 Predictions Max         -7.42279
trainer/Q1 Predictions Min       -118.771
trainer/Q2 Predictions Mean       -24.9227
trainer/Q2 Predictions Std         29.7116
trainer/Q2 Predictions Max         -7.40839
trainer/Q2 Predictions Min       -118.742
trainer/Q Targets Mean            -24.9002
trainer/Q Targets Std              30.1885
trainer/Q Targets Max              -0.838554
trainer/Q Targets Min            -120.01
trainer/Log Pis Mean                1.8365
trainer/Log Pis Std                 1.13756
trainer/Log Pis Max                 4.67595
trainer/Log Pis Min                -3.01763
trainer/Policy mu Mean             -0.00923418
trainer/Policy mu Std               0.292267
trainer/Policy mu Max               2.36162
trainer/Policy mu Min              -2.76832
trainer/Policy log std Mean        -2.31413
trainer/Policy log std Std          0.29543
trainer/Policy log std Max         -0.677142
trainer/Policy log std Min         -3.11605
trainer/Alpha                       0.0898031
trainer/Alpha Loss                 -0.394049
exploration/num steps total    354200
exploration/num paths total      3542
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.486712
exploration/Rewards Std             1.01332
exploration/Rewards Max            -0.0135925
exploration/Rewards Min            -8.99988
exploration/Returns Mean          -48.6712
exploration/Returns Std            27.28
exploration/Returns Max           -17.1569
exploration/Returns Min           -94.5397
exploration/Actions Mean           -0.00178401
exploration/Actions Std             0.212687
exploration/Actions Max             0.996982
exploration/Actions Min            -0.998208
exploration/Num Paths               5
exploration/Average Returns       -48.6712
evaluation/num steps total          1.062e+06
evaluation/num paths total      10620
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.553486
evaluation/Rewards Std              0.920592
evaluation/Rewards Max             -0.00319301
evaluation/Rewards Min             -8.22677
evaluation/Returns Mean           -55.3486
evaluation/Returns Std             53.0507
evaluation/Returns Max             -3.76048
evaluation/Returns Min           -221.409
evaluation/Actions Mean            -0.00180829
evaluation/Actions Std              0.167602
evaluation/Actions Max              0.993451
evaluation/Actions Min             -0.997203
evaluation/Num Paths               15
evaluation/Average Returns        -55.3486
time/data storing (s)               0.002584
time/evaluation sampling (s)        0.329978
time/exploration sampling (s)       0.138779
time/logging (s)                    0.00477047
time/saving (s)                     0.00188776
time/training (s)                   1.99215
time/epoch (s)                      2.47015
time/total (s)                   1738.31
Epoch                             707
-----------------------------  ---------------
2019-04-23 01:42:35.086567 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 708 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.77327
trainer/QF2 Loss                    1.80655
trainer/Policy Loss                28.769
trainer/Q1 Predictions Mean       -26.8851
trainer/Q1 Predictions Std         29.3534
trainer/Q1 Predictions Max         -7.50506
trainer/Q1 Predictions Min       -119.441
trainer/Q2 Predictions Mean       -26.916
trainer/Q2 Predictions Std         29.3155
trainer/Q2 Predictions Max         -7.56032
trainer/Q2 Predictions Min       -119.315
trainer/Q Targets Mean            -26.7627
trainer/Q Targets Std              29.5142
trainer/Q Targets Max              -0.100587
trainer/Q Targets Min            -119.793
trainer/Log Pis Mean                1.89456
trainer/Log Pis Std                 1.22354
trainer/Log Pis Max                 5.53265
trainer/Log Pis Min                -4.48459
trainer/Policy mu Mean              0.00115885
trainer/Policy mu Std               0.406749
trainer/Policy mu Max               2.91802
trainer/Policy mu Min              -1.45876
trainer/Policy log std Mean        -2.29097
trainer/Policy log std Std          0.337863
trainer/Policy log std Max         -0.605399
trainer/Policy log std Min         -2.77092
trainer/Alpha                       0.0868714
trainer/Alpha Loss                 -0.257601
exploration/num steps total    354700
exploration/num paths total      3547
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.565341
exploration/Rewards Std             1.51099
exploration/Rewards Max            -0.0042572
exploration/Rewards Min           -11.9242
exploration/Returns Mean          -56.5341
exploration/Returns Std            14.2891
exploration/Returns Max           -34.2298
exploration/Returns Min           -75.2556
exploration/Actions Mean            0.00843623
exploration/Actions Std             0.255709
exploration/Actions Max             0.999789
exploration/Actions Min            -0.999614
exploration/Num Paths               5
exploration/Average Returns       -56.5341
evaluation/num steps total          1.0635e+06
evaluation/num paths total      10635
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.529482
evaluation/Rewards Std              1.05499
evaluation/Rewards Max             -0.0206967
evaluation/Rewards Min             -9.17544
evaluation/Returns Mean           -52.9482
evaluation/Returns Std             52.0604
evaluation/Returns Max             -7.56632
evaluation/Returns Min           -221.568
evaluation/Actions Mean             0.00107979
evaluation/Actions Std              0.168922
evaluation/Actions Max              0.997669
evaluation/Actions Min             -0.996093
evaluation/Num Paths               15
evaluation/Average Returns        -52.9482
time/data storing (s)               0.00251996
time/evaluation sampling (s)        0.332897
time/exploration sampling (s)       0.14007
time/logging (s)                    0.00481934
time/saving (s)                     0.00194231
time/training (s)                   2.0133
time/epoch (s)                      2.49554
time/total (s)                   1740.81
Epoch                             708
-----------------------------  ---------------
2019-04-23 01:42:37.580060 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 709 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.30531
trainer/QF2 Loss                    1.28656
trainer/Policy Loss                22.8185
trainer/Q1 Predictions Mean       -20.7549
trainer/Q1 Predictions Std         24.6742
trainer/Q1 Predictions Max         -7.34118
trainer/Q1 Predictions Min       -117.661
trainer/Q2 Predictions Mean       -20.7551
trainer/Q2 Predictions Std         24.6796
trainer/Q2 Predictions Max         -7.2791
trainer/Q2 Predictions Min       -118.27
trainer/Q Targets Mean            -21.1084
trainer/Q Targets Std              25.2525
trainer/Q Targets Max              -0.023022
trainer/Q Targets Min            -120.407
trainer/Log Pis Mean                2.12882
trainer/Log Pis Std                 0.982747
trainer/Log Pis Max                 5.48212
trainer/Log Pis Min                -0.805236
trainer/Policy mu Mean             -0.0206933
trainer/Policy mu Std               0.352987
trainer/Policy mu Max               2.00753
trainer/Policy mu Min              -2.90339
trainer/Policy log std Mean        -2.32879
trainer/Policy log std Std          0.325272
trainer/Policy log std Max         -0.620649
trainer/Policy log std Min         -2.81318
trainer/Alpha                       0.0865038
trainer/Alpha Loss                  0.315311
exploration/num steps total    355200
exploration/num paths total      3552
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.05754
exploration/Rewards Std             1.35705
exploration/Rewards Max            -0.0143058
exploration/Rewards Min            -9.77856
exploration/Returns Mean         -105.754
exploration/Returns Std            72.2957
exploration/Returns Max           -33.2299
exploration/Returns Min          -223.996
exploration/Actions Mean            0.00624696
exploration/Actions Std             0.235302
exploration/Actions Max             0.999207
exploration/Actions Min            -0.998807
exploration/Num Paths               5
exploration/Average Returns      -105.754
evaluation/num steps total          1.065e+06
evaluation/num paths total      10650
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.545904
evaluation/Rewards Std              1.02598
evaluation/Rewards Max             -0.00765748
evaluation/Rewards Min             -9.47425
evaluation/Returns Mean           -54.5904
evaluation/Returns Std             58.4549
evaluation/Returns Max             -6.47064
evaluation/Returns Min           -228.882
evaluation/Actions Mean            -0.00895749
evaluation/Actions Std              0.171623
evaluation/Actions Max              0.996729
evaluation/Actions Min             -0.998866
evaluation/Num Paths               15
evaluation/Average Returns        -54.5904
time/data storing (s)               0.00272085
time/evaluation sampling (s)        0.333831
time/exploration sampling (s)       0.13985
time/logging (s)                    0.00482398
time/saving (s)                     0.00194181
time/training (s)                   1.99571
time/epoch (s)                      2.47888
time/total (s)                   1743.29
Epoch                             709
-----------------------------  ---------------
2019-04-23 01:42:40.077551 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 710 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.89289
trainer/QF2 Loss                    1.93399
trainer/Policy Loss                28.7987
trainer/Q1 Predictions Mean       -27.0204
trainer/Q1 Predictions Std         32.527
trainer/Q1 Predictions Max         -7.22524
trainer/Q1 Predictions Min       -118.889
trainer/Q2 Predictions Mean       -27.0202
trainer/Q2 Predictions Std         32.5183
trainer/Q2 Predictions Max         -7.44799
trainer/Q2 Predictions Min       -118.85
trainer/Q Targets Mean            -26.8128
trainer/Q Targets Std              32.6356
trainer/Q Targets Max              -0.230177
trainer/Q Targets Min            -118.914
trainer/Log Pis Mean                1.82274
trainer/Log Pis Std                 1.24594
trainer/Log Pis Max                 5.50059
trainer/Log Pis Min                -3.35546
trainer/Policy mu Mean              0.0584497
trainer/Policy mu Std               0.394784
trainer/Policy mu Max               3.27655
trainer/Policy mu Min              -1.48395
trainer/Policy log std Mean        -2.23741
trainer/Policy log std Std          0.365547
trainer/Policy log std Max         -0.879797
trainer/Policy log std Min         -2.88099
trainer/Alpha                       0.0877392
trainer/Alpha Loss                 -0.431346
exploration/num steps total    355700
exploration/num paths total      3557
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.861772
exploration/Rewards Std             1.07742
exploration/Rewards Max            -0.00953064
exploration/Rewards Min            -8.17038
exploration/Returns Mean          -86.1772
exploration/Returns Std            71.9054
exploration/Returns Max           -26.7994
exploration/Returns Min          -217.38
exploration/Actions Mean            0.00126272
exploration/Actions Std             0.194471
exploration/Actions Max             0.999311
exploration/Actions Min            -0.99803
exploration/Num Paths               5
exploration/Average Returns       -86.1772
evaluation/num steps total          1.0665e+06
evaluation/num paths total      10665
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.372096
evaluation/Rewards Std              0.981181
evaluation/Rewards Max             -0.0110118
evaluation/Rewards Min            -11.1817
evaluation/Returns Mean           -37.2096
evaluation/Returns Std             22.9905
evaluation/Returns Max            -11.4472
evaluation/Returns Min           -102.064
evaluation/Actions Mean             0.00614779
evaluation/Actions Std              0.180288
evaluation/Actions Max              0.99745
evaluation/Actions Min             -0.998702
evaluation/Num Paths               15
evaluation/Average Returns        -37.2096
time/data storing (s)               0.00279922
time/evaluation sampling (s)        0.327472
time/exploration sampling (s)       0.141593
time/logging (s)                    0.00487784
time/saving (s)                     0.00199199
time/training (s)                   2.00448
time/epoch (s)                      2.48321
time/total (s)                   1745.78
Epoch                             710
-----------------------------  ---------------
2019-04-23 01:42:42.582149 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 711 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   11.8493
trainer/QF2 Loss                   11.873
trainer/Policy Loss                24.1849
trainer/Q1 Predictions Mean       -22.1012
trainer/Q1 Predictions Std         23.794
trainer/Q1 Predictions Max         -7.29538
trainer/Q1 Predictions Min       -118.727
trainer/Q2 Predictions Mean       -22.1377
trainer/Q2 Predictions Std         23.8111
trainer/Q2 Predictions Max         -7.52297
trainer/Q2 Predictions Min       -119.308
trainer/Q Targets Mean            -21.8083
trainer/Q Targets Std              23.8848
trainer/Q Targets Max              -0.780857
trainer/Q Targets Min            -118.622
trainer/Log Pis Mean                2.09185
trainer/Log Pis Std                 1.15445
trainer/Log Pis Max                 7.06293
trainer/Log Pis Min                -1.54402
trainer/Policy mu Mean              0.0388834
trainer/Policy mu Std               0.532989
trainer/Policy mu Max               2.75115
trainer/Policy mu Min              -3.39411
trainer/Policy log std Mean        -2.22119
trainer/Policy log std Std          0.399349
trainer/Policy log std Max         -0.458697
trainer/Policy log std Min         -2.89862
trainer/Alpha                       0.0880156
trainer/Alpha Loss                  0.223221
exploration/num steps total    356200
exploration/num paths total      3562
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.301689
exploration/Rewards Std             0.786141
exploration/Rewards Max            -0.00223731
exploration/Rewards Min           -10.2091
exploration/Returns Mean          -30.1689
exploration/Returns Std            17.1557
exploration/Returns Max           -20.0546
exploration/Returns Min           -64.4179
exploration/Actions Mean           -0.00109253
exploration/Actions Std             0.190657
exploration/Actions Max             0.998226
exploration/Actions Min            -0.995991
exploration/Num Paths               5
exploration/Average Returns       -30.1689
evaluation/num steps total          1.068e+06
evaluation/num paths total      10680
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.572977
evaluation/Rewards Std              1.11456
evaluation/Rewards Max             -0.0200612
evaluation/Rewards Min             -9.78217
evaluation/Returns Mean           -57.2977
evaluation/Returns Std             61.5623
evaluation/Returns Max            -10.1571
evaluation/Returns Min           -243.902
evaluation/Actions Mean            -0.0082245
evaluation/Actions Std              0.174679
evaluation/Actions Max              0.994128
evaluation/Actions Min             -0.998082
evaluation/Num Paths               15
evaluation/Average Returns        -57.2977
time/data storing (s)               0.00275245
time/evaluation sampling (s)        0.327401
time/exploration sampling (s)       0.139471
time/logging (s)                    0.0040598
time/saving (s)                     0.0100382
time/training (s)                   2.00629
time/epoch (s)                      2.49002
time/total (s)                   1748.27
Epoch                             711
-----------------------------  ---------------
2019-04-23 01:42:45.073956 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 712 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   32.9838
trainer/QF2 Loss                   33.0077
trainer/Policy Loss                26.7558
trainer/Q1 Predictions Mean       -24.9742
trainer/Q1 Predictions Std         28.9282
trainer/Q1 Predictions Max         -7.20861
trainer/Q1 Predictions Min       -114.814
trainer/Q2 Predictions Mean       -24.9695
trainer/Q2 Predictions Std         28.9271
trainer/Q2 Predictions Max         -7.12994
trainer/Q2 Predictions Min       -114.643
trainer/Q Targets Mean            -24.8952
trainer/Q Targets Std              29.4624
trainer/Q Targets Max              -1.26445
trainer/Q Targets Min            -117.045
trainer/Log Pis Mean                1.81463
trainer/Log Pis Std                 1.00817
trainer/Log Pis Max                 4.35158
trainer/Log Pis Min                -1.1249
trainer/Policy mu Mean              0.0129363
trainer/Policy mu Std               0.396896
trainer/Policy mu Max               2.74884
trainer/Policy mu Min              -2.52435
trainer/Policy log std Mean        -2.28844
trainer/Policy log std Std          0.355993
trainer/Policy log std Max         -0.490347
trainer/Policy log std Min         -2.92597
trainer/Alpha                       0.0873065
trainer/Alpha Loss                 -0.451979
exploration/num steps total    356700
exploration/num paths total      3567
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.554763
exploration/Rewards Std             1.11196
exploration/Rewards Max            -0.00177862
exploration/Rewards Min            -9.03086
exploration/Returns Mean          -55.4763
exploration/Returns Std            30.6868
exploration/Returns Max           -21.2132
exploration/Returns Min          -109.168
exploration/Actions Mean            0.00755948
exploration/Actions Std             0.233288
exploration/Actions Max             0.998914
exploration/Actions Min            -0.99931
exploration/Num Paths               5
exploration/Average Returns       -55.4763
evaluation/num steps total          1.0695e+06
evaluation/num paths total      10695
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.477513
evaluation/Rewards Std              1.08818
evaluation/Rewards Max             -0.0130376
evaluation/Rewards Min            -10.6251
evaluation/Returns Mean           -47.7513
evaluation/Returns Std             36.3537
evaluation/Returns Max             -7.34191
evaluation/Returns Min           -127.224
evaluation/Actions Mean             0.0127551
evaluation/Actions Std              0.192241
evaluation/Actions Max              0.998723
evaluation/Actions Min             -0.997669
evaluation/Num Paths               15
evaluation/Average Returns        -47.7513
time/data storing (s)               0.00280824
time/evaluation sampling (s)        0.322659
time/exploration sampling (s)       0.141702
time/logging (s)                    0.00481726
time/saving (s)                     0.00196469
time/training (s)                   2.00629
time/epoch (s)                      2.48024
time/total (s)                   1750.76
Epoch                             712
-----------------------------  ---------------
2019-04-23 01:42:47.577398 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 713 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.32923
trainer/QF2 Loss                    1.31441
trainer/Policy Loss                27.4894
trainer/Q1 Predictions Mean       -25.3277
trainer/Q1 Predictions Std         26.6132
trainer/Q1 Predictions Max         -7.23113
trainer/Q1 Predictions Min       -121.053
trainer/Q2 Predictions Mean       -25.3561
trainer/Q2 Predictions Std         26.6193
trainer/Q2 Predictions Max         -7.18255
trainer/Q2 Predictions Min       -122.05
trainer/Q Targets Mean            -25.5775
trainer/Q Targets Std              27.1377
trainer/Q Targets Max              -0.256835
trainer/Q Targets Min            -123.471
trainer/Log Pis Mean                2.23929
trainer/Log Pis Std                 1.01858
trainer/Log Pis Max                 5.10051
trainer/Log Pis Min                -2.10591
trainer/Policy mu Mean             -0.0862227
trainer/Policy mu Std               0.421528
trainer/Policy mu Max               0.782359
trainer/Policy mu Min              -3.00635
trainer/Policy log std Mean        -2.30516
trainer/Policy log std Std          0.352336
trainer/Policy log std Max         -0.778665
trainer/Policy log std Min         -2.82289
trainer/Alpha                       0.0865864
trainer/Alpha Loss                  0.585477
exploration/num steps total    357200
exploration/num paths total      3572
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.0153
exploration/Rewards Std             1.17035
exploration/Rewards Max            -0.0161386
exploration/Rewards Min            -7.89009
exploration/Returns Mean         -101.53
exploration/Returns Std            82.1355
exploration/Returns Max           -20.285
exploration/Returns Min          -244.441
exploration/Actions Mean           -0.00194198
exploration/Actions Std             0.208769
exploration/Actions Max             0.9971
exploration/Actions Min            -0.994216
exploration/Num Paths               5
exploration/Average Returns      -101.53
evaluation/num steps total          1.071e+06
evaluation/num paths total      10710
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.518085
evaluation/Rewards Std              1.0992
evaluation/Rewards Max             -0.0103479
evaluation/Rewards Min            -11.1593
evaluation/Returns Mean           -51.8085
evaluation/Returns Std             35.0962
evaluation/Returns Max            -16.4896
evaluation/Returns Min           -141.127
evaluation/Actions Mean            -0.00481195
evaluation/Actions Std              0.182471
evaluation/Actions Max              0.998776
evaluation/Actions Min             -0.996768
evaluation/Num Paths               15
evaluation/Average Returns        -51.8085
time/data storing (s)               0.00276153
time/evaluation sampling (s)        0.326947
time/exploration sampling (s)       0.143532
time/logging (s)                    0.0035614
time/saving (s)                     0.00190058
time/training (s)                   2.00935
time/epoch (s)                      2.48805
time/total (s)                   1753.25
Epoch                             713
-----------------------------  ---------------
2019-04-23 01:42:50.073492 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 714 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.25475
trainer/QF2 Loss                    0.882413
trainer/Policy Loss                30.3706
trainer/Q1 Predictions Mean       -28.5596
trainer/Q1 Predictions Std         35.2128
trainer/Q1 Predictions Max         -7.20425
trainer/Q1 Predictions Min       -148.861
trainer/Q2 Predictions Mean       -28.6135
trainer/Q2 Predictions Std         35.308
trainer/Q2 Predictions Max         -7.2033
trainer/Q2 Predictions Min       -152.919
trainer/Q Targets Mean            -29.1442
trainer/Q Targets Std              36.0289
trainer/Q Targets Max              -7.30606
trainer/Q Targets Min            -155.59
trainer/Log Pis Mean                1.83252
trainer/Log Pis Std                 1.36729
trainer/Log Pis Max                 6.39702
trainer/Log Pis Min                -2.52673
trainer/Policy mu Mean             -0.0133866
trainer/Policy mu Std               0.498837
trainer/Policy mu Max               2.87452
trainer/Policy mu Min              -3.41037
trainer/Policy log std Mean        -2.26506
trainer/Policy log std Std          0.407118
trainer/Policy log std Max         -0.0995636
trainer/Policy log std Min         -2.81949
trainer/Alpha                       0.0869142
trainer/Alpha Loss                 -0.40912
exploration/num steps total    357700
exploration/num paths total      3577
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.388925
exploration/Rewards Std             0.707806
exploration/Rewards Max            -0.00630381
exploration/Rewards Min            -8.90637
exploration/Returns Mean          -38.8925
exploration/Returns Std             9.04289
exploration/Returns Max           -26.0111
exploration/Returns Min           -53.306
exploration/Actions Mean            0.0223639
exploration/Actions Std             0.18478
exploration/Actions Max             0.999978
exploration/Actions Min            -0.96232
exploration/Num Paths               5
exploration/Average Returns       -38.8925
evaluation/num steps total          1.0725e+06
evaluation/num paths total      10725
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.516952
evaluation/Rewards Std              1.17951
evaluation/Rewards Max             -0.0189825
evaluation/Rewards Min             -9.75481
evaluation/Returns Mean           -51.6952
evaluation/Returns Std             48.2139
evaluation/Returns Max             -8.80026
evaluation/Returns Min           -215.099
evaluation/Actions Mean            -0.00161738
evaluation/Actions Std              0.193634
evaluation/Actions Max              0.998641
evaluation/Actions Min             -0.996273
evaluation/Num Paths               15
evaluation/Average Returns        -51.6952
time/data storing (s)               0.00286447
time/evaluation sampling (s)        0.324645
time/exploration sampling (s)       0.140865
time/logging (s)                    0.00482003
time/saving (s)                     0.00207639
time/training (s)                   2.00913
time/epoch (s)                      2.4844
time/total (s)                   1755.74
Epoch                             714
-----------------------------  ---------------
2019-04-23 01:42:52.560493 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 715 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.732965
trainer/QF2 Loss                    0.713645
trainer/Policy Loss                24.8471
trainer/Q1 Predictions Mean       -23.0752
trainer/Q1 Predictions Std         31.0051
trainer/Q1 Predictions Max         -7.39451
trainer/Q1 Predictions Min       -128.679
trainer/Q2 Predictions Mean       -23.058
trainer/Q2 Predictions Std         30.9206
trainer/Q2 Predictions Max         -7.4231
trainer/Q2 Predictions Min       -127.127
trainer/Q Targets Mean            -23.0851
trainer/Q Targets Std              31.0962
trainer/Q Targets Max              -0.0924699
trainer/Q Targets Min            -126.868
trainer/Log Pis Mean                1.88089
trainer/Log Pis Std                 1.02231
trainer/Log Pis Max                 3.42629
trainer/Log Pis Min                -3.00325
trainer/Policy mu Mean             -0.0415374
trainer/Policy mu Std               0.32834
trainer/Policy mu Max               1.0124
trainer/Policy mu Min              -2.5215
trainer/Policy log std Mean        -2.24243
trainer/Policy log std Std          0.339802
trainer/Policy log std Max         -0.695172
trainer/Policy log std Min         -2.87939
trainer/Alpha                       0.0864102
trainer/Alpha Loss                 -0.291674
exploration/num steps total    358200
exploration/num paths total      3582
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.868906
exploration/Rewards Std             1.39166
exploration/Rewards Max            -0.0140645
exploration/Rewards Min            -9.76332
exploration/Returns Mean          -86.8906
exploration/Returns Std            65.2603
exploration/Returns Max           -32.3582
exploration/Returns Min          -214.138
exploration/Actions Mean            0.0127109
exploration/Actions Std             0.21744
exploration/Actions Max             0.999338
exploration/Actions Min            -0.997624
exploration/Num Paths               5
exploration/Average Returns       -86.8906
evaluation/num steps total          1.074e+06
evaluation/num paths total      10740
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.574315
evaluation/Rewards Std              1.00963
evaluation/Rewards Max             -0.0192732
evaluation/Rewards Min             -8.79159
evaluation/Returns Mean           -57.4315
evaluation/Returns Std             67.567
evaluation/Returns Max             -9.19984
evaluation/Returns Min           -227.829
evaluation/Actions Mean             0.00332778
evaluation/Actions Std              0.1757
evaluation/Actions Max              0.993191
evaluation/Actions Min             -0.997284
evaluation/Num Paths               15
evaluation/Average Returns        -57.4315
time/data storing (s)               0.00275711
time/evaluation sampling (s)        0.323748
time/exploration sampling (s)       0.140152
time/logging (s)                    0.00482973
time/saving (s)                     0.00191701
time/training (s)                   2.00122
time/epoch (s)                      2.47463
time/total (s)                   1758.22
Epoch                             715
-----------------------------  ---------------
2019-04-23 01:42:55.060260 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 716 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.902708
trainer/QF2 Loss                    0.932718
trainer/Policy Loss                23.132
trainer/Q1 Predictions Mean       -21.3098
trainer/Q1 Predictions Std         25.529
trainer/Q1 Predictions Max         -7.48645
trainer/Q1 Predictions Min       -115.626
trainer/Q2 Predictions Mean       -21.2982
trainer/Q2 Predictions Std         25.4681
trainer/Q2 Predictions Max         -7.61915
trainer/Q2 Predictions Min       -115.269
trainer/Q Targets Mean            -21.4181
trainer/Q Targets Std              25.6464
trainer/Q Targets Max              -0.194928
trainer/Q Targets Min            -116.145
trainer/Log Pis Mean                1.92911
trainer/Log Pis Std                 1.07135
trainer/Log Pis Max                 3.67349
trainer/Log Pis Min                -1.13315
trainer/Policy mu Mean             -0.00487617
trainer/Policy mu Std               0.219389
trainer/Policy mu Max               0.586986
trainer/Policy mu Min              -2.13326
trainer/Policy log std Mean        -2.31996
trainer/Policy log std Std          0.327144
trainer/Policy log std Max         -0.605998
trainer/Policy log std Min         -2.9344
trainer/Alpha                       0.0852319
trainer/Alpha Loss                 -0.174549
exploration/num steps total    358700
exploration/num paths total      3587
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.476317
exploration/Rewards Std             0.898794
exploration/Rewards Max            -0.00123904
exploration/Rewards Min            -8.61871
exploration/Returns Mean          -47.6317
exploration/Returns Std            20.6928
exploration/Returns Max           -23.7648
exploration/Returns Min           -82.5403
exploration/Actions Mean           -0.0322018
exploration/Actions Std             0.215602
exploration/Actions Max             0.9579
exploration/Actions Min            -0.999281
exploration/Num Paths               5
exploration/Average Returns       -47.6317
evaluation/num steps total          1.0755e+06
evaluation/num paths total      10755
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.528606
evaluation/Rewards Std              1.10791
evaluation/Rewards Max             -0.00451205
evaluation/Rewards Min             -9.62788
evaluation/Returns Mean           -52.8606
evaluation/Returns Std             53.1358
evaluation/Returns Max             -6.84288
evaluation/Returns Min           -225.547
evaluation/Actions Mean            -0.000627432
evaluation/Actions Std              0.193277
evaluation/Actions Max              0.998244
evaluation/Actions Min             -0.997578
evaluation/Num Paths               15
evaluation/Average Returns        -52.8606
time/data storing (s)               0.00263272
time/evaluation sampling (s)        0.327722
time/exploration sampling (s)       0.141809
time/logging (s)                    0.00507312
time/saving (s)                     0.00192775
time/training (s)                   2.0067
time/epoch (s)                      2.48587
time/total (s)                   1760.71
Epoch                             716
-----------------------------  ----------------
2019-04-23 01:42:57.549799 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 717 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    3.19778
trainer/QF2 Loss                    3.16066
trainer/Policy Loss                26.7672
trainer/Q1 Predictions Mean       -24.7559
trainer/Q1 Predictions Std         27.0771
trainer/Q1 Predictions Max         -7.20434
trainer/Q1 Predictions Min       -113.741
trainer/Q2 Predictions Mean       -24.7644
trainer/Q2 Predictions Std         27.0791
trainer/Q2 Predictions Max         -7.27077
trainer/Q2 Predictions Min       -113.423
trainer/Q Targets Mean            -24.9784
trainer/Q Targets Std              27.6197
trainer/Q Targets Max              -0.207139
trainer/Q Targets Min            -114.728
trainer/Log Pis Mean                2.07364
trainer/Log Pis Std                 1.43566
trainer/Log Pis Max                 7.74879
trainer/Log Pis Min                -4.07577
trainer/Policy mu Mean              0.000428367
trainer/Policy mu Std               0.46223
trainer/Policy mu Max               2.87303
trainer/Policy mu Min              -3.24002
trainer/Policy log std Mean        -2.31956
trainer/Policy log std Std          0.39911
trainer/Policy log std Max         -0.391318
trainer/Policy log std Min         -2.83592
trainer/Alpha                       0.0851354
trainer/Alpha Loss                  0.18142
exploration/num steps total    359200
exploration/num paths total      3592
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.394158
exploration/Rewards Std             0.89883
exploration/Rewards Max            -0.00667674
exploration/Rewards Min            -8.53829
exploration/Returns Mean          -39.4158
exploration/Returns Std            23.3931
exploration/Returns Max           -18.3636
exploration/Returns Min           -82.8745
exploration/Actions Mean           -0.00866468
exploration/Actions Std             0.210803
exploration/Actions Max             0.991141
exploration/Actions Min            -0.993046
exploration/Num Paths               5
exploration/Average Returns       -39.4158
evaluation/num steps total          1.077e+06
evaluation/num paths total      10770
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.770001
evaluation/Rewards Std              1.21167
evaluation/Rewards Max             -0.0137388
evaluation/Rewards Min            -10.1986
evaluation/Returns Mean           -77.0001
evaluation/Returns Std             63.5704
evaluation/Returns Max             -6.84637
evaluation/Returns Min           -215.211
evaluation/Actions Mean            -0.0041616
evaluation/Actions Std              0.182712
evaluation/Actions Max              0.998657
evaluation/Actions Min             -0.997344
evaluation/Num Paths               15
evaluation/Average Returns        -77.0001
time/data storing (s)               0.00261562
time/evaluation sampling (s)        0.32601
time/exploration sampling (s)       0.140311
time/logging (s)                    0.00481809
time/saving (s)                     0.00191802
time/training (s)                   1.99995
time/epoch (s)                      2.47563
time/total (s)                   1763.19
Epoch                             717
-----------------------------  ----------------
2019-04-23 01:43:00.045663 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 718 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.88708
trainer/QF2 Loss                    1.90993
trainer/Policy Loss                23.6958
trainer/Q1 Predictions Mean       -21.8798
trainer/Q1 Predictions Std         24.8079
trainer/Q1 Predictions Max         -7.39016
trainer/Q1 Predictions Min       -115.907
trainer/Q2 Predictions Mean       -21.907
trainer/Q2 Predictions Std         24.8494
trainer/Q2 Predictions Max         -7.48986
trainer/Q2 Predictions Min       -117.426
trainer/Q Targets Mean            -21.8818
trainer/Q Targets Std              25.2525
trainer/Q Targets Max              -0.111138
trainer/Q Targets Min            -118.58
trainer/Log Pis Mean                1.87543
trainer/Log Pis Std                 1.0858
trainer/Log Pis Max                 4.93899
trainer/Log Pis Min                -1.31881
trainer/Policy mu Mean              0.0363684
trainer/Policy mu Std               0.332227
trainer/Policy mu Max               2.71523
trainer/Policy mu Min              -0.770475
trainer/Policy log std Mean        -2.25974
trainer/Policy log std Std          0.340429
trainer/Policy log std Max         -0.583898
trainer/Policy log std Min         -2.94224
trainer/Alpha                       0.0868253
trainer/Alpha Loss                 -0.304424
exploration/num steps total    359700
exploration/num paths total      3597
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.444052
exploration/Rewards Std             1.26963
exploration/Rewards Max            -0.00667077
exploration/Rewards Min           -10.3094
exploration/Returns Mean          -44.4052
exploration/Returns Std            19.4151
exploration/Returns Max           -20.3502
exploration/Returns Min           -69.3416
exploration/Actions Mean            0.021721
exploration/Actions Std             0.236685
exploration/Actions Max             0.998983
exploration/Actions Min            -0.99239
exploration/Num Paths               5
exploration/Average Returns       -44.4052
evaluation/num steps total          1.0785e+06
evaluation/num paths total      10785
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.707785
evaluation/Rewards Std              1.12219
evaluation/Rewards Max             -0.0146772
evaluation/Rewards Min            -10.1892
evaluation/Returns Mean           -70.7785
evaluation/Returns Std             84.4595
evaluation/Returns Max            -12.9962
evaluation/Returns Min           -253.128
evaluation/Actions Mean            -2.33631e-05
evaluation/Actions Std              0.170813
evaluation/Actions Max              0.997448
evaluation/Actions Min             -0.995688
evaluation/Num Paths               15
evaluation/Average Returns        -70.7785
time/data storing (s)               0.00288499
time/evaluation sampling (s)        0.326387
time/exploration sampling (s)       0.140313
time/logging (s)                    0.00484745
time/saving (s)                     0.0019774
time/training (s)                   2.00565
time/epoch (s)                      2.48206
time/total (s)                   1765.68
Epoch                             718
-----------------------------  ----------------
2019-04-23 01:43:02.552970 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 719 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.243312
trainer/QF2 Loss                    0.247479
trainer/Policy Loss                27.2534
trainer/Q1 Predictions Mean       -25.2701
trainer/Q1 Predictions Std         30.8297
trainer/Q1 Predictions Max         -7.34433
trainer/Q1 Predictions Min       -112.06
trainer/Q2 Predictions Mean       -25.2831
trainer/Q2 Predictions Std         30.8473
trainer/Q2 Predictions Max         -7.33332
trainer/Q2 Predictions Min       -111.92
trainer/Q Targets Mean            -25.4752
trainer/Q Targets Std              31.141
trainer/Q Targets Max              -7.31441
trainer/Q Targets Min            -113.081
trainer/Log Pis Mean                2.03202
trainer/Log Pis Std                 1.35644
trainer/Log Pis Max                 6.41444
trainer/Log Pis Min                -2.99597
trainer/Policy mu Mean              0.00432244
trainer/Policy mu Std               0.308279
trainer/Policy mu Max               2.50883
trainer/Policy mu Min              -2.47898
trainer/Policy log std Mean        -2.32116
trainer/Policy log std Std          0.355523
trainer/Policy log std Max         -0.600424
trainer/Policy log std Min         -2.99805
trainer/Alpha                       0.0867685
trainer/Alpha Loss                  0.0782654
exploration/num steps total    360200
exploration/num paths total      3602
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.509808
exploration/Rewards Std             0.533982
exploration/Rewards Max            -0.0135737
exploration/Rewards Min            -4.66488
exploration/Returns Mean          -50.9808
exploration/Returns Std            22.7158
exploration/Returns Max           -20.963
exploration/Returns Min           -81.325
exploration/Actions Mean            0.0101891
exploration/Actions Std             0.189504
exploration/Actions Max             0.992025
exploration/Actions Min            -0.987746
exploration/Num Paths               5
exploration/Average Returns       -50.9808
evaluation/num steps total          1.08e+06
evaluation/num paths total      10800
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.791381
evaluation/Rewards Std              1.33173
evaluation/Rewards Max             -0.00158539
evaluation/Rewards Min            -11.1653
evaluation/Returns Mean           -79.1381
evaluation/Returns Std             71.4808
evaluation/Returns Max            -15.7611
evaluation/Returns Min           -222.188
evaluation/Actions Mean            -0.0128697
evaluation/Actions Std              0.192282
evaluation/Actions Max              0.998004
evaluation/Actions Min             -0.997235
evaluation/Num Paths               15
evaluation/Average Returns        -79.1381
time/data storing (s)               0.00279645
time/evaluation sampling (s)        0.325695
time/exploration sampling (s)       0.136909
time/logging (s)                    0.00447641
time/saving (s)                     0.00193269
time/training (s)                   2.02084
time/epoch (s)                      2.49265
time/total (s)                   1768.17
Epoch                             719
-----------------------------  ---------------
2019-04-23 01:43:05.059516 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 720 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.584827
trainer/QF2 Loss                    0.562791
trainer/Policy Loss                23.7664
trainer/Q1 Predictions Mean       -21.8889
trainer/Q1 Predictions Std         23.0824
trainer/Q1 Predictions Max         -6.87617
trainer/Q1 Predictions Min       -109.993
trainer/Q2 Predictions Mean       -21.9023
trainer/Q2 Predictions Std         23.091
trainer/Q2 Predictions Max         -7.01309
trainer/Q2 Predictions Min       -110.152
trainer/Q Targets Mean            -22.293
trainer/Q Targets Std              23.6348
trainer/Q Targets Max              -7.22559
trainer/Q Targets Min            -112.313
trainer/Log Pis Mean                1.91204
trainer/Log Pis Std                 1.22305
trainer/Log Pis Max                 4.83126
trainer/Log Pis Min                -3.57854
trainer/Policy mu Mean              0.0139001
trainer/Policy mu Std               0.375954
trainer/Policy mu Max               3.17411
trainer/Policy mu Min              -2.32877
trainer/Policy log std Mean        -2.34629
trainer/Policy log std Std          0.352172
trainer/Policy log std Max         -0.708542
trainer/Policy log std Min         -3.01153
trainer/Alpha                       0.0858336
trainer/Alpha Loss                 -0.215982
exploration/num steps total    360700
exploration/num paths total      3607
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.441345
exploration/Rewards Std             0.81161
exploration/Rewards Max            -0.00818829
exploration/Rewards Min            -8.80905
exploration/Returns Mean          -44.1345
exploration/Returns Std            33.0729
exploration/Returns Max           -18.6391
exploration/Returns Min          -108.35
exploration/Actions Mean           -0.011041
exploration/Actions Std             0.209183
exploration/Actions Max             0.998694
exploration/Actions Min            -0.99905
exploration/Num Paths               5
exploration/Average Returns       -44.1345
evaluation/num steps total          1.0815e+06
evaluation/num paths total      10815
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.458746
evaluation/Rewards Std              0.907749
evaluation/Rewards Max             -0.0221007
evaluation/Rewards Min             -8.13515
evaluation/Returns Mean           -45.8746
evaluation/Returns Std             54.2993
evaluation/Returns Max             -4.6097
evaluation/Returns Min           -223.975
evaluation/Actions Mean            -0.0111517
evaluation/Actions Std              0.168665
evaluation/Actions Max              0.995722
evaluation/Actions Min             -0.996086
evaluation/Num Paths               15
evaluation/Average Returns        -45.8746
time/data storing (s)               0.00271989
time/evaluation sampling (s)        0.333981
time/exploration sampling (s)       0.140359
time/logging (s)                    0.00364622
time/saving (s)                     0.00206808
time/training (s)                   2.00875
time/epoch (s)                      2.49153
time/total (s)                   1770.67
Epoch                             720
-----------------------------  ---------------
2019-04-23 01:43:07.550265 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 721 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.10069
trainer/QF2 Loss                    1.08958
trainer/Policy Loss                25.0994
trainer/Q1 Predictions Mean       -22.8819
trainer/Q1 Predictions Std         25.8007
trainer/Q1 Predictions Max         -7.03421
trainer/Q1 Predictions Min       -111.696
trainer/Q2 Predictions Mean       -22.8933
trainer/Q2 Predictions Std         25.7691
trainer/Q2 Predictions Max         -7.19415
trainer/Q2 Predictions Min       -111.173
trainer/Q Targets Mean            -22.935
trainer/Q Targets Std              26.0288
trainer/Q Targets Max              -0.176228
trainer/Q Targets Min            -112.222
trainer/Log Pis Mean                2.2719
trainer/Log Pis Std                 1.33962
trainer/Log Pis Max                 6.33973
trainer/Log Pis Min                -4.05225
trainer/Policy mu Mean             -0.0138608
trainer/Policy mu Std               0.453439
trainer/Policy mu Max               2.96758
trainer/Policy mu Min              -3.18296
trainer/Policy log std Mean        -2.37614
trainer/Policy log std Std          0.421756
trainer/Policy log std Max         -0.54788
trainer/Policy log std Min         -3.09384
trainer/Alpha                       0.0876868
trainer/Alpha Loss                  0.661811
exploration/num steps total    361200
exploration/num paths total      3612
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.447886
exploration/Rewards Std             0.780676
exploration/Rewards Max            -0.00626748
exploration/Rewards Min            -7.19047
exploration/Returns Mean          -44.7886
exploration/Returns Std            19.8395
exploration/Returns Max           -30.0255
exploration/Returns Min           -83.0941
exploration/Actions Mean            0.0193438
exploration/Actions Std             0.198262
exploration/Actions Max             0.998236
exploration/Actions Min            -0.943114
exploration/Num Paths               5
exploration/Average Returns       -44.7886
evaluation/num steps total          1.083e+06
evaluation/num paths total      10830
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.421953
evaluation/Rewards Std              1.17879
evaluation/Rewards Max             -0.0302006
evaluation/Rewards Min            -11.2584
evaluation/Returns Mean           -42.1953
evaluation/Returns Std             23.2625
evaluation/Returns Max             -7.33726
evaluation/Returns Min           -109.504
evaluation/Actions Mean             0.0154546
evaluation/Actions Std              0.198173
evaluation/Actions Max              0.998669
evaluation/Actions Min             -0.996567
evaluation/Num Paths               15
evaluation/Average Returns        -42.1953
time/data storing (s)               0.00276986
time/evaluation sampling (s)        0.333656
time/exploration sampling (s)       0.138932
time/logging (s)                    0.00485828
time/saving (s)                     0.00218559
time/training (s)                   1.99585
time/epoch (s)                      2.47825
time/total (s)                   1773.15
Epoch                             721
-----------------------------  ---------------
2019-04-23 01:43:10.046584 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 722 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                  115.934
trainer/QF2 Loss                  115.79
trainer/Policy Loss                23.7504
trainer/Q1 Predictions Mean       -21.9317
trainer/Q1 Predictions Std         24.5307
trainer/Q1 Predictions Max         -7.03834
trainer/Q1 Predictions Min       -109.891
trainer/Q2 Predictions Mean       -21.8798
trainer/Q2 Predictions Std         24.5016
trainer/Q2 Predictions Max         -7.12455
trainer/Q2 Predictions Min       -109.795
trainer/Q Targets Mean            -20.865
trainer/Q Targets Std              23.1028
trainer/Q Targets Max              -0.130404
trainer/Q Targets Min            -110.4
trainer/Log Pis Mean                1.87312
trainer/Log Pis Std                 1.07587
trainer/Log Pis Max                 4.61388
trainer/Log Pis Min                -2.08272
trainer/Policy mu Mean              0.0249464
trainer/Policy mu Std               0.401962
trainer/Policy mu Max               2.56992
trainer/Policy mu Min              -2.69697
trainer/Policy log std Mean        -2.26112
trainer/Policy log std Std          0.34536
trainer/Policy log std Max         -0.811177
trainer/Policy log std Min         -2.83716
trainer/Alpha                       0.0869342
trainer/Alpha Loss                 -0.309896
exploration/num steps total    361700
exploration/num paths total      3617
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.01876
exploration/Rewards Std             1.0363
exploration/Rewards Max            -0.0101275
exploration/Rewards Min            -9.58678
exploration/Returns Mean         -101.876
exploration/Returns Std            55.8884
exploration/Returns Max           -19.1599
exploration/Returns Min          -185.764
exploration/Actions Mean           -0.00398696
exploration/Actions Std             0.190718
exploration/Actions Max             0.989886
exploration/Actions Min            -0.998667
exploration/Num Paths               5
exploration/Average Returns      -101.876
evaluation/num steps total          1.0845e+06
evaluation/num paths total      10845
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.530044
evaluation/Rewards Std              1.09395
evaluation/Rewards Max             -0.02307
evaluation/Rewards Min            -10.2539
evaluation/Returns Mean           -53.0044
evaluation/Returns Std             44.8651
evaluation/Returns Max            -13.0374
evaluation/Returns Min           -182.13
evaluation/Actions Mean             0.00333149
evaluation/Actions Std              0.178314
evaluation/Actions Max              0.998994
evaluation/Actions Min             -0.995864
evaluation/Num Paths               15
evaluation/Average Returns        -53.0044
time/data storing (s)               0.00268987
time/evaluation sampling (s)        0.329564
time/exploration sampling (s)       0.137652
time/logging (s)                    0.00414801
time/saving (s)                     0.00206087
time/training (s)                   2.00488
time/epoch (s)                      2.481
time/total (s)                   1775.64
Epoch                             722
-----------------------------  ---------------
2019-04-23 01:43:12.595071 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 723 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                  112.863
trainer/QF2 Loss                  112.902
trainer/Policy Loss                22.8614
trainer/Q1 Predictions Mean       -21.0889
trainer/Q1 Predictions Std         22.2792
trainer/Q1 Predictions Max         -7.30533
trainer/Q1 Predictions Min       -113.287
trainer/Q2 Predictions Mean       -21.0593
trainer/Q2 Predictions Std         22.2125
trainer/Q2 Predictions Max         -7.38968
trainer/Q2 Predictions Min       -112.87
trainer/Q Targets Mean            -19.9807
trainer/Q Targets Std              20.6633
trainer/Q Targets Max              -0.267204
trainer/Q Targets Min            -113.669
trainer/Log Pis Mean                1.79423
trainer/Log Pis Std                 1.40121
trainer/Log Pis Max                 4.91278
trainer/Log Pis Min                -4.8133
trainer/Policy mu Mean             -0.00460638
trainer/Policy mu Std               0.395712
trainer/Policy mu Max               2.57798
trainer/Policy mu Min              -2.40386
trainer/Policy log std Mean        -2.27177
trainer/Policy log std Std          0.372713
trainer/Policy log std Max         -0.618979
trainer/Policy log std Min         -2.92388
trainer/Alpha                       0.086299
trainer/Alpha Loss                 -0.504142
exploration/num steps total    362200
exploration/num paths total      3622
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.407689
exploration/Rewards Std             0.797707
exploration/Rewards Max            -0.0126248
exploration/Rewards Min            -8.44639
exploration/Returns Mean          -40.7689
exploration/Returns Std            21.7054
exploration/Returns Max           -23.8611
exploration/Returns Min           -81.7841
exploration/Actions Mean            0.0159945
exploration/Actions Std             0.218188
exploration/Actions Max             0.996049
exploration/Actions Min            -0.9971
exploration/Num Paths               5
exploration/Average Returns       -40.7689
evaluation/num steps total          1.086e+06
evaluation/num paths total      10860
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.341496
evaluation/Rewards Std              0.756917
evaluation/Rewards Max             -0.00154139
evaluation/Rewards Min             -7.68257
evaluation/Returns Mean           -34.1496
evaluation/Returns Std             34.717
evaluation/Returns Max             -3.08639
evaluation/Returns Min           -118.977
evaluation/Actions Mean             0.0111761
evaluation/Actions Std              0.160609
evaluation/Actions Max              0.998975
evaluation/Actions Min             -0.995686
evaluation/Num Paths               15
evaluation/Average Returns        -34.1496
time/data storing (s)               0.00289334
time/evaluation sampling (s)        0.334685
time/exploration sampling (s)       0.141294
time/logging (s)                    0.00483846
time/saving (s)                     0.0100131
time/training (s)                   2.04128
time/epoch (s)                      2.53501
time/total (s)                   1778.18
Epoch                             723
-----------------------------  ---------------
2019-04-23 01:43:15.176639 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 724 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.33079
trainer/QF2 Loss                    1.33134
trainer/Policy Loss                30.8556
trainer/Q1 Predictions Mean       -28.8516
trainer/Q1 Predictions Std         33.8051
trainer/Q1 Predictions Max         -7.32511
trainer/Q1 Predictions Min       -109.292
trainer/Q2 Predictions Mean       -28.8594
trainer/Q2 Predictions Std         33.8094
trainer/Q2 Predictions Max         -7.28334
trainer/Q2 Predictions Min       -109.286
trainer/Q Targets Mean            -28.9021
trainer/Q Targets Std              34.0377
trainer/Q Targets Max              -0.146551
trainer/Q Targets Min            -109.902
trainer/Log Pis Mean                2.1663
trainer/Log Pis Std                 1.34853
trainer/Log Pis Max                 7.70354
trainer/Log Pis Min                -3.56668
trainer/Policy mu Mean              0.0276239
trainer/Policy mu Std               0.534557
trainer/Policy mu Max               3.21777
trainer/Policy mu Min              -2.656
trainer/Policy log std Mean        -2.271
trainer/Policy log std Std          0.416073
trainer/Policy log std Max         -0.662313
trainer/Policy log std Min         -2.86009
trainer/Alpha                       0.0852058
trainer/Alpha Loss                  0.409559
exploration/num steps total    362700
exploration/num paths total      3627
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.621056
exploration/Rewards Std             0.919947
exploration/Rewards Max            -0.00430317
exploration/Rewards Min            -7.51962
exploration/Returns Mean          -62.1056
exploration/Returns Std            73.173
exploration/Returns Max           -18.7229
exploration/Returns Min          -208.196
exploration/Actions Mean           -0.0150404
exploration/Actions Std             0.192022
exploration/Actions Max             0.978123
exploration/Actions Min            -0.984787
exploration/Num Paths               5
exploration/Average Returns       -62.1056
evaluation/num steps total          1.0875e+06
evaluation/num paths total      10875
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.544539
evaluation/Rewards Std              0.914441
evaluation/Rewards Max             -0.00738134
evaluation/Rewards Min             -9.15254
evaluation/Returns Mean           -54.4539
evaluation/Returns Std             52.2193
evaluation/Returns Max             -2.45626
evaluation/Returns Min           -191.261
evaluation/Actions Mean            -0.00809129
evaluation/Actions Std              0.148121
evaluation/Actions Max              0.999044
evaluation/Actions Min             -0.997433
evaluation/Num Paths               15
evaluation/Average Returns        -54.4539
time/data storing (s)               0.00371798
time/evaluation sampling (s)        0.343672
time/exploration sampling (s)       0.166998
time/logging (s)                    0.00500657
time/saving (s)                     0.00161433
time/training (s)                   2.04679
time/epoch (s)                      2.5678
time/total (s)                   1780.75
Epoch                             724
-----------------------------  ---------------
2019-04-23 01:43:17.699848 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 725 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.14341
trainer/QF2 Loss                    1.10981
trainer/Policy Loss                28.3378
trainer/Q1 Predictions Mean       -26.1816
trainer/Q1 Predictions Std         28.2915
trainer/Q1 Predictions Max         -7.17939
trainer/Q1 Predictions Min       -106.68
trainer/Q2 Predictions Mean       -26.1976
trainer/Q2 Predictions Std         28.3301
trainer/Q2 Predictions Max         -7.19299
trainer/Q2 Predictions Min       -107.001
trainer/Q Targets Mean            -26.4856
trainer/Q Targets Std              28.7735
trainer/Q Targets Max              -0.304768
trainer/Q Targets Min            -108.176
trainer/Log Pis Mean                2.26184
trainer/Log Pis Std                 1.03429
trainer/Log Pis Max                 5.63478
trainer/Log Pis Min                -0.629798
trainer/Policy mu Mean             -0.0303585
trainer/Policy mu Std               0.511807
trainer/Policy mu Max               2.23123
trainer/Policy mu Min              -2.83466
trainer/Policy log std Mean        -2.28932
trainer/Policy log std Std          0.389509
trainer/Policy log std Max         -0.48463
trainer/Policy log std Min         -2.84844
trainer/Alpha                       0.0836932
trainer/Alpha Loss                  0.649526
exploration/num steps total    363200
exploration/num paths total      3632
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.487328
exploration/Rewards Std             1.17722
exploration/Rewards Max            -0.00946322
exploration/Rewards Min            -9.79289
exploration/Returns Mean          -48.7328
exploration/Returns Std            15.4738
exploration/Returns Max           -32.1183
exploration/Returns Min           -74.6818
exploration/Actions Mean           -0.0174466
exploration/Actions Std             0.230312
exploration/Actions Max             0.999281
exploration/Actions Min            -0.998073
exploration/Num Paths               5
exploration/Average Returns       -48.7328
evaluation/num steps total          1.089e+06
evaluation/num paths total      10890
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.70257
evaluation/Rewards Std              1.22804
evaluation/Rewards Max             -0.0443947
evaluation/Rewards Min            -10.3903
evaluation/Returns Mean           -70.257
evaluation/Returns Std             48.434
evaluation/Returns Max            -24.4358
evaluation/Returns Min           -186.083
evaluation/Actions Mean            -0.00703327
evaluation/Actions Std              0.205361
evaluation/Actions Max              0.998013
evaluation/Actions Min             -0.998145
evaluation/Num Paths               15
evaluation/Average Returns        -70.257
time/data storing (s)               0.00271524
time/evaluation sampling (s)        0.336368
time/exploration sampling (s)       0.146548
time/logging (s)                    0.00484539
time/saving (s)                     0.00216849
time/training (s)                   2.01705
time/epoch (s)                      2.5097
time/total (s)                   1783.26
Epoch                             725
-----------------------------  ---------------
2019-04-23 01:43:20.234771 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 726 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   31.925
trainer/QF2 Loss                   31.9313
trainer/Policy Loss                23.6353
trainer/Q1 Predictions Mean       -21.6158
trainer/Q1 Predictions Std         21.7924
trainer/Q1 Predictions Max         -7.45087
trainer/Q1 Predictions Min       -107.929
trainer/Q2 Predictions Mean       -21.5912
trainer/Q2 Predictions Std         21.7872
trainer/Q2 Predictions Max         -7.4737
trainer/Q2 Predictions Min       -108.589
trainer/Q Targets Mean            -21.0204
trainer/Q Targets Std              21.7425
trainer/Q Targets Max              -0.86786
trainer/Q Targets Min            -107.852
trainer/Log Pis Mean                2.13671
trainer/Log Pis Std                 1.05232
trainer/Log Pis Max                 6.99559
trainer/Log Pis Min                -1.19131
trainer/Policy mu Mean             -0.0386868
trainer/Policy mu Std               0.437206
trainer/Policy mu Max               2.3933
trainer/Policy mu Min              -3.36621
trainer/Policy log std Mean        -2.27937
trainer/Policy log std Std          0.360311
trainer/Policy log std Max         -0.339826
trainer/Policy log std Min         -2.82472
trainer/Alpha                       0.0826061
trainer/Alpha Loss                  0.340933
exploration/num steps total    363700
exploration/num paths total      3637
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.565679
exploration/Rewards Std             0.789286
exploration/Rewards Max            -0.00362119
exploration/Rewards Min            -5.26724
exploration/Returns Mean          -56.5679
exploration/Returns Std            68.6935
exploration/Returns Max           -13.1898
exploration/Returns Min          -193.35
exploration/Actions Mean            0.0143789
exploration/Actions Std             0.171308
exploration/Actions Max             0.998128
exploration/Actions Min            -0.772249
exploration/Num Paths               5
exploration/Average Returns       -56.5679
evaluation/num steps total          1.0905e+06
evaluation/num paths total      10905
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.696782
evaluation/Rewards Std              1.09534
evaluation/Rewards Max             -0.0167876
evaluation/Rewards Min             -8.51816
evaluation/Returns Mean           -69.6782
evaluation/Returns Std             49.0863
evaluation/Returns Max            -14.501
evaluation/Returns Min           -196.182
evaluation/Actions Mean             0.00260404
evaluation/Actions Std              0.199868
evaluation/Actions Max              0.999369
evaluation/Actions Min             -0.996928
evaluation/Num Paths               15
evaluation/Average Returns        -69.6782
time/data storing (s)               0.00280655
time/evaluation sampling (s)        0.335013
time/exploration sampling (s)       0.149691
time/logging (s)                    0.00390153
time/saving (s)                     0.00218352
time/training (s)                   2.02599
time/epoch (s)                      2.51959
time/total (s)                   1785.79
Epoch                             726
-----------------------------  ---------------
2019-04-23 01:43:22.775111 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 727 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.54833
trainer/QF2 Loss                    0.539971
trainer/Policy Loss                21.3236
trainer/Q1 Predictions Mean       -19.5638
trainer/Q1 Predictions Std         20.4227
trainer/Q1 Predictions Max         -7.05355
trainer/Q1 Predictions Min       -102.584
trainer/Q2 Predictions Mean       -19.5384
trainer/Q2 Predictions Std         20.4489
trainer/Q2 Predictions Max         -7.01146
trainer/Q2 Predictions Min       -102.946
trainer/Q Targets Mean            -19.9824
trainer/Q Targets Std              20.9346
trainer/Q Targets Max              -7.43374
trainer/Q Targets Min            -104.943
trainer/Log Pis Mean                1.83232
trainer/Log Pis Std                 1.14162
trainer/Log Pis Max                 3.786
trainer/Log Pis Min                -1.63477
trainer/Policy mu Mean             -0.00479193
trainer/Policy mu Std               0.259918
trainer/Policy mu Max               1.61419
trainer/Policy mu Min              -2.32556
trainer/Policy log std Mean        -2.30505
trainer/Policy log std Std          0.285064
trainer/Policy log std Max         -0.551583
trainer/Policy log std Min         -2.84699
trainer/Alpha                       0.0793125
trainer/Alpha Loss                 -0.424937
exploration/num steps total    364200
exploration/num paths total      3642
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.69609
exploration/Rewards Std             1.1091
exploration/Rewards Max            -0.00817148
exploration/Rewards Min            -9.70155
exploration/Returns Mean          -69.609
exploration/Returns Std            23.623
exploration/Returns Max           -43.0439
exploration/Returns Min          -103.871
exploration/Actions Mean           -0.00632998
exploration/Actions Std             0.226504
exploration/Actions Max             0.991179
exploration/Actions Min            -0.999397
exploration/Num Paths               5
exploration/Average Returns       -69.609
evaluation/num steps total          1.092e+06
evaluation/num paths total      10920
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.392574
evaluation/Rewards Std              1.06958
evaluation/Rewards Max             -0.000853163
evaluation/Rewards Min            -10.036
evaluation/Returns Mean           -39.2574
evaluation/Returns Std             30.206
evaluation/Returns Max            -10.4702
evaluation/Returns Min           -133.829
evaluation/Actions Mean             0.00253731
evaluation/Actions Std              0.193739
evaluation/Actions Max              0.998992
evaluation/Actions Min             -0.997081
evaluation/Num Paths               15
evaluation/Average Returns        -39.2574
time/data storing (s)               0.00336122
time/evaluation sampling (s)        0.332313
time/exploration sampling (s)       0.14629
time/logging (s)                    0.00483204
time/saving (s)                     0.00194692
time/training (s)                   2.03852
time/epoch (s)                      2.52726
time/total (s)                   1788.32
Epoch                             727
-----------------------------  ----------------
2019-04-23 01:43:25.322866 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 728 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.54826
trainer/QF2 Loss                    1.52386
trainer/Policy Loss                26.8691
trainer/Q1 Predictions Mean       -24.8367
trainer/Q1 Predictions Std         28.1489
trainer/Q1 Predictions Max         -7.18891
trainer/Q1 Predictions Min       -102.645
trainer/Q2 Predictions Mean       -24.8394
trainer/Q2 Predictions Std         28.1454
trainer/Q2 Predictions Max         -7.25738
trainer/Q2 Predictions Min       -103.089
trainer/Q Targets Mean            -25.2954
trainer/Q Targets Std              28.6568
trainer/Q Targets Max              -0.111269
trainer/Q Targets Min            -104.244
trainer/Log Pis Mean                2.14527
trainer/Log Pis Std                 1.0725
trainer/Log Pis Max                 3.70804
trainer/Log Pis Min                -2.31669
trainer/Policy mu Mean             -0.0092416
trainer/Policy mu Std               0.264545
trainer/Policy mu Max               1.97639
trainer/Policy mu Min              -1.63352
trainer/Policy log std Mean        -2.36239
trainer/Policy log std Std          0.282578
trainer/Policy log std Max         -0.921384
trainer/Policy log std Min         -2.98451
trainer/Alpha                       0.0781875
trainer/Alpha Loss                  0.370272
exploration/num steps total    364700
exploration/num paths total      3647
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.437776
exploration/Rewards Std             0.953488
exploration/Rewards Max            -0.0159681
exploration/Rewards Min            -7.99257
exploration/Returns Mean          -43.7776
exploration/Returns Std            16.6209
exploration/Returns Max           -20.3942
exploration/Returns Min           -71.2617
exploration/Actions Mean            0.0118429
exploration/Actions Std             0.217883
exploration/Actions Max             0.996718
exploration/Actions Min            -0.996673
exploration/Num Paths               5
exploration/Average Returns       -43.7776
evaluation/num steps total          1.0935e+06
evaluation/num paths total      10935
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.439622
evaluation/Rewards Std              0.831972
evaluation/Rewards Max             -0.012309
evaluation/Rewards Min             -9.47636
evaluation/Returns Mean           -43.9622
evaluation/Returns Std             37.1336
evaluation/Returns Max             -5.04509
evaluation/Returns Min           -125.942
evaluation/Actions Mean            -0.00837586
evaluation/Actions Std              0.161386
evaluation/Actions Max              0.991278
evaluation/Actions Min             -0.998324
evaluation/Num Paths               15
evaluation/Average Returns        -43.9622
time/data storing (s)               0.00279326
time/evaluation sampling (s)        0.33519
time/exploration sampling (s)       0.148299
time/logging (s)                    0.0051062
time/saving (s)                     0.0023323
time/training (s)                   2.03971
time/epoch (s)                      2.53343
time/total (s)                   1790.86
Epoch                             728
-----------------------------  ---------------
2019-04-23 01:43:27.865932 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 729 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    9.77933
trainer/QF2 Loss                    9.85191
trainer/Policy Loss                24.5188
trainer/Q1 Predictions Mean       -22.6321
trainer/Q1 Predictions Std         25.25
trainer/Q1 Predictions Max         -7.46615
trainer/Q1 Predictions Min       -102.781
trainer/Q2 Predictions Mean       -22.6484
trainer/Q2 Predictions Std         25.2665
trainer/Q2 Predictions Max         -7.53901
trainer/Q2 Predictions Min       -102.815
trainer/Q Targets Mean            -22.2873
trainer/Q Targets Std              25.6061
trainer/Q Targets Max              -0.0518402
trainer/Q Targets Min            -103.109
trainer/Log Pis Mean                1.99685
trainer/Log Pis Std                 1.11866
trainer/Log Pis Max                 4.49391
trainer/Log Pis Min                -2.73799
trainer/Policy mu Mean             -0.0272707
trainer/Policy mu Std               0.284993
trainer/Policy mu Max               0.857029
trainer/Policy mu Min              -2.89063
trainer/Policy log std Mean        -2.299
trainer/Policy log std Std          0.280854
trainer/Policy log std Max         -0.817845
trainer/Policy log std Min         -2.89837
trainer/Alpha                       0.0785898
trainer/Alpha Loss                 -0.00801029
exploration/num steps total    365200
exploration/num paths total      3652
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.523586
exploration/Rewards Std             1.00065
exploration/Rewards Max            -0.0177914
exploration/Rewards Min            -8.75724
exploration/Returns Mean          -52.3586
exploration/Returns Std            30.516
exploration/Returns Max           -19.3285
exploration/Returns Min          -107.117
exploration/Actions Mean            0.00247379
exploration/Actions Std             0.219005
exploration/Actions Max             0.999258
exploration/Actions Min            -0.99547
exploration/Num Paths               5
exploration/Average Returns       -52.3586
evaluation/num steps total          1.095e+06
evaluation/num paths total      10950
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.542671
evaluation/Rewards Std              1.27086
evaluation/Rewards Max             -0.00924761
evaluation/Rewards Min            -11.4474
evaluation/Returns Mean           -54.2671
evaluation/Returns Std             37.7241
evaluation/Returns Max            -10.0343
evaluation/Returns Min           -143.338
evaluation/Actions Mean             0.00591173
evaluation/Actions Std              0.207146
evaluation/Actions Max              0.997904
evaluation/Actions Min             -0.997175
evaluation/Num Paths               15
evaluation/Average Returns        -54.2671
time/data storing (s)               0.00345144
time/evaluation sampling (s)        0.334605
time/exploration sampling (s)       0.145415
time/logging (s)                    0.00512818
time/saving (s)                     0.00177562
time/training (s)                   2.03975
time/epoch (s)                      2.53013
time/total (s)                   1793.39
Epoch                             729
-----------------------------  ---------------
2019-04-23 01:43:30.424077 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 730 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.282783
trainer/QF2 Loss                    0.276317
trainer/Policy Loss                26.174
trainer/Q1 Predictions Mean       -24.2908
trainer/Q1 Predictions Std         25.227
trainer/Q1 Predictions Max         -7.2735
trainer/Q1 Predictions Min       -101.66
trainer/Q2 Predictions Mean       -24.3026
trainer/Q2 Predictions Std         25.216
trainer/Q2 Predictions Max         -7.52749
trainer/Q2 Predictions Min       -101.322
trainer/Q Targets Mean            -24.5505
trainer/Q Targets Std              25.5745
trainer/Q Targets Max              -7.62236
trainer/Q Targets Min            -103.251
trainer/Log Pis Mean                1.95701
trainer/Log Pis Std                 1.16121
trainer/Log Pis Max                 4.42046
trainer/Log Pis Min                -1.75724
trainer/Policy mu Mean              0.0286948
trainer/Policy mu Std               0.244109
trainer/Policy mu Max               2.26761
trainer/Policy mu Min              -0.911701
trainer/Policy log std Mean        -2.30449
trainer/Policy log std Std          0.297843
trainer/Policy log std Max         -0.78122
trainer/Policy log std Min         -2.93646
trainer/Alpha                       0.0780822
trainer/Alpha Loss                 -0.109618
exploration/num steps total    365700
exploration/num paths total      3657
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.432652
exploration/Rewards Std             0.70369
exploration/Rewards Max            -0.00844432
exploration/Rewards Min            -6.2397
exploration/Returns Mean          -43.2652
exploration/Returns Std            26.0594
exploration/Returns Max           -20.0371
exploration/Returns Min           -93.7443
exploration/Actions Mean            0.0217319
exploration/Actions Std             0.194183
exploration/Actions Max             0.996004
exploration/Actions Min            -0.949345
exploration/Num Paths               5
exploration/Average Returns       -43.2652
evaluation/num steps total          1.0965e+06
evaluation/num paths total      10965
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.442853
evaluation/Rewards Std              1.04596
evaluation/Rewards Max             -0.018822
evaluation/Rewards Min            -10.3279
evaluation/Returns Mean           -44.2853
evaluation/Returns Std             34.5206
evaluation/Returns Max             -6.96114
evaluation/Returns Min           -126.159
evaluation/Actions Mean             0.00355777
evaluation/Actions Std              0.184966
evaluation/Actions Max              0.998446
evaluation/Actions Min             -0.997899
evaluation/Num Paths               15
evaluation/Average Returns        -44.2853
time/data storing (s)               0.00280096
time/evaluation sampling (s)        0.339591
time/exploration sampling (s)       0.147002
time/logging (s)                    0.00487407
time/saving (s)                     0.00224071
time/training (s)                   2.04637
time/epoch (s)                      2.54287
time/total (s)                   1795.94
Epoch                             730
-----------------------------  ---------------
2019-04-23 01:43:32.977210 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 731 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.42852
trainer/QF2 Loss                    1.42413
trainer/Policy Loss                22.438
trainer/Q1 Predictions Mean       -20.3186
trainer/Q1 Predictions Std         20.991
trainer/Q1 Predictions Max         -7.36411
trainer/Q1 Predictions Min        -99.0557
trainer/Q2 Predictions Mean       -20.3075
trainer/Q2 Predictions Std         20.9821
trainer/Q2 Predictions Max         -7.27999
trainer/Q2 Predictions Min        -99.1002
trainer/Q Targets Mean            -20.6183
trainer/Q Targets Std              21.6153
trainer/Q Targets Max              -0.113102
trainer/Q Targets Min            -102.33
trainer/Log Pis Mean                2.16863
trainer/Log Pis Std                 1.19403
trainer/Log Pis Max                 8.03316
trainer/Log Pis Min                -1.67854
trainer/Policy mu Mean              0.0148518
trainer/Policy mu Std               0.505967
trainer/Policy mu Max               2.8344
trainer/Policy mu Min              -2.91396
trainer/Policy log std Mean        -2.27977
trainer/Policy log std Std          0.382307
trainer/Policy log std Max         -0.564574
trainer/Policy log std Min         -2.82103
trainer/Alpha                       0.0799904
trainer/Alpha Loss                  0.425962
exploration/num steps total    366200
exploration/num paths total      3662
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.377043
exploration/Rewards Std             0.604749
exploration/Rewards Max            -0.0143619
exploration/Rewards Min            -6.71259
exploration/Returns Mean          -37.7043
exploration/Returns Std            27.624
exploration/Returns Max           -15.3832
exploration/Returns Min           -91.088
exploration/Actions Mean            0.00519595
exploration/Actions Std             0.165138
exploration/Actions Max             0.998638
exploration/Actions Min            -0.996695
exploration/Num Paths               5
exploration/Average Returns       -37.7043
evaluation/num steps total          1.098e+06
evaluation/num paths total      10980
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.60225
evaluation/Rewards Std              1.24099
evaluation/Rewards Max             -0.02026
evaluation/Rewards Min             -9.79444
evaluation/Returns Mean           -60.225
evaluation/Returns Std             60.9116
evaluation/Returns Max            -12.735
evaluation/Returns Min           -214.17
evaluation/Actions Mean             0.00277425
evaluation/Actions Std              0.206551
evaluation/Actions Max              0.9995
evaluation/Actions Min             -0.996589
evaluation/Num Paths               15
evaluation/Average Returns        -60.225
time/data storing (s)               0.00258784
time/evaluation sampling (s)        0.341735
time/exploration sampling (s)       0.146398
time/logging (s)                    0.00483041
time/saving (s)                     0.00161364
time/training (s)                   2.04232
time/epoch (s)                      2.53948
time/total (s)                   1798.48
Epoch                             731
-----------------------------  ---------------
2019-04-23 01:43:35.541287 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 732 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.112769
trainer/QF2 Loss                    0.157018
trainer/Policy Loss                23.5214
trainer/Q1 Predictions Mean       -21.6475
trainer/Q1 Predictions Std         23.8581
trainer/Q1 Predictions Max         -7.54681
trainer/Q1 Predictions Min       -120.871
trainer/Q2 Predictions Mean       -21.6647
trainer/Q2 Predictions Std         23.911
trainer/Q2 Predictions Max         -7.47042
trainer/Q2 Predictions Min       -121.728
trainer/Q Targets Mean            -21.7901
trainer/Q Targets Std              23.797
trainer/Q Targets Max              -7.56969
trainer/Q Targets Min            -119.466
trainer/Log Pis Mean                1.92596
trainer/Log Pis Std                 1.1574
trainer/Log Pis Max                 6.28885
trainer/Log Pis Min                -1.36615
trainer/Policy mu Mean              0.00587025
trainer/Policy mu Std               0.510935
trainer/Policy mu Max               2.77274
trainer/Policy mu Min              -2.47488
trainer/Policy log std Mean        -2.24405
trainer/Policy log std Std          0.392151
trainer/Policy log std Max         -0.195881
trainer/Policy log std Min         -2.84808
trainer/Alpha                       0.0813819
trainer/Alpha Loss                 -0.185734
exploration/num steps total    366700
exploration/num paths total      3667
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.468903
exploration/Rewards Std             0.912419
exploration/Rewards Max            -0.0176047
exploration/Rewards Min            -9.70724
exploration/Returns Mean          -46.8903
exploration/Returns Std            26.4007
exploration/Returns Max           -23.797
exploration/Returns Min           -98.5267
exploration/Actions Mean            0.00959082
exploration/Actions Std             0.222955
exploration/Actions Max             0.999619
exploration/Actions Min            -0.991835
exploration/Num Paths               5
exploration/Average Returns       -46.8903
evaluation/num steps total          1.0995e+06
evaluation/num paths total      10995
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.696853
evaluation/Rewards Std              1.20561
evaluation/Rewards Max             -0.00707693
evaluation/Rewards Min            -10.6775
evaluation/Returns Mean           -69.6853
evaluation/Returns Std             79.3361
evaluation/Returns Max            -13.121
evaluation/Returns Min           -241.24
evaluation/Actions Mean             0.0122278
evaluation/Actions Std              0.180378
evaluation/Actions Max              0.998428
evaluation/Actions Min             -0.997116
evaluation/Num Paths               15
evaluation/Average Returns        -69.6853
time/data storing (s)               0.00282865
time/evaluation sampling (s)        0.338158
time/exploration sampling (s)       0.146883
time/logging (s)                    0.00485481
time/saving (s)                     0.00196097
time/training (s)                   2.05427
time/epoch (s)                      2.54895
time/total (s)                   1801.04
Epoch                             732
-----------------------------  ---------------
2019-04-23 01:43:38.096078 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 733 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0747818
trainer/QF2 Loss                    0.0880485
trainer/Policy Loss                23.0862
trainer/Q1 Predictions Mean       -21.3159
trainer/Q1 Predictions Std         23.6142
trainer/Q1 Predictions Max         -7.37682
trainer/Q1 Predictions Min       -100.81
trainer/Q2 Predictions Mean       -21.294
trainer/Q2 Predictions Std         23.6131
trainer/Q2 Predictions Max         -7.59158
trainer/Q2 Predictions Min       -100.55
trainer/Q Targets Mean            -21.5113
trainer/Q Targets Std              23.6198
trainer/Q Targets Max              -7.58552
trainer/Q Targets Min            -101.026
trainer/Log Pis Mean                1.85516
trainer/Log Pis Std                 1.20616
trainer/Log Pis Max                 3.72745
trainer/Log Pis Min                -3.18561
trainer/Policy mu Mean              0.0134069
trainer/Policy mu Std               0.146728
trainer/Policy mu Max               0.456071
trainer/Policy mu Min              -0.543047
trainer/Policy log std Mean        -2.34243
trainer/Policy log std Std          0.240806
trainer/Policy log std Max         -1.74732
trainer/Policy log std Min         -2.88053
trainer/Alpha                       0.0807108
trainer/Alpha Loss                 -0.364536
exploration/num steps total    367200
exploration/num paths total      3672
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.01657
exploration/Rewards Std             1.20658
exploration/Rewards Max            -0.00190555
exploration/Rewards Min           -12.1762
exploration/Returns Mean         -101.657
exploration/Returns Std            72.7964
exploration/Returns Max           -20.4205
exploration/Returns Min          -208.081
exploration/Actions Mean           -0.00294564
exploration/Actions Std             0.171347
exploration/Actions Max             0.935311
exploration/Actions Min            -0.999774
exploration/Num Paths               5
exploration/Average Returns      -101.657
evaluation/num steps total          1.101e+06
evaluation/num paths total      11010
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.354009
evaluation/Rewards Std              0.999829
evaluation/Rewards Max             -0.00544277
evaluation/Rewards Min             -9.35757
evaluation/Returns Mean           -35.4009
evaluation/Returns Std             22.4701
evaluation/Returns Max             -2.50004
evaluation/Returns Min            -98.2122
evaluation/Actions Mean            -0.00809668
evaluation/Actions Std              0.195241
evaluation/Actions Max              0.995045
evaluation/Actions Min             -0.998458
evaluation/Num Paths               15
evaluation/Average Returns        -35.4009
time/data storing (s)               0.00287133
time/evaluation sampling (s)        0.336677
time/exploration sampling (s)       0.148925
time/logging (s)                    0.00495471
time/saving (s)                     0.0021643
time/training (s)                   2.0448
time/epoch (s)                      2.5404
time/total (s)                   1803.58
Epoch                             733
-----------------------------  ---------------
2019-04-23 01:43:40.703671 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 734 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   95.2738
trainer/QF2 Loss                   95.0354
trainer/Policy Loss                26.1532
trainer/Q1 Predictions Mean       -24.3538
trainer/Q1 Predictions Std         24.7426
trainer/Q1 Predictions Max         -7.64929
trainer/Q1 Predictions Min       -113.453
trainer/Q2 Predictions Mean       -24.3145
trainer/Q2 Predictions Std         24.6589
trainer/Q2 Predictions Max         -7.74428
trainer/Q2 Predictions Min       -111.427
trainer/Q Targets Mean            -23.3202
trainer/Q Targets Std              23.7757
trainer/Q Targets Max              -0.185008
trainer/Q Targets Min            -111.524
trainer/Log Pis Mean                1.88648
trainer/Log Pis Std                 1.21878
trainer/Log Pis Max                 3.86331
trainer/Log Pis Min                -3.39321
trainer/Policy mu Mean             -0.0247108
trainer/Policy mu Std               0.360241
trainer/Policy mu Max               2.27393
trainer/Policy mu Min              -2.66283
trainer/Policy log std Mean        -2.27272
trainer/Policy log std Std          0.33669
trainer/Policy log std Max         -0.687429
trainer/Policy log std Min         -2.92598
trainer/Alpha                       0.0809758
trainer/Alpha Loss                 -0.285322
exploration/num steps total    367700
exploration/num paths total      3677
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.791723
exploration/Rewards Std             1.27134
exploration/Rewards Max            -0.00708932
exploration/Rewards Min           -10.457
exploration/Returns Mean          -79.1723
exploration/Returns Std            66.0917
exploration/Returns Max           -14.1736
exploration/Returns Min          -204.142
exploration/Actions Mean           -0.0358028
exploration/Actions Std             0.206085
exploration/Actions Max             0.994861
exploration/Actions Min            -0.999718
exploration/Num Paths               5
exploration/Average Returns       -79.1723
evaluation/num steps total          1.1025e+06
evaluation/num paths total      11025
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.589268
evaluation/Rewards Std              1.01828
evaluation/Rewards Max             -0.00510548
evaluation/Rewards Min            -10.7148
evaluation/Returns Mean           -58.9268
evaluation/Returns Std             49.4224
evaluation/Returns Max             -7.22132
evaluation/Returns Min           -207.75
evaluation/Actions Mean             0.00299138
evaluation/Actions Std              0.171078
evaluation/Actions Max              0.99865
evaluation/Actions Min             -0.993479
evaluation/Num Paths               15
evaluation/Average Returns        -58.9268
time/data storing (s)               0.00295632
time/evaluation sampling (s)        0.337985
time/exploration sampling (s)       0.152285
time/logging (s)                    0.00438981
time/saving (s)                     0.00196348
time/training (s)                   2.0933
time/epoch (s)                      2.59288
time/total (s)                   1806.18
Epoch                             734
-----------------------------  ---------------
2019-04-23 01:43:43.336278 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 735 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.36873
trainer/QF2 Loss                    1.30911
trainer/Policy Loss                26.335
trainer/Q1 Predictions Mean       -24.3878
trainer/Q1 Predictions Std         28.2942
trainer/Q1 Predictions Max         -7.35787
trainer/Q1 Predictions Min       -125.348
trainer/Q2 Predictions Mean       -24.3892
trainer/Q2 Predictions Std         28.3273
trainer/Q2 Predictions Max         -7.41843
trainer/Q2 Predictions Min       -125.963
trainer/Q Targets Mean            -24.7917
trainer/Q Targets Std              28.9792
trainer/Q Targets Max              -0.17178
trainer/Q Targets Min            -126.45
trainer/Log Pis Mean                2.00918
trainer/Log Pis Std                 0.888037
trainer/Log Pis Max                 3.99638
trainer/Log Pis Min                -0.441493
trainer/Policy mu Mean             -0.00703321
trainer/Policy mu Std               0.370385
trainer/Policy mu Max               2.51992
trainer/Policy mu Min              -2.60869
trainer/Policy log std Mean        -2.29046
trainer/Policy log std Std          0.348293
trainer/Policy log std Max         -0.545995
trainer/Policy log std Min         -2.92928
trainer/Alpha                       0.0795138
trainer/Alpha Loss                  0.0232307
exploration/num steps total    368200
exploration/num paths total      3682
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.6805
exploration/Rewards Std             0.962745
exploration/Rewards Max            -0.0167086
exploration/Rewards Min            -6.60541
exploration/Returns Mean          -68.05
exploration/Returns Std            64.5149
exploration/Returns Max           -32.4603
exploration/Returns Min          -197.012
exploration/Actions Mean            0.0121536
exploration/Actions Std             0.21267
exploration/Actions Max             0.999761
exploration/Actions Min            -0.996613
exploration/Num Paths               5
exploration/Average Returns       -68.05
evaluation/num steps total          1.104e+06
evaluation/num paths total      11040
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.389684
evaluation/Rewards Std              0.974761
evaluation/Rewards Max             -0.0251004
evaluation/Rewards Min             -9.13969
evaluation/Returns Mean           -38.9684
evaluation/Returns Std             47.8216
evaluation/Returns Max             -6.43658
evaluation/Returns Min           -209.393
evaluation/Actions Mean            -0.0157874
evaluation/Actions Std              0.185975
evaluation/Actions Max              0.996044
evaluation/Actions Min             -0.998971
evaluation/Num Paths               15
evaluation/Average Returns        -38.9684
time/data storing (s)               0.00277714
time/evaluation sampling (s)        0.347413
time/exploration sampling (s)       0.151108
time/logging (s)                    0.00482371
time/saving (s)                     0.00199013
time/training (s)                   2.11038
time/epoch (s)                      2.61849
time/total (s)                   1808.8
Epoch                             735
-----------------------------  ---------------
2019-04-23 01:43:45.894094 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 736 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.301567
trainer/QF2 Loss                    0.379367
trainer/Policy Loss                21.6097
trainer/Q1 Predictions Mean       -19.6578
trainer/Q1 Predictions Std         20.8102
trainer/Q1 Predictions Max         -7.64517
trainer/Q1 Predictions Min        -99.1896
trainer/Q2 Predictions Mean       -19.6373
trainer/Q2 Predictions Std         20.7719
trainer/Q2 Predictions Max         -7.39436
trainer/Q2 Predictions Min        -99.3292
trainer/Q Targets Mean            -19.9642
trainer/Q Targets Std              21.1806
trainer/Q Targets Max              -7.70856
trainer/Q Targets Min            -100.48
trainer/Log Pis Mean                2.00825
trainer/Log Pis Std                 1.0422
trainer/Log Pis Max                 4.99053
trainer/Log Pis Min                -1.33201
trainer/Policy mu Mean             -0.0131698
trainer/Policy mu Std               0.477611
trainer/Policy mu Max               2.91109
trainer/Policy mu Min              -2.72503
trainer/Policy log std Mean        -2.21928
trainer/Policy log std Std          0.386844
trainer/Policy log std Max         -0.544465
trainer/Policy log std Min         -2.82115
trainer/Alpha                       0.0768742
trainer/Alpha Loss                  0.02116
exploration/num steps total    368700
exploration/num paths total      3687
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.472245
exploration/Rewards Std             1.17811
exploration/Rewards Max            -0.00518526
exploration/Rewards Min           -10.1627
exploration/Returns Mean          -47.2245
exploration/Returns Std            15.28
exploration/Returns Max           -34.1554
exploration/Returns Min           -66.4569
exploration/Actions Mean            0.0257878
exploration/Actions Std             0.254087
exploration/Actions Max             0.999913
exploration/Actions Min            -0.994744
exploration/Num Paths               5
exploration/Average Returns       -47.2245
evaluation/num steps total          1.1055e+06
evaluation/num paths total      11055
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.631303
evaluation/Rewards Std              1.08141
evaluation/Rewards Max             -0.0408402
evaluation/Rewards Min            -11.166
evaluation/Returns Mean           -63.1303
evaluation/Returns Std             54.7846
evaluation/Returns Max             -6.34147
evaluation/Returns Min           -196.776
evaluation/Actions Mean             0.0065377
evaluation/Actions Std              0.175123
evaluation/Actions Max              0.998815
evaluation/Actions Min             -0.996555
evaluation/Num Paths               15
evaluation/Average Returns        -63.1303
time/data storing (s)               0.0028439
time/evaluation sampling (s)        0.338598
time/exploration sampling (s)       0.146816
time/logging (s)                    0.00453933
time/saving (s)                     0.00196798
time/training (s)                   2.04825
time/epoch (s)                      2.54302
time/total (s)                   1811.35
Epoch                             736
-----------------------------  ---------------
2019-04-23 01:43:48.460373 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 737 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.279815
trainer/QF2 Loss                    0.281616
trainer/Policy Loss                26.5523
trainer/Q1 Predictions Mean       -24.56
trainer/Q1 Predictions Std         24.0641
trainer/Q1 Predictions Max         -7.59623
trainer/Q1 Predictions Min        -98.8995
trainer/Q2 Predictions Mean       -24.5778
trainer/Q2 Predictions Std         24.062
trainer/Q2 Predictions Max         -7.51484
trainer/Q2 Predictions Min        -99.1296
trainer/Q Targets Mean            -24.8614
trainer/Q Targets Std              24.3968
trainer/Q Targets Max              -7.77095
trainer/Q Targets Min            -100.325
trainer/Log Pis Mean                2.06742
trainer/Log Pis Std                 1.05309
trainer/Log Pis Max                 5.83554
trainer/Log Pis Min                -1.55903
trainer/Policy mu Mean             -0.0144943
trainer/Policy mu Std               0.42113
trainer/Policy mu Max               2.76256
trainer/Policy mu Min              -2.98643
trainer/Policy log std Mean        -2.2795
trainer/Policy log std Std          0.382132
trainer/Policy log std Max         -0.640566
trainer/Policy log std Min         -3.00234
trainer/Alpha                       0.0771683
trainer/Alpha Loss                  0.17272
exploration/num steps total    369200
exploration/num paths total      3692
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.556063
exploration/Rewards Std             1.38522
exploration/Rewards Max            -0.0117034
exploration/Rewards Min            -9.65648
exploration/Returns Mean          -55.6063
exploration/Returns Std            18.4767
exploration/Returns Max           -19.2535
exploration/Returns Min           -68.2799
exploration/Actions Mean           -0.0211204
exploration/Actions Std             0.23572
exploration/Actions Max             0.999101
exploration/Actions Min            -0.999635
exploration/Num Paths               5
exploration/Average Returns       -55.6063
evaluation/num steps total          1.107e+06
evaluation/num paths total      11070
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.446948
evaluation/Rewards Std              0.889742
evaluation/Rewards Max             -0.00600308
evaluation/Rewards Min             -7.42138
evaluation/Returns Mean           -44.6948
evaluation/Returns Std             54.8628
evaluation/Returns Max             -6.45914
evaluation/Returns Min           -220.471
evaluation/Actions Mean             0.000392099
evaluation/Actions Std              0.167074
evaluation/Actions Max              0.99582
evaluation/Actions Min             -0.994397
evaluation/Num Paths               15
evaluation/Average Returns        -44.6948
time/data storing (s)               0.00282312
time/evaluation sampling (s)        0.334911
time/exploration sampling (s)       0.145585
time/logging (s)                    0.00487383
time/saving (s)                     0.00156006
time/training (s)                   2.06191
time/epoch (s)                      2.55166
time/total (s)                   1813.91
Epoch                             737
-----------------------------  ----------------
2019-04-23 01:43:50.994269 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 738 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0593748
trainer/QF2 Loss                    0.0473191
trainer/Policy Loss                22.6573
trainer/Q1 Predictions Mean       -20.8511
trainer/Q1 Predictions Std         20.5633
trainer/Q1 Predictions Max         -7.96218
trainer/Q1 Predictions Min       -101.092
trainer/Q2 Predictions Mean       -20.8354
trainer/Q2 Predictions Std         20.5607
trainer/Q2 Predictions Max         -7.9449
trainer/Q2 Predictions Min       -101.347
trainer/Q Targets Mean            -20.7657
trainer/Q Targets Std              20.4816
trainer/Q Targets Max              -7.89036
trainer/Q Targets Min            -100.583
trainer/Log Pis Mean                1.85625
trainer/Log Pis Std                 1.4228
trainer/Log Pis Max                 6.90975
trainer/Log Pis Min                -4.02077
trainer/Policy mu Mean              0.0157177
trainer/Policy mu Std               0.429808
trainer/Policy mu Max               2.86638
trainer/Policy mu Min              -3.06205
trainer/Policy log std Mean        -2.28946
trainer/Policy log std Std          0.331451
trainer/Policy log std Max         -0.655728
trainer/Policy log std Min         -2.91798
trainer/Alpha                       0.0771916
trainer/Alpha Loss                 -0.368206
exploration/num steps total    369700
exploration/num paths total      3697
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.604989
exploration/Rewards Std             1.04927
exploration/Rewards Max            -0.00717732
exploration/Rewards Min            -8.92476
exploration/Returns Mean          -60.4989
exploration/Returns Std            19.6795
exploration/Returns Max           -34.8937
exploration/Returns Min           -94.2843
exploration/Actions Mean           -0.0231839
exploration/Actions Std             0.224231
exploration/Actions Max             0.999144
exploration/Actions Min            -0.997861
exploration/Num Paths               5
exploration/Average Returns       -60.4989
evaluation/num steps total          1.1085e+06
evaluation/num paths total      11085
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.526963
evaluation/Rewards Std              1.02053
evaluation/Rewards Max             -0.00688655
evaluation/Rewards Min            -10.6734
evaluation/Returns Mean           -52.6963
evaluation/Returns Std             47.5199
evaluation/Returns Max            -15.4632
evaluation/Returns Min           -205.475
evaluation/Actions Mean            -0.00622456
evaluation/Actions Std              0.176484
evaluation/Actions Max              0.998137
evaluation/Actions Min             -0.998608
evaluation/Num Paths               15
evaluation/Average Returns        -52.6963
time/data storing (s)               0.00274529
time/evaluation sampling (s)        0.335583
time/exploration sampling (s)       0.144365
time/logging (s)                    0.00530662
time/saving (s)                     0.00214568
time/training (s)                   2.03053
time/epoch (s)                      2.52067
time/total (s)                   1816.43
Epoch                             738
-----------------------------  ---------------
2019-04-23 01:43:53.529305 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 739 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   90.8371
trainer/QF2 Loss                   90.4403
trainer/Policy Loss                27.5613
trainer/Q1 Predictions Mean       -25.4708
trainer/Q1 Predictions Std         27.6185
trainer/Q1 Predictions Max         -7.68739
trainer/Q1 Predictions Min        -98.812
trainer/Q2 Predictions Mean       -25.4645
trainer/Q2 Predictions Std         27.6121
trainer/Q2 Predictions Max         -7.68819
trainer/Q2 Predictions Min        -98.7669
trainer/Q Targets Mean            -24.833
trainer/Q Targets Std              27.2419
trainer/Q Targets Max              -0.19319
trainer/Q Targets Min            -100.166
trainer/Log Pis Mean                2.18686
trainer/Log Pis Std                 1.01905
trainer/Log Pis Max                 4.02492
trainer/Log Pis Min                -2.70854
trainer/Policy mu Mean              0.0262427
trainer/Policy mu Std               0.35524
trainer/Policy mu Max               2.53019
trainer/Policy mu Min              -0.483923
trainer/Policy log std Mean        -2.35443
trainer/Policy log std Std          0.310984
trainer/Policy log std Max         -0.618351
trainer/Policy log std Min         -2.87734
trainer/Alpha                       0.0757101
trainer/Alpha Loss                  0.48226
exploration/num steps total    370200
exploration/num paths total      3702
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.403288
exploration/Rewards Std             0.679764
exploration/Rewards Max            -0.0135732
exploration/Rewards Min            -6.77716
exploration/Returns Mean          -40.3288
exploration/Returns Std            22.2318
exploration/Returns Max           -23.9373
exploration/Returns Min           -84.242
exploration/Actions Mean            0.0197916
exploration/Actions Std             0.194938
exploration/Actions Max             0.998899
exploration/Actions Min            -0.810295
exploration/Num Paths               5
exploration/Average Returns       -40.3288
evaluation/num steps total          1.11e+06
evaluation/num paths total      11100
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.469221
evaluation/Rewards Std              1.23681
evaluation/Rewards Max             -0.0438085
evaluation/Rewards Min            -10.8078
evaluation/Returns Mean           -46.9221
evaluation/Returns Std             15.4035
evaluation/Returns Max            -13.346
evaluation/Returns Min            -72.6062
evaluation/Actions Mean            -0.00396269
evaluation/Actions Std              0.207769
evaluation/Actions Max              0.998538
evaluation/Actions Min             -0.997599
evaluation/Num Paths               15
evaluation/Average Returns        -46.9221
time/data storing (s)               0.0026111
time/evaluation sampling (s)        0.33249
time/exploration sampling (s)       0.147075
time/logging (s)                    0.00479725
time/saving (s)                     0.00195867
time/training (s)                   2.03052
time/epoch (s)                      2.51945
time/total (s)                   1818.96
Epoch                             739
-----------------------------  ---------------
2019-04-23 01:43:56.081465 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 740 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.55104
trainer/QF2 Loss                    1.56445
trainer/Policy Loss                25.042
trainer/Q1 Predictions Mean       -23.1826
trainer/Q1 Predictions Std         25.96
trainer/Q1 Predictions Max         -7.62589
trainer/Q1 Predictions Min        -99.0653
trainer/Q2 Predictions Mean       -23.1802
trainer/Q2 Predictions Std         25.9547
trainer/Q2 Predictions Max         -7.77788
trainer/Q2 Predictions Min        -98.6085
trainer/Q Targets Mean            -23.2343
trainer/Q Targets Std              26.3093
trainer/Q Targets Max              -0.0788925
trainer/Q Targets Min             -99.549
trainer/Log Pis Mean                1.95535
trainer/Log Pis Std                 1.29001
trainer/Log Pis Max                 9.12325
trainer/Log Pis Min                -1.84524
trainer/Policy mu Mean             -0.0546105
trainer/Policy mu Std               0.39107
trainer/Policy mu Max               2.52534
trainer/Policy mu Min              -3.14824
trainer/Policy log std Mean        -2.25612
trainer/Policy log std Std          0.35331
trainer/Policy log std Max         -0.164598
trainer/Policy log std Min         -2.92134
trainer/Alpha                       0.0763099
trainer/Alpha Loss                 -0.114895
exploration/num steps total    370700
exploration/num paths total      3707
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.473651
exploration/Rewards Std             1.01834
exploration/Rewards Max            -0.00968292
exploration/Rewards Min            -9.41744
exploration/Returns Mean          -47.3651
exploration/Returns Std            18.1852
exploration/Returns Max           -25.7788
exploration/Returns Min           -72.735
exploration/Actions Mean           -0.035163
exploration/Actions Std             0.219868
exploration/Actions Max             0.795452
exploration/Actions Min            -0.999903
exploration/Num Paths               5
exploration/Average Returns       -47.3651
evaluation/num steps total          1.1115e+06
evaluation/num paths total      11115
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.608001
evaluation/Rewards Std              1.17334
evaluation/Rewards Max             -0.0311463
evaluation/Rewards Min             -9.72811
evaluation/Returns Mean           -60.8001
evaluation/Returns Std             52.8359
evaluation/Returns Max            -21.2551
evaluation/Returns Min           -230.878
evaluation/Actions Mean            -0.00379791
evaluation/Actions Std              0.199471
evaluation/Actions Max              0.997852
evaluation/Actions Min             -0.997788
evaluation/Num Paths               15
evaluation/Average Returns        -60.8001
time/data storing (s)               0.00282117
time/evaluation sampling (s)        0.334358
time/exploration sampling (s)       0.147635
time/logging (s)                    0.00481759
time/saving (s)                     0.00195352
time/training (s)                   2.04517
time/epoch (s)                      2.53675
time/total (s)                   1821.5
Epoch                             740
-----------------------------  ---------------
2019-04-23 01:43:58.617688 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 741 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                  116.607
trainer/QF2 Loss                  116.672
trainer/Policy Loss                26.8958
trainer/Q1 Predictions Mean       -24.9015
trainer/Q1 Predictions Std         26.1701
trainer/Q1 Predictions Max         -7.52052
trainer/Q1 Predictions Min        -97.2092
trainer/Q2 Predictions Mean       -24.8983
trainer/Q2 Predictions Std         26.1442
trainer/Q2 Predictions Max         -7.68681
trainer/Q2 Predictions Min        -96.9352
trainer/Q Targets Mean            -23.7299
trainer/Q Targets Std              25.4211
trainer/Q Targets Max              -1.57303
trainer/Q Targets Min             -97.9969
trainer/Log Pis Mean                2.08835
trainer/Log Pis Std                 1.11314
trainer/Log Pis Max                 3.97537
trainer/Log Pis Min                -1.54831
trainer/Policy mu Mean              0.0480499
trainer/Policy mu Std               0.297067
trainer/Policy mu Max               2.22201
trainer/Policy mu Min              -0.37603
trainer/Policy log std Mean        -2.35064
trainer/Policy log std Std          0.319938
trainer/Policy log std Max         -0.651747
trainer/Policy log std Min         -2.95171
trainer/Alpha                       0.0765725
trainer/Alpha Loss                  0.227015
exploration/num steps total    371200
exploration/num paths total      3712
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.454503
exploration/Rewards Std             0.758667
exploration/Rewards Max            -0.0163083
exploration/Rewards Min            -7.42911
exploration/Returns Mean          -45.4503
exploration/Returns Std            24.2377
exploration/Returns Max           -25.5515
exploration/Returns Min           -91.223
exploration/Actions Mean            0.00827395
exploration/Actions Std             0.20085
exploration/Actions Max             0.999954
exploration/Actions Min            -0.999308
exploration/Num Paths               5
exploration/Average Returns       -45.4503
evaluation/num steps total          1.113e+06
evaluation/num paths total      11130
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.506525
evaluation/Rewards Std              0.856734
evaluation/Rewards Max             -0.0286038
evaluation/Rewards Min             -8.83598
evaluation/Returns Mean           -50.6525
evaluation/Returns Std             51.9949
evaluation/Returns Max             -4.48456
evaluation/Returns Min           -219.65
evaluation/Actions Mean             0.0071282
evaluation/Actions Std              0.155316
evaluation/Actions Max              0.99861
evaluation/Actions Min             -0.993738
evaluation/Num Paths               15
evaluation/Average Returns        -50.6525
time/data storing (s)               0.00279039
time/evaluation sampling (s)        0.3383
time/exploration sampling (s)       0.146078
time/logging (s)                    0.00479091
time/saving (s)                     0.0019522
time/training (s)                   2.02767
time/epoch (s)                      2.52158
time/total (s)                   1824.02
Epoch                             741
-----------------------------  ---------------
2019-04-23 01:44:01.167589 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 742 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.203128
trainer/QF2 Loss                    0.188854
trainer/Policy Loss                17.4644
trainer/Q1 Predictions Mean       -15.4604
trainer/Q1 Predictions Std         13.6124
trainer/Q1 Predictions Max         -7.59457
trainer/Q1 Predictions Min        -93.917
trainer/Q2 Predictions Mean       -15.4721
trainer/Q2 Predictions Std         13.5964
trainer/Q2 Predictions Max         -7.69831
trainer/Q2 Predictions Min        -93.962
trainer/Q Targets Mean            -15.6866
trainer/Q Targets Std              13.855
trainer/Q Targets Max              -7.9164
trainer/Q Targets Min             -96.2894
trainer/Log Pis Mean                2.02001
trainer/Log Pis Std                 1.1726
trainer/Log Pis Max                 6.17409
trainer/Log Pis Min                -1.11827
trainer/Policy mu Mean             -0.082558
trainer/Policy mu Std               0.414731
trainer/Policy mu Max               0.932844
trainer/Policy mu Min              -2.93396
trainer/Policy log std Mean        -2.29146
trainer/Policy log std Std          0.370862
trainer/Policy log std Max         -0.41692
trainer/Policy log std Min         -2.94922
trainer/Alpha                       0.0778562
trainer/Alpha Loss                  0.0510834
exploration/num steps total    371700
exploration/num paths total      3717
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.577154
exploration/Rewards Std             1.47003
exploration/Rewards Max            -0.00857713
exploration/Rewards Min           -10.0324
exploration/Returns Mean          -57.7154
exploration/Returns Std            16.0479
exploration/Returns Max           -26.2778
exploration/Returns Min           -68.6665
exploration/Actions Mean           -0.0118345
exploration/Actions Std             0.247899
exploration/Actions Max             0.994852
exploration/Actions Min            -0.999713
exploration/Num Paths               5
exploration/Average Returns       -57.7154
evaluation/num steps total          1.1145e+06
evaluation/num paths total      11145
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.781279
evaluation/Rewards Std              1.28164
evaluation/Rewards Max             -0.0082266
evaluation/Rewards Min            -10.0027
evaluation/Returns Mean           -78.1279
evaluation/Returns Std             58.6438
evaluation/Returns Max            -16.1689
evaluation/Returns Min           -200.563
evaluation/Actions Mean            -0.000932074
evaluation/Actions Std              0.195221
evaluation/Actions Max              0.998657
evaluation/Actions Min             -0.998917
evaluation/Num Paths               15
evaluation/Average Returns        -78.1279
time/data storing (s)               0.00290212
time/evaluation sampling (s)        0.336981
time/exploration sampling (s)       0.148079
time/logging (s)                    0.00534292
time/saving (s)                     0.00209765
time/training (s)                   2.04045
time/epoch (s)                      2.53585
time/total (s)                   1826.56
Epoch                             742
-----------------------------  ----------------
2019-04-23 01:44:03.755287 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 743 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.486775
trainer/QF2 Loss                    0.452461
trainer/Policy Loss                25.8079
trainer/Q1 Predictions Mean       -23.7929
trainer/Q1 Predictions Std         24.16
trainer/Q1 Predictions Max         -7.86014
trainer/Q1 Predictions Min        -96.105
trainer/Q2 Predictions Mean       -23.8024
trainer/Q2 Predictions Std         24.1973
trainer/Q2 Predictions Max         -7.73647
trainer/Q2 Predictions Min        -96.1708
trainer/Q Targets Mean            -24.0657
trainer/Q Targets Std              24.6635
trainer/Q Targets Max              -7.86354
trainer/Q Targets Min             -98.1883
trainer/Log Pis Mean                2.12723
trainer/Log Pis Std                 0.943307
trainer/Log Pis Max                 5.6974
trainer/Log Pis Min                -1.37857
trainer/Policy mu Mean             -0.0128536
trainer/Policy mu Std               0.266508
trainer/Policy mu Max               0.753161
trainer/Policy mu Min              -2.89905
trainer/Policy log std Mean        -2.36815
trainer/Policy log std Std          0.300238
trainer/Policy log std Max         -0.720506
trainer/Policy log std Min         -3.02993
trainer/Alpha                       0.0791102
trainer/Alpha Loss                  0.322769
exploration/num steps total    372200
exploration/num paths total      3722
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.610979
exploration/Rewards Std             0.808849
exploration/Rewards Max            -0.0145921
exploration/Rewards Min            -8.709
exploration/Returns Mean          -61.0979
exploration/Returns Std            50.9648
exploration/Returns Max           -18.0784
exploration/Returns Min          -140.001
exploration/Actions Mean            0.0200902
exploration/Actions Std             0.163435
exploration/Actions Max             0.992233
exploration/Actions Min            -0.374133
exploration/Num Paths               5
exploration/Average Returns       -61.0979
evaluation/num steps total          1.116e+06
evaluation/num paths total      11160
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.369373
evaluation/Rewards Std              1.10911
evaluation/Rewards Max             -0.0246537
evaluation/Rewards Min            -10.1607
evaluation/Returns Mean           -36.9373
evaluation/Returns Std             16.1538
evaluation/Returns Max             -9.33658
evaluation/Returns Min            -62.8919
evaluation/Actions Mean             0.00756588
evaluation/Actions Std              0.199103
evaluation/Actions Max              0.99915
evaluation/Actions Min             -0.997951
evaluation/Num Paths               15
evaluation/Average Returns        -36.9373
time/data storing (s)               0.00274984
time/evaluation sampling (s)        0.338386
time/exploration sampling (s)       0.146554
time/logging (s)                    0.00489628
time/saving (s)                     0.00199932
time/training (s)                   2.07989
time/epoch (s)                      2.57448
time/total (s)                   1829.14
Epoch                             743
-----------------------------  ---------------
2019-04-23 01:44:06.897820 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 744 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   30.4315
trainer/QF2 Loss                   30.2711
trainer/Policy Loss                22.277
trainer/Q1 Predictions Mean       -20.2112
trainer/Q1 Predictions Std         20.8234
trainer/Q1 Predictions Max         -7.64373
trainer/Q1 Predictions Min       -122.049
trainer/Q2 Predictions Mean       -20.2054
trainer/Q2 Predictions Std         20.9316
trainer/Q2 Predictions Max         -7.69066
trainer/Q2 Predictions Min       -124.012
trainer/Q Targets Mean            -19.8346
trainer/Q Targets Std              20.8151
trainer/Q Targets Max              -0.975621
trainer/Q Targets Min            -122.812
trainer/Log Pis Mean                2.10451
trainer/Log Pis Std                 1.4132
trainer/Log Pis Max                 6.95774
trainer/Log Pis Min                -2.41575
trainer/Policy mu Mean             -0.0425609
trainer/Policy mu Std               0.511687
trainer/Policy mu Max               2.83577
trainer/Policy mu Min              -2.98881
trainer/Policy log std Mean        -2.28858
trainer/Policy log std Std          0.407299
trainer/Policy log std Max         -0.267983
trainer/Policy log std Min         -2.90269
trainer/Alpha                       0.0791863
trainer/Alpha Loss                  0.265051
exploration/num steps total    372700
exploration/num paths total      3727
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.49193
exploration/Rewards Std             1.33339
exploration/Rewards Max            -0.00448926
exploration/Rewards Min           -10.179
exploration/Returns Mean          -49.193
exploration/Returns Std            20.4731
exploration/Returns Max           -22.0519
exploration/Returns Min           -76.78
exploration/Actions Mean            0.0379073
exploration/Actions Std             0.231419
exploration/Actions Max             0.999387
exploration/Actions Min            -0.986453
exploration/Num Paths               5
exploration/Average Returns       -49.193
evaluation/num steps total          1.1175e+06
evaluation/num paths total      11175
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.37561
evaluation/Rewards Std              0.995252
evaluation/Rewards Max             -0.00181085
evaluation/Rewards Min             -9.69766
evaluation/Returns Mean           -37.561
evaluation/Returns Std             20.4252
evaluation/Returns Max            -16.7874
evaluation/Returns Min            -88.7292
evaluation/Actions Mean            -0.00634397
evaluation/Actions Std              0.191875
evaluation/Actions Max              0.996401
evaluation/Actions Min             -0.997705
evaluation/Num Paths               15
evaluation/Average Returns        -37.561
time/data storing (s)               0.00292454
time/evaluation sampling (s)        0.342361
time/exploration sampling (s)       0.15529
time/logging (s)                    0.00479281
time/saving (s)                     0.00195844
time/training (s)                   2.62103
time/epoch (s)                      3.12835
time/total (s)                   1832.28
Epoch                             744
-----------------------------  ---------------
2019-04-23 01:44:09.407854 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 745 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    3.27143
trainer/QF2 Loss                    3.36825
trainer/Policy Loss                24.0324
trainer/Q1 Predictions Mean       -22.2183
trainer/Q1 Predictions Std         23.496
trainer/Q1 Predictions Max         -7.92706
trainer/Q1 Predictions Min        -97.1463
trainer/Q2 Predictions Mean       -22.2044
trainer/Q2 Predictions Std         23.4703
trainer/Q2 Predictions Max         -7.97861
trainer/Q2 Predictions Min        -97.4544
trainer/Q Targets Mean            -21.9289
trainer/Q Targets Std              23.6613
trainer/Q Targets Max              -0.069868
trainer/Q Targets Min             -96.8767
trainer/Log Pis Mean                1.84368
trainer/Log Pis Std                 1.11537
trainer/Log Pis Max                 4.51329
trainer/Log Pis Min                -1.97606
trainer/Policy mu Mean              0.00367733
trainer/Policy mu Std               0.270615
trainer/Policy mu Max               2.72852
trainer/Policy mu Min              -1.94148
trainer/Policy log std Mean        -2.32378
trainer/Policy log std Std          0.280484
trainer/Policy log std Max         -0.651626
trainer/Policy log std Min         -2.98511
trainer/Alpha                       0.081254
trainer/Alpha Loss                 -0.392351
exploration/num steps total    373200
exploration/num paths total      3732
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.864371
exploration/Rewards Std             1.28905
exploration/Rewards Max            -0.00182476
exploration/Rewards Min           -10.8598
exploration/Returns Mean          -86.4371
exploration/Returns Std            79.4212
exploration/Returns Max           -14.7167
exploration/Returns Min          -238.974
exploration/Actions Mean            0.0130066
exploration/Actions Std             0.213402
exploration/Actions Max             0.997588
exploration/Actions Min            -0.993095
exploration/Num Paths               5
exploration/Average Returns       -86.4371
evaluation/num steps total          1.119e+06
evaluation/num paths total      11190
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.667238
evaluation/Rewards Std              1.05964
evaluation/Rewards Max             -0.0220846
evaluation/Rewards Min            -11.5557
evaluation/Returns Mean           -66.7238
evaluation/Returns Std             54.7495
evaluation/Returns Max            -12.1322
evaluation/Returns Min           -217.462
evaluation/Actions Mean            -0.00992242
evaluation/Actions Std              0.183129
evaluation/Actions Max              0.994625
evaluation/Actions Min             -0.998247
evaluation/Num Paths               15
evaluation/Average Returns        -66.7238
time/data storing (s)               0.00258823
time/evaluation sampling (s)        0.33107
time/exploration sampling (s)       0.139607
time/logging (s)                    0.0048548
time/saving (s)                     0.00194466
time/training (s)                   2.01531
time/epoch (s)                      2.49537
time/total (s)                   1834.78
Epoch                             745
-----------------------------  ---------------
2019-04-23 01:44:11.929810 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 746 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0877723
trainer/QF2 Loss                    0.12103
trainer/Policy Loss                25.0341
trainer/Q1 Predictions Mean       -23.1081
trainer/Q1 Predictions Std         24.9111
trainer/Q1 Predictions Max         -7.7253
trainer/Q1 Predictions Min        -96.8474
trainer/Q2 Predictions Mean       -23.0602
trainer/Q2 Predictions Std         24.8771
trainer/Q2 Predictions Max         -7.83208
trainer/Q2 Predictions Min        -96.3644
trainer/Q Targets Mean            -23.2556
trainer/Q Targets Std              24.967
trainer/Q Targets Max              -7.86838
trainer/Q Targets Min             -96.6302
trainer/Log Pis Mean                1.97626
trainer/Log Pis Std                 0.99733
trainer/Log Pis Max                 3.49471
trainer/Log Pis Min                -2.53
trainer/Policy mu Mean              0.0299196
trainer/Policy mu Std               0.292689
trainer/Policy mu Max               3.31302
trainer/Policy mu Min              -1.41603
trainer/Policy log std Mean        -2.33833
trainer/Policy log std Std          0.305951
trainer/Policy log std Max         -0.580829
trainer/Policy log std Min         -3.11688
trainer/Alpha                       0.0791715
trainer/Alpha Loss                 -0.0602045
exploration/num steps total    373700
exploration/num paths total      3737
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.07852
exploration/Rewards Std             1.16776
exploration/Rewards Max            -0.00875149
exploration/Rewards Min            -8.56876
exploration/Returns Mean         -107.852
exploration/Returns Std            71.7327
exploration/Returns Max           -20.3069
exploration/Returns Min          -219.029
exploration/Actions Mean           -0.0114764
exploration/Actions Std             0.203184
exploration/Actions Max             0.987294
exploration/Actions Min            -0.998241
exploration/Num Paths               5
exploration/Average Returns      -107.852
evaluation/num steps total          1.1205e+06
evaluation/num paths total      11205
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.706695
evaluation/Rewards Std              1.09435
evaluation/Rewards Max             -0.0341833
evaluation/Rewards Min            -10.602
evaluation/Returns Mean           -70.6695
evaluation/Returns Std             74.5225
evaluation/Returns Max             -8.15419
evaluation/Returns Min           -218.739
evaluation/Actions Mean            -0.0118651
evaluation/Actions Std              0.174047
evaluation/Actions Max              0.996375
evaluation/Actions Min             -0.99799
evaluation/Num Paths               15
evaluation/Average Returns        -70.6695
time/data storing (s)               0.00277377
time/evaluation sampling (s)        0.333785
time/exploration sampling (s)       0.136065
time/logging (s)                    0.00484254
time/saving (s)                     0.00592911
time/training (s)                   2.02399
time/epoch (s)                      2.50739
time/total (s)                   1837.29
Epoch                             746
-----------------------------  ---------------
2019-04-23 01:44:14.435660 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 747 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    3.27145
trainer/QF2 Loss                    3.36976
trainer/Policy Loss                21.6383
trainer/Q1 Predictions Mean       -19.7898
trainer/Q1 Predictions Std         21.4721
trainer/Q1 Predictions Max         -7.9754
trainer/Q1 Predictions Min        -97.0616
trainer/Q2 Predictions Mean       -19.8102
trainer/Q2 Predictions Std         21.4585
trainer/Q2 Predictions Max         -8.06502
trainer/Q2 Predictions Min        -96.8291
trainer/Q Targets Mean            -19.551
trainer/Q Targets Std              21.6529
trainer/Q Targets Max              -0.0573094
trainer/Q Targets Min             -96.5113
trainer/Log Pis Mean                1.90776
trainer/Log Pis Std                 1.14869
trainer/Log Pis Max                 5.46953
trainer/Log Pis Min                -2.55159
trainer/Policy mu Mean             -0.0412839
trainer/Policy mu Std               0.31407
trainer/Policy mu Max               2.57564
trainer/Policy mu Min              -2.93252
trainer/Policy log std Mean        -2.34592
trainer/Policy log std Std          0.287515
trainer/Policy log std Max         -0.618513
trainer/Policy log std Min         -3.04729
trainer/Alpha                       0.0774682
trainer/Alpha Loss                 -0.235947
exploration/num steps total    374200
exploration/num paths total      3742
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.407505
exploration/Rewards Std             0.985947
exploration/Rewards Max            -0.00344101
exploration/Rewards Min            -8.97132
exploration/Returns Mean          -40.7505
exploration/Returns Std            17.0099
exploration/Returns Max           -21.2338
exploration/Returns Min           -63.6411
exploration/Actions Mean            0.00732744
exploration/Actions Std             0.219259
exploration/Actions Max             0.999031
exploration/Actions Min            -0.999571
exploration/Num Paths               5
exploration/Average Returns       -40.7505
evaluation/num steps total          1.122e+06
evaluation/num paths total      11220
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.394252
evaluation/Rewards Std              1.14762
evaluation/Rewards Max             -0.0335759
evaluation/Rewards Min            -10.3294
evaluation/Returns Mean           -39.4252
evaluation/Returns Std             16.1974
evaluation/Returns Max            -10.6038
evaluation/Returns Min            -71.2085
evaluation/Actions Mean             0.00783229
evaluation/Actions Std              0.203448
evaluation/Actions Max              0.997985
evaluation/Actions Min             -0.996623
evaluation/Num Paths               15
evaluation/Average Returns        -39.4252
time/data storing (s)               0.00278738
time/evaluation sampling (s)        0.326168
time/exploration sampling (s)       0.141698
time/logging (s)                    0.00483185
time/saving (s)                     0.00193238
time/training (s)                   2.01389
time/epoch (s)                      2.49131
time/total (s)                   1839.78
Epoch                             747
-----------------------------  ---------------
2019-04-23 01:44:16.940571 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 748 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.367269
trainer/QF2 Loss                    0.353234
trainer/Policy Loss                24.7464
trainer/Q1 Predictions Mean       -22.9347
trainer/Q1 Predictions Std         23.7947
trainer/Q1 Predictions Max         -7.56799
trainer/Q1 Predictions Min        -94.219
trainer/Q2 Predictions Mean       -22.8933
trainer/Q2 Predictions Std         23.8079
trainer/Q2 Predictions Max         -7.61582
trainer/Q2 Predictions Min        -94.3209
trainer/Q Targets Mean            -23.2913
trainer/Q Targets Std              24.1744
trainer/Q Targets Max              -7.87966
trainer/Q Targets Min             -95.579
trainer/Log Pis Mean                1.89382
trainer/Log Pis Std                 1.30635
trainer/Log Pis Max                 5.04837
trainer/Log Pis Min                -1.77316
trainer/Policy mu Mean             -0.0309278
trainer/Policy mu Std               0.418204
trainer/Policy mu Max               2.64846
trainer/Policy mu Min              -2.95712
trainer/Policy log std Mean        -2.30238
trainer/Policy log std Std          0.386048
trainer/Policy log std Max         -0.482299
trainer/Policy log std Min         -3.13445
trainer/Alpha                       0.0781744
trainer/Alpha Loss                 -0.270645
exploration/num steps total    374700
exploration/num paths total      3747
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.540409
exploration/Rewards Std             1.02581
exploration/Rewards Max            -0.00970079
exploration/Rewards Min            -9.59769
exploration/Returns Mean          -54.0409
exploration/Returns Std            24.9287
exploration/Returns Max           -30.5013
exploration/Returns Min           -96.2466
exploration/Actions Mean            0.0226662
exploration/Actions Std             0.227465
exploration/Actions Max             0.99759
exploration/Actions Min            -0.997034
exploration/Num Paths               5
exploration/Average Returns       -54.0409
evaluation/num steps total          1.1235e+06
evaluation/num paths total      11235
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.236559
evaluation/Rewards Std              0.788461
evaluation/Rewards Max             -0.0113924
evaluation/Rewards Min            -11.2129
evaluation/Returns Mean           -23.6559
evaluation/Returns Std             15.9921
evaluation/Returns Max             -6.75963
evaluation/Returns Min            -71.119
evaluation/Actions Mean             0.0109178
evaluation/Actions Std              0.168393
evaluation/Actions Max              0.997241
evaluation/Actions Min             -0.991046
evaluation/Num Paths               15
evaluation/Average Returns        -23.6559
time/data storing (s)               0.00261348
time/evaluation sampling (s)        0.329258
time/exploration sampling (s)       0.1368
time/logging (s)                    0.00483175
time/saving (s)                     0.00191766
time/training (s)                   2.01485
time/epoch (s)                      2.49027
time/total (s)                   1842.28
Epoch                             748
-----------------------------  ---------------
2019-04-23 01:44:19.427868 PDT | [sac-pointmass-multitask-15_2019_04_23_01_13_30_0000--s-0] Epoch 749 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.185415
trainer/QF2 Loss                    0.242706
trainer/Policy Loss                29.0426
trainer/Q1 Predictions Mean       -27.172
trainer/Q1 Predictions Std         29.5824
trainer/Q1 Predictions Max         -7.73454
trainer/Q1 Predictions Min       -105.757
trainer/Q2 Predictions Mean       -27.1767
trainer/Q2 Predictions Std         29.6125
trainer/Q2 Predictions Max         -7.86118
trainer/Q2 Predictions Min       -106.944
trainer/Q Targets Mean            -27.3707
trainer/Q Targets Std              29.7427
trainer/Q Targets Max              -7.76659
trainer/Q Targets Min            -103.975
trainer/Log Pis Mean                1.9944
trainer/Log Pis Std                 1.1103
trainer/Log Pis Max                 4.47212
trainer/Log Pis Min                -0.95746
trainer/Policy mu Mean             -0.00390011
trainer/Policy mu Std               0.474191
trainer/Policy mu Max               2.44712
trainer/Policy mu Min              -2.92611
trainer/Policy log std Mean        -2.26598
trainer/Policy log std Std          0.387085
trainer/Policy log std Max         -0.630388
trainer/Policy log std Min         -3.11723
trainer/Alpha                       0.0797218
trainer/Alpha Loss                 -0.0141571
exploration/num steps total    375200
exploration/num paths total      3752
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.581707
exploration/Rewards Std             1.18444
exploration/Rewards Max            -0.00501709
exploration/Rewards Min            -9.68823
exploration/Returns Mean          -58.1707
exploration/Returns Std            41.2755
exploration/Returns Max           -19.7875
exploration/Returns Min          -135.605
exploration/Actions Mean            0.0290445
exploration/Actions Std             0.227209
exploration/Actions Max             0.998253
exploration/Actions Min            -0.989103
exploration/Num Paths               5
exploration/Average Returns       -58.1707
evaluation/num steps total          1.125e+06
evaluation/num paths total      11250
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.694125
evaluation/Rewards Std              1.23187
evaluation/Rewards Max             -0.0194068
evaluation/Rewards Min             -9.75798
evaluation/Returns Mean           -69.4125
evaluation/Returns Std             85.606
evaluation/Returns Max             -3.69587
evaluation/Returns Min           -254.893
evaluation/Actions Mean            -0.00170167
evaluation/Actions Std              0.164412
evaluation/Actions Max              0.998036
evaluation/Actions Min             -0.997623
evaluation/Num Paths               15
evaluation/Average Returns        -69.4125
time/data storing (s)               0.00265414
time/evaluation sampling (s)        0.333542
time/exploration sampling (s)       0.137657
time/logging (s)                    0.00355828
time/saving (s)                     0.00190801
time/training (s)                   1.99366
time/epoch (s)                      2.47298
time/total (s)                   1844.76
Epoch                             749
-----------------------------  ---------------
