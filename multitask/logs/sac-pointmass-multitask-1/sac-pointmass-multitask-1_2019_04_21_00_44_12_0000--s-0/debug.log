2019-04-21 00:44:13.665525 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 0 finished
-----------------------------  ---------------
replay_buffer/size               400
trainer/QF1 Loss                  49.3982
trainer/QF2 Loss                  49.4086
trainer/Policy Loss               -1.37417
trainer/Q1 Predictions Mean        0.00134779
trainer/Q1 Predictions Std         0.00106518
trainer/Q1 Predictions Max         0.00355188
trainer/Q1 Predictions Min        -0.00136557
trainer/Q2 Predictions Mean        0.00252927
trainer/Q2 Predictions Std         0.000976929
trainer/Q2 Predictions Max         0.0048085
trainer/Q2 Predictions Min         0.000834462
trainer/Q Targets Mean            -6.14289
trainer/Q Targets Std              3.41274
trainer/Q Targets Max             -0.480523
trainer/Q Targets Min            -12.2119
trainer/Log Pis Mean              -1.37294
trainer/Log Pis Std                0.277612
trainer/Log Pis Max               -0.534498
trainer/Log Pis Min               -1.83703
trainer/Policy mu Mean            -0.000327547
trainer/Policy mu Std              0.00136915
trainer/Policy mu Max              0.00199799
trainer/Policy mu Min             -0.00252324
trainer/Policy log std Mean       -0.000493518
trainer/Policy log std Std         0.000552033
trainer/Policy log std Max         0.000406006
trainer/Policy log std Min        -0.00174178
trainer/Alpha                      0.9997
trainer/Alpha Loss                -0
exploration/num steps total      400
exploration/num paths total        4
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -7.02757
exploration/Rewards Std            3.80169
exploration/Rewards Max           -0.0366703
exploration/Rewards Min          -12.2109
exploration/Returns Mean        -702.757
exploration/Returns Std          323.587
exploration/Returns Max         -379.17
exploration/Returns Min        -1026.34
exploration/Actions Mean          -0.0213259
exploration/Actions Std            0.609281
exploration/Actions Max            0.990693
exploration/Actions Min           -0.989611
exploration/Num Paths              2
exploration/Average Returns     -702.757
evaluation/num steps total      1000
evaluation/num paths total        10
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -6.77134
evaluation/Rewards Std             3.37292
evaluation/Rewards Max            -0.230268
evaluation/Rewards Min           -11.1419
evaluation/Returns Mean         -677.134
evaluation/Returns Std           337.246
evaluation/Returns Max           -31.3683
evaluation/Returns Min         -1105.27
evaluation/Actions Mean           -8.01399e-05
evaluation/Actions Std             0.00159465
evaluation/Actions Max             0.00241448
evaluation/Actions Min            -0.00243325
evaluation/Num Paths              10
evaluation/Average Returns      -677.134
time/data storing (s)              0.00112737
time/evaluation sampling (s)       0.215516
time/exploration sampling (s)      0.0616236
time/logging (s)                   0.00358017
time/saving (s)                    0.00269842
time/training (s)                  0.801989
time/epoch (s)                     1.08653
time/total (s)                     1.30392
Epoch                              0
-----------------------------  ---------------
2019-04-21 00:44:14.774544 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 1 finished
-----------------------------  -------------
replay_buffer/size              600
trainer/QF1 Loss                  0.866832
trainer/QF2 Loss                  2.34841
trainer/Policy Loss               6.39088
trainer/Q1 Predictions Mean      -7.4902
trainer/Q1 Predictions Std        3.2441
trainer/Q1 Predictions Max       -2.51578
trainer/Q1 Predictions Min      -14.1678
trainer/Q2 Predictions Mean      -7.2444
trainer/Q2 Predictions Std        2.65589
trainer/Q2 Predictions Max       -3.08696
trainer/Q2 Predictions Min      -13.9703
trainer/Q Targets Mean           -7.72276
trainer/Q Targets Std             3.43862
trainer/Q Targets Max            -1.46509
trainer/Q Targets Min           -13.4175
trainer/Log Pis Mean             -1.31674
trainer/Log Pis Std               0.282115
trainer/Log Pis Max              -0.682422
trainer/Log Pis Min              -1.87842
trainer/Policy mu Mean            0.144744
trainer/Policy mu Std             0.0430139
trainer/Policy mu Max             0.256129
trainer/Policy mu Min             0.0716387
trainer/Policy log std Mean      -0.164648
trainer/Policy log std Std        0.025389
trainer/Policy log std Max       -0.110954
trainer/Policy log std Min       -0.218245
trainer/Alpha                     0.941455
trainer/Alpha Loss               -0.199105
exploration/num steps total     600
exploration/num paths total       6
exploration/path length Mean    100
exploration/path length Std       0
exploration/path length Max     100
exploration/path length Min     100
exploration/Rewards Mean         -8.90767
exploration/Rewards Std           1.91846
exploration/Rewards Max          -4.84589
exploration/Rewards Min         -12.1975
exploration/Returns Mean       -890.767
exploration/Returns Std         106.815
exploration/Returns Max        -783.951
exploration/Returns Min        -997.582
exploration/Actions Mean          0.0241801
exploration/Actions Std           0.576906
exploration/Actions Max           0.997147
exploration/Actions Min          -0.975564
exploration/Num Paths             2
exploration/Average Returns    -890.767
evaluation/num steps total     2000
evaluation/num paths total       20
evaluation/path length Mean     100
evaluation/path length Std        0
evaluation/path length Max      100
evaluation/path length Min      100
evaluation/Rewards Mean          -4.97312
evaluation/Rewards Std            2.1664
evaluation/Rewards Max           -0.674487
evaluation/Rewards Min          -11.3748
evaluation/Returns Mean        -497.312
evaluation/Returns Std          175.637
evaluation/Returns Max         -254.384
evaluation/Returns Min         -860.099
evaluation/Actions Mean           0.145671
evaluation/Actions Std            0.0379963
evaluation/Actions Max            0.214029
evaluation/Actions Min            0.0723753
evaluation/Num Paths             10
evaluation/Average Returns     -497.312
time/data storing (s)             0.00117148
time/evaluation sampling (s)      0.247328
time/exploration sampling (s)     0.0630875
time/logging (s)                  0.00337524
time/saving (s)                   0.00194713
time/training (s)                 0.786254
time/epoch (s)                    1.10316
time/total (s)                    2.41191
Epoch                             1
-----------------------------  -------------
2019-04-21 00:44:15.891259 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 2 finished
-----------------------------  -------------
replay_buffer/size              800
trainer/QF1 Loss                  0.354509
trainer/QF2 Loss                  0.294179
trainer/Policy Loss               8.98365
trainer/Q1 Predictions Mean     -10.2271
trainer/Q1 Predictions Std        5.10242
trainer/Q1 Predictions Max       -3.59329
trainer/Q1 Predictions Min      -21.0033
trainer/Q2 Predictions Mean     -10.2828
trainer/Q2 Predictions Std        5.08149
trainer/Q2 Predictions Max       -3.8295
trainer/Q2 Predictions Min      -21.3911
trainer/Q Targets Mean          -10.3175
trainer/Q Targets Std             5.18308
trainer/Q Targets Max            -1.83997
trainer/Q Targets Min           -20.5681
trainer/Log Pis Mean             -1.16658
trainer/Log Pis Std               0.69751
trainer/Log Pis Max               0.211787
trainer/Log Pis Min              -4.12358
trainer/Policy mu Mean            0.292
trainer/Policy mu Std             0.261046
trainer/Policy mu Max             0.871843
trainer/Policy mu Min            -0.139685
trainer/Policy log std Mean      -0.210307
trainer/Policy log std Std        0.0528842
trainer/Policy log std Max       -0.142538
trainer/Policy log std Min       -0.338537
trainer/Alpha                     0.887982
trainer/Alpha Loss               -0.375294
exploration/num steps total     800
exploration/num paths total       8
exploration/path length Mean    100
exploration/path length Std       0
exploration/path length Max     100
exploration/path length Min     100
exploration/Rewards Mean         -2.81867
exploration/Rewards Std           2.4069
exploration/Rewards Max          -0.348121
exploration/Rewards Min         -10.4222
exploration/Returns Mean       -281.867
exploration/Returns Std          53.5884
exploration/Returns Max        -228.279
exploration/Returns Min        -335.456
exploration/Actions Mean          0.127669
exploration/Actions Std           0.560478
exploration/Actions Max           0.98425
exploration/Actions Min          -0.98145
exploration/Num Paths             2
exploration/Average Returns    -281.867
evaluation/num steps total     3000
evaluation/num paths total       30
evaluation/path length Mean     100
evaluation/path length Std        0
evaluation/path length Max      100
evaluation/path length Min      100
evaluation/Rewards Mean          -3.19776
evaluation/Rewards Std            1.63561
evaluation/Rewards Max           -0.336765
evaluation/Rewards Min          -11.8053
evaluation/Returns Mean        -319.776
evaluation/Returns Std          114.079
evaluation/Returns Max         -161.258
evaluation/Returns Min         -501.061
evaluation/Actions Mean           0.221797
evaluation/Actions Std            0.158022
evaluation/Actions Max            0.681459
evaluation/Actions Min           -0.106301
evaluation/Num Paths             10
evaluation/Average Returns     -319.776
time/data storing (s)             0.00125575
time/evaluation sampling (s)      0.246961
time/exploration sampling (s)     0.0645259
time/logging (s)                  0.00331192
time/saving (s)                   0.00196014
time/training (s)                 0.793788
time/epoch (s)                    1.1118
time/total (s)                    3.52783
Epoch                             2
-----------------------------  -------------
2019-04-21 00:44:17.025445 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 3 finished
-----------------------------  -------------
replay_buffer/size             1000
trainer/QF1 Loss                  2.26538
trainer/QF2 Loss                  2.26803
trainer/Policy Loss              10.8519
trainer/Q1 Predictions Mean     -12.2781
trainer/Q1 Predictions Std        6.64449
trainer/Q1 Predictions Max       -4.73158
trainer/Q1 Predictions Min      -25.4527
trainer/Q2 Predictions Mean     -12.3053
trainer/Q2 Predictions Std        6.60836
trainer/Q2 Predictions Max       -4.92169
trainer/Q2 Predictions Min      -25.5844
trainer/Q Targets Mean          -12.2001
trainer/Q Targets Std             6.69465
trainer/Q Targets Max            -4.43287
trainer/Q Targets Min           -25.8927
trainer/Log Pis Mean             -0.945971
trainer/Log Pis Std               0.823889
trainer/Log Pis Max               1.09872
trainer/Log Pis Min              -3.31663
trainer/Policy mu Mean            0.277118
trainer/Policy mu Std             0.425312
trainer/Policy mu Max             1.02077
trainer/Policy mu Min            -0.713543
trainer/Policy log std Mean      -0.227608
trainer/Policy log std Std        0.0508137
trainer/Policy log std Max       -0.177028
trainer/Policy log std Min       -0.337431
trainer/Alpha                     0.839271
trainer/Alpha Loss               -0.515392
exploration/num steps total    1000
exploration/num paths total      10
exploration/path length Mean    100
exploration/path length Std       0
exploration/path length Max     100
exploration/path length Min     100
exploration/Rewards Mean         -2.02856
exploration/Rewards Std           1.98516
exploration/Rewards Max          -0.149088
exploration/Rewards Min         -10.5077
exploration/Returns Mean       -202.856
exploration/Returns Std          10.0533
exploration/Returns Max        -192.803
exploration/Returns Min        -212.909
exploration/Actions Mean          0.105535
exploration/Actions Std           0.580083
exploration/Actions Max           0.988839
exploration/Actions Min          -0.977206
exploration/Num Paths             2
exploration/Average Returns    -202.856
evaluation/num steps total     4000
evaluation/num paths total       40
evaluation/path length Mean     100
evaluation/path length Std        0
evaluation/path length Max      100
evaluation/path length Min      100
evaluation/Rewards Mean          -1.54294
evaluation/Rewards Std            1.28414
evaluation/Rewards Max           -0.104688
evaluation/Rewards Min          -11.188
evaluation/Returns Mean        -154.294
evaluation/Returns Std           23.834
evaluation/Returns Max         -119.518
evaluation/Returns Min         -193.385
evaluation/Actions Mean           0.105427
evaluation/Actions Std            0.145194
evaluation/Actions Max            0.77813
evaluation/Actions Min           -0.529316
evaluation/Num Paths             10
evaluation/Average Returns     -154.294
time/data storing (s)             0.00134775
time/evaluation sampling (s)      0.249589
time/exploration sampling (s)     0.0660025
time/logging (s)                  0.00333643
time/saving (s)                   0.00505366
time/training (s)                 0.803996
time/epoch (s)                    1.12933
time/total (s)                    4.6613
Epoch                             3
-----------------------------  -------------
2019-04-21 00:44:18.103107 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 4 finished
-----------------------------  -------------
replay_buffer/size             1200
trainer/QF1 Loss                  7.0023
trainer/QF2 Loss                  7.0495
trainer/Policy Loss              13.7582
trainer/Q1 Predictions Mean     -15.8786
trainer/Q1 Predictions Std        9.47343
trainer/Q1 Predictions Max       -5.82378
trainer/Q1 Predictions Min      -36.4716
trainer/Q2 Predictions Mean     -15.851
trainer/Q2 Predictions Std        9.45166
trainer/Q2 Predictions Max       -5.77365
trainer/Q2 Predictions Min      -36.2918
trainer/Q Targets Mean          -15.737
trainer/Q Targets Std             9.36145
trainer/Q Targets Max            -5.22556
trainer/Q Targets Min           -35.7984
trainer/Log Pis Mean             -0.724195
trainer/Log Pis Std               0.93616
trainer/Log Pis Max               1.90453
trainer/Log Pis Min              -3.56625
trainer/Policy mu Mean            0.261372
trainer/Policy mu Std             0.588303
trainer/Policy mu Max             1.20539
trainer/Policy mu Min            -1.08008
trainer/Policy log std Mean      -0.294658
trainer/Policy log std Std        0.0600819
trainer/Policy log std Max       -0.185475
trainer/Policy log std Min       -0.3989
trainer/Alpha                     0.794753
trainer/Alpha Loss               -0.625089
exploration/num steps total    1200
exploration/num paths total      12
exploration/path length Mean    100
exploration/path length Std       0
exploration/path length Max     100
exploration/path length Min     100
exploration/Rewards Mean         -1.28206
exploration/Rewards Std           0.606695
exploration/Rewards Max          -0.133978
exploration/Rewards Min          -3.647
exploration/Returns Mean       -128.206
exploration/Returns Std           3.71757
exploration/Returns Max        -124.488
exploration/Returns Min        -131.924
exploration/Actions Mean          0.0480415
exploration/Actions Std           0.562307
exploration/Actions Max           0.987238
exploration/Actions Min          -0.992309
exploration/Num Paths             2
exploration/Average Returns    -128.206
evaluation/num steps total     5000
evaluation/num paths total       50
evaluation/path length Mean     100
evaluation/path length Std        0
evaluation/path length Max      100
evaluation/path length Min      100
evaluation/Rewards Mean          -1.12832
evaluation/Rewards Std            1.2813
evaluation/Rewards Max           -0.0316955
evaluation/Rewards Min          -10.5549
evaluation/Returns Mean        -112.832
evaluation/Returns Std           74.1009
evaluation/Returns Max          -66.2099
evaluation/Returns Min         -324.552
evaluation/Actions Mean           0.0622629
evaluation/Actions Std            0.179233
evaluation/Actions Max            0.83586
evaluation/Actions Min           -0.718565
evaluation/Num Paths             10
evaluation/Average Returns     -112.832
time/data storing (s)             0.00132583
time/evaluation sampling (s)      0.239032
time/exploration sampling (s)     0.0717912
time/logging (s)                  0.00338785
time/saving (s)                   0.00198647
time/training (s)                 0.755241
time/epoch (s)                    1.07276
time/total (s)                    5.73825
Epoch                             4
-----------------------------  -------------
2019-04-21 00:44:19.183382 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 5 finished
-----------------------------  -------------
replay_buffer/size             1400
trainer/QF1 Loss                  0.983903
trainer/QF2 Loss                  0.997103
trainer/Policy Loss              12.4035
trainer/Q1 Predictions Mean     -14.3458
trainer/Q1 Predictions Std        9.71917
trainer/Q1 Predictions Max       -6.66607
trainer/Q1 Predictions Min      -42.5907
trainer/Q2 Predictions Mean     -14.3633
trainer/Q2 Predictions Std        9.73025
trainer/Q2 Predictions Max       -6.55384
trainer/Q2 Predictions Min      -42.7642
trainer/Q Targets Mean          -14.3032
trainer/Q Targets Std             9.82275
trainer/Q Targets Max            -0.905508
trainer/Q Targets Min           -45.199
trainer/Log Pis Mean             -0.662478
trainer/Log Pis Std               1.14146
trainer/Log Pis Max               2.46277
trainer/Log Pis Min              -2.88519
trainer/Policy mu Mean            0.210198
trainer/Policy mu Std             0.60588
trainer/Policy mu Max             1.38232
trainer/Policy mu Min            -1.20998
trainer/Policy log std Mean      -0.311323
trainer/Policy log std Std        0.091726
trainer/Policy log std Max       -0.170382
trainer/Policy log std Min       -0.493209
trainer/Alpha                     0.75327
trainer/Alpha Loss               -0.753663
exploration/num steps total    1400
exploration/num paths total      14
exploration/path length Mean    100
exploration/path length Std       0
exploration/path length Max     100
exploration/path length Min     100
exploration/Rewards Mean         -1.52764
exploration/Rewards Std           1.51818
exploration/Rewards Max          -0.124244
exploration/Rewards Min         -10.4826
exploration/Returns Mean       -152.764
exploration/Returns Std           5.26978
exploration/Returns Max        -147.494
exploration/Returns Min        -158.033
exploration/Actions Mean          0.0421346
exploration/Actions Std           0.560836
exploration/Actions Max           0.983505
exploration/Actions Min          -0.988481
exploration/Num Paths             2
exploration/Average Returns    -152.764
evaluation/num steps total     6000
evaluation/num paths total       60
evaluation/path length Mean     100
evaluation/path length Std        0
evaluation/path length Max      100
evaluation/path length Min      100
evaluation/Rewards Mean          -0.440621
evaluation/Rewards Std            1.06827
evaluation/Rewards Max           -0.122732
evaluation/Rewards Min           -9.32628
evaluation/Returns Mean         -44.0621
evaluation/Returns Std           16.8174
evaluation/Returns Max          -21.1394
evaluation/Returns Min          -73.943
evaluation/Actions Mean           0.0287918
evaluation/Actions Std            0.152021
evaluation/Actions Max            0.869108
evaluation/Actions Min           -0.767977
evaluation/Num Paths             10
evaluation/Average Returns      -44.0621
time/data storing (s)             0.00120684
time/evaluation sampling (s)      0.228427
time/exploration sampling (s)     0.0708223
time/logging (s)                  0.00316398
time/saving (s)                   0.00201259
time/training (s)                 0.769553
time/epoch (s)                    1.07519
time/total (s)                    6.81758
Epoch                             5
-----------------------------  -------------
2019-04-21 00:44:20.264961 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 6 finished
-----------------------------  --------------
replay_buffer/size             1600
trainer/QF1 Loss                  0.50367
trainer/QF2 Loss                  0.50214
trainer/Policy Loss              14.198
trainer/Q1 Predictions Mean     -16.0422
trainer/Q1 Predictions Std       11.878
trainer/Q1 Predictions Max       -7.4355
trainer/Q1 Predictions Min      -49.1544
trainer/Q2 Predictions Mean     -16.0469
trainer/Q2 Predictions Std       11.8746
trainer/Q2 Predictions Max       -7.29305
trainer/Q2 Predictions Min      -49.1502
trainer/Q Targets Mean          -16.2114
trainer/Q Targets Std            12.1238
trainer/Q Targets Max            -6.93077
trainer/Q Targets Min           -49.629
trainer/Log Pis Mean             -0.621613
trainer/Log Pis Std               1.11768
trainer/Log Pis Max               1.92385
trainer/Log Pis Min              -3.97535
trainer/Policy mu Mean            0.250043
trainer/Policy mu Std             0.663109
trainer/Policy mu Max             1.52081
trainer/Policy mu Min            -1.33162
trainer/Policy log std Mean      -0.334003
trainer/Policy log std Std        0.0892473
trainer/Policy log std Max       -0.187375
trainer/Policy log std Min       -0.557326
trainer/Alpha                     0.714368
trainer/Alpha Loss               -0.881116
exploration/num steps total    1600
exploration/num paths total      16
exploration/path length Mean    100
exploration/path length Std       0
exploration/path length Max     100
exploration/path length Min     100
exploration/Rewards Mean         -1.39287
exploration/Rewards Std           1.43471
exploration/Rewards Max          -0.0696567
exploration/Rewards Min          -8.41528
exploration/Returns Mean       -139.287
exploration/Returns Std           9.42929
exploration/Returns Max        -129.858
exploration/Returns Min        -148.716
exploration/Actions Mean          0.0587246
exploration/Actions Std           0.552838
exploration/Actions Max           0.982628
exploration/Actions Min          -0.991403
exploration/Num Paths             2
exploration/Average Returns    -139.287
evaluation/num steps total     7000
evaluation/num paths total       70
evaluation/path length Mean     100
evaluation/path length Std        0
evaluation/path length Max      100
evaluation/path length Min      100
evaluation/Rewards Mean          -0.92133
evaluation/Rewards Std            1.56447
evaluation/Rewards Max           -0.0523339
evaluation/Rewards Min           -9.86349
evaluation/Returns Mean         -92.133
evaluation/Returns Std          122.98
evaluation/Returns Max          -30.1265
evaluation/Returns Min         -456.743
evaluation/Actions Mean           0.000393247
evaluation/Actions Std            0.24117
evaluation/Actions Max            0.899741
evaluation/Actions Min           -0.867365
evaluation/Num Paths             10
evaluation/Average Returns      -92.133
time/data storing (s)             0.00141071
time/evaluation sampling (s)      0.230097
time/exploration sampling (s)     0.065118
time/logging (s)                  0.00334468
time/saving (s)                   0.00194177
time/training (s)                 0.774798
time/epoch (s)                    1.07671
time/total (s)                    7.89837
Epoch                             6
-----------------------------  --------------
2019-04-21 00:44:21.345780 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 7 finished
-----------------------------  -------------
replay_buffer/size             1800
trainer/QF1 Loss                 18.917
trainer/QF2 Loss                 18.711
trainer/Policy Loss              17.5143
trainer/Q1 Predictions Mean     -19.4778
trainer/Q1 Predictions Std       14.4569
trainer/Q1 Predictions Max       -8.19273
trainer/Q1 Predictions Min      -54.8956
trainer/Q2 Predictions Mean     -19.484
trainer/Q2 Predictions Std       14.4286
trainer/Q2 Predictions Max       -8.13763
trainer/Q2 Predictions Min      -54.6085
trainer/Q Targets Mean          -18.8394
trainer/Q Targets Std            14.3855
trainer/Q Targets Max            -7.54357
trainer/Q Targets Min           -55.8823
trainer/Log Pis Mean             -0.476942
trainer/Log Pis Std               1.16636
trainer/Log Pis Max               2.8165
trainer/Log Pis Min              -2.81596
trainer/Policy mu Mean            0.352453
trainer/Policy mu Std             0.689635
trainer/Policy mu Max             1.55258
trainer/Policy mu Min            -1.40784
trainer/Policy log std Mean      -0.367781
trainer/Policy log std Std        0.101787
trainer/Policy log std Max       -0.218023
trainer/Policy log std Min       -0.586627
trainer/Alpha                     0.677244
trainer/Alpha Loss               -0.964656
exploration/num steps total    1800
exploration/num paths total      18
exploration/path length Mean    100
exploration/path length Std       0
exploration/path length Max     100
exploration/path length Min     100
exploration/Rewards Mean         -1.03881
exploration/Rewards Std           0.745112
exploration/Rewards Max          -0.127148
exploration/Rewards Min          -5.80584
exploration/Returns Mean       -103.881
exploration/Returns Std           3.91386
exploration/Returns Max         -99.9667
exploration/Returns Min        -107.794
exploration/Actions Mean          0.0301319
exploration/Actions Std           0.564957
exploration/Actions Max           0.987679
exploration/Actions Min          -0.980015
exploration/Num Paths             2
exploration/Average Returns    -103.881
evaluation/num steps total     8000
evaluation/num paths total       80
evaluation/path length Mean     100
evaluation/path length Std        0
evaluation/path length Max      100
evaluation/path length Min      100
evaluation/Rewards Mean          -0.367015
evaluation/Rewards Std            0.902723
evaluation/Rewards Max           -0.0784558
evaluation/Rewards Min           -8.83765
evaluation/Returns Mean         -36.7015
evaluation/Returns Std           10.8306
evaluation/Returns Max          -23.8418
evaluation/Returns Min          -58.0442
evaluation/Actions Mean           0.0326346
evaluation/Actions Std            0.162099
evaluation/Actions Max            0.911844
evaluation/Actions Min           -0.826945
evaluation/Num Paths             10
evaluation/Average Returns      -36.7015
time/data storing (s)             0.00130178
time/evaluation sampling (s)      0.227285
time/exploration sampling (s)     0.0647047
time/logging (s)                  0.00303992
time/saving (s)                   0.00194778
time/training (s)                 0.777338
time/epoch (s)                    1.07562
time/total (s)                    8.97797
Epoch                             7
-----------------------------  -------------
2019-04-21 00:44:22.417803 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 8 finished
-----------------------------  -------------
replay_buffer/size             2000
trainer/QF1 Loss                  0.711881
trainer/QF2 Loss                  0.747857
trainer/Policy Loss              16.4845
trainer/Q1 Predictions Mean     -18.415
trainer/Q1 Predictions Std       13.853
trainer/Q1 Predictions Max       -8.85455
trainer/Q1 Predictions Min      -59.7179
trainer/Q2 Predictions Mean     -18.427
trainer/Q2 Predictions Std       13.8472
trainer/Q2 Predictions Max       -8.87153
trainer/Q2 Predictions Min      -59.5637
trainer/Q Targets Mean          -18.6145
trainer/Q Targets Std            14.2122
trainer/Q Targets Max            -8.40157
trainer/Q Targets Min           -61.5981
trainer/Log Pis Mean             -0.469797
trainer/Log Pis Std               1.10635
trainer/Log Pis Max               2.77485
trainer/Log Pis Min              -2.63935
trainer/Policy mu Mean            0.224136
trainer/Policy mu Std             0.745088
trainer/Policy mu Max             1.65453
trainer/Policy mu Min            -1.60265
trainer/Policy log std Mean      -0.388896
trainer/Policy log std Std        0.0965683
trainer/Policy log std Max       -0.224375
trainer/Policy log std Min       -0.645437
trainer/Alpha                     0.641653
trainer/Alpha Loss               -1.0952
exploration/num steps total    2000
exploration/num paths total      20
exploration/path length Mean    100
exploration/path length Std       0
exploration/path length Max     100
exploration/path length Min     100
exploration/Rewards Mean         -1.0548
exploration/Rewards Std           1.12462
exploration/Rewards Max          -0.0238295
exploration/Rewards Min          -8.87409
exploration/Returns Mean       -105.48
exploration/Returns Std          20.9964
exploration/Returns Max         -84.484
exploration/Returns Min        -126.477
exploration/Actions Mean          0.0392236
exploration/Actions Std           0.544036
exploration/Actions Max           0.978123
exploration/Actions Min          -0.947431
exploration/Num Paths             2
exploration/Average Returns    -105.48
evaluation/num steps total     9000
evaluation/num paths total       90
evaluation/path length Mean     100
evaluation/path length Std        0
evaluation/path length Max      100
evaluation/path length Min      100
evaluation/Rewards Mean          -0.192438
evaluation/Rewards Std            0.778002
evaluation/Rewards Max           -0.0248343
evaluation/Rewards Min           -8.42939
evaluation/Returns Mean         -19.2438
evaluation/Returns Std           11.1354
evaluation/Returns Max           -4.81546
evaluation/Returns Min          -48.0105
evaluation/Actions Mean           0.0122649
evaluation/Actions Std            0.153952
evaluation/Actions Max            0.925987
evaluation/Actions Min           -0.912742
evaluation/Num Paths             10
evaluation/Average Returns      -19.2438
time/data storing (s)             0.0012182
time/evaluation sampling (s)      0.22376
time/exploration sampling (s)     0.066149
time/logging (s)                  0.00341888
time/saving (s)                   0.00192301
time/training (s)                 0.771807
time/epoch (s)                    1.06828
time/total (s)                   10.0498
Epoch                             8
-----------------------------  -------------
2019-04-21 00:44:23.487295 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 9 finished
-----------------------------  --------------
replay_buffer/size              2200
trainer/QF1 Loss                  22.5695
trainer/QF2 Loss                  22.5336
trainer/Policy Loss               15.4725
trainer/Q1 Predictions Mean      -17.116
trainer/Q1 Predictions Std        13.9043
trainer/Q1 Predictions Max        -9.52728
trainer/Q1 Predictions Min       -58.6527
trainer/Q2 Predictions Mean      -17.1402
trainer/Q2 Predictions Std        13.8925
trainer/Q2 Predictions Max        -9.55997
trainer/Q2 Predictions Min       -58.792
trainer/Q Targets Mean           -16.7509
trainer/Q Targets Std             13.6053
trainer/Q Targets Max             -1.83997
trainer/Q Targets Min            -60.547
trainer/Log Pis Mean              -0.616091
trainer/Log Pis Std                1.18114
trainer/Log Pis Max                2.6207
trainer/Log Pis Min               -3.1317
trainer/Policy mu Mean             0.154797
trainer/Policy mu Std              0.673626
trainer/Policy mu Max              1.66465
trainer/Policy mu Min             -1.53952
trainer/Policy log std Mean       -0.379412
trainer/Policy log std Std         0.095798
trainer/Policy log std Max        -0.212087
trainer/Policy log std Min        -0.598943
trainer/Alpha                      0.607756
trainer/Alpha Loss                -1.30205
exploration/num steps total     2200
exploration/num paths total       22
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.28502
exploration/Rewards Std            1.2111
exploration/Rewards Max           -0.0538866
exploration/Rewards Min           -9.0354
exploration/Returns Mean        -128.502
exploration/Returns Std           11.5159
exploration/Returns Max         -116.986
exploration/Returns Min         -140.018
exploration/Actions Mean           0.034224
exploration/Actions Std            0.582774
exploration/Actions Max            0.990271
exploration/Actions Min           -0.995149
exploration/Num Paths              2
exploration/Average Returns     -128.502
evaluation/num steps total     10000
evaluation/num paths total       100
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.385452
evaluation/Rewards Std             1.2007
evaluation/Rewards Max            -0.0955168
evaluation/Rewards Min            -9.73011
evaluation/Returns Mean          -38.5452
evaluation/Returns Std            18.9042
evaluation/Returns Max           -13.7124
evaluation/Returns Min           -62.2561
evaluation/Actions Mean            0.0337897
evaluation/Actions Std             0.17704
evaluation/Actions Max             0.933062
evaluation/Actions Min            -0.908577
evaluation/Num Paths              10
evaluation/Average Returns       -38.5452
time/data storing (s)              0.00134561
time/evaluation sampling (s)       0.226765
time/exploration sampling (s)      0.0759249
time/logging (s)                   0.00334753
time/saving (s)                    0.00184118
time/training (s)                  0.755324
time/epoch (s)                     1.06455
time/total (s)                    11.1184
Epoch                              9
-----------------------------  --------------
2019-04-21 00:44:24.547210 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 10 finished
-----------------------------  --------------
replay_buffer/size              2400
trainer/QF1 Loss                   0.439765
trainer/QF2 Loss                   0.478816
trainer/Policy Loss               14.2138
trainer/Q1 Predictions Mean      -16.0015
trainer/Q1 Predictions Std        11.9161
trainer/Q1 Predictions Max       -10.0132
trainer/Q1 Predictions Min       -62.3619
trainer/Q2 Predictions Mean      -15.9997
trainer/Q2 Predictions Std        11.8988
trainer/Q2 Predictions Max        -9.9746
trainer/Q2 Predictions Min       -62.1336
trainer/Q Targets Mean           -16.1738
trainer/Q Targets Std             12.0429
trainer/Q Targets Max             -9.49418
trainer/Q Targets Min            -64.2605
trainer/Log Pis Mean              -0.609971
trainer/Log Pis Std                1.26221
trainer/Log Pis Max                3.29862
trainer/Log Pis Min               -4.72252
trainer/Policy mu Mean             0.114738
trainer/Policy mu Std              0.695209
trainer/Policy mu Max              1.83808
trainer/Policy mu Min             -1.37771
trainer/Policy log std Mean       -0.440374
trainer/Policy log std Std         0.0970249
trainer/Policy log std Max        -0.253688
trainer/Policy log std Min        -0.699064
trainer/Alpha                      0.575422
trainer/Alpha Loss                -1.44169
exploration/num steps total     2400
exploration/num paths total       24
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.00268
exploration/Rewards Std            1.01059
exploration/Rewards Max           -0.0264787
exploration/Rewards Min           -7.55996
exploration/Returns Mean        -100.268
exploration/Returns Std           11.3792
exploration/Returns Max          -88.8887
exploration/Returns Min         -111.647
exploration/Actions Mean           0.047781
exploration/Actions Std            0.549907
exploration/Actions Max            0.986738
exploration/Actions Min           -0.98498
exploration/Num Paths              2
exploration/Average Returns     -100.268
evaluation/num steps total     11000
evaluation/num paths total       110
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.367923
evaluation/Rewards Std             0.970384
evaluation/Rewards Max            -0.108744
evaluation/Rewards Min           -10.5824
evaluation/Returns Mean          -36.7923
evaluation/Returns Std            17.2115
evaluation/Returns Max           -17.5287
evaluation/Returns Min           -72.7559
evaluation/Actions Mean            0.0187401
evaluation/Actions Std             0.161772
evaluation/Actions Max             0.94953
evaluation/Actions Min            -0.909038
evaluation/Num Paths              10
evaluation/Average Returns       -36.7923
time/data storing (s)              0.00143741
time/evaluation sampling (s)       0.224239
time/exploration sampling (s)      0.0829719
time/logging (s)                   0.00335423
time/saving (s)                    0.00192928
time/training (s)                  0.741092
time/epoch (s)                     1.05502
time/total (s)                    12.1775
Epoch                             10
-----------------------------  --------------
2019-04-21 00:44:25.621643 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 11 finished
-----------------------------  --------------
replay_buffer/size              2600
trainer/QF1 Loss                   0.49274
trainer/QF2 Loss                   0.494798
trainer/Policy Loss               17.0608
trainer/Q1 Predictions Mean      -18.806
trainer/Q1 Predictions Std        15.1479
trainer/Q1 Predictions Max       -10.564
trainer/Q1 Predictions Min       -72.5986
trainer/Q2 Predictions Mean      -18.7984
trainer/Q2 Predictions Std        15.1563
trainer/Q2 Predictions Max       -10.4733
trainer/Q2 Predictions Min       -72.9136
trainer/Q Targets Mean           -18.8692
trainer/Q Targets Std             15.1509
trainer/Q Targets Max            -10.1791
trainer/Q Targets Min            -70.2822
trainer/Log Pis Mean              -0.245926
trainer/Log Pis Std                1.33273
trainer/Log Pis Max                3.01075
trainer/Log Pis Min               -4.5604
trainer/Policy mu Mean             0.144071
trainer/Policy mu Std              0.783811
trainer/Policy mu Max              1.87981
trainer/Policy mu Min             -1.80484
trainer/Policy log std Mean       -0.461903
trainer/Policy log std Std         0.0949701
trainer/Policy log std Max        -0.289751
trainer/Policy log std Min        -0.678809
trainer/Alpha                      0.544626
trainer/Alpha Loss                -1.36414
exploration/num steps total     2600
exploration/num paths total       26
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.970103
exploration/Rewards Std            0.768318
exploration/Rewards Max           -0.106531
exploration/Rewards Min           -6.13499
exploration/Returns Mean         -97.0103
exploration/Returns Std            0.192871
exploration/Returns Max          -96.8174
exploration/Returns Min          -97.2031
exploration/Actions Mean          -0.00200463
exploration/Actions Std            0.512169
exploration/Actions Max            0.954708
exploration/Actions Min           -0.995784
exploration/Num Paths              2
exploration/Average Returns      -97.0103
evaluation/num steps total     12000
evaluation/num paths total       120
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.409771
evaluation/Rewards Std             1.17219
evaluation/Rewards Max            -0.0494674
evaluation/Rewards Min           -10.3525
evaluation/Returns Mean          -40.9771
evaluation/Returns Std            22.78
evaluation/Returns Max           -16.5224
evaluation/Returns Min           -77.4575
evaluation/Actions Mean            0.0227054
evaluation/Actions Std             0.166812
evaluation/Actions Max             0.954755
evaluation/Actions Min            -0.915062
evaluation/Num Paths              10
evaluation/Average Returns       -40.9771
time/data storing (s)              0.00124017
time/evaluation sampling (s)       0.231968
time/exploration sampling (s)      0.0694148
time/logging (s)                   0.00335905
time/saving (s)                    0.0019561
time/training (s)                  0.761603
time/epoch (s)                     1.06954
time/total (s)                    13.2511
Epoch                             11
-----------------------------  --------------
2019-04-21 00:44:26.700643 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 12 finished
-----------------------------  --------------
replay_buffer/size              2800
trainer/QF1 Loss                   8.96172
trainer/QF2 Loss                   8.9324
trainer/Policy Loss               16.6638
trainer/Q1 Predictions Mean      -18.4908
trainer/Q1 Predictions Std        14.016
trainer/Q1 Predictions Max       -10.9279
trainer/Q1 Predictions Min       -66.971
trainer/Q2 Predictions Mean      -18.5218
trainer/Q2 Predictions Std        14.0191
trainer/Q2 Predictions Max       -10.909
trainer/Q2 Predictions Min       -67.0095
trainer/Q Targets Mean           -18.3595
trainer/Q Targets Std             14.2257
trainer/Q Targets Max             -1.48467
trainer/Q Targets Min            -67.1339
trainer/Log Pis Mean              -0.317659
trainer/Log Pis Std                1.46521
trainer/Log Pis Max                3.59835
trainer/Log Pis Min               -3.8638
trainer/Policy mu Mean             0.133162
trainer/Policy mu Std              0.771889
trainer/Policy mu Max              1.98322
trainer/Policy mu Min             -1.68187
trainer/Policy log std Mean       -0.485039
trainer/Policy log std Std         0.0847625
trainer/Policy log std Max        -0.308172
trainer/Policy log std Min        -0.661113
trainer/Alpha                      0.515399
trainer/Alpha Loss                -1.53554
exploration/num steps total     2800
exploration/num paths total       28
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.898027
exploration/Rewards Std            0.726679
exploration/Rewards Max           -0.0613129
exploration/Rewards Min           -5.98285
exploration/Returns Mean         -89.8027
exploration/Returns Std            3.14427
exploration/Returns Max          -86.6584
exploration/Returns Min          -92.947
exploration/Actions Mean           0.0156626
exploration/Actions Std            0.527343
exploration/Actions Max            0.966217
exploration/Actions Min           -0.960633
exploration/Num Paths              2
exploration/Average Returns      -89.8027
evaluation/num steps total     13000
evaluation/num paths total       130
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.38222
evaluation/Rewards Std             1.08467
evaluation/Rewards Max            -0.120861
evaluation/Rewards Min            -9.84474
evaluation/Returns Mean          -38.222
evaluation/Returns Std            13.3616
evaluation/Returns Max           -21.1453
evaluation/Returns Min           -64.0825
evaluation/Actions Mean            0.0293409
evaluation/Actions Std             0.176591
evaluation/Actions Max             0.958804
evaluation/Actions Min            -0.856778
evaluation/Num Paths              10
evaluation/Average Returns       -38.222
time/data storing (s)              0.0013367
time/evaluation sampling (s)       0.22827
time/exploration sampling (s)      0.0664826
time/logging (s)                   0.00368797
time/saving (s)                    0.00199903
time/training (s)                  0.772672
time/epoch (s)                     1.07445
time/total (s)                    14.3295
Epoch                             12
-----------------------------  --------------
2019-04-21 00:44:27.780251 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 13 finished
-----------------------------  --------------
replay_buffer/size              3000
trainer/QF1 Loss                   0.639952
trainer/QF2 Loss                   0.626955
trainer/Policy Loss               15.9937
trainer/Q1 Predictions Mean      -17.9941
trainer/Q1 Predictions Std        13.2417
trainer/Q1 Predictions Max       -11.6349
trainer/Q1 Predictions Min       -77.3904
trainer/Q2 Predictions Mean      -17.9983
trainer/Q2 Predictions Std        13.2644
trainer/Q2 Predictions Max       -11.6118
trainer/Q2 Predictions Min       -77.6222
trainer/Q Targets Mean           -18.0537
trainer/Q Targets Std             13.2795
trainer/Q Targets Max            -11.1917
trainer/Q Targets Min            -75.0236
trainer/Log Pis Mean              -0.703583
trainer/Log Pis Std                1.39029
trainer/Log Pis Max                3.16569
trainer/Log Pis Min               -4.12314
trainer/Policy mu Mean             0.156148
trainer/Policy mu Std              0.746405
trainer/Policy mu Max              1.93141
trainer/Policy mu Min             -1.44477
trainer/Policy log std Mean       -0.48752
trainer/Policy log std Std         0.083034
trainer/Policy log std Max        -0.325022
trainer/Policy log std Min        -0.629763
trainer/Alpha                      0.487285
trainer/Alpha Loss                -1.94285
exploration/num steps total     3000
exploration/num paths total       30
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.18741
exploration/Rewards Std            1.49628
exploration/Rewards Max           -0.0730561
exploration/Rewards Min           -9.35724
exploration/Returns Mean        -118.741
exploration/Returns Std            1.4801
exploration/Returns Max         -117.261
exploration/Returns Min         -120.221
exploration/Actions Mean           0.0184211
exploration/Actions Std            0.519742
exploration/Actions Max            0.994038
exploration/Actions Min           -0.978615
exploration/Num Paths              2
exploration/Average Returns     -118.741
evaluation/num steps total     14000
evaluation/num paths total       140
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.392079
evaluation/Rewards Std             1.088
evaluation/Rewards Max            -0.111861
evaluation/Rewards Min            -9.93962
evaluation/Returns Mean          -39.2079
evaluation/Returns Std            18.5703
evaluation/Returns Max           -18.3314
evaluation/Returns Min           -72.1729
evaluation/Actions Mean            0.0314385
evaluation/Actions Std             0.177116
evaluation/Actions Max             0.957411
evaluation/Actions Min            -0.905938
evaluation/Num Paths              10
evaluation/Average Returns       -39.2079
time/data storing (s)              0.00125423
time/evaluation sampling (s)       0.225009
time/exploration sampling (s)      0.0633447
time/logging (s)                   0.00338474
time/saving (s)                    0.00194845
time/training (s)                  0.779376
time/epoch (s)                     1.07432
time/total (s)                    15.408
Epoch                             13
-----------------------------  --------------
2019-04-21 00:44:28.855493 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 14 finished
-----------------------------  --------------
replay_buffer/size              3200
trainer/QF1 Loss                   1.82711
trainer/QF2 Loss                   1.80816
trainer/Policy Loss               18.3514
trainer/Q1 Predictions Mean      -20.0812
trainer/Q1 Predictions Std        14.0821
trainer/Q1 Predictions Max       -12.2187
trainer/Q1 Predictions Min       -75.691
trainer/Q2 Predictions Mean      -20.083
trainer/Q2 Predictions Std        14.0714
trainer/Q2 Predictions Max       -12.1578
trainer/Q2 Predictions Min       -75.4817
trainer/Q Targets Mean           -20.0351
trainer/Q Targets Std             14.298
trainer/Q Targets Max             -1.05505
trainer/Q Targets Min            -76.7926
trainer/Log Pis Mean              -0.279601
trainer/Log Pis Std                1.35606
trainer/Log Pis Max                3.14755
trainer/Log Pis Min               -2.99728
trainer/Policy mu Mean             0.169277
trainer/Policy mu Std              0.815067
trainer/Policy mu Max              2.00462
trainer/Policy mu Min             -1.45815
trainer/Policy log std Mean       -0.524963
trainer/Policy log std Std         0.0780743
trainer/Policy log std Max        -0.367085
trainer/Policy log std Min        -0.675988
trainer/Alpha                      0.460658
trainer/Alpha Loss                -1.76628
exploration/num steps total     3200
exploration/num paths total       32
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.729279
exploration/Rewards Std            0.508425
exploration/Rewards Max           -0.00742658
exploration/Rewards Min           -4.13564
exploration/Returns Mean         -72.9279
exploration/Returns Std            6.08066
exploration/Returns Max          -66.8472
exploration/Returns Min          -79.0086
exploration/Actions Mean          -0.0132507
exploration/Actions Std            0.500465
exploration/Actions Max            0.948268
exploration/Actions Min           -0.976749
exploration/Num Paths              2
exploration/Average Returns      -72.9279
evaluation/num steps total     15000
evaluation/num paths total       150
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.804789
evaluation/Rewards Std             1.54295
evaluation/Rewards Max            -0.00556563
evaluation/Rewards Min            -8.79396
evaluation/Returns Mean          -80.4789
evaluation/Returns Std           129.412
evaluation/Returns Max           -18.5023
evaluation/Returns Min          -467.007
evaluation/Actions Mean            0.0807308
evaluation/Actions Std             0.259002
evaluation/Actions Max             0.964495
evaluation/Actions Min            -0.952132
evaluation/Num Paths              10
evaluation/Average Returns       -80.4789
time/data storing (s)              0.00118923
time/evaluation sampling (s)       0.225546
time/exploration sampling (s)      0.0639932
time/logging (s)                   0.00333129
time/saving (s)                    0.0019423
time/training (s)                  0.77421
time/epoch (s)                     1.07021
time/total (s)                    16.4822
Epoch                             14
-----------------------------  --------------
2019-04-21 00:44:29.914974 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 15 finished
-----------------------------  --------------
replay_buffer/size              3400
trainer/QF1 Loss                   2.16472
trainer/QF2 Loss                   2.08816
trainer/Policy Loss               17.1755
trainer/Q1 Predictions Mean      -18.7514
trainer/Q1 Predictions Std        13.0623
trainer/Q1 Predictions Max       -12.5932
trainer/Q1 Predictions Min       -73.9885
trainer/Q2 Predictions Mean      -18.7553
trainer/Q2 Predictions Std        13.0643
trainer/Q2 Predictions Max       -12.5605
trainer/Q2 Predictions Min       -73.9816
trainer/Q Targets Mean           -18.7988
trainer/Q Targets Std             13.3228
trainer/Q Targets Max             -1.36765
trainer/Q Targets Min            -77.1296
trainer/Log Pis Mean              -0.546959
trainer/Log Pis Std                1.32617
trainer/Log Pis Max                3.36705
trainer/Log Pis Min               -3.35453
trainer/Policy mu Mean             0.0230771
trainer/Policy mu Std              0.743282
trainer/Policy mu Max              2.04117
trainer/Policy mu Min             -1.74964
trainer/Policy log std Mean       -0.533502
trainer/Policy log std Std         0.0973008
trainer/Policy log std Max        -0.358526
trainer/Policy log std Min        -0.657047
trainer/Alpha                      0.435391
trainer/Alpha Loss                -2.11708
exploration/num steps total     3400
exploration/num paths total       34
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.809267
exploration/Rewards Std            0.661358
exploration/Rewards Max           -0.0423775
exploration/Rewards Min           -5.02327
exploration/Returns Mean         -80.9267
exploration/Returns Std            8.80002
exploration/Returns Max          -72.1267
exploration/Returns Min          -89.7267
exploration/Actions Mean          -0.0233775
exploration/Actions Std            0.531906
exploration/Actions Max            0.939613
exploration/Actions Min           -0.991498
exploration/Num Paths              2
exploration/Average Returns      -80.9267
evaluation/num steps total     16000
evaluation/num paths total       160
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.825314
evaluation/Rewards Std             1.4186
evaluation/Rewards Max            -0.0843045
evaluation/Rewards Min            -9.53756
evaluation/Returns Mean          -82.5314
evaluation/Returns Std           121.983
evaluation/Returns Max           -30.3052
evaluation/Returns Min          -445.884
evaluation/Actions Mean            0.0757398
evaluation/Actions Std             0.241129
evaluation/Actions Max             0.963794
evaluation/Actions Min            -0.92774
evaluation/Num Paths              10
evaluation/Average Returns       -82.5314
time/data storing (s)              0.00140714
time/evaluation sampling (s)       0.220903
time/exploration sampling (s)      0.0670378
time/logging (s)                   0.00335993
time/saving (s)                    0.00190963
time/training (s)                  0.75996
time/epoch (s)                     1.05458
time/total (s)                    17.5408
Epoch                             15
-----------------------------  --------------
2019-04-21 00:44:30.997064 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 16 finished
-----------------------------  --------------
replay_buffer/size              3600
trainer/QF1 Loss                  11.4781
trainer/QF2 Loss                  11.3996
trainer/Policy Loss               18.3472
trainer/Q1 Predictions Mean      -19.8341
trainer/Q1 Predictions Std        13.8851
trainer/Q1 Predictions Max       -12.8308
trainer/Q1 Predictions Min       -73.9439
trainer/Q2 Predictions Mean      -19.8518
trainer/Q2 Predictions Std        13.8976
trainer/Q2 Predictions Max       -12.8422
trainer/Q2 Predictions Min       -74.017
trainer/Q Targets Mean           -19.5339
trainer/Q Targets Std             14.1935
trainer/Q Targets Max             -0.500817
trainer/Q Targets Min            -75.5717
trainer/Log Pis Mean              -0.164495
trainer/Log Pis Std                1.67315
trainer/Log Pis Max                4.90125
trainer/Log Pis Min               -4.02163
trainer/Policy mu Mean             0.147146
trainer/Policy mu Std              0.81003
trainer/Policy mu Max              2.13482
trainer/Policy mu Min             -1.73711
trainer/Policy log std Mean       -0.556001
trainer/Policy log std Std         0.0875548
trainer/Policy log std Max        -0.393641
trainer/Policy log std Min        -0.675995
trainer/Alpha                      0.411285
trainer/Alpha Loss                -1.92248
exploration/num steps total     3600
exploration/num paths total       36
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.75158
exploration/Rewards Std            0.513492
exploration/Rewards Max           -0.0156162
exploration/Rewards Min           -4.29032
exploration/Returns Mean         -75.158
exploration/Returns Std            0.461459
exploration/Returns Max          -74.6966
exploration/Returns Min          -75.6195
exploration/Actions Mean           0.0177405
exploration/Actions Std            0.519973
exploration/Actions Max            0.97877
exploration/Actions Min           -0.992105
exploration/Num Paths              2
exploration/Average Returns      -75.158
evaluation/num steps total     17000
evaluation/num paths total       170
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.469739
evaluation/Rewards Std             1.18744
evaluation/Rewards Max            -0.0507633
evaluation/Rewards Min           -10.4361
evaluation/Returns Mean          -46.9739
evaluation/Returns Std            19.9718
evaluation/Returns Max           -22.1799
evaluation/Returns Min           -78.4982
evaluation/Actions Mean            0.0257243
evaluation/Actions Std             0.185793
evaluation/Actions Max             0.973443
evaluation/Actions Min            -0.9115
evaluation/Num Paths              10
evaluation/Average Returns       -46.9739
time/data storing (s)              0.00148812
time/evaluation sampling (s)       0.226052
time/exploration sampling (s)      0.0668242
time/logging (s)                   0.00334712
time/saving (s)                    0.00182278
time/training (s)                  0.778149
time/epoch (s)                     1.07768
time/total (s)                    18.622
Epoch                             16
-----------------------------  --------------
2019-04-21 00:44:32.077373 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 17 finished
-----------------------------  ---------------
replay_buffer/size              3800
trainer/QF1 Loss                   2.22502
trainer/QF2 Loss                   2.24755
trainer/Policy Loss               18.1212
trainer/Q1 Predictions Mean      -19.6783
trainer/Q1 Predictions Std        14.2652
trainer/Q1 Predictions Max       -13.0737
trainer/Q1 Predictions Min       -79.8811
trainer/Q2 Predictions Mean      -19.7043
trainer/Q2 Predictions Std        14.2815
trainer/Q2 Predictions Max       -13.1056
trainer/Q2 Predictions Min       -79.9761
trainer/Q Targets Mean           -19.8121
trainer/Q Targets Std             14.2848
trainer/Q Targets Max             -0.513355
trainer/Q Targets Min            -75.9179
trainer/Log Pis Mean              -0.282326
trainer/Log Pis Std                1.47733
trainer/Log Pis Max                4.19453
trainer/Log Pis Min               -4.52166
trainer/Policy mu Mean             0.0179862
trainer/Policy mu Std              0.807725
trainer/Policy mu Max              2.08201
trainer/Policy mu Min             -1.6289
trainer/Policy log std Mean       -0.553962
trainer/Policy log std Std         0.0931472
trainer/Policy log std Max        -0.391196
trainer/Policy log std Min        -0.667406
trainer/Alpha                      0.38843
trainer/Alpha Loss                -2.15763
exploration/num steps total     3800
exploration/num paths total       38
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.704483
exploration/Rewards Std            0.40074
exploration/Rewards Max           -0.0850955
exploration/Rewards Min           -2.04424
exploration/Returns Mean         -70.4483
exploration/Returns Std            4.4684
exploration/Returns Max          -65.9799
exploration/Returns Min          -74.9167
exploration/Actions Mean          -0.000900087
exploration/Actions Std            0.480317
exploration/Actions Max            0.964237
exploration/Actions Min           -0.969624
exploration/Num Paths              2
exploration/Average Returns      -70.4483
evaluation/num steps total     18000
evaluation/num paths total       180
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.417886
evaluation/Rewards Std             0.72618
evaluation/Rewards Max            -0.127515
evaluation/Rewards Min            -9.49612
evaluation/Returns Mean          -41.7886
evaluation/Returns Std            13.5225
evaluation/Returns Max           -31.3357
evaluation/Returns Min           -78.9173
evaluation/Actions Mean            0.0175737
evaluation/Actions Std             0.148035
evaluation/Actions Max             0.969515
evaluation/Actions Min            -0.918608
evaluation/Num Paths              10
evaluation/Average Returns       -41.7886
time/data storing (s)              0.00120402
time/evaluation sampling (s)       0.224477
time/exploration sampling (s)      0.0658458
time/logging (s)                   0.00335853
time/saving (s)                    0.00195519
time/training (s)                  0.778444
time/epoch (s)                     1.07528
time/total (s)                    19.7013
Epoch                             17
-----------------------------  ---------------
2019-04-21 00:44:33.149665 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 18 finished
-----------------------------  --------------
replay_buffer/size              4000
trainer/QF1 Loss                   2.11759
trainer/QF2 Loss                   2.1552
trainer/Policy Loss               19.1703
trainer/Q1 Predictions Mean      -20.909
trainer/Q1 Predictions Std        14.4598
trainer/Q1 Predictions Max       -13.6875
trainer/Q1 Predictions Min       -71.8824
trainer/Q2 Predictions Mean      -20.9085
trainer/Q2 Predictions Std        14.441
trainer/Q2 Predictions Max       -13.7384
trainer/Q2 Predictions Min       -71.9597
trainer/Q Targets Mean           -20.8324
trainer/Q Targets Std             14.5739
trainer/Q Targets Max             -0.383439
trainer/Q Targets Min            -72.8923
trainer/Log Pis Mean              -0.137269
trainer/Log Pis Std                1.453
trainer/Log Pis Max                4.18659
trainer/Log Pis Min               -3.40029
trainer/Policy mu Mean             0.285921
trainer/Policy mu Std              0.802616
trainer/Policy mu Max              2.2067
trainer/Policy mu Min             -1.37718
trainer/Policy log std Mean       -0.600498
trainer/Policy log std Std         0.0922112
trainer/Policy log std Max        -0.427936
trainer/Policy log std Min        -0.727984
trainer/Alpha                      0.366735
trainer/Alpha Loss                -2.14332
exploration/num steps total     4000
exploration/num paths total       40
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.687494
exploration/Rewards Std            0.449444
exploration/Rewards Max           -0.053272
exploration/Rewards Min           -3.31267
exploration/Returns Mean         -68.7494
exploration/Returns Std            6.85393
exploration/Returns Max          -61.8954
exploration/Returns Min          -75.6033
exploration/Actions Mean           0.0191504
exploration/Actions Std            0.484038
exploration/Actions Max            0.963628
exploration/Actions Min           -0.964767
exploration/Num Paths              2
exploration/Average Returns      -68.7494
evaluation/num steps total     19000
evaluation/num paths total       190
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.24159
evaluation/Rewards Std             0.843384
evaluation/Rewards Max            -0.0553074
evaluation/Rewards Min            -8.32156
evaluation/Returns Mean          -24.159
evaluation/Returns Std            11.3089
evaluation/Returns Max            -9.06488
evaluation/Returns Min           -42.4546
evaluation/Actions Mean            0.0214515
evaluation/Actions Std             0.176983
evaluation/Actions Max             0.971627
evaluation/Actions Min            -0.934902
evaluation/Num Paths              10
evaluation/Average Returns       -24.159
time/data storing (s)              0.00129966
time/evaluation sampling (s)       0.232432
time/exploration sampling (s)      0.0685577
time/logging (s)                   0.00301157
time/saving (s)                    0.00197468
time/training (s)                  0.759607
time/epoch (s)                     1.06688
time/total (s)                    20.7722
Epoch                             18
-----------------------------  --------------
2019-04-21 00:44:34.222489 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 19 finished
-----------------------------  --------------
replay_buffer/size              4200
trainer/QF1 Loss                  23.0695
trainer/QF2 Loss                  22.8618
trainer/Policy Loss               19.095
trainer/Q1 Predictions Mean      -20.77
trainer/Q1 Predictions Std        13.7684
trainer/Q1 Predictions Max       -14.1703
trainer/Q1 Predictions Min       -72.2919
trainer/Q2 Predictions Mean      -20.7662
trainer/Q2 Predictions Std        13.7458
trainer/Q2 Predictions Max       -14.2064
trainer/Q2 Predictions Min       -72.2088
trainer/Q Targets Mean           -20.3382
trainer/Q Targets Std             13.5546
trainer/Q Targets Max             -9.93025
trainer/Q Targets Min            -73.0761
trainer/Log Pis Mean              -0.293604
trainer/Log Pis Std                1.49216
trainer/Log Pis Max                4.31796
trainer/Log Pis Min               -3.4522
trainer/Policy mu Mean             0.124113
trainer/Policy mu Std              0.820142
trainer/Policy mu Max              2.25074
trainer/Policy mu Min             -1.84016
trainer/Policy log std Mean       -0.62753
trainer/Policy log std Std         0.0869993
trainer/Policy log std Max        -0.504406
trainer/Policy log std Min        -0.745378
trainer/Alpha                      0.346351
trainer/Alpha Loss                -2.43126
exploration/num steps total     4200
exploration/num paths total       42
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.718055
exploration/Rewards Std            0.645598
exploration/Rewards Max           -0.00655366
exploration/Rewards Min           -4.72296
exploration/Returns Mean         -71.8055
exploration/Returns Std            0.00273392
exploration/Returns Max          -71.8027
exploration/Returns Min          -71.8082
exploration/Actions Mean           0.00610068
exploration/Actions Std            0.502682
exploration/Actions Max            0.985598
exploration/Actions Min           -0.973692
exploration/Num Paths              2
exploration/Average Returns      -71.8055
evaluation/num steps total     20000
evaluation/num paths total       200
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.320597
evaluation/Rewards Std             1.10532
evaluation/Rewards Max            -0.0777512
evaluation/Rewards Min           -11.005
evaluation/Returns Mean          -32.0597
evaluation/Returns Std            19.5226
evaluation/Returns Max            -9.43391
evaluation/Returns Min           -68.6639
evaluation/Actions Mean            0.0253592
evaluation/Actions Std             0.178294
evaluation/Actions Max             0.975471
evaluation/Actions Min            -0.944109
evaluation/Num Paths              10
evaluation/Average Returns       -32.0597
time/data storing (s)              0.0013535
time/evaluation sampling (s)       0.230801
time/exploration sampling (s)      0.0699961
time/logging (s)                   0.00337786
time/saving (s)                    0.00196485
time/training (s)                  0.761696
time/epoch (s)                     1.06919
time/total (s)                    21.8447
Epoch                             19
-----------------------------  --------------
2019-04-21 00:44:35.303471 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 20 finished
-----------------------------  ---------------
replay_buffer/size              4400
trainer/QF1 Loss                   2.36989
trainer/QF2 Loss                   2.36747
trainer/Policy Loss               16.4914
trainer/Q1 Predictions Mean      -17.4301
trainer/Q1 Predictions Std         8.31108
trainer/Q1 Predictions Max       -14.3128
trainer/Q1 Predictions Min       -70.2185
trainer/Q2 Predictions Mean      -17.4843
trainer/Q2 Predictions Std         8.30174
trainer/Q2 Predictions Max       -14.3925
trainer/Q2 Predictions Min       -70.0623
trainer/Q Targets Mean           -17.5937
trainer/Q Targets Std              8.7234
trainer/Q Targets Max             -1.05505
trainer/Q Targets Min            -71.8668
trainer/Log Pis Mean              -0.230484
trainer/Log Pis Std                1.16676
trainer/Log Pis Max                4.03737
trainer/Log Pis Min               -3.62518
trainer/Policy mu Mean             0.0347586
trainer/Policy mu Std              0.721396
trainer/Policy mu Max              2.13444
trainer/Policy mu Min             -1.86745
trainer/Policy log std Mean       -0.644316
trainer/Policy log std Std         0.104245
trainer/Policy log std Max        -0.501791
trainer/Policy log std Min        -0.785194
trainer/Alpha                      0.327242
trainer/Alpha Loss                -2.49095
exploration/num steps total     4400
exploration/num paths total       44
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.692442
exploration/Rewards Std            0.577567
exploration/Rewards Max           -0.052669
exploration/Rewards Min           -5.49146
exploration/Returns Mean         -69.2442
exploration/Returns Std            4.39092
exploration/Returns Max          -64.8532
exploration/Returns Min          -73.6351
exploration/Actions Mean           0.000417181
exploration/Actions Std            0.510182
exploration/Actions Max            0.97917
exploration/Actions Min           -0.996383
exploration/Num Paths              2
exploration/Average Returns      -69.2442
evaluation/num steps total     21000
evaluation/num paths total       210
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.243393
evaluation/Rewards Std             0.878976
evaluation/Rewards Max            -0.0660246
evaluation/Rewards Min            -9.60271
evaluation/Returns Mean          -24.3393
evaluation/Returns Std            15.5305
evaluation/Returns Max           -10.7055
evaluation/Returns Min           -53.7092
evaluation/Actions Mean            0.0186151
evaluation/Actions Std             0.166399
evaluation/Actions Max             0.976351
evaluation/Actions Min            -0.922426
evaluation/Num Paths              10
evaluation/Average Returns       -24.3393
time/data storing (s)              0.00131833
time/evaluation sampling (s)       0.22874
time/exploration sampling (s)      0.0648651
time/logging (s)                   0.00337984
time/saving (s)                    0.0021827
time/training (s)                  0.775557
time/epoch (s)                     1.07604
time/total (s)                    22.9248
Epoch                             20
-----------------------------  ---------------
2019-04-21 00:44:36.374377 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 21 finished
-----------------------------  --------------
replay_buffer/size              4600
trainer/QF1 Loss                  37.8504
trainer/QF2 Loss                  37.9579
trainer/Policy Loss               19.7734
trainer/Q1 Predictions Mean      -21.258
trainer/Q1 Predictions Std        15.5582
trainer/Q1 Predictions Max       -14.4916
trainer/Q1 Predictions Min       -80.1024
trainer/Q2 Predictions Mean      -21.2289
trainer/Q2 Predictions Std        15.5946
trainer/Q2 Predictions Max       -14.4744
trainer/Q2 Predictions Min       -79.8985
trainer/Q Targets Mean           -20.5702
trainer/Q Targets Std             15.0761
trainer/Q Targets Max             -0.130862
trainer/Q Targets Min            -81.0178
trainer/Log Pis Mean              -0.25075
trainer/Log Pis Std                1.35289
trainer/Log Pis Max                4.3883
trainer/Log Pis Min               -3.3573
trainer/Policy mu Mean             0.139494
trainer/Policy mu Std              0.788
trainer/Policy mu Max              2.31128
trainer/Policy mu Min             -1.55732
trainer/Policy log std Mean       -0.645402
trainer/Policy log std Std         0.106403
trainer/Policy log std Max        -0.482561
trainer/Policy log std Min        -0.788726
trainer/Alpha                      0.309333
trainer/Alpha Loss                -2.64025
exploration/num steps total     4600
exploration/num paths total       46
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.744841
exploration/Rewards Std            0.789117
exploration/Rewards Max           -0.053677
exploration/Rewards Min           -5.93415
exploration/Returns Mean         -74.4841
exploration/Returns Std            6.1049
exploration/Returns Max          -68.3792
exploration/Returns Min          -80.589
exploration/Actions Mean           0.00823782
exploration/Actions Std            0.50427
exploration/Actions Max            0.957674
exploration/Actions Min           -0.964526
exploration/Num Paths              2
exploration/Average Returns      -74.4841
evaluation/num steps total     22000
evaluation/num paths total       220
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.418231
evaluation/Rewards Std             0.967775
evaluation/Rewards Max            -0.0686046
evaluation/Rewards Min           -10.4989
evaluation/Returns Mean          -41.8231
evaluation/Returns Std            16.3994
evaluation/Returns Max           -25.3387
evaluation/Returns Min           -79.017
evaluation/Actions Mean            0.0237043
evaluation/Actions Std             0.175625
evaluation/Actions Max             0.977208
evaluation/Actions Min            -0.948018
evaluation/Num Paths              10
evaluation/Average Returns       -41.8231
time/data storing (s)              0.00130214
time/evaluation sampling (s)       0.228249
time/exploration sampling (s)      0.0669971
time/logging (s)                   0.00334735
time/saving (s)                    0.00206115
time/training (s)                  0.763797
time/epoch (s)                     1.06575
time/total (s)                    23.9946
Epoch                             21
-----------------------------  --------------
2019-04-21 00:44:37.456517 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 22 finished
-----------------------------  --------------
replay_buffer/size              4800
trainer/QF1 Loss                   2.58814
trainer/QF2 Loss                   2.59822
trainer/Policy Loss               19.4428
trainer/Q1 Predictions Mean      -20.416
trainer/Q1 Predictions Std        12.56
trainer/Q1 Predictions Max       -14.8095
trainer/Q1 Predictions Min       -75.4195
trainer/Q2 Predictions Mean      -20.4139
trainer/Q2 Predictions Std        12.5555
trainer/Q2 Predictions Max       -14.8264
trainer/Q2 Predictions Min       -75.5559
trainer/Q Targets Mean           -20.5903
trainer/Q Targets Std             12.806
trainer/Q Targets Max             -0.222938
trainer/Q Targets Min            -77.6667
trainer/Log Pis Mean              -0.0123608
trainer/Log Pis Std                1.40296
trainer/Log Pis Max                3.92722
trainer/Log Pis Min               -2.8712
trainer/Policy mu Mean             0.193959
trainer/Policy mu Std              0.798747
trainer/Policy mu Max              2.37527
trainer/Policy mu Min             -1.83524
trainer/Policy log std Mean       -0.695957
trainer/Policy log std Std         0.133117
trainer/Policy log std Max        -0.476907
trainer/Policy log std Min        -0.882052
trainer/Alpha                      0.292349
trainer/Alpha Loss                -2.47426
exploration/num steps total     4800
exploration/num paths total       48
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.56257
exploration/Rewards Std            0.411914
exploration/Rewards Max           -0.0518299
exploration/Rewards Min           -3.69419
exploration/Returns Mean         -56.257
exploration/Returns Std            1.51387
exploration/Returns Max          -54.7431
exploration/Returns Min          -57.7709
exploration/Actions Mean           0.0101201
exploration/Actions Std            0.481754
exploration/Actions Max            0.996071
exploration/Actions Min           -0.958867
exploration/Num Paths              2
exploration/Average Returns      -56.257
evaluation/num steps total     23000
evaluation/num paths total       230
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.354928
evaluation/Rewards Std             1.03442
evaluation/Rewards Max            -0.0300933
evaluation/Rewards Min           -10.2114
evaluation/Returns Mean          -35.4928
evaluation/Returns Std            13.8877
evaluation/Returns Max           -17.5079
evaluation/Returns Min           -62.6376
evaluation/Actions Mean            0.0203135
evaluation/Actions Std             0.195069
evaluation/Actions Max             0.979856
evaluation/Actions Min            -0.954664
evaluation/Num Paths              10
evaluation/Average Returns       -35.4928
time/data storing (s)              0.00129374
time/evaluation sampling (s)       0.218349
time/exploration sampling (s)      0.0636979
time/logging (s)                   0.00313656
time/saving (s)                    0.00195492
time/training (s)                  0.788408
time/epoch (s)                     1.07684
time/total (s)                    25.0755
Epoch                             22
-----------------------------  --------------
2019-04-21 00:44:38.532856 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 23 finished
-----------------------------  --------------
replay_buffer/size              5000
trainer/QF1 Loss                   7.21864
trainer/QF2 Loss                   7.0201
trainer/Policy Loss               19.4008
trainer/Q1 Predictions Mean      -20.5069
trainer/Q1 Predictions Std        13.0648
trainer/Q1 Predictions Max       -15.3776
trainer/Q1 Predictions Min       -80.9489
trainer/Q2 Predictions Mean      -20.482
trainer/Q2 Predictions Std        13.0492
trainer/Q2 Predictions Max       -15.3686
trainer/Q2 Predictions Min       -80.9246
trainer/Q Targets Mean           -20.1593
trainer/Q Targets Std             13.4731
trainer/Q Targets Max             -1.31705
trainer/Q Targets Min            -80.354
trainer/Log Pis Mean               0.0323869
trainer/Log Pis Std                1.44496
trainer/Log Pis Max                5.39263
trainer/Log Pis Min               -2.87593
trainer/Policy mu Mean             0.105894
trainer/Policy mu Std              0.815674
trainer/Policy mu Max              2.39446
trainer/Policy mu Min             -1.77836
trainer/Policy log std Mean       -0.71515
trainer/Policy log std Std         0.113708
trainer/Policy log std Max        -0.458921
trainer/Policy log std Min        -0.87599
trainer/Alpha                      0.276538
trainer/Alpha Loss                -2.52863
exploration/num steps total     5000
exploration/num paths total       50
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.948257
exploration/Rewards Std            1.51487
exploration/Rewards Max           -0.036203
exploration/Rewards Min           -9.72083
exploration/Returns Mean         -94.8257
exploration/Returns Std            1.62165
exploration/Returns Max          -93.204
exploration/Returns Min          -96.4473
exploration/Actions Mean           0.0658314
exploration/Actions Std            0.502457
exploration/Actions Max            0.994769
exploration/Actions Min           -0.938063
exploration/Num Paths              2
exploration/Average Returns      -94.8257
evaluation/num steps total     24000
evaluation/num paths total       240
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.33645
evaluation/Rewards Std             0.990318
evaluation/Rewards Max            -0.0375341
evaluation/Rewards Min           -10.2179
evaluation/Returns Mean          -33.645
evaluation/Returns Std            19.6001
evaluation/Returns Max           -15.494
evaluation/Returns Min           -72.6633
evaluation/Actions Mean            0.0170143
evaluation/Actions Std             0.167771
evaluation/Actions Max             0.984029
evaluation/Actions Min            -0.939889
evaluation/Num Paths              10
evaluation/Average Returns       -33.645
time/data storing (s)              0.00171406
time/evaluation sampling (s)       0.222397
time/exploration sampling (s)      0.0681806
time/logging (s)                   0.00307662
time/saving (s)                    0.00195869
time/training (s)                  0.774057
time/epoch (s)                     1.07138
time/total (s)                    26.151
Epoch                             23
-----------------------------  --------------
2019-04-21 00:44:39.608463 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 24 finished
-----------------------------  --------------
replay_buffer/size              5200
trainer/QF1 Loss                   4.91834
trainer/QF2 Loss                   4.91618
trainer/Policy Loss               19.8785
trainer/Q1 Predictions Mean      -21.1249
trainer/Q1 Predictions Std        13.9691
trainer/Q1 Predictions Max       -15.1945
trainer/Q1 Predictions Min       -81.0422
trainer/Q2 Predictions Mean      -21.1103
trainer/Q2 Predictions Std        14.0089
trainer/Q2 Predictions Max       -15.171
trainer/Q2 Predictions Min       -81.1477
trainer/Q Targets Mean           -21.0099
trainer/Q Targets Std             14.0584
trainer/Q Targets Max             -0.252152
trainer/Q Targets Min            -77.9591
trainer/Log Pis Mean              -0.0266166
trainer/Log Pis Std                1.40842
trainer/Log Pis Max                4.3677
trainer/Log Pis Min               -3.80502
trainer/Policy mu Mean             0.217497
trainer/Policy mu Std              0.81375
trainer/Policy mu Max              2.4442
trainer/Policy mu Min             -1.93138
trainer/Policy log std Mean       -0.735006
trainer/Policy log std Std         0.126931
trainer/Policy log std Max        -0.497634
trainer/Policy log std Min        -0.902494
trainer/Alpha                      0.26165
trainer/Alpha Loss                -2.71663
exploration/num steps total     5200
exploration/num paths total       52
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.64408
exploration/Rewards Std            0.73434
exploration/Rewards Max           -0.0152541
exploration/Rewards Min           -6.50423
exploration/Returns Mean         -64.408
exploration/Returns Std            9.78815
exploration/Returns Max          -54.6199
exploration/Returns Min          -74.1962
exploration/Actions Mean           0.0202397
exploration/Actions Std            0.476596
exploration/Actions Max            0.999037
exploration/Actions Min           -0.937709
exploration/Num Paths              2
exploration/Average Returns      -64.408
evaluation/num steps total     25000
evaluation/num paths total       250
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.329384
evaluation/Rewards Std             1.11375
evaluation/Rewards Max            -0.0389514
evaluation/Rewards Min           -10.2288
evaluation/Returns Mean          -32.9384
evaluation/Returns Std            19.5762
evaluation/Returns Max           -10.8946
evaluation/Returns Min           -65.2886
evaluation/Actions Mean            0.0225291
evaluation/Actions Std             0.184825
evaluation/Actions Max             0.984821
evaluation/Actions Min            -0.956756
evaluation/Num Paths              10
evaluation/Average Returns       -32.9384
time/data storing (s)              0.00164747
time/evaluation sampling (s)       0.228667
time/exploration sampling (s)      0.0653981
time/logging (s)                   0.00333007
time/saving (s)                    0.00157729
time/training (s)                  0.770122
time/epoch (s)                     1.07074
time/total (s)                    27.2258
Epoch                             24
-----------------------------  --------------
2019-04-21 00:44:40.688712 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 25 finished
-----------------------------  --------------
replay_buffer/size              5400
trainer/QF1 Loss                  26.0289
trainer/QF2 Loss                  25.813
trainer/Policy Loss               19.4382
trainer/Q1 Predictions Mean      -20.6413
trainer/Q1 Predictions Std        12.1942
trainer/Q1 Predictions Max       -15.4271
trainer/Q1 Predictions Min       -73.746
trainer/Q2 Predictions Mean      -20.5982
trainer/Q2 Predictions Std        12.1835
trainer/Q2 Predictions Max       -15.3991
trainer/Q2 Predictions Min       -73.5211
trainer/Q Targets Mean           -20.3111
trainer/Q Targets Std             11.9536
trainer/Q Targets Max             -0.535433
trainer/Q Targets Min            -75.3066
trainer/Log Pis Mean              -0.0381451
trainer/Log Pis Std                1.43842
trainer/Log Pis Max                5.34217
trainer/Log Pis Min               -3.14969
trainer/Policy mu Mean             0.10109
trainer/Policy mu Std              0.830865
trainer/Policy mu Max              2.45605
trainer/Policy mu Min             -1.8554
trainer/Policy log std Mean       -0.766331
trainer/Policy log std Std         0.127457
trainer/Policy log std Max        -0.472701
trainer/Policy log std Min        -0.949633
trainer/Alpha                      0.247687
trainer/Alpha Loss                -2.84386
exploration/num steps total     5400
exploration/num paths total       54
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.94723
exploration/Rewards Std            1.66572
exploration/Rewards Max           -0.0455802
exploration/Rewards Min           -9.74949
exploration/Returns Mean         -94.723
exploration/Returns Std            2.47389
exploration/Returns Max          -92.2491
exploration/Returns Min          -97.1969
exploration/Actions Mean           0.0451329
exploration/Actions Std            0.485294
exploration/Actions Max            0.997872
exploration/Actions Min           -0.973088
exploration/Num Paths              2
exploration/Average Returns      -94.723
evaluation/num steps total     26000
evaluation/num paths total       260
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.240304
evaluation/Rewards Std             0.994622
evaluation/Rewards Max            -0.0307126
evaluation/Rewards Min            -9.57705
evaluation/Returns Mean          -24.0304
evaluation/Returns Std            16.6036
evaluation/Returns Max            -4.99861
evaluation/Returns Min           -55.9416
evaluation/Actions Mean            0.030437
evaluation/Actions Std             0.178682
evaluation/Actions Max             0.985488
evaluation/Actions Min            -0.969552
evaluation/Num Paths              10
evaluation/Average Returns       -24.0304
time/data storing (s)              0.00121645
time/evaluation sampling (s)       0.229051
time/exploration sampling (s)      0.0646215
time/logging (s)                   0.00334961
time/saving (s)                    0.00196213
time/training (s)                  0.774987
time/epoch (s)                     1.07519
time/total (s)                    28.305
Epoch                             25
-----------------------------  --------------
2019-04-21 00:44:41.760328 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 26 finished
-----------------------------  --------------
replay_buffer/size              5600
trainer/QF1 Loss                   2.67987
trainer/QF2 Loss                   2.65222
trainer/Policy Loss               19.7175
trainer/Q1 Predictions Mean      -20.5015
trainer/Q1 Predictions Std        12.1551
trainer/Q1 Predictions Max       -15.7737
trainer/Q1 Predictions Min       -77.5761
trainer/Q2 Predictions Mean      -20.5172
trainer/Q2 Predictions Std        12.1718
trainer/Q2 Predictions Max       -15.7857
trainer/Q2 Predictions Min       -77.7552
trainer/Q Targets Mean           -20.398
trainer/Q Targets Std             12.4257
trainer/Q Targets Max             -0.652025
trainer/Q Targets Min            -78.1303
trainer/Log Pis Mean               0.237428
trainer/Log Pis Std                1.4841
trainer/Log Pis Max                5.81391
trainer/Log Pis Min               -3.58542
trainer/Policy mu Mean             0.13295
trainer/Policy mu Std              0.820121
trainer/Policy mu Max              2.42187
trainer/Policy mu Min             -2.11308
trainer/Policy log std Mean       -0.801503
trainer/Policy log std Std         0.13058
trainer/Policy log std Max        -0.540778
trainer/Policy log std Min        -0.994559
trainer/Alpha                      0.23455
trainer/Alpha Loss                -2.55541
exploration/num steps total     5600
exploration/num paths total       56
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.577993
exploration/Rewards Std            0.567942
exploration/Rewards Max           -0.0519221
exploration/Rewards Min           -5.43706
exploration/Returns Mean         -57.7993
exploration/Returns Std            9.35052
exploration/Returns Max          -48.4488
exploration/Returns Min          -67.1498
exploration/Actions Mean           0.0205572
exploration/Actions Std            0.468985
exploration/Actions Max            0.974969
exploration/Actions Min           -0.95158
exploration/Num Paths              2
exploration/Average Returns      -57.7993
evaluation/num steps total     27000
evaluation/num paths total       270
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.193736
evaluation/Rewards Std             0.869238
evaluation/Rewards Max            -0.00253154
evaluation/Rewards Min            -8.45773
evaluation/Returns Mean          -19.3736
evaluation/Returns Std            11.4984
evaluation/Returns Max            -2.74484
evaluation/Returns Min           -42.9598
evaluation/Actions Mean            0.0139054
evaluation/Actions Std             0.17803
evaluation/Actions Max             0.981559
evaluation/Actions Min            -0.976518
evaluation/Num Paths              10
evaluation/Average Returns       -19.3736
time/data storing (s)              0.00118926
time/evaluation sampling (s)       0.229227
time/exploration sampling (s)      0.061855
time/logging (s)                   0.00337368
time/saving (s)                    0.00196684
time/training (s)                  0.768951
time/epoch (s)                     1.06656
time/total (s)                    29.3756
Epoch                             26
-----------------------------  --------------
2019-04-21 00:44:42.827058 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 27 finished
-----------------------------  --------------
replay_buffer/size              5800
trainer/QF1 Loss                   5.16346
trainer/QF2 Loss                   5.18052
trainer/Policy Loss               18.1062
trainer/Q1 Predictions Mean      -18.8215
trainer/Q1 Predictions Std         8.27397
trainer/Q1 Predictions Max       -15.7249
trainer/Q1 Predictions Min       -70.3782
trainer/Q2 Predictions Mean      -18.8078
trainer/Q2 Predictions Std         8.24932
trainer/Q2 Predictions Max       -15.7225
trainer/Q2 Predictions Min       -70.4303
trainer/Q Targets Mean           -18.7476
trainer/Q Targets Std              8.78572
trainer/Q Targets Max             -0.244414
trainer/Q Targets Min            -71.1136
trainer/Log Pis Mean              -0.0308064
trainer/Log Pis Std                1.3144
trainer/Log Pis Max                4.2735
trainer/Log Pis Min               -3.76746
trainer/Policy mu Mean             0.150628
trainer/Policy mu Std              0.762043
trainer/Policy mu Max              2.50822
trainer/Policy mu Min             -1.99072
trainer/Policy log std Mean       -0.809602
trainer/Policy log std Std         0.116489
trainer/Policy log std Max        -0.377873
trainer/Policy log std Min        -0.982025
trainer/Alpha                      0.222334
trainer/Alpha Loss                -3.05291
exploration/num steps total     5800
exploration/num paths total       58
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.587761
exploration/Rewards Std            0.740799
exploration/Rewards Max           -0.018897
exploration/Rewards Min           -6.75734
exploration/Returns Mean         -58.7761
exploration/Returns Std            9.26271
exploration/Returns Max          -49.5134
exploration/Returns Min          -68.0389
exploration/Actions Mean           0.0152091
exploration/Actions Std            0.465727
exploration/Actions Max            0.982427
exploration/Actions Min           -0.95944
exploration/Num Paths              2
exploration/Average Returns      -58.7761
evaluation/num steps total     28000
evaluation/num paths total       280
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.328743
evaluation/Rewards Std             0.978804
evaluation/Rewards Max            -0.0600037
evaluation/Rewards Min           -10.5021
evaluation/Returns Mean          -32.8743
evaluation/Returns Std            15.9827
evaluation/Returns Max           -14.4846
evaluation/Returns Min           -66.8827
evaluation/Actions Mean            0.0208684
evaluation/Actions Std             0.185968
evaluation/Actions Max             0.983219
evaluation/Actions Min            -0.948993
evaluation/Num Paths              10
evaluation/Average Returns       -32.8743
time/data storing (s)              0.00123755
time/evaluation sampling (s)       0.226319
time/exploration sampling (s)      0.06414
time/logging (s)                   0.00333323
time/saving (s)                    0.00195316
time/training (s)                  0.764288
time/epoch (s)                     1.06127
time/total (s)                    30.4412
Epoch                             27
-----------------------------  --------------
2019-04-21 00:44:43.905045 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 28 finished
-----------------------------  --------------
replay_buffer/size              6000
trainer/QF1 Loss                   0.32981
trainer/QF2 Loss                   0.354037
trainer/Policy Loss               18.2605
trainer/Q1 Predictions Mean      -19.0458
trainer/Q1 Predictions Std        10.6668
trainer/Q1 Predictions Max       -15.7676
trainer/Q1 Predictions Min       -84.4764
trainer/Q2 Predictions Mean      -19.018
trainer/Q2 Predictions Std        10.7005
trainer/Q2 Predictions Max       -15.7491
trainer/Q2 Predictions Min       -84.4322
trainer/Q Targets Mean           -19.2396
trainer/Q Targets Std             10.4723
trainer/Q Targets Max            -15.8923
trainer/Q Targets Min            -85.7206
trainer/Log Pis Mean               0.0115297
trainer/Log Pis Std                1.49936
trainer/Log Pis Max                4.71371
trainer/Log Pis Min               -4.43884
trainer/Policy mu Mean             0.259684
trainer/Policy mu Std              0.702898
trainer/Policy mu Max              2.57323
trainer/Policy mu Min             -2.10643
trainer/Policy log std Mean       -0.845211
trainer/Policy log std Std         0.130066
trainer/Policy log std Max        -0.549498
trainer/Policy log std Min        -1.04632
trainer/Alpha                      0.210694
trainer/Alpha Loss                -3.0962
exploration/num steps total     6000
exploration/num paths total       60
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.791764
exploration/Rewards Std            1.31433
exploration/Rewards Max           -0.0374933
exploration/Rewards Min           -9.56518
exploration/Returns Mean         -79.1764
exploration/Returns Std           12.8046
exploration/Returns Max          -66.3717
exploration/Returns Min          -91.981
exploration/Actions Mean           0.0281371
exploration/Actions Std            0.479805
exploration/Actions Max            0.995555
exploration/Actions Min           -0.9801
exploration/Num Paths              2
exploration/Average Returns      -79.1764
evaluation/num steps total     29000
evaluation/num paths total       290
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.27057
evaluation/Rewards Std             0.670365
evaluation/Rewards Max            -0.0346795
evaluation/Rewards Min            -6.71885
evaluation/Returns Mean          -27.057
evaluation/Returns Std             6.17301
evaluation/Returns Max           -14.9754
evaluation/Returns Min           -36.3501
evaluation/Actions Mean            0.00900155
evaluation/Actions Std             0.178128
evaluation/Actions Max             0.972543
evaluation/Actions Min            -0.971367
evaluation/Num Paths              10
evaluation/Average Returns       -27.057
time/data storing (s)              0.0012181
time/evaluation sampling (s)       0.226735
time/exploration sampling (s)      0.0648317
time/logging (s)                   0.00332156
time/saving (s)                    0.00193254
time/training (s)                  0.774973
time/epoch (s)                     1.07301
time/total (s)                    31.5182
Epoch                             28
-----------------------------  --------------
2019-04-21 00:44:44.990901 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 29 finished
-----------------------------  --------------
replay_buffer/size              6200
trainer/QF1 Loss                   0.209266
trainer/QF2 Loss                   0.225747
trainer/Policy Loss               19.8366
trainer/Q1 Predictions Mean      -20.3389
trainer/Q1 Predictions Std        10.8281
trainer/Q1 Predictions Max       -15.8565
trainer/Q1 Predictions Min       -70.0526
trainer/Q2 Predictions Mean      -20.352
trainer/Q2 Predictions Std        10.8236
trainer/Q2 Predictions Max       -15.8961
trainer/Q2 Predictions Min       -70.1047
trainer/Q Targets Mean           -20.5891
trainer/Q Targets Std             10.8559
trainer/Q Targets Max            -15.8837
trainer/Q Targets Min            -71.1845
trainer/Log Pis Mean               0.362554
trainer/Log Pis Std                1.63036
trainer/Log Pis Max                5.5503
trainer/Log Pis Min               -3.78532
trainer/Policy mu Mean             0.131414
trainer/Policy mu Std              0.884974
trainer/Policy mu Max              2.60822
trainer/Policy mu Min             -1.72125
trainer/Policy log std Mean       -0.885997
trainer/Policy log std Std         0.130375
trainer/Policy log std Max        -0.616214
trainer/Policy log std Min        -1.10289
trainer/Alpha                      0.199899
trainer/Alpha Loss                -2.63577
exploration/num steps total     6200
exploration/num paths total       62
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.493913
exploration/Rewards Std            0.389097
exploration/Rewards Max           -0.0205127
exploration/Rewards Min           -3.22231
exploration/Returns Mean         -49.3913
exploration/Returns Std            2.15531
exploration/Returns Max          -47.236
exploration/Returns Min          -51.5466
exploration/Actions Mean          -0.0010815
exploration/Actions Std            0.45221
exploration/Actions Max            0.954329
exploration/Actions Min           -0.980855
exploration/Num Paths              2
exploration/Average Returns      -49.3913
evaluation/num steps total     30000
evaluation/num paths total       300
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.435538
evaluation/Rewards Std             1.19934
evaluation/Rewards Max            -0.0136815
evaluation/Rewards Min            -9.98241
evaluation/Returns Mean          -43.5538
evaluation/Returns Std            17.8401
evaluation/Returns Max           -20.9023
evaluation/Returns Min           -70.692
evaluation/Actions Mean            0.0321255
evaluation/Actions Std             0.196901
evaluation/Actions Max             0.98969
evaluation/Actions Min            -0.976738
evaluation/Num Paths              10
evaluation/Average Returns       -43.5538
time/data storing (s)              0.00169436
time/evaluation sampling (s)       0.222759
time/exploration sampling (s)      0.0675593
time/logging (s)                   0.00307658
time/saving (s)                    0.00193988
time/training (s)                  0.783426
time/epoch (s)                     1.08046
time/total (s)                    32.6027
Epoch                             29
-----------------------------  --------------
2019-04-21 00:44:46.063123 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 30 finished
-----------------------------  --------------
replay_buffer/size              6400
trainer/QF1 Loss                  20.0042
trainer/QF2 Loss                  19.7741
trainer/Policy Loss               21.0332
trainer/Q1 Predictions Mean      -21.5336
trainer/Q1 Predictions Std        12.8127
trainer/Q1 Predictions Max       -16.109
trainer/Q1 Predictions Min       -73.5923
trainer/Q2 Predictions Mean      -21.5796
trainer/Q2 Predictions Std        12.817
trainer/Q2 Predictions Max       -16.1719
trainer/Q2 Predictions Min       -73.468
trainer/Q Targets Mean           -21.0878
trainer/Q Targets Std             12.9264
trainer/Q Targets Max             -0.762948
trainer/Q Targets Min            -75.2674
trainer/Log Pis Mean               0.556665
trainer/Log Pis Std                1.51744
trainer/Log Pis Max                5.59442
trainer/Log Pis Min               -3.07787
trainer/Policy mu Mean             0.173061
trainer/Policy mu Std              0.877694
trainer/Policy mu Max              2.47977
trainer/Policy mu Min             -2.05517
trainer/Policy log std Mean       -0.906366
trainer/Policy log std Std         0.161015
trainer/Policy log std Max        -0.533406
trainer/Policy log std Min        -1.16538
trainer/Alpha                      0.189626
trainer/Alpha Loss                -2.39947
exploration/num steps total     6400
exploration/num paths total       64
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.537438
exploration/Rewards Std            0.559497
exploration/Rewards Max           -0.0386504
exploration/Rewards Min           -4.63743
exploration/Returns Mean         -53.7438
exploration/Returns Std            2.39755
exploration/Returns Max          -51.3462
exploration/Returns Min          -56.1413
exploration/Actions Mean           0.0278355
exploration/Actions Std            0.429964
exploration/Actions Max            0.979579
exploration/Actions Min           -0.82634
exploration/Num Paths              2
exploration/Average Returns      -53.7438
evaluation/num steps total     31000
evaluation/num paths total       310
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.30222
evaluation/Rewards Std             0.889019
evaluation/Rewards Max            -0.0511153
evaluation/Rewards Min           -10.2075
evaluation/Returns Mean          -30.222
evaluation/Returns Std            15.7605
evaluation/Returns Max           -13.9881
evaluation/Returns Min           -70.8148
evaluation/Actions Mean            0.018839
evaluation/Actions Std             0.175404
evaluation/Actions Max             0.98746
evaluation/Actions Min            -0.954585
evaluation/Num Paths              10
evaluation/Average Returns       -30.222
time/data storing (s)              0.00130993
time/evaluation sampling (s)       0.2318
time/exploration sampling (s)      0.0677133
time/logging (s)                   0.00258159
time/saving (s)                    0.00194355
time/training (s)                  0.761419
time/epoch (s)                     1.06677
time/total (s)                    33.6733
Epoch                             30
-----------------------------  --------------
2019-04-21 00:44:47.160294 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 31 finished
-----------------------------  --------------
replay_buffer/size              6600
trainer/QF1 Loss                   2.6678
trainer/QF2 Loss                   2.69084
trainer/Policy Loss               18.7483
trainer/Q1 Predictions Mean      -19.4033
trainer/Q1 Predictions Std         9.47682
trainer/Q1 Predictions Max       -16.1777
trainer/Q1 Predictions Min       -78.0029
trainer/Q2 Predictions Mean      -19.3921
trainer/Q2 Predictions Std         9.49486
trainer/Q2 Predictions Max       -16.1819
trainer/Q2 Predictions Min       -78.1726
trainer/Q Targets Mean           -19.3984
trainer/Q Targets Std              9.93599
trainer/Q Targets Max             -0.762948
trainer/Q Targets Min            -79.0364
trainer/Log Pis Mean               0.0541841
trainer/Log Pis Std                1.44826
trainer/Log Pis Max                5.75143
trainer/Log Pis Min               -3.76106
trainer/Policy mu Mean             0.104366
trainer/Policy mu Std              0.77049
trainer/Policy mu Max              2.49282
trainer/Policy mu Min             -2.12639
trainer/Policy log std Mean       -0.927419
trainer/Policy log std Std         0.175732
trainer/Policy log std Max        -0.425951
trainer/Policy log std Min        -1.1894
trainer/Alpha                      0.179835
trainer/Alpha Loss                -3.33792
exploration/num steps total     6600
exploration/num paths total       66
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.503023
exploration/Rewards Std            0.534569
exploration/Rewards Max           -0.0334296
exploration/Rewards Min           -5.38947
exploration/Returns Mean         -50.3023
exploration/Returns Std            4.71495
exploration/Returns Max          -45.5873
exploration/Returns Min          -55.0172
exploration/Actions Mean           0.0234151
exploration/Actions Std            0.439216
exploration/Actions Max            0.99483
exploration/Actions Min           -0.853433
exploration/Num Paths              2
exploration/Average Returns      -50.3023
evaluation/num steps total     32000
evaluation/num paths total       320
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.467501
evaluation/Rewards Std             1.27414
evaluation/Rewards Max            -0.0477108
evaluation/Rewards Min            -9.69916
evaluation/Returns Mean          -46.7501
evaluation/Returns Std            16.149
evaluation/Returns Max           -21.1116
evaluation/Returns Min           -68.4709
evaluation/Actions Mean            0.0186907
evaluation/Actions Std             0.214989
evaluation/Actions Max             0.987206
evaluation/Actions Min            -0.976454
evaluation/Num Paths              10
evaluation/Average Returns       -46.7501
time/data storing (s)              0.0013528
time/evaluation sampling (s)       0.232135
time/exploration sampling (s)      0.0716443
time/logging (s)                   0.00338762
time/saving (s)                    0.0104115
time/training (s)                  0.774355
time/epoch (s)                     1.09329
time/total (s)                    34.7705
Epoch                             31
-----------------------------  --------------
2019-04-21 00:44:48.258570 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 32 finished
-----------------------------  --------------
replay_buffer/size              6800
trainer/QF1 Loss                  28.3459
trainer/QF2 Loss                  28.2319
trainer/Policy Loss               19.5549
trainer/Q1 Predictions Mean      -19.7346
trainer/Q1 Predictions Std         9.96351
trainer/Q1 Predictions Max       -16.2176
trainer/Q1 Predictions Min       -76.3765
trainer/Q2 Predictions Mean      -19.7428
trainer/Q2 Predictions Std         9.91876
trainer/Q2 Predictions Max       -16.2386
trainer/Q2 Predictions Min       -76.3113
trainer/Q Targets Mean           -19.1132
trainer/Q Targets Std              9.70044
trainer/Q Targets Max             -0.222938
trainer/Q Targets Min            -77.9563
trainer/Log Pis Mean               0.413981
trainer/Log Pis Std                1.43781
trainer/Log Pis Max                5.14362
trainer/Log Pis Min               -3.07384
trainer/Policy mu Mean             0.142215
trainer/Policy mu Std              0.791753
trainer/Policy mu Max              2.55007
trainer/Policy mu Min             -2.00746
trainer/Policy log std Mean       -0.968456
trainer/Policy log std Std         0.162381
trainer/Policy log std Max        -0.607559
trainer/Policy log std Min        -1.24348
trainer/Alpha                      0.17058
trainer/Alpha Loss                -2.80455
exploration/num steps total     6800
exploration/num paths total       68
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.724589
exploration/Rewards Std            1.40177
exploration/Rewards Max           -0.0306441
exploration/Rewards Min          -10.5481
exploration/Returns Mean         -72.4589
exploration/Returns Std           23.4212
exploration/Returns Max          -49.0377
exploration/Returns Min          -95.8802
exploration/Actions Mean           0.0107444
exploration/Actions Std            0.44312
exploration/Actions Max            0.996242
exploration/Actions Min           -0.987812
exploration/Num Paths              2
exploration/Average Returns      -72.4589
evaluation/num steps total     33000
evaluation/num paths total       330
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.654731
evaluation/Rewards Std             1.5326
evaluation/Rewards Max            -0.0222706
evaluation/Rewards Min            -9.15038
evaluation/Returns Mean          -65.4731
evaluation/Returns Std           119.339
evaluation/Returns Max            -6.37111
evaluation/Returns Min          -419.605
evaluation/Actions Mean            0.0765031
evaluation/Actions Std             0.266963
evaluation/Actions Max             0.986602
evaluation/Actions Min            -0.936931
evaluation/Num Paths              10
evaluation/Average Returns       -65.4731
time/data storing (s)              0.0011755
time/evaluation sampling (s)       0.23757
time/exploration sampling (s)      0.0643142
time/logging (s)                   0.00337248
time/saving (s)                    0.00197121
time/training (s)                  0.784397
time/epoch (s)                     1.0928
time/total (s)                    35.8677
Epoch                             32
-----------------------------  --------------
2019-04-21 00:44:49.330131 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 33 finished
-----------------------------  --------------
replay_buffer/size              7000
trainer/QF1 Loss                   8.16818
trainer/QF2 Loss                   8.16277
trainer/Policy Loss               17.7536
trainer/Q1 Predictions Mean      -18.2749
trainer/Q1 Predictions Std         5.9249
trainer/Q1 Predictions Max       -16.2385
trainer/Q1 Predictions Min       -66.5863
trainer/Q2 Predictions Mean      -18.2873
trainer/Q2 Predictions Std         5.93499
trainer/Q2 Predictions Max       -16.2682
trainer/Q2 Predictions Min       -66.5188
trainer/Q Targets Mean           -18.0003
trainer/Q Targets Std              6.83639
trainer/Q Targets Max             -0.127332
trainer/Q Targets Min            -68.3966
trainer/Log Pis Mean               0.122539
trainer/Log Pis Std                1.38923
trainer/Log Pis Max                5.10935
trainer/Log Pis Min               -3.2331
trainer/Policy mu Mean             0.0347681
trainer/Policy mu Std              0.746396
trainer/Policy mu Max              2.34698
trainer/Policy mu Min             -2.17866
trainer/Policy log std Mean       -1.00151
trainer/Policy log std Std         0.148823
trainer/Policy log std Max        -0.38963
trainer/Policy log std Min        -1.26585
trainer/Alpha                      0.161988
trainer/Alpha Loss                -3.41693
exploration/num steps total     7000
exploration/num paths total       70
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.48129
exploration/Rewards Std            0.570379
exploration/Rewards Max           -0.00786013
exploration/Rewards Min           -4.76863
exploration/Returns Mean         -48.129
exploration/Returns Std            0.485669
exploration/Returns Max          -47.6433
exploration/Returns Min          -48.6146
exploration/Actions Mean          -0.00254833
exploration/Actions Std            0.423238
exploration/Actions Max            0.918682
exploration/Actions Min           -0.959687
exploration/Num Paths              2
exploration/Average Returns      -48.129
evaluation/num steps total     34000
evaluation/num paths total       340
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.25767
evaluation/Rewards Std             1.04102
evaluation/Rewards Max            -0.014111
evaluation/Rewards Min           -10.1726
evaluation/Returns Mean          -25.767
evaluation/Returns Std            16.8239
evaluation/Returns Max            -5.49597
evaluation/Returns Min           -53.0295
evaluation/Actions Mean            0.0304638
evaluation/Actions Std             0.192154
evaluation/Actions Max             0.985864
evaluation/Actions Min            -0.977576
evaluation/Num Paths              10
evaluation/Average Returns       -25.767
time/data storing (s)              0.00125855
time/evaluation sampling (s)       0.228046
time/exploration sampling (s)      0.064372
time/logging (s)                   0.00310894
time/saving (s)                    0.00232724
time/training (s)                  0.766494
time/epoch (s)                     1.06561
time/total (s)                    36.9378
Epoch                             33
-----------------------------  --------------
2019-04-21 00:44:50.434861 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 34 finished
-----------------------------  --------------
replay_buffer/size              7200
trainer/QF1 Loss                   0.189448
trainer/QF2 Loss                   0.179662
trainer/Policy Loss               18.3613
trainer/Q1 Predictions Mean      -18.6849
trainer/Q1 Predictions Std         7.57182
trainer/Q1 Predictions Max       -16.2546
trainer/Q1 Predictions Min       -79.8354
trainer/Q2 Predictions Mean      -18.6806
trainer/Q2 Predictions Std         7.56088
trainer/Q2 Predictions Max       -16.2499
trainer/Q2 Predictions Min       -79.8586
trainer/Q Targets Mean           -18.8428
trainer/Q Targets Std              7.38749
trainer/Q Targets Max            -16.2539
trainer/Q Targets Min            -78.606
trainer/Log Pis Mean               0.274829
trainer/Log Pis Std                1.06583
trainer/Log Pis Max                3.37661
trainer/Log Pis Min               -3.91146
trainer/Policy mu Mean             0.0601877
trainer/Policy mu Std              0.728234
trainer/Policy mu Max              2.65721
trainer/Policy mu Min             -2.04109
trainer/Policy log std Mean       -1.04942
trainer/Policy log std Std         0.176468
trainer/Policy log std Max        -0.543017
trainer/Policy log std Min        -1.34051
trainer/Alpha                      0.15376
trainer/Alpha Loss                -3.22969
exploration/num steps total     7200
exploration/num paths total       72
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.571627
exploration/Rewards Std            0.884016
exploration/Rewards Max           -0.0646231
exploration/Rewards Min           -6.77991
exploration/Returns Mean         -57.1627
exploration/Returns Std            0.99807
exploration/Returns Max          -56.1647
exploration/Returns Min          -58.1608
exploration/Actions Mean           0.0185402
exploration/Actions Std            0.439338
exploration/Actions Max            0.988919
exploration/Actions Min           -0.939228
exploration/Num Paths              2
exploration/Average Returns      -57.1627
evaluation/num steps total     35000
evaluation/num paths total       350
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.26679
evaluation/Rewards Std             0.851485
evaluation/Rewards Max            -0.0902032
evaluation/Rewards Min            -9.30699
evaluation/Returns Mean          -26.679
evaluation/Returns Std            15.5074
evaluation/Returns Max           -11.8537
evaluation/Returns Min           -59.1658
evaluation/Actions Mean            0.0222897
evaluation/Actions Std             0.162378
evaluation/Actions Max             0.987451
evaluation/Actions Min            -0.961686
evaluation/Num Paths              10
evaluation/Average Returns       -26.679
time/data storing (s)              0.00123844
time/evaluation sampling (s)       0.231855
time/exploration sampling (s)      0.0654752
time/logging (s)                   0.00341874
time/saving (s)                    0.00199586
time/training (s)                  0.79574
time/epoch (s)                     1.09972
time/total (s)                    38.0417
Epoch                             34
-----------------------------  --------------
2019-04-21 00:44:51.527035 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 35 finished
-----------------------------  --------------
replay_buffer/size              7400
trainer/QF1 Loss                   2.78254
trainer/QF2 Loss                   2.79133
trainer/Policy Loss               18.8435
trainer/Q1 Predictions Mean      -19.1835
trainer/Q1 Predictions Std         7.87389
trainer/Q1 Predictions Max       -16.3843
trainer/Q1 Predictions Min       -69.786
trainer/Q2 Predictions Mean      -19.2129
trainer/Q2 Predictions Std         7.87803
trainer/Q2 Predictions Max       -16.4322
trainer/Q2 Predictions Min       -69.9532
trainer/Q Targets Mean           -19.0837
trainer/Q Targets Std              8.10759
trainer/Q Targets Max             -0.379644
trainer/Q Targets Min            -71.198
trainer/Log Pis Mean               0.412998
trainer/Log Pis Std                1.61101
trainer/Log Pis Max                6.10025
trainer/Log Pis Min               -5.1087
trainer/Policy mu Mean             0.173721
trainer/Policy mu Std              0.794042
trainer/Policy mu Max              2.52953
trainer/Policy mu Min             -2.34306
trainer/Policy log std Mean       -1.0248
trainer/Policy log std Std         0.193735
trainer/Policy log std Max        -0.498556
trainer/Policy log std Min        -1.34767
trainer/Alpha                      0.146002
trainer/Alpha Loss                -3.05318
exploration/num steps total     7400
exploration/num paths total       74
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.622925
exploration/Rewards Std            1.08236
exploration/Rewards Max           -0.0441024
exploration/Rewards Min           -7.49868
exploration/Returns Mean         -62.2925
exploration/Returns Std            6.89617
exploration/Returns Max          -55.3963
exploration/Returns Min          -69.1887
exploration/Actions Mean           0.0357988
exploration/Actions Std            0.413327
exploration/Actions Max            0.988201
exploration/Actions Min           -0.967101
exploration/Num Paths              2
exploration/Average Returns      -62.2925
evaluation/num steps total     36000
evaluation/num paths total       360
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.323653
evaluation/Rewards Std             1.0628
evaluation/Rewards Max            -0.0353961
evaluation/Rewards Min           -10.4757
evaluation/Returns Mean          -32.3653
evaluation/Returns Std            15.9646
evaluation/Returns Max           -14.5723
evaluation/Returns Min           -61.3278
evaluation/Actions Mean            0.0349322
evaluation/Actions Std             0.200757
evaluation/Actions Max             0.989056
evaluation/Actions Min            -0.977283
evaluation/Num Paths              10
evaluation/Average Returns       -32.3653
time/data storing (s)              0.00149075
time/evaluation sampling (s)       0.230944
time/exploration sampling (s)      0.0688676
time/logging (s)                   0.00334209
time/saving (s)                    0.00193254
time/training (s)                  0.7798
time/epoch (s)                     1.08638
time/total (s)                    39.1324
Epoch                             35
-----------------------------  --------------
2019-04-21 00:44:52.630475 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 36 finished
-----------------------------  --------------
replay_buffer/size              7600
trainer/QF1 Loss                  10.7678
trainer/QF2 Loss                  10.7092
trainer/Policy Loss               20.3389
trainer/Q1 Predictions Mean      -21.2093
trainer/Q1 Predictions Std        12.53
trainer/Q1 Predictions Max       -16.3546
trainer/Q1 Predictions Min       -77.1197
trainer/Q2 Predictions Mean      -21.2192
trainer/Q2 Predictions Std        12.5522
trainer/Q2 Predictions Max       -16.3576
trainer/Q2 Predictions Min       -77.0358
trainer/Q Targets Mean           -20.7363
trainer/Q Targets Std             13.2295
trainer/Q Targets Max             -0.762948
trainer/Q Targets Min            -77.3594
trainer/Log Pis Mean               0.271616
trainer/Log Pis Std                1.58752
trainer/Log Pis Max                4.24761
trainer/Log Pis Min               -4.94893
trainer/Policy mu Mean             0.111057
trainer/Policy mu Std              0.87753
trainer/Policy mu Max              2.69635
trainer/Policy mu Min             -1.93096
trainer/Policy log std Mean       -1.03523
trainer/Policy log std Std         0.176792
trainer/Policy log std Max        -0.57051
trainer/Policy log std Min        -1.37076
trainer/Alpha                      0.138545
trainer/Alpha Loss                -3.41577
exploration/num steps total     7600
exploration/num paths total       76
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.619812
exploration/Rewards Std            1.1411
exploration/Rewards Max           -0.0176831
exploration/Rewards Min           -7.86643
exploration/Returns Mean         -61.9812
exploration/Returns Std            3.17545
exploration/Returns Max          -58.8057
exploration/Returns Min          -65.1566
exploration/Actions Mean           0.0411768
exploration/Actions Std            0.43683
exploration/Actions Max            0.996366
exploration/Actions Min           -0.950443
exploration/Num Paths              2
exploration/Average Returns      -61.9812
evaluation/num steps total     37000
evaluation/num paths total       370
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.382527
evaluation/Rewards Std             1.26615
evaluation/Rewards Max            -0.0667033
evaluation/Rewards Min            -9.5136
evaluation/Returns Mean          -38.2527
evaluation/Returns Std            11.6331
evaluation/Returns Max           -23.614
evaluation/Returns Min           -57.7376
evaluation/Actions Mean            0.0393881
evaluation/Actions Std             0.217349
evaluation/Actions Max             0.990583
evaluation/Actions Min            -0.968818
evaluation/Num Paths              10
evaluation/Average Returns       -38.2527
time/data storing (s)              0.00127271
time/evaluation sampling (s)       0.235209
time/exploration sampling (s)      0.0680301
time/logging (s)                   0.00346325
time/saving (s)                    0.00193249
time/training (s)                  0.788097
time/epoch (s)                     1.098
time/total (s)                    40.2348
Epoch                             36
-----------------------------  --------------
2019-04-21 00:44:53.719403 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 37 finished
-----------------------------  --------------
replay_buffer/size              7800
trainer/QF1 Loss                   2.86536
trainer/QF2 Loss                   2.83611
trainer/Policy Loss               19.5745
trainer/Q1 Predictions Mean      -19.6817
trainer/Q1 Predictions Std         9.65765
trainer/Q1 Predictions Max       -16.5147
trainer/Q1 Predictions Min       -73.196
trainer/Q2 Predictions Mean      -19.6772
trainer/Q2 Predictions Std         9.68873
trainer/Q2 Predictions Max       -16.487
trainer/Q2 Predictions Min       -73.4472
trainer/Q Targets Mean           -19.6671
trainer/Q Targets Std             10.1216
trainer/Q Targets Max             -0.168053
trainer/Q Targets Min            -75.4746
trainer/Log Pis Mean               0.683174
trainer/Log Pis Std                1.57549
trainer/Log Pis Max                6.96466
trainer/Log Pis Min               -3.24322
trainer/Policy mu Mean             0.137967
trainer/Policy mu Std              0.821193
trainer/Policy mu Max              2.66204
trainer/Policy mu Min             -2.06399
trainer/Policy log std Mean       -1.09173
trainer/Policy log std Std         0.185882
trainer/Policy log std Max        -0.634026
trainer/Policy log std Min        -1.46027
trainer/Alpha                      0.131376
trainer/Alpha Loss                -2.67241
exploration/num steps total     7800
exploration/num paths total       78
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.762306
exploration/Rewards Std            1.58384
exploration/Rewards Max           -0.02853
exploration/Rewards Min          -10.8631
exploration/Returns Mean         -76.2306
exploration/Returns Std           16.6594
exploration/Returns Max          -59.5712
exploration/Returns Min          -92.89
exploration/Actions Mean           0.0319511
exploration/Actions Std            0.412872
exploration/Actions Max            0.996261
exploration/Actions Min           -0.889481
exploration/Num Paths              2
exploration/Average Returns      -76.2306
evaluation/num steps total     38000
evaluation/num paths total       380
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.39929
evaluation/Rewards Std             2.38231
evaluation/Rewards Max            -0.0291378
evaluation/Rewards Min           -10.4132
evaluation/Returns Mean         -139.929
evaluation/Returns Std           214.593
evaluation/Returns Max            -9.42557
evaluation/Returns Min          -612.226
evaluation/Actions Mean            0.0647589
evaluation/Actions Std             0.377799
evaluation/Actions Max             0.992517
evaluation/Actions Min            -0.988735
evaluation/Num Paths              10
evaluation/Average Returns      -139.929
time/data storing (s)              0.00130972
time/evaluation sampling (s)       0.237019
time/exploration sampling (s)      0.0630555
time/logging (s)                   0.00335088
time/saving (s)                    0.00174939
time/training (s)                  0.776766
time/epoch (s)                     1.08325
time/total (s)                    41.3224
Epoch                             37
-----------------------------  --------------
2019-04-21 00:44:54.813123 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 38 finished
-----------------------------  --------------
replay_buffer/size              8000
trainer/QF1 Loss                   5.65703
trainer/QF2 Loss                   5.64077
trainer/Policy Loss               21.2564
trainer/Q1 Predictions Mean      -21.6606
trainer/Q1 Predictions Std        13.0867
trainer/Q1 Predictions Max       -16.6567
trainer/Q1 Predictions Min       -75.5799
trainer/Q2 Predictions Mean      -21.6488
trainer/Q2 Predictions Std        13.0807
trainer/Q2 Predictions Max       -16.6848
trainer/Q2 Predictions Min       -75.4311
trainer/Q Targets Mean           -21.4391
trainer/Q Targets Std             13.6287
trainer/Q Targets Max             -0.916609
trainer/Q Targets Min            -77.315
trainer/Log Pis Mean               0.725831
trainer/Log Pis Std                1.7037
trainer/Log Pis Max                7.32503
trainer/Log Pis Min               -2.53358
trainer/Policy mu Mean             0.0291867
trainer/Policy mu Std              0.935033
trainer/Policy mu Max              2.67532
trainer/Policy mu Min             -2.55774
trainer/Policy log std Mean       -1.04138
trainer/Policy log std Std         0.203105
trainer/Policy log std Max        -0.417272
trainer/Policy log std Min        -1.42602
trainer/Alpha                      0.124665
trainer/Alpha Loss                -2.65267
exploration/num steps total     8000
exploration/num paths total       80
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.810688
exploration/Rewards Std            1.64022
exploration/Rewards Max           -0.0410319
exploration/Rewards Min           -9.96277
exploration/Returns Mean         -81.0688
exploration/Returns Std            7.22511
exploration/Returns Max          -73.8436
exploration/Returns Min          -88.2939
exploration/Actions Mean           0.0519254
exploration/Actions Std            0.43543
exploration/Actions Max            0.997622
exploration/Actions Min           -0.980054
exploration/Num Paths              2
exploration/Average Returns      -81.0688
evaluation/num steps total     39000
evaluation/num paths total       390
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.243519
evaluation/Rewards Std             0.997554
evaluation/Rewards Max            -0.0351495
evaluation/Rewards Min            -9.2922
evaluation/Returns Mean          -24.3519
evaluation/Returns Std            16.0602
evaluation/Returns Max            -4.7634
evaluation/Returns Min           -53.0849
evaluation/Actions Mean            0.0277897
evaluation/Actions Std             0.178692
evaluation/Actions Max             0.988554
evaluation/Actions Min            -0.957648
evaluation/Num Paths              10
evaluation/Average Returns       -24.3519
time/data storing (s)              0.00129078
time/evaluation sampling (s)       0.229226
time/exploration sampling (s)      0.0710161
time/logging (s)                   0.00323916
time/saving (s)                    0.00192383
time/training (s)                  0.781433
time/epoch (s)                     1.08813
time/total (s)                    42.4147
Epoch                             38
-----------------------------  --------------
2019-04-21 00:44:55.945826 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 39 finished
-----------------------------  --------------
replay_buffer/size              8200
trainer/QF1 Loss                   0.120594
trainer/QF2 Loss                   0.143965
trainer/Policy Loss               18.3246
trainer/Q1 Predictions Mean      -18.5003
trainer/Q1 Predictions Std         5.4144
trainer/Q1 Predictions Max       -16.4979
trainer/Q1 Predictions Min       -52.7407
trainer/Q2 Predictions Mean      -18.4534
trainer/Q2 Predictions Std         5.42167
trainer/Q2 Predictions Max       -16.4714
trainer/Q2 Predictions Min       -52.6347
trainer/Q Targets Mean           -18.6711
trainer/Q Targets Std              5.34494
trainer/Q Targets Max            -16.4658
trainer/Q Targets Min            -52.0319
trainer/Log Pis Mean               0.270147
trainer/Log Pis Std                1.55848
trainer/Log Pis Max                5.014
trainer/Log Pis Min               -6.88879
trainer/Policy mu Mean             0.0527004
trainer/Policy mu Std              0.773906
trainer/Policy mu Max              2.69525
trainer/Policy mu Min             -2.09779
trainer/Policy log std Mean       -1.11059
trainer/Policy log std Std         0.176908
trainer/Policy log std Max        -0.484768
trainer/Policy log std Min        -1.44827
trainer/Alpha                      0.118171
trainer/Alpha Loss                -3.69386
exploration/num steps total     8200
exploration/num paths total       82
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.700377
exploration/Rewards Std            1.50477
exploration/Rewards Max           -0.0185886
exploration/Rewards Min          -11.3361
exploration/Returns Mean         -70.0377
exploration/Returns Std           23.6858
exploration/Returns Max          -46.3519
exploration/Returns Min          -93.7236
exploration/Actions Mean           0.0627078
exploration/Actions Std            0.43684
exploration/Actions Max            0.997475
exploration/Actions Min           -0.885454
exploration/Num Paths              2
exploration/Average Returns      -70.0377
evaluation/num steps total     40000
evaluation/num paths total       400
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.20597
evaluation/Rewards Std             0.69313
evaluation/Rewards Max            -0.0223073
evaluation/Rewards Min            -8.39362
evaluation/Returns Mean          -20.597
evaluation/Returns Std             8.98496
evaluation/Returns Max           -10.4429
evaluation/Returns Min           -43.4669
evaluation/Actions Mean            0.0170522
evaluation/Actions Std             0.175255
evaluation/Actions Max             0.990394
evaluation/Actions Min            -0.97958
evaluation/Num Paths              10
evaluation/Average Returns       -20.597
time/data storing (s)              0.00122858
time/evaluation sampling (s)       0.228608
time/exploration sampling (s)      0.0669518
time/logging (s)                   0.00350214
time/saving (s)                    0.00212339
time/training (s)                  0.825545
time/epoch (s)                     1.12796
time/total (s)                    43.5469
Epoch                             39
-----------------------------  --------------
2019-04-21 00:44:57.056632 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 40 finished
-----------------------------  --------------
replay_buffer/size              8400
trainer/QF1 Loss                   0.47344
trainer/QF2 Loss                   0.473877
trainer/Policy Loss               19.7958
trainer/Q1 Predictions Mean      -20.2145
trainer/Q1 Predictions Std        11.2868
trainer/Q1 Predictions Max       -16.4279
trainer/Q1 Predictions Min       -78.9347
trainer/Q2 Predictions Mean      -20.2135
trainer/Q2 Predictions Std        11.2857
trainer/Q2 Predictions Max       -16.4149
trainer/Q2 Predictions Min       -78.9357
trainer/Q Targets Mean           -20.6124
trainer/Q Targets Std             11.7328
trainer/Q Targets Max            -16.5413
trainer/Q Targets Min            -81.0386
trainer/Log Pis Mean               0.507952
trainer/Log Pis Std                1.69709
trainer/Log Pis Max                7.34865
trainer/Log Pis Min               -3.56777
trainer/Policy mu Mean             0.119092
trainer/Policy mu Std              0.845365
trainer/Policy mu Max              2.78892
trainer/Policy mu Min             -2.29985
trainer/Policy log std Mean       -1.1056
trainer/Policy log std Std         0.168627
trainer/Policy log std Max        -0.628934
trainer/Policy log std Min        -1.44199
trainer/Alpha                      0.112122
trainer/Alpha Loss                -3.26447
exploration/num steps total     8400
exploration/num paths total       84
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.441267
exploration/Rewards Std            0.516269
exploration/Rewards Max           -0.0224829
exploration/Rewards Min           -4.60545
exploration/Returns Mean         -44.1267
exploration/Returns Std            2.3379
exploration/Returns Max          -41.7888
exploration/Returns Min          -46.4646
exploration/Actions Mean           0.0136746
exploration/Actions Std            0.403021
exploration/Actions Max            0.987785
exploration/Actions Min           -0.991978
exploration/Num Paths              2
exploration/Average Returns      -44.1267
evaluation/num steps total     41000
evaluation/num paths total       410
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.353337
evaluation/Rewards Std             1.2027
evaluation/Rewards Max            -0.0671029
evaluation/Rewards Min           -10.4671
evaluation/Returns Mean          -35.3337
evaluation/Returns Std            17.747
evaluation/Returns Max           -10.7238
evaluation/Returns Min           -67.27
evaluation/Actions Mean            0.0295794
evaluation/Actions Std             0.207463
evaluation/Actions Max             0.992826
evaluation/Actions Min            -0.987045
evaluation/Num Paths              10
evaluation/Average Returns       -35.3337
time/data storing (s)              0.00149638
time/evaluation sampling (s)       0.233453
time/exploration sampling (s)      0.0678859
time/logging (s)                   0.00335703
time/saving (s)                    0.00193889
time/training (s)                  0.796885
time/epoch (s)                     1.10502
time/total (s)                    44.6561
Epoch                             40
-----------------------------  --------------
2019-04-21 00:44:58.163515 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 41 finished
-----------------------------  --------------
replay_buffer/size              8600
trainer/QF1 Loss                   0.116497
trainer/QF2 Loss                   0.128554
trainer/Policy Loss               19.6256
trainer/Q1 Predictions Mean      -19.7687
trainer/Q1 Predictions Std        11.1177
trainer/Q1 Predictions Max       -16.5596
trainer/Q1 Predictions Min       -76.3088
trainer/Q2 Predictions Mean      -19.7356
trainer/Q2 Predictions Std        11.0867
trainer/Q2 Predictions Max       -16.5381
trainer/Q2 Predictions Min       -76.0618
trainer/Q Targets Mean           -19.9324
trainer/Q Targets Std             11.1151
trainer/Q Targets Max            -16.4648
trainer/Q Targets Min            -77.4437
trainer/Log Pis Mean               0.37637
trainer/Log Pis Std                1.43171
trainer/Log Pis Max                5.40897
trainer/Log Pis Min               -4.6127
trainer/Policy mu Mean             0.111902
trainer/Policy mu Std              0.783124
trainer/Policy mu Max              2.92497
trainer/Policy mu Min             -2.18083
trainer/Policy log std Mean       -1.13441
trainer/Policy log std Std         0.198298
trainer/Policy log std Max        -0.24122
trainer/Policy log std Min        -1.4683
trainer/Alpha                      0.106282
trainer/Alpha Loss                -3.63919
exploration/num steps total     8600
exploration/num paths total       86
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.404545
exploration/Rewards Std            0.326989
exploration/Rewards Max           -0.0366262
exploration/Rewards Min           -3.28944
exploration/Returns Mean         -40.4545
exploration/Returns Std            2.6612
exploration/Returns Max          -37.7933
exploration/Returns Min          -43.1157
exploration/Actions Mean           0.0169644
exploration/Actions Std            0.39631
exploration/Actions Max            0.986312
exploration/Actions Min           -0.881611
exploration/Num Paths              2
exploration/Average Returns      -40.4545
evaluation/num steps total     42000
evaluation/num paths total       420
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.453629
evaluation/Rewards Std             1.33724
evaluation/Rewards Max            -0.12973
evaluation/Rewards Min           -10.4157
evaluation/Returns Mean          -45.3629
evaluation/Returns Std            18.215
evaluation/Returns Max           -15.2625
evaluation/Returns Min           -70.429
evaluation/Actions Mean            0.0441108
evaluation/Actions Std             0.211847
evaluation/Actions Max             0.993672
evaluation/Actions Min            -0.955486
evaluation/Num Paths              10
evaluation/Average Returns       -45.3629
time/data storing (s)              0.00120881
time/evaluation sampling (s)       0.234461
time/exploration sampling (s)      0.0740787
time/logging (s)                   0.00336582
time/saving (s)                    0.00194237
time/training (s)                  0.786506
time/epoch (s)                     1.10156
time/total (s)                    45.7618
Epoch                             41
-----------------------------  --------------
2019-04-21 00:44:59.250108 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 42 finished
-----------------------------  --------------
replay_buffer/size              8800
trainer/QF1 Loss                   0.0976023
trainer/QF2 Loss                   0.0983009
trainer/Policy Loss               19.2375
trainer/Q1 Predictions Mean      -19.1421
trainer/Q1 Predictions Std         6.63238
trainer/Q1 Predictions Max       -16.5682
trainer/Q1 Predictions Min       -50.3823
trainer/Q2 Predictions Mean      -19.1322
trainer/Q2 Predictions Std         6.61034
trainer/Q2 Predictions Max       -16.545
trainer/Q2 Predictions Min       -50.2912
trainer/Q Targets Mean           -19.3168
trainer/Q Targets Std              6.53439
trainer/Q Targets Max            -16.5289
trainer/Q Targets Min            -49.9578
trainer/Log Pis Mean               0.601685
trainer/Log Pis Std                1.25507
trainer/Log Pis Max                4.62439
trainer/Log Pis Min               -2.71718
trainer/Policy mu Mean             0.114586
trainer/Policy mu Std              0.847721
trainer/Policy mu Max              2.59323
trainer/Policy mu Min             -1.92834
trainer/Policy log std Mean       -1.15962
trainer/Policy log std Std         0.197907
trainer/Policy log std Max        -0.573335
trainer/Policy log std Min        -1.51491
trainer/Alpha                      0.100889
trainer/Alpha Loss                -3.20698
exploration/num steps total     8800
exploration/num paths total       88
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.680783
exploration/Rewards Std            1.36435
exploration/Rewards Max           -0.0127068
exploration/Rewards Min           -9.97352
exploration/Returns Mean         -68.0783
exploration/Returns Std           14.6579
exploration/Returns Max          -53.4204
exploration/Returns Min          -82.7363
exploration/Actions Mean           0.0166293
exploration/Actions Std            0.417422
exploration/Actions Max            0.996452
exploration/Actions Min           -0.995522
exploration/Num Paths              2
exploration/Average Returns      -68.0783
evaluation/num steps total     43000
evaluation/num paths total       430
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.297715
evaluation/Rewards Std             0.974548
evaluation/Rewards Max            -0.0771247
evaluation/Rewards Min            -8.83297
evaluation/Returns Mean          -29.7715
evaluation/Returns Std            12.5031
evaluation/Returns Max            -9.53471
evaluation/Returns Min           -51.4704
evaluation/Actions Mean            0.0249693
evaluation/Actions Std             0.191155
evaluation/Actions Max             0.99162
evaluation/Actions Min            -0.987277
evaluation/Num Paths              10
evaluation/Average Returns       -29.7715
time/data storing (s)              0.00138127
time/evaluation sampling (s)       0.232251
time/exploration sampling (s)      0.064696
time/logging (s)                   0.00346924
time/saving (s)                    0.00197297
time/training (s)                  0.777662
time/epoch (s)                     1.08143
time/total (s)                    46.8472
Epoch                             42
-----------------------------  --------------
2019-04-21 00:45:00.326278 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 43 finished
-----------------------------  --------------
replay_buffer/size              9000
trainer/QF1 Loss                   5.4831
trainer/QF2 Loss                   5.49622
trainer/Policy Loss               19.9482
trainer/Q1 Predictions Mean      -20.0019
trainer/Q1 Predictions Std        10.987
trainer/Q1 Predictions Max       -16.538
trainer/Q1 Predictions Min       -78.1362
trainer/Q2 Predictions Mean      -20.0085
trainer/Q2 Predictions Std        10.9824
trainer/Q2 Predictions Max       -16.5562
trainer/Q2 Predictions Min       -78.0253
trainer/Q Targets Mean           -19.9303
trainer/Q Targets Std             11.2978
trainer/Q Targets Max             -0.713629
trainer/Q Targets Min            -79.4378
trainer/Log Pis Mean               0.669488
trainer/Log Pis Std                1.63893
trainer/Log Pis Max                7.52258
trainer/Log Pis Min               -3.39827
trainer/Policy mu Mean             0.240483
trainer/Policy mu Std              0.850021
trainer/Policy mu Max              2.97968
trainer/Policy mu Min             -1.76518
trainer/Policy log std Mean       -1.16894
trainer/Policy log std Std         0.19986
trainer/Policy log std Max        -0.578419
trainer/Policy log std Min        -1.52863
trainer/Alpha                      0.0957982
trainer/Alpha Loss                -3.12039
exploration/num steps total     9000
exploration/num paths total       90
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.444182
exploration/Rewards Std            0.722052
exploration/Rewards Max           -0.0241033
exploration/Rewards Min           -5.44051
exploration/Returns Mean         -44.4182
exploration/Returns Std            0.608344
exploration/Returns Max          -43.8098
exploration/Returns Min          -45.0265
exploration/Actions Mean           0.00555811
exploration/Actions Std            0.364369
exploration/Actions Max            0.983601
exploration/Actions Min           -0.995209
exploration/Num Paths              2
exploration/Average Returns      -44.4182
evaluation/num steps total     44000
evaluation/num paths total       440
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.219878
evaluation/Rewards Std             0.743857
evaluation/Rewards Max            -0.0708283
evaluation/Rewards Min            -7.90426
evaluation/Returns Mean          -21.9878
evaluation/Returns Std            12.8596
evaluation/Returns Max            -9.7399
evaluation/Returns Min           -44.2048
evaluation/Actions Mean            0.019214
evaluation/Actions Std             0.158382
evaluation/Actions Max             0.991012
evaluation/Actions Min            -0.982416
evaluation/Num Paths              10
evaluation/Average Returns       -21.9878
time/data storing (s)              0.00141276
time/evaluation sampling (s)       0.228047
time/exploration sampling (s)      0.0658335
time/logging (s)                   0.00333694
time/saving (s)                    0.00156639
time/training (s)                  0.770509
time/epoch (s)                     1.07071
time/total (s)                    47.9219
Epoch                             43
-----------------------------  --------------
2019-04-21 00:45:01.412265 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 44 finished
-----------------------------  --------------
replay_buffer/size              9200
trainer/QF1 Loss                   0.077377
trainer/QF2 Loss                   0.0807083
trainer/Policy Loss               18.6405
trainer/Q1 Predictions Mean      -18.3515
trainer/Q1 Predictions Std         5.56473
trainer/Q1 Predictions Max       -16.6978
trainer/Q1 Predictions Min       -60.6682
trainer/Q2 Predictions Mean      -18.3783
trainer/Q2 Predictions Std         5.56272
trainer/Q2 Predictions Max       -16.6956
trainer/Q2 Predictions Min       -60.8386
trainer/Q Targets Mean           -18.4782
trainer/Q Targets Std              5.53546
trainer/Q Targets Max            -16.6031
trainer/Q Targets Min            -60.782
trainer/Log Pis Mean               0.639043
trainer/Log Pis Std                1.35978
trainer/Log Pis Max                5.49206
trainer/Log Pis Min               -3.49516
trainer/Policy mu Mean             0.101625
trainer/Policy mu Std              0.75103
trainer/Policy mu Max              2.84047
trainer/Policy mu Min             -2.74575
trainer/Policy log std Mean       -1.23032
trainer/Policy log std Std         0.203549
trainer/Policy log std Max        -0.390111
trainer/Policy log std Min        -1.5956
trainer/Alpha                      0.0909715
trainer/Alpha Loss                -3.26214
exploration/num steps total     9200
exploration/num paths total       92
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.422415
exploration/Rewards Std            0.60337
exploration/Rewards Max           -0.0142023
exploration/Rewards Min           -5.19763
exploration/Returns Mean         -42.2415
exploration/Returns Std            3.20684
exploration/Returns Max          -39.0347
exploration/Returns Min          -45.4483
exploration/Actions Mean           0.00633985
exploration/Actions Std            0.381093
exploration/Actions Max            0.982249
exploration/Actions Min           -0.992246
exploration/Num Paths              2
exploration/Average Returns      -42.2415
evaluation/num steps total     45000
evaluation/num paths total       450
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.421238
evaluation/Rewards Std             1.30985
evaluation/Rewards Max            -0.0674259
evaluation/Rewards Min           -10.1488
evaluation/Returns Mean          -42.1238
evaluation/Returns Std            17.2595
evaluation/Returns Max           -13.6048
evaluation/Returns Min           -67.0222
evaluation/Actions Mean            0.0341587
evaluation/Actions Std             0.208565
evaluation/Actions Max             0.994168
evaluation/Actions Min            -0.992951
evaluation/Num Paths              10
evaluation/Average Returns       -42.1238
time/data storing (s)              0.00124451
time/evaluation sampling (s)       0.227304
time/exploration sampling (s)      0.0637922
time/logging (s)                   0.00338533
time/saving (s)                    0.00195771
time/training (s)                  0.783338
time/epoch (s)                     1.08102
time/total (s)                    49.0067
Epoch                             44
-----------------------------  --------------
2019-04-21 00:45:02.494995 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 45 finished
-----------------------------  --------------
replay_buffer/size              9400
trainer/QF1 Loss                   0.126083
trainer/QF2 Loss                   0.135801
trainer/Policy Loss               18.3903
trainer/Q1 Predictions Mean      -18.2131
trainer/Q1 Predictions Std         5.84821
trainer/Q1 Predictions Max       -16.5312
trainer/Q1 Predictions Min       -57.2889
trainer/Q2 Predictions Mean      -18.2005
trainer/Q2 Predictions Std         5.8556
trainer/Q2 Predictions Max       -16.4724
trainer/Q2 Predictions Min       -57.3488
trainer/Q Targets Mean           -18.4871
trainer/Q Targets Std              5.87821
trainer/Q Targets Max            -16.5646
trainer/Q Targets Min            -58.8563
trainer/Log Pis Mean               0.682029
trainer/Log Pis Std                1.11548
trainer/Log Pis Max                5.92775
trainer/Log Pis Min               -2.66206
trainer/Policy mu Mean             0.0642281
trainer/Policy mu Std              0.71184
trainer/Policy mu Max              2.61192
trainer/Policy mu Min             -2.27721
trainer/Policy log std Mean       -1.25981
trainer/Policy log std Std         0.184954
trainer/Policy log std Max        -0.610982
trainer/Policy log std Min        -1.57458
trainer/Alpha                      0.0864664
trainer/Alpha Loss                -3.22603
exploration/num steps total     9400
exploration/num paths total       94
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.68168
exploration/Rewards Std            1.55369
exploration/Rewards Max           -0.0198907
exploration/Rewards Min          -10.5671
exploration/Returns Mean         -68.168
exploration/Returns Std           13.6995
exploration/Returns Max          -54.4685
exploration/Returns Min          -81.8675
exploration/Actions Mean           0.0192363
exploration/Actions Std            0.394013
exploration/Actions Max            0.995151
exploration/Actions Min           -0.991191
exploration/Num Paths              2
exploration/Average Returns      -68.168
evaluation/num steps total     46000
evaluation/num paths total       460
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.16885
evaluation/Rewards Std             0.825084
evaluation/Rewards Max            -0.0180104
evaluation/Rewards Min            -9.81838
evaluation/Returns Mean          -16.885
evaluation/Returns Std            16.3379
evaluation/Returns Max            -3.2652
evaluation/Returns Min           -55.8107
evaluation/Actions Mean            0.0235838
evaluation/Actions Std             0.15855
evaluation/Actions Max             0.993852
evaluation/Actions Min            -0.960169
evaluation/Num Paths              10
evaluation/Average Returns       -16.885
time/data storing (s)              0.00148144
time/evaluation sampling (s)       0.222651
time/exploration sampling (s)      0.0710954
time/logging (s)                   0.00338305
time/saving (s)                    0.00195324
time/training (s)                  0.776783
time/epoch (s)                     1.07735
time/total (s)                    50.0881
Epoch                             45
-----------------------------  --------------
2019-04-21 00:45:03.585040 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 46 finished
-----------------------------  --------------
replay_buffer/size              9600
trainer/QF1 Loss                   5.62064
trainer/QF2 Loss                   5.64238
trainer/Policy Loss               20.6754
trainer/Q1 Predictions Mean      -21.0749
trainer/Q1 Predictions Std        12.98
trainer/Q1 Predictions Max       -16.5848
trainer/Q1 Predictions Min       -83.8851
trainer/Q2 Predictions Mean      -21.0705
trainer/Q2 Predictions Std        12.9878
trainer/Q2 Predictions Max       -16.5591
trainer/Q2 Predictions Min       -84.0631
trainer/Q Targets Mean           -20.8485
trainer/Q Targets Std             12.9298
trainer/Q Targets Max             -0.0980874
trainer/Q Targets Min            -79.5391
trainer/Log Pis Mean               0.716234
trainer/Log Pis Std                1.62236
trainer/Log Pis Max                7.28816
trainer/Log Pis Min               -3.1182
trainer/Policy mu Mean             0.124839
trainer/Policy mu Std              0.91142
trainer/Policy mu Max              3.148
trainer/Policy mu Min             -2.35861
trainer/Policy log std Mean       -1.26409
trainer/Policy log std Std         0.211913
trainer/Policy log std Max        -0.707709
trainer/Policy log std Min        -1.59686
trainer/Alpha                      0.0822375
trainer/Alpha Loss                -3.2067
exploration/num steps total     9600
exploration/num paths total       96
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.333926
exploration/Rewards Std            0.211555
exploration/Rewards Max           -0.0473252
exploration/Rewards Min           -2.112
exploration/Returns Mean         -33.3926
exploration/Returns Std            2.40582
exploration/Returns Max          -30.9868
exploration/Returns Min          -35.7985
exploration/Actions Mean           0.0132662
exploration/Actions Std            0.32927
exploration/Actions Max            0.977494
exploration/Actions Min           -0.747906
exploration/Num Paths              2
exploration/Average Returns      -33.3926
evaluation/num steps total     47000
evaluation/num paths total       470
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.225003
evaluation/Rewards Std             0.650808
evaluation/Rewards Max            -0.0958468
evaluation/Rewards Min            -7.16074
evaluation/Returns Mean          -22.5003
evaluation/Returns Std             9.13829
evaluation/Returns Max           -11.845
evaluation/Returns Min           -36.7387
evaluation/Actions Mean            0.00873713
evaluation/Actions Std             0.169179
evaluation/Actions Max             0.989841
evaluation/Actions Min            -0.989808
evaluation/Num Paths              10
evaluation/Average Returns       -22.5003
time/data storing (s)              0.00129944
time/evaluation sampling (s)       0.222467
time/exploration sampling (s)      0.0689653
time/logging (s)                   0.0033853
time/saving (s)                    0.00198909
time/training (s)                  0.786612
time/epoch (s)                     1.08472
time/total (s)                    51.1769
Epoch                             46
-----------------------------  --------------
2019-04-21 00:45:04.667657 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 47 finished
-----------------------------  --------------
replay_buffer/size              9800
trainer/QF1 Loss                   2.75664
trainer/QF2 Loss                   2.75763
trainer/Policy Loss               19.6747
trainer/Q1 Predictions Mean      -19.2516
trainer/Q1 Predictions Std         6.73808
trainer/Q1 Predictions Max       -16.7528
trainer/Q1 Predictions Min       -51.1983
trainer/Q2 Predictions Mean      -19.2653
trainer/Q2 Predictions Std         6.71265
trainer/Q2 Predictions Max       -16.7492
trainer/Q2 Predictions Min       -51.271
trainer/Q Targets Mean           -19.0971
trainer/Q Targets Std              7.14777
trainer/Q Targets Max             -1.48261
trainer/Q Targets Min            -52.3372
trainer/Log Pis Mean               1.09247
trainer/Log Pis Std                1.56951
trainer/Log Pis Max                7.08229
trainer/Log Pis Min               -3.877
trainer/Policy mu Mean             0.155206
trainer/Policy mu Std              0.853131
trainer/Policy mu Max              2.82201
trainer/Policy mu Min             -2.00133
trainer/Policy log std Mean       -1.39351
trainer/Policy log std Std         0.25124
trainer/Policy log std Max        -0.415475
trainer/Policy log std Min        -1.79464
trainer/Alpha                      0.0783861
trainer/Alpha Loss                -2.31045
exploration/num steps total     9800
exploration/num paths total       98
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.484902
exploration/Rewards Std            0.939098
exploration/Rewards Max           -0.0410892
exploration/Rewards Min           -6.6694
exploration/Returns Mean         -48.4902
exploration/Returns Std            2.02938
exploration/Returns Max          -46.4608
exploration/Returns Min          -50.5195
exploration/Actions Mean           0.0414375
exploration/Actions Std            0.340558
exploration/Actions Max            0.997429
exploration/Actions Min           -0.769044
exploration/Num Paths              2
exploration/Average Returns      -48.4902
evaluation/num steps total     48000
evaluation/num paths total       480
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.340664
evaluation/Rewards Std             1.08685
evaluation/Rewards Max            -0.0536326
evaluation/Rewards Min            -9.82281
evaluation/Returns Mean          -34.0664
evaluation/Returns Std            12.7966
evaluation/Returns Max           -20.2732
evaluation/Returns Min           -62.7861
evaluation/Actions Mean            0.0323978
evaluation/Actions Std             0.204739
evaluation/Actions Max             0.996214
evaluation/Actions Min            -0.991218
evaluation/Num Paths              10
evaluation/Average Returns       -34.0664
time/data storing (s)              0.00130481
time/evaluation sampling (s)       0.227797
time/exploration sampling (s)      0.0661145
time/logging (s)                   0.00334599
time/saving (s)                    0.00199055
time/training (s)                  0.776638
time/epoch (s)                     1.07719
time/total (s)                    52.2581
Epoch                             47
-----------------------------  --------------
2019-04-21 00:45:05.734178 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 48 finished
-----------------------------  --------------
replay_buffer/size             10000
trainer/QF1 Loss                   5.53578
trainer/QF2 Loss                   5.54169
trainer/Policy Loss               18.7887
trainer/Q1 Predictions Mean      -18.2325
trainer/Q1 Predictions Std         3.83109
trainer/Q1 Predictions Max       -16.761
trainer/Q1 Predictions Min       -42.0545
trainer/Q2 Predictions Mean      -18.2172
trainer/Q2 Predictions Std         3.84324
trainer/Q2 Predictions Max       -16.7338
trainer/Q2 Predictions Min       -41.7832
trainer/Q Targets Mean           -17.8852
trainer/Q Targets Std              4.6268
trainer/Q Targets Max             -0.244414
trainer/Q Targets Min            -42.2624
trainer/Log Pis Mean               1.08443
trainer/Log Pis Std                1.27568
trainer/Log Pis Max                6.73603
trainer/Log Pis Min               -1.35697
trainer/Policy mu Mean             0.0670217
trainer/Policy mu Std              0.802077
trainer/Policy mu Max              2.78742
trainer/Policy mu Min             -2.40822
trainer/Policy log std Mean       -1.35209
trainer/Policy log std Std         0.224268
trainer/Policy log std Max        -0.492349
trainer/Policy log std Min        -1.66503
trainer/Alpha                      0.0747541
trainer/Alpha Loss                -2.37436
exploration/num steps total    10000
exploration/num paths total      100
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.410527
exploration/Rewards Std            0.714774
exploration/Rewards Max           -0.0146486
exploration/Rewards Min           -5.42898
exploration/Returns Mean         -41.0527
exploration/Returns Std            2.44503
exploration/Returns Max          -38.6077
exploration/Returns Min          -43.4977
exploration/Actions Mean           0.0387496
exploration/Actions Std            0.348669
exploration/Actions Max            0.997767
exploration/Actions Min           -0.756856
exploration/Num Paths              2
exploration/Average Returns      -41.0527
evaluation/num steps total     49000
evaluation/num paths total       490
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.316386
evaluation/Rewards Std             1.20648
evaluation/Rewards Max            -0.0225224
evaluation/Rewards Min           -10.5182
evaluation/Returns Mean          -31.6386
evaluation/Returns Std            21.0437
evaluation/Returns Max            -7.34382
evaluation/Returns Min           -63.7419
evaluation/Actions Mean            0.0265574
evaluation/Actions Std             0.200869
evaluation/Actions Max             0.995619
evaluation/Actions Min            -0.983522
evaluation/Num Paths              10
evaluation/Average Returns       -31.6386
time/data storing (s)              0.00121917
time/evaluation sampling (s)       0.222733
time/exploration sampling (s)      0.0638713
time/logging (s)                   0.00356889
time/saving (s)                    0.0017763
time/training (s)                  0.768146
time/epoch (s)                     1.06131
time/total (s)                    53.3235
Epoch                             48
-----------------------------  --------------
2019-04-21 00:45:06.804562 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 49 finished
-----------------------------  --------------
replay_buffer/size             10200
trainer/QF1 Loss                   0.246903
trainer/QF2 Loss                   0.243949
trainer/Policy Loss               20.1006
trainer/Q1 Predictions Mean      -19.6147
trainer/Q1 Predictions Std        10.3491
trainer/Q1 Predictions Max       -16.5431
trainer/Q1 Predictions Min       -82.9992
trainer/Q2 Predictions Mean      -19.6067
trainer/Q2 Predictions Std        10.3307
trainer/Q2 Predictions Max       -16.4864
trainer/Q2 Predictions Min       -82.8118
trainer/Q Targets Mean           -19.7707
trainer/Q Targets Std             10.2331
trainer/Q Targets Max            -16.5751
trainer/Q Targets Min            -79.566
trainer/Log Pis Mean               1.02465
trainer/Log Pis Std                1.49447
trainer/Log Pis Max                8.06584
trainer/Log Pis Min               -2.02499
trainer/Policy mu Mean             0.146245
trainer/Policy mu Std              0.844295
trainer/Policy mu Max              3.0935
trainer/Policy mu Min             -2.03709
trainer/Policy log std Mean       -1.3825
trainer/Policy log std Std         0.247487
trainer/Policy log std Max        -0.525835
trainer/Policy log std Min        -1.71821
trainer/Alpha                      0.0713422
trainer/Alpha Loss                -2.57499
exploration/num steps total    10200
exploration/num paths total      102
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.475908
exploration/Rewards Std            0.999808
exploration/Rewards Max           -0.0154043
exploration/Rewards Min           -7.30377
exploration/Returns Mean         -47.5908
exploration/Returns Std            7.05866
exploration/Returns Max          -40.5321
exploration/Returns Min          -54.6495
exploration/Actions Mean           0.0432059
exploration/Actions Std            0.344616
exploration/Actions Max            0.996601
exploration/Actions Min           -0.835767
exploration/Num Paths              2
exploration/Average Returns      -47.5908
evaluation/num steps total     50000
evaluation/num paths total       500
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.198934
evaluation/Rewards Std             0.941841
evaluation/Rewards Max            -0.0103398
evaluation/Rewards Min            -9.62757
evaluation/Returns Mean          -19.8934
evaluation/Returns Std            16.7957
evaluation/Returns Max            -2.49483
evaluation/Returns Min           -53.5701
evaluation/Actions Mean            0.0258041
evaluation/Actions Std             0.17825
evaluation/Actions Max             0.995657
evaluation/Actions Min            -0.98662
evaluation/Num Paths              10
evaluation/Average Returns       -19.8934
time/data storing (s)              0.00124469
time/evaluation sampling (s)       0.23014
time/exploration sampling (s)      0.0661384
time/logging (s)                   0.00337378
time/saving (s)                    0.00193721
time/training (s)                  0.761874
time/epoch (s)                     1.06471
time/total (s)                    54.3924
Epoch                             49
-----------------------------  --------------
2019-04-21 00:45:07.889183 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 50 finished
-----------------------------  --------------
replay_buffer/size             10400
trainer/QF1 Loss                   0.229873
trainer/QF2 Loss                   0.21309
trainer/Policy Loss               18.4536
trainer/Q1 Predictions Mean      -17.8418
trainer/Q1 Predictions Std         3.87131
trainer/Q1 Predictions Max       -16.5243
trainer/Q1 Predictions Min       -41.8864
trainer/Q2 Predictions Mean      -17.8243
trainer/Q2 Predictions Std         3.84068
trainer/Q2 Predictions Max       -16.474
trainer/Q2 Predictions Min       -41.6271
trainer/Q Targets Mean           -17.9991
trainer/Q Targets Std              3.86543
trainer/Q Targets Max            -16.4858
trainer/Q Targets Min            -40.967
trainer/Log Pis Mean               1.07424
trainer/Log Pis Std                1.51378
trainer/Log Pis Max                7.53176
trainer/Log Pis Min               -4.85882
trainer/Policy mu Mean             0.0294197
trainer/Policy mu Std              0.735762
trainer/Policy mu Max              3.10356
trainer/Policy mu Min             -2.91669
trainer/Policy log std Mean       -1.46002
trainer/Policy log std Std         0.234366
trainer/Policy log std Max        -0.229522
trainer/Policy log std Min        -1.77786
trainer/Alpha                      0.0682029
trainer/Alpha Loss                -2.4857
exploration/num steps total    10400
exploration/num paths total      104
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.276255
exploration/Rewards Std            0.235329
exploration/Rewards Max           -0.00801282
exploration/Rewards Min           -2.2314
exploration/Returns Mean         -27.6255
exploration/Returns Std            0.380173
exploration/Returns Max          -27.2453
exploration/Returns Min          -28.0057
exploration/Actions Mean          -0.00326937
exploration/Actions Std            0.31847
exploration/Actions Max            0.980105
exploration/Actions Min           -0.992464
exploration/Num Paths              2
exploration/Average Returns      -27.6255
evaluation/num steps total     51000
evaluation/num paths total       510
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.277922
evaluation/Rewards Std             1.05083
evaluation/Rewards Max            -0.0382439
evaluation/Rewards Min           -11.3493
evaluation/Returns Mean          -27.7922
evaluation/Returns Std            16.0664
evaluation/Returns Max            -9.00326
evaluation/Returns Min           -66.1209
evaluation/Actions Mean            0.0217329
evaluation/Actions Std             0.202279
evaluation/Actions Max             0.996569
evaluation/Actions Min            -0.992037
evaluation/Num Paths              10
evaluation/Average Returns       -27.7922
time/data storing (s)              0.00139261
time/evaluation sampling (s)       0.225611
time/exploration sampling (s)      0.0656038
time/logging (s)                   0.00251655
time/saving (s)                    0.00195026
time/training (s)                  0.78179
time/epoch (s)                     1.07886
time/total (s)                    55.4746
Epoch                             50
-----------------------------  --------------
2019-04-21 00:45:08.951778 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 51 finished
-----------------------------  --------------
replay_buffer/size             10600
trainer/QF1 Loss                   2.78079
trainer/QF2 Loss                   2.80217
trainer/Policy Loss               20.7998
trainer/Q1 Predictions Mean      -20.2337
trainer/Q1 Predictions Std        10.0575
trainer/Q1 Predictions Max       -16.4495
trainer/Q1 Predictions Min       -80.6112
trainer/Q2 Predictions Mean      -20.1905
trainer/Q2 Predictions Std        10.0448
trainer/Q2 Predictions Max       -16.3879
trainer/Q2 Predictions Min       -80.4409
trainer/Q Targets Mean           -20.2698
trainer/Q Targets Std             10.2141
trainer/Q Targets Max             -0.598408
trainer/Q Targets Min            -80.9702
trainer/Log Pis Mean               1.31633
trainer/Log Pis Std                1.83351
trainer/Log Pis Max                7.71033
trainer/Log Pis Min               -4.58893
trainer/Policy mu Mean             0.1388
trainer/Policy mu Std              0.996177
trainer/Policy mu Max              3.08313
trainer/Policy mu Min             -2.86429
trainer/Policy log std Mean       -1.45298
trainer/Policy log std Std         0.315882
trainer/Policy log std Max        -0.429794
trainer/Policy log std Min        -1.86992
trainer/Alpha                      0.0652518
trainer/Alpha Loss                -1.86592
exploration/num steps total    10600
exploration/num paths total      106
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.414111
exploration/Rewards Std            0.830666
exploration/Rewards Max           -0.00909898
exploration/Rewards Min           -5.14551
exploration/Returns Mean         -41.4111
exploration/Returns Std           17.2184
exploration/Returns Max          -24.1927
exploration/Returns Min          -58.6295
exploration/Actions Mean           0.0222569
exploration/Actions Std            0.321234
exploration/Actions Max            0.999073
exploration/Actions Min           -0.995336
exploration/Num Paths              2
exploration/Average Returns      -41.4111
evaluation/num steps total     52000
evaluation/num paths total       520
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.198502
evaluation/Rewards Std             0.921252
evaluation/Rewards Max            -0.00125875
evaluation/Rewards Min            -9.27526
evaluation/Returns Mean          -19.8502
evaluation/Returns Std            13.3398
evaluation/Returns Max            -3.65058
evaluation/Returns Min           -48.2169
evaluation/Actions Mean            0.0353042
evaluation/Actions Std             0.188985
evaluation/Actions Max             0.995064
evaluation/Actions Min            -0.939295
evaluation/Num Paths              10
evaluation/Average Returns       -19.8502
time/data storing (s)              0.00162516
time/evaluation sampling (s)       0.224519
time/exploration sampling (s)      0.0655409
time/logging (s)                   0.00336404
time/saving (s)                    0.00205697
time/training (s)                  0.761028
time/epoch (s)                     1.05813
time/total (s)                    56.5367
Epoch                             51
-----------------------------  --------------
2019-04-21 00:45:10.040823 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 52 finished
-----------------------------  ---------------
replay_buffer/size             10800
trainer/QF1 Loss                   5.4273
trainer/QF2 Loss                   5.4571
trainer/Policy Loss               19.3042
trainer/Q1 Predictions Mean      -18.7003
trainer/Q1 Predictions Std         8.7385
trainer/Q1 Predictions Max       -16.4747
trainer/Q1 Predictions Min       -85.4901
trainer/Q2 Predictions Mean      -18.7312
trainer/Q2 Predictions Std         8.75254
trainer/Q2 Predictions Max       -16.4397
trainer/Q2 Predictions Min       -85.693
trainer/Q Targets Mean           -18.489
trainer/Q Targets Std              8.85512
trainer/Q Targets Max             -0.182785
trainer/Q Targets Min            -82.4699
trainer/Log Pis Mean               1.19499
trainer/Log Pis Std                1.30986
trainer/Log Pis Max                5.66222
trainer/Log Pis Min               -2.69011
trainer/Policy mu Mean             0.0588343
trainer/Policy mu Std              0.788539
trainer/Policy mu Max              3.04879
trainer/Policy mu Min             -2.04935
trainer/Policy log std Mean       -1.52477
trainer/Policy log std Std         0.261443
trainer/Policy log std Max        -0.578151
trainer/Policy log std Min        -1.85773
trainer/Alpha                      0.0624828
trainer/Alpha Loss                -2.232
exploration/num steps total    10800
exploration/num paths total      108
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.270608
exploration/Rewards Std            0.375353
exploration/Rewards Max           -0.00784999
exploration/Rewards Min           -4.04736
exploration/Returns Mean         -27.0608
exploration/Returns Std            4.82094
exploration/Returns Max          -22.2399
exploration/Returns Min          -31.8818
exploration/Actions Mean           0.00260099
exploration/Actions Std            0.291175
exploration/Actions Max            0.991345
exploration/Actions Min           -0.978675
exploration/Num Paths              2
exploration/Average Returns      -27.0608
evaluation/num steps total     53000
evaluation/num paths total       530
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.658531
evaluation/Rewards Std             1.53693
evaluation/Rewards Max            -0.0377021
evaluation/Rewards Min            -9.75827
evaluation/Returns Mean          -65.8531
evaluation/Returns Std           121.73
evaluation/Returns Max            -5.41982
evaluation/Returns Min          -428.788
evaluation/Actions Mean           -0.000912159
evaluation/Actions Std             0.298999
evaluation/Actions Max             0.99555
evaluation/Actions Min            -0.992458
evaluation/Num Paths              10
evaluation/Average Returns       -65.8531
time/data storing (s)              0.00123386
time/evaluation sampling (s)       0.22135
time/exploration sampling (s)      0.0681842
time/logging (s)                   0.00250368
time/saving (s)                    0.00156599
time/training (s)                  0.787925
time/epoch (s)                     1.08276
time/total (s)                    57.6235
Epoch                             52
-----------------------------  ---------------
2019-04-21 00:45:11.117010 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 53 finished
-----------------------------  --------------
replay_buffer/size             11000
trainer/QF1 Loss                   5.25955
trainer/QF2 Loss                   5.30606
trainer/Policy Loss               19.5137
trainer/Q1 Predictions Mean      -18.5762
trainer/Q1 Predictions Std         7.24893
trainer/Q1 Predictions Max       -16.2654
trainer/Q1 Predictions Min       -65.1275
trainer/Q2 Predictions Mean      -18.5842
trainer/Q2 Predictions Std         7.25385
trainer/Q2 Predictions Max       -16.2629
trainer/Q2 Predictions Min       -64.9861
trainer/Q Targets Mean           -18.435
trainer/Q Targets Std              7.68923
trainer/Q Targets Max             -0.252152
trainer/Q Targets Min            -65.8209
trainer/Log Pis Mean               1.30756
trainer/Log Pis Std                1.71296
trainer/Log Pis Max                8.44196
trainer/Log Pis Min               -3.88516
trainer/Policy mu Mean             0.108927
trainer/Policy mu Std              0.83757
trainer/Policy mu Max              3.12993
trainer/Policy mu Min             -1.84866
trainer/Policy log std Mean       -1.54102
trainer/Policy log std Std         0.294829
trainer/Policy log std Max        -0.250822
trainer/Policy log std Min        -1.87813
trainer/Alpha                      0.0600981
trainer/Alpha Loss                -1.94684
exploration/num steps total    11000
exploration/num paths total      110
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.241187
exploration/Rewards Std            0.153934
exploration/Rewards Max           -0.00644719
exploration/Rewards Min           -1.56679
exploration/Returns Mean         -24.1187
exploration/Returns Std            0.657569
exploration/Returns Max          -23.4611
exploration/Returns Min          -24.7763
exploration/Actions Mean           0.00590438
exploration/Actions Std            0.269201
exploration/Actions Max            0.964741
exploration/Actions Min           -0.842657
exploration/Num Paths              2
exploration/Average Returns      -24.1187
evaluation/num steps total     54000
evaluation/num paths total       540
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.296826
evaluation/Rewards Std             1.11708
evaluation/Rewards Max            -0.0598306
evaluation/Rewards Min           -10.9162
evaluation/Returns Mean          -29.6826
evaluation/Returns Std            17.6935
evaluation/Returns Max            -7.14344
evaluation/Returns Min           -61.6708
evaluation/Actions Mean            0.0309825
evaluation/Actions Std             0.204835
evaluation/Actions Max             0.997975
evaluation/Actions Min            -0.99158
evaluation/Num Paths              10
evaluation/Average Returns       -29.6826
time/data storing (s)              0.00136163
time/evaluation sampling (s)       0.224594
time/exploration sampling (s)      0.0651573
time/logging (s)                   0.00310063
time/saving (s)                    0.00154113
time/training (s)                  0.775744
time/epoch (s)                     1.0715
time/total (s)                    58.6989
Epoch                             53
-----------------------------  --------------
2019-04-21 00:45:12.204667 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 54 finished
-----------------------------  --------------
replay_buffer/size             11200
trainer/QF1 Loss                   2.75748
trainer/QF2 Loss                   2.73924
trainer/Policy Loss               20.1739
trainer/Q1 Predictions Mean      -19.3348
trainer/Q1 Predictions Std         8.47808
trainer/Q1 Predictions Max       -16.3129
trainer/Q1 Predictions Min       -79.0089
trainer/Q2 Predictions Mean      -19.3005
trainer/Q2 Predictions Std         8.49041
trainer/Q2 Predictions Max       -16.265
trainer/Q2 Predictions Min       -78.9595
trainer/Q Targets Mean           -19.2822
trainer/Q Targets Std              8.75816
trainer/Q Targets Max             -0.95713
trainer/Q Targets Min            -80.2388
trainer/Log Pis Mean               1.4634
trainer/Log Pis Std                1.53591
trainer/Log Pis Max                6.14701
trainer/Log Pis Min               -2.67741
trainer/Policy mu Mean             0.164041
trainer/Policy mu Std              0.976007
trainer/Policy mu Max              3.15055
trainer/Policy mu Min             -2.85865
trainer/Policy log std Mean       -1.5041
trainer/Policy log std Std         0.356489
trainer/Policy log std Max        -0.411696
trainer/Policy log std Min        -1.92635
trainer/Alpha                      0.057746
trainer/Alpha Loss                -1.53011
exploration/num steps total    11200
exploration/num paths total      112
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.243045
exploration/Rewards Std            0.247921
exploration/Rewards Max           -0.0131361
exploration/Rewards Min           -2.98475
exploration/Returns Mean         -24.3045
exploration/Returns Std            3.25796
exploration/Returns Max          -21.0465
exploration/Returns Min          -27.5625
exploration/Actions Mean          -0.00263461
exploration/Actions Std            0.270719
exploration/Actions Max            0.981463
exploration/Actions Min           -0.984228
exploration/Num Paths              2
exploration/Average Returns      -24.3045
evaluation/num steps total     55000
evaluation/num paths total       550
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.759524
evaluation/Rewards Std             1.82962
evaluation/Rewards Max            -0.0170863
evaluation/Rewards Min            -8.24897
evaluation/Returns Mean          -75.9524
evaluation/Returns Std           169.006
evaluation/Returns Max            -6.44595
evaluation/Returns Min          -582.219
evaluation/Actions Mean            0.102648
evaluation/Actions Std             0.307424
evaluation/Actions Max             0.997466
evaluation/Actions Min            -0.992413
evaluation/Num Paths              10
evaluation/Average Returns       -75.9524
time/data storing (s)              0.00124542
time/evaluation sampling (s)       0.232756
time/exploration sampling (s)      0.0693318
time/logging (s)                   0.00340958
time/saving (s)                    0.00184845
time/training (s)                  0.77496
time/epoch (s)                     1.08355
time/total (s)                    59.7856
Epoch                             54
-----------------------------  --------------
2019-04-21 00:45:13.283951 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 55 finished
-----------------------------  --------------
replay_buffer/size             11400
trainer/QF1 Loss                  12.55
trainer/QF2 Loss                  12.4853
trainer/Policy Loss               19.8517
trainer/Q1 Predictions Mean      -18.9176
trainer/Q1 Predictions Std         7.04517
trainer/Q1 Predictions Max       -16.2309
trainer/Q1 Predictions Min       -58.2742
trainer/Q2 Predictions Mean      -18.887
trainer/Q2 Predictions Std         7.02282
trainer/Q2 Predictions Max       -16.1537
trainer/Q2 Predictions Min       -57.8661
trainer/Q Targets Mean           -18.2638
trainer/Q Targets Std              7.69457
trainer/Q Targets Max             -0.253206
trainer/Q Targets Min            -57.862
trainer/Log Pis Mean               1.34423
trainer/Log Pis Std                1.54629
trainer/Log Pis Max                7.38203
trainer/Log Pis Min               -2.72352
trainer/Policy mu Mean             0.138506
trainer/Policy mu Std              0.896132
trainer/Policy mu Max              3.05646
trainer/Policy mu Min             -2.62962
trainer/Policy log std Mean       -1.54035
trainer/Policy log std Std         0.33467
trainer/Policy log std Max        -0.344027
trainer/Policy log std Min        -1.87556
trainer/Alpha                      0.0555648
trainer/Alpha Loss                -1.89518
exploration/num steps total    11400
exploration/num paths total      114
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.343548
exploration/Rewards Std            0.744013
exploration/Rewards Max           -0.0426498
exploration/Rewards Min           -7.05549
exploration/Returns Mean         -34.3548
exploration/Returns Std           11.9392
exploration/Returns Max          -22.4157
exploration/Returns Min          -46.294
exploration/Actions Mean           0.020678
exploration/Actions Std            0.293814
exploration/Actions Max            0.993474
exploration/Actions Min           -0.961352
exploration/Num Paths              2
exploration/Average Returns      -34.3548
evaluation/num steps total     56000
evaluation/num paths total       560
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.330264
evaluation/Rewards Std             1.15129
evaluation/Rewards Max            -0.0669464
evaluation/Rewards Min           -10.2055
evaluation/Returns Mean          -33.0264
evaluation/Returns Std            18.5538
evaluation/Returns Max            -8.9762
evaluation/Returns Min           -62.8757
evaluation/Actions Mean            0.0296353
evaluation/Actions Std             0.200187
evaluation/Actions Max             0.996835
evaluation/Actions Min            -0.989263
evaluation/Num Paths              10
evaluation/Average Returns       -33.0264
time/data storing (s)              0.00120429
time/evaluation sampling (s)       0.233677
time/exploration sampling (s)      0.0662947
time/logging (s)                   0.00358366
time/saving (s)                    0.00196508
time/training (s)                  0.767602
time/epoch (s)                     1.07433
time/total (s)                    60.8639
Epoch                             55
-----------------------------  --------------
2019-04-21 00:45:14.357603 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 56 finished
-----------------------------  --------------
replay_buffer/size             11600
trainer/QF1 Loss                   0.0708211
trainer/QF2 Loss                   0.0829027
trainer/Policy Loss               19.1961
trainer/Q1 Predictions Mean      -18.2936
trainer/Q1 Predictions Std         7.01362
trainer/Q1 Predictions Max       -15.9911
trainer/Q1 Predictions Min       -71.8188
trainer/Q2 Predictions Mean      -18.2723
trainer/Q2 Predictions Std         7.03865
trainer/Q2 Predictions Max       -15.9581
trainer/Q2 Predictions Min       -72.1254
trainer/Q Targets Mean           -18.4966
trainer/Q Targets Std              7.01129
trainer/Q Targets Max            -16.0652
trainer/Q Targets Min            -72.0793
trainer/Log Pis Mean               1.53522
trainer/Log Pis Std                1.50909
trainer/Log Pis Max                6.9141
trainer/Log Pis Min               -2.22281
trainer/Policy mu Mean             0.129931
trainer/Policy mu Std              0.849313
trainer/Policy mu Max              3.31041
trainer/Policy mu Min             -2.54039
trainer/Policy log std Mean       -1.71575
trainer/Policy log std Std         0.328681
trainer/Policy log std Max        -0.59211
trainer/Policy log std Min        -2.06663
trainer/Alpha                      0.0535175
trainer/Alpha Loss                -1.3607
exploration/num steps total    11600
exploration/num paths total      116
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.483998
exploration/Rewards Std            1.2937
exploration/Rewards Max           -0.0050544
exploration/Rewards Min           -9.21214
exploration/Returns Mean         -48.3998
exploration/Returns Std           11.0743
exploration/Returns Max          -37.3255
exploration/Returns Min          -59.4741
exploration/Actions Mean           0.039876
exploration/Actions Std            0.303023
exploration/Actions Max            0.999187
exploration/Actions Min           -0.990962
exploration/Num Paths              2
exploration/Average Returns      -48.3998
evaluation/num steps total     57000
evaluation/num paths total       570
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.275697
evaluation/Rewards Std             1.03428
evaluation/Rewards Max            -0.0374038
evaluation/Rewards Min            -9.68172
evaluation/Returns Mean          -27.5697
evaluation/Returns Std            15.3165
evaluation/Returns Max            -7.58936
evaluation/Returns Min           -52.4202
evaluation/Actions Mean            0.0215894
evaluation/Actions Std             0.20096
evaluation/Actions Max             0.99638
evaluation/Actions Min            -0.99568
evaluation/Num Paths              10
evaluation/Average Returns       -27.5697
time/data storing (s)              0.00119914
time/evaluation sampling (s)       0.22946
time/exploration sampling (s)      0.0667342
time/logging (s)                   0.00359168
time/saving (s)                    0.00197615
time/training (s)                  0.765118
time/epoch (s)                     1.06808
time/total (s)                    61.9361
Epoch                             56
-----------------------------  --------------
2019-04-21 00:45:15.437463 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 57 finished
-----------------------------  --------------
replay_buffer/size             11800
trainer/QF1 Loss                   2.58687
trainer/QF2 Loss                   2.59543
trainer/Policy Loss               18.607
trainer/Q1 Predictions Mean      -17.5
trainer/Q1 Predictions Std         5.04875
trainer/Q1 Predictions Max       -16.0368
trainer/Q1 Predictions Min       -55.7314
trainer/Q2 Predictions Mean      -17.5134
trainer/Q2 Predictions Std         5.01878
trainer/Q2 Predictions Max       -16.0598
trainer/Q2 Predictions Min       -55.339
trainer/Q Targets Mean           -17.4847
trainer/Q Targets Std              5.37628
trainer/Q Targets Max             -0.169179
trainer/Q Targets Min            -56.2843
trainer/Log Pis Mean               1.63404
trainer/Log Pis Std                1.31115
trainer/Log Pis Max                7.95893
trainer/Log Pis Min               -2.86752
trainer/Policy mu Mean            -0.0890445
trainer/Policy mu Std              0.746139
trainer/Policy mu Max              2.91795
trainer/Policy mu Min             -2.9758
trainer/Policy log std Mean       -1.73875
trainer/Policy log std Std         0.293432
trainer/Policy log std Max        -0.539723
trainer/Policy log std Min        -2.01841
trainer/Alpha                      0.051912
trainer/Alpha Loss                -1.08252
exploration/num steps total    11800
exploration/num paths total      118
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.490287
exploration/Rewards Std            1.27204
exploration/Rewards Max           -0.00913081
exploration/Rewards Min           -9.41933
exploration/Returns Mean         -49.0287
exploration/Returns Std           17.214
exploration/Returns Max          -31.8147
exploration/Returns Min          -66.2427
exploration/Actions Mean           0.0362575
exploration/Actions Std            0.287471
exploration/Actions Max            0.999478
exploration/Actions Min           -0.95261
exploration/Num Paths              2
exploration/Average Returns      -49.0287
evaluation/num steps total     58000
evaluation/num paths total       580
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.298936
evaluation/Rewards Std             0.997171
evaluation/Rewards Max            -0.0925012
evaluation/Rewards Min            -9.10486
evaluation/Returns Mean          -29.8936
evaluation/Returns Std            12.2791
evaluation/Returns Max           -10.2438
evaluation/Returns Min           -49.5271
evaluation/Actions Mean            0.028021
evaluation/Actions Std             0.208639
evaluation/Actions Max             0.996129
evaluation/Actions Min            -0.995754
evaluation/Num Paths              10
evaluation/Average Returns       -29.8936
time/data storing (s)              0.00145675
time/evaluation sampling (s)       0.220519
time/exploration sampling (s)      0.0630857
time/logging (s)                   0.00334794
time/saving (s)                    0.00201738
time/training (s)                  0.783591
time/epoch (s)                     1.07402
time/total (s)                    63.0143
Epoch                             57
-----------------------------  --------------
2019-04-21 00:45:16.511084 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 58 finished
-----------------------------  --------------
replay_buffer/size             12000
trainer/QF1 Loss                   0.150071
trainer/QF2 Loss                   0.131611
trainer/Policy Loss               21.232
trainer/Q1 Predictions Mean      -20.3548
trainer/Q1 Predictions Std        13.0719
trainer/Q1 Predictions Max       -15.9085
trainer/Q1 Predictions Min       -80.8694
trainer/Q2 Predictions Mean      -20.3559
trainer/Q2 Predictions Std        13.0232
trainer/Q2 Predictions Max       -15.9319
trainer/Q2 Predictions Min       -80.7842
trainer/Q Targets Mean           -20.4393
trainer/Q Targets Std             13.0235
trainer/Q Targets Max            -15.8877
trainer/Q Targets Min            -80.7222
trainer/Log Pis Mean               1.9644
trainer/Log Pis Std                1.81979
trainer/Log Pis Max                8.18021
trainer/Log Pis Min               -3.86986
trainer/Policy mu Mean             0.185693
trainer/Policy mu Std              0.990561
trainer/Policy mu Max              3.48404
trainer/Policy mu Min             -2.82729
trainer/Policy log std Mean       -1.72608
trainer/Policy log std Std         0.398072
trainer/Policy log std Max        -0.20879
trainer/Policy log std Min        -2.02925
trainer/Alpha                      0.0504144
trainer/Alpha Loss                -0.106355
exploration/num steps total    12000
exploration/num paths total      120
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.410695
exploration/Rewards Std            1.22068
exploration/Rewards Max           -0.00182154
exploration/Rewards Min           -9.60487
exploration/Returns Mean         -41.0695
exploration/Returns Std           23.3555
exploration/Returns Max          -17.714
exploration/Returns Min          -64.4249
exploration/Actions Mean           0.0209627
exploration/Actions Std            0.260886
exploration/Actions Max            0.997585
exploration/Actions Min           -0.970058
exploration/Num Paths              2
exploration/Average Returns      -41.0695
evaluation/num steps total     59000
evaluation/num paths total       590
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.199961
evaluation/Rewards Std             0.86478
evaluation/Rewards Max            -0.0163738
evaluation/Rewards Min           -10.7037
evaluation/Returns Mean          -19.9961
evaluation/Returns Std            16.3349
evaluation/Returns Max            -6.05329
evaluation/Returns Min           -57.4513
evaluation/Actions Mean            0.0210096
evaluation/Actions Std             0.173067
evaluation/Actions Max             0.99864
evaluation/Actions Min            -0.992084
evaluation/Num Paths              10
evaluation/Average Returns       -19.9961
time/data storing (s)              0.00130474
time/evaluation sampling (s)       0.228353
time/exploration sampling (s)      0.0694024
time/logging (s)                   0.00334812
time/saving (s)                    0.0019404
time/training (s)                  0.763737
time/epoch (s)                     1.06809
time/total (s)                    64.0864
Epoch                             58
-----------------------------  --------------
2019-04-21 00:45:17.623719 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 59 finished
-----------------------------  --------------
replay_buffer/size             12200
trainer/QF1 Loss                   4.95241
trainer/QF2 Loss                   4.94756
trainer/Policy Loss               18.4611
trainer/Q1 Predictions Mean      -17.5968
trainer/Q1 Predictions Std         6.01608
trainer/Q1 Predictions Max       -15.8796
trainer/Q1 Predictions Min       -61.4813
trainer/Q2 Predictions Mean      -17.5885
trainer/Q2 Predictions Std         6.00335
trainer/Q2 Predictions Max       -15.876
trainer/Q2 Predictions Min       -61.529
trainer/Q Targets Mean           -17.3405
trainer/Q Targets Std              6.43651
trainer/Q Targets Max             -0.708425
trainer/Q Targets Min            -61.7271
trainer/Log Pis Mean               1.32501
trainer/Log Pis Std                1.71246
trainer/Log Pis Max                7.69706
trainer/Log Pis Min               -4.84793
trainer/Policy mu Mean             0.0226772
trainer/Policy mu Std              0.749464
trainer/Policy mu Max              3.15099
trainer/Policy mu Min             -3.11576
trainer/Policy log std Mean       -1.76895
trainer/Policy log std Std         0.313142
trainer/Policy log std Max        -0.368174
trainer/Policy log std Min        -2.01285
trainer/Alpha                      0.0490625
trainer/Alpha Loss                -2.03474
exploration/num steps total    12200
exploration/num paths total      122
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.368059
exploration/Rewards Std            1.06866
exploration/Rewards Max           -0.00423049
exploration/Rewards Min           -8.98922
exploration/Returns Mean         -36.8059
exploration/Returns Std           18.3496
exploration/Returns Max          -18.4563
exploration/Returns Min          -55.1556
exploration/Actions Mean           0.0377054
exploration/Actions Std            0.264518
exploration/Actions Max            0.99902
exploration/Actions Min           -0.639136
exploration/Num Paths              2
exploration/Average Returns      -36.8059
evaluation/num steps total     60000
evaluation/num paths total       600
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.687919
evaluation/Rewards Std             1.68491
evaluation/Rewards Max            -0.0412126
evaluation/Rewards Min            -8.14302
evaluation/Returns Mean          -68.7919
evaluation/Returns Std           153.193
evaluation/Returns Max            -4.86914
evaluation/Returns Min          -527.106
evaluation/Actions Mean            0.10089
evaluation/Actions Std             0.288649
evaluation/Actions Max             0.997559
evaluation/Actions Min            -0.953135
evaluation/Num Paths              10
evaluation/Average Returns       -68.7919
time/data storing (s)              0.00183341
time/evaluation sampling (s)       0.228505
time/exploration sampling (s)      0.0695077
time/logging (s)                   0.00333375
time/saving (s)                    0.0102292
time/training (s)                  0.793629
time/epoch (s)                     1.10704
time/total (s)                    65.1975
Epoch                             59
-----------------------------  --------------
2019-04-21 00:45:18.708058 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 60 finished
-----------------------------  --------------
replay_buffer/size             12400
trainer/QF1 Loss                   5.15632
trainer/QF2 Loss                   5.15984
trainer/Policy Loss               19.5405
trainer/Q1 Predictions Mean      -18.1879
trainer/Q1 Predictions Std         8.20674
trainer/Q1 Predictions Max       -15.8343
trainer/Q1 Predictions Min       -72.9377
trainer/Q2 Predictions Mean      -18.1858
trainer/Q2 Predictions Std         8.21716
trainer/Q2 Predictions Max       -15.7962
trainer/Q2 Predictions Min       -72.7749
trainer/Q Targets Mean           -17.9615
trainer/Q Targets Std              8.89821
trainer/Q Targets Max             -0.120241
trainer/Q Targets Min            -75.8962
trainer/Log Pis Mean               1.87718
trainer/Log Pis Std                1.61316
trainer/Log Pis Max                8.82065
trainer/Log Pis Min               -1.57493
trainer/Policy mu Mean             0.20964
trainer/Policy mu Std              0.86916
trainer/Policy mu Max              3.26754
trainer/Policy mu Min             -2.75148
trainer/Policy log std Mean       -1.78641
trainer/Policy log std Std         0.370058
trainer/Policy log std Max        -0.520089
trainer/Policy log std Min        -2.04869
trainer/Alpha                      0.0475417
trainer/Alpha Loss                -0.374103
exploration/num steps total    12400
exploration/num paths total      124
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.189918
exploration/Rewards Std            0.268236
exploration/Rewards Max           -0.00768154
exploration/Rewards Min           -3.10181
exploration/Returns Mean         -18.9918
exploration/Returns Std            2.12954
exploration/Returns Max          -16.8623
exploration/Returns Min          -21.1213
exploration/Actions Mean           0.0175813
exploration/Actions Std            0.216571
exploration/Actions Max            0.988471
exploration/Actions Min           -0.555721
exploration/Num Paths              2
exploration/Average Returns      -18.9918
evaluation/num steps total     61000
evaluation/num paths total       610
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.742221
evaluation/Rewards Std             1.8003
evaluation/Rewards Max            -0.0103027
evaluation/Rewards Min           -10.0972
evaluation/Returns Mean          -74.2221
evaluation/Returns Std           146.691
evaluation/Returns Max            -5.61023
evaluation/Returns Min          -511.379
evaluation/Actions Mean            0.108073
evaluation/Actions Std             0.310977
evaluation/Actions Max             0.998223
evaluation/Actions Min            -0.989149
evaluation/Num Paths              10
evaluation/Average Returns       -74.2221
time/data storing (s)              0.00130107
time/evaluation sampling (s)       0.230375
time/exploration sampling (s)      0.0685877
time/logging (s)                   0.00251906
time/saving (s)                    0.00196653
time/training (s)                  0.772779
time/epoch (s)                     1.07753
time/total (s)                    66.2792
Epoch                             60
-----------------------------  --------------
2019-04-21 00:45:19.793716 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 61 finished
-----------------------------  --------------
replay_buffer/size             12600
trainer/QF1 Loss                   0.0586777
trainer/QF2 Loss                   0.072779
trainer/Policy Loss               18.8188
trainer/Q1 Predictions Mean      -17.6481
trainer/Q1 Predictions Std         7.50482
trainer/Q1 Predictions Max       -15.7011
trainer/Q1 Predictions Min       -61.6076
trainer/Q2 Predictions Mean      -17.6499
trainer/Q2 Predictions Std         7.49132
trainer/Q2 Predictions Max       -15.712
trainer/Q2 Predictions Min       -61.3379
trainer/Q Targets Mean           -17.7149
trainer/Q Targets Std              7.47335
trainer/Q Targets Max            -15.6191
trainer/Q Targets Min            -61.5566
trainer/Log Pis Mean               1.60533
trainer/Log Pis Std                1.44174
trainer/Log Pis Max                6.49876
trainer/Log Pis Min               -5.22804
trainer/Policy mu Mean             0.0919031
trainer/Policy mu Std              0.745609
trainer/Policy mu Max              3.16377
trainer/Policy mu Min             -2.4176
trainer/Policy log std Mean       -1.84512
trainer/Policy log std Std         0.332254
trainer/Policy log std Max        -0.522651
trainer/Policy log std Min        -2.10399
trainer/Alpha                      0.0462236
trainer/Alpha Loss                -1.21329
exploration/num steps total    12600
exploration/num paths total      126
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.279028
exploration/Rewards Std            0.616889
exploration/Rewards Max           -0.0305591
exploration/Rewards Min           -5.11373
exploration/Returns Mean         -27.9028
exploration/Returns Std            0.983379
exploration/Returns Max          -26.9195
exploration/Returns Min          -28.8862
exploration/Actions Mean           0.0131013
exploration/Actions Std            0.256894
exploration/Actions Max            0.991792
exploration/Actions Min           -0.998864
exploration/Num Paths              2
exploration/Average Returns      -27.9028
evaluation/num steps total     62000
evaluation/num paths total       620
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.197122
evaluation/Rewards Std             0.792047
evaluation/Rewards Max            -0.0268588
evaluation/Rewards Min            -8.26079
evaluation/Returns Mean          -19.7122
evaluation/Returns Std             8.45569
evaluation/Returns Max           -10.8692
evaluation/Returns Min           -35.3611
evaluation/Actions Mean            0.0135885
evaluation/Actions Std             0.191818
evaluation/Actions Max             0.995316
evaluation/Actions Min            -0.995977
evaluation/Num Paths              10
evaluation/Average Returns       -19.7122
time/data storing (s)              0.00141944
time/evaluation sampling (s)       0.227731
time/exploration sampling (s)      0.0625203
time/logging (s)                   0.00338157
time/saving (s)                    0.00195916
time/training (s)                  0.784597
time/epoch (s)                     1.08161
time/total (s)                    67.3647
Epoch                             61
-----------------------------  --------------
2019-04-21 00:45:20.873532 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 62 finished
-----------------------------  --------------
replay_buffer/size             12800
trainer/QF1 Loss                   0.259346
trainer/QF2 Loss                   0.277439
trainer/Policy Loss               19.3438
trainer/Q1 Predictions Mean      -18.1812
trainer/Q1 Predictions Std         9.65247
trainer/Q1 Predictions Max       -15.4581
trainer/Q1 Predictions Min       -83.8554
trainer/Q2 Predictions Mean      -18.1715
trainer/Q2 Predictions Std         9.66354
trainer/Q2 Predictions Max       -15.4419
trainer/Q2 Predictions Min       -83.9917
trainer/Q Targets Mean           -18.3067
trainer/Q Targets Std              9.3362
trainer/Q Targets Max            -15.5574
trainer/Q Targets Min            -79.4897
trainer/Log Pis Mean               1.9519
trainer/Log Pis Std                1.49496
trainer/Log Pis Max                9.12534
trainer/Log Pis Min               -2.45802
trainer/Policy mu Mean             0.0726697
trainer/Policy mu Std              0.82466
trainer/Policy mu Max              3.4192
trainer/Policy mu Min             -2.46671
trainer/Policy log std Mean       -1.86097
trainer/Policy log std Std         0.364528
trainer/Policy log std Max        -0.430211
trainer/Policy log std Min        -2.15632
trainer/Alpha                      0.0452785
trainer/Alpha Loss                -0.148875
exploration/num steps total    12800
exploration/num paths total      128
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.297973
exploration/Rewards Std            0.769653
exploration/Rewards Max           -0.0126478
exploration/Rewards Min           -6.95393
exploration/Returns Mean         -29.7973
exploration/Returns Std           11.6459
exploration/Returns Max          -18.1514
exploration/Returns Min          -41.4432
exploration/Actions Mean           0.0374024
exploration/Actions Std            0.251643
exploration/Actions Max            0.99878
exploration/Actions Min           -0.535664
exploration/Num Paths              2
exploration/Average Returns      -29.7973
evaluation/num steps total     63000
evaluation/num paths total       630
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.02462
evaluation/Rewards Std             1.76441
evaluation/Rewards Max            -0.066066
evaluation/Rewards Min            -9.87374
evaluation/Returns Mean         -102.462
evaluation/Returns Std           139.734
evaluation/Returns Max           -12.4113
evaluation/Returns Min          -397.062
evaluation/Actions Mean            0.0512069
evaluation/Actions Std             0.367126
evaluation/Actions Max             0.998041
evaluation/Actions Min            -0.995186
evaluation/Num Paths              10
evaluation/Average Returns      -102.462
time/data storing (s)              0.00123169
time/evaluation sampling (s)       0.219432
time/exploration sampling (s)      0.0638609
time/logging (s)                   0.00335417
time/saving (s)                    0.00193801
time/training (s)                  0.78393
time/epoch (s)                     1.07375
time/total (s)                    68.4429
Epoch                             62
-----------------------------  --------------
2019-04-21 00:45:21.954459 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 63 finished
-----------------------------  --------------
replay_buffer/size             13000
trainer/QF1 Loss                  18.4191
trainer/QF2 Loss                  18.1182
trainer/Policy Loss               19.9286
trainer/Q1 Predictions Mean      -19.0809
trainer/Q1 Predictions Std        11.5651
trainer/Q1 Predictions Max       -15.4201
trainer/Q1 Predictions Min       -82.9591
trainer/Q2 Predictions Mean      -19.0567
trainer/Q2 Predictions Std        11.5307
trainer/Q2 Predictions Max       -15.388
trainer/Q2 Predictions Min       -82.9772
trainer/Q Targets Mean           -18.7585
trainer/Q Targets Std             10.8912
trainer/Q Targets Max             -8.1047
trainer/Q Targets Min            -79.8668
trainer/Log Pis Mean               1.73155
trainer/Log Pis Std                1.78452
trainer/Log Pis Max                8.10617
trainer/Log Pis Min               -3.36407
trainer/Policy mu Mean             0.0571297
trainer/Policy mu Std              0.904322
trainer/Policy mu Max              3.30227
trainer/Policy mu Min             -2.80876
trainer/Policy log std Mean       -1.78912
trainer/Policy log std Std         0.379753
trainer/Policy log std Max        -0.459003
trainer/Policy log std Min        -2.13108
trainer/Alpha                      0.0442457
trainer/Alpha Loss                -0.836997
exploration/num steps total    13000
exploration/num paths total      130
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.34079
exploration/Rewards Std            0.823825
exploration/Rewards Max           -0.0241512
exploration/Rewards Min           -6.62525
exploration/Returns Mean         -34.079
exploration/Returns Std            3.95167
exploration/Returns Max          -30.1273
exploration/Returns Min          -38.0307
exploration/Actions Mean           0.0496156
exploration/Actions Std            0.271349
exploration/Actions Max            0.995238
exploration/Actions Min           -0.661126
exploration/Num Paths              2
exploration/Average Returns      -34.079
evaluation/num steps total     64000
evaluation/num paths total       640
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.23682
evaluation/Rewards Std             0.895252
evaluation/Rewards Max            -0.0539623
evaluation/Rewards Min           -10.0557
evaluation/Returns Mean          -23.682
evaluation/Returns Std            12.995
evaluation/Returns Max           -11.6761
evaluation/Returns Min           -55.4979
evaluation/Actions Mean            0.0284248
evaluation/Actions Std             0.201642
evaluation/Actions Max             0.998088
evaluation/Actions Min            -0.994004
evaluation/Num Paths              10
evaluation/Average Returns       -23.682
time/data storing (s)              0.00125025
time/evaluation sampling (s)       0.226019
time/exploration sampling (s)      0.0655442
time/logging (s)                   0.00336357
time/saving (s)                    0.00194782
time/training (s)                  0.776995
time/epoch (s)                     1.07512
time/total (s)                    69.5223
Epoch                             63
-----------------------------  --------------
2019-04-21 00:45:23.042657 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 64 finished
-----------------------------  --------------
replay_buffer/size             13200
trainer/QF1 Loss                  26.1103
trainer/QF2 Loss                  25.8295
trainer/Policy Loss               20.5673
trainer/Q1 Predictions Mean      -19.2402
trainer/Q1 Predictions Std        10.3746
trainer/Q1 Predictions Max       -15.3954
trainer/Q1 Predictions Min       -71.7419
trainer/Q2 Predictions Mean      -19.2214
trainer/Q2 Predictions Std        10.3637
trainer/Q2 Predictions Max       -15.3983
trainer/Q2 Predictions Min       -71.7668
trainer/Q Targets Mean           -18.8084
trainer/Q Targets Std             10.2932
trainer/Q Targets Max             -0.255696
trainer/Q Targets Min            -75.5525
trainer/Log Pis Mean               1.9455
trainer/Log Pis Std                1.77123
trainer/Log Pis Max                8.69556
trainer/Log Pis Min               -1.57073
trainer/Policy mu Mean             0.152749
trainer/Policy mu Std              0.978963
trainer/Policy mu Max              3.32912
trainer/Policy mu Min             -2.72065
trainer/Policy log std Mean       -1.77033
trainer/Policy log std Std         0.441548
trainer/Policy log std Max        -0.342709
trainer/Policy log std Min        -2.1055
trainer/Alpha                      0.0431859
trainer/Alpha Loss                -0.17125
exploration/num steps total    13200
exploration/num paths total      132
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.279666
exploration/Rewards Std            0.576035
exploration/Rewards Max           -0.02755
exploration/Rewards Min           -5.16051
exploration/Returns Mean         -27.9666
exploration/Returns Std            5.41583
exploration/Returns Max          -22.5508
exploration/Returns Min          -33.3825
exploration/Actions Mean          -0.0118963
exploration/Actions Std            0.273187
exploration/Actions Max            0.961578
exploration/Actions Min           -0.994833
exploration/Num Paths              2
exploration/Average Returns      -27.9666
evaluation/num steps total     65000
evaluation/num paths total       650
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.216672
evaluation/Rewards Std             0.968837
evaluation/Rewards Max            -0.0285838
evaluation/Rewards Min           -11.1615
evaluation/Returns Mean          -21.6672
evaluation/Returns Std            15.826
evaluation/Returns Max            -3.56939
evaluation/Returns Min           -62.3185
evaluation/Actions Mean            0.0318677
evaluation/Actions Std             0.189703
evaluation/Actions Max             0.998851
evaluation/Actions Min            -0.974565
evaluation/Num Paths              10
evaluation/Average Returns       -21.6672
time/data storing (s)              0.00135933
time/evaluation sampling (s)       0.225986
time/exploration sampling (s)      0.0744301
time/logging (s)                   0.00336137
time/saving (s)                    0.00195319
time/training (s)                  0.774994
time/epoch (s)                     1.08208
time/total (s)                    70.6088
Epoch                             64
-----------------------------  --------------
2019-04-21 00:45:24.123639 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 65 finished
-----------------------------  --------------
replay_buffer/size             13400
trainer/QF1 Loss                   2.40224
trainer/QF2 Loss                   2.39754
trainer/Policy Loss               17.8466
trainer/Q1 Predictions Mean      -16.6656
trainer/Q1 Predictions Std         4.13931
trainer/Q1 Predictions Max       -15.0805
trainer/Q1 Predictions Min       -38.5183
trainer/Q2 Predictions Mean      -16.6467
trainer/Q2 Predictions Std         4.13974
trainer/Q2 Predictions Max       -15.084
trainer/Q2 Predictions Min       -38.6594
trainer/Q Targets Mean           -16.7613
trainer/Q Targets Std              4.43832
trainer/Q Targets Max             -0.469052
trainer/Q Targets Min            -38.5532
trainer/Log Pis Mean               1.56681
trainer/Log Pis Std                1.73286
trainer/Log Pis Max                7.62194
trainer/Log Pis Min               -3.97135
trainer/Policy mu Mean             0.112177
trainer/Policy mu Std              0.793705
trainer/Policy mu Max              3.2764
trainer/Policy mu Min             -1.96824
trainer/Policy log std Mean       -1.87974
trainer/Policy log std Std         0.377792
trainer/Policy log std Max        -0.442026
trainer/Policy log std Min        -2.1551
trainer/Alpha                      0.0422613
trainer/Alpha Loss                -1.3705
exploration/num steps total    13400
exploration/num paths total      134
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.391294
exploration/Rewards Std            0.957948
exploration/Rewards Max           -0.00378867
exploration/Rewards Min           -7.63171
exploration/Returns Mean         -39.1294
exploration/Returns Std           11.8645
exploration/Returns Max          -27.2649
exploration/Returns Min          -50.9939
exploration/Actions Mean           0.0177355
exploration/Actions Std            0.261106
exploration/Actions Max            0.996803
exploration/Actions Min           -0.997603
exploration/Num Paths              2
exploration/Average Returns      -39.1294
evaluation/num steps total     66000
evaluation/num paths total       660
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.250313
evaluation/Rewards Std             0.729462
evaluation/Rewards Max            -0.109254
evaluation/Rewards Min            -8.38385
evaluation/Returns Mean          -25.0313
evaluation/Returns Std            10.752
evaluation/Returns Max           -12.9559
evaluation/Returns Min           -44.5063
evaluation/Actions Mean            0.0155887
evaluation/Actions Std             0.183032
evaluation/Actions Max             0.995449
evaluation/Actions Min            -0.98955
evaluation/Num Paths              10
evaluation/Average Returns       -25.0313
time/data storing (s)              0.00132405
time/evaluation sampling (s)       0.226968
time/exploration sampling (s)      0.065393
time/logging (s)                   0.00335934
time/saving (s)                    0.00195202
time/training (s)                  0.776131
time/epoch (s)                     1.07513
time/total (s)                    71.6882
Epoch                             65
-----------------------------  --------------
2019-04-21 00:45:25.213830 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 66 finished
-----------------------------  --------------
replay_buffer/size             13600
trainer/QF1 Loss                   6.7349
trainer/QF2 Loss                   6.75371
trainer/Policy Loss               19.4115
trainer/Q1 Predictions Mean      -18.1248
trainer/Q1 Predictions Std        10.604
trainer/Q1 Predictions Max       -14.9731
trainer/Q1 Predictions Min       -75.5436
trainer/Q2 Predictions Mean      -18.1526
trainer/Q2 Predictions Std        10.6253
trainer/Q2 Predictions Max       -14.9939
trainer/Q2 Predictions Min       -75.6091
trainer/Q Targets Mean           -17.9336
trainer/Q Targets Std             11.1734
trainer/Q Targets Max             -0.252152
trainer/Q Targets Min            -76.9773
trainer/Log Pis Mean               1.99909
trainer/Log Pis Std                1.68804
trainer/Log Pis Max               10.1509
trainer/Log Pis Min               -4.26231
trainer/Policy mu Mean             0.101349
trainer/Policy mu Std              0.902259
trainer/Policy mu Max              3.31376
trainer/Policy mu Min             -2.92831
trainer/Policy log std Mean       -1.88305
trainer/Policy log std Std         0.417973
trainer/Policy log std Max        -0.431763
trainer/Policy log std Min        -2.25418
trainer/Alpha                      0.0419211
trainer/Alpha Loss                -0.00289694
exploration/num steps total    13600
exploration/num paths total      136
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.192636
exploration/Rewards Std            0.327986
exploration/Rewards Max           -0.0148309
exploration/Rewards Min           -3.4945
exploration/Returns Mean         -19.2636
exploration/Returns Std            2.99485
exploration/Returns Max          -16.2687
exploration/Returns Min          -22.2584
exploration/Actions Mean          -0.0124489
exploration/Actions Std            0.208467
exploration/Actions Max            0.858099
exploration/Actions Min           -0.993062
exploration/Num Paths              2
exploration/Average Returns      -19.2636
evaluation/num steps total     67000
evaluation/num paths total       670
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.206598
evaluation/Rewards Std             0.939954
evaluation/Rewards Max            -0.0320597
evaluation/Rewards Min           -10.0278
evaluation/Returns Mean          -20.6598
evaluation/Returns Std            16.037
evaluation/Returns Max            -3.33348
evaluation/Returns Min           -50.7685
evaluation/Actions Mean            0.0267603
evaluation/Actions Std             0.182326
evaluation/Actions Max             0.998382
evaluation/Actions Min            -0.975939
evaluation/Num Paths              10
evaluation/Average Returns       -20.6598
time/data storing (s)              0.00133619
time/evaluation sampling (s)       0.23477
time/exploration sampling (s)      0.0696158
time/logging (s)                   0.00341227
time/saving (s)                    0.0017183
time/training (s)                  0.773511
time/epoch (s)                     1.08436
time/total (s)                    72.777
Epoch                             66
-----------------------------  --------------
2019-04-21 00:45:26.295382 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 67 finished
-----------------------------  --------------
replay_buffer/size             13800
trainer/QF1 Loss                   2.39828
trainer/QF2 Loss                   2.42376
trainer/Policy Loss               18.5557
trainer/Q1 Predictions Mean      -17.1437
trainer/Q1 Predictions Std         8.20065
trainer/Q1 Predictions Max       -15.0265
trainer/Q1 Predictions Min       -76.5961
trainer/Q2 Predictions Mean      -17.1188
trainer/Q2 Predictions Std         8.18656
trainer/Q2 Predictions Max       -15.0015
trainer/Q2 Predictions Min       -76.5403
trainer/Q Targets Mean           -17.1558
trainer/Q Targets Std              8.68671
trainer/Q Targets Max             -0.326306
trainer/Q Targets Min            -78.5444
trainer/Log Pis Mean               1.99648
trainer/Log Pis Std                1.42459
trainer/Log Pis Max                9.46359
trainer/Log Pis Min               -1.62587
trainer/Policy mu Mean             0.118507
trainer/Policy mu Std              0.816979
trainer/Policy mu Max              3.41056
trainer/Policy mu Min             -2.55574
trainer/Policy log std Mean       -1.89592
trainer/Policy log std Std         0.385707
trainer/Policy log std Max        -0.411948
trainer/Policy log std Min        -2.20343
trainer/Alpha                      0.0412095
trainer/Alpha Loss                -0.0112269
exploration/num steps total    13800
exploration/num paths total      138
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.268732
exploration/Rewards Std            0.629456
exploration/Rewards Max           -0.0298411
exploration/Rewards Min           -5.69636
exploration/Returns Mean         -26.8732
exploration/Returns Std            8.18617
exploration/Returns Max          -18.687
exploration/Returns Min          -35.0594
exploration/Actions Mean           0.0294754
exploration/Actions Std            0.241161
exploration/Actions Max            0.998675
exploration/Actions Min           -0.484823
exploration/Num Paths              2
exploration/Average Returns      -26.8732
evaluation/num steps total     68000
evaluation/num paths total       680
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.488438
evaluation/Rewards Std             1.29233
evaluation/Rewards Max            -0.00280695
evaluation/Rewards Min            -8.97825
evaluation/Returns Mean          -48.8438
evaluation/Returns Std           103.451
evaluation/Returns Max            -1.89973
evaluation/Returns Min          -356.167
evaluation/Actions Mean            0.061441
evaluation/Actions Std             0.269429
evaluation/Actions Max             0.997769
evaluation/Actions Min            -0.989535
evaluation/Num Paths              10
evaluation/Average Returns       -48.8438
time/data storing (s)              0.00149032
time/evaluation sampling (s)       0.232197
time/exploration sampling (s)      0.0652166
time/logging (s)                   0.00333055
time/saving (s)                    0.00194189
time/training (s)                  0.771795
time/epoch (s)                     1.07597
time/total (s)                    73.8565
Epoch                             67
-----------------------------  --------------
2019-04-21 00:45:27.373137 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 68 finished
-----------------------------  --------------
replay_buffer/size             14000
trainer/QF1 Loss                   2.3297
trainer/QF2 Loss                   2.29116
trainer/Policy Loss               18.3776
trainer/Q1 Predictions Mean      -16.6454
trainer/Q1 Predictions Std         6.39977
trainer/Q1 Predictions Max       -14.9076
trainer/Q1 Predictions Min       -63.7194
trainer/Q2 Predictions Mean      -16.6516
trainer/Q2 Predictions Std         6.36849
trainer/Q2 Predictions Max       -14.8976
trainer/Q2 Predictions Min       -63.6944
trainer/Q Targets Mean           -16.5741
trainer/Q Targets Std              6.70139
trainer/Q Targets Max             -1.62555
trainer/Q Targets Min            -64.3252
trainer/Log Pis Mean               2.1644
trainer/Log Pis Std                1.42348
trainer/Log Pis Max               10.7196
trainer/Log Pis Min               -1.75468
trainer/Policy mu Mean             0.0461544
trainer/Policy mu Std              0.806314
trainer/Policy mu Max              3.25281
trainer/Policy mu Min             -3.28988
trainer/Policy log std Mean       -1.97404
trainer/Policy log std Std         0.385758
trainer/Policy log std Max        -0.558393
trainer/Policy log std Min        -2.26099
trainer/Alpha                      0.0409473
trainer/Alpha Loss                 0.525346
exploration/num steps total    14000
exploration/num paths total      140
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.373677
exploration/Rewards Std            1.09562
exploration/Rewards Max           -0.0105289
exploration/Rewards Min           -8.44238
exploration/Returns Mean         -37.3677
exploration/Returns Std           15.9582
exploration/Returns Max          -21.4095
exploration/Returns Min          -53.3259
exploration/Actions Mean           0.0453961
exploration/Actions Std            0.249357
exploration/Actions Max            0.998305
exploration/Actions Min           -0.483307
exploration/Num Paths              2
exploration/Average Returns      -37.3677
evaluation/num steps total     69000
evaluation/num paths total       690
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.350387
evaluation/Rewards Std             1.37069
evaluation/Rewards Max            -0.0237071
evaluation/Rewards Min           -11.0103
evaluation/Returns Mean          -35.0387
evaluation/Returns Std            17.4656
evaluation/Returns Max            -3.23306
evaluation/Returns Min           -59.2887
evaluation/Actions Mean            0.0434444
evaluation/Actions Std             0.225496
evaluation/Actions Max             0.998831
evaluation/Actions Min            -0.996025
evaluation/Num Paths              10
evaluation/Average Returns       -35.0387
time/data storing (s)              0.00131676
time/evaluation sampling (s)       0.234044
time/exploration sampling (s)      0.0697329
time/logging (s)                   0.00334747
time/saving (s)                    0.00194416
time/training (s)                  0.76156
time/epoch (s)                     1.07195
time/total (s)                    74.9327
Epoch                             68
-----------------------------  --------------
2019-04-21 00:45:28.443865 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 69 finished
-----------------------------  --------------
replay_buffer/size             14200
trainer/QF1 Loss                   0.35982
trainer/QF2 Loss                   0.300777
trainer/Policy Loss               18.9029
trainer/Q1 Predictions Mean      -17.3877
trainer/Q1 Predictions Std         8.46446
trainer/Q1 Predictions Max       -14.7811
trainer/Q1 Predictions Min       -74.6401
trainer/Q2 Predictions Mean      -17.4234
trainer/Q2 Predictions Std         8.43211
trainer/Q2 Predictions Max       -14.7785
trainer/Q2 Predictions Min       -74.6452
trainer/Q Targets Mean           -17.4414
trainer/Q Targets Std              8.25501
trainer/Q Targets Max            -14.764
trainer/Q Targets Min            -75.7492
trainer/Log Pis Mean               2.22283
trainer/Log Pis Std                1.5353
trainer/Log Pis Max                8.1495
trainer/Log Pis Min               -1.65996
trainer/Policy mu Mean             0.0108559
trainer/Policy mu Std              0.900428
trainer/Policy mu Max              3.37142
trainer/Policy mu Min             -3.08068
trainer/Policy log std Mean       -1.92377
trainer/Policy log std Std         0.468653
trainer/Policy log std Max        -0.433016
trainer/Policy log std Min        -2.30833
trainer/Alpha                      0.0411144
trainer/Alpha Loss                 0.711189
exploration/num steps total    14200
exploration/num paths total      142
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.612321
exploration/Rewards Std            1.69457
exploration/Rewards Max           -0.0085924
exploration/Rewards Min          -10.293
exploration/Returns Mean         -61.2321
exploration/Returns Std            2.16839
exploration/Returns Max          -59.0637
exploration/Returns Min          -63.4005
exploration/Actions Mean           0.0724013
exploration/Actions Std            0.282103
exploration/Actions Max            0.999697
exploration/Actions Min           -0.370595
exploration/Num Paths              2
exploration/Average Returns      -61.2321
evaluation/num steps total     70000
evaluation/num paths total       700
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.257647
evaluation/Rewards Std             0.989202
evaluation/Rewards Max            -0.0321145
evaluation/Rewards Min           -10.0237
evaluation/Returns Mean          -25.7647
evaluation/Returns Std            17.0193
evaluation/Returns Max            -9.65437
evaluation/Returns Min           -58.5214
evaluation/Actions Mean            0.0235117
evaluation/Actions Std             0.192892
evaluation/Actions Max             0.998057
evaluation/Actions Min            -0.989987
evaluation/Num Paths              10
evaluation/Average Returns       -25.7647
time/data storing (s)              0.00131367
time/evaluation sampling (s)       0.223798
time/exploration sampling (s)      0.0683938
time/logging (s)                   0.00337467
time/saving (s)                    0.0019421
time/training (s)                  0.765968
time/epoch (s)                     1.06479
time/total (s)                    76.0018
Epoch                             69
-----------------------------  --------------
2019-04-21 00:45:29.525300 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 70 finished
-----------------------------  --------------
replay_buffer/size             14400
trainer/QF1 Loss                   4.21557
trainer/QF2 Loss                   4.17457
trainer/Policy Loss               17.8791
trainer/Q1 Predictions Mean      -16.3323
trainer/Q1 Predictions Std         4.14638
trainer/Q1 Predictions Max       -14.6286
trainer/Q1 Predictions Min       -36.7293
trainer/Q2 Predictions Mean      -16.3382
trainer/Q2 Predictions Std         4.13433
trainer/Q2 Predictions Max       -14.6181
trainer/Q2 Predictions Min       -36.6765
trainer/Q Targets Mean           -16.1821
trainer/Q Targets Std              4.67662
trainer/Q Targets Max             -0.302387
trainer/Q Targets Min            -36.8265
trainer/Log Pis Mean               1.9935
trainer/Log Pis Std                1.49794
trainer/Log Pis Max                7.82236
trainer/Log Pis Min               -2.92105
trainer/Policy mu Mean             0.0599305
trainer/Policy mu Std              0.854727
trainer/Policy mu Max              3.1568
trainer/Policy mu Min             -2.82089
trainer/Policy log std Mean       -1.96639
trainer/Policy log std Std         0.427303
trainer/Policy log std Max        -0.39978
trainer/Policy log std Min        -2.30927
trainer/Alpha                      0.0411676
trainer/Alpha Loss                -0.0207459
exploration/num steps total    14400
exploration/num paths total      144
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.27028
exploration/Rewards Std            0.704271
exploration/Rewards Max           -0.00734212
exploration/Rewards Min           -6.3402
exploration/Returns Mean         -27.028
exploration/Returns Std           11.4474
exploration/Returns Max          -15.5806
exploration/Returns Min          -38.4755
exploration/Actions Mean           0.00837257
exploration/Actions Std            0.218994
exploration/Actions Max            0.996946
exploration/Actions Min           -0.985491
exploration/Num Paths              2
exploration/Average Returns      -27.028
evaluation/num steps total     71000
evaluation/num paths total       710
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.309565
evaluation/Rewards Std             1.15257
evaluation/Rewards Max            -0.0574714
evaluation/Rewards Min           -10.4311
evaluation/Returns Mean          -30.9565
evaluation/Returns Std            17.4922
evaluation/Returns Max            -8.2172
evaluation/Returns Min           -58.4276
evaluation/Actions Mean            0.0404582
evaluation/Actions Std             0.211929
evaluation/Actions Max             0.998577
evaluation/Actions Min            -0.985742
evaluation/Num Paths              10
evaluation/Average Returns       -30.9565
time/data storing (s)              0.00133999
time/evaluation sampling (s)       0.223478
time/exploration sampling (s)      0.0663741
time/logging (s)                   0.00337654
time/saving (s)                    0.00197592
time/training (s)                  0.778982
time/epoch (s)                     1.07553
time/total (s)                    77.0816
Epoch                             70
-----------------------------  --------------
2019-04-21 00:45:30.607353 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 71 finished
-----------------------------  --------------
replay_buffer/size             14600
trainer/QF1 Loss                   2.46432
trainer/QF2 Loss                   2.44591
trainer/Policy Loss               18.6172
trainer/Q1 Predictions Mean      -17.3201
trainer/Q1 Predictions Std         9.01094
trainer/Q1 Predictions Max       -14.5495
trainer/Q1 Predictions Min       -74.64
trainer/Q2 Predictions Mean      -17.34
trainer/Q2 Predictions Std         8.98733
trainer/Q2 Predictions Max       -14.5552
trainer/Q2 Predictions Min       -74.402
trainer/Q Targets Mean           -17.3444
trainer/Q Targets Std              9.24461
trainer/Q Targets Max             -0.333551
trainer/Q Targets Min            -75.6975
trainer/Log Pis Mean               1.85637
trainer/Log Pis Std                1.42407
trainer/Log Pis Max                5.7248
trainer/Log Pis Min               -4.03763
trainer/Policy mu Mean             0.126691
trainer/Policy mu Std              0.892927
trainer/Policy mu Max              3.52331
trainer/Policy mu Min             -2.34124
trainer/Policy log std Mean       -1.90169
trainer/Policy log std Std         0.464538
trainer/Policy log std Max        -0.137282
trainer/Policy log std Min        -2.2799
trainer/Alpha                      0.0414601
trainer/Alpha Loss                -0.457165
exploration/num steps total    14600
exploration/num paths total      146
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.300516
exploration/Rewards Std            0.672684
exploration/Rewards Max           -0.0121324
exploration/Rewards Min           -4.92591
exploration/Returns Mean         -30.0516
exploration/Returns Std            1.09253
exploration/Returns Max          -28.9591
exploration/Returns Min          -31.1442
exploration/Actions Mean           0.0391122
exploration/Actions Std            0.242384
exploration/Actions Max            0.997562
exploration/Actions Min           -0.561797
exploration/Num Paths              2
exploration/Average Returns      -30.0516
evaluation/num steps total     72000
evaluation/num paths total       720
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.260389
evaluation/Rewards Std             0.877815
evaluation/Rewards Max            -0.0755481
evaluation/Rewards Min            -9.09516
evaluation/Returns Mean          -26.0389
evaluation/Returns Std            13.4033
evaluation/Returns Max           -11.8341
evaluation/Returns Min           -52.2994
evaluation/Actions Mean            0.0208936
evaluation/Actions Std             0.193817
evaluation/Actions Max             0.998042
evaluation/Actions Min            -0.996241
evaluation/Num Paths              10
evaluation/Average Returns       -26.0389
time/data storing (s)              0.00164746
time/evaluation sampling (s)       0.229727
time/exploration sampling (s)      0.0710954
time/logging (s)                   0.0033838
time/saving (s)                    0.00159783
time/training (s)                  0.768506
time/epoch (s)                     1.07596
time/total (s)                    78.162
Epoch                             71
-----------------------------  --------------
2019-04-21 00:45:31.694008 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 72 finished
-----------------------------  --------------
replay_buffer/size             14800
trainer/QF1 Loss                   4.46338
trainer/QF2 Loss                   4.47419
trainer/Policy Loss               18.2943
trainer/Q1 Predictions Mean      -16.6932
trainer/Q1 Predictions Std         8.53101
trainer/Q1 Predictions Max       -14.2884
trainer/Q1 Predictions Min       -72.2953
trainer/Q2 Predictions Mean      -16.6275
trainer/Q2 Predictions Std         8.49442
trainer/Q2 Predictions Max       -14.2089
trainer/Q2 Predictions Min       -71.905
trainer/Q Targets Mean           -16.7517
trainer/Q Targets Std              9.15692
trainer/Q Targets Max             -0.127826
trainer/Q Targets Min            -75.8303
trainer/Log Pis Mean               2.1433
trainer/Log Pis Std                1.39896
trainer/Log Pis Max                7.54737
trainer/Log Pis Min               -2.11128
trainer/Policy mu Mean             0.078238
trainer/Policy mu Std              0.812337
trainer/Policy mu Max              3.44477
trainer/Policy mu Min             -2.78604
trainer/Policy log std Mean       -2.01977
trainer/Policy log std Std         0.413658
trainer/Policy log std Max        -0.256779
trainer/Policy log std Min        -2.31441
trainer/Alpha                      0.0419883
trainer/Alpha Loss                 0.454321
exploration/num steps total    14800
exploration/num paths total      148
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.416353
exploration/Rewards Std            1.12547
exploration/Rewards Max           -0.0157338
exploration/Rewards Min           -8.4832
exploration/Returns Mean         -41.6353
exploration/Returns Std           10.9797
exploration/Returns Max          -30.6556
exploration/Returns Min          -52.6149
exploration/Actions Mean           0.0355123
exploration/Actions Std            0.267371
exploration/Actions Max            0.999691
exploration/Actions Min           -0.981315
exploration/Num Paths              2
exploration/Average Returns      -41.6353
evaluation/num steps total     73000
evaluation/num paths total       730
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.316384
evaluation/Rewards Std             1.14622
evaluation/Rewards Max            -0.0207486
evaluation/Rewards Min           -11.0951
evaluation/Returns Mean          -31.6384
evaluation/Returns Std            19.1135
evaluation/Returns Max            -8.6191
evaluation/Returns Min           -67.6434
evaluation/Actions Mean            0.0223043
evaluation/Actions Std             0.201306
evaluation/Actions Max             0.998436
evaluation/Actions Min            -0.994876
evaluation/Num Paths              10
evaluation/Average Returns       -31.6384
time/data storing (s)              0.00124917
time/evaluation sampling (s)       0.231853
time/exploration sampling (s)      0.0669233
time/logging (s)                   0.0030292
time/saving (s)                    0.00155215
time/training (s)                  0.775518
time/epoch (s)                     1.08012
time/total (s)                    79.2464
Epoch                             72
-----------------------------  --------------
2019-04-21 00:45:32.780132 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 73 finished
-----------------------------  --------------
replay_buffer/size             15000
trainer/QF1 Loss                   4.9748
trainer/QF2 Loss                   4.9116
trainer/Policy Loss               18.2598
trainer/Q1 Predictions Mean      -16.5185
trainer/Q1 Predictions Std         7.81648
trainer/Q1 Predictions Max       -14.2577
trainer/Q1 Predictions Min       -64.6528
trainer/Q2 Predictions Mean      -16.5345
trainer/Q2 Predictions Std         7.85047
trainer/Q2 Predictions Max       -14.2544
trainer/Q2 Predictions Min       -64.7732
trainer/Q Targets Mean           -16.5813
trainer/Q Targets Std              8.51304
trainer/Q Targets Max             -0.252152
trainer/Q Targets Min            -65.9001
trainer/Log Pis Mean               2.13674
trainer/Log Pis Std                1.45954
trainer/Log Pis Max                7.49547
trainer/Log Pis Min               -1.09676
trainer/Policy mu Mean             0.0659022
trainer/Policy mu Std              0.886511
trainer/Policy mu Max              3.54691
trainer/Policy mu Min             -3.39845
trainer/Policy log std Mean       -1.97493
trainer/Policy log std Std         0.446156
trainer/Policy log std Max        -0.229734
trainer/Policy log std Min        -2.34918
trainer/Alpha                      0.042409
trainer/Alpha Loss                 0.432173
exploration/num steps total    15000
exploration/num paths total      150
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -3.09414
exploration/Rewards Std            2.86896
exploration/Rewards Max           -0.0353405
exploration/Rewards Min           -5.9282
exploration/Returns Mean        -309.414
exploration/Returns Std          283.407
exploration/Returns Max          -26.0069
exploration/Returns Min         -592.82
exploration/Actions Mean          -0.0172622
exploration/Actions Std            0.676734
exploration/Actions Max            0.996696
exploration/Actions Min           -0.999911
exploration/Num Paths              2
exploration/Average Returns     -309.414
evaluation/num steps total     74000
evaluation/num paths total       740
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.286485
evaluation/Rewards Std             1.21211
evaluation/Rewards Max            -0.0127812
evaluation/Rewards Min           -10.6163
evaluation/Returns Mean          -28.6485
evaluation/Returns Std            20.9701
evaluation/Returns Max            -6.40279
evaluation/Returns Min           -59.3461
evaluation/Actions Mean            0.0281282
evaluation/Actions Std             0.2024
evaluation/Actions Max             0.997441
evaluation/Actions Min            -0.991407
evaluation/Num Paths              10
evaluation/Average Returns       -28.6485
time/data storing (s)              0.00139099
time/evaluation sampling (s)       0.228934
time/exploration sampling (s)      0.0725164
time/logging (s)                   0.00330427
time/saving (s)                    0.0019611
time/training (s)                  0.772042
time/epoch (s)                     1.08015
time/total (s)                    80.3312
Epoch                             73
-----------------------------  --------------
2019-04-21 00:45:33.864496 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 74 finished
-----------------------------  --------------
replay_buffer/size             15200
trainer/QF1 Loss                   6.47776
trainer/QF2 Loss                   6.40418
trainer/Policy Loss               18.0558
trainer/Q1 Predictions Mean      -16.7368
trainer/Q1 Predictions Std         9.07531
trainer/Q1 Predictions Max       -14.2243
trainer/Q1 Predictions Min       -78.2437
trainer/Q2 Predictions Mean      -16.6818
trainer/Q2 Predictions Std         9.0861
trainer/Q2 Predictions Max       -14.1584
trainer/Q2 Predictions Min       -78.2509
trainer/Q Targets Mean           -16.4396
trainer/Q Targets Std              9.72131
trainer/Q Targets Max             -0.215738
trainer/Q Targets Min            -78.321
trainer/Log Pis Mean               2.00555
trainer/Log Pis Std                1.1386
trainer/Log Pis Max                6.87268
trainer/Log Pis Min               -0.708798
trainer/Policy mu Mean             0.123897
trainer/Policy mu Std              0.848217
trainer/Policy mu Max              3.50111
trainer/Policy mu Min             -3.17285
trainer/Policy log std Mean       -1.89146
trainer/Policy log std Std         0.443077
trainer/Policy log std Max        -0.179205
trainer/Policy log std Min        -2.24719
trainer/Alpha                      0.0419848
trainer/Alpha Loss                 0.0175919
exploration/num steps total    15200
exploration/num paths total      152
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.344145
exploration/Rewards Std            0.891099
exploration/Rewards Max           -0.0117279
exploration/Rewards Min           -6.64238
exploration/Returns Mean         -34.4145
exploration/Returns Std            2.31018
exploration/Returns Max          -32.1043
exploration/Returns Min          -36.7247
exploration/Actions Mean           0.0373547
exploration/Actions Std            0.258575
exploration/Actions Max            0.999291
exploration/Actions Min           -0.854239
exploration/Num Paths              2
exploration/Average Returns      -34.4145
evaluation/num steps total     75000
evaluation/num paths total       750
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.277308
evaluation/Rewards Std             1.14457
evaluation/Rewards Max            -0.0323086
evaluation/Rewards Min           -10.1261
evaluation/Returns Mean          -27.7308
evaluation/Returns Std            18.1176
evaluation/Returns Max            -4.26229
evaluation/Returns Min           -54.835
evaluation/Actions Mean            0.030749
evaluation/Actions Std             0.201762
evaluation/Actions Max             0.997608
evaluation/Actions Min            -0.994713
evaluation/Num Paths              10
evaluation/Average Returns       -27.7308
time/data storing (s)              0.00131865
time/evaluation sampling (s)       0.226833
time/exploration sampling (s)      0.0652901
time/logging (s)                   0.00334777
time/saving (s)                    0.00194581
time/training (s)                  0.779514
time/epoch (s)                     1.07825
time/total (s)                    81.4138
Epoch                             74
-----------------------------  --------------
2019-04-21 00:45:34.954576 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 75 finished
-----------------------------  --------------
replay_buffer/size             15400
trainer/QF1 Loss                  10.1588
trainer/QF2 Loss                  10.163
trainer/Policy Loss               17.9924
trainer/Q1 Predictions Mean      -16.7761
trainer/Q1 Predictions Std         9.3276
trainer/Q1 Predictions Max       -14.1111
trainer/Q1 Predictions Min       -76.8056
trainer/Q2 Predictions Mean      -16.7872
trainer/Q2 Predictions Std         9.30812
trainer/Q2 Predictions Max       -14.1509
trainer/Q2 Predictions Min       -76.8257
trainer/Q Targets Mean           -16.0741
trainer/Q Targets Std              9.93046
trainer/Q Targets Max             -0.176259
trainer/Q Targets Min            -77.8738
trainer/Log Pis Mean               1.90815
trainer/Log Pis Std                1.59823
trainer/Log Pis Max                7.70669
trainer/Log Pis Min               -3.02133
trainer/Policy mu Mean             0.0876047
trainer/Policy mu Std              0.844022
trainer/Policy mu Max              3.59757
trainer/Policy mu Min             -2.90932
trainer/Policy log std Mean       -1.96147
trainer/Policy log std Std         0.444907
trainer/Policy log std Max        -0.350997
trainer/Policy log std Min        -2.36709
trainer/Alpha                      0.0416516
trainer/Alpha Loss                -0.291924
exploration/num steps total    15400
exploration/num paths total      154
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.362109
exploration/Rewards Std            0.963013
exploration/Rewards Max           -0.00141042
exploration/Rewards Min           -7.25415
exploration/Returns Mean         -36.2109
exploration/Returns Std            7.84291
exploration/Returns Max          -28.368
exploration/Returns Min          -44.0538
exploration/Actions Mean           0.038891
exploration/Actions Std            0.2557
exploration/Actions Max            0.998524
exploration/Actions Min           -0.58244
exploration/Num Paths              2
exploration/Average Returns      -36.2109
evaluation/num steps total     76000
evaluation/num paths total       760
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.797349
evaluation/Rewards Std             1.83337
evaluation/Rewards Max            -0.0414961
evaluation/Rewards Min           -10.8231
evaluation/Returns Mean          -79.7349
evaluation/Returns Std           142.84
evaluation/Returns Max           -12.679
evaluation/Returns Min          -506.153
evaluation/Actions Mean            0.125871
evaluation/Actions Std             0.323986
evaluation/Actions Max             0.998051
evaluation/Actions Min            -0.989327
evaluation/Num Paths              10
evaluation/Average Returns       -79.7349
time/data storing (s)              0.00124734
time/evaluation sampling (s)       0.23092
time/exploration sampling (s)      0.0694541
time/logging (s)                   0.0033406
time/saving (s)                    0.00195746
time/training (s)                  0.777805
time/epoch (s)                     1.08473
time/total (s)                    82.5023
Epoch                             75
-----------------------------  --------------
2019-04-21 00:45:36.050154 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 76 finished
-----------------------------  --------------
replay_buffer/size             15600
trainer/QF1 Loss                   0.154888
trainer/QF2 Loss                   0.134324
trainer/Policy Loss               16.7429
trainer/Q1 Predictions Mean      -15.1709
trainer/Q1 Predictions Std         3.62152
trainer/Q1 Predictions Max       -14.0007
trainer/Q1 Predictions Min       -40.8769
trainer/Q2 Predictions Mean      -15.203
trainer/Q2 Predictions Std         3.60466
trainer/Q2 Predictions Max       -14.0216
trainer/Q2 Predictions Min       -40.7318
trainer/Q Targets Mean           -15.1691
trainer/Q Targets Std              3.35455
trainer/Q Targets Max            -13.966
trainer/Q Targets Min            -39.0073
trainer/Log Pis Mean               1.80204
trainer/Log Pis Std                1.27544
trainer/Log Pis Max                8.4025
trainer/Log Pis Min               -1.89001
trainer/Policy mu Mean             0.0232768
trainer/Policy mu Std              0.718243
trainer/Policy mu Max              2.90825
trainer/Policy mu Min             -2.86816
trainer/Policy log std Mean       -1.92116
trainer/Policy log std Std         0.346767
trainer/Policy log std Max        -0.287807
trainer/Policy log std Min        -2.22311
trainer/Alpha                      0.0418329
trainer/Alpha Loss                -0.628323
exploration/num steps total    15600
exploration/num paths total      156
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.346552
exploration/Rewards Std            0.922883
exploration/Rewards Max           -0.00966063
exploration/Rewards Min           -7.13591
exploration/Returns Mean         -34.6552
exploration/Returns Std            7.52117
exploration/Returns Max          -27.1341
exploration/Returns Min          -42.1764
exploration/Actions Mean           0.0426524
exploration/Actions Std            0.249287
exploration/Actions Max            0.997678
exploration/Actions Min           -0.392514
exploration/Num Paths              2
exploration/Average Returns      -34.6552
evaluation/num steps total     77000
evaluation/num paths total       770
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.222937
evaluation/Rewards Std             0.904825
evaluation/Rewards Max            -0.0410592
evaluation/Rewards Min            -9.07504
evaluation/Returns Mean          -22.2937
evaluation/Returns Std            12.8896
evaluation/Returns Max            -4.73658
evaluation/Returns Min           -50.4061
evaluation/Actions Mean            0.0208841
evaluation/Actions Std             0.191795
evaluation/Actions Max             0.996861
evaluation/Actions Min            -0.995
evaluation/Num Paths              10
evaluation/Average Returns       -22.2937
time/data storing (s)              0.00205786
time/evaluation sampling (s)       0.231367
time/exploration sampling (s)      0.0708141
time/logging (s)                   0.00344674
time/saving (s)                    0.00195266
time/training (s)                  0.779879
time/epoch (s)                     1.08952
time/total (s)                    83.5962
Epoch                             76
-----------------------------  --------------
2019-04-21 00:45:37.139987 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 77 finished
-----------------------------  ---------------
replay_buffer/size             15800
trainer/QF1 Loss                   0.152509
trainer/QF2 Loss                   0.156632
trainer/Policy Loss               17.3562
trainer/Q1 Predictions Mean      -15.794
trainer/Q1 Predictions Std         6.0176
trainer/Q1 Predictions Max       -13.9597
trainer/Q1 Predictions Min       -54.8196
trainer/Q2 Predictions Mean      -15.7939
trainer/Q2 Predictions Std         6.03787
trainer/Q2 Predictions Max       -13.977
trainer/Q2 Predictions Min       -54.975
trainer/Q Targets Mean           -15.6941
trainer/Q Targets Std              5.77876
trainer/Q Targets Max            -13.8357
trainer/Q Targets Min            -52.5707
trainer/Log Pis Mean               2.05336
trainer/Log Pis Std                1.32543
trainer/Log Pis Max                8.34186
trainer/Log Pis Min               -0.898078
trainer/Policy mu Mean            -0.00708495
trainer/Policy mu Std              0.741012
trainer/Policy mu Max              3.08104
trainer/Policy mu Min             -3.20814
trainer/Policy log std Mean       -2.01584
trainer/Policy log std Std         0.381926
trainer/Policy log std Max        -0.464414
trainer/Policy log std Min        -2.30409
trainer/Alpha                      0.0411991
trainer/Alpha Loss                 0.170185
exploration/num steps total    15800
exploration/num paths total      158
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.143823
exploration/Rewards Std            0.0783916
exploration/Rewards Max           -0.00440484
exploration/Rewards Min           -0.396267
exploration/Returns Mean         -14.3823
exploration/Returns Std            0.39487
exploration/Returns Max          -13.9874
exploration/Returns Min          -14.7771
exploration/Actions Mean          -0.000282764
exploration/Actions Std            0.167701
exploration/Actions Max            0.86281
exploration/Actions Min           -0.965144
exploration/Num Paths              2
exploration/Average Returns      -14.3823
evaluation/num steps total     78000
evaluation/num paths total       780
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.604119
evaluation/Rewards Std             1.47666
evaluation/Rewards Max            -0.014253
evaluation/Rewards Min            -6.09386
evaluation/Returns Mean          -60.4119
evaluation/Returns Std           134.809
evaluation/Returns Max            -4.3018
evaluation/Returns Min          -464.393
evaluation/Actions Mean            0.105924
evaluation/Actions Std             0.306974
evaluation/Actions Max             0.996982
evaluation/Actions Min            -0.996438
evaluation/Num Paths              10
evaluation/Average Returns       -60.4119
time/data storing (s)              0.00132952
time/evaluation sampling (s)       0.225785
time/exploration sampling (s)      0.0723611
time/logging (s)                   0.00336094
time/saving (s)                    0.00158153
time/training (s)                  0.779566
time/epoch (s)                     1.08398
time/total (s)                    84.6842
Epoch                             77
-----------------------------  ---------------
2019-04-21 00:45:38.230029 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 78 finished
-----------------------------  --------------
replay_buffer/size             16000
trainer/QF1 Loss                   2.44673
trainer/QF2 Loss                   2.38417
trainer/Policy Loss               17.5403
trainer/Q1 Predictions Mean      -16.4582
trainer/Q1 Predictions Std         8.0548
trainer/Q1 Predictions Max       -13.7991
trainer/Q1 Predictions Min       -58.3546
trainer/Q2 Predictions Mean      -16.445
trainer/Q2 Predictions Std         8.03901
trainer/Q2 Predictions Max       -13.7756
trainer/Q2 Predictions Min       -58.2575
trainer/Q Targets Mean           -16.4435
trainer/Q Targets Std              8.37459
trainer/Q Targets Max             -0.406135
trainer/Q Targets Min            -58.9846
trainer/Log Pis Mean               1.72448
trainer/Log Pis Std                1.73957
trainer/Log Pis Max                7.94963
trainer/Log Pis Min               -2.53007
trainer/Policy mu Mean            -0.0136194
trainer/Policy mu Std              0.853456
trainer/Policy mu Max              3.25834
trainer/Policy mu Min             -3.21344
trainer/Policy log std Mean       -1.92746
trainer/Policy log std Std         0.42018
trainer/Policy log std Max        -0.335925
trainer/Policy log std Min        -2.26751
trainer/Alpha                      0.0410915
trainer/Alpha Loss                -0.879411
exploration/num steps total    16000
exploration/num paths total      160
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.452147
exploration/Rewards Std            1.21228
exploration/Rewards Max           -0.0118647
exploration/Rewards Min           -8.89676
exploration/Returns Mean         -45.2147
exploration/Returns Std           14.3994
exploration/Returns Max          -30.8154
exploration/Returns Min          -59.6141
exploration/Actions Mean           0.039003
exploration/Actions Std            0.274301
exploration/Actions Max            0.999176
exploration/Actions Min           -0.808368
exploration/Num Paths              2
exploration/Average Returns      -45.2147
evaluation/num steps total     79000
evaluation/num paths total       790
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.182166
evaluation/Rewards Std             0.630283
evaluation/Rewards Max            -0.0438085
evaluation/Rewards Min            -8.88774
evaluation/Returns Mean          -18.2166
evaluation/Returns Std            12.0486
evaluation/Returns Max            -9.05549
evaluation/Returns Min           -51.7706
evaluation/Actions Mean            0.0166607
evaluation/Actions Std             0.151203
evaluation/Actions Max             0.996619
evaluation/Actions Min            -0.995542
evaluation/Num Paths              10
evaluation/Average Returns       -18.2166
time/data storing (s)              0.00131671
time/evaluation sampling (s)       0.236635
time/exploration sampling (s)      0.0763766
time/logging (s)                   0.00335765
time/saving (s)                    0.00195267
time/training (s)                  0.764673
time/epoch (s)                     1.08431
time/total (s)                    85.7726
Epoch                             78
-----------------------------  --------------
2019-04-21 00:45:39.311725 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 79 finished
-----------------------------  --------------
replay_buffer/size             16200
trainer/QF1 Loss                   0.133222
trainer/QF2 Loss                   0.105294
trainer/Policy Loss               16.2789
trainer/Q1 Predictions Mean      -14.871
trainer/Q1 Predictions Std         6.39392
trainer/Q1 Predictions Max       -13.6554
trainer/Q1 Predictions Min       -77.4506
trainer/Q2 Predictions Mean      -14.9091
trainer/Q2 Predictions Std         6.42187
trainer/Q2 Predictions Max       -13.6765
trainer/Q2 Predictions Min       -77.7594
trainer/Q Targets Mean           -14.973
trainer/Q Targets Std              6.41083
trainer/Q Targets Max            -13.7036
trainer/Q Targets Min            -77.8606
trainer/Log Pis Mean               1.78734
trainer/Log Pis Std                1.14072
trainer/Log Pis Max                4.60935
trainer/Log Pis Min               -4.47581
trainer/Policy mu Mean             0.138092
trainer/Policy mu Std              0.662054
trainer/Policy mu Max              3.11142
trainer/Policy mu Min             -2.02236
trainer/Policy log std Mean       -1.99667
trainer/Policy log std Std         0.386654
trainer/Policy log std Max        -0.671076
trainer/Policy log std Min        -2.3617
trainer/Alpha                      0.0408176
trainer/Alpha Loss                -0.680208
exploration/num steps total    16200
exploration/num paths total      162
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.280459
exploration/Rewards Std            0.581718
exploration/Rewards Max           -0.00885241
exploration/Rewards Min           -5.58882
exploration/Returns Mean         -28.0459
exploration/Returns Std            8.4512
exploration/Returns Max          -19.5947
exploration/Returns Min          -36.4971
exploration/Actions Mean           0.0112203
exploration/Actions Std            0.2057
exploration/Actions Max            0.997623
exploration/Actions Min           -0.921736
exploration/Num Paths              2
exploration/Average Returns      -28.0459
evaluation/num steps total     80000
evaluation/num paths total       800
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.391638
evaluation/Rewards Std             1.1444
evaluation/Rewards Max            -0.12439
evaluation/Rewards Min           -11.0658
evaluation/Returns Mean          -39.1638
evaluation/Returns Std            19.5456
evaluation/Returns Max           -19.7006
evaluation/Returns Min           -74.0265
evaluation/Actions Mean            0.031711
evaluation/Actions Std             0.201583
evaluation/Actions Max             0.997412
evaluation/Actions Min            -0.990722
evaluation/Num Paths              10
evaluation/Average Returns       -39.1638
time/data storing (s)              0.00141149
time/evaluation sampling (s)       0.229451
time/exploration sampling (s)      0.0706204
time/logging (s)                   0.0033703
time/saving (s)                    0.00186073
time/training (s)                  0.769
time/epoch (s)                     1.07571
time/total (s)                    86.8523
Epoch                             79
-----------------------------  --------------
2019-04-21 00:45:40.386844 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 80 finished
-----------------------------  --------------
replay_buffer/size             16400
trainer/QF1 Loss                   0.454901
trainer/QF2 Loss                   0.437303
trainer/Policy Loss               19.0196
trainer/Q1 Predictions Mean      -17.4416
trainer/Q1 Predictions Std        11.5319
trainer/Q1 Predictions Max       -13.6112
trainer/Q1 Predictions Min       -76.9629
trainer/Q2 Predictions Mean      -17.4353
trainer/Q2 Predictions Std        11.5333
trainer/Q2 Predictions Max       -13.5951
trainer/Q2 Predictions Min       -77.0793
trainer/Q Targets Mean           -17.6311
trainer/Q Targets Std             11.9924
trainer/Q Targets Max            -13.6092
trainer/Q Targets Min            -80.1346
trainer/Log Pis Mean               2.15242
trainer/Log Pis Std                1.44534
trainer/Log Pis Max                7.05388
trainer/Log Pis Min               -1.22078
trainer/Policy mu Mean             0.108906
trainer/Policy mu Std              0.91311
trainer/Policy mu Max              3.25171
trainer/Policy mu Min             -3.0047
trainer/Policy log std Mean       -1.87928
trainer/Policy log std Std         0.429875
trainer/Policy log std Max        -0.391277
trainer/Policy log std Min        -2.27709
trainer/Alpha                      0.0411598
trainer/Alpha Loss                 0.486304
exploration/num steps total    16400
exploration/num paths total      164
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.39914
exploration/Rewards Std            1.13787
exploration/Rewards Max           -0.0262943
exploration/Rewards Min           -9.61354
exploration/Returns Mean         -39.914
exploration/Returns Std           18.9846
exploration/Returns Max          -20.9294
exploration/Returns Min          -58.8985
exploration/Actions Mean           0.0459091
exploration/Actions Std            0.258991
exploration/Actions Max            0.999641
exploration/Actions Min           -0.468947
exploration/Num Paths              2
exploration/Average Returns      -39.914
evaluation/num steps total     81000
evaluation/num paths total       810
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.271906
evaluation/Rewards Std             0.763115
evaluation/Rewards Max            -0.0922985
evaluation/Rewards Min            -8.41814
evaluation/Returns Mean          -27.1906
evaluation/Returns Std            11.7971
evaluation/Returns Max           -13.8428
evaluation/Returns Min           -52.7926
evaluation/Actions Mean            0.0239835
evaluation/Actions Std             0.169447
evaluation/Actions Max             0.995442
evaluation/Actions Min            -0.990141
evaluation/Num Paths              10
evaluation/Average Returns       -27.1906
time/data storing (s)              0.0013215
time/evaluation sampling (s)       0.231818
time/exploration sampling (s)      0.0665867
time/logging (s)                   0.00334792
time/saving (s)                    0.00192782
time/training (s)                  0.764526
time/epoch (s)                     1.06953
time/total (s)                    87.926
Epoch                             80
-----------------------------  --------------
2019-04-21 00:45:41.465685 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 81 finished
-----------------------------  --------------
replay_buffer/size             16600
trainer/QF1 Loss                   0.122803
trainer/QF2 Loss                   0.125595
trainer/Policy Loss               16.2236
trainer/Q1 Predictions Mean      -15.0276
trainer/Q1 Predictions Std         5.5281
trainer/Q1 Predictions Max       -13.6096
trainer/Q1 Predictions Min       -64.9965
trainer/Q2 Predictions Mean      -15.0354
trainer/Q2 Predictions Std         5.51905
trainer/Q2 Predictions Max       -13.6065
trainer/Q2 Predictions Min       -64.989
trainer/Q Targets Mean           -15.0169
trainer/Q Targets Std              5.56052
trainer/Q Targets Max            -13.5545
trainer/Q Targets Min            -65.4221
trainer/Log Pis Mean               1.648
trainer/Log Pis Std                1.13049
trainer/Log Pis Max                6.75228
trainer/Log Pis Min               -2.12952
trainer/Policy mu Mean             0.0749495
trainer/Policy mu Std              0.657457
trainer/Policy mu Max              3.02691
trainer/Policy mu Min             -2.35718
trainer/Policy log std Mean       -1.94046
trainer/Policy log std Std         0.340387
trainer/Policy log std Max        -0.4756
trainer/Policy log std Min        -2.25157
trainer/Alpha                      0.0402275
trainer/Alpha Loss                -1.13094
exploration/num steps total    16600
exploration/num paths total      166
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.373079
exploration/Rewards Std            1.10661
exploration/Rewards Max           -0.00714016
exploration/Rewards Min           -8.72177
exploration/Returns Mean         -37.3079
exploration/Returns Std           20.1433
exploration/Returns Max          -17.1646
exploration/Returns Min          -57.4512
exploration/Actions Mean           0.0280837
exploration/Actions Std            0.237215
exploration/Actions Max            0.999587
exploration/Actions Min           -0.773614
exploration/Num Paths              2
exploration/Average Returns      -37.3079
evaluation/num steps total     82000
evaluation/num paths total       820
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.760109
evaluation/Rewards Std             1.68573
evaluation/Rewards Max            -0.06749
evaluation/Rewards Min           -10.4442
evaluation/Returns Mean          -76.0109
evaluation/Returns Std           124.29
evaluation/Returns Max           -11.1624
evaluation/Returns Min          -445.693
evaluation/Actions Mean            0.121961
evaluation/Actions Std             0.333478
evaluation/Actions Max             0.997835
evaluation/Actions Min            -0.994675
evaluation/Num Paths              10
evaluation/Average Returns       -76.0109
time/data storing (s)              0.00129088
time/evaluation sampling (s)       0.231199
time/exploration sampling (s)      0.0677737
time/logging (s)                   0.00335253
time/saving (s)                    0.00159495
time/training (s)                  0.767814
time/epoch (s)                     1.07303
time/total (s)                    89.0031
Epoch                             81
-----------------------------  --------------
2019-04-21 00:45:42.554296 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 82 finished
-----------------------------  --------------
replay_buffer/size             16800
trainer/QF1 Loss                   7.2988
trainer/QF2 Loss                   7.33457
trainer/Policy Loss               16.5325
trainer/Q1 Predictions Mean      -14.8907
trainer/Q1 Predictions Std         6.06958
trainer/Q1 Predictions Max       -13.4356
trainer/Q1 Predictions Min       -68.7179
trainer/Q2 Predictions Mean      -14.919
trainer/Q2 Predictions Std         6.05249
trainer/Q2 Predictions Max       -13.4542
trainer/Q2 Predictions Min       -68.4787
trainer/Q Targets Mean           -14.4569
trainer/Q Targets Std              6.70075
trainer/Q Targets Max             -0.127826
trainer/Q Targets Min            -68.8668
trainer/Log Pis Mean               2.05923
trainer/Log Pis Std                1.23009
trainer/Log Pis Max                8.6381
trainer/Log Pis Min               -1.2522
trainer/Policy mu Mean             0.134801
trainer/Policy mu Std              0.656484
trainer/Policy mu Max              3.18836
trainer/Policy mu Min             -2.35163
trainer/Policy log std Mean       -2.07456
trainer/Policy log std Std         0.353391
trainer/Policy log std Max        -0.499547
trainer/Policy log std Min        -2.40012
trainer/Alpha                      0.0393993
trainer/Alpha Loss                 0.191538
exploration/num steps total    16800
exploration/num paths total      168
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.269466
exploration/Rewards Std            0.514225
exploration/Rewards Max           -0.00484984
exploration/Rewards Min           -3.66576
exploration/Returns Mean         -26.9466
exploration/Returns Std            4.11452
exploration/Returns Max          -22.832
exploration/Returns Min          -31.0611
exploration/Actions Mean           0.0360273
exploration/Actions Std            0.23885
exploration/Actions Max            0.999319
exploration/Actions Min           -0.488013
exploration/Num Paths              2
exploration/Average Returns      -26.9466
evaluation/num steps total     83000
evaluation/num paths total       830
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.27023
evaluation/Rewards Std             0.928137
evaluation/Rewards Max            -0.080254
evaluation/Rewards Min            -9.33594
evaluation/Returns Mean          -27.023
evaluation/Returns Std            12.1437
evaluation/Returns Max            -9.31538
evaluation/Returns Min           -47.8335
evaluation/Actions Mean            0.0327467
evaluation/Actions Std             0.196215
evaluation/Actions Max             0.997765
evaluation/Actions Min            -0.994475
evaluation/Num Paths              10
evaluation/Average Returns       -27.023
time/data storing (s)              0.00151364
time/evaluation sampling (s)       0.229771
time/exploration sampling (s)      0.0861158
time/logging (s)                   0.00341998
time/saving (s)                    0.00172292
time/training (s)                  0.760317
time/epoch (s)                     1.08286
time/total (s)                    90.09
Epoch                             82
-----------------------------  --------------
2019-04-21 00:45:43.630583 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 83 finished
-----------------------------  --------------
replay_buffer/size             17000
trainer/QF1 Loss                   0.296904
trainer/QF2 Loss                   0.310316
trainer/Policy Loss               16.6023
trainer/Q1 Predictions Mean      -15.0087
trainer/Q1 Predictions Std         6.72616
trainer/Q1 Predictions Max       -13.2602
trainer/Q1 Predictions Min       -65.6469
trainer/Q2 Predictions Mean      -14.9802
trainer/Q2 Predictions Std         6.70446
trainer/Q2 Predictions Max       -13.2287
trainer/Q2 Predictions Min       -65.0582
trainer/Q Targets Mean           -15.2395
trainer/Q Targets Std              6.96443
trainer/Q Targets Max            -13.3227
trainer/Q Targets Min            -66.6834
trainer/Log Pis Mean               1.86033
trainer/Log Pis Std                1.37054
trainer/Log Pis Max                7.92421
trainer/Log Pis Min               -1.58787
trainer/Policy mu Mean             0.129737
trainer/Policy mu Std              0.702539
trainer/Policy mu Max              3.57628
trainer/Policy mu Min             -3.30197
trainer/Policy log std Mean       -2.0152
trainer/Policy log std Std         0.347262
trainer/Policy log std Max        -0.288908
trainer/Policy log std Min        -2.29767
trainer/Alpha                      0.0384543
trainer/Alpha Loss                -0.455036
exploration/num steps total    17000
exploration/num paths total      170
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.37343
exploration/Rewards Std            0.993743
exploration/Rewards Max           -0.017396
exploration/Rewards Min           -8.07364
exploration/Returns Mean         -37.343
exploration/Returns Std           16.709
exploration/Returns Max          -20.634
exploration/Returns Min          -54.052
exploration/Actions Mean           0.0322429
exploration/Actions Std            0.243486
exploration/Actions Max            0.997719
exploration/Actions Min           -0.626998
exploration/Num Paths              2
exploration/Average Returns      -37.343
evaluation/num steps total     84000
evaluation/num paths total       840
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.632729
evaluation/Rewards Std             1.39729
evaluation/Rewards Max            -0.0965414
evaluation/Rewards Min           -10.6614
evaluation/Returns Mean          -63.2729
evaluation/Returns Std           108.978
evaluation/Returns Max            -9.74647
evaluation/Returns Min          -387.362
evaluation/Actions Mean            0.094644
evaluation/Actions Std             0.309332
evaluation/Actions Max             0.995986
evaluation/Actions Min            -0.997031
evaluation/Num Paths              10
evaluation/Average Returns       -63.2729
time/data storing (s)              0.00130521
time/evaluation sampling (s)       0.227807
time/exploration sampling (s)      0.0719241
time/logging (s)                   0.00332143
time/saving (s)                    0.00194979
time/training (s)                  0.763766
time/epoch (s)                     1.07007
time/total (s)                    91.1644
Epoch                             83
-----------------------------  --------------
2019-04-21 00:45:44.705757 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 84 finished
-----------------------------  --------------
replay_buffer/size             17200
trainer/QF1 Loss                   0.952058
trainer/QF2 Loss                   0.892142
trainer/Policy Loss               17.0543
trainer/Q1 Predictions Mean      -15.4269
trainer/Q1 Predictions Std         8.05205
trainer/Q1 Predictions Max       -13.1986
trainer/Q1 Predictions Min       -67.2863
trainer/Q2 Predictions Mean      -15.4631
trainer/Q2 Predictions Std         8.0488
trainer/Q2 Predictions Max       -13.2305
trainer/Q2 Predictions Min       -66.9615
trainer/Q Targets Mean           -15.8269
trainer/Q Targets Std              8.55357
trainer/Q Targets Max            -13.2945
trainer/Q Targets Min            -71.0731
trainer/Log Pis Mean               1.86342
trainer/Log Pis Std                1.62908
trainer/Log Pis Max                7.50456
trainer/Log Pis Min               -3.23686
trainer/Policy mu Mean             0.0656197
trainer/Policy mu Std              0.746385
trainer/Policy mu Max              3.25623
trainer/Policy mu Min             -3.34863
trainer/Policy log std Mean       -1.98918
trainer/Policy log std Std         0.390154
trainer/Policy log std Max        -0.221395
trainer/Policy log std Min        -2.24991
trainer/Alpha                      0.0371563
trainer/Alpha Loss                -0.449665
exploration/num steps total    17200
exploration/num paths total      172
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.45415
exploration/Rewards Std            2.22824
exploration/Rewards Max           -0.0110009
exploration/Rewards Min          -10.2202
exploration/Returns Mean        -245.415
exploration/Returns Std          178.689
exploration/Returns Max          -66.7253
exploration/Returns Min         -424.104
exploration/Actions Mean           0.427847
exploration/Actions Std            0.477904
exploration/Actions Max            0.999905
exploration/Actions Min           -0.990519
exploration/Num Paths              2
exploration/Average Returns     -245.415
evaluation/num steps total     85000
evaluation/num paths total       850
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.51431
evaluation/Rewards Std             1.34584
evaluation/Rewards Max            -0.0124424
evaluation/Rewards Min            -9.05887
evaluation/Returns Mean          -51.431
evaluation/Returns Std           121.052
evaluation/Returns Max            -3.16814
evaluation/Returns Min          -413.26
evaluation/Actions Mean            0.104485
evaluation/Actions Std             0.2989
evaluation/Actions Max             0.997057
evaluation/Actions Min            -0.991741
evaluation/Num Paths              10
evaluation/Average Returns       -51.431
time/data storing (s)              0.00125622
time/evaluation sampling (s)       0.227155
time/exploration sampling (s)      0.0651385
time/logging (s)                   0.00285322
time/saving (s)                    0.00202177
time/training (s)                  0.770439
time/epoch (s)                     1.06886
time/total (s)                    92.2371
Epoch                             84
-----------------------------  --------------
2019-04-21 00:45:45.793351 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 85 finished
-----------------------------  --------------
replay_buffer/size             17400
trainer/QF1 Loss                   2.35537
trainer/QF2 Loss                   2.42251
trainer/Policy Loss               16.5955
trainer/Q1 Predictions Mean      -15.5379
trainer/Q1 Predictions Std         7.47221
trainer/Q1 Predictions Max       -13.2034
trainer/Q1 Predictions Min       -70.4942
trainer/Q2 Predictions Mean      -15.5173
trainer/Q2 Predictions Std         7.50164
trainer/Q2 Predictions Max       -13.2191
trainer/Q2 Predictions Min       -70.4364
trainer/Q Targets Mean           -15.5404
trainer/Q Targets Std              7.75345
trainer/Q Targets Max             -1.25387
trainer/Q Targets Min            -71.7373
trainer/Log Pis Mean               1.49614
trainer/Log Pis Std                1.67049
trainer/Log Pis Max                8.57362
trainer/Log Pis Min               -5.25467
trainer/Policy mu Mean             0.0419598
trainer/Policy mu Std              0.831785
trainer/Policy mu Max              3.51983
trainer/Policy mu Min             -3.24674
trainer/Policy log std Mean       -1.83748
trainer/Policy log std Std         0.426244
trainer/Policy log std Max        -0.206056
trainer/Policy log std Min        -2.24623
trainer/Alpha                      0.0362066
trainer/Alpha Loss                -1.67186
exploration/num steps total    17400
exploration/num paths total      174
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.630036
exploration/Rewards Std            1.55011
exploration/Rewards Max           -0.0114521
exploration/Rewards Min           -9.85624
exploration/Returns Mean         -63.0036
exploration/Returns Std           10.3803
exploration/Returns Max          -52.6232
exploration/Returns Min          -73.3839
exploration/Actions Mean           0.0312112
exploration/Actions Std            0.290803
exploration/Actions Max            0.999348
exploration/Actions Min           -0.998818
exploration/Num Paths              2
exploration/Average Returns      -63.0036
evaluation/num steps total     86000
evaluation/num paths total       860
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.665724
evaluation/Rewards Std             1.30247
evaluation/Rewards Max            -0.125272
evaluation/Rewards Min           -10.3399
evaluation/Returns Mean          -66.5724
evaluation/Returns Std            99.0231
evaluation/Returns Max           -17.6877
evaluation/Returns Min          -360.839
evaluation/Actions Mean            0.0847345
evaluation/Actions Std             0.277905
evaluation/Actions Max             0.996612
evaluation/Actions Min            -0.996331
evaluation/Num Paths              10
evaluation/Average Returns       -66.5724
time/data storing (s)              0.00129178
time/evaluation sampling (s)       0.22876
time/exploration sampling (s)      0.0659696
time/logging (s)                   0.00339094
time/saving (s)                    0.00195006
time/training (s)                  0.782258
time/epoch (s)                     1.08362
time/total (s)                    93.3239
Epoch                             85
-----------------------------  --------------
2019-04-21 00:45:46.880156 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 86 finished
-----------------------------  --------------
replay_buffer/size             17600
trainer/QF1 Loss                   0.462392
trainer/QF2 Loss                   0.41762
trainer/Policy Loss               17.1636
trainer/Q1 Predictions Mean      -15.387
trainer/Q1 Predictions Std         7.01131
trainer/Q1 Predictions Max       -13.2
trainer/Q1 Predictions Min       -55.9675
trainer/Q2 Predictions Mean      -15.3723
trainer/Q2 Predictions Std         6.99704
trainer/Q2 Predictions Max       -13.2011
trainer/Q2 Predictions Min       -55.722
trainer/Q Targets Mean           -15.4574
trainer/Q Targets Std              7.2045
trainer/Q Targets Max            -13.1548
trainer/Q Targets Min            -55.9423
trainer/Log Pis Mean               2.15492
trainer/Log Pis Std                1.45377
trainer/Log Pis Max                7.9763
trainer/Log Pis Min               -3.43742
trainer/Policy mu Mean             0.124094
trainer/Policy mu Std              0.857643
trainer/Policy mu Max              3.12382
trainer/Policy mu Min             -3.21933
trainer/Policy log std Mean       -1.98318
trainer/Policy log std Std         0.461948
trainer/Policy log std Max        -0.324038
trainer/Policy log std Min        -2.39356
trainer/Alpha                      0.0362998
trainer/Alpha Loss                 0.513728
exploration/num steps total    17600
exploration/num paths total      176
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.322523
exploration/Rewards Std            0.725029
exploration/Rewards Max           -0.00507978
exploration/Rewards Min           -5.36642
exploration/Returns Mean         -32.2523
exploration/Returns Std            0.933768
exploration/Returns Max          -31.3185
exploration/Returns Min          -33.186
exploration/Actions Mean           0.00152913
exploration/Actions Std            0.239114
exploration/Actions Max            0.996182
exploration/Actions Min           -0.996502
exploration/Num Paths              2
exploration/Average Returns      -32.2523
evaluation/num steps total     87000
evaluation/num paths total       870
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.323685
evaluation/Rewards Std             1.08548
evaluation/Rewards Max            -0.0746377
evaluation/Rewards Min            -9.45269
evaluation/Returns Mean          -32.3685
evaluation/Returns Std            17.7353
evaluation/Returns Max           -11.6121
evaluation/Returns Min           -59.0508
evaluation/Actions Mean            0.038848
evaluation/Actions Std             0.191175
evaluation/Actions Max             0.998368
evaluation/Actions Min            -0.984055
evaluation/Num Paths              10
evaluation/Average Returns       -32.3685
time/data storing (s)              0.00131826
time/evaluation sampling (s)       0.22805
time/exploration sampling (s)      0.067248
time/logging (s)                   0.00254254
time/saving (s)                    0.00158058
time/training (s)                  0.779827
time/epoch (s)                     1.08057
time/total (s)                    94.4084
Epoch                             86
-----------------------------  --------------
2019-04-21 00:45:48.038568 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 87 finished
-----------------------------  --------------
replay_buffer/size             17800
trainer/QF1 Loss                   2.12296
trainer/QF2 Loss                   2.12946
trainer/Policy Loss               16.7061
trainer/Q1 Predictions Mean      -15.1335
trainer/Q1 Predictions Std         7.39437
trainer/Q1 Predictions Max       -13.0265
trainer/Q1 Predictions Min       -64.0447
trainer/Q2 Predictions Mean      -15.1534
trainer/Q2 Predictions Std         7.38912
trainer/Q2 Predictions Max       -13.0403
trainer/Q2 Predictions Min       -64.1127
trainer/Q Targets Mean           -15.0366
trainer/Q Targets Std              7.6427
trainer/Q Targets Max             -0.176259
trainer/Q Targets Min            -64.6309
trainer/Log Pis Mean               2.00411
trainer/Log Pis Std                1.37571
trainer/Log Pis Max                6.89932
trainer/Log Pis Min               -4.24404
trainer/Policy mu Mean            -0.0284852
trainer/Policy mu Std              0.688481
trainer/Policy mu Max              3.0794
trainer/Policy mu Min             -3.29781
trainer/Policy log std Mean       -2.14171
trainer/Policy log std Std         0.399527
trainer/Policy log std Max        -0.391839
trainer/Policy log std Min        -2.47827
trainer/Alpha                      0.0373013
trainer/Alpha Loss                 0.013522
exploration/num steps total    17800
exploration/num paths total      178
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.328705
exploration/Rewards Std            0.917253
exploration/Rewards Max           -0.0133353
exploration/Rewards Min           -7.02179
exploration/Returns Mean         -32.8705
exploration/Returns Std            8.16692
exploration/Returns Max          -24.7036
exploration/Returns Min          -41.0374
exploration/Actions Mean           0.0165045
exploration/Actions Std            0.234136
exploration/Actions Max            0.998531
exploration/Actions Min           -0.994576
exploration/Num Paths              2
exploration/Average Returns      -32.8705
evaluation/num steps total     88000
evaluation/num paths total       880
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.246466
evaluation/Rewards Std             1.01782
evaluation/Rewards Max            -0.025291
evaluation/Rewards Min            -9.87065
evaluation/Returns Mean          -24.6466
evaluation/Returns Std            14.5314
evaluation/Returns Max            -5.94133
evaluation/Returns Min           -51.9063
evaluation/Actions Mean            0.0373812
evaluation/Actions Std             0.196992
evaluation/Actions Max             0.99836
evaluation/Actions Min            -0.986387
evaluation/Num Paths              10
evaluation/Average Returns       -24.6466
time/data storing (s)              0.00138901
time/evaluation sampling (s)       0.24384
time/exploration sampling (s)      0.066815
time/logging (s)                   0.00334514
time/saving (s)                    0.00157667
time/training (s)                  0.836752
time/epoch (s)                     1.15372
time/total (s)                    95.5664
Epoch                             87
-----------------------------  --------------
2019-04-21 00:45:49.130201 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 88 finished
-----------------------------  --------------
replay_buffer/size             18000
trainer/QF1 Loss                   1.89644
trainer/QF2 Loss                   1.9379
trainer/Policy Loss               17.4843
trainer/Q1 Predictions Mean      -16.0844
trainer/Q1 Predictions Std         9.54183
trainer/Q1 Predictions Max       -12.8584
trainer/Q1 Predictions Min       -67.9748
trainer/Q2 Predictions Mean      -16.055
trainer/Q2 Predictions Std         9.49796
trainer/Q2 Predictions Max       -12.8313
trainer/Q2 Predictions Min       -67.5778
trainer/Q Targets Mean           -16.0263
trainer/Q Targets Std              9.63033
trainer/Q Targets Max             -0.652025
trainer/Q Targets Min            -67.4406
trainer/Log Pis Mean               2.18374
trainer/Log Pis Std                1.5534
trainer/Log Pis Max                7.55956
trainer/Log Pis Min               -2.12963
trainer/Policy mu Mean             0.204695
trainer/Policy mu Std              0.854342
trainer/Policy mu Max              3.18613
trainer/Policy mu Min             -2.73666
trainer/Policy log std Mean       -2.0021
trainer/Policy log std Std         0.478019
trainer/Policy log std Max        -0.524937
trainer/Policy log std Min        -2.4881
trainer/Alpha                      0.0381929
trainer/Alpha Loss                 0.59995
exploration/num steps total    18000
exploration/num paths total      180
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.303364
exploration/Rewards Std            0.749722
exploration/Rewards Max           -0.0181094
exploration/Rewards Min           -5.63376
exploration/Returns Mean         -30.3364
exploration/Returns Std            0.852551
exploration/Returns Max          -29.4839
exploration/Returns Min          -31.189
exploration/Actions Mean           0.0387294
exploration/Actions Std            0.232827
exploration/Actions Max            0.998657
exploration/Actions Min           -0.584588
exploration/Num Paths              2
exploration/Average Returns      -30.3364
evaluation/num steps total     89000
evaluation/num paths total       890
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.287152
evaluation/Rewards Std             1.02183
evaluation/Rewards Max            -0.0677045
evaluation/Rewards Min            -9.55877
evaluation/Returns Mean          -28.7152
evaluation/Returns Std            15.5005
evaluation/Returns Max           -10.545
evaluation/Returns Min           -58.1527
evaluation/Actions Mean            0.0342683
evaluation/Actions Std             0.195837
evaluation/Actions Max             0.996566
evaluation/Actions Min            -0.996276
evaluation/Num Paths              10
evaluation/Average Returns       -28.7152
time/data storing (s)              0.00124968
time/evaluation sampling (s)       0.240257
time/exploration sampling (s)      0.0749924
time/logging (s)                   0.00336719
time/saving (s)                    0.00198235
time/training (s)                  0.763689
time/epoch (s)                     1.08554
time/total (s)                    96.6562
Epoch                             88
-----------------------------  --------------
2019-04-21 00:45:50.217182 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 89 finished
-----------------------------  --------------
replay_buffer/size             18200
trainer/QF1 Loss                   0.746163
trainer/QF2 Loss                   0.664005
trainer/Policy Loss               16.0661
trainer/Q1 Predictions Mean      -14.4966
trainer/Q1 Predictions Std         5.22799
trainer/Q1 Predictions Max       -12.6345
trainer/Q1 Predictions Min       -43.7408
trainer/Q2 Predictions Mean      -14.5074
trainer/Q2 Predictions Std         5.22983
trainer/Q2 Predictions Max       -12.6419
trainer/Q2 Predictions Min       -43.7178
trainer/Q Targets Mean           -14.8477
trainer/Q Targets Std              5.66775
trainer/Q Targets Max            -12.8479
trainer/Q Targets Min            -43.5736
trainer/Log Pis Mean               1.94521
trainer/Log Pis Std                1.57285
trainer/Log Pis Max                8.62555
trainer/Log Pis Min               -1.41989
trainer/Policy mu Mean             0.126314
trainer/Policy mu Std              0.817308
trainer/Policy mu Max              3.43965
trainer/Policy mu Min             -3.31825
trainer/Policy log std Mean       -1.99566
trainer/Policy log std Std         0.466928
trainer/Policy log std Max        -0.128365
trainer/Policy log std Min        -2.41167
trainer/Alpha                      0.0392355
trainer/Alpha Loss                -0.177403
exploration/num steps total    18200
exploration/num paths total      182
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.297859
exploration/Rewards Std            0.681657
exploration/Rewards Max           -0.0136177
exploration/Rewards Min           -6.30856
exploration/Returns Mean         -29.7859
exploration/Returns Std            5.32763
exploration/Returns Max          -24.4583
exploration/Returns Min          -35.1135
exploration/Actions Mean           0.0233212
exploration/Actions Std            0.233274
exploration/Actions Max            0.997382
exploration/Actions Min           -0.969651
exploration/Num Paths              2
exploration/Average Returns      -29.7859
evaluation/num steps total     90000
evaluation/num paths total       900
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.304066
evaluation/Rewards Std             0.919766
evaluation/Rewards Max            -0.0658938
evaluation/Rewards Min            -9.69441
evaluation/Returns Mean          -30.4066
evaluation/Returns Std            12.6157
evaluation/Returns Max           -14.6808
evaluation/Returns Min           -56.2029
evaluation/Actions Mean            0.0277464
evaluation/Actions Std             0.193833
evaluation/Actions Max             0.997184
evaluation/Actions Min            -0.994167
evaluation/Num Paths              10
evaluation/Average Returns       -30.4066
time/data storing (s)              0.00125985
time/evaluation sampling (s)       0.230976
time/exploration sampling (s)      0.0680425
time/logging (s)                   0.00357784
time/saving (s)                    0.0019865
time/training (s)                  0.774988
time/epoch (s)                     1.08083
time/total (s)                    97.7414
Epoch                             89
-----------------------------  --------------
2019-04-21 00:45:51.308336 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 90 finished
-----------------------------  --------------
replay_buffer/size             18400
trainer/QF1 Loss                   2.47211
trainer/QF2 Loss                   2.52363
trainer/Policy Loss               16.0445
trainer/Q1 Predictions Mean      -14.6555
trainer/Q1 Predictions Std         6.44975
trainer/Q1 Predictions Max       -12.616
trainer/Q1 Predictions Min       -66.2214
trainer/Q2 Predictions Mean      -14.6256
trainer/Q2 Predictions Std         6.44953
trainer/Q2 Predictions Max       -12.5903
trainer/Q2 Predictions Min       -66.2066
trainer/Q Targets Mean           -14.7433
trainer/Q Targets Std              6.9006
trainer/Q Targets Max             -0.253206
trainer/Q Targets Min            -68.1002
trainer/Log Pis Mean               1.64379
trainer/Log Pis Std                1.50805
trainer/Log Pis Max                6.21068
trainer/Log Pis Min               -4.78221
trainer/Policy mu Mean             0.0423864
trainer/Policy mu Std              0.788215
trainer/Policy mu Max              3.42485
trainer/Policy mu Min             -2.87132
trainer/Policy log std Mean       -1.94771
trainer/Policy log std Std         0.483414
trainer/Policy log std Max        -0.145569
trainer/Policy log std Min        -2.42868
trainer/Alpha                      0.0401569
trainer/Alpha Loss                -1.14522
exploration/num steps total    18400
exploration/num paths total      184
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.170594
exploration/Rewards Std            0.161037
exploration/Rewards Max           -0.0217377
exploration/Rewards Min           -1.91726
exploration/Returns Mean         -17.0594
exploration/Returns Std            1.08319
exploration/Returns Max          -15.9762
exploration/Returns Min          -18.1426
exploration/Actions Mean           0.00492917
exploration/Actions Std            0.182955
exploration/Actions Max            0.998949
exploration/Actions Min           -0.666368
exploration/Num Paths              2
exploration/Average Returns      -17.0594
evaluation/num steps total     91000
evaluation/num paths total       910
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.291237
evaluation/Rewards Std             1.22106
evaluation/Rewards Max            -0.0194922
evaluation/Rewards Min           -10.4432
evaluation/Returns Mean          -29.1237
evaluation/Returns Std            18.6309
evaluation/Returns Max            -3.06594
evaluation/Returns Min           -58.1812
evaluation/Actions Mean            0.0321946
evaluation/Actions Std             0.201633
evaluation/Actions Max             0.995808
evaluation/Actions Min            -0.997276
evaluation/Num Paths              10
evaluation/Average Returns       -29.1237
time/data storing (s)              0.00130619
time/evaluation sampling (s)       0.226756
time/exploration sampling (s)      0.070385
time/logging (s)                   0.00335232
time/saving (s)                    0.00192855
time/training (s)                  0.780913
time/epoch (s)                     1.08464
time/total (s)                    98.8304
Epoch                             90
-----------------------------  --------------
2019-04-21 00:45:52.384510 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 91 finished
-----------------------------  --------------
replay_buffer/size             18600
trainer/QF1 Loss                   0.687097
trainer/QF2 Loss                   0.652641
trainer/Policy Loss               17.467
trainer/Q1 Predictions Mean      -15.6424
trainer/Q1 Predictions Std         9.87646
trainer/Q1 Predictions Max       -12.606
trainer/Q1 Predictions Min       -70.6939
trainer/Q2 Predictions Mean      -15.664
trainer/Q2 Predictions Std         9.9026
trainer/Q2 Predictions Max       -12.615
trainer/Q2 Predictions Min       -70.4824
trainer/Q Targets Mean           -15.8763
trainer/Q Targets Std             10.3262
trainer/Q Targets Max            -12.5956
trainer/Q Targets Min            -73.6672
trainer/Log Pis Mean               2.29874
trainer/Log Pis Std                1.31032
trainer/Log Pis Max                7.09099
trainer/Log Pis Min               -1.39802
trainer/Policy mu Mean             0.169402
trainer/Policy mu Std              0.857354
trainer/Policy mu Max              3.89261
trainer/Policy mu Min             -3.23013
trainer/Policy log std Mean       -1.99498
trainer/Policy log std Std         0.479828
trainer/Policy log std Max        -0.152418
trainer/Policy log std Min        -2.45192
trainer/Alpha                      0.0410232
trainer/Alpha Loss                 0.954136
exploration/num steps total    18600
exploration/num paths total      186
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.480094
exploration/Rewards Std            1.33264
exploration/Rewards Max           -0.0223119
exploration/Rewards Min          -10.1211
exploration/Returns Mean         -48.0094
exploration/Returns Std           25.0517
exploration/Returns Max          -22.9577
exploration/Returns Min          -73.061
exploration/Actions Mean           0.0455575
exploration/Actions Std            0.243791
exploration/Actions Max            0.999459
exploration/Actions Min           -0.422738
exploration/Num Paths              2
exploration/Average Returns      -48.0094
evaluation/num steps total     92000
evaluation/num paths total       920
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.309029
evaluation/Rewards Std             0.793371
evaluation/Rewards Max            -0.0758682
evaluation/Rewards Min            -8.98264
evaluation/Returns Mean          -30.9029
evaluation/Returns Std            14.9267
evaluation/Returns Max           -18.5569
evaluation/Returns Min           -61.6885
evaluation/Actions Mean            0.0255131
evaluation/Actions Std             0.161195
evaluation/Actions Max             0.996722
evaluation/Actions Min            -0.993241
evaluation/Num Paths              10
evaluation/Average Returns       -30.9029
time/data storing (s)              0.00123612
time/evaluation sampling (s)       0.228105
time/exploration sampling (s)      0.0655434
time/logging (s)                   0.00332804
time/saving (s)                    0.00181973
time/training (s)                  0.769692
time/epoch (s)                     1.06972
time/total (s)                    99.9047
Epoch                             91
-----------------------------  --------------
2019-04-21 00:45:53.466932 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 92 finished
-----------------------------  --------------
replay_buffer/size             18800
trainer/QF1 Loss                   1.91109
trainer/QF2 Loss                   1.94301
trainer/Policy Loss               16.1893
trainer/Q1 Predictions Mean      -14.789
trainer/Q1 Predictions Std         8.43574
trainer/Q1 Predictions Max       -12.3345
trainer/Q1 Predictions Min       -69.7572
trainer/Q2 Predictions Mean      -14.7789
trainer/Q2 Predictions Std         8.43167
trainer/Q2 Predictions Max       -12.3535
trainer/Q2 Predictions Min       -69.5617
trainer/Q Targets Mean           -14.9476
trainer/Q Targets Std              8.65141
trainer/Q Targets Max             -0.406135
trainer/Q Targets Min            -71.3898
trainer/Log Pis Mean               1.92426
trainer/Log Pis Std                1.203
trainer/Log Pis Max                6.26321
trainer/Log Pis Min               -1.49605
trainer/Policy mu Mean             0.0713645
trainer/Policy mu Std              0.721836
trainer/Policy mu Max              3.24007
trainer/Policy mu Min             -2.74064
trainer/Policy log std Mean       -2.02305
trainer/Policy log std Std         0.443026
trainer/Policy log std Max        -0.36097
trainer/Policy log std Min        -2.49074
trainer/Alpha                      0.0408311
trainer/Alpha Loss                -0.242224
exploration/num steps total    18800
exploration/num paths total      188
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.301202
exploration/Rewards Std            0.708167
exploration/Rewards Max           -0.00542445
exploration/Rewards Min           -5.54536
exploration/Returns Mean         -30.1202
exploration/Returns Std            0.685159
exploration/Returns Max          -29.435
exploration/Returns Min          -30.8054
exploration/Actions Mean           0.0182162
exploration/Actions Std            0.243355
exploration/Actions Max            0.995541
exploration/Actions Min           -0.996219
exploration/Num Paths              2
exploration/Average Returns      -30.1202
evaluation/num steps total     93000
evaluation/num paths total       930
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.308282
evaluation/Rewards Std             1.12847
evaluation/Rewards Max            -0.00948878
evaluation/Rewards Min           -10.7168
evaluation/Returns Mean          -30.8282
evaluation/Returns Std            17.5026
evaluation/Returns Max           -11.6458
evaluation/Returns Min           -64.0846
evaluation/Actions Mean            0.02539
evaluation/Actions Std             0.201799
evaluation/Actions Max             0.997751
evaluation/Actions Min            -0.997519
evaluation/Num Paths              10
evaluation/Average Returns       -30.8282
time/data storing (s)              0.00146027
time/evaluation sampling (s)       0.231091
time/exploration sampling (s)      0.0665908
time/logging (s)                   0.00341615
time/saving (s)                    0.00194262
time/training (s)                  0.772362
time/epoch (s)                     1.07686
time/total (s)                   100.985
Epoch                             92
-----------------------------  --------------
2019-04-21 00:45:54.554857 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 93 finished
-----------------------------  --------------
replay_buffer/size             19000
trainer/QF1 Loss                   1.86723
trainer/QF2 Loss                   1.8381
trainer/Policy Loss               15.7121
trainer/Q1 Predictions Mean      -14.2106
trainer/Q1 Predictions Std         5.53767
trainer/Q1 Predictions Max       -12.3872
trainer/Q1 Predictions Min       -50.7921
trainer/Q2 Predictions Mean      -14.19
trainer/Q2 Predictions Std         5.51226
trainer/Q2 Predictions Max       -12.3862
trainer/Q2 Predictions Min       -50.4286
trainer/Q Targets Mean           -14.271
trainer/Q Targets Std              5.75671
trainer/Q Targets Max             -0.535433
trainer/Q Targets Min            -51.4939
trainer/Log Pis Mean               1.84131
trainer/Log Pis Std                1.24484
trainer/Log Pis Max                5.79234
trainer/Log Pis Min               -2.4378
trainer/Policy mu Mean             0.0527052
trainer/Policy mu Std              0.76058
trainer/Policy mu Max              3.41866
trainer/Policy mu Min             -2.39357
trainer/Policy log std Mean       -1.99458
trainer/Policy log std Std         0.423553
trainer/Policy log std Max        -0.25259
trainer/Policy log std Min        -2.46801
trainer/Alpha                      0.040409
trainer/Alpha Loss                -0.509195
exploration/num steps total    19000
exploration/num paths total      190
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.235194
exploration/Rewards Std            0.572121
exploration/Rewards Max           -0.0119726
exploration/Rewards Min           -5.65929
exploration/Returns Mean         -23.5194
exploration/Returns Std            7.68427
exploration/Returns Max          -15.8351
exploration/Returns Min          -31.2036
exploration/Actions Mean           0.0275066
exploration/Actions Std            0.205851
exploration/Actions Max            0.998666
exploration/Actions Min           -0.468439
exploration/Num Paths              2
exploration/Average Returns      -23.5194
evaluation/num steps total     94000
evaluation/num paths total       940
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.232392
evaluation/Rewards Std             0.990915
evaluation/Rewards Max            -0.0339784
evaluation/Rewards Min            -9.24568
evaluation/Returns Mean          -23.2392
evaluation/Returns Std            14.8954
evaluation/Returns Max            -3.66078
evaluation/Returns Min           -50.5376
evaluation/Actions Mean            0.0202774
evaluation/Actions Std             0.193933
evaluation/Actions Max             0.996705
evaluation/Actions Min            -0.997001
evaluation/Num Paths              10
evaluation/Average Returns       -23.2392
time/data storing (s)              0.00139914
time/evaluation sampling (s)       0.227819
time/exploration sampling (s)      0.0709059
time/logging (s)                   0.00263549
time/saving (s)                    0.00199246
time/training (s)                  0.776151
time/epoch (s)                     1.0809
time/total (s)                   102.07
Epoch                             93
-----------------------------  --------------
2019-04-21 00:45:55.637746 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 94 finished
-----------------------------  --------------
replay_buffer/size             19200
trainer/QF1 Loss                   6.37016
trainer/QF2 Loss                   6.3834
trainer/Policy Loss               15.663
trainer/Q1 Predictions Mean      -14.1454
trainer/Q1 Predictions Std         4.93371
trainer/Q1 Predictions Max       -12.3542
trainer/Q1 Predictions Min       -47.1028
trainer/Q2 Predictions Mean      -14.1325
trainer/Q2 Predictions Std         4.93522
trainer/Q2 Predictions Max       -12.3945
trainer/Q2 Predictions Min       -47.2405
trainer/Q Targets Mean           -13.7014
trainer/Q Targets Std              5.63546
trainer/Q Targets Max             -0.148102
trainer/Q Targets Min            -45.3851
trainer/Log Pis Mean               1.9278
trainer/Log Pis Std                1.10348
trainer/Log Pis Max                5.28447
trainer/Log Pis Min               -1.77402
trainer/Policy mu Mean             0.114946
trainer/Policy mu Std              0.743401
trainer/Policy mu Max              3.33956
trainer/Policy mu Min             -2.55496
trainer/Policy log std Mean       -2.00829
trainer/Policy log std Std         0.436971
trainer/Policy log std Max        -0.296923
trainer/Policy log std Min        -2.46685
trainer/Alpha                      0.0398763
trainer/Alpha Loss                -0.232615
exploration/num steps total    19200
exploration/num paths total      192
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.278386
exploration/Rewards Std            0.666797
exploration/Rewards Max           -0.008706
exploration/Rewards Min           -6.02304
exploration/Returns Mean         -27.8386
exploration/Returns Std            7.42981
exploration/Returns Max          -20.4088
exploration/Returns Min          -35.2684
exploration/Actions Mean           0.0019529
exploration/Actions Std            0.224715
exploration/Actions Max            0.997551
exploration/Actions Min           -0.999384
exploration/Num Paths              2
exploration/Average Returns      -27.8386
evaluation/num steps total     95000
evaluation/num paths total       950
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.338483
evaluation/Rewards Std             1.13696
evaluation/Rewards Max            -0.0200585
evaluation/Rewards Min            -9.09883
evaluation/Returns Mean          -33.8483
evaluation/Returns Std            14.7722
evaluation/Returns Max            -9.90937
evaluation/Returns Min           -50.06
evaluation/Actions Mean            0.0289394
evaluation/Actions Std             0.202986
evaluation/Actions Max             0.996413
evaluation/Actions Min            -0.997095
evaluation/Num Paths              10
evaluation/Average Returns       -33.8483
time/data storing (s)              0.00139991
time/evaluation sampling (s)       0.231111
time/exploration sampling (s)      0.0761106
time/logging (s)                   0.00332545
time/saving (s)                    0.0019455
time/training (s)                  0.763473
time/epoch (s)                     1.07737
time/total (s)                   103.152
Epoch                             94
-----------------------------  --------------
2019-04-21 00:45:56.728925 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 95 finished
-----------------------------  --------------
replay_buffer/size             19400
trainer/QF1 Loss                   4.70763
trainer/QF2 Loss                   4.7503
trainer/Policy Loss               15.6623
trainer/Q1 Predictions Mean      -14.0897
trainer/Q1 Predictions Std         8.15367
trainer/Q1 Predictions Max       -12.3135
trainer/Q1 Predictions Min       -80.6792
trainer/Q2 Predictions Mean      -14.0944
trainer/Q2 Predictions Std         8.2025
trainer/Q2 Predictions Max       -12.3019
trainer/Q2 Predictions Min       -81.0207
trainer/Q Targets Mean           -13.7144
trainer/Q Targets Std              8.15545
trainer/Q Targets Max             -0.0812295
trainer/Q Targets Min            -76.7969
trainer/Log Pis Mean               1.97741
trainer/Log Pis Std                1.2746
trainer/Log Pis Max                9.20235
trainer/Log Pis Min               -0.699876
trainer/Policy mu Mean             0.132863
trainer/Policy mu Std              0.660152
trainer/Policy mu Max              3.29272
trainer/Policy mu Min             -2.72306
trainer/Policy log std Mean       -2.05302
trainer/Policy log std Std         0.420582
trainer/Policy log std Max        -0.540517
trainer/Policy log std Min        -2.51934
trainer/Alpha                      0.0394163
trainer/Alpha Loss                -0.0730375
exploration/num steps total    19400
exploration/num paths total      194
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.18993
exploration/Rewards Std            0.305561
exploration/Rewards Max           -0.00544559
exploration/Rewards Min           -3.13732
exploration/Returns Mean         -18.993
exploration/Returns Std            2.7047
exploration/Returns Max          -16.2883
exploration/Returns Min          -21.6977
exploration/Actions Mean          -0.015519
exploration/Actions Std            0.195568
exploration/Actions Max            0.539698
exploration/Actions Min           -0.994117
exploration/Num Paths              2
exploration/Average Returns      -18.993
evaluation/num steps total     96000
evaluation/num paths total       960
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.255792
evaluation/Rewards Std             0.974506
evaluation/Rewards Max            -0.0511114
evaluation/Rewards Min            -9.33579
evaluation/Returns Mean          -25.5792
evaluation/Returns Std            16.1902
evaluation/Returns Max            -7.00933
evaluation/Returns Min           -53.5666
evaluation/Actions Mean            0.0206582
evaluation/Actions Std             0.183396
evaluation/Actions Max             0.998178
evaluation/Actions Min            -0.994761
evaluation/Num Paths              10
evaluation/Average Returns       -25.5792
time/data storing (s)              0.00155853
time/evaluation sampling (s)       0.233028
time/exploration sampling (s)      0.0671653
time/logging (s)                   0.00336464
time/saving (s)                    0.00157626
time/training (s)                  0.778373
time/epoch (s)                     1.08507
time/total (s)                   104.241
Epoch                             95
-----------------------------  --------------
2019-04-21 00:45:57.815409 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 96 finished
-----------------------------  --------------
replay_buffer/size             19600
trainer/QF1 Loss                   2.05473
trainer/QF2 Loss                   1.96928
trainer/Policy Loss               16.2818
trainer/Q1 Predictions Mean      -14.871
trainer/Q1 Predictions Std         8.67998
trainer/Q1 Predictions Max       -12.1004
trainer/Q1 Predictions Min       -60.5402
trainer/Q2 Predictions Mean      -14.904
trainer/Q2 Predictions Std         8.70854
trainer/Q2 Predictions Max       -12.1605
trainer/Q2 Predictions Min       -60.76
trainer/Q Targets Mean           -14.91
trainer/Q Targets Std              8.91918
trainer/Q Targets Max             -0.537134
trainer/Q Targets Min            -60.9354
trainer/Log Pis Mean               1.87392
trainer/Log Pis Std                1.5699
trainer/Log Pis Max                9.07847
trainer/Log Pis Min               -3.9276
trainer/Policy mu Mean            -0.0484634
trainer/Policy mu Std              0.832555
trainer/Policy mu Max              3.09667
trainer/Policy mu Min             -3.37016
trainer/Policy log std Mean       -1.98809
trainer/Policy log std Std         0.454932
trainer/Policy log std Max        -0.255053
trainer/Policy log std Min        -2.49119
trainer/Alpha                      0.0391619
trainer/Alpha Loss                -0.408505
exploration/num steps total    19600
exploration/num paths total      196
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.43054
exploration/Rewards Std            1.2351
exploration/Rewards Max           -0.0156794
exploration/Rewards Min           -9.11054
exploration/Returns Mean         -43.054
exploration/Returns Std           15.9297
exploration/Returns Max          -27.1243
exploration/Returns Min          -58.9837
exploration/Actions Mean           0.0468111
exploration/Actions Std            0.238089
exploration/Actions Max            0.998637
exploration/Actions Min           -0.3738
exploration/Num Paths              2
exploration/Average Returns      -43.054
evaluation/num steps total     97000
evaluation/num paths total       970
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.30697
evaluation/Rewards Std             1.23247
evaluation/Rewards Max            -0.00631833
evaluation/Rewards Min           -10.2678
evaluation/Returns Mean          -30.697
evaluation/Returns Std            17.8159
evaluation/Returns Max            -7.173
evaluation/Returns Min           -59.5549
evaluation/Actions Mean            0.0344779
evaluation/Actions Std             0.204537
evaluation/Actions Max             0.998787
evaluation/Actions Min            -0.991328
evaluation/Num Paths              10
evaluation/Average Returns       -30.697
time/data storing (s)              0.00156871
time/evaluation sampling (s)       0.230466
time/exploration sampling (s)      0.0655429
time/logging (s)                   0.00351317
time/saving (s)                    0.00193332
time/training (s)                  0.777431
time/epoch (s)                     1.08046
time/total (s)                   105.326
Epoch                             96
-----------------------------  --------------
2019-04-21 00:45:58.897748 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 97 finished
-----------------------------  --------------
replay_buffer/size             19800
trainer/QF1 Loss                   4.65579
trainer/QF2 Loss                   4.65162
trainer/Policy Loss               17.6788
trainer/Q1 Predictions Mean      -16.3994
trainer/Q1 Predictions Std        12.2924
trainer/Q1 Predictions Max       -12.0659
trainer/Q1 Predictions Min       -70.1699
trainer/Q2 Predictions Mean      -16.4119
trainer/Q2 Predictions Std        12.2992
trainer/Q2 Predictions Max       -12.0793
trainer/Q2 Predictions Min       -70.6108
trainer/Q Targets Mean           -16.1984
trainer/Q Targets Std             12.6006
trainer/Q Targets Max             -0.220909
trainer/Q Targets Min            -70.633
trainer/Log Pis Mean               2.22315
trainer/Log Pis Std                1.88542
trainer/Log Pis Max                9.97419
trainer/Log Pis Min               -1.63004
trainer/Policy mu Mean             0.0326661
trainer/Policy mu Std              0.9411
trainer/Policy mu Max              3.2211
trainer/Policy mu Min             -3.4389
trainer/Policy log std Mean       -1.96952
trainer/Policy log std Std         0.482745
trainer/Policy log std Max        -0.329882
trainer/Policy log std Min        -2.50771
trainer/Alpha                      0.0385648
trainer/Alpha Loss                 0.726435
exploration/num steps total    19800
exploration/num paths total      198
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.425533
exploration/Rewards Std            1.19248
exploration/Rewards Max           -0.0191544
exploration/Rewards Min           -9.03812
exploration/Returns Mean         -42.5533
exploration/Returns Std            8.36398
exploration/Returns Max          -34.1893
exploration/Returns Min          -50.9172
exploration/Actions Mean           0.0603131
exploration/Actions Std            0.262872
exploration/Actions Max            0.997616
exploration/Actions Min           -0.476636
exploration/Num Paths              2
exploration/Average Returns      -42.5533
evaluation/num steps total     98000
evaluation/num paths total       980
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.206235
evaluation/Rewards Std             0.824309
evaluation/Rewards Max            -0.0452522
evaluation/Rewards Min            -8.94984
evaluation/Returns Mean          -20.6235
evaluation/Returns Std            11.8658
evaluation/Returns Max            -9.90743
evaluation/Returns Min           -48.6931
evaluation/Actions Mean            0.0181762
evaluation/Actions Std             0.184066
evaluation/Actions Max             0.997089
evaluation/Actions Min            -0.994502
evaluation/Num Paths              10
evaluation/Average Returns       -20.6235
time/data storing (s)              0.00134887
time/evaluation sampling (s)       0.228513
time/exploration sampling (s)      0.0709822
time/logging (s)                   0.00253901
time/saving (s)                    0.00195674
time/training (s)                  0.769989
time/epoch (s)                     1.07533
time/total (s)                   106.405
Epoch                             97
-----------------------------  --------------
2019-04-21 00:45:59.979704 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 98 finished
-----------------------------  --------------
replay_buffer/size             20000
trainer/QF1 Loss                   0.22992
trainer/QF2 Loss                   0.221394
trainer/Policy Loss               15.1329
trainer/Q1 Predictions Mean      -13.6573
trainer/Q1 Predictions Std         6.58952
trainer/Q1 Predictions Max       -11.9453
trainer/Q1 Predictions Min       -67.7645
trainer/Q2 Predictions Mean      -13.6981
trainer/Q2 Predictions Std         6.63347
trainer/Q2 Predictions Max       -11.9737
trainer/Q2 Predictions Min       -68.1371
trainer/Q Targets Mean           -13.769
trainer/Q Targets Std              6.57014
trainer/Q Targets Max            -12.0435
trainer/Q Targets Min            -69.2579
trainer/Log Pis Mean               1.96673
trainer/Log Pis Std                1.18159
trainer/Log Pis Max                6.06212
trainer/Log Pis Min               -1.33602
trainer/Policy mu Mean             0.00940875
trainer/Policy mu Std              0.665685
trainer/Policy mu Max              3.2062
trainer/Policy mu Min             -3.04301
trainer/Policy log std Mean       -2.1239
trainer/Policy log std Std         0.418008
trainer/Policy log std Max        -0.527939
trainer/Policy log std Min        -2.58586
trainer/Alpha                      0.0388966
trainer/Alpha Loss                -0.108032
exploration/num steps total    20000
exploration/num paths total      200
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.326503
exploration/Rewards Std            0.72167
exploration/Rewards Max           -0.00840078
exploration/Rewards Min           -5.99028
exploration/Returns Mean         -32.6503
exploration/Returns Std            5.88424
exploration/Returns Max          -26.7661
exploration/Returns Min          -38.5346
exploration/Actions Mean           0.00205193
exploration/Actions Std            0.231239
exploration/Actions Max            0.995442
exploration/Actions Min           -0.993278
exploration/Num Paths              2
exploration/Average Returns      -32.6503
evaluation/num steps total     99000
evaluation/num paths total       990
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.298614
evaluation/Rewards Std             0.91831
evaluation/Rewards Max            -0.02764
evaluation/Rewards Min            -8.34653
evaluation/Returns Mean          -29.8614
evaluation/Returns Std             9.88099
evaluation/Returns Max           -16.6734
evaluation/Returns Min           -49.2553
evaluation/Actions Mean            0.0306616
evaluation/Actions Std             0.200851
evaluation/Actions Max             0.998029
evaluation/Actions Min            -0.997651
evaluation/Num Paths              10
evaluation/Average Returns       -29.8614
time/data storing (s)              0.00142023
time/evaluation sampling (s)       0.230138
time/exploration sampling (s)      0.0682624
time/logging (s)                   0.00337795
time/saving (s)                    0.00194596
time/training (s)                  0.77233
time/epoch (s)                     1.07747
time/total (s)                   107.486
Epoch                             98
-----------------------------  --------------
2019-04-21 00:46:01.072121 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 99 finished
-----------------------------  ---------------
replay_buffer/size              20200
trainer/QF1 Loss                    1.79707
trainer/QF2 Loss                    1.80565
trainer/Policy Loss                16.0622
trainer/Q1 Predictions Mean       -14.312
trainer/Q1 Predictions Std          6.34956
trainer/Q1 Predictions Max        -12.1327
trainer/Q1 Predictions Min        -45.5823
trainer/Q2 Predictions Mean       -14.3306
trainer/Q2 Predictions Std          6.31728
trainer/Q2 Predictions Max        -12.1618
trainer/Q2 Predictions Min        -45.4961
trainer/Q Targets Mean            -14.1335
trainer/Q Targets Std               6.55394
trainer/Q Targets Max              -1.48261
trainer/Q Targets Min             -45.0555
trainer/Log Pis Mean                2.20865
trainer/Log Pis Std                 1.61306
trainer/Log Pis Max                 8.49087
trainer/Log Pis Min                -1.27668
trainer/Policy mu Mean              0.134682
trainer/Policy mu Std               0.787118
trainer/Policy mu Max               3.33036
trainer/Policy mu Min              -3.31317
trainer/Policy log std Mean        -2.09673
trainer/Policy log std Std          0.46715
trainer/Policy log std Max         -0.311857
trainer/Policy log std Min         -2.58917
trainer/Alpha                       0.0395746
trainer/Alpha Loss                  0.673893
exploration/num steps total     20200
exploration/num paths total       202
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.371726
exploration/Rewards Std             1.01171
exploration/Rewards Max            -0.0110972
exploration/Rewards Min            -8.27626
exploration/Returns Mean          -37.1726
exploration/Returns Std            14.277
exploration/Returns Max           -22.8956
exploration/Returns Min           -51.4496
exploration/Actions Mean            0.0289487
exploration/Actions Std             0.239139
exploration/Actions Max             0.997772
exploration/Actions Min            -0.975225
exploration/Num Paths               2
exploration/Average Returns       -37.1726
evaluation/num steps total     100000
evaluation/num paths total       1000
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.22788
evaluation/Rewards Std              0.633114
evaluation/Rewards Max             -0.0430316
evaluation/Rewards Min             -7.87385
evaluation/Returns Mean           -22.788
evaluation/Returns Std              8.54116
evaluation/Returns Max            -14.8933
evaluation/Returns Min            -39.1944
evaluation/Actions Mean             0.0107158
evaluation/Actions Std              0.170349
evaluation/Actions Max              0.997031
evaluation/Actions Min             -0.996461
evaluation/Num Paths               10
evaluation/Average Returns        -22.788
time/data storing (s)               0.00132829
time/evaluation sampling (s)        0.231305
time/exploration sampling (s)       0.0758582
time/logging (s)                    0.00335439
time/saving (s)                     0.0019318
time/training (s)                   0.772536
time/epoch (s)                      1.08631
time/total (s)                    108.577
Epoch                              99
-----------------------------  ---------------
2019-04-21 00:46:02.142738 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 100 finished
-----------------------------  ---------------
replay_buffer/size              20400
trainer/QF1 Loss                    1.53552
trainer/QF2 Loss                    1.56845
trainer/Policy Loss                15.8124
trainer/Q1 Predictions Mean       -14.1675
trainer/Q1 Predictions Std          7.64131
trainer/Q1 Predictions Max        -11.8308
trainer/Q1 Predictions Min        -66.829
trainer/Q2 Predictions Mean       -14.1907
trainer/Q2 Predictions Std          7.72424
trainer/Q2 Predictions Max        -11.8329
trainer/Q2 Predictions Min        -67.6047
trainer/Q Targets Mean            -14.1314
trainer/Q Targets Std               7.63587
trainer/Q Targets Max              -0.255696
trainer/Q Targets Min             -66.6266
trainer/Log Pis Mean                2.06539
trainer/Log Pis Std                 1.67626
trainer/Log Pis Max                 9.5678
trainer/Log Pis Min                -2.94596
trainer/Policy mu Mean              0.0871569
trainer/Policy mu Std               0.739893
trainer/Policy mu Max               3.7397
trainer/Policy mu Min              -2.98789
trainer/Policy log std Mean        -2.12504
trainer/Policy log std Std          0.422591
trainer/Policy log std Max         -0.379892
trainer/Policy log std Min         -2.56244
trainer/Alpha                       0.0402856
trainer/Alpha Loss                  0.210011
exploration/num steps total     20400
exploration/num paths total       204
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.265871
exploration/Rewards Std             0.671279
exploration/Rewards Max            -0.00422744
exploration/Rewards Min            -5.15898
exploration/Returns Mean          -26.5871
exploration/Returns Std             0.818762
exploration/Returns Max           -25.7683
exploration/Returns Min           -27.4058
exploration/Actions Mean            0.045842
exploration/Actions Std             0.234121
exploration/Actions Max             0.996188
exploration/Actions Min            -0.465942
exploration/Num Paths               2
exploration/Average Returns       -26.5871
evaluation/num steps total     101000
evaluation/num paths total       1010
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.241981
evaluation/Rewards Std              0.978977
evaluation/Rewards Max             -0.0303703
evaluation/Rewards Min             -8.52318
evaluation/Returns Mean           -24.1981
evaluation/Returns Std             11.7689
evaluation/Returns Max             -5.15035
evaluation/Returns Min            -44.261
evaluation/Actions Mean             0.0181295
evaluation/Actions Std              0.194052
evaluation/Actions Max              0.998001
evaluation/Actions Min             -0.99773
evaluation/Num Paths               10
evaluation/Average Returns        -24.1981
time/data storing (s)               0.00127319
time/evaluation sampling (s)        0.236038
time/exploration sampling (s)       0.0689601
time/logging (s)                    0.00360221
time/saving (s)                     0.00158766
time/training (s)                   0.753302
time/epoch (s)                      1.06476
time/total (s)                    109.645
Epoch                             100
-----------------------------  ---------------
2019-04-21 00:46:03.226599 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 101 finished
-----------------------------  ---------------
replay_buffer/size              20600
trainer/QF1 Loss                    0.203024
trainer/QF2 Loss                    0.208945
trainer/Policy Loss                14.1731
trainer/Q1 Predictions Mean       -12.6812
trainer/Q1 Predictions Std          2.86578
trainer/Q1 Predictions Max        -11.737
trainer/Q1 Predictions Min        -33.735
trainer/Q2 Predictions Mean       -12.6924
trainer/Q2 Predictions Std          2.9107
trainer/Q2 Predictions Max        -11.7551
trainer/Q2 Predictions Min        -33.9528
trainer/Q Targets Mean            -12.8199
trainer/Q Targets Std               2.66387
trainer/Q Targets Max             -11.8357
trainer/Q Targets Min             -30.6436
trainer/Log Pis Mean                1.89301
trainer/Log Pis Std                 1.15847
trainer/Log Pis Max                 5.49951
trainer/Log Pis Min                -1.4745
trainer/Policy mu Mean             -0.00485428
trainer/Policy mu Std               0.507734
trainer/Policy mu Max               2.4484
trainer/Policy mu Min              -2.96262
trainer/Policy log std Mean        -2.18216
trainer/Policy log std Std          0.374309
trainer/Policy log std Max         -0.526549
trainer/Policy log std Min         -2.62129
trainer/Alpha                       0.0414758
trainer/Alpha Loss                 -0.340529
exploration/num steps total     20600
exploration/num paths total       206
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.518294
exploration/Rewards Std             1.45655
exploration/Rewards Max            -0.00293259
exploration/Rewards Min            -9.80421
exploration/Returns Mean          -51.8294
exploration/Returns Std             8.65096
exploration/Returns Max           -43.1784
exploration/Returns Min           -60.4803
exploration/Actions Mean            0.0419891
exploration/Actions Std             0.272694
exploration/Actions Max             0.997579
exploration/Actions Min            -0.999328
exploration/Num Paths               2
exploration/Average Returns       -51.8294
evaluation/num steps total     102000
evaluation/num paths total       1020
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.247755
evaluation/Rewards Std              1.02569
evaluation/Rewards Max             -0.0106668
evaluation/Rewards Min            -11.0779
evaluation/Returns Mean           -24.7755
evaluation/Returns Std             17.7102
evaluation/Returns Max             -6.80834
evaluation/Returns Min            -62.5348
evaluation/Actions Mean             0.0306024
evaluation/Actions Std              0.192621
evaluation/Actions Max              0.998623
evaluation/Actions Min             -0.995994
evaluation/Num Paths               10
evaluation/Average Returns        -24.7755
time/data storing (s)               0.00132222
time/evaluation sampling (s)        0.223271
time/exploration sampling (s)       0.0623592
time/logging (s)                    0.00337996
time/saving (s)                     0.0019587
time/training (s)                   0.785191
time/epoch (s)                      1.07748
time/total (s)                    110.727
Epoch                             101
-----------------------------  ---------------
2019-04-21 00:46:04.304246 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 102 finished
-----------------------------  ---------------
replay_buffer/size              20800
trainer/QF1 Loss                    0.109809
trainer/QF2 Loss                    0.10116
trainer/Policy Loss                14.7762
trainer/Q1 Predictions Mean       -13.1177
trainer/Q1 Predictions Std          4.32013
trainer/Q1 Predictions Max        -11.7029
trainer/Q1 Predictions Min        -40.0446
trainer/Q2 Predictions Mean       -13.1383
trainer/Q2 Predictions Std          4.32817
trainer/Q2 Predictions Max        -11.7255
trainer/Q2 Predictions Min        -40.2112
trainer/Q Targets Mean            -13.1878
trainer/Q Targets Std               4.15273
trainer/Q Targets Max             -11.7449
trainer/Q Targets Min             -38.9626
trainer/Log Pis Mean                1.97844
trainer/Log Pis Std                 1.05624
trainer/Log Pis Max                 5.31017
trainer/Log Pis Min                -1.62708
trainer/Policy mu Mean              0.038443
trainer/Policy mu Std               0.631507
trainer/Policy mu Max               3.24675
trainer/Policy mu Min              -2.90813
trainer/Policy log std Mean        -2.15753
trainer/Policy log std Std          0.419131
trainer/Policy log std Max         -0.444996
trainer/Policy log std Min         -2.61148
trainer/Alpha                       0.0425009
trainer/Alpha Loss                 -0.0680996
exploration/num steps total     20800
exploration/num paths total       208
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.331227
exploration/Rewards Std             0.975932
exploration/Rewards Max            -0.008079
exploration/Rewards Min            -8.13674
exploration/Returns Mean          -33.1227
exploration/Returns Std            13.5911
exploration/Returns Max           -19.5316
exploration/Returns Min           -46.7137
exploration/Actions Mean            0.0267509
exploration/Actions Std             0.232758
exploration/Actions Max             0.996484
exploration/Actions Min            -0.985123
exploration/Num Paths               2
exploration/Average Returns       -33.1227
evaluation/num steps total     103000
evaluation/num paths total       1030
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.210168
evaluation/Rewards Std              1.01643
evaluation/Rewards Max             -0.00861624
evaluation/Rewards Min            -10.1557
evaluation/Returns Mean           -21.0168
evaluation/Returns Std             18.7016
evaluation/Returns Max             -1.98454
evaluation/Returns Min            -59.2629
evaluation/Actions Mean             0.0257965
evaluation/Actions Std              0.173325
evaluation/Actions Max              0.997032
evaluation/Actions Min             -0.997378
evaluation/Num Paths               10
evaluation/Average Returns        -21.0168
time/data storing (s)               0.00127307
time/evaluation sampling (s)        0.222003
time/exploration sampling (s)       0.0652485
time/logging (s)                    0.00271502
time/saving (s)                     0.00197115
time/training (s)                   0.777368
time/epoch (s)                      1.07058
time/total (s)                    111.802
Epoch                             102
-----------------------------  ---------------
2019-04-21 00:46:05.372579 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 103 finished
-----------------------------  ---------------
replay_buffer/size              21000
trainer/QF1 Loss                    4.85523
trainer/QF2 Loss                    4.7096
trainer/Policy Loss                16.5737
trainer/Q1 Predictions Mean       -15.1523
trainer/Q1 Predictions Std         10.4425
trainer/Q1 Predictions Max        -11.6731
trainer/Q1 Predictions Min        -73.2101
trainer/Q2 Predictions Mean       -15.1583
trainer/Q2 Predictions Std         10.5291
trainer/Q2 Predictions Max        -11.6277
trainer/Q2 Predictions Min        -73.7125
trainer/Q Targets Mean            -15.0198
trainer/Q Targets Std              11.2553
trainer/Q Targets Max              -0.11339
trainer/Q Targets Min             -76.0082
trainer/Log Pis Mean                2.03358
trainer/Log Pis Std                 1.51674
trainer/Log Pis Max                 8.7949
trainer/Log Pis Min                -1.83012
trainer/Policy mu Mean              0.0529117
trainer/Policy mu Std               0.866941
trainer/Policy mu Max               3.13907
trainer/Policy mu Min              -3.37515
trainer/Policy log std Mean        -1.94805
trainer/Policy log std Std          0.484327
trainer/Policy log std Max         -0.305108
trainer/Policy log std Min         -2.45256
trainer/Alpha                       0.0425423
trainer/Alpha Loss                  0.106007
exploration/num steps total     21000
exploration/num paths total       210
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.431801
exploration/Rewards Std             1.13752
exploration/Rewards Max            -0.0199334
exploration/Rewards Min            -8.57173
exploration/Returns Mean          -43.1801
exploration/Returns Std            11.6607
exploration/Returns Max           -31.5193
exploration/Returns Min           -54.8408
exploration/Actions Mean            0.0522526
exploration/Actions Std             0.253967
exploration/Actions Max             0.999048
exploration/Actions Min            -0.390473
exploration/Num Paths               2
exploration/Average Returns       -43.1801
evaluation/num steps total     104000
evaluation/num paths total       1040
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.299961
evaluation/Rewards Std              1.14316
evaluation/Rewards Max             -0.0614948
evaluation/Rewards Min            -10.3373
evaluation/Returns Mean           -29.9961
evaluation/Returns Std             19.5437
evaluation/Returns Max             -6.34633
evaluation/Returns Min            -62.0872
evaluation/Actions Mean             0.0172093
evaluation/Actions Std              0.189647
evaluation/Actions Max              0.997777
evaluation/Actions Min             -0.996428
evaluation/Num Paths               10
evaluation/Average Returns        -29.9961
time/data storing (s)               0.00118915
time/evaluation sampling (s)        0.224982
time/exploration sampling (s)       0.0673253
time/logging (s)                    0.0033284
time/saving (s)                     0.00193742
time/training (s)                   0.764138
time/epoch (s)                      1.0629
time/total (s)                    112.869
Epoch                             103
-----------------------------  ---------------
2019-04-21 00:46:06.461767 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 104 finished
-----------------------------  ---------------
replay_buffer/size              21200
trainer/QF1 Loss                    3.15699
trainer/QF2 Loss                    3.18401
trainer/Policy Loss                15.3902
trainer/Q1 Predictions Mean       -13.536
trainer/Q1 Predictions Std          5.17462
trainer/Q1 Predictions Max        -11.6223
trainer/Q1 Predictions Min        -47.8143
trainer/Q2 Predictions Mean       -13.6082
trainer/Q2 Predictions Std          5.20458
trainer/Q2 Predictions Max        -11.6772
trainer/Q2 Predictions Min        -47.9353
trainer/Q Targets Mean            -13.34
trainer/Q Targets Std               5.42911
trainer/Q Targets Max              -0.080533
trainer/Q Targets Min             -46.6473
trainer/Log Pis Mean                2.14635
trainer/Log Pis Std                 1.28967
trainer/Log Pis Max                 7.60101
trainer/Log Pis Min                -1.59554
trainer/Policy mu Mean              0.0575476
trainer/Policy mu Std               0.747283
trainer/Policy mu Max               3.15404
trainer/Policy mu Min              -3.24043
trainer/Policy log std Mean        -2.09245
trainer/Policy log std Std          0.477189
trainer/Policy log std Max         -0.377244
trainer/Policy log std Min         -2.59619
trainer/Alpha                       0.0428186
trainer/Alpha Loss                  0.461118
exploration/num steps total     21200
exploration/num paths total       212
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.328892
exploration/Rewards Std             0.934635
exploration/Rewards Max            -0.00659795
exploration/Rewards Min            -7.74411
exploration/Returns Mean          -32.8892
exploration/Returns Std             7.70303
exploration/Returns Max           -25.1862
exploration/Returns Min           -40.5922
exploration/Actions Mean            0.015923
exploration/Actions Std             0.248224
exploration/Actions Max             0.999331
exploration/Actions Min            -0.999409
exploration/Num Paths               2
exploration/Average Returns       -32.8892
evaluation/num steps total     105000
evaluation/num paths total       1050
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.225938
evaluation/Rewards Std              1.06537
evaluation/Rewards Max             -0.00859674
evaluation/Rewards Min            -10.7524
evaluation/Returns Mean           -22.5938
evaluation/Returns Std             18.8025
evaluation/Returns Max             -5.82178
evaluation/Returns Min            -57.0851
evaluation/Actions Mean             0.0347991
evaluation/Actions Std              0.193014
evaluation/Actions Max              0.998311
evaluation/Actions Min             -0.990332
evaluation/Num Paths               10
evaluation/Average Returns        -22.5938
time/data storing (s)               0.00137025
time/evaluation sampling (s)        0.227264
time/exploration sampling (s)       0.0674256
time/logging (s)                    0.00251817
time/saving (s)                     0.00194665
time/training (s)                   0.781736
time/epoch (s)                      1.08226
time/total (s)                    113.955
Epoch                             104
-----------------------------  ---------------
2019-04-21 00:46:07.543858 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 105 finished
-----------------------------  ---------------
replay_buffer/size              21400
trainer/QF1 Loss                    1.62779
trainer/QF2 Loss                    1.62274
trainer/Policy Loss                14.4827
trainer/Q1 Predictions Mean       -12.8304
trainer/Q1 Predictions Std          4.97407
trainer/Q1 Predictions Max        -11.5555
trainer/Q1 Predictions Min        -57.9509
trainer/Q2 Predictions Mean       -12.8441
trainer/Q2 Predictions Std          4.99647
trainer/Q2 Predictions Max        -11.5658
trainer/Q2 Predictions Min        -58.3117
trainer/Q Targets Mean            -12.7568
trainer/Q Targets Std               5.15545
trainer/Q Targets Max              -0.36765
trainer/Q Targets Min             -58.7091
trainer/Log Pis Mean                1.97681
trainer/Log Pis Std                 1.26556
trainer/Log Pis Max                 8.29399
trainer/Log Pis Min                -3.83586
trainer/Policy mu Mean              0.0550012
trainer/Policy mu Std               0.602298
trainer/Policy mu Max               2.97667
trainer/Policy mu Min              -2.5929
trainer/Policy log std Mean        -2.10285
trainer/Policy log std Std          0.435665
trainer/Policy log std Max         -0.556332
trainer/Policy log std Min         -2.59804
trainer/Alpha                       0.0424703
trainer/Alpha Loss                 -0.0732653
exploration/num steps total     21400
exploration/num paths total       214
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.337434
exploration/Rewards Std             0.967192
exploration/Rewards Max            -0.00934986
exploration/Rewards Min            -8.36171
exploration/Returns Mean          -33.7434
exploration/Returns Std            17.2924
exploration/Returns Max           -16.451
exploration/Returns Min           -51.0359
exploration/Actions Mean            0.037123
exploration/Actions Std             0.222193
exploration/Actions Max             0.997562
exploration/Actions Min            -0.485982
exploration/Num Paths               2
exploration/Average Returns       -33.7434
evaluation/num steps total     106000
evaluation/num paths total       1060
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.307025
evaluation/Rewards Std              1.06945
evaluation/Rewards Max             -0.0448834
evaluation/Rewards Min             -9.98689
evaluation/Returns Mean           -30.7025
evaluation/Returns Std             15.2625
evaluation/Returns Max             -9.91191
evaluation/Returns Min            -53.6068
evaluation/Actions Mean             0.042999
evaluation/Actions Std              0.191436
evaluation/Actions Max              0.998536
evaluation/Actions Min             -0.550548
evaluation/Num Paths               10
evaluation/Average Returns        -30.7025
time/data storing (s)               0.00117072
time/evaluation sampling (s)        0.224668
time/exploration sampling (s)       0.0677869
time/logging (s)                    0.0033258
time/saving (s)                     0.00194035
time/training (s)                   0.778737
time/epoch (s)                      1.07763
time/total (s)                    115.036
Epoch                             105
-----------------------------  ---------------
2019-04-21 00:46:08.621086 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 106 finished
-----------------------------  ---------------
replay_buffer/size              21600
trainer/QF1 Loss                    2.67349
trainer/QF2 Loss                    2.70379
trainer/Policy Loss                14.0348
trainer/Q1 Predictions Mean       -12.3454
trainer/Q1 Predictions Std          3.15996
trainer/Q1 Predictions Max        -11.4042
trainer/Q1 Predictions Min        -37.3591
trainer/Q2 Predictions Mean       -12.376
trainer/Q2 Predictions Std          3.12288
trainer/Q2 Predictions Max        -11.4237
trainer/Q2 Predictions Min        -37.2056
trainer/Q Targets Mean            -12.2653
trainer/Q Targets Std               3.64766
trainer/Q Targets Max              -0.476917
trainer/Q Targets Min             -37.0228
trainer/Log Pis Mean                2.03847
trainer/Log Pis Std                 1.19077
trainer/Log Pis Max                 6.40387
trainer/Log Pis Min                -0.803844
trainer/Policy mu Mean             -0.0121848
trainer/Policy mu Std               0.617527
trainer/Policy mu Max               2.95591
trainer/Policy mu Min              -2.26907
trainer/Policy log std Mean        -2.10727
trainer/Policy log std Std          0.409182
trainer/Policy log std Max         -0.460859
trainer/Policy log std Min         -2.58613
trainer/Alpha                       0.0429193
trainer/Alpha Loss                  0.121125
exploration/num steps total     21600
exploration/num paths total       216
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.346557
exploration/Rewards Std             0.956047
exploration/Rewards Max            -0.0119315
exploration/Rewards Min            -7.66656
exploration/Returns Mean          -34.6557
exploration/Returns Std            12.5013
exploration/Returns Max           -22.1544
exploration/Returns Min           -47.157
exploration/Actions Mean            0.0400269
exploration/Actions Std             0.227644
exploration/Actions Max             0.999568
exploration/Actions Min            -0.453818
exploration/Num Paths               2
exploration/Average Returns       -34.6557
evaluation/num steps total     107000
evaluation/num paths total       1070
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.209557
evaluation/Rewards Std              0.983815
evaluation/Rewards Max             -0.00167107
evaluation/Rewards Min             -9.56025
evaluation/Returns Mean           -20.9557
evaluation/Returns Std             16.0526
evaluation/Returns Max             -4.91064
evaluation/Returns Min            -52.8473
evaluation/Actions Mean             0.0337265
evaluation/Actions Std              0.182399
evaluation/Actions Max              0.997493
evaluation/Actions Min             -0.992484
evaluation/Num Paths               10
evaluation/Average Returns        -20.9557
time/data storing (s)               0.00156544
time/evaluation sampling (s)        0.2315
time/exploration sampling (s)       0.0675506
time/logging (s)                    0.00332526
time/saving (s)                     0.00160784
time/training (s)                   0.765859
time/epoch (s)                      1.07141
time/total (s)                    116.111
Epoch                             106
-----------------------------  ---------------
2019-04-21 00:46:09.692735 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 107 finished
-----------------------------  ----------------
replay_buffer/size              21800
trainer/QF1 Loss                    1.35499
trainer/QF2 Loss                    1.33895
trainer/Policy Loss                14.7137
trainer/Q1 Predictions Mean       -12.9925
trainer/Q1 Predictions Std          6.85999
trainer/Q1 Predictions Max        -11.435
trainer/Q1 Predictions Min        -61.2154
trainer/Q2 Predictions Mean       -12.9616
trainer/Q2 Predictions Std          6.83362
trainer/Q2 Predictions Max        -11.3902
trainer/Q2 Predictions Min        -60.9725
trainer/Q Targets Mean            -12.9257
trainer/Q Targets Std               6.91325
trainer/Q Targets Max              -0.260564
trainer/Q Targets Min             -60.9522
trainer/Log Pis Mean                1.96688
trainer/Log Pis Std                 1.45071
trainer/Log Pis Max                10.1342
trainer/Log Pis Min                -2.28865
trainer/Policy mu Mean              0.0765232
trainer/Policy mu Std               0.608611
trainer/Policy mu Max               3.22962
trainer/Policy mu Min              -2.34916
trainer/Policy log std Mean        -2.14472
trainer/Policy log std Std          0.394716
trainer/Policy log std Max         -0.318221
trainer/Policy log std Min         -2.55987
trainer/Alpha                       0.0428261
trainer/Alpha Loss                 -0.104336
exploration/num steps total     21800
exploration/num paths total       218
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.384561
exploration/Rewards Std             1.04061
exploration/Rewards Max            -0.0162242
exploration/Rewards Min            -7.602
exploration/Returns Mean          -38.4561
exploration/Returns Std             5.0821
exploration/Returns Max           -33.374
exploration/Returns Min           -43.5382
exploration/Actions Mean           -0.000645854
exploration/Actions Std             0.255603
exploration/Actions Max             0.997355
exploration/Actions Min            -0.995701
exploration/Num Paths               2
exploration/Average Returns       -38.4561
evaluation/num steps total     108000
evaluation/num paths total       1080
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.310476
evaluation/Rewards Std              1.21345
evaluation/Rewards Max             -0.0517862
evaluation/Rewards Min            -11.1132
evaluation/Returns Mean           -31.0476
evaluation/Returns Std             20.6639
evaluation/Returns Max             -6.38447
evaluation/Returns Min            -64.0634
evaluation/Actions Mean             0.0312963
evaluation/Actions Std              0.196664
evaluation/Actions Max              0.998453
evaluation/Actions Min             -0.992908
evaluation/Num Paths               10
evaluation/Average Returns        -31.0476
time/data storing (s)               0.00122748
time/evaluation sampling (s)        0.233216
time/exploration sampling (s)       0.0669601
time/logging (s)                    0.00333209
time/saving (s)                     0.00198402
time/training (s)                   0.758794
time/epoch (s)                      1.06551
time/total (s)                    117.181
Epoch                             107
-----------------------------  ----------------
2019-04-21 00:46:10.770675 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 108 finished
-----------------------------  ---------------
replay_buffer/size              22000
trainer/QF1 Loss                    2.77239
trainer/QF2 Loss                    2.77998
trainer/Policy Loss                14.5732
trainer/Q1 Predictions Mean       -13.0033
trainer/Q1 Predictions Std          6.26888
trainer/Q1 Predictions Max        -11.2949
trainer/Q1 Predictions Min        -65.3376
trainer/Q2 Predictions Mean       -13.0191
trainer/Q2 Predictions Std          6.23814
trainer/Q2 Predictions Max        -11.2884
trainer/Q2 Predictions Min        -65.2064
trainer/Q Targets Mean            -12.9105
trainer/Q Targets Std               6.58908
trainer/Q Targets Max              -0.333551
trainer/Q Targets Min             -66.0382
trainer/Log Pis Mean                2.01607
trainer/Log Pis Std                 1.4047
trainer/Log Pis Max                 9.45238
trainer/Log Pis Min                -3.91235
trainer/Policy mu Mean              0.0155992
trainer/Policy mu Std               0.697463
trainer/Policy mu Max               2.91677
trainer/Policy mu Min              -2.95176
trainer/Policy log std Mean        -2.14305
trainer/Policy log std Std          0.448663
trainer/Policy log std Max         -0.551117
trainer/Policy log std Min         -2.59038
trainer/Alpha                       0.0428934
trainer/Alpha Loss                  0.0505943
exploration/num steps total     22000
exploration/num paths total       220
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.352404
exploration/Rewards Std             0.980744
exploration/Rewards Max            -0.00698645
exploration/Rewards Min            -7.19193
exploration/Returns Mean          -35.2404
exploration/Returns Std             3.924
exploration/Returns Max           -31.3164
exploration/Returns Min           -39.1644
exploration/Actions Mean            0.0344958
exploration/Actions Std             0.252428
exploration/Actions Max             0.998207
exploration/Actions Min            -0.997024
exploration/Num Paths               2
exploration/Average Returns       -35.2404
evaluation/num steps total     109000
evaluation/num paths total       1090
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.295534
evaluation/Rewards Std              1.0463
evaluation/Rewards Max             -0.0151789
evaluation/Rewards Min            -10.1032
evaluation/Returns Mean           -29.5534
evaluation/Returns Std             12.017
evaluation/Returns Max            -17.7281
evaluation/Returns Min            -56.1684
evaluation/Actions Mean             0.00632463
evaluation/Actions Std              0.211292
evaluation/Actions Max              0.998126
evaluation/Actions Min             -0.997071
evaluation/Num Paths               10
evaluation/Average Returns        -29.5534
time/data storing (s)               0.00116037
time/evaluation sampling (s)        0.225256
time/exploration sampling (s)       0.0645835
time/logging (s)                    0.00255399
time/saving (s)                     0.00159139
time/training (s)                   0.775638
time/epoch (s)                      1.07078
time/total (s)                    118.256
Epoch                             108
-----------------------------  ---------------
2019-04-21 00:46:11.855523 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 109 finished
-----------------------------  ----------------
replay_buffer/size              22200
trainer/QF1 Loss                    0.193499
trainer/QF2 Loss                    0.178205
trainer/Policy Loss                13.8568
trainer/Q1 Predictions Mean       -12.164
trainer/Q1 Predictions Std          3.25858
trainer/Q1 Predictions Max        -11.3142
trainer/Q1 Predictions Min        -36.3544
trainer/Q2 Predictions Mean       -12.1811
trainer/Q2 Predictions Std          3.29533
trainer/Q2 Predictions Max        -11.3143
trainer/Q2 Predictions Min        -36.7183
trainer/Q Targets Mean            -12.1661
trainer/Q Targets Std               3.50084
trainer/Q Targets Max             -11.233
trainer/Q Targets Min             -39.6949
trainer/Log Pis Mean                1.93853
trainer/Log Pis Std                 1.3045
trainer/Log Pis Max                 7.6763
trainer/Log Pis Min                -3.19366
trainer/Policy mu Mean             -0.0243583
trainer/Policy mu Std               0.531289
trainer/Policy mu Max               2.05409
trainer/Policy mu Min              -3.23288
trainer/Policy log std Mean        -2.13759
trainer/Policy log std Std          0.386413
trainer/Policy log std Max         -0.362495
trainer/Policy log std Min         -2.57292
trainer/Alpha                       0.0434441
trainer/Alpha Loss                 -0.192786
exploration/num steps total     22200
exploration/num paths total       222
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.195859
exploration/Rewards Std             0.403041
exploration/Rewards Max            -0.00123101
exploration/Rewards Min            -3.84955
exploration/Returns Mean          -19.5859
exploration/Returns Std             2.65283
exploration/Returns Max           -16.9331
exploration/Returns Min           -22.2387
exploration/Actions Mean            0.0234576
exploration/Actions Std             0.197225
exploration/Actions Max             0.991845
exploration/Actions Min            -0.762412
exploration/Num Paths               2
exploration/Average Returns       -19.5859
evaluation/num steps total     110000
evaluation/num paths total       1100
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.266749
evaluation/Rewards Std              1.15143
evaluation/Rewards Max             -9.29076e-05
evaluation/Rewards Min            -10.1868
evaluation/Returns Mean           -26.6749
evaluation/Returns Std             14.4223
evaluation/Returns Max             -9.32564
evaluation/Returns Min            -56.9595
evaluation/Actions Mean             0.0330581
evaluation/Actions Std              0.199631
evaluation/Actions Max              0.996918
evaluation/Actions Min             -0.989266
evaluation/Num Paths               10
evaluation/Average Returns        -26.6749
time/data storing (s)               0.00130533
time/evaluation sampling (s)        0.227338
time/exploration sampling (s)       0.0669819
time/logging (s)                    0.00332164
time/saving (s)                     0.00196076
time/training (s)                   0.779538
time/epoch (s)                      1.08045
time/total (s)                    119.34
Epoch                             109
-----------------------------  ----------------
2019-04-21 00:46:12.988688 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 110 finished
-----------------------------  ---------------
replay_buffer/size              22400
trainer/QF1 Loss                    1.56514
trainer/QF2 Loss                    1.57518
trainer/Policy Loss                14.8118
trainer/Q1 Predictions Mean       -12.8193
trainer/Q1 Predictions Std          4.63491
trainer/Q1 Predictions Max        -11.1984
trainer/Q1 Predictions Min        -42.4678
trainer/Q2 Predictions Mean       -12.7926
trainer/Q2 Predictions Std          4.61556
trainer/Q2 Predictions Max        -11.181
trainer/Q2 Predictions Min        -42.5581
trainer/Q Targets Mean            -12.7978
trainer/Q Targets Std               5.05854
trainer/Q Targets Max              -0.057511
trainer/Q Targets Min             -43.7587
trainer/Log Pis Mean                2.3496
trainer/Log Pis Std                 1.15999
trainer/Log Pis Max                 7.12544
trainer/Log Pis Min                -0.372209
trainer/Policy mu Mean              0.103365
trainer/Policy mu Std               0.696881
trainer/Policy mu Max               3.33923
trainer/Policy mu Min              -2.24709
trainer/Policy log std Mean        -2.1079
trainer/Policy log std Std          0.440108
trainer/Policy log std Max         -0.348269
trainer/Policy log std Min         -2.5788
trainer/Alpha                       0.043933
trainer/Alpha Loss                  1.09259
exploration/num steps total     22400
exploration/num paths total       224
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.48945
exploration/Rewards Std             1.33304
exploration/Rewards Max            -0.00387527
exploration/Rewards Min            -8.13879
exploration/Returns Mean          -48.945
exploration/Returns Std             2.02427
exploration/Returns Max           -46.9207
exploration/Returns Min           -50.9692
exploration/Actions Mean            0.0534803
exploration/Actions Std             0.252917
exploration/Actions Max             0.99949
exploration/Actions Min            -0.426837
exploration/Num Paths               2
exploration/Average Returns       -48.945
evaluation/num steps total     111000
evaluation/num paths total       1110
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.250003
evaluation/Rewards Std              1.06668
evaluation/Rewards Max             -0.0040958
evaluation/Rewards Min            -11.2677
evaluation/Returns Mean           -25.0003
evaluation/Returns Std             17.4783
evaluation/Returns Max             -7.26329
evaluation/Returns Min            -63.0622
evaluation/Actions Mean             0.0288495
evaluation/Actions Std              0.20005
evaluation/Actions Max              0.999266
evaluation/Actions Min             -0.988581
evaluation/Num Paths               10
evaluation/Average Returns        -25.0003
time/data storing (s)               0.00130883
time/evaluation sampling (s)        0.226951
time/exploration sampling (s)       0.0651076
time/logging (s)                    0.00335332
time/saving (s)                     0.00196765
time/training (s)                   0.828998
time/epoch (s)                      1.12769
time/total (s)                    120.471
Epoch                             110
-----------------------------  ---------------
2019-04-21 00:46:14.081102 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 111 finished
-----------------------------  ---------------
replay_buffer/size              22600
trainer/QF1 Loss                    0.238448
trainer/QF2 Loss                    0.272596
trainer/Policy Loss                14.6232
trainer/Q1 Predictions Mean       -12.7031
trainer/Q1 Predictions Std          6.12803
trainer/Q1 Predictions Max        -10.9492
trainer/Q1 Predictions Min        -53.6567
trainer/Q2 Predictions Mean       -12.6595
trainer/Q2 Predictions Std          6.08921
trainer/Q2 Predictions Max        -10.9261
trainer/Q2 Predictions Min        -53.0367
trainer/Q Targets Mean            -12.8493
trainer/Q Targets Std               6.16934
trainer/Q Targets Max             -11.0908
trainer/Q Targets Min             -55.4228
trainer/Log Pis Mean                2.33216
trainer/Log Pis Std                 0.837535
trainer/Log Pis Max                 5.95471
trainer/Log Pis Min                 0.288097
trainer/Policy mu Mean              0.00393411
trainer/Policy mu Std               0.672594
trainer/Policy mu Max               3.01675
trainer/Policy mu Min              -2.90358
trainer/Policy log std Mean        -2.14504
trainer/Policy log std Std          0.431369
trainer/Policy log std Max         -0.499638
trainer/Policy log std Min         -2.59361
trainer/Alpha                       0.0449123
trainer/Alpha Loss                  1.03079
exploration/num steps total     22600
exploration/num paths total       226
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.272884
exploration/Rewards Std             0.791877
exploration/Rewards Max            -0.00243898
exploration/Rewards Min            -7.23376
exploration/Returns Mean          -27.2884
exploration/Returns Std            13.8295
exploration/Returns Max           -13.459
exploration/Returns Min           -41.1179
exploration/Actions Mean            0.0289289
exploration/Actions Std             0.196364
exploration/Actions Max             0.996249
exploration/Actions Min            -0.429382
exploration/Num Paths               2
exploration/Average Returns       -27.2884
evaluation/num steps total     112000
evaluation/num paths total       1120
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.346485
evaluation/Rewards Std              1.22292
evaluation/Rewards Max             -0.0684977
evaluation/Rewards Min            -10.6755
evaluation/Returns Mean           -34.6485
evaluation/Returns Std             18.7514
evaluation/Returns Max             -8.64308
evaluation/Returns Min            -63.1894
evaluation/Actions Mean             0.0457676
evaluation/Actions Std              0.198315
evaluation/Actions Max              0.998213
evaluation/Actions Min             -0.749079
evaluation/Num Paths               10
evaluation/Average Returns        -34.6485
time/data storing (s)               0.00127883
time/evaluation sampling (s)        0.241816
time/exploration sampling (s)       0.0730031
time/logging (s)                    0.00341157
time/saving (s)                     0.00196928
time/training (s)                   0.764729
time/epoch (s)                      1.08621
time/total (s)                    121.562
Epoch                             111
-----------------------------  ---------------
2019-04-21 00:46:15.164948 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 112 finished
-----------------------------  ---------------
replay_buffer/size              22800
trainer/QF1 Loss                    3.98017
trainer/QF2 Loss                    3.97708
trainer/Policy Loss                15.6652
trainer/Q1 Predictions Mean       -14.0674
trainer/Q1 Predictions Std          8.73974
trainer/Q1 Predictions Max        -11.1103
trainer/Q1 Predictions Min        -71.191
trainer/Q2 Predictions Mean       -14.0594
trainer/Q2 Predictions Std          8.71571
trainer/Q2 Predictions Max        -11.0964
trainer/Q2 Predictions Min        -71.1536
trainer/Q Targets Mean            -13.7984
trainer/Q Targets Std               9.16796
trainer/Q Targets Max              -0.0813208
trainer/Q Targets Min             -72.7783
trainer/Log Pis Mean                2.16996
trainer/Log Pis Std                 1.48038
trainer/Log Pis Max                 6.91045
trainer/Log Pis Min                -3.856
trainer/Policy mu Mean              0.127821
trainer/Policy mu Std               0.823767
trainer/Policy mu Max               3.19392
trainer/Policy mu Min              -2.86496
trainer/Policy log std Mean        -2.04228
trainer/Policy log std Std          0.510608
trainer/Policy log std Max         -0.35107
trainer/Policy log std Min         -2.53634
trainer/Alpha                       0.0457704
trainer/Alpha Loss                  0.524179
exploration/num steps total     22800
exploration/num paths total       228
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.213307
exploration/Rewards Std             0.530511
exploration/Rewards Max            -0.00716771
exploration/Rewards Min            -5.10438
exploration/Returns Mean          -21.3307
exploration/Returns Std             7.66983
exploration/Returns Max           -13.6609
exploration/Returns Min           -29.0005
exploration/Actions Mean            0.0085782
exploration/Actions Std             0.183241
exploration/Actions Max             0.996522
exploration/Actions Min            -0.966033
exploration/Num Paths               2
exploration/Average Returns       -21.3307
evaluation/num steps total     113000
evaluation/num paths total       1130
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.221152
evaluation/Rewards Std              0.970537
evaluation/Rewards Max             -0.023279
evaluation/Rewards Min            -10.1491
evaluation/Returns Mean           -22.1152
evaluation/Returns Std             15.7864
evaluation/Returns Max             -4.65312
evaluation/Returns Min            -52.8908
evaluation/Actions Mean             0.0280454
evaluation/Actions Std              0.183222
evaluation/Actions Max              0.997779
evaluation/Actions Min             -0.991038
evaluation/Num Paths               10
evaluation/Average Returns        -22.1152
time/data storing (s)               0.00124885
time/evaluation sampling (s)        0.235058
time/exploration sampling (s)       0.0656926
time/logging (s)                    0.00337869
time/saving (s)                     0.0015891
time/training (s)                   0.770643
time/epoch (s)                      1.07761
time/total (s)                    122.643
Epoch                             112
-----------------------------  ---------------
2019-04-21 00:46:16.255220 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 113 finished
-----------------------------  ---------------
replay_buffer/size              23000
trainer/QF1 Loss                    0.543116
trainer/QF2 Loss                    0.526033
trainer/Policy Loss                14.5155
trainer/Q1 Predictions Mean       -13.1923
trainer/Q1 Predictions Std          7.41512
trainer/Q1 Predictions Max        -11.0387
trainer/Q1 Predictions Min        -74.0634
trainer/Q2 Predictions Mean       -13.1996
trainer/Q2 Predictions Std          7.42731
trainer/Q2 Predictions Max        -11.0343
trainer/Q2 Predictions Min        -74.2359
trainer/Q Targets Mean            -13.28
trainer/Q Targets Std               7.60417
trainer/Q Targets Max             -10.9346
trainer/Q Targets Min             -73.1307
trainer/Log Pis Mean                1.73877
trainer/Log Pis Std                 1.82644
trainer/Log Pis Max                 7.93582
trainer/Log Pis Min                -3.83481
trainer/Policy mu Mean              0.0221611
trainer/Policy mu Std               0.767986
trainer/Policy mu Max               3.32951
trainer/Policy mu Min              -3.23187
trainer/Policy log std Mean        -2.05094
trainer/Policy log std Std          0.458295
trainer/Policy log std Max         -0.300587
trainer/Policy log std Min         -2.52748
trainer/Alpha                       0.0449228
trainer/Alpha Loss                 -0.810523
exploration/num steps total     23000
exploration/num paths total       230
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.338193
exploration/Rewards Std             0.902088
exploration/Rewards Max            -0.0118934
exploration/Rewards Min            -6.68896
exploration/Returns Mean          -33.8193
exploration/Returns Std             5.60911
exploration/Returns Max           -28.2102
exploration/Returns Min           -39.4285
exploration/Actions Mean            0.00699298
exploration/Actions Std             0.229251
exploration/Actions Max             0.998358
exploration/Actions Min            -0.995675
exploration/Num Paths               2
exploration/Average Returns       -33.8193
evaluation/num steps total     114000
evaluation/num paths total       1140
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.262063
evaluation/Rewards Std              1.08489
evaluation/Rewards Max             -0.00929073
evaluation/Rewards Min             -9.91346
evaluation/Returns Mean           -26.2063
evaluation/Returns Std             17.2515
evaluation/Returns Max             -3.58044
evaluation/Returns Min            -58.44
evaluation/Actions Mean             0.0237327
evaluation/Actions Std              0.191944
evaluation/Actions Max              0.996995
evaluation/Actions Min             -0.996662
evaluation/Num Paths               10
evaluation/Average Returns        -26.2063
time/data storing (s)               0.0012494
time/evaluation sampling (s)        0.230901
time/exploration sampling (s)       0.0660086
time/logging (s)                    0.00335991
time/saving (s)                     0.00195573
time/training (s)                   0.780434
time/epoch (s)                      1.08391
time/total (s)                    123.731
Epoch                             113
-----------------------------  ---------------
2019-04-21 00:46:17.410826 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 114 finished
-----------------------------  ---------------
replay_buffer/size              23200
trainer/QF1 Loss                    2.85673
trainer/QF2 Loss                    2.81932
trainer/Policy Loss                14.7755
trainer/Q1 Predictions Mean       -13.2664
trainer/Q1 Predictions Std         10.0344
trainer/Q1 Predictions Max        -10.6466
trainer/Q1 Predictions Min        -76.9554
trainer/Q2 Predictions Mean       -13.321
trainer/Q2 Predictions Std         10.0416
trainer/Q2 Predictions Max        -10.6797
trainer/Q2 Predictions Min        -77.3048
trainer/Q Targets Mean            -13.4106
trainer/Q Targets Std              10.0725
trainer/Q Targets Max              -0.138496
trainer/Q Targets Min             -74.7388
trainer/Log Pis Mean                2.11915
trainer/Log Pis Std                 1.47612
trainer/Log Pis Max                 7.91618
trainer/Log Pis Min                -2.34382
trainer/Policy mu Mean              0.0799811
trainer/Policy mu Std               0.739065
trainer/Policy mu Max               3.34824
trainer/Policy mu Min              -3.20159
trainer/Policy log std Mean        -2.1159
trainer/Policy log std Std          0.458385
trainer/Policy log std Max         -0.426476
trainer/Policy log std Min         -2.58872
trainer/Alpha                       0.0447548
trainer/Alpha Loss                  0.370149
exploration/num steps total     23200
exploration/num paths total       232
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.318406
exploration/Rewards Std             0.861886
exploration/Rewards Max            -0.0252893
exploration/Rewards Min            -7.05817
exploration/Returns Mean          -31.8406
exploration/Returns Std             9.19814
exploration/Returns Max           -22.6424
exploration/Returns Min           -41.0387
exploration/Actions Mean            0.0266831
exploration/Actions Std             0.228855
exploration/Actions Max             0.994228
exploration/Actions Min            -0.968918
exploration/Num Paths               2
exploration/Average Returns       -31.8406
evaluation/num steps total     115000
evaluation/num paths total       1150
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.165237
evaluation/Rewards Std              0.745216
evaluation/Rewards Max             -0.0250677
evaluation/Rewards Min             -8.05946
evaluation/Returns Mean           -16.5237
evaluation/Returns Std             10.8015
evaluation/Returns Max             -6.34618
evaluation/Returns Min            -35.9724
evaluation/Actions Mean             0.01732
evaluation/Actions Std              0.164178
evaluation/Actions Max              0.994432
evaluation/Actions Min             -0.989161
evaluation/Num Paths               10
evaluation/Average Returns        -16.5237
time/data storing (s)               0.00125468
time/evaluation sampling (s)        0.23604
time/exploration sampling (s)       0.0731197
time/logging (s)                    0.00322112
time/saving (s)                     0.00199029
time/training (s)                   0.834469
time/epoch (s)                      1.15009
time/total (s)                    124.884
Epoch                             114
-----------------------------  ---------------
2019-04-21 00:46:18.491581 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 115 finished
-----------------------------  ---------------
replay_buffer/size              23400
trainer/QF1 Loss                    0.467064
trainer/QF2 Loss                    0.407567
trainer/Policy Loss                13.6222
trainer/Q1 Predictions Mean       -11.9481
trainer/Q1 Predictions Std          4.37508
trainer/Q1 Predictions Max        -10.6667
trainer/Q1 Predictions Min        -35.8619
trainer/Q2 Predictions Mean       -11.9235
trainer/Q2 Predictions Std          4.42414
trainer/Q2 Predictions Max        -10.6317
trainer/Q2 Predictions Min        -36.1702
trainer/Q Targets Mean            -12.2628
trainer/Q Targets Std               4.89359
trainer/Q Targets Max             -10.8378
trainer/Q Targets Min             -39.1963
trainer/Log Pis Mean                1.91904
trainer/Log Pis Std                 1.28222
trainer/Log Pis Max                 7.6452
trainer/Log Pis Min                -3.25734
trainer/Policy mu Mean             -0.0799873
trainer/Policy mu Std               0.630185
trainer/Policy mu Max               2.43567
trainer/Policy mu Min              -3.18358
trainer/Policy log std Mean        -2.11309
trainer/Policy log std Std          0.40788
trainer/Policy log std Max         -0.301655
trainer/Policy log std Min         -2.53012
trainer/Alpha                       0.0446928
trainer/Alpha Loss                 -0.251633
exploration/num steps total     23400
exploration/num paths total       234
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.311573
exploration/Rewards Std             0.818694
exploration/Rewards Max            -0.00546914
exploration/Rewards Min            -6.60545
exploration/Returns Mean          -31.1573
exploration/Returns Std             8.39417
exploration/Returns Max           -22.7631
exploration/Returns Min           -39.5515
exploration/Actions Mean            0.0356541
exploration/Actions Std             0.223341
exploration/Actions Max             0.998006
exploration/Actions Min            -0.550829
exploration/Num Paths               2
exploration/Average Returns       -31.1573
evaluation/num steps total     116000
evaluation/num paths total       1160
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.238908
evaluation/Rewards Std              0.967469
evaluation/Rewards Max             -0.0601656
evaluation/Rewards Min             -9.78706
evaluation/Returns Mean           -23.8908
evaluation/Returns Std             18.3605
evaluation/Returns Max             -6.73357
evaluation/Returns Min            -57.453
evaluation/Actions Mean             0.0143634
evaluation/Actions Std              0.177426
evaluation/Actions Max              0.996854
evaluation/Actions Min             -0.994501
evaluation/Num Paths               10
evaluation/Average Returns        -23.8908
time/data storing (s)               0.00140514
time/evaluation sampling (s)        0.233489
time/exploration sampling (s)       0.0732957
time/logging (s)                    0.00336887
time/saving (s)                     0.00197844
time/training (s)                   0.761565
time/epoch (s)                      1.0751
time/total (s)                    125.964
Epoch                             115
-----------------------------  ---------------
2019-04-21 00:46:19.578036 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 116 finished
-----------------------------  ---------------
replay_buffer/size              23600
trainer/QF1 Loss                    1.40787
trainer/QF2 Loss                    1.40096
trainer/Policy Loss                13.9407
trainer/Q1 Predictions Mean       -12.21
trainer/Q1 Predictions Std          5.8406
trainer/Q1 Predictions Max        -10.6987
trainer/Q1 Predictions Min        -55.7859
trainer/Q2 Predictions Mean       -12.1867
trainer/Q2 Predictions Std          5.858
trainer/Q2 Predictions Max        -10.6753
trainer/Q2 Predictions Min        -55.8115
trainer/Q Targets Mean            -12.1762
trainer/Q Targets Std               5.91774
trainer/Q Targets Max              -0.121672
trainer/Q Targets Min             -55.8169
trainer/Log Pis Mean                2.03888
trainer/Log Pis Std                 1.03921
trainer/Log Pis Max                 5.66491
trainer/Log Pis Min                -1.42554
trainer/Policy mu Mean              0.0356873
trainer/Policy mu Std               0.576955
trainer/Policy mu Max               3.06204
trainer/Policy mu Min              -2.66959
trainer/Policy log std Mean        -2.15945
trainer/Policy log std Std          0.406148
trainer/Policy log std Max         -0.603336
trainer/Policy log std Min         -2.57117
trainer/Alpha                       0.0446201
trainer/Alpha Loss                  0.120903
exploration/num steps total     23600
exploration/num paths total       236
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.325272
exploration/Rewards Std             0.9187
exploration/Rewards Max            -0.0131937
exploration/Rewards Min            -7.43286
exploration/Returns Mean          -32.5272
exploration/Returns Std            10.9996
exploration/Returns Max           -21.5276
exploration/Returns Min           -43.5268
exploration/Actions Mean            0.0239295
exploration/Actions Std             0.216054
exploration/Actions Max             0.999474
exploration/Actions Min            -0.928608
exploration/Num Paths               2
exploration/Average Returns       -32.5272
evaluation/num steps total     117000
evaluation/num paths total       1170
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.318951
evaluation/Rewards Std              1.26184
evaluation/Rewards Max             -0.0277792
evaluation/Rewards Min            -10.2291
evaluation/Returns Mean           -31.8951
evaluation/Returns Std             16.0247
evaluation/Returns Max             -9.63423
evaluation/Returns Min            -52.9778
evaluation/Actions Mean             0.0262547
evaluation/Actions Std              0.218444
evaluation/Actions Max              0.995504
evaluation/Actions Min             -0.995237
evaluation/Num Paths               10
evaluation/Average Returns        -31.8951
time/data storing (s)               0.00128817
time/evaluation sampling (s)        0.229264
time/exploration sampling (s)       0.0771011
time/logging (s)                    0.00337304
time/saving (s)                     0.00184432
time/training (s)                   0.766892
time/epoch (s)                      1.07976
time/total (s)                    127.048
Epoch                             116
-----------------------------  ---------------
2019-04-21 00:46:20.661124 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 117 finished
-----------------------------  ---------------
replay_buffer/size              23800
trainer/QF1 Loss                    2.38084
trainer/QF2 Loss                    2.34953
trainer/Policy Loss                13.8157
trainer/Q1 Predictions Mean       -12.0636
trainer/Q1 Predictions Std          5.74933
trainer/Q1 Predictions Max        -10.6675
trainer/Q1 Predictions Min        -52.2542
trainer/Q2 Predictions Mean       -12.0531
trainer/Q2 Predictions Std          5.72428
trainer/Q2 Predictions Max        -10.6328
trainer/Q2 Predictions Min        -52.0369
trainer/Q Targets Mean            -11.8885
trainer/Q Targets Std               5.80937
trainer/Q Targets Max              -0.0980874
trainer/Q Targets Min             -50.2121
trainer/Log Pis Mean                2.01741
trainer/Log Pis Std                 1.28826
trainer/Log Pis Max                 7.33708
trainer/Log Pis Min                -2.16735
trainer/Policy mu Mean              0.0210716
trainer/Policy mu Std               0.589896
trainer/Policy mu Max               3.15763
trainer/Policy mu Min              -2.25092
trainer/Policy log std Mean        -2.1823
trainer/Policy log std Std          0.420064
trainer/Policy log std Max         -0.358579
trainer/Policy log std Min         -2.61524
trainer/Alpha                       0.0450035
trainer/Alpha Loss                  0.0539994
exploration/num steps total     23800
exploration/num paths total       238
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.327851
exploration/Rewards Std             0.886853
exploration/Rewards Max            -0.00686375
exploration/Rewards Min            -6.89229
exploration/Returns Mean          -32.7851
exploration/Returns Std             8.81946
exploration/Returns Max           -23.9656
exploration/Returns Min           -41.6046
exploration/Actions Mean            0.041206
exploration/Actions Std             0.220834
exploration/Actions Max             0.997811
exploration/Actions Min            -0.410356
exploration/Num Paths               2
exploration/Average Returns       -32.7851
evaluation/num steps total     118000
evaluation/num paths total       1180
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.275543
evaluation/Rewards Std              1.07102
evaluation/Rewards Max             -0.0342909
evaluation/Rewards Min             -9.13053
evaluation/Returns Mean           -27.5543
evaluation/Returns Std             11.405
evaluation/Returns Max            -13.4612
evaluation/Returns Min            -48.8429
evaluation/Actions Mean             0.0375444
evaluation/Actions Std              0.205418
evaluation/Actions Max              0.996743
evaluation/Actions Min             -0.995056
evaluation/Num Paths               10
evaluation/Average Returns        -27.5543
time/data storing (s)               0.00126216
time/evaluation sampling (s)        0.234247
time/exploration sampling (s)       0.0688146
time/logging (s)                    0.00338138
time/saving (s)                     0.0019535
time/training (s)                   0.766826
time/epoch (s)                      1.07649
time/total (s)                    128.129
Epoch                             117
-----------------------------  ---------------
2019-04-21 00:46:21.744896 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 118 finished
-----------------------------  ---------------
replay_buffer/size              24000
trainer/QF1 Loss                    3.86442
trainer/QF2 Loss                    3.8299
trainer/Policy Loss                13.9779
trainer/Q1 Predictions Mean       -12.4478
trainer/Q1 Predictions Std          5.51778
trainer/Q1 Predictions Max        -10.6184
trainer/Q1 Predictions Min        -41.7116
trainer/Q2 Predictions Mean       -12.4349
trainer/Q2 Predictions Std          5.53292
trainer/Q2 Predictions Max        -10.5776
trainer/Q2 Predictions Min        -41.404
trainer/Q Targets Mean            -12.2534
trainer/Q Targets Std               6.00713
trainer/Q Targets Max              -0.0882932
trainer/Q Targets Min             -41.6097
trainer/Log Pis Mean                1.86191
trainer/Log Pis Std                 1.51571
trainer/Log Pis Max                 8.07732
trainer/Log Pis Min                -2.06337
trainer/Policy mu Mean             -0.0393506
trainer/Policy mu Std               0.732331
trainer/Policy mu Max               2.67273
trainer/Policy mu Min              -3.1617
trainer/Policy log std Mean        -2.08913
trainer/Policy log std Std          0.440541
trainer/Policy log std Max         -0.410782
trainer/Policy log std Min         -2.55466
trainer/Alpha                       0.0462958
trainer/Alpha Loss                 -0.424311
exploration/num steps total     24000
exploration/num paths total       240
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.19402
exploration/Rewards Std             0.299958
exploration/Rewards Max            -0.00414577
exploration/Rewards Min            -2.69879
exploration/Returns Mean          -19.402
exploration/Returns Std             1.92928
exploration/Returns Max           -17.4727
exploration/Returns Min           -21.3313
exploration/Actions Mean           -0.0189968
exploration/Actions Std             0.204105
exploration/Actions Max             0.554509
exploration/Actions Min            -0.98785
exploration/Num Paths               2
exploration/Average Returns       -19.402
evaluation/num steps total     119000
evaluation/num paths total       1190
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.318647
evaluation/Rewards Std              1.27344
evaluation/Rewards Max             -0.00879544
evaluation/Rewards Min            -10.1738
evaluation/Returns Mean           -31.8647
evaluation/Returns Std             17.8941
evaluation/Returns Max             -2.93085
evaluation/Returns Min            -58.2288
evaluation/Actions Mean             0.0256312
evaluation/Actions Std              0.205724
evaluation/Actions Max              0.996611
evaluation/Actions Min             -0.997001
evaluation/Num Paths               10
evaluation/Average Returns        -31.8647
time/data storing (s)               0.00121493
time/evaluation sampling (s)        0.231685
time/exploration sampling (s)       0.0657909
time/logging (s)                    0.00339732
time/saving (s)                     0.00199168
time/training (s)                   0.772911
time/epoch (s)                      1.07699
time/total (s)                    129.21
Epoch                             118
-----------------------------  ---------------
2019-04-21 00:46:22.808459 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 119 finished
-----------------------------  ---------------
replay_buffer/size              24200
trainer/QF1 Loss                    1.20741
trainer/QF2 Loss                    1.22532
trainer/Policy Loss                12.8733
trainer/Q1 Predictions Mean       -11.3315
trainer/Q1 Predictions Std          2.40188
trainer/Q1 Predictions Max        -10.4689
trainer/Q1 Predictions Min        -29.8364
trainer/Q2 Predictions Mean       -11.3437
trainer/Q2 Predictions Std          2.40516
trainer/Q2 Predictions Max        -10.4496
trainer/Q2 Predictions Min        -29.6936
trainer/Q Targets Mean            -11.3414
trainer/Q Targets Std               2.47121
trainer/Q Targets Max              -0.368706
trainer/Q Targets Min             -29.5012
trainer/Log Pis Mean                1.74945
trainer/Log Pis Std                 1.19677
trainer/Log Pis Max                 5.83355
trainer/Log Pis Min                -2.25988
trainer/Policy mu Mean              0.0836777
trainer/Policy mu Std               0.561877
trainer/Policy mu Max               3.11955
trainer/Policy mu Min              -2.08268
trainer/Policy log std Mean        -2.11779
trainer/Policy log std Std          0.413032
trainer/Policy log std Max         -0.483593
trainer/Policy log std Min         -2.55936
trainer/Alpha                       0.047039
trainer/Alpha Loss                 -0.76588
exploration/num steps total     24200
exploration/num paths total       242
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.231731
exploration/Rewards Std             0.499521
exploration/Rewards Max            -0.0143613
exploration/Rewards Min            -4.80482
exploration/Returns Mean          -23.1731
exploration/Returns Std             4.93467
exploration/Returns Max           -18.2384
exploration/Returns Min           -28.1077
exploration/Actions Mean            0.00895828
exploration/Actions Std             0.201977
exploration/Actions Max             0.987935
exploration/Actions Min            -0.994841
exploration/Num Paths               2
exploration/Average Returns       -23.1731
evaluation/num steps total     120000
evaluation/num paths total       1200
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.243495
evaluation/Rewards Std              0.931617
evaluation/Rewards Max             -0.0348503
evaluation/Rewards Min             -8.96975
evaluation/Returns Mean           -24.3495
evaluation/Returns Std             16.0137
evaluation/Returns Max             -6.26719
evaluation/Returns Min            -51.6009
evaluation/Actions Mean             0.031285
evaluation/Actions Std              0.167
evaluation/Actions Max              0.995825
evaluation/Actions Min             -0.684718
evaluation/Num Paths               10
evaluation/Average Returns        -24.3495
time/data storing (s)               0.00132288
time/evaluation sampling (s)        0.220291
time/exploration sampling (s)       0.0627007
time/logging (s)                    0.00317257
time/saving (s)                     0.00195392
time/training (s)                   0.767111
time/epoch (s)                      1.05655
time/total (s)                    130.271
Epoch                             119
-----------------------------  ---------------
2019-04-21 00:46:23.892632 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 120 finished
-----------------------------  ---------------
replay_buffer/size              24400
trainer/QF1 Loss                    3.59533
trainer/QF2 Loss                    3.50193
trainer/Policy Loss                14.1769
trainer/Q1 Predictions Mean       -12.7536
trainer/Q1 Predictions Std          6.58857
trainer/Q1 Predictions Max        -10.4747
trainer/Q1 Predictions Min        -57.457
trainer/Q2 Predictions Mean       -12.7464
trainer/Q2 Predictions Std          6.59184
trainer/Q2 Predictions Max        -10.4561
trainer/Q2 Predictions Min        -57.2001
trainer/Q Targets Mean            -12.6107
trainer/Q Targets Std               7.0849
trainer/Q Targets Max              -0.0705705
trainer/Q Targets Min             -57.8392
trainer/Log Pis Mean                1.91662
trainer/Log Pis Std                 1.2216
trainer/Log Pis Max                 5.83391
trainer/Log Pis Min                -1.03035
trainer/Policy mu Mean              0.0964294
trainer/Policy mu Std               0.71197
trainer/Policy mu Max               2.89812
trainer/Policy mu Min              -3.15602
trainer/Policy log std Mean        -2.05731
trainer/Policy log std Std          0.469107
trainer/Policy log std Max         -0.486273
trainer/Policy log std Min         -2.55927
trainer/Alpha                       0.0460748
trainer/Alpha Loss                 -0.256583
exploration/num steps total     24400
exploration/num paths total       244
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.493339
exploration/Rewards Std             1.43286
exploration/Rewards Max            -0.0105024
exploration/Rewards Min            -9.80975
exploration/Returns Mean          -49.3339
exploration/Returns Std            20.4755
exploration/Returns Max           -28.8585
exploration/Returns Min           -69.8094
exploration/Actions Mean            0.0321441
exploration/Actions Std             0.254485
exploration/Actions Max             0.997433
exploration/Actions Min            -0.997042
exploration/Num Paths               2
exploration/Average Returns       -49.3339
evaluation/num steps total     121000
evaluation/num paths total       1210
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.310968
evaluation/Rewards Std              1.28632
evaluation/Rewards Max             -0.0166577
evaluation/Rewards Min            -10.394
evaluation/Returns Mean           -31.0968
evaluation/Returns Std             21.6674
evaluation/Returns Max             -3.97233
evaluation/Returns Min            -59.5994
evaluation/Actions Mean             0.0331594
evaluation/Actions Std              0.194356
evaluation/Actions Max              0.997845
evaluation/Actions Min             -0.995731
evaluation/Num Paths               10
evaluation/Average Returns        -31.0968
time/data storing (s)               0.00131911
time/evaluation sampling (s)        0.220104
time/exploration sampling (s)       0.0668237
time/logging (s)                    0.00280394
time/saving (s)                     0.001978
time/training (s)                   0.784833
time/epoch (s)                      1.07786
time/total (s)                    131.353
Epoch                             120
-----------------------------  ---------------
2019-04-21 00:46:24.972490 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 121 finished
-----------------------------  ---------------
replay_buffer/size              24600
trainer/QF1 Loss                    2.4414
trainer/QF2 Loss                    2.42596
trainer/Policy Loss                13.4265
trainer/Q1 Predictions Mean       -11.8493
trainer/Q1 Predictions Std          6.85886
trainer/Q1 Predictions Max        -10.2847
trainer/Q1 Predictions Min        -73.1832
trainer/Q2 Predictions Mean       -11.8338
trainer/Q2 Predictions Std          6.90351
trainer/Q2 Predictions Max        -10.2398
trainer/Q2 Predictions Min        -73.6319
trainer/Q Targets Mean            -11.9031
trainer/Q Targets Std               7.31112
trainer/Q Targets Max              -0.0302478
trainer/Q Targets Min             -76.6277
trainer/Log Pis Mean                1.88554
trainer/Log Pis Std                 1.16269
trainer/Log Pis Max                 6.28687
trainer/Log Pis Min                -1.20089
trainer/Policy mu Mean              0.067159
trainer/Policy mu Std               0.60155
trainer/Policy mu Max               3.25936
trainer/Policy mu Min              -2.80785
trainer/Policy log std Mean        -2.10575
trainer/Policy log std Std          0.412644
trainer/Policy log std Max         -0.555871
trainer/Policy log std Min         -2.5564
trainer/Alpha                       0.0455657
trainer/Alpha Loss                 -0.353514
exploration/num steps total     24600
exploration/num paths total       246
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.557017
exploration/Rewards Std             1.48537
exploration/Rewards Max            -0.00722004
exploration/Rewards Min            -9.19863
exploration/Returns Mean          -55.7017
exploration/Returns Std             6.70019
exploration/Returns Max           -49.0015
exploration/Returns Min           -62.4019
exploration/Actions Mean            0.0606259
exploration/Actions Std             0.262018
exploration/Actions Max             0.998545
exploration/Actions Min            -0.383044
exploration/Num Paths               2
exploration/Average Returns       -55.7017
evaluation/num steps total     122000
evaluation/num paths total       1220
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.290277
evaluation/Rewards Std              1.09609
evaluation/Rewards Max             -0.0687145
evaluation/Rewards Min            -10.4873
evaluation/Returns Mean           -29.0277
evaluation/Returns Std             18.6941
evaluation/Returns Max             -7.47322
evaluation/Returns Min            -61.6114
evaluation/Actions Mean             0.0218537
evaluation/Actions Std              0.190675
evaluation/Actions Max              0.997662
evaluation/Actions Min             -0.996896
evaluation/Num Paths               10
evaluation/Average Returns        -29.0277
time/data storing (s)               0.00129935
time/evaluation sampling (s)        0.22358
time/exploration sampling (s)       0.0640792
time/logging (s)                    0.0025443
time/saving (s)                     0.00199499
time/training (s)                   0.779389
time/epoch (s)                      1.07289
time/total (s)                    132.43
Epoch                             121
-----------------------------  ---------------
2019-04-21 00:46:26.057496 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 122 finished
-----------------------------  ---------------
replay_buffer/size              24800
trainer/QF1 Loss                    0.371874
trainer/QF2 Loss                    0.374964
trainer/Policy Loss                12.9746
trainer/Q1 Predictions Mean       -11.3275
trainer/Q1 Predictions Std          3.50592
trainer/Q1 Predictions Max        -10.3657
trainer/Q1 Predictions Min        -35.6105
trainer/Q2 Predictions Mean       -11.3107
trainer/Q2 Predictions Std          3.5637
trainer/Q2 Predictions Max        -10.335
trainer/Q2 Predictions Min        -36.1403
trainer/Q Targets Mean            -11.4722
trainer/Q Targets Std               3.89917
trainer/Q Targets Max             -10.4002
trainer/Q Targets Min             -40.0741
trainer/Log Pis Mean                1.84107
trainer/Log Pis Std                 1.21319
trainer/Log Pis Max                 6.79727
trainer/Log Pis Min                -3.09027
trainer/Policy mu Mean              0.0440861
trainer/Policy mu Std               0.527323
trainer/Policy mu Max               2.91716
trainer/Policy mu Min              -3.07795
trainer/Policy log std Mean        -2.15122
trainer/Policy log std Std          0.363847
trainer/Policy log std Max         -0.363104
trainer/Policy log std Min         -2.56252
trainer/Alpha                       0.0465361
trainer/Alpha Loss                 -0.48756
exploration/num steps total     24800
exploration/num paths total       248
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.440497
exploration/Rewards Std             1.43126
exploration/Rewards Max            -0.00784388
exploration/Rewards Min           -10.9185
exploration/Returns Mean          -44.0497
exploration/Returns Std            28.2873
exploration/Returns Max           -15.7624
exploration/Returns Min           -72.337
exploration/Actions Mean            0.0474712
exploration/Actions Std             0.235083
exploration/Actions Max             0.999122
exploration/Actions Min            -0.342378
exploration/Num Paths               2
exploration/Average Returns       -44.0497
evaluation/num steps total     123000
evaluation/num paths total       1230
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.292333
evaluation/Rewards Std              1.12861
evaluation/Rewards Max             -0.0477868
evaluation/Rewards Min            -10.4452
evaluation/Returns Mean           -29.2333
evaluation/Returns Std             15.8054
evaluation/Returns Max             -5.0539
evaluation/Returns Min            -54.928
evaluation/Actions Mean             0.0253807
evaluation/Actions Std              0.197713
evaluation/Actions Max              0.998198
evaluation/Actions Min             -0.994869
evaluation/Num Paths               10
evaluation/Average Returns        -29.2333
time/data storing (s)               0.00139777
time/evaluation sampling (s)        0.221455
time/exploration sampling (s)       0.0673707
time/logging (s)                    0.00332497
time/saving (s)                     0.00196519
time/training (s)                   0.783969
time/epoch (s)                      1.07948
time/total (s)                    133.514
Epoch                             122
-----------------------------  ---------------
2019-04-21 00:46:27.136895 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 123 finished
-----------------------------  ---------------
replay_buffer/size              25000
trainer/QF1 Loss                    1.17772
trainer/QF2 Loss                    1.20537
trainer/Policy Loss                13.1754
trainer/Q1 Predictions Mean       -11.3872
trainer/Q1 Predictions Std          3.84904
trainer/Q1 Predictions Max        -10.3541
trainer/Q1 Predictions Min        -38.7628
trainer/Q2 Predictions Mean       -11.3776
trainer/Q2 Predictions Std          3.81975
trainer/Q2 Predictions Max        -10.321
trainer/Q2 Predictions Min        -38.2844
trainer/Q Targets Mean            -11.3452
trainer/Q Targets Std               4.03821
trainer/Q Targets Max              -0.652025
trainer/Q Targets Min             -37.917
trainer/Log Pis Mean                1.97569
trainer/Log Pis Std                 1.08386
trainer/Log Pis Max                 5.51358
trainer/Log Pis Min                -1.55177
trainer/Policy mu Mean              0.128091
trainer/Policy mu Std               0.525535
trainer/Policy mu Max               2.87405
trainer/Policy mu Min              -0.91934
trainer/Policy log std Mean        -2.23873
trainer/Policy log std Std          0.391219
trainer/Policy log std Max         -0.644766
trainer/Policy log std Min         -2.67605
trainer/Alpha                       0.0474587
trainer/Alpha Loss                 -0.074092
exploration/num steps total     25000
exploration/num paths total       250
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.249315
exploration/Rewards Std             0.507468
exploration/Rewards Max            -0.0155604
exploration/Rewards Min            -4.92211
exploration/Returns Mean          -24.9315
exploration/Returns Std             5.7852
exploration/Returns Max           -19.1463
exploration/Returns Min           -30.7167
exploration/Actions Mean            0.0114195
exploration/Actions Std             0.210411
exploration/Actions Max             0.997756
exploration/Actions Min            -0.978149
exploration/Num Paths               2
exploration/Average Returns       -24.9315
evaluation/num steps total     124000
evaluation/num paths total       1240
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.445523
evaluation/Rewards Std              1.37105
evaluation/Rewards Max             -0.0740064
evaluation/Rewards Min            -10.6249
evaluation/Returns Mean           -44.5523
evaluation/Returns Std             21.2151
evaluation/Returns Max            -13.2097
evaluation/Returns Min            -69.0852
evaluation/Actions Mean             0.044619
evaluation/Actions Std              0.208799
evaluation/Actions Max              0.997158
evaluation/Actions Min             -0.987778
evaluation/Num Paths               10
evaluation/Average Returns        -44.5523
time/data storing (s)               0.00143076
time/evaluation sampling (s)        0.226945
time/exploration sampling (s)       0.0693008
time/logging (s)                    0.00331509
time/saving (s)                     0.00195766
time/training (s)                   0.770354
time/epoch (s)                      1.0733
time/total (s)                    134.591
Epoch                             123
-----------------------------  ---------------
2019-04-21 00:46:28.199907 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 124 finished
-----------------------------  ---------------
replay_buffer/size              25200
trainer/QF1 Loss                    0.150112
trainer/QF2 Loss                    0.167198
trainer/Policy Loss                14.0519
trainer/Q1 Predictions Mean       -12.5825
trainer/Q1 Predictions Std          7.4616
trainer/Q1 Predictions Max        -10.2721
trainer/Q1 Predictions Min        -66.2957
trainer/Q2 Predictions Mean       -12.5738
trainer/Q2 Predictions Std          7.47135
trainer/Q2 Predictions Max        -10.2513
trainer/Q2 Predictions Min        -66.4955
trainer/Q Targets Mean            -12.6765
trainer/Q Targets Std               7.53991
trainer/Q Targets Max             -10.2245
trainer/Q Targets Min             -66.5526
trainer/Log Pis Mean                2.01443
trainer/Log Pis Std                 1.70976
trainer/Log Pis Max                 7.409
trainer/Log Pis Min                -7.55702
trainer/Policy mu Mean              0.121757
trainer/Policy mu Std               0.727363
trainer/Policy mu Max               3.07415
trainer/Policy mu Min              -2.90168
trainer/Policy log std Mean        -2.09994
trainer/Policy log std Std          0.489518
trainer/Policy log std Max         -0.401988
trainer/Policy log std Min         -2.63491
trainer/Alpha                       0.047797
trainer/Alpha Loss                  0.0438703
exploration/num steps total     25200
exploration/num paths total       252
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.344752
exploration/Rewards Std             0.928889
exploration/Rewards Max            -0.0102372
exploration/Rewards Min            -7.32144
exploration/Returns Mean          -34.4752
exploration/Returns Std             5.40655
exploration/Returns Max           -29.0687
exploration/Returns Min           -39.8818
exploration/Actions Mean            0.014493
exploration/Actions Std             0.245254
exploration/Actions Max             0.997408
exploration/Actions Min            -0.994349
exploration/Num Paths               2
exploration/Average Returns       -34.4752
evaluation/num steps total     125000
evaluation/num paths total       1250
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.237415
evaluation/Rewards Std              0.920174
evaluation/Rewards Max             -0.0364925
evaluation/Rewards Min            -11.1458
evaluation/Returns Mean           -23.7415
evaluation/Returns Std             16.8466
evaluation/Returns Max             -6.66985
evaluation/Returns Min            -64.7499
evaluation/Actions Mean             0.0196072
evaluation/Actions Std              0.177933
evaluation/Actions Max              0.997923
evaluation/Actions Min             -0.996341
evaluation/Num Paths               10
evaluation/Average Returns        -23.7415
time/data storing (s)               0.00120944
time/evaluation sampling (s)        0.22998
time/exploration sampling (s)       0.0666935
time/logging (s)                    0.00359761
time/saving (s)                     0.00202133
time/training (s)                   0.753161
time/epoch (s)                      1.05666
time/total (s)                    135.652
Epoch                             124
-----------------------------  ---------------
2019-04-21 00:46:29.284050 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 125 finished
-----------------------------  ---------------
replay_buffer/size              25400
trainer/QF1 Loss                    2.3868
trainer/QF2 Loss                    2.30294
trainer/Policy Loss                12.9775
trainer/Q1 Predictions Mean       -11.4628
trainer/Q1 Predictions Std          4.9444
trainer/Q1 Predictions Max        -10.1872
trainer/Q1 Predictions Min        -54.4729
trainer/Q2 Predictions Mean       -11.4073
trainer/Q2 Predictions Std          4.92077
trainer/Q2 Predictions Max        -10.1274
trainer/Q2 Predictions Min        -54.2234
trainer/Q Targets Mean            -11.2359
trainer/Q Targets Std               4.99621
trainer/Q Targets Max              -0.390867
trainer/Q Targets Min             -53.6813
trainer/Log Pis Mean                1.94151
trainer/Log Pis Std                 1.07065
trainer/Log Pis Max                 6.95118
trainer/Log Pis Min                -0.667152
trainer/Policy mu Mean              0.050717
trainer/Policy mu Std               0.580009
trainer/Policy mu Max               2.85852
trainer/Policy mu Min              -2.51825
trainer/Policy log std Mean        -2.14618
trainer/Policy log std Std          0.435966
trainer/Policy log std Max         -0.672733
trainer/Policy log std Min         -2.62885
trainer/Alpha                       0.0477275
trainer/Alpha Loss                 -0.177956
exploration/num steps total     25400
exploration/num paths total       254
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.201266
exploration/Rewards Std             0.443234
exploration/Rewards Max            -0.0130727
exploration/Rewards Min            -4.3329
exploration/Returns Mean          -20.1266
exploration/Returns Std             1.97552
exploration/Returns Max           -18.1511
exploration/Returns Min           -22.1021
exploration/Actions Mean            0.0255201
exploration/Actions Std             0.203751
exploration/Actions Max             0.994854
exploration/Actions Min            -0.887962
exploration/Num Paths               2
exploration/Average Returns       -20.1266
evaluation/num steps total     126000
evaluation/num paths total       1260
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.224501
evaluation/Rewards Std              0.856546
evaluation/Rewards Max             -0.0227622
evaluation/Rewards Min             -8.28436
evaluation/Returns Mean           -22.4501
evaluation/Returns Std              9.96861
evaluation/Returns Max             -9.87647
evaluation/Returns Min            -40.4773
evaluation/Actions Mean             0.024837
evaluation/Actions Std              0.1878
evaluation/Actions Max              0.99496
evaluation/Actions Min             -0.992841
evaluation/Num Paths               10
evaluation/Average Returns        -22.4501
time/data storing (s)               0.00131732
time/evaluation sampling (s)        0.229002
time/exploration sampling (s)       0.0651129
time/logging (s)                    0.00299021
time/saving (s)                     0.00214613
time/training (s)                   0.776207
time/epoch (s)                      1.07677
time/total (s)                    136.733
Epoch                             125
-----------------------------  ---------------
2019-04-21 00:46:30.355532 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 126 finished
-----------------------------  ---------------
replay_buffer/size              25600
trainer/QF1 Loss                    3.58123
trainer/QF2 Loss                    3.49418
trainer/Policy Loss                14.6694
trainer/Q1 Predictions Mean       -13.0612
trainer/Q1 Predictions Std          8.52158
trainer/Q1 Predictions Max        -10.1078
trainer/Q1 Predictions Min        -64.0142
trainer/Q2 Predictions Mean       -13.087
trainer/Q2 Predictions Std          8.49128
trainer/Q2 Predictions Max        -10.1391
trainer/Q2 Predictions Min        -64.3211
trainer/Q Targets Mean            -12.8364
trainer/Q Targets Std               8.91208
trainer/Q Targets Max              -0.240982
trainer/Q Targets Min             -64.4942
trainer/Log Pis Mean                2.24701
trainer/Log Pis Std                 1.46199
trainer/Log Pis Max                 7.51562
trainer/Log Pis Min                -2.71334
trainer/Policy mu Mean              0.089326
trainer/Policy mu Std               0.826296
trainer/Policy mu Max               3.10702
trainer/Policy mu Min              -3.20892
trainer/Policy log std Mean        -2.09449
trainer/Policy log std Std          0.497669
trainer/Policy log std Max         -0.576187
trainer/Policy log std Min         -2.64454
trainer/Alpha                       0.0478687
trainer/Alpha Loss                  0.750754
exploration/num steps total     25600
exploration/num paths total       256
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.429652
exploration/Rewards Std             1.23177
exploration/Rewards Max            -0.0082968
exploration/Rewards Min            -9.37669
exploration/Returns Mean          -42.9652
exploration/Returns Std            23.8386
exploration/Returns Max           -19.1267
exploration/Returns Min           -66.8038
exploration/Actions Mean            0.0208534
exploration/Actions Std             0.22176
exploration/Actions Max             0.997878
exploration/Actions Min            -0.982278
exploration/Num Paths               2
exploration/Average Returns       -42.9652
evaluation/num steps total     127000
evaluation/num paths total       1270
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.329304
evaluation/Rewards Std              0.961219
evaluation/Rewards Max             -0.0247745
evaluation/Rewards Min             -9.76897
evaluation/Returns Mean           -32.9304
evaluation/Returns Std             16.0385
evaluation/Returns Max            -14.4888
evaluation/Returns Min            -65.6171
evaluation/Actions Mean             0.0240038
evaluation/Actions Std              0.182841
evaluation/Actions Max              0.997007
evaluation/Actions Min             -0.992756
evaluation/Num Paths               10
evaluation/Average Returns        -32.9304
time/data storing (s)               0.00127966
time/evaluation sampling (s)        0.229123
time/exploration sampling (s)       0.0698535
time/logging (s)                    0.00335344
time/saving (s)                     0.00195995
time/training (s)                   0.760331
time/epoch (s)                      1.0659
time/total (s)                    137.804
Epoch                             126
-----------------------------  ---------------
2019-04-21 00:46:31.443018 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 127 finished
-----------------------------  ---------------
replay_buffer/size              25800
trainer/QF1 Loss                    8.98648
trainer/QF2 Loss                    9.16665
trainer/Policy Loss                12.9503
trainer/Q1 Predictions Mean       -11.5854
trainer/Q1 Predictions Std          6.60026
trainer/Q1 Predictions Max         -9.87881
trainer/Q1 Predictions Min        -68.0279
trainer/Q2 Predictions Mean       -11.5571
trainer/Q2 Predictions Std          6.64699
trainer/Q2 Predictions Max         -9.83536
trainer/Q2 Predictions Min        -68.2895
trainer/Q Targets Mean            -11.432
trainer/Q Targets Std               6.62378
trainer/Q Targets Max              -0.0538284
trainer/Q Targets Min             -72.2062
trainer/Log Pis Mean                1.80731
trainer/Log Pis Std                 1.3911
trainer/Log Pis Max                 7.11431
trainer/Log Pis Min                -3.52876
trainer/Policy mu Mean             -0.0774789
trainer/Policy mu Std               0.660168
trainer/Policy mu Max               3.11267
trainer/Policy mu Min              -3.19488
trainer/Policy log std Mean        -2.09527
trainer/Policy log std Std          0.449386
trainer/Policy log std Max         -0.431109
trainer/Policy log std Min         -2.61558
trainer/Alpha                       0.0478039
trainer/Alpha Loss                 -0.58588
exploration/num steps total     25800
exploration/num paths total       258
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.245952
exploration/Rewards Std             0.551485
exploration/Rewards Max            -0.010621
exploration/Rewards Min            -4.25386
exploration/Returns Mean          -24.5952
exploration/Returns Std             1.7342
exploration/Returns Max           -22.861
exploration/Returns Min           -26.3294
exploration/Actions Mean            0.0236398
exploration/Actions Std             0.199791
exploration/Actions Max             0.99469
exploration/Actions Min            -0.58908
exploration/Num Paths               2
exploration/Average Returns       -24.5952
evaluation/num steps total     128000
evaluation/num paths total       1280
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.276507
evaluation/Rewards Std              1.01462
evaluation/Rewards Max             -0.0110731
evaluation/Rewards Min            -10.7284
evaluation/Returns Mean           -27.6507
evaluation/Returns Std             15.2182
evaluation/Returns Max             -7.06565
evaluation/Returns Min            -60.2304
evaluation/Actions Mean             0.0265714
evaluation/Actions Std              0.194057
evaluation/Actions Max              0.997338
evaluation/Actions Min             -0.99776
evaluation/Num Paths               10
evaluation/Average Returns        -27.6507
time/data storing (s)               0.00125844
time/evaluation sampling (s)        0.226085
time/exploration sampling (s)       0.0663922
time/logging (s)                    0.00250356
time/saving (s)                     0.00160051
time/training (s)                   0.781977
time/epoch (s)                      1.07982
time/total (s)                    138.888
Epoch                             127
-----------------------------  ---------------
2019-04-21 00:46:32.527289 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 128 finished
-----------------------------  ---------------
replay_buffer/size              26000
trainer/QF1 Loss                    0.160263
trainer/QF2 Loss                    0.173354
trainer/Policy Loss                13.7069
trainer/Q1 Predictions Mean       -12.1586
trainer/Q1 Predictions Std          8.5075
trainer/Q1 Predictions Max         -9.98652
trainer/Q1 Predictions Min        -73.2772
trainer/Q2 Predictions Mean       -12.1196
trainer/Q2 Predictions Std          8.49192
trainer/Q2 Predictions Max         -9.92277
trainer/Q2 Predictions Min        -73.3881
trainer/Q Targets Mean            -12.2689
trainer/Q Targets Std               8.61803
trainer/Q Targets Max              -9.93771
trainer/Q Targets Min             -74.6277
trainer/Log Pis Mean                1.99813
trainer/Log Pis Std                 1.55209
trainer/Log Pis Max                 7.53893
trainer/Log Pis Min                -4.27672
trainer/Policy mu Mean              0.0827647
trainer/Policy mu Std               0.686384
trainer/Policy mu Max               3.33249
trainer/Policy mu Min              -2.84644
trainer/Policy log std Mean        -2.14396
trainer/Policy log std Std          0.456651
trainer/Policy log std Max         -0.325046
trainer/Policy log std Min         -2.64066
trainer/Alpha                       0.0474083
trainer/Alpha Loss                 -0.00570473
exploration/num steps total     26000
exploration/num paths total       260
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.20262
exploration/Rewards Std             0.489925
exploration/Rewards Max            -0.00561543
exploration/Rewards Min            -4.48627
exploration/Returns Mean          -20.262
exploration/Returns Std             4.69412
exploration/Returns Max           -15.5679
exploration/Returns Min           -24.9561
exploration/Actions Mean            0.0198231
exploration/Actions Std             0.197313
exploration/Actions Max             0.998068
exploration/Actions Min            -0.709701
exploration/Num Paths               2
exploration/Average Returns       -20.262
evaluation/num steps total     129000
evaluation/num paths total       1290
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.176811
evaluation/Rewards Std              0.861218
evaluation/Rewards Max             -0.0201148
evaluation/Rewards Min            -10.1038
evaluation/Returns Mean           -17.6811
evaluation/Returns Std             14.2664
evaluation/Returns Max             -3.03428
evaluation/Returns Min            -50.0065
evaluation/Actions Mean             0.0244236
evaluation/Actions Std              0.176437
evaluation/Actions Max              0.997394
evaluation/Actions Min             -0.996342
evaluation/Num Paths               10
evaluation/Average Returns        -17.6811
time/data storing (s)               0.00144098
time/evaluation sampling (s)        0.226559
time/exploration sampling (s)       0.0691043
time/logging (s)                    0.00314225
time/saving (s)                     0.00197291
time/training (s)                   0.77695
time/epoch (s)                      1.07917
time/total (s)                    139.971
Epoch                             128
-----------------------------  ---------------
2019-04-21 00:46:33.606089 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 129 finished
-----------------------------  ---------------
replay_buffer/size              26200
trainer/QF1 Loss                    0.146555
trainer/QF2 Loss                    0.133276
trainer/Policy Loss                12.7574
trainer/Q1 Predictions Mean       -11.1526
trainer/Q1 Predictions Std          4.15228
trainer/Q1 Predictions Max         -9.84233
trainer/Q1 Predictions Min        -33.1714
trainer/Q2 Predictions Mean       -11.1461
trainer/Q2 Predictions Std          4.17255
trainer/Q2 Predictions Max         -9.83102
trainer/Q2 Predictions Min        -33.2622
trainer/Q Targets Mean            -11.2943
trainer/Q Targets Std               4.09562
trainer/Q Targets Max              -9.90447
trainer/Q Targets Min             -33.6441
trainer/Log Pis Mean                1.84991
trainer/Log Pis Std                 1.28937
trainer/Log Pis Max                 5.50845
trainer/Log Pis Min                -3.54102
trainer/Policy mu Mean              0.0683319
trainer/Policy mu Std               0.600696
trainer/Policy mu Max               2.90806
trainer/Policy mu Min              -2.90186
trainer/Policy log std Mean        -2.13115
trainer/Policy log std Std          0.41925
trainer/Policy log std Max         -0.681465
trainer/Policy log std Min         -2.59634
trainer/Alpha                       0.0477282
trainer/Alpha Loss                 -0.45662
exploration/num steps total     26200
exploration/num paths total       262
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.259207
exploration/Rewards Std             0.570207
exploration/Rewards Max            -0.0216002
exploration/Rewards Min            -4.08799
exploration/Returns Mean          -25.9207
exploration/Returns Std             0.00116797
exploration/Returns Max           -25.9196
exploration/Returns Min           -25.9219
exploration/Actions Mean           -0.00107024
exploration/Actions Std             0.220105
exploration/Actions Max             0.996189
exploration/Actions Min            -0.998217
exploration/Num Paths               2
exploration/Average Returns       -25.9207
evaluation/num steps total     130000
evaluation/num paths total       1300
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.193126
evaluation/Rewards Std              0.715683
evaluation/Rewards Max             -0.0660381
evaluation/Rewards Min             -9.15581
evaluation/Returns Mean           -19.3126
evaluation/Returns Std             13.6824
evaluation/Returns Max             -7.70975
evaluation/Returns Min            -54.6026
evaluation/Actions Mean             0.0191375
evaluation/Actions Std              0.152896
evaluation/Actions Max              0.995773
evaluation/Actions Min             -0.991919
evaluation/Num Paths               10
evaluation/Average Returns        -19.3126
time/data storing (s)               0.00133879
time/evaluation sampling (s)        0.221928
time/exploration sampling (s)       0.0655707
time/logging (s)                    0.00251402
time/saving (s)                     0.00196826
time/training (s)                   0.77801
time/epoch (s)                      1.07133
time/total (s)                    141.046
Epoch                             129
-----------------------------  ---------------
2019-04-21 00:46:34.692006 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 130 finished
-----------------------------  ---------------
replay_buffer/size              26400
trainer/QF1 Loss                    1.16973
trainer/QF2 Loss                    1.19653
trainer/Policy Loss                13.8486
trainer/Q1 Predictions Mean       -12.2337
trainer/Q1 Predictions Std          8.53947
trainer/Q1 Predictions Max         -9.87963
trainer/Q1 Predictions Min        -65.7353
trainer/Q2 Predictions Mean       -12.2264
trainer/Q2 Predictions Std          8.51753
trainer/Q2 Predictions Max         -9.85407
trainer/Q2 Predictions Min        -65.962
trainer/Q Targets Mean            -12.2212
trainer/Q Targets Std               8.6339
trainer/Q Targets Max              -0.36765
trainer/Q Targets Min             -66.2897
trainer/Log Pis Mean                2.04485
trainer/Log Pis Std                 1.33478
trainer/Log Pis Max                 7.03145
trainer/Log Pis Min                -1.5683
trainer/Policy mu Mean              0.0953631
trainer/Policy mu Std               0.739185
trainer/Policy mu Max               3.19551
trainer/Policy mu Min              -2.6348
trainer/Policy log std Mean        -2.0519
trainer/Policy log std Std          0.447294
trainer/Policy log std Max         -0.309985
trainer/Policy log std Min         -2.51134
trainer/Alpha                       0.0471341
trainer/Alpha Loss                  0.136984
exploration/num steps total     26400
exploration/num paths total       264
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.259296
exploration/Rewards Std             0.681848
exploration/Rewards Max            -0.0130038
exploration/Rewards Min            -6.51966
exploration/Returns Mean          -25.9296
exploration/Returns Std             9.61467
exploration/Returns Max           -16.3149
exploration/Returns Min           -35.5443
exploration/Actions Mean            0.00800983
exploration/Actions Std             0.208221
exploration/Actions Max             0.976849
exploration/Actions Min            -0.882079
exploration/Num Paths               2
exploration/Average Returns       -25.9296
evaluation/num steps total     131000
evaluation/num paths total       1310
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.233313
evaluation/Rewards Std              1.03938
evaluation/Rewards Max             -0.0197619
evaluation/Rewards Min            -10.4385
evaluation/Returns Mean           -23.3313
evaluation/Returns Std             19.1059
evaluation/Returns Max             -2.88078
evaluation/Returns Min            -60.2783
evaluation/Actions Mean             0.0160191
evaluation/Actions Std              0.180103
evaluation/Actions Max              0.99799
evaluation/Actions Min             -0.994721
evaluation/Num Paths               10
evaluation/Average Returns        -23.3313
time/data storing (s)               0.00123558
time/evaluation sampling (s)        0.231192
time/exploration sampling (s)       0.0649927
time/logging (s)                    0.00335623
time/saving (s)                     0.00191787
time/training (s)                   0.777497
time/epoch (s)                      1.08019
time/total (s)                    142.131
Epoch                             130
-----------------------------  ---------------
2019-04-21 00:46:35.786897 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 131 finished
-----------------------------  ----------------
replay_buffer/size              26600
trainer/QF1 Loss                    1.99917
trainer/QF2 Loss                    2.00538
trainer/Policy Loss                12.5932
trainer/Q1 Predictions Mean       -10.7968
trainer/Q1 Predictions Std          4.80845
trainer/Q1 Predictions Max         -9.69931
trainer/Q1 Predictions Min        -53.8561
trainer/Q2 Predictions Mean       -10.7931
trainer/Q2 Predictions Std          4.82586
trainer/Q2 Predictions Max         -9.69628
trainer/Q2 Predictions Min        -54.1348
trainer/Q Targets Mean            -10.835
trainer/Q Targets Std               5.15044
trainer/Q Targets Max              -0.0655693
trainer/Q Targets Min             -54.4918
trainer/Log Pis Mean                2.07199
trainer/Log Pis Std                 1.09064
trainer/Log Pis Max                 5.78027
trainer/Log Pis Min                -1.89103
trainer/Policy mu Mean              0.0371013
trainer/Policy mu Std               0.534095
trainer/Policy mu Max               3.0319
trainer/Policy mu Min              -2.28922
trainer/Policy log std Mean        -2.2506
trainer/Policy log std Std          0.397136
trainer/Policy log std Max         -0.554347
trainer/Policy log std Min         -2.68196
trainer/Alpha                       0.0461702
trainer/Alpha Loss                  0.221421
exploration/num steps total     26600
exploration/num paths total       266
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.272878
exploration/Rewards Std             0.741836
exploration/Rewards Max            -0.00694966
exploration/Rewards Min            -5.27418
exploration/Returns Mean          -27.2878
exploration/Returns Std             2.9062
exploration/Returns Max           -24.3816
exploration/Returns Min           -30.194
exploration/Actions Mean            0.000379578
exploration/Actions Std             0.210725
exploration/Actions Max             0.996814
exploration/Actions Min            -0.997756
exploration/Num Paths               2
exploration/Average Returns       -27.2878
evaluation/num steps total     132000
evaluation/num paths total       1320
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.285145
evaluation/Rewards Std              1.13604
evaluation/Rewards Max             -0.0347521
evaluation/Rewards Min             -9.62816
evaluation/Returns Mean           -28.5145
evaluation/Returns Std             17.4326
evaluation/Returns Max             -4.37599
evaluation/Returns Min            -55.7621
evaluation/Actions Mean             0.0210455
evaluation/Actions Std              0.187769
evaluation/Actions Max              0.99578
evaluation/Actions Min             -0.991596
evaluation/Num Paths               10
evaluation/Average Returns        -28.5145
time/data storing (s)               0.00168184
time/evaluation sampling (s)        0.232946
time/exploration sampling (s)       0.0665849
time/logging (s)                    0.00337431
time/saving (s)                     0.00212465
time/training (s)                   0.781175
time/epoch (s)                      1.08789
time/total (s)                    143.223
Epoch                             131
-----------------------------  ----------------
2019-04-21 00:46:36.867657 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 132 finished
-----------------------------  ---------------
replay_buffer/size              26800
trainer/QF1 Loss                    1.20794
trainer/QF2 Loss                    1.2178
trainer/Policy Loss                13.4573
trainer/Q1 Predictions Mean       -11.3691
trainer/Q1 Predictions Std          6.5221
trainer/Q1 Predictions Max         -9.86101
trainer/Q1 Predictions Min        -66.9887
trainer/Q2 Predictions Mean       -11.4261
trainer/Q2 Predictions Std          6.54041
trainer/Q2 Predictions Max         -9.8721
trainer/Q2 Predictions Min        -67.2186
trainer/Q Targets Mean            -11.3499
trainer/Q Targets Std               6.85457
trainer/Q Targets Max              -0.102699
trainer/Q Targets Min             -67.6921
trainer/Log Pis Mean                2.21947
trainer/Log Pis Std                 1.2978
trainer/Log Pis Max                 8.78179
trainer/Log Pis Min                -4.15406
trainer/Policy mu Mean              0.0824137
trainer/Policy mu Std               0.661925
trainer/Policy mu Max               3.29377
trainer/Policy mu Min              -3.08831
trainer/Policy log std Mean        -2.18579
trainer/Policy log std Std          0.458077
trainer/Policy log std Max         -0.055035
trainer/Policy log std Min         -2.63084
trainer/Alpha                       0.0470849
trainer/Alpha Loss                  0.670645
exploration/num steps total     26800
exploration/num paths total       268
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.49238
exploration/Rewards Std             1.44398
exploration/Rewards Max            -0.0163736
exploration/Rewards Min           -10.0639
exploration/Returns Mean          -49.238
exploration/Returns Std            18.8016
exploration/Returns Max           -30.4365
exploration/Returns Min           -68.0396
exploration/Actions Mean            0.0263302
exploration/Actions Std             0.240523
exploration/Actions Max             0.998963
exploration/Actions Min            -0.996294
exploration/Num Paths               2
exploration/Average Returns       -49.238
evaluation/num steps total     133000
evaluation/num paths total       1330
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.279605
evaluation/Rewards Std              0.963125
evaluation/Rewards Max             -0.0565439
evaluation/Rewards Min             -9.01655
evaluation/Returns Mean           -27.9605
evaluation/Returns Std             13.7538
evaluation/Returns Max             -9.3086
evaluation/Returns Min            -51.4048
evaluation/Actions Mean             0.0244362
evaluation/Actions Std              0.180445
evaluation/Actions Max              0.996293
evaluation/Actions Min             -0.992882
evaluation/Num Paths               10
evaluation/Average Returns        -27.9605
time/data storing (s)               0.0012885
time/evaluation sampling (s)        0.219335
time/exploration sampling (s)       0.0637059
time/logging (s)                    0.00331478
time/saving (s)                     0.00200673
time/training (s)                   0.784417
time/epoch (s)                      1.07407
time/total (s)                    144.302
Epoch                             132
-----------------------------  ---------------
2019-04-21 00:46:37.955867 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 133 finished
-----------------------------  ---------------
replay_buffer/size              27000
trainer/QF1 Loss                    0.142537
trainer/QF2 Loss                    0.141964
trainer/Policy Loss                13.4313
trainer/Q1 Predictions Mean       -11.6774
trainer/Q1 Predictions Std          7.50624
trainer/Q1 Predictions Max         -9.70145
trainer/Q1 Predictions Min        -68.7046
trainer/Q2 Predictions Mean       -11.6596
trainer/Q2 Predictions Std          7.5333
trainer/Q2 Predictions Max         -9.63645
trainer/Q2 Predictions Min        -68.7807
trainer/Q Targets Mean            -11.7886
trainer/Q Targets Std               7.7044
trainer/Q Targets Max              -9.70917
trainer/Q Targets Min             -70.6386
trainer/Log Pis Mean                2.14256
trainer/Log Pis Std                 1.06316
trainer/Log Pis Max                 5.92911
trainer/Log Pis Min                -0.667328
trainer/Policy mu Mean              0.158567
trainer/Policy mu Std               0.679369
trainer/Policy mu Max               3.21716
trainer/Policy mu Min              -1.8281
trainer/Policy log std Mean        -2.09687
trainer/Policy log std Std          0.475254
trainer/Policy log std Max         -0.195663
trainer/Policy log std Min         -2.56945
trainer/Alpha                       0.0476644
trainer/Alpha Loss                  0.433946
exploration/num steps total     27000
exploration/num paths total       270
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.489048
exploration/Rewards Std             1.38358
exploration/Rewards Max            -0.0151303
exploration/Rewards Min            -9.77946
exploration/Returns Mean          -48.9048
exploration/Returns Std            15.2983
exploration/Returns Max           -33.6065
exploration/Returns Min           -64.2031
exploration/Actions Mean            0.0451924
exploration/Actions Std             0.25448
exploration/Actions Max             0.998867
exploration/Actions Min            -0.87167
exploration/Num Paths               2
exploration/Average Returns       -48.9048
evaluation/num steps total     134000
evaluation/num paths total       1340
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.216482
evaluation/Rewards Std              0.855325
evaluation/Rewards Max             -0.0509972
evaluation/Rewards Min             -8.62506
evaluation/Returns Mean           -21.6482
evaluation/Returns Std             11.5659
evaluation/Returns Max             -7.81108
evaluation/Returns Min            -43.3945
evaluation/Actions Mean             0.0272857
evaluation/Actions Std              0.179229
evaluation/Actions Max              0.995263
evaluation/Actions Min             -0.992525
evaluation/Num Paths               10
evaluation/Average Returns        -21.6482
time/data storing (s)               0.00126578
time/evaluation sampling (s)        0.220398
time/exploration sampling (s)       0.0656435
time/logging (s)                    0.00333303
time/saving (s)                     0.0019877
time/training (s)                   0.789083
time/epoch (s)                      1.08171
time/total (s)                    145.388
Epoch                             133
-----------------------------  ---------------
2019-04-21 00:46:39.045011 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 134 finished
-----------------------------  ---------------
replay_buffer/size              27200
trainer/QF1 Loss                    1.10421
trainer/QF2 Loss                    1.08549
trainer/Policy Loss                12.5105
trainer/Q1 Predictions Mean       -10.6587
trainer/Q1 Predictions Std          3.24835
trainer/Q1 Predictions Max         -9.60731
trainer/Q1 Predictions Min        -31.2665
trainer/Q2 Predictions Mean       -10.6831
trainer/Q2 Predictions Std          3.28511
trainer/Q2 Predictions Max         -9.60265
trainer/Q2 Predictions Min        -31.4845
trainer/Q Targets Mean            -10.7027
trainer/Q Targets Std               3.60226
trainer/Q Targets Max              -0.0691865
trainer/Q Targets Min             -35.0319
trainer/Log Pis Mean                1.99874
trainer/Log Pis Std                 1.36274
trainer/Log Pis Max                 7.9196
trainer/Log Pis Min                -5.29878
trainer/Policy mu Mean              0.0575844
trainer/Policy mu Std               0.581812
trainer/Policy mu Max               2.7494
trainer/Policy mu Min              -3.09337
trainer/Policy log std Mean        -2.17954
trainer/Policy log std Std          0.404348
trainer/Policy log std Max         -0.479892
trainer/Policy log std Min         -2.57371
trainer/Alpha                       0.0474868
trainer/Alpha Loss                 -0.00384918
exploration/num steps total     27200
exploration/num paths total       272
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.316485
exploration/Rewards Std             1.04448
exploration/Rewards Max            -0.0083088
exploration/Rewards Min            -9.01316
exploration/Returns Mean          -31.6485
exploration/Returns Std            18.2678
exploration/Returns Max           -13.3807
exploration/Returns Min           -49.9163
exploration/Actions Mean            0.0323029
exploration/Actions Std             0.220627
exploration/Actions Max             0.999896
exploration/Actions Min            -0.99004
exploration/Num Paths               2
exploration/Average Returns       -31.6485
evaluation/num steps total     135000
evaluation/num paths total       1350
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.29571
evaluation/Rewards Std              1.14666
evaluation/Rewards Max             -0.0406861
evaluation/Rewards Min            -10.0682
evaluation/Returns Mean           -29.571
evaluation/Returns Std             16.0247
evaluation/Returns Max             -8.51276
evaluation/Returns Min            -54.1157
evaluation/Actions Mean             0.0243674
evaluation/Actions Std              0.201352
evaluation/Actions Max              0.996717
evaluation/Actions Min             -0.996353
evaluation/Num Paths               10
evaluation/Average Returns        -29.571
time/data storing (s)               0.00130723
time/evaluation sampling (s)        0.223336
time/exploration sampling (s)       0.0721922
time/logging (s)                    0.00334566
time/saving (s)                     0.00199809
time/training (s)                   0.780482
time/epoch (s)                      1.08266
time/total (s)                    146.474
Epoch                             134
-----------------------------  ---------------
2019-04-21 00:46:40.139772 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 135 finished
-----------------------------  ---------------
replay_buffer/size              27400
trainer/QF1 Loss                    0.232916
trainer/QF2 Loss                    0.191359
trainer/Policy Loss                13.1584
trainer/Q1 Predictions Mean       -11.4789
trainer/Q1 Predictions Std          6.25036
trainer/Q1 Predictions Max         -9.63612
trainer/Q1 Predictions Min        -54.0382
trainer/Q2 Predictions Mean       -11.4832
trainer/Q2 Predictions Std          6.32677
trainer/Q2 Predictions Max         -9.60344
trainer/Q2 Predictions Min        -54.4821
trainer/Q Targets Mean            -11.5566
trainer/Q Targets Std               6.32125
trainer/Q Targets Max              -9.65123
trainer/Q Targets Min             -54.0288
trainer/Log Pis Mean                2.05314
trainer/Log Pis Std                 1.49501
trainer/Log Pis Max                 7.62836
trainer/Log Pis Min                -2.97695
trainer/Policy mu Mean             -0.012775
trainer/Policy mu Std               0.679637
trainer/Policy mu Max               3.15851
trainer/Policy mu Min              -3.04922
trainer/Policy log std Mean        -2.17708
trainer/Policy log std Std          0.448362
trainer/Policy log std Max         -0.445933
trainer/Policy log std Min         -2.62064
trainer/Alpha                       0.048418
trainer/Alpha Loss                  0.160911
exploration/num steps total     27400
exploration/num paths total       274
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.344643
exploration/Rewards Std             1.11757
exploration/Rewards Max            -0.0127468
exploration/Rewards Min            -9.17111
exploration/Returns Mean          -34.4643
exploration/Returns Std            18.1438
exploration/Returns Max           -16.3205
exploration/Returns Min           -52.6081
exploration/Actions Mean            0.0234398
exploration/Actions Std             0.23421
exploration/Actions Max             0.998867
exploration/Actions Min            -0.988091
exploration/Num Paths               2
exploration/Average Returns       -34.4643
evaluation/num steps total     136000
evaluation/num paths total       1360
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.256306
evaluation/Rewards Std              1.07124
evaluation/Rewards Max             -0.020014
evaluation/Rewards Min            -10.3373
evaluation/Returns Mean           -25.6306
evaluation/Returns Std             14.4924
evaluation/Returns Max             -9.58893
evaluation/Returns Min            -52.1953
evaluation/Actions Mean             0.041618
evaluation/Actions Std              0.204547
evaluation/Actions Max              0.997533
evaluation/Actions Min             -0.982793
evaluation/Num Paths               10
evaluation/Average Returns        -25.6306
time/data storing (s)               0.00159472
time/evaluation sampling (s)        0.227366
time/exploration sampling (s)       0.0681437
time/logging (s)                    0.00335456
time/saving (s)                     0.00198451
time/training (s)                   0.785621
time/epoch (s)                      1.08806
time/total (s)                    147.566
Epoch                             135
-----------------------------  ---------------
2019-04-21 00:46:41.229960 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 136 finished
-----------------------------  ---------------
replay_buffer/size              27600
trainer/QF1 Loss                    0.972107
trainer/QF2 Loss                    0.982517
trainer/Policy Loss                12.1486
trainer/Q1 Predictions Mean       -10.432
trainer/Q1 Predictions Std          3.06433
trainer/Q1 Predictions Max         -9.59658
trainer/Q1 Predictions Min        -35.6405
trainer/Q2 Predictions Mean       -10.4306
trainer/Q2 Predictions Std          3.08658
trainer/Q2 Predictions Max         -9.57586
trainer/Q2 Predictions Min        -35.817
trainer/Q Targets Mean            -10.371
trainer/Q Targets Std               3.28196
trainer/Q Targets Max              -0.0639161
trainer/Q Targets Min             -36.3142
trainer/Log Pis Mean                1.863
trainer/Log Pis Std                 1.07815
trainer/Log Pis Max                 5.08248
trainer/Log Pis Min                -2.07303
trainer/Policy mu Mean              0.0843098
trainer/Policy mu Std               0.472043
trainer/Policy mu Max               2.88042
trainer/Policy mu Min              -2.30408
trainer/Policy log std Mean        -2.19714
trainer/Policy log std Std          0.379734
trainer/Policy log std Max         -0.484695
trainer/Policy log std Min         -2.62108
trainer/Alpha                       0.0485669
trainer/Alpha Loss                 -0.414401
exploration/num steps total     27600
exploration/num paths total       276
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.307124
exploration/Rewards Std             0.914242
exploration/Rewards Max            -0.0131192
exploration/Rewards Min            -7.5772
exploration/Returns Mean          -30.7124
exploration/Returns Std            16.0458
exploration/Returns Max           -14.6666
exploration/Returns Min           -46.7583
exploration/Actions Mean            0.0110071
exploration/Actions Std             0.221411
exploration/Actions Max             0.999417
exploration/Actions Min            -0.96838
exploration/Num Paths               2
exploration/Average Returns       -30.7124
evaluation/num steps total     137000
evaluation/num paths total       1370
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.269166
evaluation/Rewards Std              1.07465
evaluation/Rewards Max             -0.0142845
evaluation/Rewards Min             -9.57296
evaluation/Returns Mean           -26.9166
evaluation/Returns Std             15.4706
evaluation/Returns Max             -5.25895
evaluation/Returns Min            -55.2784
evaluation/Actions Mean             0.0251904
evaluation/Actions Std              0.192153
evaluation/Actions Max              0.995324
evaluation/Actions Min             -0.992873
evaluation/Num Paths               10
evaluation/Average Returns        -26.9166
time/data storing (s)               0.00130275
time/evaluation sampling (s)        0.231912
time/exploration sampling (s)       0.0648725
time/logging (s)                    0.00341163
time/saving (s)                     0.00197172
time/training (s)                   0.780232
time/epoch (s)                      1.0837
time/total (s)                    148.654
Epoch                             136
-----------------------------  ---------------
2019-04-21 00:46:42.317966 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 137 finished
-----------------------------  ---------------
replay_buffer/size              27800
trainer/QF1 Loss                    2.88176
trainer/QF2 Loss                    2.87972
trainer/Policy Loss                13.2445
trainer/Q1 Predictions Mean       -11.6821
trainer/Q1 Predictions Std          8.05701
trainer/Q1 Predictions Max         -9.31378
trainer/Q1 Predictions Min        -57.4751
trainer/Q2 Predictions Mean       -11.6702
trainer/Q2 Predictions Std          8.04877
trainer/Q2 Predictions Max         -9.29185
trainer/Q2 Predictions Min        -57.4858
trainer/Q Targets Mean            -11.6229
trainer/Q Targets Std               8.25576
trainer/Q Targets Max              -0.105802
trainer/Q Targets Min             -57.3476
trainer/Log Pis Mean                1.9913
trainer/Log Pis Std                 1.57753
trainer/Log Pis Max                 8.87464
trainer/Log Pis Min                -2.56752
trainer/Policy mu Mean              0.0550879
trainer/Policy mu Std               0.751901
trainer/Policy mu Max               3.08431
trainer/Policy mu Min              -3.06056
trainer/Policy log std Mean        -2.06938
trainer/Policy log std Std          0.455933
trainer/Policy log std Max         -0.3937
trainer/Policy log std Min         -2.5167
trainer/Alpha                       0.0499812
trainer/Alpha Loss                 -0.0260774
exploration/num steps total     27800
exploration/num paths total       278
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.361444
exploration/Rewards Std             0.966126
exploration/Rewards Max            -0.00448449
exploration/Rewards Min            -6.5838
exploration/Returns Mean          -36.1444
exploration/Returns Std             0.694057
exploration/Returns Max           -35.4503
exploration/Returns Min           -36.8384
exploration/Actions Mean            0.0266527
exploration/Actions Std             0.247899
exploration/Actions Max             0.989415
exploration/Actions Min            -0.991636
exploration/Num Paths               2
exploration/Average Returns       -36.1444
evaluation/num steps total     138000
evaluation/num paths total       1380
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.273589
evaluation/Rewards Std              0.992119
evaluation/Rewards Max             -0.0638969
evaluation/Rewards Min             -9.27911
evaluation/Returns Mean           -27.3589
evaluation/Returns Std             14.3097
evaluation/Returns Max            -11.227
evaluation/Returns Min            -54.0775
evaluation/Actions Mean             0.0258132
evaluation/Actions Std              0.182292
evaluation/Actions Max              0.996157
evaluation/Actions Min             -0.995385
evaluation/Num Paths               10
evaluation/Average Returns        -27.3589
time/data storing (s)               0.00140592
time/evaluation sampling (s)        0.227941
time/exploration sampling (s)       0.064964
time/logging (s)                    0.00336057
time/saving (s)                     0.002149
time/training (s)                   0.781315
time/epoch (s)                      1.08114
time/total (s)                    149.74
Epoch                             137
-----------------------------  ---------------
2019-04-21 00:46:43.406816 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 138 finished
-----------------------------  ---------------
replay_buffer/size              28000
trainer/QF1 Loss                    1.28626
trainer/QF2 Loss                    1.2876
trainer/Policy Loss                12.8695
trainer/Q1 Predictions Mean       -11.1261
trainer/Q1 Predictions Std          4.41813
trainer/Q1 Predictions Max         -9.34923
trainer/Q1 Predictions Min        -30.7493
trainer/Q2 Predictions Mean       -11.1176
trainer/Q2 Predictions Std          4.38203
trainer/Q2 Predictions Max         -9.35937
trainer/Q2 Predictions Min        -31.0123
trainer/Q Targets Mean            -11.2175
trainer/Q Targets Std               4.73092
trainer/Q Targets Max              -0.177496
trainer/Q Targets Min             -34.6189
trainer/Log Pis Mean                2.07499
trainer/Log Pis Std                 1.31031
trainer/Log Pis Max                 7.74772
trainer/Log Pis Min                -1.76706
trainer/Policy mu Mean             -0.0075261
trainer/Policy mu Std               0.725893
trainer/Policy mu Max               3.07616
trainer/Policy mu Min              -3.07648
trainer/Policy log std Mean        -2.10699
trainer/Policy log std Std          0.48048
trainer/Policy log std Max         -0.416165
trainer/Policy log std Min         -2.59963
trainer/Alpha                       0.0498692
trainer/Alpha Loss                  0.224839
exploration/num steps total     28000
exploration/num paths total       280
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.333553
exploration/Rewards Std             0.965958
exploration/Rewards Max            -0.00638635
exploration/Rewards Min            -7.94348
exploration/Returns Mean          -33.3553
exploration/Returns Std             7.29776
exploration/Returns Max           -26.0575
exploration/Returns Min           -40.6531
exploration/Actions Mean           -0.00565801
exploration/Actions Std             0.245026
exploration/Actions Max             0.993504
exploration/Actions Min            -0.99756
exploration/Num Paths               2
exploration/Average Returns       -33.3553
evaluation/num steps total     139000
evaluation/num paths total       1390
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.191411
evaluation/Rewards Std              0.852506
evaluation/Rewards Max             -0.0110902
evaluation/Rewards Min             -7.99944
evaluation/Returns Mean           -19.1411
evaluation/Returns Std             11.905
evaluation/Returns Max             -2.64425
evaluation/Returns Min            -35.352
evaluation/Actions Mean             0.0184892
evaluation/Actions Std              0.174604
evaluation/Actions Max              0.994919
evaluation/Actions Min             -0.988941
evaluation/Num Paths               10
evaluation/Average Returns        -19.1411
time/data storing (s)               0.00141272
time/evaluation sampling (s)        0.237504
time/exploration sampling (s)       0.0710411
time/logging (s)                    0.00334776
time/saving (s)                     0.00196368
time/training (s)                   0.76695
time/epoch (s)                      1.08222
time/total (s)                    150.826
Epoch                             138
-----------------------------  ---------------
2019-04-21 00:46:44.476042 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 139 finished
-----------------------------  ---------------
replay_buffer/size              28200
trainer/QF1 Loss                    1.21642
trainer/QF2 Loss                    1.27121
trainer/Policy Loss                13.6925
trainer/Q1 Predictions Mean       -12.2475
trainer/Q1 Predictions Std          9.82805
trainer/Q1 Predictions Max         -9.51883
trainer/Q1 Predictions Min        -71.5925
trainer/Q2 Predictions Mean       -12.2551
trainer/Q2 Predictions Std          9.83472
trainer/Q2 Predictions Max         -9.50516
trainer/Q2 Predictions Min        -71.5371
trainer/Q Targets Mean            -12.1864
trainer/Q Targets Std              10.1477
trainer/Q Targets Max              -0.652025
trainer/Q Targets Min             -72.3392
trainer/Log Pis Mean                2.0649
trainer/Log Pis Std                 1.42276
trainer/Log Pis Max                 8.99319
trainer/Log Pis Min                -1.43678
trainer/Policy mu Mean              0.115747
trainer/Policy mu Std               0.70533
trainer/Policy mu Max               3.10022
trainer/Policy mu Min              -2.59572
trainer/Policy log std Mean        -2.06986
trainer/Policy log std Std          0.454466
trainer/Policy log std Max         -0.446444
trainer/Policy log std Min         -2.56842
trainer/Alpha                       0.0504311
trainer/Alpha Loss                  0.193866
exploration/num steps total     28200
exploration/num paths total       282
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.301642
exploration/Rewards Std             0.810755
exploration/Rewards Max            -0.0196084
exploration/Rewards Min            -6.93474
exploration/Returns Mean          -30.1642
exploration/Returns Std             8.20638
exploration/Returns Max           -21.9578
exploration/Returns Min           -38.3706
exploration/Actions Mean            0.0463186
exploration/Actions Std             0.233967
exploration/Actions Max             0.996626
exploration/Actions Min            -0.42151
exploration/Num Paths               2
exploration/Average Returns       -30.1642
evaluation/num steps total     140000
evaluation/num paths total       1400
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.292087
evaluation/Rewards Std              1.0993
evaluation/Rewards Max             -0.055658
evaluation/Rewards Min             -9.82618
evaluation/Returns Mean           -29.2087
evaluation/Returns Std             17.473
evaluation/Returns Max             -6.73639
evaluation/Returns Min            -57.0489
evaluation/Actions Mean             0.0364553
evaluation/Actions Std              0.191348
evaluation/Actions Max              0.99616
evaluation/Actions Min             -0.973819
evaluation/Num Paths               10
evaluation/Average Returns        -29.2087
time/data storing (s)               0.00136603
time/evaluation sampling (s)        0.224922
time/exploration sampling (s)       0.0674926
time/logging (s)                    0.00334582
time/saving (s)                     0.001982
time/training (s)                   0.763497
time/epoch (s)                      1.06261
time/total (s)                    151.893
Epoch                             139
-----------------------------  ---------------
2019-04-21 00:46:45.560871 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 140 finished
-----------------------------  ---------------
replay_buffer/size              28400
trainer/QF1 Loss                    0.167036
trainer/QF2 Loss                    0.167307
trainer/Policy Loss                13.4231
trainer/Q1 Predictions Mean       -11.7543
trainer/Q1 Predictions Std          8.67347
trainer/Q1 Predictions Max         -9.3716
trainer/Q1 Predictions Min        -64.5689
trainer/Q2 Predictions Mean       -11.7782
trainer/Q2 Predictions Std          8.6851
trainer/Q2 Predictions Max         -9.37332
trainer/Q2 Predictions Min        -64.4204
trainer/Q Targets Mean            -11.7794
trainer/Q Targets Std               8.672
trainer/Q Targets Max              -9.3092
trainer/Q Targets Min             -63.107
trainer/Log Pis Mean                2.19101
trainer/Log Pis Std                 1.52192
trainer/Log Pis Max                 7.97206
trainer/Log Pis Min                -3.54829
trainer/Policy mu Mean              0.0278377
trainer/Policy mu Std               0.693891
trainer/Policy mu Max               3.00952
trainer/Policy mu Min              -3.08523
trainer/Policy log std Mean        -2.09844
trainer/Policy log std Std          0.458133
trainer/Policy log std Max         -0.515504
trainer/Policy log std Min         -2.56696
trainer/Alpha                       0.0498621
trainer/Alpha Loss                  0.572699
exploration/num steps total     28400
exploration/num paths total       284
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.454673
exploration/Rewards Std             1.30994
exploration/Rewards Max            -0.015011
exploration/Rewards Min            -9.14562
exploration/Returns Mean          -45.4673
exploration/Returns Std            12.8753
exploration/Returns Max           -32.5919
exploration/Returns Min           -58.3426
exploration/Actions Mean            0.0298931
exploration/Actions Std             0.249606
exploration/Actions Max             0.998596
exploration/Actions Min            -0.932702
exploration/Num Paths               2
exploration/Average Returns       -45.4673
evaluation/num steps total     141000
evaluation/num paths total       1410
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.283616
evaluation/Rewards Std              1.18753
evaluation/Rewards Max             -0.0185627
evaluation/Rewards Min            -10.7317
evaluation/Returns Mean           -28.3616
evaluation/Returns Std             17.1198
evaluation/Returns Max             -7.55509
evaluation/Returns Min            -58.8819
evaluation/Actions Mean             0.0339218
evaluation/Actions Std              0.207078
evaluation/Actions Max              0.996859
evaluation/Actions Min             -0.992431
evaluation/Num Paths               10
evaluation/Average Returns        -28.3616
time/data storing (s)               0.00127571
time/evaluation sampling (s)        0.22713
time/exploration sampling (s)       0.0671304
time/logging (s)                    0.00254831
time/saving (s)                     0.00197171
time/training (s)                   0.777301
time/epoch (s)                      1.07736
time/total (s)                    152.974
Epoch                             140
-----------------------------  ---------------
2019-04-21 00:46:46.705983 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 141 finished
-----------------------------  ---------------
replay_buffer/size              28600
trainer/QF1 Loss                    0.0808459
trainer/QF2 Loss                    0.0765506
trainer/Policy Loss                11.8144
trainer/Q1 Predictions Mean       -10.0774
trainer/Q1 Predictions Std          3.5984
trainer/Q1 Predictions Max         -9.22025
trainer/Q1 Predictions Min        -44.2971
trainer/Q2 Predictions Mean       -10.0895
trainer/Q2 Predictions Std          3.62589
trainer/Q2 Predictions Max         -9.22675
trainer/Q2 Predictions Min        -44.567
trainer/Q Targets Mean            -10.23
trainer/Q Targets Std               3.74683
trainer/Q Targets Max              -9.27853
trainer/Q Targets Min             -45.9177
trainer/Log Pis Mean                2.03079
trainer/Log Pis Std                 1.115
trainer/Log Pis Max                 4.17142
trainer/Log Pis Min                -2.18495
trainer/Policy mu Mean              0.0853647
trainer/Policy mu Std               0.48314
trainer/Policy mu Max               2.93307
trainer/Policy mu Min              -2.17231
trainer/Policy log std Mean        -2.23246
trainer/Policy log std Std          0.40384
trainer/Policy log std Max         -0.584964
trainer/Policy log std Min         -2.68413
trainer/Alpha                       0.0500848
trainer/Alpha Loss                  0.0922038
exploration/num steps total     28600
exploration/num paths total       286
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.378822
exploration/Rewards Std             1.06992
exploration/Rewards Max            -0.00758699
exploration/Rewards Min            -8.42788
exploration/Returns Mean          -37.8822
exploration/Returns Std            15.505
exploration/Returns Max           -22.3772
exploration/Returns Min           -53.3872
exploration/Actions Mean            0.0080181
exploration/Actions Std             0.230838
exploration/Actions Max             0.99929
exploration/Actions Min            -0.986898
exploration/Num Paths               2
exploration/Average Returns       -37.8822
evaluation/num steps total     142000
evaluation/num paths total       1420
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.290172
evaluation/Rewards Std              0.955543
evaluation/Rewards Max             -0.0245367
evaluation/Rewards Min            -10.002
evaluation/Returns Mean           -29.0172
evaluation/Returns Std             13.745
evaluation/Returns Max            -13.2438
evaluation/Returns Min            -64.5543
evaluation/Actions Mean             0.0242229
evaluation/Actions Std              0.197105
evaluation/Actions Max              0.996083
evaluation/Actions Min             -0.992973
evaluation/Num Paths               10
evaluation/Average Returns        -29.0172
time/data storing (s)               0.00158733
time/evaluation sampling (s)        0.239464
time/exploration sampling (s)       0.0902144
time/logging (s)                    0.0027739
time/saving (s)                     0.00211305
time/training (s)                   0.802529
time/epoch (s)                      1.13868
time/total (s)                    154.117
Epoch                             141
-----------------------------  ---------------
2019-04-21 00:46:47.947229 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 142 finished
-----------------------------  ---------------
replay_buffer/size              28800
trainer/QF1 Loss                    1.20334
trainer/QF2 Loss                    1.21549
trainer/Policy Loss                13.0873
trainer/Q1 Predictions Mean       -11.5946
trainer/Q1 Predictions Std          8.26368
trainer/Q1 Predictions Max         -9.33995
trainer/Q1 Predictions Min        -66.6803
trainer/Q2 Predictions Mean       -11.6346
trainer/Q2 Predictions Std          8.30299
trainer/Q2 Predictions Max         -9.36245
trainer/Q2 Predictions Min        -67.1156
trainer/Q Targets Mean            -11.5667
trainer/Q Targets Std               8.75657
trainer/Q Targets Max              -0.236972
trainer/Q Targets Min             -69.3043
trainer/Log Pis Mean                1.97657
trainer/Log Pis Std                 1.18049
trainer/Log Pis Max                 6.03984
trainer/Log Pis Min                -2.53255
trainer/Policy mu Mean              0.093562
trainer/Policy mu Std               0.676412
trainer/Policy mu Max               3.08004
trainer/Policy mu Min              -2.64921
trainer/Policy log std Mean        -2.03821
trainer/Policy log std Std          0.464357
trainer/Policy log std Max         -0.26926
trainer/Policy log std Min         -2.53222
trainer/Alpha                       0.0495633
trainer/Alpha Loss                 -0.0703893
exploration/num steps total     28800
exploration/num paths total       288
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.354003
exploration/Rewards Std             1.10693
exploration/Rewards Max            -0.00603558
exploration/Rewards Min            -9.3388
exploration/Returns Mean          -35.4003
exploration/Returns Std            20.8606
exploration/Returns Max           -14.5397
exploration/Returns Min           -56.2609
exploration/Actions Mean            0.00581321
exploration/Actions Std             0.231939
exploration/Actions Max             0.998045
exploration/Actions Min            -0.989372
exploration/Num Paths               2
exploration/Average Returns       -35.4003
evaluation/num steps total     143000
evaluation/num paths total       1430
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.237862
evaluation/Rewards Std              0.825161
evaluation/Rewards Max             -0.0186383
evaluation/Rewards Min             -9.76884
evaluation/Returns Mean           -23.7862
evaluation/Returns Std             14.2486
evaluation/Returns Max             -8.91391
evaluation/Returns Min            -59.8666
evaluation/Actions Mean             0.0268851
evaluation/Actions Std              0.167117
evaluation/Actions Max              0.995742
evaluation/Actions Min             -0.989135
evaluation/Num Paths               10
evaluation/Average Returns        -23.7862
time/data storing (s)               0.00124355
time/evaluation sampling (s)        0.260118
time/exploration sampling (s)       0.0777495
time/logging (s)                    0.0039996
time/saving (s)                     0.00252429
time/training (s)                   0.88967
time/epoch (s)                      1.23531
time/total (s)                    155.357
Epoch                             142
-----------------------------  ---------------
2019-04-21 00:46:49.134949 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 143 finished
-----------------------------  ---------------
replay_buffer/size              29000
trainer/QF1 Loss                    0.0547663
trainer/QF2 Loss                    0.0446189
trainer/Policy Loss                12.366
trainer/Q1 Predictions Mean       -10.8042
trainer/Q1 Predictions Std          6.93964
trainer/Q1 Predictions Max         -9.24438
trainer/Q1 Predictions Min        -56.7456
trainer/Q2 Predictions Mean       -10.8069
trainer/Q2 Predictions Std          6.91115
trainer/Q2 Predictions Max         -9.24053
trainer/Q2 Predictions Min        -56.8674
trainer/Q Targets Mean            -10.806
trainer/Q Targets Std               6.90836
trainer/Q Targets Max              -9.1812
trainer/Q Targets Min             -57.4838
trainer/Log Pis Mean                1.95687
trainer/Log Pis Std                 1.10159
trainer/Log Pis Max                 5.6483
trainer/Log Pis Min                -2.60416
trainer/Policy mu Mean              0.0454485
trainer/Policy mu Std               0.565024
trainer/Policy mu Max               3.03242
trainer/Policy mu Min              -1.88342
trainer/Policy log std Mean        -2.11673
trainer/Policy log std Std          0.400131
trainer/Policy log std Max         -0.48196
trainer/Policy log std Min         -2.55686
trainer/Alpha                       0.0489723
trainer/Alpha Loss                 -0.130097
exploration/num steps total     29000
exploration/num paths total       290
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.199506
exploration/Rewards Std             0.446783
exploration/Rewards Max            -0.022436
exploration/Rewards Min            -4.50433
exploration/Returns Mean          -19.9506
exploration/Returns Std             6.15498
exploration/Returns Max           -13.7957
exploration/Returns Min           -26.1056
exploration/Actions Mean            0.0195682
exploration/Actions Std             0.190729
exploration/Actions Max             0.985087
exploration/Actions Min            -0.414212
exploration/Num Paths               2
exploration/Average Returns       -19.9506
evaluation/num steps total     144000
evaluation/num paths total       1440
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.259694
evaluation/Rewards Std              1.04107
evaluation/Rewards Max             -0.0357784
evaluation/Rewards Min             -9.48008
evaluation/Returns Mean           -25.9694
evaluation/Returns Std             15.5286
evaluation/Returns Max             -5.60487
evaluation/Returns Min            -50.0537
evaluation/Actions Mean             0.0260223
evaluation/Actions Std              0.192848
evaluation/Actions Max              0.996875
evaluation/Actions Min             -0.990179
evaluation/Num Paths               10
evaluation/Average Returns        -25.9694
time/data storing (s)               0.00161428
time/evaluation sampling (s)        0.240692
time/exploration sampling (s)       0.0658786
time/logging (s)                    0.00299468
time/saving (s)                     0.00202475
time/training (s)                   0.866139
time/epoch (s)                      1.17934
time/total (s)                    156.541
Epoch                             143
-----------------------------  ---------------
2019-04-21 00:46:50.282231 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 144 finished
-----------------------------  ---------------
replay_buffer/size              29200
trainer/QF1 Loss                    0.985288
trainer/QF2 Loss                    0.960531
trainer/Policy Loss                13.3103
trainer/Q1 Predictions Mean       -11.5769
trainer/Q1 Predictions Std          9.84161
trainer/Q1 Predictions Max         -9.08046
trainer/Q1 Predictions Min        -70.68
trainer/Q2 Predictions Mean       -11.6035
trainer/Q2 Predictions Std          9.8411
trainer/Q2 Predictions Max         -9.11467
trainer/Q2 Predictions Min        -70.7101
trainer/Q Targets Mean            -11.6722
trainer/Q Targets Std              10.0149
trainer/Q Targets Max              -0.219528
trainer/Q Targets Min             -71.6504
trainer/Log Pis Mean                2.06999
trainer/Log Pis Std                 1.25452
trainer/Log Pis Max                 8.09489
trainer/Log Pis Min                -1.19505
trainer/Policy mu Mean              0.119899
trainer/Policy mu Std               0.684788
trainer/Policy mu Max               3.23022
trainer/Policy mu Min              -3.00711
trainer/Policy log std Mean        -2.1416
trainer/Policy log std Std          0.440504
trainer/Policy log std Max         -0.367496
trainer/Policy log std Min         -2.57416
trainer/Alpha                       0.0472994
trainer/Alpha Loss                  0.213562
exploration/num steps total     29200
exploration/num paths total       292
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.362608
exploration/Rewards Std             1.09313
exploration/Rewards Max            -0.00456713
exploration/Rewards Min            -8.54694
exploration/Returns Mean          -36.2608
exploration/Returns Std            17.207
exploration/Returns Max           -19.0538
exploration/Returns Min           -53.4678
exploration/Actions Mean            0.0195596
exploration/Actions Std             0.225011
exploration/Actions Max             0.998985
exploration/Actions Min            -0.993774
exploration/Num Paths               2
exploration/Average Returns       -36.2608
evaluation/num steps total     145000
evaluation/num paths total       1450
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.292202
evaluation/Rewards Std              1.13321
evaluation/Rewards Max             -0.0295005
evaluation/Rewards Min            -10.9129
evaluation/Returns Mean           -29.2202
evaluation/Returns Std             14.8812
evaluation/Returns Max             -7.86761
evaluation/Returns Min            -60.8018
evaluation/Actions Mean             0.043851
evaluation/Actions Std              0.202393
evaluation/Actions Max              0.997796
evaluation/Actions Min             -0.965142
evaluation/Num Paths               10
evaluation/Average Returns        -29.2202
time/data storing (s)               0.00142814
time/evaluation sampling (s)        0.264448
time/exploration sampling (s)       0.0714439
time/logging (s)                    0.00347257
time/saving (s)                     0.00182074
time/training (s)                   0.798135
time/epoch (s)                      1.14075
time/total (s)                    157.686
Epoch                             144
-----------------------------  ---------------
2019-04-21 00:46:51.371043 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 145 finished
-----------------------------  ---------------
replay_buffer/size              29400
trainer/QF1 Loss                    0.225245
trainer/QF2 Loss                    0.200936
trainer/Policy Loss                12.3291
trainer/Q1 Predictions Mean       -10.5112
trainer/Q1 Predictions Std          5.39041
trainer/Q1 Predictions Max         -9.03603
trainer/Q1 Predictions Min        -50.7348
trainer/Q2 Predictions Mean       -10.5345
trainer/Q2 Predictions Std          5.42488
trainer/Q2 Predictions Max         -9.0611
trainer/Q2 Predictions Min        -50.9968
trainer/Q Targets Mean            -10.6957
trainer/Q Targets Std               5.56105
trainer/Q Targets Max              -9.10069
trainer/Q Targets Min             -49.885
trainer/Log Pis Mean                2.1657
trainer/Log Pis Std                 1.26726
trainer/Log Pis Max                 7.87273
trainer/Log Pis Min                -0.871344
trainer/Policy mu Mean              0.0580434
trainer/Policy mu Std               0.64062
trainer/Policy mu Max               3.14542
trainer/Policy mu Min              -3.13157
trainer/Policy log std Mean        -2.20672
trainer/Policy log std Std          0.436089
trainer/Policy log std Max         -0.363943
trainer/Policy log std Min         -2.65952
trainer/Alpha                       0.0471666
trainer/Alpha Loss                  0.506053
exploration/num steps total     29400
exploration/num paths total       294
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.386584
exploration/Rewards Std             1.07079
exploration/Rewards Max            -0.00967086
exploration/Rewards Min            -8.17699
exploration/Returns Mean          -38.6584
exploration/Returns Std             9.93773
exploration/Returns Max           -28.7207
exploration/Returns Min           -48.5961
exploration/Actions Mean            0.00416953
exploration/Actions Std             0.228383
exploration/Actions Max             0.997691
exploration/Actions Min            -0.987637
exploration/Num Paths               2
exploration/Average Returns       -38.6584
evaluation/num steps total     146000
evaluation/num paths total       1460
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.192819
evaluation/Rewards Std              0.613572
evaluation/Rewards Max             -0.0558431
evaluation/Rewards Min             -7.06785
evaluation/Returns Mean           -19.2819
evaluation/Returns Std              8.25763
evaluation/Returns Max             -9.42136
evaluation/Returns Min            -32.8312
evaluation/Actions Mean             0.0129704
evaluation/Actions Std              0.164676
evaluation/Actions Max              0.992852
evaluation/Actions Min             -0.994797
evaluation/Num Paths               10
evaluation/Average Returns        -19.2819
time/data storing (s)               0.00139334
time/evaluation sampling (s)        0.224567
time/exploration sampling (s)       0.0605489
time/logging (s)                    0.00338705
time/saving (s)                     0.0019866
time/training (s)                   0.791258
time/epoch (s)                      1.08314
time/total (s)                    158.773
Epoch                             145
-----------------------------  ---------------
2019-04-21 00:46:52.549357 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 146 finished
-----------------------------  ---------------
replay_buffer/size              29600
trainer/QF1 Loss                    0.905816
trainer/QF2 Loss                    0.907995
trainer/Policy Loss                12.8447
trainer/Q1 Predictions Mean       -11.103
trainer/Q1 Predictions Std          7.66188
trainer/Q1 Predictions Max         -9.03112
trainer/Q1 Predictions Min        -58.843
trainer/Q2 Predictions Mean       -11.0956
trainer/Q2 Predictions Std          7.66234
trainer/Q2 Predictions Max         -9.02732
trainer/Q2 Predictions Min        -58.8315
trainer/Q Targets Mean            -11.0559
trainer/Q Targets Std               7.7675
trainer/Q Targets Max              -0.0354318
trainer/Q Targets Min             -60.4106
trainer/Log Pis Mean                2.05366
trainer/Log Pis Std                 1.29891
trainer/Log Pis Max                 5.75876
trainer/Log Pis Min                -2.79115
trainer/Policy mu Mean              0.0906932
trainer/Policy mu Std               0.6317
trainer/Policy mu Max               3.1072
trainer/Policy mu Min              -2.75508
trainer/Policy log std Mean        -2.15526
trainer/Policy log std Std          0.425244
trainer/Policy log std Max         -0.600468
trainer/Policy log std Min         -2.59371
trainer/Alpha                       0.0475998
trainer/Alpha Loss                  0.163372
exploration/num steps total     29600
exploration/num paths total       296
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.370845
exploration/Rewards Std             1.22322
exploration/Rewards Max            -0.0096351
exploration/Rewards Min            -9.99689
exploration/Returns Mean          -37.0845
exploration/Returns Std            19.4342
exploration/Returns Max           -17.6504
exploration/Returns Min           -56.5187
exploration/Actions Mean            0.0368183
exploration/Actions Std             0.244637
exploration/Actions Max             0.994278
exploration/Actions Min            -0.989424
exploration/Num Paths               2
exploration/Average Returns       -37.0845
evaluation/num steps total     147000
evaluation/num paths total       1470
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.245544
evaluation/Rewards Std              1.073
evaluation/Rewards Max             -0.0238272
evaluation/Rewards Min            -10.1565
evaluation/Returns Mean           -24.5544
evaluation/Returns Std             16.918
evaluation/Returns Max             -2.97346
evaluation/Returns Min            -55.2357
evaluation/Actions Mean             0.0266268
evaluation/Actions Std              0.19284
evaluation/Actions Max              0.996717
evaluation/Actions Min             -0.990133
evaluation/Num Paths               10
evaluation/Average Returns        -24.5544
time/data storing (s)               0.00114166
time/evaluation sampling (s)        0.230014
time/exploration sampling (s)       0.0575242
time/logging (s)                    0.00305615
time/saving (s)                     0.00195244
time/training (s)                   0.877308
time/epoch (s)                      1.171
time/total (s)                    159.948
Epoch                             146
-----------------------------  ---------------
2019-04-21 00:46:53.620952 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 147 finished
-----------------------------  ---------------
replay_buffer/size              29800
trainer/QF1 Loss                    0.122676
trainer/QF2 Loss                    0.0888769
trainer/Policy Loss                11.9023
trainer/Q1 Predictions Mean       -10.1522
trainer/Q1 Predictions Std          4.92179
trainer/Q1 Predictions Max         -8.90408
trainer/Q1 Predictions Min        -45.3738
trainer/Q2 Predictions Mean       -10.1883
trainer/Q2 Predictions Std          4.92195
trainer/Q2 Predictions Max         -8.93761
trainer/Q2 Predictions Min        -45.4335
trainer/Q Targets Mean            -10.2977
trainer/Q Targets Std               4.87518
trainer/Q Targets Max              -8.9617
trainer/Q Targets Min             -45.1969
trainer/Log Pis Mean                2.05455
trainer/Log Pis Std                 1.06323
trainer/Log Pis Max                 7.46894
trainer/Log Pis Min                -0.886838
trainer/Policy mu Mean              0.0705896
trainer/Policy mu Std               0.580368
trainer/Policy mu Max               2.96279
trainer/Policy mu Min              -2.23302
trainer/Policy log std Mean        -2.16618
trainer/Policy log std Std          0.424398
trainer/Policy log std Max         -0.683671
trainer/Policy log std Min         -2.60262
trainer/Alpha                       0.0481429
trainer/Alpha Loss                  0.1655
exploration/num steps total     29800
exploration/num paths total       298
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.191941
exploration/Rewards Std             0.409628
exploration/Rewards Max            -0.0118552
exploration/Rewards Min            -3.88914
exploration/Returns Mean          -19.1941
exploration/Returns Std             2.81938
exploration/Returns Max           -16.3747
exploration/Returns Min           -22.0135
exploration/Actions Mean            0.0161684
exploration/Actions Std             0.202853
exploration/Actions Max             0.998931
exploration/Actions Min            -0.819029
exploration/Num Paths               2
exploration/Average Returns       -19.1941
evaluation/num steps total     148000
evaluation/num paths total       1480
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.204421
evaluation/Rewards Std              0.939879
evaluation/Rewards Max             -0.00250441
evaluation/Rewards Min             -9.48551
evaluation/Returns Mean           -20.4421
evaluation/Returns Std             13.2458
evaluation/Returns Max             -4.09474
evaluation/Returns Min            -43.3982
evaluation/Actions Mean             0.0211035
evaluation/Actions Std              0.197056
evaluation/Actions Max              0.995457
evaluation/Actions Min             -0.993884
evaluation/Num Paths               10
evaluation/Average Returns        -20.4421
time/data storing (s)               0.00110896
time/evaluation sampling (s)        0.236662
time/exploration sampling (s)       0.0581826
time/logging (s)                    0.00334887
time/saving (s)                     0.00197747
time/training (s)                   0.764418
time/epoch (s)                      1.0657
time/total (s)                    161.018
Epoch                             147
-----------------------------  ---------------
2019-04-21 00:46:54.852567 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 148 finished
-----------------------------  ---------------
replay_buffer/size              30000
trainer/QF1 Loss                    1.83318
trainer/QF2 Loss                    1.83418
trainer/Policy Loss                12.8101
trainer/Q1 Predictions Mean       -11.0343
trainer/Q1 Predictions Std          5.82748
trainer/Q1 Predictions Max         -9.0945
trainer/Q1 Predictions Min        -42.1147
trainer/Q2 Predictions Mean       -11.0061
trainer/Q2 Predictions Std          5.81646
trainer/Q2 Predictions Max         -9.07845
trainer/Q2 Predictions Min        -42.1926
trainer/Q Targets Mean            -10.7686
trainer/Q Targets Std               6.0129
trainer/Q Targets Max              -0.383193
trainer/Q Targets Min             -42.1669
trainer/Log Pis Mean                2.17278
trainer/Log Pis Std                 1.19733
trainer/Log Pis Max                 8.40258
trainer/Log Pis Min                -1.04558
trainer/Policy mu Mean              0.103925
trainer/Policy mu Std               0.731314
trainer/Policy mu Max               3.05772
trainer/Policy mu Min              -1.70783
trainer/Policy log std Mean        -2.09646
trainer/Policy log std Std          0.48027
trainer/Policy log std Max         -0.437413
trainer/Policy log std Min         -2.59332
trainer/Alpha                       0.0476218
trainer/Alpha Loss                  0.52605
exploration/num steps total     30000
exploration/num paths total       300
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.238482
exploration/Rewards Std             0.584371
exploration/Rewards Max            -0.0175214
exploration/Rewards Min            -4.19846
exploration/Returns Mean          -23.8482
exploration/Returns Std             0.806861
exploration/Returns Max           -23.0414
exploration/Returns Min           -24.6551
exploration/Actions Mean           -0.0233846
exploration/Actions Std             0.211931
exploration/Actions Max             0.905472
exploration/Actions Min            -0.996133
exploration/Num Paths               2
exploration/Average Returns       -23.8482
evaluation/num steps total     149000
evaluation/num paths total       1490
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.221164
evaluation/Rewards Std              0.871171
evaluation/Rewards Max             -0.018671
evaluation/Rewards Min             -9.03095
evaluation/Returns Mean           -22.1164
evaluation/Returns Std             12.7075
evaluation/Returns Max             -7.38669
evaluation/Returns Min            -47.1528
evaluation/Actions Mean             0.0215443
evaluation/Actions Std              0.177363
evaluation/Actions Max              0.995429
evaluation/Actions Min             -0.996165
evaluation/Num Paths               10
evaluation/Average Returns        -22.1164
time/data storing (s)               0.00121321
time/evaluation sampling (s)        0.253044
time/exploration sampling (s)       0.0653476
time/logging (s)                    0.00320405
time/saving (s)                     0.00208393
time/training (s)                   0.899552
time/epoch (s)                      1.22444
time/total (s)                    162.247
Epoch                             148
-----------------------------  ---------------
2019-04-21 00:46:55.979309 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 149 finished
-----------------------------  ---------------
replay_buffer/size              30200
trainer/QF1 Loss                    0.843259
trainer/QF2 Loss                    0.842989
trainer/Policy Loss                10.6462
trainer/Q1 Predictions Mean        -9.11595
trainer/Q1 Predictions Std          0.33735
trainer/Q1 Predictions Max         -8.85225
trainer/Q1 Predictions Min        -10.8383
trainer/Q2 Predictions Mean        -9.12914
trainer/Q2 Predictions Std          0.344538
trainer/Q2 Predictions Max         -8.85383
trainer/Q2 Predictions Min        -10.9772
trainer/Q Targets Mean             -9.16004
trainer/Q Targets Std               0.947862
trainer/Q Targets Max              -0.521896
trainer/Q Targets Min             -11.234
trainer/Log Pis Mean                1.65869
trainer/Log Pis Std                 1.11325
trainer/Log Pis Max                 2.89069
trainer/Log Pis Min                -2.67089
trainer/Policy mu Mean             -0.0131162
trainer/Policy mu Std               0.262608
trainer/Policy mu Max               1.04797
trainer/Policy mu Min              -1.44801
trainer/Policy log std Mean        -2.22537
trainer/Policy log std Std          0.245137
trainer/Policy log std Max         -1.43171
trainer/Policy log std Min         -2.56164
trainer/Alpha                       0.047595
trainer/Alpha Loss                 -1.03929
exploration/num steps total     30200
exploration/num paths total       302
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.500146
exploration/Rewards Std             1.42821
exploration/Rewards Max            -0.00523069
exploration/Rewards Min            -9.59477
exploration/Returns Mean          -50.0146
exploration/Returns Std            11.1739
exploration/Returns Max           -38.8407
exploration/Returns Min           -61.1885
exploration/Actions Mean            0.0653253
exploration/Actions Std             0.27485
exploration/Actions Max             0.998994
exploration/Actions Min            -0.549851
exploration/Num Paths               2
exploration/Average Returns       -50.0146
evaluation/num steps total     150000
evaluation/num paths total       1500
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.237937
evaluation/Rewards Std              1.0036
evaluation/Rewards Max             -0.0168528
evaluation/Rewards Min             -9.14569
evaluation/Returns Mean           -23.7937
evaluation/Returns Std             14.1697
evaluation/Returns Max             -3.92147
evaluation/Returns Min            -49.1924
evaluation/Actions Mean             0.0227994
evaluation/Actions Std              0.188211
evaluation/Actions Max              0.996083
evaluation/Actions Min             -0.993353
evaluation/Num Paths               10
evaluation/Average Returns        -23.7937
time/data storing (s)               0.0012018
time/evaluation sampling (s)        0.244961
time/exploration sampling (s)       0.0672259
time/logging (s)                    0.00334418
time/saving (s)                     0.00197259
time/training (s)                   0.801353
time/epoch (s)                      1.12006
time/total (s)                    163.371
Epoch                             149
-----------------------------  ---------------
2019-04-21 00:46:57.092244 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 150 finished
-----------------------------  ---------------
replay_buffer/size              30400
trainer/QF1 Loss                    1.01507
trainer/QF2 Loss                    1.02829
trainer/Policy Loss                12.4636
trainer/Q1 Predictions Mean       -10.561
trainer/Q1 Predictions Std          7.52334
trainer/Q1 Predictions Max         -8.79168
trainer/Q1 Predictions Min        -66.8962
trainer/Q2 Predictions Mean       -10.5964
trainer/Q2 Predictions Std          7.51521
trainer/Q2 Predictions Max         -8.83062
trainer/Q2 Predictions Min        -66.9236
trainer/Q Targets Mean            -10.5872
trainer/Q Targets Std               7.66203
trainer/Q Targets Max              -0.101949
trainer/Q Targets Min             -67.8139
trainer/Log Pis Mean                2.12223
trainer/Log Pis Std                 0.939541
trainer/Log Pis Max                 5.10317
trainer/Log Pis Min                -0.778515
trainer/Policy mu Mean              0.0093215
trainer/Policy mu Std               0.64805
trainer/Policy mu Max               3.33852
trainer/Policy mu Min              -2.64953
trainer/Policy log std Mean        -2.16134
trainer/Policy log std Std          0.449177
trainer/Policy log std Max         -0.410213
trainer/Policy log std Min         -2.62302
trainer/Alpha                       0.047423
trainer/Alpha Loss                  0.37264
exploration/num steps total     30400
exploration/num paths total       304
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.248268
exploration/Rewards Std             0.580153
exploration/Rewards Max            -0.00933395
exploration/Rewards Min            -5.49401
exploration/Returns Mean          -24.8268
exploration/Returns Std             7.07293
exploration/Returns Max           -17.7539
exploration/Returns Min           -31.8998
exploration/Actions Mean            0.0169922
exploration/Actions Std             0.210946
exploration/Actions Max             0.996627
exploration/Actions Min            -0.984343
exploration/Num Paths               2
exploration/Average Returns       -24.8268
evaluation/num steps total     151000
evaluation/num paths total       1510
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.282771
evaluation/Rewards Std              0.97922
evaluation/Rewards Max             -0.0188007
evaluation/Rewards Min            -10.0301
evaluation/Returns Mean           -28.2771
evaluation/Returns Std             17.6541
evaluation/Returns Max             -9.84396
evaluation/Returns Min            -64.3967
evaluation/Actions Mean             0.011157
evaluation/Actions Std              0.183423
evaluation/Actions Max              0.996468
evaluation/Actions Min             -0.994098
evaluation/Num Paths               10
evaluation/Average Returns        -28.2771
time/data storing (s)               0.00188545
time/evaluation sampling (s)        0.235562
time/exploration sampling (s)       0.0757853
time/logging (s)                    0.00334513
time/saving (s)                     0.00196195
time/training (s)                   0.787393
time/epoch (s)                      1.10593
time/total (s)                    164.482
Epoch                             150
-----------------------------  ---------------
2019-04-21 00:46:58.282492 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 151 finished
-----------------------------  ---------------
replay_buffer/size              30600
trainer/QF1 Loss                   10.2039
trainer/QF2 Loss                   10.1356
trainer/Policy Loss                11.9106
trainer/Q1 Predictions Mean       -10.2482
trainer/Q1 Predictions Std          5.03089
trainer/Q1 Predictions Max         -8.77437
trainer/Q1 Predictions Min        -39.1207
trainer/Q2 Predictions Mean       -10.3124
trainer/Q2 Predictions Std          5.05355
trainer/Q2 Predictions Max         -8.83297
trainer/Q2 Predictions Min        -39.0247
trainer/Q Targets Mean            -10.0725
trainer/Q Targets Std               4.22541
trainer/Q Targets Max              -7.39625
trainer/Q Targets Min             -33.6758
trainer/Log Pis Mean                1.89386
trainer/Log Pis Std                 1.42916
trainer/Log Pis Max                 8.03834
trainer/Log Pis Min                -4.98222
trainer/Policy mu Mean             -0.00183461
trainer/Policy mu Std               0.648224
trainer/Policy mu Max               2.77107
trainer/Policy mu Min              -3.09156
trainer/Policy log std Mean        -2.14697
trainer/Policy log std Std          0.431201
trainer/Policy log std Max         -0.429597
trainer/Policy log std Min         -2.57631
trainer/Alpha                       0.0472844
trainer/Alpha Loss                 -0.3239
exploration/num steps total     30600
exploration/num paths total       306
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.330549
exploration/Rewards Std             1.00223
exploration/Rewards Max            -0.00755839
exploration/Rewards Min            -8.09697
exploration/Returns Mean          -33.0549
exploration/Returns Std            16.6725
exploration/Returns Max           -16.3825
exploration/Returns Min           -49.7274
exploration/Actions Mean            0.0221262
exploration/Actions Std             0.211596
exploration/Actions Max             0.996437
exploration/Actions Min            -0.850407
exploration/Num Paths               2
exploration/Average Returns       -33.0549
evaluation/num steps total     152000
evaluation/num paths total       1520
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.1917
evaluation/Rewards Std              0.864056
evaluation/Rewards Max             -0.0380432
evaluation/Rewards Min             -9.55693
evaluation/Returns Mean           -19.17
evaluation/Returns Std             15.4803
evaluation/Returns Max             -4.46296
evaluation/Returns Min            -54.9474
evaluation/Actions Mean             0.0213177
evaluation/Actions Std              0.169941
evaluation/Actions Max              0.996009
evaluation/Actions Min             -0.995024
evaluation/Num Paths               10
evaluation/Average Returns        -19.17
time/data storing (s)               0.00130623
time/evaluation sampling (s)        0.248563
time/exploration sampling (s)       0.0810336
time/logging (s)                    0.00360209
time/saving (s)                     0.00208231
time/training (s)                   0.847076
time/epoch (s)                      1.18366
time/total (s)                    165.669
Epoch                             151
-----------------------------  ---------------
2019-04-21 00:46:59.398477 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 152 finished
-----------------------------  ---------------
replay_buffer/size              30800
trainer/QF1 Loss                    1.94235
trainer/QF2 Loss                    1.92245
trainer/Policy Loss                12.1973
trainer/Q1 Predictions Mean       -10.5159
trainer/Q1 Predictions Std          4.3903
trainer/Q1 Predictions Max         -8.79166
trainer/Q1 Predictions Min        -33.0836
trainer/Q2 Predictions Mean       -10.4973
trainer/Q2 Predictions Std          4.37808
trainer/Q2 Predictions Max         -8.75406
trainer/Q2 Predictions Min        -32.9598
trainer/Q Targets Mean            -10.2567
trainer/Q Targets Std               4.38688
trainer/Q Targets Max              -0.121672
trainer/Q Targets Min             -32.9821
trainer/Log Pis Mean                1.85255
trainer/Log Pis Std                 1.30949
trainer/Log Pis Max                 5.595
trainer/Log Pis Min                -2.69896
trainer/Policy mu Mean              0.158723
trainer/Policy mu Std               0.737243
trainer/Policy mu Max               3.06396
trainer/Policy mu Min              -2.56437
trainer/Policy log std Mean        -2.01881
trainer/Policy log std Std          0.487969
trainer/Policy log std Max         -0.337822
trainer/Policy log std Min         -2.53002
trainer/Alpha                       0.0470914
trainer/Alpha Loss                 -0.450566
exploration/num steps total     30800
exploration/num paths total       308
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.249275
exploration/Rewards Std             0.678791
exploration/Rewards Max            -0.0098148
exploration/Rewards Min            -6.17961
exploration/Returns Mean          -24.9275
exploration/Returns Std            11.7408
exploration/Returns Max           -13.1867
exploration/Returns Min           -36.6684
exploration/Actions Mean            0.0180739
exploration/Actions Std             0.205139
exploration/Actions Max             0.998893
exploration/Actions Min            -0.826337
exploration/Num Paths               2
exploration/Average Returns       -24.9275
evaluation/num steps total     153000
evaluation/num paths total       1530
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.243209
evaluation/Rewards Std              1.14048
evaluation/Rewards Max             -0.00818773
evaluation/Rewards Min            -10.676
evaluation/Returns Mean           -24.3209
evaluation/Returns Std             19.2553
evaluation/Returns Max             -2.44516
evaluation/Returns Min            -57.3011
evaluation/Actions Mean             0.0323448
evaluation/Actions Std              0.199525
evaluation/Actions Max              0.997851
evaluation/Actions Min             -0.994252
evaluation/Num Paths               10
evaluation/Average Returns        -24.3209
time/data storing (s)               0.00129587
time/evaluation sampling (s)        0.247627
time/exploration sampling (s)       0.0590594
time/logging (s)                    0.00344607
time/saving (s)                     0.00196562
time/training (s)                   0.795876
time/epoch (s)                      1.10927
time/total (s)                    166.783
Epoch                             152
-----------------------------  ---------------
2019-04-21 00:47:00.504564 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 153 finished
-----------------------------  ---------------
replay_buffer/size              31000
trainer/QF1 Loss                    0.273335
trainer/QF2 Loss                    0.281204
trainer/Policy Loss                12.3614
trainer/Q1 Predictions Mean       -10.4634
trainer/Q1 Predictions Std          5.29669
trainer/Q1 Predictions Max         -8.73857
trainer/Q1 Predictions Min        -40.441
trainer/Q2 Predictions Mean       -10.4356
trainer/Q2 Predictions Std          5.30086
trainer/Q2 Predictions Max         -8.71496
trainer/Q2 Predictions Min        -40.2868
trainer/Q Targets Mean            -10.5426
trainer/Q Targets Std               5.46647
trainer/Q Targets Max              -8.72721
trainer/Q Targets Min             -40.319
trainer/Log Pis Mean                2.1318
trainer/Log Pis Std                 1.46322
trainer/Log Pis Max                 8.3502
trainer/Log Pis Min                -2.22761
trainer/Policy mu Mean              0.0122333
trainer/Policy mu Std               0.729873
trainer/Policy mu Max               3.13478
trainer/Policy mu Min              -3.14226
trainer/Policy log std Mean        -2.11246
trainer/Policy log std Std          0.429768
trainer/Policy log std Max         -0.490234
trainer/Policy log std Min         -2.55622
trainer/Alpha                       0.0460676
trainer/Alpha Loss                  0.405627
exploration/num steps total     31000
exploration/num paths total       310
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.148299
exploration/Rewards Std             0.220937
exploration/Rewards Max            -0.0145766
exploration/Rewards Min            -2.6774
exploration/Returns Mean          -14.8299
exploration/Returns Std             2.41078
exploration/Returns Max           -12.4191
exploration/Returns Min           -17.2407
exploration/Actions Mean            0.00240635
exploration/Actions Std             0.164104
exploration/Actions Max             0.749823
exploration/Actions Min            -0.970718
exploration/Num Paths               2
exploration/Average Returns       -14.8299
evaluation/num steps total     154000
evaluation/num paths total       1540
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.219303
evaluation/Rewards Std              0.870881
evaluation/Rewards Max             -0.0203606
evaluation/Rewards Min             -9.83867
evaluation/Returns Mean           -21.9303
evaluation/Returns Std             14.1838
evaluation/Returns Max             -6.95579
evaluation/Returns Min            -57.1059
evaluation/Actions Mean             0.0138545
evaluation/Actions Std              0.18106
evaluation/Actions Max              0.997481
evaluation/Actions Min             -0.996141
evaluation/Num Paths               10
evaluation/Average Returns        -21.9303
time/data storing (s)               0.00122019
time/evaluation sampling (s)        0.229406
time/exploration sampling (s)       0.0618812
time/logging (s)                    0.00334287
time/saving (s)                     0.00196399
time/training (s)                   0.801229
time/epoch (s)                      1.09904
time/total (s)                    167.886
Epoch                             153
-----------------------------  ---------------
2019-04-21 00:47:01.611178 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 154 finished
-----------------------------  ---------------
replay_buffer/size              31200
trainer/QF1 Loss                    1.58053
trainer/QF2 Loss                    1.60616
trainer/Policy Loss                11.9046
trainer/Q1 Predictions Mean       -10.141
trainer/Q1 Predictions Std          6.47721
trainer/Q1 Predictions Max         -8.67127
trainer/Q1 Predictions Min        -62.8128
trainer/Q2 Predictions Mean       -10.1319
trainer/Q2 Predictions Std          6.45055
trainer/Q2 Predictions Max         -8.66389
trainer/Q2 Predictions Min        -62.6486
trainer/Q Targets Mean            -10.0863
trainer/Q Targets Std               6.65403
trainer/Q Targets Max              -0.0354318
trainer/Q Targets Min             -63.305
trainer/Log Pis Mean                1.95081
trainer/Log Pis Std                 1.20361
trainer/Log Pis Max                 6.82699
trainer/Log Pis Min                -2.97293
trainer/Policy mu Mean              0.0226969
trainer/Policy mu Std               0.564464
trainer/Policy mu Max               3.2531
trainer/Policy mu Min              -1.45881
trainer/Policy log std Mean        -2.17471
trainer/Policy log std Std          0.367491
trainer/Policy log std Max         -0.57839
trainer/Policy log std Min         -2.54905
trainer/Alpha                       0.04617
trainer/Alpha Loss                 -0.151274
exploration/num steps total     31200
exploration/num paths total       312
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.41162
exploration/Rewards Std             1.11381
exploration/Rewards Max            -0.0175119
exploration/Rewards Min            -8.39186
exploration/Returns Mean          -41.162
exploration/Returns Std             7.86492
exploration/Returns Max           -33.297
exploration/Returns Min           -49.0269
exploration/Actions Mean            0.00308709
exploration/Actions Std             0.245346
exploration/Actions Max             0.998836
exploration/Actions Min            -0.996392
exploration/Num Paths               2
exploration/Average Returns       -41.162
evaluation/num steps total     155000
evaluation/num paths total       1550
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.403535
evaluation/Rewards Std              1.29892
evaluation/Rewards Max             -0.0993969
evaluation/Rewards Min            -10.2674
evaluation/Returns Mean           -40.3535
evaluation/Returns Std             16.5293
evaluation/Returns Max            -12.754
evaluation/Returns Min            -66.538
evaluation/Actions Mean             0.025266
evaluation/Actions Std              0.210951
evaluation/Actions Max              0.997282
evaluation/Actions Min             -0.994986
evaluation/Num Paths               10
evaluation/Average Returns        -40.3535
time/data storing (s)               0.00119177
time/evaluation sampling (s)        0.233344
time/exploration sampling (s)       0.0706427
time/logging (s)                    0.00376554
time/saving (s)                     0.00202567
time/training (s)                   0.78926
time/epoch (s)                      1.10023
time/total (s)                    168.991
Epoch                             154
-----------------------------  ---------------
2019-04-21 00:47:02.835148 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 155 finished
-----------------------------  ---------------
replay_buffer/size              31400
trainer/QF1 Loss                    0.238035
trainer/QF2 Loss                    0.364671
trainer/Policy Loss                12.4481
trainer/Q1 Predictions Mean       -10.5038
trainer/Q1 Predictions Std          6.60997
trainer/Q1 Predictions Max         -8.61859
trainer/Q1 Predictions Min        -63.2432
trainer/Q2 Predictions Mean       -10.5203
trainer/Q2 Predictions Std          6.56788
trainer/Q2 Predictions Max         -8.66159
trainer/Q2 Predictions Min        -63.0417
trainer/Q Targets Mean            -10.7243
trainer/Q Targets Std               6.92085
trainer/Q Targets Max              -8.69106
trainer/Q Targets Min             -65.4128
trainer/Log Pis Mean                2.13779
trainer/Log Pis Std                 1.36179
trainer/Log Pis Max                 5.81347
trainer/Log Pis Min                -2.33898
trainer/Policy mu Mean              0.132879
trainer/Policy mu Std               0.68146
trainer/Policy mu Max               3.27937
trainer/Policy mu Min              -1.88662
trainer/Policy log std Mean        -2.12398
trainer/Policy log std Std          0.437078
trainer/Policy log std Max         -0.453335
trainer/Policy log std Min         -2.54638
trainer/Alpha                       0.0467031
trainer/Alpha Loss                  0.422179
exploration/num steps total     31400
exploration/num paths total       314
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.25675
exploration/Rewards Std             0.626811
exploration/Rewards Max            -0.0131573
exploration/Rewards Min            -5.5715
exploration/Returns Mean          -25.675
exploration/Returns Std             5.44484
exploration/Returns Max           -20.2302
exploration/Returns Min           -31.1199
exploration/Actions Mean            0.0359258
exploration/Actions Std             0.220326
exploration/Actions Max             0.996195
exploration/Actions Min            -0.471131
exploration/Num Paths               2
exploration/Average Returns       -25.675
evaluation/num steps total     156000
evaluation/num paths total       1560
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.279431
evaluation/Rewards Std              1.01018
evaluation/Rewards Max             -0.0200933
evaluation/Rewards Min             -9.16805
evaluation/Returns Mean           -27.9431
evaluation/Returns Std              9.3961
evaluation/Returns Max            -18.5456
evaluation/Returns Min            -45.4591
evaluation/Actions Mean             0.0293542
evaluation/Actions Std              0.20452
evaluation/Actions Max              0.997208
evaluation/Actions Min             -0.995737
evaluation/Num Paths               10
evaluation/Average Returns        -27.9431
time/data storing (s)               0.00123683
time/evaluation sampling (s)        0.257309
time/exploration sampling (s)       0.0660746
time/logging (s)                    0.00339814
time/saving (s)                     0.00282013
time/training (s)                   0.885396
time/epoch (s)                      1.21623
time/total (s)                    170.211
Epoch                             155
-----------------------------  ---------------
2019-04-21 00:47:03.948070 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 156 finished
-----------------------------  ---------------
replay_buffer/size              31600
trainer/QF1 Loss                    1.18196
trainer/QF2 Loss                    1.1088
trainer/Policy Loss                11.0821
trainer/Q1 Predictions Mean        -9.43891
trainer/Q1 Predictions Std          4.47567
trainer/Q1 Predictions Max         -8.47339
trainer/Q1 Predictions Min        -48.5096
trainer/Q2 Predictions Mean        -9.43751
trainer/Q2 Predictions Std          4.40226
trainer/Q2 Predictions Max         -8.50977
trainer/Q2 Predictions Min        -48.1751
trainer/Q Targets Mean             -9.52658
trainer/Q Targets Std               4.29716
trainer/Q Targets Max              -1.83997
trainer/Q Targets Min             -47.9672
trainer/Log Pis Mean                1.85502
trainer/Log Pis Std                 1.18844
trainer/Log Pis Max                 6.75114
trainer/Log Pis Min                -1.8232
trainer/Policy mu Mean              0.0404184
trainer/Policy mu Std               0.512552
trainer/Policy mu Max               3.10377
trainer/Policy mu Min              -1.76724
trainer/Policy log std Mean        -2.175
trainer/Policy log std Std          0.370001
trainer/Policy log std Max         -0.489322
trainer/Policy log std Min         -2.53653
trainer/Alpha                       0.0449539
trainer/Alpha Loss                 -0.449731
exploration/num steps total     31600
exploration/num paths total       316
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.215972
exploration/Rewards Std             0.5093
exploration/Rewards Max            -0.00791552
exploration/Rewards Min            -4.45938
exploration/Returns Mean          -21.5972
exploration/Returns Std             2.91779
exploration/Returns Max           -18.6794
exploration/Returns Min           -24.515
exploration/Actions Mean            0.0207597
exploration/Actions Std             0.211328
exploration/Actions Max             0.999033
exploration/Actions Min            -0.916114
exploration/Num Paths               2
exploration/Average Returns       -21.5972
evaluation/num steps total     157000
evaluation/num paths total       1570
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.154214
evaluation/Rewards Std              0.715173
evaluation/Rewards Max             -0.0190157
evaluation/Rewards Min             -8.11186
evaluation/Returns Mean           -15.4214
evaluation/Returns Std              9.78522
evaluation/Returns Max             -6.87298
evaluation/Returns Min            -39.5684
evaluation/Actions Mean             0.019636
evaluation/Actions Std              0.168878
evaluation/Actions Max              0.996866
evaluation/Actions Min             -0.988283
evaluation/Num Paths               10
evaluation/Average Returns        -15.4214
time/data storing (s)               0.00121447
time/evaluation sampling (s)        0.238683
time/exploration sampling (s)       0.0687985
time/logging (s)                    0.00307129
time/saving (s)                     0.00207313
time/training (s)                   0.791838
time/epoch (s)                      1.10568
time/total (s)                    171.321
Epoch                             156
-----------------------------  ---------------
2019-04-21 00:47:05.060984 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 157 finished
-----------------------------  ---------------
replay_buffer/size              31800
trainer/QF1 Loss                    0.975762
trainer/QF2 Loss                    0.9883
trainer/Policy Loss                12.2714
trainer/Q1 Predictions Mean       -10.6838
trainer/Q1 Predictions Std          7.09573
trainer/Q1 Predictions Max         -8.63296
trainer/Q1 Predictions Min        -60.448
trainer/Q2 Predictions Mean       -10.7008
trainer/Q2 Predictions Std          7.04552
trainer/Q2 Predictions Max         -8.68995
trainer/Q2 Predictions Min        -60.025
trainer/Q Targets Mean            -10.6361
trainer/Q Targets Std               7.26113
trainer/Q Targets Max              -0.177496
trainer/Q Targets Min             -61.9814
trainer/Log Pis Mean                1.95392
trainer/Log Pis Std                 1.47332
trainer/Log Pis Max                 6.59279
trainer/Log Pis Min                -2.92083
trainer/Policy mu Mean             -0.0199949
trainer/Policy mu Std               0.718496
trainer/Policy mu Max               3.09293
trainer/Policy mu Min              -2.72176
trainer/Policy log std Mean        -2.12557
trainer/Policy log std Std          0.435559
trainer/Policy log std Max         -0.583772
trainer/Policy log std Min         -2.49883
trainer/Alpha                       0.0443241
trainer/Alpha Loss                 -0.143592
exploration/num steps total     31800
exploration/num paths total       318
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.274032
exploration/Rewards Std             0.760099
exploration/Rewards Max            -0.00890229
exploration/Rewards Min            -6.61653
exploration/Returns Mean          -27.4032
exploration/Returns Std            10.2091
exploration/Returns Max           -17.1941
exploration/Returns Min           -37.6124
exploration/Actions Mean            0.0263487
exploration/Actions Std             0.220139
exploration/Actions Max             0.994553
exploration/Actions Min            -0.910011
exploration/Num Paths               2
exploration/Average Returns       -27.4032
evaluation/num steps total     158000
evaluation/num paths total       1580
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.247734
evaluation/Rewards Std              1.03379
evaluation/Rewards Max             -0.0308009
evaluation/Rewards Min             -9.56266
evaluation/Returns Mean           -24.7734
evaluation/Returns Std             14.1445
evaluation/Returns Max             -6.14649
evaluation/Returns Min            -51.3358
evaluation/Actions Mean             0.0265843
evaluation/Actions Std              0.200828
evaluation/Actions Max              0.997716
evaluation/Actions Min             -0.996465
evaluation/Num Paths               10
evaluation/Average Returns        -24.7734
time/data storing (s)               0.00177338
time/evaluation sampling (s)        0.229147
time/exploration sampling (s)       0.0818157
time/logging (s)                    0.00335917
time/saving (s)                     0.00180625
time/training (s)                   0.78916
time/epoch (s)                      1.10706
time/total (s)                    172.432
Epoch                             157
-----------------------------  ---------------
2019-04-21 00:47:06.151861 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 158 finished
-----------------------------  ---------------
replay_buffer/size              32000
trainer/QF1 Loss                    0.0375753
trainer/QF2 Loss                    0.0415551
trainer/Policy Loss                11.1519
trainer/Q1 Predictions Mean        -9.48284
trainer/Q1 Predictions Std          4.48191
trainer/Q1 Predictions Max         -8.59799
trainer/Q1 Predictions Min        -53.1438
trainer/Q2 Predictions Mean        -9.48466
trainer/Q2 Predictions Std          4.49344
trainer/Q2 Predictions Max         -8.58726
trainer/Q2 Predictions Min        -53.2319
trainer/Q Targets Mean             -9.5772
trainer/Q Targets Std               4.5874
trainer/Q Targets Max              -8.62203
trainer/Q Targets Min             -54.3851
trainer/Log Pis Mean                1.9457
trainer/Log Pis Std                 0.964515
trainer/Log Pis Max                 3.762
trainer/Log Pis Min                -1.88184
trainer/Policy mu Mean             -0.0243883
trainer/Policy mu Std               0.476786
trainer/Policy mu Max               3.09273
trainer/Policy mu Min              -2.29812
trainer/Policy log std Mean        -2.15598
trainer/Policy log std Std          0.346221
trainer/Policy log std Max         -0.536091
trainer/Policy log std Min         -2.51185
trainer/Alpha                       0.0435219
trainer/Alpha Loss                 -0.170202
exploration/num steps total     32000
exploration/num paths total       320
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.450135
exploration/Rewards Std             1.30614
exploration/Rewards Max            -0.0215938
exploration/Rewards Min            -9.42329
exploration/Returns Mean          -45.0135
exploration/Returns Std            17.8335
exploration/Returns Max           -27.18
exploration/Returns Min           -62.8469
exploration/Actions Mean            0.0496111
exploration/Actions Std             0.247134
exploration/Actions Max             0.99889
exploration/Actions Min            -0.370307
exploration/Num Paths               2
exploration/Average Returns       -45.0135
evaluation/num steps total     159000
evaluation/num paths total       1590
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.357972
evaluation/Rewards Std              1.26173
evaluation/Rewards Max             -0.0616831
evaluation/Rewards Min            -10.3734
evaluation/Returns Mean           -35.7972
evaluation/Returns Std             16.5656
evaluation/Returns Max            -10.4766
evaluation/Returns Min            -61.8202
evaluation/Actions Mean             0.0234247
evaluation/Actions Std              0.208258
evaluation/Actions Max              0.997235
evaluation/Actions Min             -0.995251
evaluation/Num Paths               10
evaluation/Average Returns        -35.7972
time/data storing (s)               0.00133394
time/evaluation sampling (s)        0.232039
time/exploration sampling (s)       0.0767301
time/logging (s)                    0.00337536
time/saving (s)                     0.00201752
time/training (s)                   0.768552
time/epoch (s)                      1.08405
time/total (s)                    173.52
Epoch                             158
-----------------------------  ---------------
2019-04-21 00:47:07.227640 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 159 finished
-----------------------------  ---------------
replay_buffer/size              32200
trainer/QF1 Loss                    0.582566
trainer/QF2 Loss                    0.566992
trainer/Policy Loss                13.5587
trainer/Q1 Predictions Mean       -11.7424
trainer/Q1 Predictions Std          8.16038
trainer/Q1 Predictions Max         -8.55344
trainer/Q1 Predictions Min        -49.2277
trainer/Q2 Predictions Mean       -11.719
trainer/Q2 Predictions Std          8.17353
trainer/Q2 Predictions Max         -8.54921
trainer/Q2 Predictions Min        -49.1272
trainer/Q Targets Mean            -11.7375
trainer/Q Targets Std               7.96527
trainer/Q Targets Max              -8.60074
trainer/Q Targets Min             -47.2463
trainer/Log Pis Mean                2.28656
trainer/Log Pis Std                 1.63303
trainer/Log Pis Max                 9.02155
trainer/Log Pis Min                -1.01714
trainer/Policy mu Mean              0.0421932
trainer/Policy mu Std               0.933288
trainer/Policy mu Max               3.03747
trainer/Policy mu Min              -3.13326
trainer/Policy log std Mean        -2.02305
trainer/Policy log std Std          0.521872
trainer/Policy log std Max         -0.518778
trainer/Policy log std Min         -2.50704
trainer/Alpha                       0.0425039
trainer/Alpha Loss                  0.905013
exploration/num steps total     32200
exploration/num paths total       322
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.152835
exploration/Rewards Std             0.151673
exploration/Rewards Max            -0.00841714
exploration/Rewards Min            -1.51953
exploration/Returns Mean          -15.2835
exploration/Returns Std             0.0732342
exploration/Returns Max           -15.2102
exploration/Returns Min           -15.3567
exploration/Actions Mean            0.00487324
exploration/Actions Std             0.175521
exploration/Actions Max             0.999051
exploration/Actions Min            -0.9498
exploration/Num Paths               2
exploration/Average Returns       -15.2835
evaluation/num steps total     160000
evaluation/num paths total       1600
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.158866
evaluation/Rewards Std              0.732936
evaluation/Rewards Max             -0.0250392
evaluation/Rewards Min             -8.73835
evaluation/Returns Mean           -15.8866
evaluation/Returns Std              9.96748
evaluation/Returns Max             -6.18356
evaluation/Returns Min            -38.088
evaluation/Actions Mean             0.0209147
evaluation/Actions Std              0.173477
evaluation/Actions Max              0.995824
evaluation/Actions Min             -0.993358
evaluation/Num Paths               10
evaluation/Average Returns        -15.8866
time/data storing (s)               0.0013052
time/evaluation sampling (s)        0.233621
time/exploration sampling (s)       0.0675929
time/logging (s)                    0.00338573
time/saving (s)                     0.00199941
time/training (s)                   0.761061
time/epoch (s)                      1.06896
time/total (s)                    174.593
Epoch                             159
-----------------------------  ---------------
2019-04-21 00:47:08.307489 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 160 finished
-----------------------------  ---------------
replay_buffer/size              32400
trainer/QF1 Loss                    0.756575
trainer/QF2 Loss                    0.757372
trainer/Policy Loss                11.6383
trainer/Q1 Predictions Mean        -9.95434
trainer/Q1 Predictions Std          6.17437
trainer/Q1 Predictions Max         -8.47888
trainer/Q1 Predictions Min        -56.685
trainer/Q2 Predictions Mean        -9.97551
trainer/Q2 Predictions Std          6.21138
trainer/Q2 Predictions Max         -8.50174
trainer/Q2 Predictions Min        -56.8998
trainer/Q Targets Mean            -10.0273
trainer/Q Targets Std               6.30547
trainer/Q Targets Max              -0.039143
trainer/Q Targets Min             -57.3402
trainer/Log Pis Mean                1.95337
trainer/Log Pis Std                 1.1049
trainer/Log Pis Max                 5.78203
trainer/Log Pis Min                -2.00653
trainer/Policy mu Mean              0.0802109
trainer/Policy mu Std               0.569722
trainer/Policy mu Max               3.16695
trainer/Policy mu Min              -1.56269
trainer/Policy log std Mean        -2.19161
trainer/Policy log std Std          0.408956
trainer/Policy log std Max         -0.575783
trainer/Policy log std Min         -2.5822
trainer/Alpha                       0.0432309
trainer/Alpha Loss                 -0.146472
exploration/num steps total     32400
exploration/num paths total       324
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.311495
exploration/Rewards Std             0.933475
exploration/Rewards Max            -0.00951059
exploration/Rewards Min            -7.49357
exploration/Returns Mean          -31.1495
exploration/Returns Std            13.5167
exploration/Returns Max           -17.6327
exploration/Returns Min           -44.6662
exploration/Actions Mean            0.0209793
exploration/Actions Std             0.214536
exploration/Actions Max             0.994755
exploration/Actions Min            -0.990856
exploration/Num Paths               2
exploration/Average Returns       -31.1495
evaluation/num steps total     161000
evaluation/num paths total       1610
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.236172
evaluation/Rewards Std              1.11261
evaluation/Rewards Max             -0.0116244
evaluation/Rewards Min             -9.86216
evaluation/Returns Mean           -23.6172
evaluation/Returns Std             20.8096
evaluation/Returns Max             -2.10772
evaluation/Returns Min            -56.1926
evaluation/Actions Mean             0.0224745
evaluation/Actions Std              0.179712
evaluation/Actions Max              0.997954
evaluation/Actions Min             -0.994188
evaluation/Num Paths               10
evaluation/Average Returns        -23.6172
time/data storing (s)               0.00121786
time/evaluation sampling (s)        0.226107
time/exploration sampling (s)       0.065039
time/logging (s)                    0.00360484
time/saving (s)                     0.00201711
time/training (s)                   0.775036
time/epoch (s)                      1.07302
time/total (s)                    175.67
Epoch                             160
-----------------------------  ---------------
2019-04-21 00:47:09.378008 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 161 finished
-----------------------------  ---------------
replay_buffer/size              32600
trainer/QF1 Loss                    0.801069
trainer/QF2 Loss                    0.81604
trainer/Policy Loss                12.0071
trainer/Q1 Predictions Mean       -10.1273
trainer/Q1 Predictions Std          6.41858
trainer/Q1 Predictions Max         -8.59335
trainer/Q1 Predictions Min        -54.7729
trainer/Q2 Predictions Mean       -10.1288
trainer/Q2 Predictions Std          6.38385
trainer/Q2 Predictions Max         -8.58049
trainer/Q2 Predictions Min        -54.6362
trainer/Q Targets Mean             -9.97406
trainer/Q Targets Std               6.35293
trainer/Q Targets Max              -0.547446
trainer/Q Targets Min             -54.1893
trainer/Log Pis Mean                2.16895
trainer/Log Pis Std                 1.29164
trainer/Log Pis Max                 7.73798
trainer/Log Pis Min                -3.57738
trainer/Policy mu Mean              0.0646081
trainer/Policy mu Std               0.627126
trainer/Policy mu Max               3.08529
trainer/Policy mu Min              -2.26054
trainer/Policy log std Mean        -2.15025
trainer/Policy log std Std          0.415025
trainer/Policy log std Max         -0.526404
trainer/Policy log std Min         -2.52269
trainer/Alpha                       0.0429344
trainer/Alpha Loss                  0.53188
exploration/num steps total     32600
exploration/num paths total       326
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.201175
exploration/Rewards Std             0.533745
exploration/Rewards Max            -0.0134236
exploration/Rewards Min            -5.54154
exploration/Returns Mean          -20.1175
exploration/Returns Std             7.14758
exploration/Returns Max           -12.97
exploration/Returns Min           -27.2651
exploration/Actions Mean            0.0274624
exploration/Actions Std             0.204065
exploration/Actions Max             0.995315
exploration/Actions Min            -0.514144
exploration/Num Paths               2
exploration/Average Returns       -20.1175
evaluation/num steps total     162000
evaluation/num paths total       1620
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.245848
evaluation/Rewards Std              1.0963
evaluation/Rewards Max             -0.011251
evaluation/Rewards Min             -9.22473
evaluation/Returns Mean           -24.5848
evaluation/Returns Std             18.5608
evaluation/Returns Max             -2.91114
evaluation/Returns Min            -50.3935
evaluation/Actions Mean             0.0214572
evaluation/Actions Std              0.186855
evaluation/Actions Max              0.995971
evaluation/Actions Min             -0.995237
evaluation/Num Paths               10
evaluation/Average Returns        -24.5848
time/data storing (s)               0.00121939
time/evaluation sampling (s)        0.227461
time/exploration sampling (s)       0.0652864
time/logging (s)                    0.00340084
time/saving (s)                     0.00195345
time/training (s)                   0.76373
time/epoch (s)                      1.06305
time/total (s)                    176.738
Epoch                             161
-----------------------------  ---------------
2019-04-21 00:47:10.451186 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 162 finished
-----------------------------  ---------------
replay_buffer/size              32800
trainer/QF1 Loss                    0.172269
trainer/QF2 Loss                    0.134495
trainer/Policy Loss                11.6323
trainer/Q1 Predictions Mean       -10.0339
trainer/Q1 Predictions Std          6.63307
trainer/Q1 Predictions Max         -8.39303
trainer/Q1 Predictions Min        -57.8356
trainer/Q2 Predictions Mean       -10.0811
trainer/Q2 Predictions Std          6.70983
trainer/Q2 Predictions Max         -8.42973
trainer/Q2 Predictions Min        -58.2721
trainer/Q Targets Mean            -10.2679
trainer/Q Targets Std               6.90775
trainer/Q Targets Max              -8.47731
trainer/Q Targets Min             -59.878
trainer/Log Pis Mean                1.95827
trainer/Log Pis Std                 1.03094
trainer/Log Pis Max                 6.59203
trainer/Log Pis Min                -1.5495
trainer/Policy mu Mean              0.0659567
trainer/Policy mu Std               0.622089
trainer/Policy mu Max               3.07328
trainer/Policy mu Min              -3.08115
trainer/Policy log std Mean        -2.14786
trainer/Policy log std Std          0.421296
trainer/Policy log std Max         -0.442308
trainer/Policy log std Min         -2.51675
trainer/Alpha                       0.0432325
trainer/Alpha Loss                 -0.131082
exploration/num steps total     32800
exploration/num paths total       328
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.390191
exploration/Rewards Std             1.29288
exploration/Rewards Max            -0.0102084
exploration/Rewards Min           -10.263
exploration/Returns Mean          -39.0191
exploration/Returns Std            21.6167
exploration/Returns Max           -17.4024
exploration/Returns Min           -60.6358
exploration/Actions Mean            0.018624
exploration/Actions Std             0.247936
exploration/Actions Max             0.99831
exploration/Actions Min            -0.98239
exploration/Num Paths               2
exploration/Average Returns       -39.0191
evaluation/num steps total     163000
evaluation/num paths total       1630
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.30301
evaluation/Rewards Std              1.19228
evaluation/Rewards Max             -0.0299587
evaluation/Rewards Min            -10.9172
evaluation/Returns Mean           -30.301
evaluation/Returns Std             17.3501
evaluation/Returns Max             -8.97188
evaluation/Returns Min            -61.2289
evaluation/Actions Mean             0.0384011
evaluation/Actions Std              0.201746
evaluation/Actions Max              0.998139
evaluation/Actions Min             -0.993822
evaluation/Num Paths               10
evaluation/Average Returns        -30.301
time/data storing (s)               0.00124349
time/evaluation sampling (s)        0.22478
time/exploration sampling (s)       0.0658065
time/logging (s)                    0.00336417
time/saving (s)                     0.00168634
time/training (s)                   0.769455
time/epoch (s)                      1.06633
time/total (s)                    177.808
Epoch                             162
-----------------------------  ---------------
2019-04-21 00:47:11.542631 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 163 finished
-----------------------------  ---------------
replay_buffer/size              33000
trainer/QF1 Loss                    1.57474
trainer/QF2 Loss                    1.54545
trainer/Policy Loss                11.5444
trainer/Q1 Predictions Mean        -9.94704
trainer/Q1 Predictions Std          5.02858
trainer/Q1 Predictions Max         -8.43602
trainer/Q1 Predictions Min        -44.1996
trainer/Q2 Predictions Mean        -9.97125
trainer/Q2 Predictions Std          5.00968
trainer/Q2 Predictions Max         -8.48204
trainer/Q2 Predictions Min        -44.1665
trainer/Q Targets Mean             -9.80477
trainer/Q Targets Std               5.02684
trainer/Q Targets Max              -0.107541
trainer/Q Targets Min             -43.628
trainer/Log Pis Mean                1.99741
trainer/Log Pis Std                 1.48985
trainer/Log Pis Max                 6.98461
trainer/Log Pis Min                -4.62511
trainer/Policy mu Mean             -0.00108629
trainer/Policy mu Std               0.686068
trainer/Policy mu Max               2.99805
trainer/Policy mu Min              -2.76558
trainer/Policy log std Mean        -2.13283
trainer/Policy log std Std          0.421282
trainer/Policy log std Max         -0.639767
trainer/Policy log std Min         -2.49372
trainer/Alpha                       0.0441712
trainer/Alpha Loss                 -0.00806951
exploration/num steps total     33000
exploration/num paths total       330
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.300461
exploration/Rewards Std             0.924456
exploration/Rewards Max            -0.014304
exploration/Rewards Min            -7.75692
exploration/Returns Mean          -30.0461
exploration/Returns Std            16.1799
exploration/Returns Max           -13.8662
exploration/Returns Min           -46.2259
exploration/Actions Mean            0.0215841
exploration/Actions Std             0.209878
exploration/Actions Max             0.998872
exploration/Actions Min            -0.871924
exploration/Num Paths               2
exploration/Average Returns       -30.0461
evaluation/num steps total     164000
evaluation/num paths total       1640
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.408893
evaluation/Rewards Std              1.56006
evaluation/Rewards Max             -0.00487081
evaluation/Rewards Min            -10.8608
evaluation/Returns Mean           -40.8893
evaluation/Returns Std             19.1021
evaluation/Returns Max            -11.5428
evaluation/Returns Min            -60.0606
evaluation/Actions Mean             0.0315387
evaluation/Actions Std              0.230025
evaluation/Actions Max              0.998484
evaluation/Actions Min             -0.99741
evaluation/Num Paths               10
evaluation/Average Returns        -40.8893
time/data storing (s)               0.00128004
time/evaluation sampling (s)        0.230675
time/exploration sampling (s)       0.0716545
time/logging (s)                    0.00336205
time/saving (s)                     0.00195357
time/training (s)                   0.775646
time/epoch (s)                      1.08457
time/total (s)                    178.897
Epoch                             163
-----------------------------  ---------------
2019-04-21 00:47:12.617138 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 164 finished
-----------------------------  ---------------
replay_buffer/size              33200
trainer/QF1 Loss                    0.873375
trainer/QF2 Loss                    0.898091
trainer/Policy Loss                11.3022
trainer/Q1 Predictions Mean        -9.51729
trainer/Q1 Predictions Std          3.27446
trainer/Q1 Predictions Max         -8.43061
trainer/Q1 Predictions Min        -30.1682
trainer/Q2 Predictions Mean        -9.52048
trainer/Q2 Predictions Std          3.29264
trainer/Q2 Predictions Max         -8.43845
trainer/Q2 Predictions Min        -30.3073
trainer/Q Targets Mean             -9.443
trainer/Q Targets Std               3.46569
trainer/Q Targets Max              -0.916609
trainer/Q Targets Min             -32.7223
trainer/Log Pis Mean                2.06933
trainer/Log Pis Std                 1.23223
trainer/Log Pis Max                 7.39795
trainer/Log Pis Min                -1.77709
trainer/Policy mu Mean              0.0086491
trainer/Policy mu Std               0.610157
trainer/Policy mu Max               2.8609
trainer/Policy mu Min              -3.09496
trainer/Policy log std Mean        -2.22033
trainer/Policy log std Std          0.398991
trainer/Policy log std Max         -0.371021
trainer/Policy log std Min         -2.5183
trainer/Alpha                       0.0450999
trainer/Alpha Loss                  0.21484
exploration/num steps total     33200
exploration/num paths total       332
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.231079
exploration/Rewards Std             0.601084
exploration/Rewards Max            -0.00981659
exploration/Rewards Min            -5.3582
exploration/Returns Mean          -23.1079
exploration/Returns Std             5.25378
exploration/Returns Max           -17.8541
exploration/Returns Min           -28.3617
exploration/Actions Mean            0.0120984
exploration/Actions Std             0.2068
exploration/Actions Max             0.98715
exploration/Actions Min            -0.990816
exploration/Num Paths               2
exploration/Average Returns       -23.1079
evaluation/num steps total     165000
evaluation/num paths total       1650
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.237994
evaluation/Rewards Std              0.958834
evaluation/Rewards Max             -0.0177169
evaluation/Rewards Min             -9.17027
evaluation/Returns Mean           -23.7994
evaluation/Returns Std             12.5513
evaluation/Returns Max             -7.31751
evaluation/Returns Min            -50.9429
evaluation/Actions Mean             0.0421195
evaluation/Actions Std              0.190175
evaluation/Actions Max              0.996299
evaluation/Actions Min             -0.703911
evaluation/Num Paths               10
evaluation/Average Returns        -23.7994
time/data storing (s)               0.00132693
time/evaluation sampling (s)        0.232101
time/exploration sampling (s)       0.0750175
time/logging (s)                    0.00337742
time/saving (s)                     0.00212792
time/training (s)                   0.754944
time/epoch (s)                      1.0689
time/total (s)                    179.969
Epoch                             164
-----------------------------  ---------------
2019-04-21 00:47:13.697884 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 165 finished
-----------------------------  ---------------
replay_buffer/size              33400
trainer/QF1 Loss                    0.747115
trainer/QF2 Loss                    0.761867
trainer/Policy Loss                11.3657
trainer/Q1 Predictions Mean        -9.9501
trainer/Q1 Predictions Std          6.23053
trainer/Q1 Predictions Max         -8.39551
trainer/Q1 Predictions Min        -58.7965
trainer/Q2 Predictions Mean        -9.9283
trainer/Q2 Predictions Std          6.24477
trainer/Q2 Predictions Max         -8.41302
trainer/Q2 Predictions Min        -59.0607
trainer/Q Targets Mean             -9.94814
trainer/Q Targets Std               6.41144
trainer/Q Targets Max              -0.0907289
trainer/Q Targets Min             -59.8123
trainer/Log Pis Mean                1.80302
trainer/Log Pis Std                 1.04731
trainer/Log Pis Max                 6.20278
trainer/Log Pis Min                -1.28768
trainer/Policy mu Mean              0.115679
trainer/Policy mu Std               0.5772
trainer/Policy mu Max               3.14928
trainer/Policy mu Min              -2.27947
trainer/Policy log std Mean        -2.08741
trainer/Policy log std Std          0.359151
trainer/Policy log std Max         -0.618532
trainer/Policy log std Min         -2.42855
trainer/Alpha                       0.0463521
trainer/Alpha Loss                 -0.605026
exploration/num steps total     33400
exploration/num paths total       334
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.308746
exploration/Rewards Std             0.704526
exploration/Rewards Max            -0.00446703
exploration/Rewards Min            -6.10761
exploration/Returns Mean          -30.8746
exploration/Returns Std             3.63936
exploration/Returns Max           -27.2353
exploration/Returns Min           -34.514
exploration/Actions Mean           -0.00550662
exploration/Actions Std             0.239865
exploration/Actions Max             0.988749
exploration/Actions Min            -0.998398
exploration/Num Paths               2
exploration/Average Returns       -30.8746
evaluation/num steps total     166000
evaluation/num paths total       1660
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.326351
evaluation/Rewards Std              1.08953
evaluation/Rewards Max             -0.0327983
evaluation/Rewards Min             -9.83809
evaluation/Returns Mean           -32.6351
evaluation/Returns Std             17.0448
evaluation/Returns Max            -10.8088
evaluation/Returns Min            -62.0238
evaluation/Actions Mean             0.030445
evaluation/Actions Std              0.193584
evaluation/Actions Max              0.997682
evaluation/Actions Min             -0.995113
evaluation/Num Paths               10
evaluation/Average Returns        -32.6351
time/data storing (s)               0.00133838
time/evaluation sampling (s)        0.22898
time/exploration sampling (s)       0.0723928
time/logging (s)                    0.0034492
time/saving (s)                     0.0019705
time/training (s)                   0.765751
time/epoch (s)                      1.07388
time/total (s)                    181.047
Epoch                             165
-----------------------------  ---------------
2019-04-21 00:47:14.783860 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 166 finished
-----------------------------  ---------------
replay_buffer/size              33600
trainer/QF1 Loss                    0.13933
trainer/QF2 Loss                    0.144791
trainer/Policy Loss                11.3197
trainer/Q1 Predictions Mean        -9.50197
trainer/Q1 Predictions Std          3.6257
trainer/Q1 Predictions Max         -8.23678
trainer/Q1 Predictions Min        -34.9093
trainer/Q2 Predictions Mean        -9.5308
trainer/Q2 Predictions Std          3.63043
trainer/Q2 Predictions Max         -8.28427
trainer/Q2 Predictions Min        -34.8893
trainer/Q Targets Mean             -9.65929
trainer/Q Targets Std               3.6468
trainer/Q Targets Max              -8.3416
trainer/Q Targets Min             -36.4655
trainer/Log Pis Mean                2.08561
trainer/Log Pis Std                 1.01479
trainer/Log Pis Max                 5.05619
trainer/Log Pis Min                -0.206546
trainer/Policy mu Mean              0.0567223
trainer/Policy mu Std               0.666165
trainer/Policy mu Max               2.93522
trainer/Policy mu Min              -2.85931
trainer/Policy log std Mean        -2.16413
trainer/Policy log std Std          0.445968
trainer/Policy log std Max         -0.568508
trainer/Policy log std Min         -2.53218
trainer/Alpha                       0.0468823
trainer/Alpha Loss                  0.261979
exploration/num steps total     33600
exploration/num paths total       336
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.181728
exploration/Rewards Std             0.427563
exploration/Rewards Max            -0.00776781
exploration/Rewards Min            -4.29055
exploration/Returns Mean          -18.1728
exploration/Returns Std             3.38474
exploration/Returns Max           -14.788
exploration/Returns Min           -21.5575
exploration/Actions Mean            0.00941404
exploration/Actions Std             0.199892
exploration/Actions Max             0.998397
exploration/Actions Min            -0.977189
exploration/Num Paths               2
exploration/Average Returns       -18.1728
evaluation/num steps total     167000
evaluation/num paths total       1670
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.231108
evaluation/Rewards Std              1.04027
evaluation/Rewards Max             -0.0160056
evaluation/Rewards Min             -9.21527
evaluation/Returns Mean           -23.1108
evaluation/Returns Std             15.9326
evaluation/Returns Max             -1.89078
evaluation/Returns Min            -49.5362
evaluation/Actions Mean             0.0221824
evaluation/Actions Std              0.183163
evaluation/Actions Max              0.996334
evaluation/Actions Min             -0.984734
evaluation/Num Paths               10
evaluation/Average Returns        -23.1108
time/data storing (s)               0.00120081
time/evaluation sampling (s)        0.229739
time/exploration sampling (s)       0.0663909
time/logging (s)                    0.00331331
time/saving (s)                     0.00214588
time/training (s)                   0.775793
time/epoch (s)                      1.07858
time/total (s)                    182.13
Epoch                             166
-----------------------------  ---------------
2019-04-21 00:47:15.863864 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 167 finished
-----------------------------  ---------------
replay_buffer/size              33800
trainer/QF1 Loss                    1.44051
trainer/QF2 Loss                    1.45082
trainer/Policy Loss                11.0997
trainer/Q1 Predictions Mean        -9.26976
trainer/Q1 Predictions Std          3.24275
trainer/Q1 Predictions Max         -8.41461
trainer/Q1 Predictions Min        -32.7121
trainer/Q2 Predictions Mean        -9.25165
trainer/Q2 Predictions Std          3.19269
trainer/Q2 Predictions Max         -8.41445
trainer/Q2 Predictions Min        -32.0303
trainer/Q Targets Mean             -9.09682
trainer/Q Targets Std               3.52663
trainer/Q Targets Max              -0.0485654
trainer/Q Targets Min             -33.1373
trainer/Log Pis Mean                2.12131
trainer/Log Pis Std                 0.953716
trainer/Log Pis Max                 5.83134
trainer/Log Pis Min                -0.975305
trainer/Policy mu Mean              0.0370054
trainer/Policy mu Std               0.499264
trainer/Policy mu Max               2.9163
trainer/Policy mu Min              -2.02018
trainer/Policy log std Mean        -2.21712
trainer/Policy log std Std          0.334332
trainer/Policy log std Max         -0.392572
trainer/Policy log std Min         -2.46341
trainer/Alpha                       0.0474981
trainer/Alpha Loss                  0.369668
exploration/num steps total     33800
exploration/num paths total       338
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.397168
exploration/Rewards Std             1.12118
exploration/Rewards Max            -0.0234611
exploration/Rewards Min            -7.55534
exploration/Returns Mean          -39.7168
exploration/Returns Std             1.28702
exploration/Returns Max           -38.4297
exploration/Returns Min           -41.0038
exploration/Actions Mean            0.0445243
exploration/Actions Std             0.241088
exploration/Actions Max             0.997318
exploration/Actions Min            -0.732434
exploration/Num Paths               2
exploration/Average Returns       -39.7168
evaluation/num steps total     168000
evaluation/num paths total       1680
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.199425
evaluation/Rewards Std              0.867144
evaluation/Rewards Max             -0.0269307
evaluation/Rewards Min             -8.3073
evaluation/Returns Mean           -19.9425
evaluation/Returns Std             10.9483
evaluation/Returns Max             -5.70696
evaluation/Returns Min            -41.8824
evaluation/Actions Mean             0.0223396
evaluation/Actions Std              0.186958
evaluation/Actions Max              0.996194
evaluation/Actions Min             -0.992374
evaluation/Num Paths               10
evaluation/Average Returns        -19.9425
time/data storing (s)               0.00127858
time/evaluation sampling (s)        0.22913
time/exploration sampling (s)       0.0668448
time/logging (s)                    0.00360088
time/saving (s)                     0.00169304
time/training (s)                   0.77069
time/epoch (s)                      1.07324
time/total (s)                    183.207
Epoch                             167
-----------------------------  ---------------
2019-04-21 00:47:16.949973 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 168 finished
-----------------------------  ---------------
replay_buffer/size              34000
trainer/QF1 Loss                    1.51108
trainer/QF2 Loss                    1.5773
trainer/Policy Loss                11.8809
trainer/Q1 Predictions Mean       -10.2989
trainer/Q1 Predictions Std          7.7971
trainer/Q1 Predictions Max         -8.24121
trainer/Q1 Predictions Min        -73.9508
trainer/Q2 Predictions Mean       -10.3639
trainer/Q2 Predictions Std          7.82193
trainer/Q2 Predictions Max         -8.30272
trainer/Q2 Predictions Min        -74.3036
trainer/Q Targets Mean            -10.208
trainer/Q Targets Std               8.09698
trainer/Q Targets Max              -0.20078
trainer/Q Targets Min             -76.4438
trainer/Log Pis Mean                2.0286
trainer/Log Pis Std                 1.59289
trainer/Log Pis Max                 8.1035
trainer/Log Pis Min                -5.08319
trainer/Policy mu Mean              0.0591304
trainer/Policy mu Std               0.725552
trainer/Policy mu Max               3.17904
trainer/Policy mu Min              -2.97402
trainer/Policy log std Mean        -2.14001
trainer/Policy log std Std          0.475142
trainer/Policy log std Max         -0.24004
trainer/Policy log std Min         -2.51216
trainer/Alpha                       0.0474485
trainer/Alpha Loss                  0.0871744
exploration/num steps total     34000
exploration/num paths total       340
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.428789
exploration/Rewards Std             1.30568
exploration/Rewards Max            -0.0131759
exploration/Rewards Min            -9.65876
exploration/Returns Mean          -42.8789
exploration/Returns Std            17.9039
exploration/Returns Max           -24.975
exploration/Returns Min           -60.7828
exploration/Actions Mean            0.0533267
exploration/Actions Std             0.234391
exploration/Actions Max             0.999267
exploration/Actions Min            -0.350161
exploration/Num Paths               2
exploration/Average Returns       -42.8789
evaluation/num steps total     169000
evaluation/num paths total       1690
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.192196
evaluation/Rewards Std              0.715157
evaluation/Rewards Max             -0.0220175
evaluation/Rewards Min             -7.26765
evaluation/Returns Mean           -19.2196
evaluation/Returns Std              8.76314
evaluation/Returns Max             -5.92158
evaluation/Returns Min            -36.4552
evaluation/Actions Mean             0.0199247
evaluation/Actions Std              0.167686
evaluation/Actions Max              0.993997
evaluation/Actions Min             -0.994755
evaluation/Num Paths               10
evaluation/Average Returns        -19.2196
time/data storing (s)               0.00120483
time/evaluation sampling (s)        0.222462
time/exploration sampling (s)       0.0645548
time/logging (s)                    0.00343585
time/saving (s)                     0.00197526
time/training (s)                   0.785823
time/epoch (s)                      1.07946
time/total (s)                    184.29
Epoch                             168
-----------------------------  ---------------
2019-04-21 00:47:18.045719 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 169 finished
-----------------------------  ----------------
replay_buffer/size              34200
trainer/QF1 Loss                    0.0739859
trainer/QF2 Loss                    0.0939432
trainer/Policy Loss                11.62
trainer/Q1 Predictions Mean        -9.9072
trainer/Q1 Predictions Std          6.31688
trainer/Q1 Predictions Max         -8.23987
trainer/Q1 Predictions Min        -62.1249
trainer/Q2 Predictions Mean        -9.92497
trainer/Q2 Predictions Std          6.32412
trainer/Q2 Predictions Max         -8.27886
trainer/Q2 Predictions Min        -61.969
trainer/Q Targets Mean             -9.96941
trainer/Q Targets Std               6.28051
trainer/Q Targets Max              -8.26963
trainer/Q Targets Min             -62.3358
trainer/Log Pis Mean                1.97733
trainer/Log Pis Std                 1.46433
trainer/Log Pis Max                 7.33924
trainer/Log Pis Min                -5.27824
trainer/Policy mu Mean              0.112513
trainer/Policy mu Std               0.650197
trainer/Policy mu Max               3.21463
trainer/Policy mu Min              -2.16024
trainer/Policy log std Mean        -2.17076
trainer/Policy log std Std          0.410162
trainer/Policy log std Max         -0.54191
trainer/Policy log std Min         -2.50492
trainer/Alpha                       0.0476615
trainer/Alpha Loss                 -0.0689871
exploration/num steps total     34200
exploration/num paths total       342
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.424303
exploration/Rewards Std             1.31914
exploration/Rewards Max            -0.000371162
exploration/Rewards Min            -9.72169
exploration/Returns Mean          -42.4303
exploration/Returns Std            23.6073
exploration/Returns Max           -18.823
exploration/Returns Min           -66.0376
exploration/Actions Mean            0.00862764
exploration/Actions Std             0.241313
exploration/Actions Max             0.999479
exploration/Actions Min            -0.995648
exploration/Num Paths               2
exploration/Average Returns       -42.4303
evaluation/num steps total     170000
evaluation/num paths total       1700
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.268308
evaluation/Rewards Std              1.1093
evaluation/Rewards Max             -0.0296893
evaluation/Rewards Min             -9.98212
evaluation/Returns Mean           -26.8308
evaluation/Returns Std             17.8686
evaluation/Returns Max             -8.14591
evaluation/Returns Min            -58.2793
evaluation/Actions Mean             0.0236716
evaluation/Actions Std              0.183847
evaluation/Actions Max              0.996434
evaluation/Actions Min             -0.995479
evaluation/Num Paths               10
evaluation/Average Returns        -26.8308
time/data storing (s)               0.00142202
time/evaluation sampling (s)        0.230091
time/exploration sampling (s)       0.0735219
time/logging (s)                    0.00253688
time/saving (s)                     0.00191505
time/training (s)                   0.777924
time/epoch (s)                      1.08741
time/total (s)                    185.382
Epoch                             169
-----------------------------  ----------------
2019-04-21 00:47:19.133085 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 170 finished
-----------------------------  ---------------
replay_buffer/size              34400
trainer/QF1 Loss                    0.733346
trainer/QF2 Loss                    0.745872
trainer/Policy Loss                11.1316
trainer/Q1 Predictions Mean        -9.32358
trainer/Q1 Predictions Std          4.25195
trainer/Q1 Predictions Max         -8.1896
trainer/Q1 Predictions Min        -39.3275
trainer/Q2 Predictions Mean        -9.30896
trainer/Q2 Predictions Std          4.23951
trainer/Q2 Predictions Max         -8.20045
trainer/Q2 Predictions Min        -38.9731
trainer/Q Targets Mean             -9.34491
trainer/Q Targets Std               4.26357
trainer/Q Targets Max              -0.694467
trainer/Q Targets Min             -39.0122
trainer/Log Pis Mean                1.95163
trainer/Log Pis Std                 1.13077
trainer/Log Pis Max                 4.36461
trainer/Log Pis Min                -3.28475
trainer/Policy mu Mean              0.0593095
trainer/Policy mu Std               0.577986
trainer/Policy mu Max               2.97152
trainer/Policy mu Min              -2.00883
trainer/Policy log std Mean        -2.21285
trainer/Policy log std Std          0.392855
trainer/Policy log std Max         -0.575219
trainer/Policy log std Min         -2.55827
trainer/Alpha                       0.0478077
trainer/Alpha Loss                 -0.147085
exploration/num steps total     34400
exploration/num paths total       344
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.287218
exploration/Rewards Std             0.725377
exploration/Rewards Max            -0.00712352
exploration/Rewards Min            -5.20558
exploration/Returns Mean          -28.7218
exploration/Returns Std             1.77531
exploration/Returns Max           -26.9465
exploration/Returns Min           -30.4971
exploration/Actions Mean            0.0262169
exploration/Actions Std             0.214982
exploration/Actions Max             0.997547
exploration/Actions Min            -0.981869
exploration/Num Paths               2
exploration/Average Returns       -28.7218
evaluation/num steps total     171000
evaluation/num paths total       1710
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.22573
evaluation/Rewards Std              0.956251
evaluation/Rewards Max             -0.0502784
evaluation/Rewards Min            -10.5319
evaluation/Returns Mean           -22.573
evaluation/Returns Std             18.4822
evaluation/Returns Max             -5.9729
evaluation/Returns Min            -58.307
evaluation/Actions Mean             0.0150391
evaluation/Actions Std              0.175316
evaluation/Actions Max              0.997154
evaluation/Actions Min             -0.995096
evaluation/Num Paths               10
evaluation/Average Returns        -22.573
time/data storing (s)               0.00134018
time/evaluation sampling (s)        0.231868
time/exploration sampling (s)       0.0693264
time/logging (s)                    0.00337799
time/saving (s)                     0.00195441
time/training (s)                   0.773458
time/epoch (s)                      1.08133
time/total (s)                    186.468
Epoch                             170
-----------------------------  ---------------
2019-04-21 00:47:20.195330 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 171 finished
-----------------------------  ---------------
replay_buffer/size              34600
trainer/QF1 Loss                    1.40061
trainer/QF2 Loss                    1.45199
trainer/Policy Loss                11.0486
trainer/Q1 Predictions Mean        -9.46861
trainer/Q1 Predictions Std          6.33418
trainer/Q1 Predictions Max         -8.07371
trainer/Q1 Predictions Min        -61.7396
trainer/Q2 Predictions Mean        -9.48333
trainer/Q2 Predictions Std          6.29998
trainer/Q2 Predictions Max         -8.1222
trainer/Q2 Predictions Min        -61.5344
trainer/Q Targets Mean             -9.55949
trainer/Q Targets Std               6.52628
trainer/Q Targets Max              -0.0764458
trainer/Q Targets Min             -62.4983
trainer/Log Pis Mean                1.83516
trainer/Log Pis Std                 1.40665
trainer/Log Pis Max                 7.18243
trainer/Log Pis Min                -3.84613
trainer/Policy mu Mean              0.0300095
trainer/Policy mu Std               0.544042
trainer/Policy mu Max               3.04682
trainer/Policy mu Min              -2.26436
trainer/Policy log std Mean        -2.14541
trainer/Policy log std Std          0.3668
trainer/Policy log std Max         -0.51387
trainer/Policy log std Min         -2.43418
trainer/Alpha                       0.0479959
trainer/Alpha Loss                 -0.500536
exploration/num steps total     34600
exploration/num paths total       346
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.371946
exploration/Rewards Std             1.10047
exploration/Rewards Max            -0.0213567
exploration/Rewards Min            -8.95622
exploration/Returns Mean          -37.1946
exploration/Returns Std            18.1934
exploration/Returns Max           -19.0012
exploration/Returns Min           -55.3881
exploration/Actions Mean            0.025851
exploration/Actions Std             0.240278
exploration/Actions Max             0.996911
exploration/Actions Min            -0.995689
exploration/Num Paths               2
exploration/Average Returns       -37.1946
evaluation/num steps total     172000
evaluation/num paths total       1720
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.256875
evaluation/Rewards Std              0.966723
evaluation/Rewards Max             -0.0428231
evaluation/Rewards Min             -9.40824
evaluation/Returns Mean           -25.6875
evaluation/Returns Std             17.679
evaluation/Returns Max             -7.50589
evaluation/Returns Min            -56.9093
evaluation/Actions Mean             0.0248624
evaluation/Actions Std              0.17166
evaluation/Actions Max              0.995568
evaluation/Actions Min             -0.990024
evaluation/Num Paths               10
evaluation/Average Returns        -25.6875
time/data storing (s)               0.00125076
time/evaluation sampling (s)        0.230529
time/exploration sampling (s)       0.0690312
time/logging (s)                    0.00334013
time/saving (s)                     0.00196105
time/training (s)                   0.748852
time/epoch (s)                      1.05496
time/total (s)                    187.527
Epoch                             171
-----------------------------  ---------------
2019-04-21 00:47:21.274779 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 172 finished
-----------------------------  ----------------
replay_buffer/size              34800
trainer/QF1 Loss                    0.70265
trainer/QF2 Loss                    0.744253
trainer/Policy Loss                10.9976
trainer/Q1 Predictions Mean        -9.05701
trainer/Q1 Predictions Std          2.61213
trainer/Q1 Predictions Max         -8.32713
trainer/Q1 Predictions Min        -29.7728
trainer/Q2 Predictions Mean        -9.07602
trainer/Q2 Predictions Std          2.59473
trainer/Q2 Predictions Max         -8.35793
trainer/Q2 Predictions Min        -29.8182
trainer/Q Targets Mean             -8.95579
trainer/Q Targets Std               2.83603
trainer/Q Targets Max              -0.285315
trainer/Q Targets Min             -30.3393
trainer/Log Pis Mean                2.10853
trainer/Log Pis Std                 1.12184
trainer/Log Pis Max                 7.01035
trainer/Log Pis Min                -1.96007
trainer/Policy mu Mean              0.0329683
trainer/Policy mu Std               0.528427
trainer/Policy mu Max               2.89816
trainer/Policy mu Min              -2.41922
trainer/Policy log std Mean        -2.22363
trainer/Policy log std Std          0.352656
trainer/Policy log std Max         -0.563315
trainer/Policy log std Min         -2.49859
trainer/Alpha                       0.0478751
trainer/Alpha Loss                  0.329841
exploration/num steps total     34800
exploration/num paths total       348
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.205424
exploration/Rewards Std             0.386727
exploration/Rewards Max            -0.011922
exploration/Rewards Min            -3.93211
exploration/Returns Mean          -20.5424
exploration/Returns Std             4.00966
exploration/Returns Max           -16.5328
exploration/Returns Min           -24.5521
exploration/Actions Mean            4.42466e-05
exploration/Actions Std             0.190419
exploration/Actions Max             0.97592
exploration/Actions Min            -0.984551
exploration/Num Paths               2
exploration/Average Returns       -20.5424
evaluation/num steps total     173000
evaluation/num paths total       1730
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.291507
evaluation/Rewards Std              0.993881
evaluation/Rewards Max             -0.0400174
evaluation/Rewards Min             -9.86117
evaluation/Returns Mean           -29.1507
evaluation/Returns Std             15.47
evaluation/Returns Max            -10.9399
evaluation/Returns Min            -58.1454
evaluation/Actions Mean             0.0312352
evaluation/Actions Std              0.188033
evaluation/Actions Max              0.997851
evaluation/Actions Min             -0.984462
evaluation/Num Paths               10
evaluation/Average Returns        -29.1507
time/data storing (s)               0.00146843
time/evaluation sampling (s)        0.22823
time/exploration sampling (s)       0.0654995
time/logging (s)                    0.00338235
time/saving (s)                     0.00196365
time/training (s)                   0.771374
time/epoch (s)                      1.07192
time/total (s)                    188.604
Epoch                             172
-----------------------------  ----------------
2019-04-21 00:47:22.343901 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 173 finished
-----------------------------  ---------------
replay_buffer/size              35000
trainer/QF1 Loss                   29.4219
trainer/QF2 Loss                   28.8372
trainer/Policy Loss                13.2031
trainer/Q1 Predictions Mean       -11.5254
trainer/Q1 Predictions Std         11.721
trainer/Q1 Predictions Max         -8.15835
trainer/Q1 Predictions Min        -73.8931
trainer/Q2 Predictions Mean       -11.5423
trainer/Q2 Predictions Std         11.6689
trainer/Q2 Predictions Max         -8.20576
trainer/Q2 Predictions Min        -73.588
trainer/Q Targets Mean            -11.0894
trainer/Q Targets Std              10.4362
trainer/Q Targets Max              -8.1807
trainer/Q Targets Min             -72.8313
trainer/Log Pis Mean                2.33886
trainer/Log Pis Std                 1.47293
trainer/Log Pis Max                 8.56265
trainer/Log Pis Min                -2.80026
trainer/Policy mu Mean              0.0997794
trainer/Policy mu Std               0.775833
trainer/Policy mu Max               3.2231
trainer/Policy mu Min              -2.73262
trainer/Policy log std Mean        -2.15516
trainer/Policy log std Std          0.498528
trainer/Policy log std Max         -0.531458
trainer/Policy log std Min         -2.56139
trainer/Alpha                       0.0485779
trainer/Alpha Loss                  1.02496
exploration/num steps total     35000
exploration/num paths total       350
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.46222
exploration/Rewards Std             1.47872
exploration/Rewards Max            -0.00474214
exploration/Rewards Min           -11.1019
exploration/Returns Mean          -46.222
exploration/Returns Std            22.3618
exploration/Returns Max           -23.8602
exploration/Returns Min           -68.5838
exploration/Actions Mean            0.062367
exploration/Actions Std             0.252238
exploration/Actions Max             0.999696
exploration/Actions Min            -0.302018
exploration/Num Paths               2
exploration/Average Returns       -46.222
evaluation/num steps total     174000
evaluation/num paths total       1740
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.233841
evaluation/Rewards Std              1.09762
evaluation/Rewards Max             -0.00854825
evaluation/Rewards Min             -9.92359
evaluation/Returns Mean           -23.3841
evaluation/Returns Std             18.5294
evaluation/Returns Max             -1.50237
evaluation/Returns Min            -49.7389
evaluation/Actions Mean             0.0294589
evaluation/Actions Std              0.188667
evaluation/Actions Max              0.997717
evaluation/Actions Min             -0.987607
evaluation/Num Paths               10
evaluation/Average Returns        -23.3841
time/data storing (s)               0.00123793
time/evaluation sampling (s)        0.223459
time/exploration sampling (s)       0.0676052
time/logging (s)                    0.00336433
time/saving (s)                     0.00193264
time/training (s)                   0.763963
time/epoch (s)                      1.06156
time/total (s)                    189.67
Epoch                             173
-----------------------------  ---------------
2019-04-21 00:47:23.435283 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 174 finished
-----------------------------  ---------------
replay_buffer/size              35200
trainer/QF1 Loss                    0.929228
trainer/QF2 Loss                    0.897761
trainer/Policy Loss                11.307
trainer/Q1 Predictions Mean        -9.57356
trainer/Q1 Predictions Std          5.45432
trainer/Q1 Predictions Max         -8.13454
trainer/Q1 Predictions Min        -48.2549
trainer/Q2 Predictions Mean        -9.5628
trainer/Q2 Predictions Std          5.50689
trainer/Q2 Predictions Max         -8.12227
trainer/Q2 Predictions Min        -48.7664
trainer/Q Targets Mean             -9.66374
trainer/Q Targets Std               5.87808
trainer/Q Targets Max              -0.18891
trainer/Q Targets Min             -50.1574
trainer/Log Pis Mean                1.95379
trainer/Log Pis Std                 1.50377
trainer/Log Pis Max                 7.0337
trainer/Log Pis Min                -4.18848
trainer/Policy mu Mean             -0.0349633
trainer/Policy mu Std               0.623251
trainer/Policy mu Max               3.00052
trainer/Policy mu Min              -3.14935
trainer/Policy log std Mean        -2.26056
trainer/Policy log std Std          0.431283
trainer/Policy log std Max         -0.421617
trainer/Policy log std Min         -2.56744
trainer/Alpha                       0.0497312
trainer/Alpha Loss                 -0.138691
exploration/num steps total     35200
exploration/num paths total       352
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.26307
exploration/Rewards Std             0.734628
exploration/Rewards Max            -0.0103186
exploration/Rewards Min            -6.6715
exploration/Returns Mean          -26.307
exploration/Returns Std             8.59905
exploration/Returns Max           -17.708
exploration/Returns Min           -34.9061
exploration/Actions Mean            0.0315243
exploration/Actions Std             0.221249
exploration/Actions Max             0.995105
exploration/Actions Min            -0.940278
exploration/Num Paths               2
exploration/Average Returns       -26.307
evaluation/num steps total     175000
evaluation/num paths total       1750
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.279824
evaluation/Rewards Std              1.10083
evaluation/Rewards Max             -0.010639
evaluation/Rewards Min            -10.627
evaluation/Returns Mean           -27.9824
evaluation/Returns Std             18.8436
evaluation/Returns Max             -6.03664
evaluation/Returns Min            -64.2033
evaluation/Actions Mean             0.0289377
evaluation/Actions Std              0.189977
evaluation/Actions Max              0.997659
evaluation/Actions Min             -0.990491
evaluation/Num Paths               10
evaluation/Average Returns        -27.9824
time/data storing (s)               0.00145053
time/evaluation sampling (s)        0.227181
time/exploration sampling (s)       0.0691336
time/logging (s)                    0.00334463
time/saving (s)                     0.00198426
time/training (s)                   0.78057
time/epoch (s)                      1.08366
time/total (s)                    190.758
Epoch                             174
-----------------------------  ---------------
2019-04-21 00:47:24.527147 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 175 finished
-----------------------------  ---------------
replay_buffer/size              35400
trainer/QF1 Loss                    1.33383
trainer/QF2 Loss                    1.34047
trainer/Policy Loss                10.7219
trainer/Q1 Predictions Mean        -8.65062
trainer/Q1 Predictions Std          2.16125
trainer/Q1 Predictions Max         -8.09209
trainer/Q1 Predictions Min        -29.4175
trainer/Q2 Predictions Mean        -8.67081
trainer/Q2 Predictions Std          2.18143
trainer/Q2 Predictions Max         -8.13277
trainer/Q2 Predictions Min        -29.6398
trainer/Q Targets Mean             -8.57678
trainer/Q Targets Std               2.44146
trainer/Q Targets Max              -0.0187232
trainer/Q Targets Min             -29.1436
trainer/Log Pis Mean                2.23083
trainer/Log Pis Std                 0.94599
trainer/Log Pis Max                 7.39802
trainer/Log Pis Min                -0.793388
trainer/Policy mu Mean             -0.025691
trainer/Policy mu Std               0.459247
trainer/Policy mu Max               2.56993
trainer/Policy mu Min              -2.53677
trainer/Policy log std Mean        -2.27392
trainer/Policy log std Std          0.335644
trainer/Policy log std Max         -0.640605
trainer/Policy log std Min         -2.55491
trainer/Alpha                       0.0506615
trainer/Alpha Loss                  0.688526
exploration/num steps total     35400
exploration/num paths total       354
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.223922
exploration/Rewards Std             0.619804
exploration/Rewards Max            -0.0116911
exploration/Rewards Min            -6.02349
exploration/Returns Mean          -22.3922
exploration/Returns Std             5.48504
exploration/Returns Max           -16.9072
exploration/Returns Min           -27.8773
exploration/Actions Mean            0.0304092
exploration/Actions Std             0.213845
exploration/Actions Max             0.991497
exploration/Actions Min            -0.853888
exploration/Num Paths               2
exploration/Average Returns       -22.3922
evaluation/num steps total     176000
evaluation/num paths total       1760
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.273198
evaluation/Rewards Std              1.05598
evaluation/Rewards Max             -0.0249636
evaluation/Rewards Min            -10.0518
evaluation/Returns Mean           -27.3198
evaluation/Returns Std             17.8593
evaluation/Returns Max             -6.69227
evaluation/Returns Min            -55.5665
evaluation/Actions Mean             0.0291135
evaluation/Actions Std              0.188469
evaluation/Actions Max              0.997385
evaluation/Actions Min             -0.992557
evaluation/Num Paths               10
evaluation/Average Returns        -27.3198
time/data storing (s)               0.00139307
time/evaluation sampling (s)        0.227469
time/exploration sampling (s)       0.0735484
time/logging (s)                    0.00343
time/saving (s)                     0.00198325
time/training (s)                   0.776691
time/epoch (s)                      1.08451
time/total (s)                    191.847
Epoch                             175
-----------------------------  ---------------
2019-04-21 00:47:25.612940 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 176 finished
-----------------------------  ---------------
replay_buffer/size              35600
trainer/QF1 Loss                   18.2311
trainer/QF2 Loss                   18.4615
trainer/Policy Loss                11.0806
trainer/Q1 Predictions Mean        -9.25888
trainer/Q1 Predictions Std          5.7636
trainer/Q1 Predictions Max         -7.96816
trainer/Q1 Predictions Min        -52.5578
trainer/Q2 Predictions Mean        -9.28091
trainer/Q2 Predictions Std          5.81224
trainer/Q2 Predictions Max         -7.98897
trainer/Q2 Predictions Min        -52.8115
trainer/Q Targets Mean             -9.00896
trainer/Q Targets Std               3.64871
trainer/Q Targets Max              -8.06359
trainer/Q Targets Min             -39.5258
trainer/Log Pis Mean                1.98813
trainer/Log Pis Std                 1.28174
trainer/Log Pis Max                 7.53431
trainer/Log Pis Min                -1.98356
trainer/Policy mu Mean              0.0400178
trainer/Policy mu Std               0.572703
trainer/Policy mu Max               3.01279
trainer/Policy mu Min              -2.48291
trainer/Policy log std Mean        -2.25379
trainer/Policy log std Std          0.393645
trainer/Policy log std Max         -0.539406
trainer/Policy log std Min         -2.55263
trainer/Alpha                       0.0520104
trainer/Alpha Loss                 -0.0351007
exploration/num steps total     35600
exploration/num paths total       356
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.48495
exploration/Rewards Std             1.36347
exploration/Rewards Max            -0.0100731
exploration/Rewards Min            -8.22314
exploration/Returns Mean          -48.495
exploration/Returns Std             2.36525
exploration/Returns Max           -46.1297
exploration/Returns Min           -50.8602
exploration/Actions Mean            0.0423332
exploration/Actions Std             0.239245
exploration/Actions Max             0.997872
exploration/Actions Min            -0.682124
exploration/Num Paths               2
exploration/Average Returns       -48.495
evaluation/num steps total     177000
evaluation/num paths total       1770
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.211789
evaluation/Rewards Std              0.931439
evaluation/Rewards Max             -0.0284369
evaluation/Rewards Min            -10.3536
evaluation/Returns Mean           -21.1789
evaluation/Returns Std             15.5234
evaluation/Returns Max             -3.71393
evaluation/Returns Min            -60.9075
evaluation/Actions Mean             0.0124169
evaluation/Actions Std              0.183596
evaluation/Actions Max              0.996316
evaluation/Actions Min             -0.995141
evaluation/Num Paths               10
evaluation/Average Returns        -21.1789
time/data storing (s)               0.00127778
time/evaluation sampling (s)        0.225652
time/exploration sampling (s)       0.0703313
time/logging (s)                    0.00326211
time/saving (s)                     0.00205376
time/training (s)                   0.775452
time/epoch (s)                      1.07803
time/total (s)                    192.93
Epoch                             176
-----------------------------  ---------------
2019-04-21 00:47:26.696395 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 177 finished
-----------------------------  ---------------
replay_buffer/size              35800
trainer/QF1 Loss                    0.692951
trainer/QF2 Loss                    0.700238
trainer/Policy Loss                10.7188
trainer/Q1 Predictions Mean        -9.07531
trainer/Q1 Predictions Std          2.77945
trainer/Q1 Predictions Max         -8.07021
trainer/Q1 Predictions Min        -25.5733
trainer/Q2 Predictions Mean        -9.0754
trainer/Q2 Predictions Std          2.76774
trainer/Q2 Predictions Max         -8.10971
trainer/Q2 Predictions Min        -25.752
trainer/Q Targets Mean             -9.06448
trainer/Q Targets Std               2.85751
trainer/Q Targets Max              -0.220108
trainer/Q Targets Min             -25.1159
trainer/Log Pis Mean                1.83257
trainer/Log Pis Std                 1.30317
trainer/Log Pis Max                 6.66898
trainer/Log Pis Min                -3.65332
trainer/Policy mu Mean              0.0300862
trainer/Policy mu Std               0.59924
trainer/Policy mu Max               2.80884
trainer/Policy mu Min              -2.53734
trainer/Policy log std Mean        -2.09279
trainer/Policy log std Std          0.400912
trainer/Policy log std Max         -0.458082
trainer/Policy log std Min         -2.44246
trainer/Alpha                       0.0520808
trainer/Alpha Loss                 -0.494748
exploration/num steps total     35800
exploration/num paths total       358
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.246122
exploration/Rewards Std             0.703891
exploration/Rewards Max            -0.0197662
exploration/Rewards Min            -6.84001
exploration/Returns Mean          -24.6122
exploration/Returns Std             9.83321
exploration/Returns Max           -14.779
exploration/Returns Min           -34.4455
exploration/Actions Mean            0.00527291
exploration/Actions Std             0.211966
exploration/Actions Max             0.992205
exploration/Actions Min            -0.994653
exploration/Num Paths               2
exploration/Average Returns       -24.6122
evaluation/num steps total     178000
evaluation/num paths total       1780
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.215371
evaluation/Rewards Std              0.782717
evaluation/Rewards Max             -0.0622637
evaluation/Rewards Min             -8.10771
evaluation/Returns Mean           -21.5371
evaluation/Returns Std              8.75936
evaluation/Returns Max             -6.51748
evaluation/Returns Min            -35.1538
evaluation/Actions Mean             0.0186912
evaluation/Actions Std              0.17894
evaluation/Actions Max              0.996308
evaluation/Actions Min             -0.992788
evaluation/Num Paths               10
evaluation/Average Returns        -21.5371
time/data storing (s)               0.00126671
time/evaluation sampling (s)        0.232032
time/exploration sampling (s)       0.0677008
time/logging (s)                    0.00333848
time/saving (s)                     0.00197308
time/training (s)                   0.769811
time/epoch (s)                      1.07612
time/total (s)                    194.01
Epoch                             177
-----------------------------  ---------------
2019-04-21 00:47:27.783562 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 178 finished
-----------------------------  ---------------
replay_buffer/size              36000
trainer/QF1 Loss                    0.0213129
trainer/QF2 Loss                    0.0393155
trainer/Policy Loss                10.1348
trainer/Q1 Predictions Mean        -8.6678
trainer/Q1 Predictions Std          2.0756
trainer/Q1 Predictions Max         -8.03755
trainer/Q1 Predictions Min        -25.3341
trainer/Q2 Predictions Mean        -8.61999
trainer/Q2 Predictions Std          2.10448
trainer/Q2 Predictions Max         -8.01197
trainer/Q2 Predictions Min        -25.5094
trainer/Q Targets Mean             -8.71969
trainer/Q Targets Std               2.05094
trainer/Q Targets Max              -8.039
trainer/Q Targets Min             -24.7256
trainer/Log Pis Mean                1.57764
trainer/Log Pis Std                 0.981111
trainer/Log Pis Max                 3.33624
trainer/Log Pis Min                -1.8317
trainer/Policy mu Mean             -0.0168208
trainer/Policy mu Std               0.500355
trainer/Policy mu Max               2.93665
trainer/Policy mu Min              -1.91161
trainer/Policy log std Mean        -2.10378
trainer/Policy log std Std          0.351601
trainer/Policy log std Max         -0.538448
trainer/Policy log std Min         -2.39598
trainer/Alpha                       0.0516978
trainer/Alpha Loss                 -1.25106
exploration/num steps total     36000
exploration/num paths total       360
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.275725
exploration/Rewards Std             0.763922
exploration/Rewards Max            -0.0119846
exploration/Rewards Min            -6.98859
exploration/Returns Mean          -27.5725
exploration/Returns Std            10.6014
exploration/Returns Max           -16.9711
exploration/Returns Min           -38.1739
exploration/Actions Mean            0.0296867
exploration/Actions Std             0.230872
exploration/Actions Max             0.997895
exploration/Actions Min            -0.869124
exploration/Num Paths               2
exploration/Average Returns       -27.5725
evaluation/num steps total     179000
evaluation/num paths total       1790
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.226391
evaluation/Rewards Std              0.916113
evaluation/Rewards Max             -0.0496925
evaluation/Rewards Min             -9.15202
evaluation/Returns Mean           -22.6391
evaluation/Returns Std             15.6798
evaluation/Returns Max             -5.38096
evaluation/Returns Min            -52.3003
evaluation/Actions Mean             0.0192794
evaluation/Actions Std              0.169293
evaluation/Actions Max              0.994951
evaluation/Actions Min             -0.994067
evaluation/Num Paths               10
evaluation/Average Returns        -22.6391
time/data storing (s)               0.00140211
time/evaluation sampling (s)        0.230231
time/exploration sampling (s)       0.0668952
time/logging (s)                    0.00350478
time/saving (s)                     0.00215166
time/training (s)                   0.775498
time/epoch (s)                      1.07968
time/total (s)                    195.094
Epoch                             178
-----------------------------  ---------------
2019-04-21 00:47:28.866249 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 179 finished
-----------------------------  ---------------
replay_buffer/size              36200
trainer/QF1 Loss                    0.0382578
trainer/QF2 Loss                    0.0660847
trainer/Policy Loss                11.0191
trainer/Q1 Predictions Mean        -9.18875
trainer/Q1 Predictions Std          4.73481
trainer/Q1 Predictions Max         -8.04077
trainer/Q1 Predictions Min        -48.2241
trainer/Q2 Predictions Mean        -9.19499
trainer/Q2 Predictions Std          4.79714
trainer/Q2 Predictions Max         -8.04993
trainer/Q2 Predictions Min        -49.084
trainer/Q Targets Mean             -9.25441
trainer/Q Targets Std               4.81172
trainer/Q Targets Max              -8.00806
trainer/Q Targets Min             -49.3061
trainer/Log Pis Mean                2.05197
trainer/Log Pis Std                 1.14903
trainer/Log Pis Max                 8.09963
trainer/Log Pis Min                -1.28114
trainer/Policy mu Mean              0.07648
trainer/Policy mu Std               0.60981
trainer/Policy mu Max               2.92196
trainer/Policy mu Min              -2.72655
trainer/Policy log std Mean        -2.1584
trainer/Policy log std Std          0.389485
trainer/Policy log std Max         -0.547208
trainer/Policy log std Min         -2.50132
trainer/Alpha                       0.0513463
trainer/Alpha Loss                  0.154301
exploration/num steps total     36200
exploration/num paths total       362
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.384626
exploration/Rewards Std             1.09856
exploration/Rewards Max            -0.00574893
exploration/Rewards Min            -7.46879
exploration/Returns Mean          -38.4626
exploration/Returns Std             1.77687
exploration/Returns Max           -36.6857
exploration/Returns Min           -40.2394
exploration/Actions Mean            0.0391805
exploration/Actions Std             0.252278
exploration/Actions Max             0.997632
exploration/Actions Min            -0.976612
exploration/Num Paths               2
exploration/Average Returns       -38.4626
evaluation/num steps total     180000
evaluation/num paths total       1800
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.262203
evaluation/Rewards Std              1.08589
evaluation/Rewards Max             -0.0159559
evaluation/Rewards Min            -11.1364
evaluation/Returns Mean           -26.2203
evaluation/Returns Std             17.7185
evaluation/Returns Max             -4.5161
evaluation/Returns Min            -61.9391
evaluation/Actions Mean             0.0183901
evaluation/Actions Std              0.194195
evaluation/Actions Max              0.997853
evaluation/Actions Min             -0.994976
evaluation/Num Paths               10
evaluation/Average Returns        -26.2203
time/data storing (s)               0.00144849
time/evaluation sampling (s)        0.220507
time/exploration sampling (s)       0.0672706
time/logging (s)                    0.00338801
time/saving (s)                     0.00209679
time/training (s)                   0.780472
time/epoch (s)                      1.07518
time/total (s)                    196.174
Epoch                             179
-----------------------------  ---------------
2019-04-21 00:47:29.940105 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 180 finished
-----------------------------  ---------------
replay_buffer/size              36400
trainer/QF1 Loss                    0.670989
trainer/QF2 Loss                    0.665586
trainer/Policy Loss                10.426
trainer/Q1 Predictions Mean        -8.63312
trainer/Q1 Predictions Std          1.43396
trainer/Q1 Predictions Max         -8.10113
trainer/Q1 Predictions Min        -20.3923
trainer/Q2 Predictions Mean        -8.60911
trainer/Q2 Predictions Std          1.46261
trainer/Q2 Predictions Max         -8.07495
trainer/Q2 Predictions Min        -20.3226
trainer/Q Targets Mean             -8.57635
trainer/Q Targets Std               1.72144
trainer/Q Targets Max              -0.302111
trainer/Q Targets Min             -20.9254
trainer/Log Pis Mean                1.97372
trainer/Log Pis Std                 0.957949
trainer/Log Pis Max                 4.63222
trainer/Log Pis Min                -1.86548
trainer/Policy mu Mean              0.0534457
trainer/Policy mu Std               0.440044
trainer/Policy mu Max               2.75468
trainer/Policy mu Min              -1.63574
trainer/Policy log std Mean        -2.2027
trainer/Policy log std Std          0.32358
trainer/Policy log std Max         -0.681695
trainer/Policy log std Min         -2.48394
trainer/Alpha                       0.0516407
trainer/Alpha Loss                 -0.0778762
exploration/num steps total     36400
exploration/num paths total       364
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.330946
exploration/Rewards Std             0.960441
exploration/Rewards Max            -0.010841
exploration/Rewards Min            -7.23877
exploration/Returns Mean          -33.0946
exploration/Returns Std             6.48861
exploration/Returns Max           -26.606
exploration/Returns Min           -39.5833
exploration/Actions Mean            0.0367001
exploration/Actions Std             0.243539
exploration/Actions Max             0.997441
exploration/Actions Min            -0.967288
exploration/Num Paths               2
exploration/Average Returns       -33.0946
evaluation/num steps total     181000
evaluation/num paths total       1810
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.265213
evaluation/Rewards Std              1.00803
evaluation/Rewards Max             -0.0302912
evaluation/Rewards Min             -9.42621
evaluation/Returns Mean           -26.5213
evaluation/Returns Std             11.4078
evaluation/Returns Max            -13.9478
evaluation/Returns Min            -51.8775
evaluation/Actions Mean             0.0384937
evaluation/Actions Std              0.189427
evaluation/Actions Max              0.996352
evaluation/Actions Min             -0.854402
evaluation/Num Paths               10
evaluation/Average Returns        -26.5213
time/data storing (s)               0.00133934
time/evaluation sampling (s)        0.226244
time/exploration sampling (s)       0.0668186
time/logging (s)                    0.00337097
time/saving (s)                     0.00162506
time/training (s)                   0.766635
time/epoch (s)                      1.06603
time/total (s)                    197.245
Epoch                             180
-----------------------------  ---------------
2019-04-21 00:47:31.003854 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 181 finished
-----------------------------  ----------------
replay_buffer/size              36600
trainer/QF1 Loss                    1.26851
trainer/QF2 Loss                    1.27128
trainer/Policy Loss                11.829
trainer/Q1 Predictions Mean       -10.0013
trainer/Q1 Predictions Std          9.1899
trainer/Q1 Predictions Max         -7.85525
trainer/Q1 Predictions Min        -72.9945
trainer/Q2 Predictions Mean        -9.99823
trainer/Q2 Predictions Std          9.14626
trainer/Q2 Predictions Max         -7.87058
trainer/Q2 Predictions Min        -72.7453
trainer/Q Targets Mean             -9.97025
trainer/Q Targets Std               9.29683
trainer/Q Targets Max              -0.0763724
trainer/Q Targets Min             -73.3346
trainer/Log Pis Mean                2.13471
trainer/Log Pis Std                 1.14217
trainer/Log Pis Max                 6.84927
trainer/Log Pis Min                -1.91976
trainer/Policy mu Mean              0.0771973
trainer/Policy mu Std               0.646899
trainer/Policy mu Max               3.2277
trainer/Policy mu Min              -2.18522
trainer/Policy log std Mean        -2.2041
trainer/Policy log std Std          0.443526
trainer/Policy log std Max         -0.182172
trainer/Policy log std Min         -2.55569
trainer/Alpha                       0.0527132
trainer/Alpha Loss                  0.396444
exploration/num steps total     36600
exploration/num paths total       366
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.234883
exploration/Rewards Std             0.626293
exploration/Rewards Max            -0.000911067
exploration/Rewards Min            -5.09758
exploration/Returns Mean          -23.4883
exploration/Returns Std             5.08356
exploration/Returns Max           -18.4047
exploration/Returns Min           -28.5718
exploration/Actions Mean           -0.0168309
exploration/Actions Std             0.221168
exploration/Actions Max             0.846587
exploration/Actions Min            -0.999243
exploration/Num Paths               2
exploration/Average Returns       -23.4883
evaluation/num steps total     182000
evaluation/num paths total       1820
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.181855
evaluation/Rewards Std              0.852165
evaluation/Rewards Max             -0.00233232
evaluation/Rewards Min             -8.61064
evaluation/Returns Mean           -18.1855
evaluation/Returns Std             10.8398
evaluation/Returns Max             -2.11017
evaluation/Returns Min            -41.5784
evaluation/Actions Mean             0.0224047
evaluation/Actions Std              0.185686
evaluation/Actions Max              0.995979
evaluation/Actions Min             -0.987022
evaluation/Num Paths               10
evaluation/Average Returns        -18.1855
time/data storing (s)               0.0014346
time/evaluation sampling (s)        0.223375
time/exploration sampling (s)       0.0692066
time/logging (s)                    0.00335463
time/saving (s)                     0.00198244
time/training (s)                   0.756846
time/epoch (s)                      1.0562
time/total (s)                    198.305
Epoch                             181
-----------------------------  ----------------
2019-04-21 00:47:32.092641 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 182 finished
-----------------------------  ---------------
replay_buffer/size              36800
trainer/QF1 Loss                    0.0733045
trainer/QF2 Loss                    0.0614391
trainer/Policy Loss                10.8923
trainer/Q1 Predictions Mean        -9.1304
trainer/Q1 Predictions Std          6.55906
trainer/Q1 Predictions Max         -7.9146
trainer/Q1 Predictions Min        -68.933
trainer/Q2 Predictions Mean        -9.13392
trainer/Q2 Predictions Std          6.59422
trainer/Q2 Predictions Max         -7.91274
trainer/Q2 Predictions Min        -69.1612
trainer/Q Targets Mean             -9.22385
trainer/Q Targets Std               6.77394
trainer/Q Targets Max              -7.90403
trainer/Q Targets Min             -70.9723
trainer/Log Pis Mean                2.06218
trainer/Log Pis Std                 1.03179
trainer/Log Pis Max                 5.6956
trainer/Log Pis Min                -1.09678
trainer/Policy mu Mean              0.08335
trainer/Policy mu Std               0.480708
trainer/Policy mu Max               3.05706
trainer/Policy mu Min              -1.37056
trainer/Policy log std Mean        -2.27615
trainer/Policy log std Std          0.370571
trainer/Policy log std Max         -0.648656
trainer/Policy log std Min         -2.55632
trainer/Alpha                       0.0524208
trainer/Alpha Loss                  0.183338
exploration/num steps total     36800
exploration/num paths total       368
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.142855
exploration/Rewards Std             0.18343
exploration/Rewards Max            -0.0116563
exploration/Rewards Min            -2.22466
exploration/Returns Mean          -14.2855
exploration/Returns Std             2.26173
exploration/Returns Max           -12.0238
exploration/Returns Min           -16.5472
exploration/Actions Mean           -0.00656637
exploration/Actions Std             0.162847
exploration/Actions Max             0.965628
exploration/Actions Min            -0.983628
exploration/Num Paths               2
exploration/Average Returns       -14.2855
evaluation/num steps total     183000
evaluation/num paths total       1830
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.232325
evaluation/Rewards Std              0.85762
evaluation/Rewards Max             -0.0123742
evaluation/Rewards Min             -8.32868
evaluation/Returns Mean           -23.2325
evaluation/Returns Std             11.0994
evaluation/Returns Max             -6.96598
evaluation/Returns Min            -41.9787
evaluation/Actions Mean             0.0307653
evaluation/Actions Std              0.182877
evaluation/Actions Max              0.996277
evaluation/Actions Min             -0.986835
evaluation/Num Paths               10
evaluation/Average Returns        -23.2325
time/data storing (s)               0.00132613
time/evaluation sampling (s)        0.230207
time/exploration sampling (s)       0.0686918
time/logging (s)                    0.00332422
time/saving (s)                     0.00189419
time/training (s)                   0.775807
time/epoch (s)                      1.08125
time/total (s)                    199.391
Epoch                             182
-----------------------------  ---------------
2019-04-21 00:47:33.157909 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 183 finished
-----------------------------  ---------------
replay_buffer/size              37000
trainer/QF1 Loss                    1.27104
trainer/QF2 Loss                    1.26663
trainer/Policy Loss                11.095
trainer/Q1 Predictions Mean        -9.29077
trainer/Q1 Predictions Std          6.31781
trainer/Q1 Predictions Max         -7.86156
trainer/Q1 Predictions Min        -62.779
trainer/Q2 Predictions Mean        -9.28483
trainer/Q2 Predictions Std          6.31953
trainer/Q2 Predictions Max         -7.85919
trainer/Q2 Predictions Min        -62.95
trainer/Q Targets Mean             -9.20658
trainer/Q Targets Std               6.49505
trainer/Q Targets Max              -0.206725
trainer/Q Targets Min             -64.0141
trainer/Log Pis Mean                1.95859
trainer/Log Pis Std                 1.37135
trainer/Log Pis Max                 8.62672
trainer/Log Pis Min                -1.35251
trainer/Policy mu Mean              0.0665915
trainer/Policy mu Std               0.615991
trainer/Policy mu Max               3.08165
trainer/Policy mu Min              -2.77299
trainer/Policy log std Mean        -2.17251
trainer/Policy log std Std          0.37978
trainer/Policy log std Max         -0.517576
trainer/Policy log std Min         -2.45108
trainer/Alpha                       0.0535319
trainer/Alpha Loss                 -0.121242
exploration/num steps total     37000
exploration/num paths total       370
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.418899
exploration/Rewards Std             1.21125
exploration/Rewards Max            -0.010067
exploration/Rewards Min            -8.98469
exploration/Returns Mean          -41.8899
exploration/Returns Std             7.27187
exploration/Returns Max           -34.618
exploration/Returns Min           -49.1618
exploration/Actions Mean            0.0579829
exploration/Actions Std             0.252945
exploration/Actions Max             0.999354
exploration/Actions Min            -0.37935
exploration/Num Paths               2
exploration/Average Returns       -41.8899
evaluation/num steps total     184000
evaluation/num paths total       1840
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.288472
evaluation/Rewards Std              1.22491
evaluation/Rewards Max             -0.00805526
evaluation/Rewards Min            -10.0263
evaluation/Returns Mean           -28.8472
evaluation/Returns Std             16.2764
evaluation/Returns Max             -4.74222
evaluation/Returns Min            -56.9217
evaluation/Actions Mean             0.0372956
evaluation/Actions Std              0.205271
evaluation/Actions Max              0.995239
evaluation/Actions Min             -0.992576
evaluation/Num Paths               10
evaluation/Average Returns        -28.8472
time/data storing (s)               0.00137303
time/evaluation sampling (s)        0.22561
time/exploration sampling (s)       0.0709031
time/logging (s)                    0.0033231
time/saving (s)                     0.00157816
time/training (s)                   0.755418
time/epoch (s)                      1.05821
time/total (s)                    200.454
Epoch                             183
-----------------------------  ---------------
2019-04-21 00:47:34.241549 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 184 finished
-----------------------------  ---------------
replay_buffer/size              37200
trainer/QF1 Loss                    0.63198
trainer/QF2 Loss                    0.640203
trainer/Policy Loss                11.6361
trainer/Q1 Predictions Mean        -9.69317
trainer/Q1 Predictions Std          7.71722
trainer/Q1 Predictions Max         -7.85643
trainer/Q1 Predictions Min        -60.5344
trainer/Q2 Predictions Mean        -9.70055
trainer/Q2 Predictions Std          7.70218
trainer/Q2 Predictions Max         -7.87379
trainer/Q2 Predictions Min        -60.5313
trainer/Q Targets Mean             -9.70419
trainer/Q Targets Std               7.73106
trainer/Q Targets Max              -0.222205
trainer/Q Targets Min             -60.7411
trainer/Log Pis Mean                2.09411
trainer/Log Pis Std                 1.08386
trainer/Log Pis Max                 6.74812
trainer/Log Pis Min                -1.16479
trainer/Policy mu Mean              0.0934367
trainer/Policy mu Std               0.562342
trainer/Policy mu Max               3.00831
trainer/Policy mu Min              -2.1586
trainer/Policy log std Mean        -2.25635
trainer/Policy log std Std          0.372701
trainer/Policy log std Max         -0.608323
trainer/Policy log std Min         -2.55031
trainer/Alpha                       0.0519995
trainer/Alpha Loss                  0.278265
exploration/num steps total     37200
exploration/num paths total       372
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.294512
exploration/Rewards Std             0.959016
exploration/Rewards Max            -0.00984594
exploration/Rewards Min            -8.19554
exploration/Returns Mean          -29.4512
exploration/Returns Std            13.2966
exploration/Returns Max           -16.1546
exploration/Returns Min           -42.7478
exploration/Actions Mean            0.0220442
exploration/Actions Std             0.22378
exploration/Actions Max             0.995961
exploration/Actions Min            -0.993166
exploration/Num Paths               2
exploration/Average Returns       -29.4512
evaluation/num steps total     185000
evaluation/num paths total       1850
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.238311
evaluation/Rewards Std              1.08647
evaluation/Rewards Max             -0.0205092
evaluation/Rewards Min            -10.3421
evaluation/Returns Mean           -23.8311
evaluation/Returns Std             18.9577
evaluation/Returns Max             -4.01319
evaluation/Returns Min            -60.3104
evaluation/Actions Mean             0.0257561
evaluation/Actions Std              0.190999
evaluation/Actions Max              0.996077
evaluation/Actions Min             -0.992793
evaluation/Num Paths               10
evaluation/Average Returns        -23.8311
time/data storing (s)               0.00130752
time/evaluation sampling (s)        0.228442
time/exploration sampling (s)       0.0656773
time/logging (s)                    0.00338306
time/saving (s)                     0.0019518
time/training (s)                   0.775496
time/epoch (s)                      1.07626
time/total (s)                    201.534
Epoch                             184
-----------------------------  ---------------
2019-04-21 00:47:35.323558 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 185 finished
-----------------------------  ---------------
replay_buffer/size              37400
trainer/QF1 Loss                    1.88827
trainer/QF2 Loss                    1.92103
trainer/Policy Loss                10.6865
trainer/Q1 Predictions Mean        -9.07755
trainer/Q1 Predictions Std          4.4298
trainer/Q1 Predictions Max         -7.84434
trainer/Q1 Predictions Min        -40.7266
trainer/Q2 Predictions Mean        -9.05465
trainer/Q2 Predictions Std          4.36084
trainer/Q2 Predictions Max         -7.85351
trainer/Q2 Predictions Min        -41.0063
trainer/Q Targets Mean             -8.94383
trainer/Q Targets Std               4.67304
trainer/Q Targets Max              -0.0635087
trainer/Q Targets Min             -40.7222
trainer/Log Pis Mean                1.79221
trainer/Log Pis Std                 1.25082
trainer/Log Pis Max                 7.42022
trainer/Log Pis Min                -2.32792
trainer/Policy mu Mean              0.0564366
trainer/Policy mu Std               0.611232
trainer/Policy mu Max               3.21617
trainer/Policy mu Min              -2.43109
trainer/Policy log std Mean        -2.06273
trainer/Policy log std Std          0.407948
trainer/Policy log std Max         -0.494579
trainer/Policy log std Min         -2.45461
trainer/Alpha                       0.0526466
trainer/Alpha Loss                 -0.611718
exploration/num steps total     37400
exploration/num paths total       374
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.240665
exploration/Rewards Std             0.486527
exploration/Rewards Max            -0.00390882
exploration/Rewards Min            -4.09928
exploration/Returns Mean          -24.0665
exploration/Returns Std             1.40676
exploration/Returns Max           -22.6597
exploration/Returns Min           -25.4733
exploration/Actions Mean            0.0289542
exploration/Actions Std             0.219526
exploration/Actions Max             0.993049
exploration/Actions Min            -0.447793
exploration/Num Paths               2
exploration/Average Returns       -24.0665
evaluation/num steps total     186000
evaluation/num paths total       1860
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.263978
evaluation/Rewards Std              0.973592
evaluation/Rewards Max             -0.0619869
evaluation/Rewards Min             -9.48846
evaluation/Returns Mean           -26.3978
evaluation/Returns Std             11.1833
evaluation/Returns Max             -8.43467
evaluation/Returns Min            -46.7846
evaluation/Actions Mean             0.0269549
evaluation/Actions Std              0.199998
evaluation/Actions Max              0.996136
evaluation/Actions Min             -0.986447
evaluation/Num Paths               10
evaluation/Average Returns        -26.3978
time/data storing (s)               0.00128408
time/evaluation sampling (s)        0.230836
time/exploration sampling (s)       0.0681731
time/logging (s)                    0.0034383
time/saving (s)                     0.00195731
time/training (s)                   0.768736
time/epoch (s)                      1.07442
time/total (s)                    202.613
Epoch                             185
-----------------------------  ---------------
2019-04-21 00:47:36.408250 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 186 finished
-----------------------------  ---------------
replay_buffer/size              37600
trainer/QF1 Loss                    0.0399359
trainer/QF2 Loss                    0.037978
trainer/Policy Loss                11.7932
trainer/Q1 Predictions Mean       -10.1996
trainer/Q1 Predictions Std          8.76191
trainer/Q1 Predictions Max         -7.84988
trainer/Q1 Predictions Min        -64.625
trainer/Q2 Predictions Mean       -10.2402
trainer/Q2 Predictions Std          8.76384
trainer/Q2 Predictions Max         -7.88747
trainer/Q2 Predictions Min        -64.5719
trainer/Q Targets Mean            -10.2998
trainer/Q Targets Std               8.83647
trainer/Q Targets Max              -7.85876
trainer/Q Targets Min             -65.8364
trainer/Log Pis Mean                1.95938
trainer/Log Pis Std                 1.12916
trainer/Log Pis Max                 6.05311
trainer/Log Pis Min                -1.48859
trainer/Policy mu Mean              0.076829
trainer/Policy mu Std               0.6599
trainer/Policy mu Max               2.96385
trainer/Policy mu Min              -2.56888
trainer/Policy log std Mean        -2.087
trainer/Policy log std Std          0.450415
trainer/Policy log std Max         -0.515162
trainer/Policy log std Min         -2.45917
trainer/Alpha                       0.0510824
trainer/Alpha Loss                 -0.120798
exploration/num steps total     37600
exploration/num paths total       376
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.219239
exploration/Rewards Std             0.567216
exploration/Rewards Max            -0.00170637
exploration/Rewards Min            -5.08646
exploration/Returns Mean          -21.9239
exploration/Returns Std             6.34306
exploration/Returns Max           -15.5809
exploration/Returns Min           -28.267
exploration/Actions Mean            0.0254796
exploration/Actions Std             0.189014
exploration/Actions Max             0.994534
exploration/Actions Min            -0.386467
exploration/Num Paths               2
exploration/Average Returns       -21.9239
evaluation/num steps total     187000
evaluation/num paths total       1870
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.233665
evaluation/Rewards Std              1.00968
evaluation/Rewards Max             -0.015832
evaluation/Rewards Min             -9.68364
evaluation/Returns Mean           -23.3665
evaluation/Returns Std             15.8405
evaluation/Returns Max             -4.67307
evaluation/Returns Min            -55.0137
evaluation/Actions Mean             0.0310942
evaluation/Actions Std              0.178936
evaluation/Actions Max              0.996292
evaluation/Actions Min             -0.986888
evaluation/Num Paths               10
evaluation/Average Returns        -23.3665
time/data storing (s)               0.00122064
time/evaluation sampling (s)        0.225149
time/exploration sampling (s)       0.0653076
time/logging (s)                    0.00258291
time/saving (s)                     0.00197636
time/training (s)                   0.780134
time/epoch (s)                      1.07637
time/total (s)                    203.694
Epoch                             186
-----------------------------  ---------------
2019-04-21 00:47:37.497821 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 187 finished
-----------------------------  ---------------
replay_buffer/size              37800
trainer/QF1 Loss                    0.215259
trainer/QF2 Loss                    0.189834
trainer/Policy Loss                11.36
trainer/Q1 Predictions Mean        -9.70266
trainer/Q1 Predictions Std          7.96109
trainer/Q1 Predictions Max         -7.70464
trainer/Q1 Predictions Min        -77.1031
trainer/Q2 Predictions Mean        -9.69899
trainer/Q2 Predictions Std          7.93448
trainer/Q2 Predictions Max         -7.73196
trainer/Q2 Predictions Min        -77.0053
trainer/Q Targets Mean             -9.79664
trainer/Q Targets Std               7.65891
trainer/Q Targets Max              -7.83722
trainer/Q Targets Min             -74.7238
trainer/Log Pis Mean                1.97786
trainer/Log Pis Std                 1.06031
trainer/Log Pis Max                 5.85308
trainer/Log Pis Min                -1.44554
trainer/Policy mu Mean              0.0285718
trainer/Policy mu Std               0.698397
trainer/Policy mu Max               3.20278
trainer/Policy mu Min              -2.66684
trainer/Policy log std Mean        -2.09688
trainer/Policy log std Std          0.462349
trainer/Policy log std Max         -0.577968
trainer/Policy log std Min         -2.49134
trainer/Alpha                       0.0501989
trainer/Alpha Loss                 -0.0662311
exploration/num steps total     37800
exploration/num paths total       378
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.368886
exploration/Rewards Std             1.21457
exploration/Rewards Max            -0.00769959
exploration/Rewards Min            -9.54647
exploration/Returns Mean          -36.8886
exploration/Returns Std            22.4679
exploration/Returns Max           -14.4207
exploration/Returns Min           -59.3564
exploration/Actions Mean            0.0389039
exploration/Actions Std             0.231839
exploration/Actions Max             0.997545
exploration/Actions Min            -0.8167
exploration/Num Paths               2
exploration/Average Returns       -36.8886
evaluation/num steps total     188000
evaluation/num paths total       1880
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.147956
evaluation/Rewards Std              0.777847
evaluation/Rewards Max             -0.0210474
evaluation/Rewards Min             -8.69863
evaluation/Returns Mean           -14.7956
evaluation/Returns Std             14.9512
evaluation/Returns Max             -2.27403
evaluation/Returns Min            -45.1094
evaluation/Actions Mean             0.0139242
evaluation/Actions Std              0.158233
evaluation/Actions Max              0.994666
evaluation/Actions Min             -0.989303
evaluation/Num Paths               10
evaluation/Average Returns        -14.7956
time/data storing (s)               0.00149033
time/evaluation sampling (s)        0.229015
time/exploration sampling (s)       0.0665294
time/logging (s)                    0.00335557
time/saving (s)                     0.00195503
time/training (s)                   0.780696
time/epoch (s)                      1.08304
time/total (s)                    204.781
Epoch                             187
-----------------------------  ---------------
2019-04-21 00:47:38.590597 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 188 finished
-----------------------------  ---------------
replay_buffer/size              38000
trainer/QF1 Loss                    0.690491
trainer/QF2 Loss                    0.695234
trainer/Policy Loss                10.5414
trainer/Q1 Predictions Mean        -8.75132
trainer/Q1 Predictions Std          3.34165
trainer/Q1 Predictions Max         -7.75279
trainer/Q1 Predictions Min        -28.5987
trainer/Q2 Predictions Mean        -8.74743
trainer/Q2 Predictions Std          3.34363
trainer/Q2 Predictions Max         -7.76086
trainer/Q2 Predictions Min        -28.7271
trainer/Q Targets Mean             -8.81062
trainer/Q Targets Std               3.56643
trainer/Q Targets Max              -0.0770174
trainer/Q Targets Min             -31.0958
trainer/Log Pis Mean                1.94682
trainer/Log Pis Std                 1.08669
trainer/Log Pis Max                 7.15062
trainer/Log Pis Min                -0.899287
trainer/Policy mu Mean              0.0263215
trainer/Policy mu Std               0.607644
trainer/Policy mu Max               2.71358
trainer/Policy mu Min              -2.9969
trainer/Policy log std Mean        -2.126
trainer/Policy log std Std          0.401622
trainer/Policy log std Max         -0.565059
trainer/Policy log std Min         -2.45023
trainer/Alpha                       0.0508213
trainer/Alpha Loss                 -0.15845
exploration/num steps total     38000
exploration/num paths total       380
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.386806
exploration/Rewards Std             1.22391
exploration/Rewards Max            -0.0134014
exploration/Rewards Min            -9.33434
exploration/Returns Mean          -38.6806
exploration/Returns Std            22.4103
exploration/Returns Max           -16.2703
exploration/Returns Min           -61.091
exploration/Actions Mean            0.0397683
exploration/Actions Std             0.22696
exploration/Actions Max             0.99958
exploration/Actions Min            -0.405169
exploration/Num Paths               2
exploration/Average Returns       -38.6806
evaluation/num steps total     189000
evaluation/num paths total       1890
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.29468
evaluation/Rewards Std              1.206
evaluation/Rewards Max             -0.0230119
evaluation/Rewards Min            -10.0672
evaluation/Returns Mean           -29.468
evaluation/Returns Std             16.3917
evaluation/Returns Max             -4.3133
evaluation/Returns Min            -52.588
evaluation/Actions Mean             0.0279162
evaluation/Actions Std              0.207571
evaluation/Actions Max              0.997591
evaluation/Actions Min             -0.995796
evaluation/Num Paths               10
evaluation/Average Returns        -29.468
time/data storing (s)               0.00136302
time/evaluation sampling (s)        0.234468
time/exploration sampling (s)       0.0780084
time/logging (s)                    0.00332808
time/saving (s)                     0.00197693
time/training (s)                   0.766288
time/epoch (s)                      1.08543
time/total (s)                    205.871
Epoch                             188
-----------------------------  ---------------
2019-04-21 00:47:39.667786 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 189 finished
-----------------------------  ---------------
replay_buffer/size              38200
trainer/QF1 Loss                    0.637037
trainer/QF2 Loss                    0.651584
trainer/Policy Loss                11.0269
trainer/Q1 Predictions Mean        -9.32548
trainer/Q1 Predictions Std          6.51462
trainer/Q1 Predictions Max         -7.80383
trainer/Q1 Predictions Min        -61.7261
trainer/Q2 Predictions Mean        -9.29718
trainer/Q2 Predictions Std          6.45666
trainer/Q2 Predictions Max         -7.79445
trainer/Q2 Predictions Min        -61.3419
trainer/Q Targets Mean             -9.28731
trainer/Q Targets Std               6.55749
trainer/Q Targets Max              -0.0750173
trainer/Q Targets Min             -61.7551
trainer/Log Pis Mean                2.04086
trainer/Log Pis Std                 1.36216
trainer/Log Pis Max                 6.99624
trainer/Log Pis Min                -4.47429
trainer/Policy mu Mean              0.0863952
trainer/Policy mu Std               0.580421
trainer/Policy mu Max               2.97415
trainer/Policy mu Min              -1.92438
trainer/Policy log std Mean        -2.20185
trainer/Policy log std Std          0.380418
trainer/Policy log std Max         -0.592109
trainer/Policy log std Min         -2.49377
trainer/Alpha                       0.0495209
trainer/Alpha Loss                  0.122786
exploration/num steps total     38200
exploration/num paths total       382
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.375217
exploration/Rewards Std             1.0732
exploration/Rewards Max            -0.00266697
exploration/Rewards Min            -7.36381
exploration/Returns Mean          -37.5217
exploration/Returns Std             0.479963
exploration/Returns Max           -37.0417
exploration/Returns Min           -38.0016
exploration/Actions Mean            0.0381288
exploration/Actions Std             0.264131
exploration/Actions Max             0.996328
exploration/Actions Min            -0.982361
exploration/Num Paths               2
exploration/Average Returns       -37.5217
evaluation/num steps total     190000
evaluation/num paths total       1900
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.283124
evaluation/Rewards Std              1.08028
evaluation/Rewards Max             -0.0592331
evaluation/Rewards Min            -10.1849
evaluation/Returns Mean           -28.3124
evaluation/Returns Std             18.1911
evaluation/Returns Max             -7.13099
evaluation/Returns Min            -63.5066
evaluation/Actions Mean             0.0375364
evaluation/Actions Std              0.187598
evaluation/Actions Max              0.996354
evaluation/Actions Min             -0.983541
evaluation/Num Paths               10
evaluation/Average Returns        -28.3124
time/data storing (s)               0.00129919
time/evaluation sampling (s)        0.222621
time/exploration sampling (s)       0.0643476
time/logging (s)                    0.00337303
time/saving (s)                     0.00203424
time/training (s)                   0.776404
time/epoch (s)                      1.07008
time/total (s)                    206.945
Epoch                             189
-----------------------------  ---------------
2019-04-21 00:47:40.752567 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 190 finished
-----------------------------  ---------------
replay_buffer/size              38400
trainer/QF1 Loss                    0.0949351
trainer/QF2 Loss                    0.105321
trainer/Policy Loss                11.5908
trainer/Q1 Predictions Mean       -10.146
trainer/Q1 Predictions Std          9.6681
trainer/Q1 Predictions Max         -7.80372
trainer/Q1 Predictions Min        -68.9964
trainer/Q2 Predictions Mean       -10.0988
trainer/Q2 Predictions Std          9.67429
trainer/Q2 Predictions Max         -7.74878
trainer/Q2 Predictions Min        -68.7314
trainer/Q Targets Mean            -10.1676
trainer/Q Targets Std               9.68795
trainer/Q Targets Max              -7.74238
trainer/Q Targets Min             -70.5005
trainer/Log Pis Mean                1.70981
trainer/Log Pis Std                 1.56597
trainer/Log Pis Max                 8.42064
trainer/Log Pis Min                -4.07344
trainer/Policy mu Mean              0.0739158
trainer/Policy mu Std               0.677226
trainer/Policy mu Max               3.32762
trainer/Policy mu Min              -2.93025
trainer/Policy log std Mean        -2.09372
trainer/Policy log std Std          0.443059
trainer/Policy log std Max         -0.301512
trainer/Policy log std Min         -2.44311
trainer/Alpha                       0.0493024
trainer/Alpha Loss                 -0.873402
exploration/num steps total     38400
exploration/num paths total       384
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.351577
exploration/Rewards Std             1.03229
exploration/Rewards Max            -0.0175433
exploration/Rewards Min            -8.2539
exploration/Returns Mean          -35.1577
exploration/Returns Std            16.9907
exploration/Returns Max           -18.1671
exploration/Returns Min           -52.1484
exploration/Actions Mean            0.0257777
exploration/Actions Std             0.232502
exploration/Actions Max             0.997715
exploration/Actions Min            -0.959038
exploration/Num Paths               2
exploration/Average Returns       -35.1577
evaluation/num steps total     191000
evaluation/num paths total       1910
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.268517
evaluation/Rewards Std              1.06976
evaluation/Rewards Max             -0.0442082
evaluation/Rewards Min             -9.96455
evaluation/Returns Mean           -26.8517
evaluation/Returns Std             15.5666
evaluation/Returns Max             -4.90945
evaluation/Returns Min            -59.7218
evaluation/Actions Mean             0.0257809
evaluation/Actions Std              0.196813
evaluation/Actions Max              0.995796
evaluation/Actions Min             -0.993684
evaluation/Num Paths               10
evaluation/Average Returns        -26.8517
time/data storing (s)               0.00138781
time/evaluation sampling (s)        0.224616
time/exploration sampling (s)       0.0679614
time/logging (s)                    0.00333378
time/saving (s)                     0.00200163
time/training (s)                   0.77818
time/epoch (s)                      1.07748
time/total (s)                    208.026
Epoch                             190
-----------------------------  ---------------
2019-04-21 00:47:41.827556 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 191 finished
-----------------------------  ---------------
replay_buffer/size              38600
trainer/QF1 Loss                    1.2379
trainer/QF2 Loss                    1.24894
trainer/Policy Loss                10.7304
trainer/Q1 Predictions Mean        -8.77486
trainer/Q1 Predictions Std          4.00472
trainer/Q1 Predictions Max         -7.66087
trainer/Q1 Predictions Min        -34.5934
trainer/Q2 Predictions Mean        -8.79816
trainer/Q2 Predictions Std          4.01765
trainer/Q2 Predictions Max         -7.6989
trainer/Q2 Predictions Min        -34.9253
trainer/Q Targets Mean             -8.72442
trainer/Q Targets Std               4.12969
trainer/Q Targets Max              -0.039143
trainer/Q Targets Min             -34.572
trainer/Log Pis Mean                2.06626
trainer/Log Pis Std                 1.12678
trainer/Log Pis Max                 6.80844
trainer/Log Pis Min                -2.11141
trainer/Policy mu Mean              0.0860018
trainer/Policy mu Std               0.606389
trainer/Policy mu Max               2.95663
trainer/Policy mu Min              -2.45309
trainer/Policy log std Mean        -2.18527
trainer/Policy log std Std          0.408383
trainer/Policy log std Max         -0.479113
trainer/Policy log std Min         -2.54369
trainer/Alpha                       0.050132
trainer/Alpha Loss                  0.198315
exploration/num steps total     38600
exploration/num paths total       386
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.387539
exploration/Rewards Std             1.37181
exploration/Rewards Max            -0.00827876
exploration/Rewards Min           -10.6804
exploration/Returns Mean          -38.7539
exploration/Returns Std            26.3285
exploration/Returns Max           -12.4254
exploration/Returns Min           -65.0825
exploration/Actions Mean            0.0108711
exploration/Actions Std             0.234148
exploration/Actions Max             0.998904
exploration/Actions Min            -0.997187
exploration/Num Paths               2
exploration/Average Returns       -38.7539
evaluation/num steps total     192000
evaluation/num paths total       1920
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.211428
evaluation/Rewards Std              0.876098
evaluation/Rewards Max             -0.0124236
evaluation/Rewards Min             -9.14744
evaluation/Returns Mean           -21.1428
evaluation/Returns Std             13.8348
evaluation/Returns Max             -6.12218
evaluation/Returns Min            -47.7671
evaluation/Actions Mean             0.0249637
evaluation/Actions Std              0.177372
evaluation/Actions Max              0.997373
evaluation/Actions Min             -0.988182
evaluation/Num Paths               10
evaluation/Average Returns        -21.1428
time/data storing (s)               0.00134835
time/evaluation sampling (s)        0.222339
time/exploration sampling (s)       0.0654544
time/logging (s)                    0.00331894
time/saving (s)                     0.00157282
time/training (s)                   0.774282
time/epoch (s)                      1.06832
time/total (s)                    209.099
Epoch                             191
-----------------------------  ---------------
2019-04-21 00:47:42.893904 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 192 finished
-----------------------------  ---------------
replay_buffer/size              38800
trainer/QF1 Loss                    1.99802
trainer/QF2 Loss                    1.96553
trainer/Policy Loss                10.3254
trainer/Q1 Predictions Mean        -8.71403
trainer/Q1 Predictions Std          5.97714
trainer/Q1 Predictions Max         -7.79532
trainer/Q1 Predictions Min        -67.9784
trainer/Q2 Predictions Mean        -8.70729
trainer/Q2 Predictions Std          6.03185
trainer/Q2 Predictions Max         -7.78127
trainer/Q2 Predictions Min        -68.5125
trainer/Q Targets Mean             -8.52243
trainer/Q Targets Std               6.54765
trainer/Q Targets Max              -0.138496
trainer/Q Targets Min             -72.1394
trainer/Log Pis Mean                1.81447
trainer/Log Pis Std                 1.16704
trainer/Log Pis Max                 5.49711
trainer/Log Pis Min                -3.40678
trainer/Policy mu Mean              0.0396202
trainer/Policy mu Std               0.471617
trainer/Policy mu Max               3.10783
trainer/Policy mu Min              -2.14308
trainer/Policy log std Mean        -2.12931
trainer/Policy log std Std          0.328394
trainer/Policy log std Max         -0.653719
trainer/Policy log std Min         -2.42432
trainer/Alpha                       0.0503128
trainer/Alpha Loss                 -0.554606
exploration/num steps total     38800
exploration/num paths total       388
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.450585
exploration/Rewards Std             1.24704
exploration/Rewards Max            -0.0039232
exploration/Rewards Min            -8.15733
exploration/Returns Mean          -45.0585
exploration/Returns Std             5.62581
exploration/Returns Max           -39.4327
exploration/Returns Min           -50.6843
exploration/Actions Mean            0.0503428
exploration/Actions Std             0.247288
exploration/Actions Max             0.999105
exploration/Actions Min            -0.623821
exploration/Num Paths               2
exploration/Average Returns       -45.0585
evaluation/num steps total     193000
evaluation/num paths total       1930
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.271504
evaluation/Rewards Std              1.07275
evaluation/Rewards Max             -0.00615135
evaluation/Rewards Min            -10.6122
evaluation/Returns Mean           -27.1504
evaluation/Returns Std             17.2239
evaluation/Returns Max             -5.58099
evaluation/Returns Min            -63.6635
evaluation/Actions Mean             0.019803
evaluation/Actions Std              0.195872
evaluation/Actions Max              0.997005
evaluation/Actions Min             -0.994783
evaluation/Num Paths               10
evaluation/Average Returns        -27.1504
time/data storing (s)               0.00132533
time/evaluation sampling (s)        0.229533
time/exploration sampling (s)       0.0634012
time/logging (s)                    0.00334063
time/saving (s)                     0.00160837
time/training (s)                   0.759822
time/epoch (s)                      1.05903
time/total (s)                    210.162
Epoch                             192
-----------------------------  ---------------
2019-04-21 00:47:43.975954 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 193 finished
-----------------------------  ---------------
replay_buffer/size              39000
trainer/QF1 Loss                    0.597362
trainer/QF2 Loss                    0.608536
trainer/Policy Loss                11.1122
trainer/Q1 Predictions Mean        -9.1477
trainer/Q1 Predictions Std          5.38552
trainer/Q1 Predictions Max         -7.66426
trainer/Q1 Predictions Min        -48.4656
trainer/Q2 Predictions Mean        -9.1828
trainer/Q2 Predictions Std          5.38244
trainer/Q2 Predictions Max         -7.70209
trainer/Q2 Predictions Min        -48.6139
trainer/Q Targets Mean             -9.12993
trainer/Q Targets Std               5.49399
trainer/Q Targets Max              -0.147066
trainer/Q Targets Min             -48.8709
trainer/Log Pis Mean                2.06559
trainer/Log Pis Std                 1.03271
trainer/Log Pis Max                 5.27431
trainer/Log Pis Min                -1.24456
trainer/Policy mu Mean              0.0502756
trainer/Policy mu Std               0.644282
trainer/Policy mu Max               3.10846
trainer/Policy mu Min              -2.69297
trainer/Policy log std Mean        -2.17471
trainer/Policy log std Std          0.443625
trainer/Policy log std Max         -0.570406
trainer/Policy log std Min         -2.52583
trainer/Alpha                       0.0497291
trainer/Alpha Loss                  0.196851
exploration/num steps total     39000
exploration/num paths total       390
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.280691
exploration/Rewards Std             0.879969
exploration/Rewards Max            -0.0116204
exploration/Rewards Min            -7.3487
exploration/Returns Mean          -28.0691
exploration/Returns Std            13.5636
exploration/Returns Max           -14.5055
exploration/Returns Min           -41.6328
exploration/Actions Mean            0.0182998
exploration/Actions Std             0.205659
exploration/Actions Max             0.996978
exploration/Actions Min            -0.966716
exploration/Num Paths               2
exploration/Average Returns       -28.0691
evaluation/num steps total     194000
evaluation/num paths total       1940
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.280894
evaluation/Rewards Std              1.1521
evaluation/Rewards Max             -0.0410331
evaluation/Rewards Min            -10.642
evaluation/Returns Mean           -28.0894
evaluation/Returns Std             18.8664
evaluation/Returns Max             -6.99871
evaluation/Returns Min            -57.8329
evaluation/Actions Mean             0.0326397
evaluation/Actions Std              0.201079
evaluation/Actions Max              0.998015
evaluation/Actions Min             -0.992994
evaluation/Num Paths               10
evaluation/Average Returns        -28.0894
time/data storing (s)               0.00128739
time/evaluation sampling (s)        0.227823
time/exploration sampling (s)       0.0648888
time/logging (s)                    0.00333364
time/saving (s)                     0.00196149
time/training (s)                   0.77581
time/epoch (s)                      1.0751
time/total (s)                    211.241
Epoch                             193
-----------------------------  ---------------
2019-04-21 00:47:45.056764 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 194 finished
-----------------------------  ---------------
replay_buffer/size              39200
trainer/QF1 Loss                    0.121591
trainer/QF2 Loss                    0.15446
trainer/Policy Loss                10.6964
trainer/Q1 Predictions Mean        -9.13401
trainer/Q1 Predictions Std          6.78221
trainer/Q1 Predictions Max         -7.71076
trainer/Q1 Predictions Min        -66.1025
trainer/Q2 Predictions Mean        -9.11072
trainer/Q2 Predictions Std          6.7501
trainer/Q2 Predictions Max         -7.70201
trainer/Q2 Predictions Min        -65.6691
trainer/Q Targets Mean             -9.22288
trainer/Q Targets Std               7.06585
trainer/Q Targets Max              -7.63289
trainer/Q Targets Min             -68.8715
trainer/Log Pis Mean                1.76291
trainer/Log Pis Std                 1.26542
trainer/Log Pis Max                 5.73739
trainer/Log Pis Min                -1.73616
trainer/Policy mu Mean              0.07271
trainer/Policy mu Std               0.535731
trainer/Policy mu Max               3.14658
trainer/Policy mu Min              -2.33749
trainer/Policy log std Mean        -2.16584
trainer/Policy log std Std          0.349791
trainer/Policy log std Max         -0.410678
trainer/Policy log std Min         -2.44514
trainer/Alpha                       0.0497869
trainer/Alpha Loss                 -0.711254
exploration/num steps total     39200
exploration/num paths total       392
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.366877
exploration/Rewards Std             1.00634
exploration/Rewards Max            -0.00723696
exploration/Rewards Min            -7.5864
exploration/Returns Mean          -36.6877
exploration/Returns Std            10.2402
exploration/Returns Max           -26.4475
exploration/Returns Min           -46.9279
exploration/Actions Mean            0.0337744
exploration/Actions Std             0.235152
exploration/Actions Max             0.998615
exploration/Actions Min            -0.886129
exploration/Num Paths               2
exploration/Average Returns       -36.6877
evaluation/num steps total     195000
evaluation/num paths total       1950
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.24728
evaluation/Rewards Std              1.03895
evaluation/Rewards Max             -0.0143179
evaluation/Rewards Min            -10.5173
evaluation/Returns Mean           -24.728
evaluation/Returns Std             18.1042
evaluation/Returns Max             -7.41291
evaluation/Returns Min            -61.9214
evaluation/Actions Mean             0.025632
evaluation/Actions Std              0.186459
evaluation/Actions Max              0.997539
evaluation/Actions Min             -0.99241
evaluation/Num Paths               10
evaluation/Average Returns        -24.728
time/data storing (s)               0.00147989
time/evaluation sampling (s)        0.230892
time/exploration sampling (s)       0.0697208
time/logging (s)                    0.00335403
time/saving (s)                     0.00165178
time/training (s)                   0.766386
time/epoch (s)                      1.07348
time/total (s)                    212.318
Epoch                             194
-----------------------------  ---------------
2019-04-21 00:47:46.142780 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 195 finished
-----------------------------  ---------------
replay_buffer/size              39400
trainer/QF1 Loss                    0.0718419
trainer/QF2 Loss                    0.103982
trainer/Policy Loss                10.6246
trainer/Q1 Predictions Mean        -8.69697
trainer/Q1 Predictions Std          3.14234
trainer/Q1 Predictions Max         -7.5778
trainer/Q1 Predictions Min        -26.0153
trainer/Q2 Predictions Mean        -8.65162
trainer/Q2 Predictions Std          3.09635
trainer/Q2 Predictions Max         -7.55593
trainer/Q2 Predictions Min        -25.9428
trainer/Q Targets Mean             -8.80412
trainer/Q Targets Std               3.14049
trainer/Q Targets Max              -7.59503
trainer/Q Targets Min             -26.1582
trainer/Log Pis Mean                2.05705
trainer/Log Pis Std                 1.0535
trainer/Log Pis Max                 5.11736
trainer/Log Pis Min                -0.669068
trainer/Policy mu Mean              0.0840024
trainer/Policy mu Std               0.650451
trainer/Policy mu Max               2.97134
trainer/Policy mu Min              -2.66099
trainer/Policy log std Mean        -2.12908
trainer/Policy log std Std          0.440497
trainer/Policy log std Max         -0.414264
trainer/Policy log std Min         -2.52193
trainer/Alpha                       0.0504357
trainer/Alpha Loss                  0.170404
exploration/num steps total     39400
exploration/num paths total       394
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.170399
exploration/Rewards Std             0.31404
exploration/Rewards Max            -0.00863259
exploration/Rewards Min            -3.26484
exploration/Returns Mean          -17.0399
exploration/Returns Std             2.35725
exploration/Returns Max           -14.6827
exploration/Returns Min           -19.3972
exploration/Actions Mean            0.00963465
exploration/Actions Std             0.181089
exploration/Actions Max             0.993548
exploration/Actions Min            -0.983803
exploration/Num Paths               2
exploration/Average Returns       -17.0399
evaluation/num steps total     196000
evaluation/num paths total       1960
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.267924
evaluation/Rewards Std              1.03355
evaluation/Rewards Max             -0.0129072
evaluation/Rewards Min            -10.7452
evaluation/Returns Mean           -26.7924
evaluation/Returns Std             15.8189
evaluation/Returns Max            -12.0186
evaluation/Returns Min            -58.4374
evaluation/Actions Mean             0.0200495
evaluation/Actions Std              0.195881
evaluation/Actions Max              0.996879
evaluation/Actions Min             -0.993251
evaluation/Num Paths               10
evaluation/Average Returns        -26.7924
time/data storing (s)               0.00130097
time/evaluation sampling (s)        0.226868
time/exploration sampling (s)       0.0700897
time/logging (s)                    0.00335897
time/saving (s)                     0.00156036
time/training (s)                   0.775464
time/epoch (s)                      1.07864
time/total (s)                    213.401
Epoch                             195
-----------------------------  ---------------
2019-04-21 00:47:47.242591 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 196 finished
-----------------------------  ---------------
replay_buffer/size              39600
trainer/QF1 Loss                    0.0979982
trainer/QF2 Loss                    0.0985416
trainer/Policy Loss                10.4829
trainer/Q1 Predictions Mean        -8.78523
trainer/Q1 Predictions Std          5.205
trainer/Q1 Predictions Max         -7.44799
trainer/Q1 Predictions Min        -51.4166
trainer/Q2 Predictions Mean        -8.78499
trainer/Q2 Predictions Std          5.23571
trainer/Q2 Predictions Max         -7.44083
trainer/Q2 Predictions Min        -51.7241
trainer/Q Targets Mean             -8.96236
trainer/Q Targets Std               5.19207
trainer/Q Targets Max              -7.57755
trainer/Q Targets Min             -51.9624
trainer/Log Pis Mean                1.97205
trainer/Log Pis Std                 1.04449
trainer/Log Pis Max                 4.79931
trainer/Log Pis Min                -0.994956
trainer/Policy mu Mean              0.0119518
trainer/Policy mu Std               0.602727
trainer/Policy mu Max               2.90633
trainer/Policy mu Min              -2.65857
trainer/Policy log std Mean        -2.16249
trainer/Policy log std Std          0.421785
trainer/Policy log std Max         -0.540817
trainer/Policy log std Min         -2.52192
trainer/Alpha                       0.0516285
trainer/Alpha Loss                 -0.0828352
exploration/num steps total     39600
exploration/num paths total       396
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.403125
exploration/Rewards Std             1.342
exploration/Rewards Max            -0.00281457
exploration/Rewards Min           -10.1533
exploration/Returns Mean          -40.3125
exploration/Returns Std            26.6383
exploration/Returns Max           -13.6741
exploration/Returns Min           -66.9508
exploration/Actions Mean            0.0223155
exploration/Actions Std             0.227822
exploration/Actions Max             0.998988
exploration/Actions Min            -0.952757
exploration/Num Paths               2
exploration/Average Returns       -40.3125
evaluation/num steps total     197000
evaluation/num paths total       1970
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.310573
evaluation/Rewards Std              1.15737
evaluation/Rewards Max             -0.0576075
evaluation/Rewards Min            -10.4761
evaluation/Returns Mean           -31.0573
evaluation/Returns Std             16.951
evaluation/Returns Max            -10.53
evaluation/Returns Min            -62.6336
evaluation/Actions Mean             0.0149476
evaluation/Actions Std              0.206817
evaluation/Actions Max              0.996409
evaluation/Actions Min             -0.991559
evaluation/Num Paths               10
evaluation/Average Returns        -31.0573
time/data storing (s)               0.00122578
time/evaluation sampling (s)        0.222163
time/exploration sampling (s)       0.0646732
time/logging (s)                    0.00338919
time/saving (s)                     0.0106862
time/training (s)                   0.790367
time/epoch (s)                      1.0925
time/total (s)                    214.498
Epoch                             196
-----------------------------  ---------------
2019-04-21 00:47:48.316576 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 197 finished
-----------------------------  ---------------
replay_buffer/size              39800
trainer/QF1 Loss                    2.29776
trainer/QF2 Loss                    2.27695
trainer/Policy Loss                10.3264
trainer/Q1 Predictions Mean        -8.60686
trainer/Q1 Predictions Std          4.26379
trainer/Q1 Predictions Max         -7.54169
trainer/Q1 Predictions Min        -39.2193
trainer/Q2 Predictions Mean        -8.57369
trainer/Q2 Predictions Std          4.26606
trainer/Q2 Predictions Max         -7.51254
trainer/Q2 Predictions Min        -39.3839
trainer/Q Targets Mean             -8.41702
trainer/Q Targets Std               4.66673
trainer/Q Targets Max              -0.0354318
trainer/Q Targets Min             -40.8273
trainer/Log Pis Mean                1.90927
trainer/Log Pis Std                 1.15617
trainer/Log Pis Max                 5.44508
trainer/Log Pis Min                -2.89542
trainer/Policy mu Mean              0.103064
trainer/Policy mu Std               0.56345
trainer/Policy mu Max               3.15114
trainer/Policy mu Min              -1.23239
trainer/Policy log std Mean        -2.16024
trainer/Policy log std Std          0.387589
trainer/Policy log std Max         -0.535126
trainer/Policy log std Min         -2.50999
trainer/Alpha                       0.0523406
trainer/Alpha Loss                 -0.267651
exploration/num steps total     39800
exploration/num paths total       398
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.220707
exploration/Rewards Std             0.574031
exploration/Rewards Max            -0.0132676
exploration/Rewards Min            -5.56887
exploration/Returns Mean          -22.0707
exploration/Returns Std             6.87908
exploration/Returns Max           -15.1916
exploration/Returns Min           -28.9498
exploration/Actions Mean            0.0177178
exploration/Actions Std             0.215901
exploration/Actions Max             0.996889
exploration/Actions Min            -0.919956
exploration/Num Paths               2
exploration/Average Returns       -22.0707
evaluation/num steps total     198000
evaluation/num paths total       1980
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.224471
evaluation/Rewards Std              0.950749
evaluation/Rewards Max             -0.00939224
evaluation/Rewards Min             -9.9972
evaluation/Returns Mean           -22.4471
evaluation/Returns Std             17.8807
evaluation/Returns Max             -5.4301
evaluation/Returns Min            -57.985
evaluation/Actions Mean             0.0255094
evaluation/Actions Std              0.178945
evaluation/Actions Max              0.997032
evaluation/Actions Min             -0.995391
evaluation/Num Paths               10
evaluation/Average Returns        -22.4471
time/data storing (s)               0.0012408
time/evaluation sampling (s)        0.229527
time/exploration sampling (s)       0.0720922
time/logging (s)                    0.00355743
time/saving (s)                     0.00194046
time/training (s)                   0.75795
time/epoch (s)                      1.06631
time/total (s)                    215.569
Epoch                             197
-----------------------------  ---------------
2019-04-21 00:47:49.396195 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 198 finished
-----------------------------  ---------------
replay_buffer/size              40000
trainer/QF1 Loss                    0.0360985
trainer/QF2 Loss                    0.0362381
trainer/Policy Loss                11.4197
trainer/Q1 Predictions Mean        -9.53823
trainer/Q1 Predictions Std          6.87728
trainer/Q1 Predictions Max         -7.62213
trainer/Q1 Predictions Min        -50.8878
trainer/Q2 Predictions Mean        -9.57124
trainer/Q2 Predictions Std          6.87456
trainer/Q2 Predictions Max         -7.66186
trainer/Q2 Predictions Min        -51.4567
trainer/Q Targets Mean             -9.55162
trainer/Q Targets Std               6.97104
trainer/Q Targets Max              -7.53543
trainer/Q Targets Min             -51.8392
trainer/Log Pis Mean                2.23351
trainer/Log Pis Std                 1.15563
trainer/Log Pis Max                 7.6585
trainer/Log Pis Min                -0.414594
trainer/Policy mu Mean              0.0490343
trainer/Policy mu Std               0.643271
trainer/Policy mu Max               2.97404
trainer/Policy mu Min              -2.91076
trainer/Policy log std Mean        -2.20051
trainer/Policy log std Std          0.392753
trainer/Policy log std Max         -0.536979
trainer/Policy log std Min         -2.50291
trainer/Alpha                       0.0521837
trainer/Alpha Loss                  0.689566
exploration/num steps total     40000
exploration/num paths total       400
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.282021
exploration/Rewards Std             0.718802
exploration/Rewards Max            -0.00443978
exploration/Rewards Min            -5.83674
exploration/Returns Mean          -28.2021
exploration/Returns Std             0.734721
exploration/Returns Max           -27.4674
exploration/Returns Min           -28.9368
exploration/Actions Mean            0.0287954
exploration/Actions Std             0.242897
exploration/Actions Max             0.99693
exploration/Actions Min            -0.981115
exploration/Num Paths               2
exploration/Average Returns       -28.2021
evaluation/num steps total     199000
evaluation/num paths total       1990
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.21292
evaluation/Rewards Std              0.693191
evaluation/Rewards Max             -0.0343995
evaluation/Rewards Min             -6.59402
evaluation/Returns Mean           -21.292
evaluation/Returns Std              7.44899
evaluation/Returns Max             -9.17502
evaluation/Returns Min            -33.6329
evaluation/Actions Mean             0.0230725
evaluation/Actions Std              0.174993
evaluation/Actions Max              0.995345
evaluation/Actions Min             -0.992192
evaluation/Num Paths               10
evaluation/Average Returns        -21.292
time/data storing (s)               0.00123006
time/evaluation sampling (s)        0.228191
time/exploration sampling (s)       0.0672234
time/logging (s)                    0.00333734
time/saving (s)                     0.00181859
time/training (s)                   0.770154
time/epoch (s)                      1.07195
time/total (s)                    216.645
Epoch                             198
-----------------------------  ---------------
2019-04-21 00:47:50.490006 PDT | [sac-pointmass-multitask-1_2019_04_21_00_44_12_0000--s-0] Epoch 199 finished
-----------------------------  ---------------
replay_buffer/size              40200
trainer/QF1 Loss                    0.602134
trainer/QF2 Loss                    0.616454
trainer/Policy Loss                10.812
trainer/Q1 Predictions Mean        -9.38367
trainer/Q1 Predictions Std          6.63729
trainer/Q1 Predictions Max         -7.52428
trainer/Q1 Predictions Min        -51.4717
trainer/Q2 Predictions Mean        -9.35547
trainer/Q2 Predictions Std          6.65455
trainer/Q2 Predictions Max         -7.47859
trainer/Q2 Predictions Min        -51.8424
trainer/Q Targets Mean             -9.41624
trainer/Q Targets Std               6.73999
trainer/Q Targets Max              -0.039143
trainer/Q Targets Min             -52.1313
trainer/Log Pis Mean                1.83777
trainer/Log Pis Std                 1.49943
trainer/Log Pis Max                 6.13578
trainer/Log Pis Min                -6.06253
trainer/Policy mu Mean              0.0553259
trainer/Policy mu Std               0.712666
trainer/Policy mu Max               3.09993
trainer/Policy mu Min              -2.19675
trainer/Policy log std Mean        -2.06711
trainer/Policy log std Std          0.482274
trainer/Policy log std Max         -0.534244
trainer/Policy log std Min         -2.4908
trainer/Alpha                       0.0527037
trainer/Alpha Loss                 -0.477418
exploration/num steps total     40200
exploration/num paths total       402
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.356146
exploration/Rewards Std             1.14341
exploration/Rewards Max            -0.0109533
exploration/Rewards Min            -9.21129
exploration/Returns Mean          -35.6146
exploration/Returns Std            20.7621
exploration/Returns Max           -14.8524
exploration/Returns Min           -56.3767
exploration/Actions Mean            0.0443858
exploration/Actions Std             0.23224
exploration/Actions Max             0.999389
exploration/Actions Min            -0.454631
exploration/Num Paths               2
exploration/Average Returns       -35.6146
evaluation/num steps total     200000
evaluation/num paths total       2000
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.199789
evaluation/Rewards Std              0.812104
evaluation/Rewards Max             -0.00922235
evaluation/Rewards Min             -7.83175
evaluation/Returns Mean           -19.9789
evaluation/Returns Std              8.28169
evaluation/Returns Max             -8.84026
evaluation/Returns Min            -38.3845
evaluation/Actions Mean             0.0242978
evaluation/Actions Std              0.186325
evaluation/Actions Max              0.994684
evaluation/Actions Min             -0.990813
evaluation/Num Paths               10
evaluation/Average Returns        -19.9789
time/data storing (s)               0.00141684
time/evaluation sampling (s)        0.225709
time/exploration sampling (s)       0.0764809
time/logging (s)                    0.00339872
time/saving (s)                     0.00203381
time/training (s)                   0.777174
time/epoch (s)                      1.08621
time/total (s)                    217.735
Epoch                             199
-----------------------------  ---------------
