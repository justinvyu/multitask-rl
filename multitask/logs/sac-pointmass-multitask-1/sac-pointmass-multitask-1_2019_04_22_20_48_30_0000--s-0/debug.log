2019-04-22 20:48:32.317922 PDT | [sac-pointmass-multitask-1_2019_04_22_20_48_30_0000--s-0] Epoch 0 finished
-----------------------------  --------------
replay_buffer/size              400
trainer/QF1 Loss                  0.999533
trainer/QF2 Loss                  1.01098
trainer/Policy Loss              -1.26681
trainer/Q1 Predictions Mean      -0.00391879
trainer/Q1 Predictions Std        0.000411596
trainer/Q1 Predictions Max       -0.00293534
trainer/Q1 Predictions Min       -0.00482476
trainer/Q2 Predictions Mean       0.00179202
trainer/Q2 Predictions Std        0.000587926
trainer/Q2 Predictions Max        0.00295813
trainer/Q2 Predictions Min        0.000612978
trainer/Q Targets Mean           -1.00368
trainer/Q Targets Std             0.000723182
trainer/Q Targets Max            -1
trainer/Q Targets Min            -1.00558
trainer/Log Pis Mean             -1.27074
trainer/Log Pis Std               0.328777
trainer/Log Pis Max              -0.534792
trainer/Log Pis Min              -1.81768
trainer/Policy mu Mean            2.81263e-05
trainer/Policy mu Std             0.000364359
trainer/Policy mu Max             0.000728442
trainer/Policy mu Min            -0.000653312
trainer/Policy log std Mean       0.000230439
trainer/Policy log std Std        0.00073553
trainer/Policy log std Max        0.00151748
trainer/Policy log std Min       -0.000695539
trainer/Alpha                     0.9997
trainer/Alpha Loss               -0
exploration/num steps total     400
exploration/num paths total       4
exploration/path length Mean    100
exploration/path length Std       0
exploration/path length Max     100
exploration/path length Min     100
exploration/Rewards Mean         -1
exploration/Rewards Std           0
exploration/Rewards Max          -1
exploration/Rewards Min          -1
exploration/Returns Mean       -100
exploration/Returns Std           0
exploration/Returns Max        -100
exploration/Returns Min        -100
exploration/Actions Mean          0.0380239
exploration/Actions Std           0.628516
exploration/Actions Max           0.995675
exploration/Actions Min          -0.997945
exploration/Num Paths             2
exploration/Average Returns    -100
evaluation/num steps total     1000
evaluation/num paths total       10
evaluation/path length Mean     100
evaluation/path length Std        0
evaluation/path length Max      100
evaluation/path length Min      100
evaluation/Rewards Mean          -0.96801
evaluation/Rewards Std            0.0961209
evaluation/Rewards Max           -0.651028
evaluation/Rewards Min           -1
evaluation/Returns Mean         -96.801
evaluation/Returns Std            9.59701
evaluation/Returns Max          -68.01
evaluation/Returns Min         -100
evaluation/Actions Mean           5.59438e-05
evaluation/Actions Std            0.000420046
evaluation/Actions Max            0.000765235
evaluation/Actions Min           -0.000620306
evaluation/Num Paths             10
evaluation/Average Returns      -96.801
time/data storing (s)             0.00115222
time/evaluation sampling (s)      0.234765
time/exploration sampling (s)     0.0650056
time/logging (s)                  0.00360213
time/saving (s)                   0.00285959
time/training (s)                 1.03939
time/epoch (s)                    1.34678
time/total (s)                    1.71209
Epoch                             0
-----------------------------  --------------
2019-04-22 20:48:33.591756 PDT | [sac-pointmass-multitask-1_2019_04_22_20_48_30_0000--s-0] Epoch 1 finished
-----------------------------  -------------
replay_buffer/size              600
trainer/QF1 Loss                  0.00841045
trainer/QF2 Loss                  0.00893207
trainer/Policy Loss              -0.10569
trainer/Q1 Predictions Mean      -1.2629
trainer/Q1 Predictions Std        0.106977
trainer/Q1 Predictions Max       -1.07545
trainer/Q1 Predictions Min       -1.50176
trainer/Q2 Predictions Mean      -1.25839
trainer/Q2 Predictions Std        0.109112
trainer/Q2 Predictions Max       -1.05896
trainer/Q2 Predictions Min       -1.48446
trainer/Q Targets Mean           -1.26909
trainer/Q Targets Std             0.0177127
trainer/Q Targets Max            -1.23872
trainer/Q Targets Min            -1.31047
trainer/Log Pis Mean             -1.37225
trainer/Log Pis Std               0.155195
trainer/Log Pis Max              -1.10173
trainer/Log Pis Min              -2.35217
trainer/Policy mu Mean           -0.0117169
trainer/Policy mu Std             0.00586942
trainer/Policy mu Max             0.00342583
trainer/Policy mu Min            -0.0247871
trainer/Policy log std Mean      -0.14533
trainer/Policy log std Std        0.01031
trainer/Policy log std Max       -0.126133
trainer/Policy log std Min       -0.17069
trainer/Alpha                     0.941407
trainer/Alpha Loss               -0.202604
exploration/num steps total     600
exploration/num paths total       6
exploration/path length Mean    100
exploration/path length Std       0
exploration/path length Max     100
exploration/path length Min     100
exploration/Rewards Mean         -1
exploration/Rewards Std           0
exploration/Rewards Max          -1
exploration/Rewards Min          -1
exploration/Returns Mean       -100
exploration/Returns Std           0
exploration/Returns Max        -100
exploration/Returns Min        -100
exploration/Actions Mean         -0.0417466
exploration/Actions Std           0.574642
exploration/Actions Max           0.967103
exploration/Actions Min          -0.988973
exploration/Num Paths             2
exploration/Average Returns    -100
evaluation/num steps total     2000
evaluation/num paths total       20
evaluation/path length Mean     100
evaluation/path length Std        0
evaluation/path length Max      100
evaluation/path length Min      100
evaluation/Rewards Mean          -1
evaluation/Rewards Std            0
evaluation/Rewards Max           -1
evaluation/Rewards Min           -1
evaluation/Returns Mean        -100
evaluation/Returns Std            0
evaluation/Returns Max         -100
evaluation/Returns Min         -100
evaluation/Actions Mean          -0.00772579
evaluation/Actions Std            0.00550168
evaluation/Actions Max            0.00361734
evaluation/Actions Min           -0.0236122
evaluation/Num Paths             10
evaluation/Average Returns     -100
time/data storing (s)             0.00132433
time/evaluation sampling (s)      0.228132
time/exploration sampling (s)     0.0712551
time/logging (s)                  0.00334042
time/saving (s)                   0.00231387
time/training (s)                 0.961905
time/epoch (s)                    1.26827
time/total (s)                    2.98487
Epoch                             1
-----------------------------  -------------
2019-04-22 20:48:34.883180 PDT | [sac-pointmass-multitask-1_2019_04_22_20_48_30_0000--s-0] Epoch 2 finished
-----------------------------  -------------
replay_buffer/size              800
trainer/QF1 Loss                  0.0263036
trainer/QF2 Loss                  0.0242205
trainer/Policy Loss               0.525726
trainer/Q1 Predictions Mean      -1.88559
trainer/Q1 Predictions Std        0.0521871
trainer/Q1 Predictions Max       -1.78336
trainer/Q1 Predictions Min       -2.06793
trainer/Q2 Predictions Mean      -1.88077
trainer/Q2 Predictions Std        0.0475962
trainer/Q2 Predictions Max       -1.81269
trainer/Q2 Predictions Min       -2.07935
trainer/Q Targets Mean           -1.85101
trainer/Q Targets Std             0.151232
trainer/Q Targets Max            -1
trainer/Q Targets Min            -2.02122
trainer/Log Pis Mean             -1.36448
trainer/Log Pis Std               0.19925
trainer/Log Pis Max              -1.00852
trainer/Log Pis Min              -2.65756
trainer/Policy mu Mean            0.00521789
trainer/Policy mu Std             0.0116212
trainer/Policy mu Max             0.0207994
trainer/Policy mu Min            -0.0112612
trainer/Policy log std Mean      -0.123211
trainer/Policy log std Std        0.0145291
trainer/Policy log std Max       -0.103685
trainer/Policy log std Min       -0.16258
trainer/Alpha                     0.886545
trainer/Alpha Loss               -0.404152
exploration/num steps total     800
exploration/num paths total       8
exploration/path length Mean    100
exploration/path length Std       0
exploration/path length Max     100
exploration/path length Min     100
exploration/Rewards Mean         -0.942826
exploration/Rewards Std           0.15595
exploration/Rewards Max          -0.168469
exploration/Rewards Min          -1
exploration/Returns Mean        -94.2826
exploration/Returns Std           3.10458
exploration/Returns Max         -91.178
exploration/Returns Min         -97.3872
exploration/Actions Mean         -0.0159814
exploration/Actions Std           0.590632
exploration/Actions Max           0.994767
exploration/Actions Min          -0.994172
exploration/Num Paths             2
exploration/Average Returns     -94.2826
evaluation/num steps total     3000
evaluation/num paths total       30
evaluation/path length Mean     100
evaluation/path length Std        0
evaluation/path length Max      100
evaluation/path length Min      100
evaluation/Rewards Mean          -0.999468
evaluation/Rewards Std            0.00600987
evaluation/Rewards Max           -0.902325
evaluation/Rewards Min           -1
evaluation/Returns Mean         -99.9468
evaluation/Returns Std            0.159727
evaluation/Returns Max          -99.4676
evaluation/Returns Min         -100
evaluation/Actions Mean           0.00556689
evaluation/Actions Std            0.00991943
evaluation/Actions Max            0.0218881
evaluation/Actions Min           -0.0115723
evaluation/Num Paths             10
evaluation/Average Returns      -99.9468
time/data storing (s)             0.00119632
time/evaluation sampling (s)      0.240344
time/exploration sampling (s)     0.0697719
time/logging (s)                  0.00335462
time/saving (s)                   0.00238904
time/training (s)                 0.969637
time/epoch (s)                    1.28669
time/total (s)                    4.27558
Epoch                             2
-----------------------------  -------------
2019-04-22 20:48:36.201450 PDT | [sac-pointmass-multitask-1_2019_04_22_20_48_30_0000--s-0] Epoch 3 finished
-----------------------------  -------------
replay_buffer/size             1000
trainer/QF1 Loss                  0.0333805
trainer/QF2 Loss                  0.0334852
trainer/Policy Loss               1.21762
trainer/Q1 Predictions Mean      -2.57408
trainer/Q1 Predictions Std        0.0667365
trainer/Q1 Predictions Max       -2.47431
trainer/Q1 Predictions Min       -2.90053
trainer/Q2 Predictions Mean      -2.57294
trainer/Q2 Predictions Std        0.0728789
trainer/Q2 Predictions Max       -2.44956
trainer/Q2 Predictions Min       -2.89342
trainer/Q Targets Mean           -2.57162
trainer/Q Targets Std             0.190215
trainer/Q Targets Max            -1
trainer/Q Targets Min            -2.80569
trainer/Log Pis Mean             -1.36659
trainer/Log Pis Std               0.145548
trainer/Log Pis Max              -1.01954
trainer/Log Pis Min              -1.62654
trainer/Policy mu Mean           -0.00776222
trainer/Policy mu Std             0.00942614
trainer/Policy mu Max             0.00397154
trainer/Policy mu Min            -0.0220378
trainer/Policy log std Mean      -0.120066
trainer/Policy log std Std        0.00556849
trainer/Policy log std Max       -0.110416
trainer/Policy log std Min       -0.133924
trainer/Alpha                     0.834911
trainer/Alpha Loss               -0.606423
exploration/num steps total    1000
exploration/num paths total      10
exploration/path length Mean    100
exploration/path length Std       0
exploration/path length Max     100
exploration/path length Min     100
exploration/Rewards Mean         -0.992245
exploration/Rewards Std           0.0483953
exploration/Rewards Max          -0.533829
exploration/Rewards Min          -1
exploration/Returns Mean        -99.2245
exploration/Returns Std           0.423237
exploration/Returns Max         -98.8013
exploration/Returns Min         -99.6477
exploration/Actions Mean         -0.0302272
exploration/Actions Std           0.605845
exploration/Actions Max           0.984497
exploration/Actions Min          -0.992772
exploration/Num Paths             2
exploration/Average Returns     -99.2245
evaluation/num steps total     4000
evaluation/num paths total       40
evaluation/path length Mean     100
evaluation/path length Std        0
evaluation/path length Max      100
evaluation/path length Min      100
evaluation/Rewards Mean          -1
evaluation/Rewards Std            0
evaluation/Rewards Max           -1
evaluation/Rewards Min           -1
evaluation/Returns Mean        -100
evaluation/Returns Std            0
evaluation/Returns Max         -100
evaluation/Returns Min         -100
evaluation/Actions Mean          -0.00737592
evaluation/Actions Std            0.00997319
evaluation/Actions Max            0.00409553
evaluation/Actions Min           -0.021255
evaluation/Num Paths             10
evaluation/Average Returns     -100
time/data storing (s)             0.00133003
time/evaluation sampling (s)      0.247316
time/exploration sampling (s)     0.0698486
time/logging (s)                  0.00349309
time/saving (s)                   0.00234976
time/training (s)                 0.989245
time/epoch (s)                    1.31358
time/total (s)                    5.59326
Epoch                             3
-----------------------------  -------------
2019-04-22 20:48:37.517570 PDT | [sac-pointmass-multitask-1_2019_04_22_20_48_30_0000--s-0] Epoch 4 finished
-----------------------------  -------------
replay_buffer/size             1200
trainer/QF1 Loss                  0.0570642
trainer/QF2 Loss                  0.0579254
trainer/Policy Loss               2.08605
trainer/Q1 Predictions Mean      -3.43099
trainer/Q1 Predictions Std        0.0909985
trainer/Q1 Predictions Max       -3.21896
trainer/Q1 Predictions Min       -3.71685
trainer/Q2 Predictions Mean      -3.43707
trainer/Q2 Predictions Std        0.0964166
trainer/Q2 Predictions Max       -3.20879
trainer/Q2 Predictions Min       -3.6828
trainer/Q Targets Mean           -3.37335
trainer/Q Targets Std             0.254801
trainer/Q Targets Max            -1
trainer/Q Targets Min            -3.59858
trainer/Log Pis Mean             -1.36056
trainer/Log Pis Std               0.134889
trainer/Log Pis Max              -1.07142
trainer/Log Pis Min              -1.83184
trainer/Policy mu Mean           -0.0134353
trainer/Policy mu Std             0.00344657
trainer/Policy mu Max            -0.00735038
trainer/Policy mu Min            -0.0203513
trainer/Policy log std Mean      -0.132601
trainer/Policy log std Std        0.00806347
trainer/Policy log std Max       -0.118073
trainer/Policy log std Min       -0.150556
trainer/Alpha                     0.786285
trainer/Alpha Loss               -0.806991
exploration/num steps total    1200
exploration/num paths total      12
exploration/path length Mean    100
exploration/path length Std       0
exploration/path length Max     100
exploration/path length Min     100
exploration/Rewards Mean         -1
exploration/Rewards Std           0
exploration/Rewards Max          -1
exploration/Rewards Min          -1
exploration/Returns Mean       -100
exploration/Returns Std           0
exploration/Returns Max        -100
exploration/Returns Min        -100
exploration/Actions Mean         -0.00736667
exploration/Actions Std           0.570648
exploration/Actions Max           0.983611
exploration/Actions Min          -0.976601
exploration/Num Paths             2
exploration/Average Returns    -100
evaluation/num steps total     5000
evaluation/num paths total       50
evaluation/path length Mean     100
evaluation/path length Std        0
evaluation/path length Max      100
evaluation/path length Min      100
evaluation/Rewards Mean          -0.971978
evaluation/Rewards Std            0.12982
evaluation/Rewards Max           -0.142312
evaluation/Rewards Min           -1
evaluation/Returns Mean         -97.1978
evaluation/Returns Std            8.40658
evaluation/Returns Max          -71.9781
evaluation/Returns Min         -100
evaluation/Actions Mean          -0.0134461
evaluation/Actions Std            0.00330614
evaluation/Actions Max           -0.00816535
evaluation/Actions Min           -0.0195757
evaluation/Num Paths             10
evaluation/Average Returns      -97.1978
time/data storing (s)             0.00120459
time/evaluation sampling (s)      0.239379
time/exploration sampling (s)     0.0694796
time/logging (s)                  0.00324563
time/saving (s)                   0.00231478
time/training (s)                 0.995206
time/epoch (s)                    1.31083
time/total (s)                    6.90825
Epoch                             4
-----------------------------  -------------
2019-04-22 20:48:38.843302 PDT | [sac-pointmass-multitask-1_2019_04_22_20_48_30_0000--s-0] Epoch 5 finished
-----------------------------  --------------
replay_buffer/size             1400
trainer/QF1 Loss                  0.0107442
trainer/QF2 Loss                  0.0100341
trainer/Policy Loss               2.8687
trainer/Q1 Predictions Mean      -4.22067
trainer/Q1 Predictions Std        0.104495
trainer/Q1 Predictions Max       -3.97316
trainer/Q1 Predictions Min       -4.44489
trainer/Q2 Predictions Mean      -4.21115
trainer/Q2 Predictions Std        0.11363
trainer/Q2 Predictions Max       -3.92969
trainer/Q2 Predictions Min       -4.431
trainer/Q Targets Mean           -4.19016
trainer/Q Targets Std             0.14548
trainer/Q Targets Max            -3.61263
trainer/Q Targets Min            -4.41036
trainer/Log Pis Mean             -1.36682
trainer/Log Pis Std               0.174994
trainer/Log Pis Max              -1.0645
trainer/Log Pis Min              -2.4192
trainer/Policy mu Mean           -0.0138283
trainer/Policy mu Std             0.00868568
trainer/Policy mu Max            -0.000290642
trainer/Policy mu Min            -0.0341895
trainer/Policy log std Mean      -0.137142
trainer/Policy log std Std        0.00497917
trainer/Policy log std Max       -0.130174
trainer/Policy log std Min       -0.152331
trainer/Alpha                     0.740487
trainer/Alpha Loss               -1.01054
exploration/num steps total    1400
exploration/num paths total      14
exploration/path length Mean    100
exploration/path length Std       0
exploration/path length Max     100
exploration/path length Min     100
exploration/Rewards Mean         -0.928763
exploration/Rewards Std           0.180159
exploration/Rewards Max          -0.196142
exploration/Rewards Min          -1
exploration/Returns Mean        -92.8763
exploration/Returns Std           7.12368
exploration/Returns Max         -85.7526
exploration/Returns Min        -100
exploration/Actions Mean         -0.00294767
exploration/Actions Std           0.570865
exploration/Actions Max           0.985534
exploration/Actions Min          -0.97809
exploration/Num Paths             2
exploration/Average Returns     -92.8763
evaluation/num steps total     6000
evaluation/num paths total       60
evaluation/path length Mean     100
evaluation/path length Std        0
evaluation/path length Max      100
evaluation/path length Min      100
evaluation/Rewards Mean          -1
evaluation/Rewards Std            0
evaluation/Rewards Max           -1
evaluation/Rewards Min           -1
evaluation/Returns Mean        -100
evaluation/Returns Std            0
evaluation/Returns Max         -100
evaluation/Returns Min         -100
evaluation/Actions Mean          -0.0123693
evaluation/Actions Std            0.00678888
evaluation/Actions Max           -0.00354455
evaluation/Actions Min           -0.0322935
evaluation/Num Paths             10
evaluation/Average Returns     -100
time/data storing (s)             0.00125665
time/evaluation sampling (s)      0.238402
time/exploration sampling (s)     0.0704764
time/logging (s)                  0.00347944
time/saving (s)                   0.0024334
time/training (s)                 1.00531
time/epoch (s)                    1.32136
time/total (s)                    8.23366
Epoch                             5
-----------------------------  --------------
2019-04-22 20:48:40.161191 PDT | [sac-pointmass-multitask-1_2019_04_22_20_48_30_0000--s-0] Epoch 6 finished
-----------------------------  -------------
replay_buffer/size             1600
trainer/QF1 Loss                  0.182608
trainer/QF2 Loss                  0.190099
trainer/Policy Loss               3.63075
trainer/Q1 Predictions Mean      -5.00117
trainer/Q1 Predictions Std        0.184719
trainer/Q1 Predictions Max       -4.39141
trainer/Q1 Predictions Min       -5.29895
trainer/Q2 Predictions Mean      -5.00464
trainer/Q2 Predictions Std        0.20127
trainer/Q2 Predictions Max       -4.34337
trainer/Q2 Predictions Min       -5.31261
trainer/Q Targets Mean           -4.96845
trainer/Q Targets Std             0.421472
trainer/Q Targets Max            -1
trainer/Q Targets Min            -5.25527
trainer/Log Pis Mean             -1.39082
trainer/Log Pis Std               0.212135
trainer/Log Pis Max              -1.11322
trainer/Log Pis Min              -3.15693
trainer/Policy mu Mean           -0.00600921
trainer/Policy mu Std             0.0158875
trainer/Policy mu Max             0.0296793
trainer/Policy mu Min            -0.0260305
trainer/Policy log std Mean      -0.138011
trainer/Policy log std Std        0.00457344
trainer/Policy log std Max       -0.129362
trainer/Policy log std Min       -0.151637
trainer/Alpha                     0.697361
trainer/Alpha Loss               -1.22121
exploration/num steps total    1600
exploration/num paths total      16
exploration/path length Mean    100
exploration/path length Std       0
exploration/path length Max     100
exploration/path length Min     100
exploration/Rewards Mean         -1
exploration/Rewards Std           0
exploration/Rewards Max          -1
exploration/Rewards Min          -1
exploration/Returns Mean       -100
exploration/Returns Std           0
exploration/Returns Max        -100
exploration/Returns Min        -100
exploration/Actions Mean          0.0523642
exploration/Actions Std           0.580383
exploration/Actions Max           0.973961
exploration/Actions Min          -0.992586
exploration/Num Paths             2
exploration/Average Returns    -100
evaluation/num steps total     7000
evaluation/num paths total       70
evaluation/path length Mean     100
evaluation/path length Std        0
evaluation/path length Max      100
evaluation/path length Min      100
evaluation/Rewards Mean          -1
evaluation/Rewards Std            0
evaluation/Rewards Max           -1
evaluation/Rewards Min           -1
evaluation/Returns Mean        -100
evaluation/Returns Std            0
evaluation/Returns Max         -100
evaluation/Returns Min         -100
evaluation/Actions Mean          -0.00757628
evaluation/Actions Std            0.0147919
evaluation/Actions Max            0.0271999
evaluation/Actions Min           -0.0244759
evaluation/Num Paths             10
evaluation/Average Returns     -100
time/data storing (s)             0.00118695
time/evaluation sampling (s)      0.240948
time/exploration sampling (s)     0.0704473
time/logging (s)                  0.003388
time/saving (s)                   0.00230842
time/training (s)                 0.994529
time/epoch (s)                    1.31281
time/total (s)                    9.55071
Epoch                             6
-----------------------------  -------------
2019-04-22 20:48:41.487699 PDT | [sac-pointmass-multitask-1_2019_04_22_20_48_30_0000--s-0] Epoch 7 finished
-----------------------------  -------------
replay_buffer/size             1800
trainer/QF1 Loss                  0.198782
trainer/QF2 Loss                  0.198381
trainer/Policy Loss               4.47227
trainer/Q1 Predictions Mean      -5.81617
trainer/Q1 Predictions Std        0.198053
trainer/Q1 Predictions Max       -5.30051
trainer/Q1 Predictions Min       -6.31798
trainer/Q2 Predictions Mean      -5.82291
trainer/Q2 Predictions Std        0.207964
trainer/Q2 Predictions Max       -5.29136
trainer/Q2 Predictions Min       -6.29915
trainer/Q Targets Mean           -5.78787
trainer/Q Targets Std             0.518952
trainer/Q Targets Max            -1
trainer/Q Targets Min            -6.40963
trainer/Log Pis Mean             -1.36227
trainer/Log Pis Std               0.132166
trainer/Log Pis Max              -1.09209
trainer/Log Pis Min              -1.85423
trainer/Policy mu Mean            0.00798175
trainer/Policy mu Std             0.0224624
trainer/Policy mu Max             0.0468965
trainer/Policy mu Min            -0.0459658
trainer/Policy log std Mean      -0.148259
trainer/Policy log std Std        0.0103434
trainer/Policy log std Max       -0.132264
trainer/Policy log std Min       -0.185125
trainer/Alpha                     0.656758
trainer/Alpha Loss               -1.41262
exploration/num steps total    1800
exploration/num paths total      18
exploration/path length Mean    100
exploration/path length Std       0
exploration/path length Max     100
exploration/path length Min     100
exploration/Rewards Mean         -1
exploration/Rewards Std           0
exploration/Rewards Max          -1
exploration/Rewards Min          -1
exploration/Returns Mean       -100
exploration/Returns Std           0
exploration/Returns Max        -100
exploration/Returns Min        -100
exploration/Actions Mean          0.027322
exploration/Actions Std           0.603724
exploration/Actions Max           0.978582
exploration/Actions Min          -0.988134
exploration/Num Paths             2
exploration/Average Returns    -100
evaluation/num steps total     8000
evaluation/num paths total       80
evaluation/path length Mean     100
evaluation/path length Std        0
evaluation/path length Max      100
evaluation/path length Min      100
evaluation/Rewards Mean          -0.965011
evaluation/Rewards Std            0.122008
evaluation/Rewards Max           -0.300129
evaluation/Rewards Min           -1
evaluation/Returns Mean         -96.5011
evaluation/Returns Std            7.65116
evaluation/Returns Max          -75.5878
evaluation/Returns Min         -100
evaluation/Actions Mean           0.00476112
evaluation/Actions Std            0.0233279
evaluation/Actions Max            0.0383172
evaluation/Actions Min           -0.0328128
evaluation/Num Paths             10
evaluation/Average Returns      -96.5011
time/data storing (s)             0.0012246
time/evaluation sampling (s)      0.242342
time/exploration sampling (s)     0.0702241
time/logging (s)                  0.00346532
time/saving (s)                   0.0028353
time/training (s)                 1.00154
time/epoch (s)                    1.32163
time/total (s)                   10.8764
Epoch                             7
-----------------------------  -------------
2019-04-22 20:48:42.837728 PDT | [sac-pointmass-multitask-1_2019_04_22_20_48_30_0000--s-0] Epoch 8 finished
-----------------------------  -------------
replay_buffer/size             2000
trainer/QF1 Loss                  0.364916
trainer/QF2 Loss                  0.363856
trainer/Policy Loss               5.09975
trainer/Q1 Predictions Mean      -6.48156
trainer/Q1 Predictions Std        0.234426
trainer/Q1 Predictions Max       -5.90435
trainer/Q1 Predictions Min       -6.86621
trainer/Q2 Predictions Mean      -6.48304
trainer/Q2 Predictions Std        0.230472
trainer/Q2 Predictions Max       -5.90146
trainer/Q2 Predictions Min       -6.86507
trainer/Q Targets Mean           -6.54555
trainer/Q Targets Std             0.620396
trainer/Q Targets Max            -1
trainer/Q Targets Min            -6.99051
trainer/Log Pis Mean             -1.38916
trainer/Log Pis Std               0.155002
trainer/Log Pis Max              -1.10595
trainer/Log Pis Min              -2.4036
trainer/Policy mu Mean           -0.0257456
trainer/Policy mu Std             0.0404804
trainer/Policy mu Max             0.0334052
trainer/Policy mu Min            -0.108113
trainer/Policy log std Mean      -0.159046
trainer/Policy log std Std        0.0206569
trainer/Policy log std Max       -0.122479
trainer/Policy log std Min       -0.212659
trainer/Alpha                     0.618544
trainer/Alpha Loss               -1.62709
exploration/num steps total    2000
exploration/num paths total      20
exploration/path length Mean    100
exploration/path length Std       0
exploration/path length Max     100
exploration/path length Min     100
exploration/Rewards Mean         -0.992815
exploration/Rewards Std           0.0514308
exploration/Rewards Max          -0.526014
exploration/Rewards Min          -1
exploration/Returns Mean        -99.2815
exploration/Returns Std           0.718518
exploration/Returns Max         -98.563
exploration/Returns Min        -100
exploration/Actions Mean         -0.0323632
exploration/Actions Std           0.586893
exploration/Actions Max           0.980965
exploration/Actions Min          -0.986018
exploration/Num Paths             2
exploration/Average Returns     -99.2815
evaluation/num steps total     9000
evaluation/num paths total       90
evaluation/path length Mean     100
evaluation/path length Std        0
evaluation/path length Max      100
evaluation/path length Min      100
evaluation/Rewards Mean          -1
evaluation/Rewards Std            0
evaluation/Rewards Max           -1
evaluation/Rewards Min           -1
evaluation/Returns Mean        -100
evaluation/Returns Std            0
evaluation/Returns Max         -100
evaluation/Returns Min         -100
evaluation/Actions Mean          -0.030471
evaluation/Actions Std            0.0516682
evaluation/Actions Max            0.0301292
evaluation/Actions Min           -0.11048
evaluation/Num Paths             10
evaluation/Average Returns     -100
time/data storing (s)             0.00117955
time/evaluation sampling (s)      0.276498
time/exploration sampling (s)     0.0685988
time/logging (s)                  0.00351409
time/saving (s)                   0.00251027
time/training (s)                 0.992922
time/epoch (s)                    1.34522
time/total (s)                   12.2256
Epoch                             8
-----------------------------  -------------
2019-04-22 20:48:44.158847 PDT | [sac-pointmass-multitask-1_2019_04_22_20_48_30_0000--s-0] Epoch 9 finished
-----------------------------  --------------
replay_buffer/size              2200
trainer/QF1 Loss                   0.438716
trainer/QF2 Loss                   0.441649
trainer/Policy Loss                6.10973
trainer/Q1 Predictions Mean       -7.47403
trainer/Q1 Predictions Std         0.273728
trainer/Q1 Predictions Max        -6.79793
trainer/Q1 Predictions Min        -8.02657
trainer/Q2 Predictions Mean       -7.46968
trainer/Q2 Predictions Std         0.278584
trainer/Q2 Predictions Max        -6.75895
trainer/Q2 Predictions Min        -7.99852
trainer/Q Targets Mean            -7.4238
trainer/Q Targets Std              0.700313
trainer/Q Targets Max             -1
trainer/Q Targets Min             -7.92812
trainer/Log Pis Mean              -1.3618
trainer/Log Pis Std                0.159232
trainer/Log Pis Max               -1.05368
trainer/Log Pis Min               -1.86002
trainer/Policy mu Mean             0.014145
trainer/Policy mu Std              0.0412038
trainer/Policy mu Max              0.0680907
trainer/Policy mu Min             -0.0984375
trainer/Policy log std Mean       -0.143883
trainer/Policy log std Std         0.0122682
trainer/Policy log std Max        -0.124442
trainer/Policy log std Min        -0.184434
trainer/Alpha                      0.582538
trainer/Alpha Loss                -1.81558
exploration/num steps total     2200
exploration/num paths total       22
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1
exploration/Rewards Std            0
exploration/Rewards Max           -1
exploration/Rewards Min           -1
exploration/Returns Mean        -100
exploration/Returns Std            0
exploration/Returns Max         -100
exploration/Returns Min         -100
exploration/Actions Mean           0.00773811
exploration/Actions Std            0.583345
exploration/Actions Max            0.976151
exploration/Actions Min           -0.987313
exploration/Num Paths              2
exploration/Average Returns     -100
evaluation/num steps total     10000
evaluation/num paths total       100
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.98416
evaluation/Rewards Std             0.089177
evaluation/Rewards Max            -0.31449
evaluation/Rewards Min            -1
evaluation/Returns Mean          -98.416
evaluation/Returns Std             4.75192
evaluation/Returns Max           -84.1603
evaluation/Returns Min          -100
evaluation/Actions Mean            0.00713592
evaluation/Actions Std             0.0478707
evaluation/Actions Max             0.0597522
evaluation/Actions Min            -0.0913306
evaluation/Num Paths              10
evaluation/Average Returns       -98.416
time/data storing (s)              0.00119632
time/evaluation sampling (s)       0.245158
time/exploration sampling (s)      0.0720313
time/logging (s)                   0.00304754
time/saving (s)                    0.00190113
time/training (s)                  0.992208
time/epoch (s)                     1.31554
time/total (s)                    13.5454
Epoch                              9
-----------------------------  --------------
2019-04-22 20:48:45.498911 PDT | [sac-pointmass-multitask-1_2019_04_22_20_48_30_0000--s-0] Epoch 10 finished
-----------------------------  --------------
replay_buffer/size              2400
trainer/QF1 Loss                   0.01773
trainer/QF2 Loss                   0.0170273
trainer/Policy Loss                6.88513
trainer/Q1 Predictions Mean       -8.22977
trainer/Q1 Predictions Std         0.281581
trainer/Q1 Predictions Max        -7.67147
trainer/Q1 Predictions Min        -8.75666
trainer/Q2 Predictions Mean       -8.22886
trainer/Q2 Predictions Std         0.285314
trainer/Q2 Predictions Max        -7.66233
trainer/Q2 Predictions Min        -8.78568
trainer/Q Targets Mean            -8.28492
trainer/Q Targets Std              0.278194
trainer/Q Targets Max             -7.52527
trainer/Q Targets Min             -8.70055
trainer/Log Pis Mean              -1.36911
trainer/Log Pis Std                0.188457
trainer/Log Pis Max               -0.937748
trainer/Log Pis Min               -2.45829
trainer/Policy mu Mean            -0.00303653
trainer/Policy mu Std              0.0613574
trainer/Policy mu Max              0.0839433
trainer/Policy mu Min             -0.152732
trainer/Policy log std Mean       -0.176462
trainer/Policy log std Std         0.0166647
trainer/Policy log std Max        -0.141715
trainer/Policy log std Min        -0.218759
trainer/Alpha                      0.548632
trainer/Alpha Loss                -2.02156
exploration/num steps total     2400
exploration/num paths total       24
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.996206
exploration/Rewards Std            0.0323996
exploration/Rewards Max           -0.663277
exploration/Rewards Min           -1
exploration/Returns Mean         -99.6206
exploration/Returns Std            0.379393
exploration/Returns Max          -99.2412
exploration/Returns Min         -100
exploration/Actions Mean           0.00313946
exploration/Actions Std            0.573897
exploration/Actions Max            0.974681
exploration/Actions Min           -0.988031
exploration/Num Paths              2
exploration/Average Returns      -99.6206
evaluation/num steps total     11000
evaluation/num paths total       110
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.99692
evaluation/Rewards Std             0.0236664
evaluation/Rewards Max            -0.756075
evaluation/Rewards Min            -1
evaluation/Returns Mean          -99.692
evaluation/Returns Std             0.875807
evaluation/Returns Max           -97.0679
evaluation/Returns Min          -100
evaluation/Actions Mean           -0.0106815
evaluation/Actions Std             0.06834
evaluation/Actions Max             0.0718029
evaluation/Actions Min            -0.133972
evaluation/Num Paths              10
evaluation/Average Returns       -99.692
time/data storing (s)              0.00120441
time/evaluation sampling (s)       0.258064
time/exploration sampling (s)      0.0694293
time/logging (s)                   0.00307468
time/saving (s)                    0.00247057
time/training (s)                  1.00097
time/epoch (s)                     1.33521
time/total (s)                    14.8846
Epoch                             10
-----------------------------  --------------
2019-04-22 20:48:46.831309 PDT | [sac-pointmass-multitask-1_2019_04_22_20_48_30_0000--s-0] Epoch 11 finished
-----------------------------  --------------
replay_buffer/size              2600
trainer/QF1 Loss                   0.602353
trainer/QF2 Loss                   0.586348
trainer/Policy Loss                7.60565
trainer/Q1 Predictions Mean       -8.92521
trainer/Q1 Predictions Std         0.339687
trainer/Q1 Predictions Max        -8.30003
trainer/Q1 Predictions Min        -9.6283
trainer/Q2 Predictions Mean       -8.92747
trainer/Q2 Predictions Std         0.340739
trainer/Q2 Predictions Max        -8.32749
trainer/Q2 Predictions Min        -9.59791
trainer/Q Targets Mean            -8.91955
trainer/Q Targets Std              0.868497
trainer/Q Targets Max             -1
trainer/Q Targets Min             -9.65563
trainer/Log Pis Mean              -1.32274
trainer/Log Pis Std                0.180242
trainer/Log Pis Max               -0.917057
trainer/Log Pis Min               -1.88716
trainer/Policy mu Mean            -0.0364438
trainer/Policy mu Std              0.0815521
trainer/Policy mu Max              0.118915
trainer/Policy mu Min             -0.214032
trainer/Policy log std Mean       -0.185576
trainer/Policy log std Std         0.0166147
trainer/Policy log std Max        -0.148043
trainer/Policy log std Min        -0.224077
trainer/Alpha                      0.516744
trainer/Alpha Loss                -2.19271
exploration/num steps total     2600
exploration/num paths total       26
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1
exploration/Rewards Std            0
exploration/Rewards Max           -1
exploration/Rewards Min           -1
exploration/Returns Mean        -100
exploration/Returns Std            0
exploration/Returns Max         -100
exploration/Returns Min         -100
exploration/Actions Mean          -0.0397393
exploration/Actions Std            0.563012
exploration/Actions Max            0.96091
exploration/Actions Min           -0.985293
exploration/Num Paths              2
exploration/Average Returns     -100
evaluation/num steps total     12000
evaluation/num paths total       120
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.988074
evaluation/Rewards Std             0.079426
evaluation/Rewards Max            -0.174911
evaluation/Rewards Min            -1
evaluation/Returns Mean          -98.8074
evaluation/Returns Std             2.44362
evaluation/Returns Max           -92.8493
evaluation/Returns Min          -100
evaluation/Actions Mean           -0.0270356
evaluation/Actions Std             0.084856
evaluation/Actions Max             0.109179
evaluation/Actions Min            -0.189761
evaluation/Num Paths              10
evaluation/Average Returns       -98.8074
time/data storing (s)              0.00123093
time/evaluation sampling (s)       0.247377
time/exploration sampling (s)      0.0709254
time/logging (s)                   0.00344932
time/saving (s)                    0.00186609
time/training (s)                  1.00289
time/epoch (s)                     1.32774
time/total (s)                    16.2167
Epoch                             11
-----------------------------  --------------
2019-04-22 20:48:48.160967 PDT | [sac-pointmass-multitask-1_2019_04_22_20_48_30_0000--s-0] Epoch 12 finished
-----------------------------  --------------
replay_buffer/size              2800
trainer/QF1 Loss                   0.0350162
trainer/QF2 Loss                   0.0327476
trainer/Policy Loss                8.38463
trainer/Q1 Predictions Mean       -9.75682
trainer/Q1 Predictions Std         0.386097
trainer/Q1 Predictions Max        -8.92843
trainer/Q1 Predictions Min       -10.4277
trainer/Q2 Predictions Mean       -9.7799
trainer/Q2 Predictions Std         0.399977
trainer/Q2 Predictions Max        -8.948
trainer/Q2 Predictions Min       -10.4661
trainer/Q Targets Mean            -9.84064
trainer/Q Targets Std              0.398389
trainer/Q Targets Max             -8.60355
trainer/Q Targets Min            -10.4207
trainer/Log Pis Mean              -1.38398
trainer/Log Pis Std                0.366466
trainer/Log Pis Max               -0.937939
trainer/Log Pis Min               -3.8025
trainer/Policy mu Mean            -0.0059617
trainer/Policy mu Std              0.0799207
trainer/Policy mu Max              0.126015
trainer/Policy mu Min             -0.224237
trainer/Policy log std Mean       -0.176321
trainer/Policy log std Std         0.0174712
trainer/Policy log std Max        -0.144448
trainer/Policy log std Min        -0.238574
trainer/Alpha                      0.486704
trainer/Alpha Loss                -2.43579
exploration/num steps total     2800
exploration/num paths total       28
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1
exploration/Rewards Std            0
exploration/Rewards Max           -1
exploration/Rewards Min           -1
exploration/Returns Mean        -100
exploration/Returns Std            0
exploration/Returns Max         -100
exploration/Returns Min         -100
exploration/Actions Mean          -0.00405213
exploration/Actions Std            0.565896
exploration/Actions Max            0.975525
exploration/Actions Min           -0.985997
exploration/Num Paths              2
exploration/Average Returns     -100
evaluation/num steps total     13000
evaluation/num paths total       130
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.986876
evaluation/Rewards Std             0.0844912
evaluation/Rewards Max            -0.165043
evaluation/Rewards Min            -1
evaluation/Returns Mean          -98.6876
evaluation/Returns Std             2.65363
evaluation/Returns Max           -92.5652
evaluation/Returns Min          -100
evaluation/Actions Mean           -0.015252
evaluation/Actions Std             0.0834572
evaluation/Actions Max             0.116163
evaluation/Actions Min            -0.22917
evaluation/Num Paths              10
evaluation/Average Returns       -98.6876
time/data storing (s)              0.00120966
time/evaluation sampling (s)       0.246511
time/exploration sampling (s)      0.0707043
time/logging (s)                   0.00346236
time/saving (s)                    0.00225126
time/training (s)                  1.00033
time/epoch (s)                     1.32447
time/total (s)                    17.5455
Epoch                             12
-----------------------------  --------------
2019-04-22 20:48:49.491225 PDT | [sac-pointmass-multitask-1_2019_04_22_20_48_30_0000--s-0] Epoch 13 finished
-----------------------------  ---------------
replay_buffer/size              3000
trainer/QF1 Loss                   0.820724
trainer/QF2 Loss                   0.821176
trainer/Policy Loss                9.14138
trainer/Q1 Predictions Mean      -10.4362
trainer/Q1 Predictions Std         0.453079
trainer/Q1 Predictions Max        -9.55554
trainer/Q1 Predictions Min       -11.2354
trainer/Q2 Predictions Mean      -10.4593
trainer/Q2 Predictions Std         0.45114
trainer/Q2 Predictions Max        -9.59737
trainer/Q2 Predictions Min       -11.2899
trainer/Q Targets Mean           -10.4463
trainer/Q Targets Std              1.02284
trainer/Q Targets Max             -1
trainer/Q Targets Min            -11.2217
trainer/Log Pis Mean              -1.29947
trainer/Log Pis Std                0.196203
trainer/Log Pis Max               -0.759038
trainer/Log Pis Min               -1.95922
trainer/Policy mu Mean            -0.000494068
trainer/Policy mu Std              0.104445
trainer/Policy mu Max              0.171455
trainer/Policy mu Min             -0.203213
trainer/Policy log std Mean       -0.174658
trainer/Policy log std Std         0.0220658
trainer/Policy log std Max        -0.13725
trainer/Policy log std Min        -0.243307
trainer/Alpha                      0.458436
trainer/Alpha Loss                -2.57239
exploration/num steps total     3000
exploration/num paths total       30
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.926032
exploration/Rewards Std            0.181542
exploration/Rewards Max           -0.134858
exploration/Rewards Min           -1
exploration/Returns Mean         -92.6032
exploration/Returns Std            0.5097
exploration/Returns Max          -92.0935
exploration/Returns Min          -93.1129
exploration/Actions Mean           0.0484885
exploration/Actions Std            0.560286
exploration/Actions Max            0.967843
exploration/Actions Min           -0.975097
exploration/Num Paths              2
exploration/Average Returns      -92.6032
evaluation/num steps total     14000
evaluation/num paths total       140
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1
evaluation/Rewards Std             0
evaluation/Rewards Max            -1
evaluation/Rewards Min            -1
evaluation/Returns Mean         -100
evaluation/Returns Std             0
evaluation/Returns Max          -100
evaluation/Returns Min          -100
evaluation/Actions Mean           -0.0117185
evaluation/Actions Std             0.101686
evaluation/Actions Max             0.137076
evaluation/Actions Min            -0.20056
evaluation/Num Paths              10
evaluation/Average Returns      -100
time/data storing (s)              0.00130779
time/evaluation sampling (s)       0.246696
time/exploration sampling (s)      0.0701447
time/logging (s)                   0.00352948
time/saving (s)                    0.00207412
time/training (s)                  1.00157
time/epoch (s)                     1.32533
time/total (s)                    18.875
Epoch                             13
-----------------------------  ---------------
2019-04-22 20:48:50.823213 PDT | [sac-pointmass-multitask-1_2019_04_22_20_48_30_0000--s-0] Epoch 14 finished
-----------------------------  --------------
replay_buffer/size              3200
trainer/QF1 Loss                   0.0894707
trainer/QF2 Loss                   0.0870183
trainer/Policy Loss                9.8382
trainer/Q1 Predictions Mean      -11.123
trainer/Q1 Predictions Std         0.416726
trainer/Q1 Predictions Max       -10.2721
trainer/Q1 Predictions Min       -11.8045
trainer/Q2 Predictions Mean      -11.1369
trainer/Q2 Predictions Std         0.438043
trainer/Q2 Predictions Max       -10.2621
trainer/Q2 Predictions Min       -11.8251
trainer/Q Targets Mean           -11.3421
trainer/Q Targets Std              0.411879
trainer/Q Targets Max            -10.3256
trainer/Q Targets Min            -12.1535
trainer/Log Pis Mean              -1.32331
trainer/Log Pis Std                0.238278
trainer/Log Pis Max               -0.563069
trainer/Log Pis Min               -1.78374
trainer/Policy mu Mean             0.00420598
trainer/Policy mu Std              0.123708
trainer/Policy mu Max              0.197321
trainer/Policy mu Min             -0.3179
trainer/Policy log std Mean       -0.176282
trainer/Policy log std Std         0.025292
trainer/Policy log std Max        -0.136095
trainer/Policy log std Min        -0.248257
trainer/Alpha                      0.43182
trainer/Alpha Loss                -2.78974
exploration/num steps total     3200
exploration/num paths total       32
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.923762
exploration/Rewards Std            0.183067
exploration/Rewards Max           -0.113678
exploration/Rewards Min           -1
exploration/Returns Mean         -92.3762
exploration/Returns Std            7.54213
exploration/Returns Max          -84.8341
exploration/Returns Min          -99.9184
exploration/Actions Mean          -0.00680315
exploration/Actions Std            0.558046
exploration/Actions Max            0.9738
exploration/Actions Min           -0.99498
exploration/Num Paths              2
exploration/Average Returns      -92.3762
evaluation/num steps total     15000
evaluation/num paths total       150
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.997499
evaluation/Rewards Std             0.0141683
evaluation/Rewards Max            -0.880921
evaluation/Rewards Min            -1
evaluation/Returns Mean          -99.7499
evaluation/Returns Std             0.394553
evaluation/Returns Max           -98.914
evaluation/Returns Min          -100
evaluation/Actions Mean           -0.0180404
evaluation/Actions Std             0.133484
evaluation/Actions Max             0.171977
evaluation/Actions Min            -0.233319
evaluation/Num Paths              10
evaluation/Average Returns       -99.7499
time/data storing (s)              0.00130859
time/evaluation sampling (s)       0.251
time/exploration sampling (s)      0.069494
time/logging (s)                   0.00340926
time/saving (s)                    0.00242501
time/training (s)                  0.999022
time/epoch (s)                     1.32666
time/total (s)                    20.2057
Epoch                             14
-----------------------------  --------------
2019-04-22 20:48:52.161046 PDT | [sac-pointmass-multitask-1_2019_04_22_20_48_30_0000--s-0] Epoch 15 finished
-----------------------------  --------------
replay_buffer/size              3400
trainer/QF1 Loss                   1.05444
trainer/QF2 Loss                   1.05306
trainer/Policy Loss               10.5403
trainer/Q1 Predictions Mean      -11.8608
trainer/Q1 Predictions Std         0.499525
trainer/Q1 Predictions Max       -10.8221
trainer/Q1 Predictions Min       -12.9389
trainer/Q2 Predictions Mean      -11.8698
trainer/Q2 Predictions Std         0.498015
trainer/Q2 Predictions Max       -10.8548
trainer/Q2 Predictions Min       -12.8438
trainer/Q Targets Mean           -11.9757
trainer/Q Targets Std              1.19009
trainer/Q Targets Max             -1
trainer/Q Targets Min            -12.8716
trainer/Log Pis Mean              -1.32399
trainer/Log Pis Std                0.260921
trainer/Log Pis Max               -0.713215
trainer/Log Pis Min               -2.57233
trainer/Policy mu Mean             0.00535982
trainer/Policy mu Std              0.146501
trainer/Policy mu Max              0.272837
trainer/Policy mu Min             -0.384767
trainer/Policy log std Mean       -0.210859
trainer/Policy log std Std         0.0315523
trainer/Policy log std Max        -0.156211
trainer/Policy log std Min        -0.312731
trainer/Alpha                      0.406784
trainer/Alpha Loss                -2.98884
exploration/num steps total     3400
exploration/num paths total       34
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.991561
exploration/Rewards Std            0.067853
exploration/Rewards Max           -0.121497
exploration/Rewards Min           -1
exploration/Returns Mean         -99.1561
exploration/Returns Std            0.843874
exploration/Returns Max          -98.3123
exploration/Returns Min         -100
exploration/Actions Mean           0.00212
exploration/Actions Std            0.573874
exploration/Actions Max            0.984214
exploration/Actions Min           -0.982461
exploration/Num Paths              2
exploration/Average Returns      -99.1561
evaluation/num steps total     16000
evaluation/num paths total       160
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.994757
evaluation/Rewards Std             0.0560123
evaluation/Rewards Max            -0.173034
evaluation/Rewards Min            -1
evaluation/Returns Mean          -99.4757
evaluation/Returns Std             1.57293
evaluation/Returns Max           -94.7569
evaluation/Returns Min          -100
evaluation/Actions Mean           -0.0378992
evaluation/Actions Std             0.176239
evaluation/Actions Max             0.240983
evaluation/Actions Min            -0.322709
evaluation/Num Paths              10
evaluation/Average Returns       -99.4757
time/data storing (s)              0.00132552
time/evaluation sampling (s)       0.259863
time/exploration sampling (s)      0.0702309
time/logging (s)                   0.00342729
time/saving (s)                    0.00236087
time/training (s)                  0.996411
time/epoch (s)                     1.33362
time/total (s)                    21.5429
Epoch                             15
-----------------------------  --------------
2019-04-22 20:48:53.515124 PDT | [sac-pointmass-multitask-1_2019_04_22_20_48_30_0000--s-0] Epoch 16 finished
-----------------------------  --------------
replay_buffer/size              3600
trainer/QF1 Loss                   0.0545207
trainer/QF2 Loss                   0.0510416
trainer/Policy Loss               11.41
trainer/Q1 Predictions Mean      -12.7406
trainer/Q1 Predictions Std         0.622887
trainer/Q1 Predictions Max       -11.7787
trainer/Q1 Predictions Min       -13.9285
trainer/Q2 Predictions Mean      -12.7434
trainer/Q2 Predictions Std         0.622943
trainer/Q2 Predictions Max       -11.7273
trainer/Q2 Predictions Min       -13.898
trainer/Q Targets Mean           -12.7216
trainer/Q Targets Std              0.571907
trainer/Q Targets Max            -11.7005
trainer/Q Targets Min            -13.7052
trainer/Log Pis Mean              -1.33581
trainer/Log Pis Std                0.320936
trainer/Log Pis Max               -0.780687
trainer/Log Pis Min               -3.13607
trainer/Policy mu Mean             0.0203526
trainer/Policy mu Std              0.136062
trainer/Policy mu Max              0.2671
trainer/Policy mu Min             -0.406142
trainer/Policy log std Mean       -0.204956
trainer/Policy log std Std         0.0468827
trainer/Policy log std Max        -0.12366
trainer/Policy log std Min        -0.329207
trainer/Alpha                      0.38327
trainer/Alpha Loss                -3.1981
exploration/num steps total     3600
exploration/num paths total       36
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.990027
exploration/Rewards Std            0.0677799
exploration/Rewards Max           -0.358364
exploration/Rewards Min           -1
exploration/Returns Mean         -99.0027
exploration/Returns Std            0.997294
exploration/Returns Max          -98.0054
exploration/Returns Min         -100
exploration/Actions Mean           0.0365682
exploration/Actions Std            0.572183
exploration/Actions Max            0.993617
exploration/Actions Min           -0.972865
exploration/Num Paths              2
exploration/Average Returns      -99.0027
evaluation/num steps total     17000
evaluation/num paths total       170
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.992958
evaluation/Rewards Std             0.0422512
evaluation/Rewards Max            -0.600951
evaluation/Rewards Min            -1
evaluation/Returns Mean          -99.2958
evaluation/Returns Std             1.13573
evaluation/Returns Max           -96.7757
evaluation/Returns Min          -100
evaluation/Actions Mean            0.0333927
evaluation/Actions Std             0.136035
evaluation/Actions Max             0.238911
evaluation/Actions Min            -0.433428
evaluation/Num Paths              10
evaluation/Average Returns       -99.2958
time/data storing (s)              0.00122812
time/evaluation sampling (s)       0.256147
time/exploration sampling (s)      0.0702548
time/logging (s)                   0.00361798
time/saving (s)                    0.00232875
time/training (s)                  1.01569
time/epoch (s)                     1.34927
time/total (s)                    22.8962
Epoch                             16
-----------------------------  --------------
2019-04-22 20:48:54.864583 PDT | [sac-pointmass-multitask-1_2019_04_22_20_48_30_0000--s-0] Epoch 17 finished
-----------------------------  --------------
replay_buffer/size              3800
trainer/QF1 Loss                   0.0786784
trainer/QF2 Loss                   0.0878011
trainer/Policy Loss               11.9402
trainer/Q1 Predictions Mean      -13.2897
trainer/Q1 Predictions Std         0.568404
trainer/Q1 Predictions Max       -12.3492
trainer/Q1 Predictions Min       -14.5604
trainer/Q2 Predictions Mean      -13.2747
trainer/Q2 Predictions Std         0.568928
trainer/Q2 Predictions Max       -12.3584
trainer/Q2 Predictions Min       -14.6337
trainer/Q Targets Mean           -13.4612
trainer/Q Targets Std              0.559958
trainer/Q Targets Max            -12.0949
trainer/Q Targets Min            -14.7238
trainer/Log Pis Mean              -1.36135
trainer/Log Pis Std                0.291932
trainer/Log Pis Max               -0.739711
trainer/Log Pis Min               -2.48958
trainer/Policy mu Mean             0.026885
trainer/Policy mu Std              0.170157
trainer/Policy mu Max              0.316727
trainer/Policy mu Min             -0.484097
trainer/Policy log std Mean       -0.220565
trainer/Policy log std Std         0.0438511
trainer/Policy log std Max        -0.152189
trainer/Policy log std Min        -0.341487
trainer/Alpha                      0.361109
trainer/Alpha Loss                -3.42279
exploration/num steps total     3800
exploration/num paths total       38
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.90906
exploration/Rewards Std            0.200262
exploration/Rewards Max           -0.125888
exploration/Rewards Min           -1
exploration/Returns Mean         -90.906
exploration/Returns Std            9.09402
exploration/Returns Max          -81.812
exploration/Returns Min         -100
exploration/Actions Mean          -0.00903662
exploration/Actions Std            0.56678
exploration/Actions Max            0.959538
exploration/Actions Min           -0.952883
exploration/Num Paths              2
exploration/Average Returns      -90.906
evaluation/num steps total     18000
evaluation/num paths total       180
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.996552
evaluation/Rewards Std             0.0355502
evaluation/Rewards Max            -0.526647
evaluation/Rewards Min            -1
evaluation/Returns Mean          -99.6552
evaluation/Returns Std             1.03442
evaluation/Returns Max           -96.5519
evaluation/Returns Min          -100
evaluation/Actions Mean            0.0608993
evaluation/Actions Std             0.160985
evaluation/Actions Max             0.309379
evaluation/Actions Min            -0.20513
evaluation/Num Paths              10
evaluation/Average Returns       -99.6552
time/data storing (s)              0.00118665
time/evaluation sampling (s)       0.250798
time/exploration sampling (s)      0.0748871
time/logging (s)                   0.00338058
time/saving (s)                    0.00236313
time/training (s)                  1.01177
time/epoch (s)                     1.34439
time/total (s)                    24.2445
Epoch                             17
-----------------------------  --------------
2019-04-22 20:48:56.222779 PDT | [sac-pointmass-multitask-1_2019_04_22_20_48_30_0000--s-0] Epoch 18 finished
-----------------------------  --------------
replay_buffer/size              4000
trainer/QF1 Loss                   0.103147
trainer/QF2 Loss                   0.115046
trainer/Policy Loss               12.6068
trainer/Q1 Predictions Mean      -13.8937
trainer/Q1 Predictions Std         0.673151
trainer/Q1 Predictions Max       -12.5945
trainer/Q1 Predictions Min       -15.4904
trainer/Q2 Predictions Mean      -13.8684
trainer/Q2 Predictions Std         0.671106
trainer/Q2 Predictions Max       -12.4894
trainer/Q2 Predictions Min       -15.3682
trainer/Q Targets Mean           -14.0673
trainer/Q Targets Std              0.583474
trainer/Q Targets Max            -12.7593
trainer/Q Targets Min            -15.3261
trainer/Log Pis Mean              -1.23855
trainer/Log Pis Std                0.357578
trainer/Log Pis Max               -0.525108
trainer/Log Pis Min               -2.15145
trainer/Policy mu Mean             0.0700848
trainer/Policy mu Std              0.211188
trainer/Policy mu Max              0.496709
trainer/Policy mu Min             -0.49812
trainer/Policy log std Mean       -0.264761
trainer/Policy log std Std         0.0494321
trainer/Policy log std Max        -0.171318
trainer/Policy log std Min        -0.392712
trainer/Alpha                      0.340308
trainer/Alpha Loss                -3.48989
exploration/num steps total     4000
exploration/num paths total       40
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.99319
exploration/Rewards Std            0.0579817
exploration/Rewards Max           -0.345124
exploration/Rewards Min           -1
exploration/Returns Mean         -99.319
exploration/Returns Std            0.681015
exploration/Returns Max          -98.638
exploration/Returns Min         -100
exploration/Actions Mean           0.0214975
exploration/Actions Std            0.574439
exploration/Actions Max            0.996754
exploration/Actions Min           -0.976232
exploration/Num Paths              2
exploration/Average Returns      -99.319
evaluation/num steps total     19000
evaluation/num paths total       190
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.99026
evaluation/Rewards Std             0.0691613
evaluation/Rewards Max            -0.0947644
evaluation/Rewards Min            -1
evaluation/Returns Mean          -99.026
evaluation/Returns Std             1.4311
evaluation/Returns Max           -95.5748
evaluation/Returns Min          -100
evaluation/Actions Mean            0.0362172
evaluation/Actions Std             0.178424
evaluation/Actions Max             0.453852
evaluation/Actions Min            -0.471906
evaluation/Num Paths              10
evaluation/Average Returns       -99.026
time/data storing (s)              0.00134243
time/evaluation sampling (s)       0.250049
time/exploration sampling (s)      0.071161
time/logging (s)                   0.00391149
time/saving (s)                    0.00278087
time/training (s)                  1.02429
time/epoch (s)                     1.35354
time/total (s)                    25.6023
Epoch                             18
-----------------------------  --------------
2019-04-22 20:48:57.572373 PDT | [sac-pointmass-multitask-1_2019_04_22_20_48_30_0000--s-0] Epoch 19 finished
-----------------------------  --------------
replay_buffer/size              4200
trainer/QF1 Loss                   1.72991
trainer/QF2 Loss                   1.71716
trainer/Policy Loss               13.233
trainer/Q1 Predictions Mean      -14.5878
trainer/Q1 Predictions Std         0.594961
trainer/Q1 Predictions Max       -13.4814
trainer/Q1 Predictions Min       -15.9353
trainer/Q2 Predictions Mean      -14.5669
trainer/Q2 Predictions Std         0.60085
trainer/Q2 Predictions Max       -13.4552
trainer/Q2 Predictions Min       -15.887
trainer/Q Targets Mean           -14.6856
trainer/Q Targets Std              1.51057
trainer/Q Targets Max             -1
trainer/Q Targets Min            -16.1473
trainer/Log Pis Mean              -1.34623
trainer/Log Pis Std                0.546109
trainer/Log Pis Max               -0.637072
trainer/Log Pis Min               -4.0926
trainer/Policy mu Mean             0.0428351
trainer/Policy mu Std              0.20078
trainer/Policy mu Max              0.472343
trainer/Policy mu Min             -0.520774
trainer/Policy log std Mean       -0.24724
trainer/Policy log std Std         0.042898
trainer/Policy log std Max        -0.164035
trainer/Policy log std Min        -0.361695
trainer/Alpha                      0.320769
trainer/Alpha Loss                -3.80378
exploration/num steps total     4200
exploration/num paths total       42
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.969469
exploration/Rewards Std            0.122656
exploration/Rewards Max           -0.124294
exploration/Rewards Min           -1
exploration/Returns Mean         -96.9469
exploration/Returns Std            0.625417
exploration/Returns Max          -96.3215
exploration/Returns Min          -97.5724
exploration/Actions Mean           0.0698544
exploration/Actions Std            0.560682
exploration/Actions Max            0.970233
exploration/Actions Min           -0.972731
exploration/Num Paths              2
exploration/Average Returns      -96.9469
evaluation/num steps total     20000
evaluation/num paths total       200
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.988491
evaluation/Rewards Std             0.0776261
evaluation/Rewards Max            -0.21133
evaluation/Rewards Min            -1
evaluation/Returns Mean          -98.8491
evaluation/Returns Std             1.63591
evaluation/Returns Max           -96.0088
evaluation/Returns Min          -100
evaluation/Actions Mean            0.0277042
evaluation/Actions Std             0.169943
evaluation/Actions Max             0.411524
evaluation/Actions Min            -0.460663
evaluation/Num Paths              10
evaluation/Average Returns       -98.8491
time/data storing (s)              0.00119124
time/evaluation sampling (s)       0.251177
time/exploration sampling (s)      0.074347
time/logging (s)                   0.00365824
time/saving (s)                    0.00248898
time/training (s)                  1.01079
time/epoch (s)                     1.34365
time/total (s)                    26.9504
Epoch                             19
-----------------------------  --------------
2019-04-22 20:48:58.924225 PDT | [sac-pointmass-multitask-1_2019_04_22_20_48_30_0000--s-0] Epoch 20 finished
-----------------------------  --------------
replay_buffer/size              4400
trainer/QF1 Loss                   1.99376
trainer/QF2 Loss                   1.99187
trainer/Policy Loss               13.9775
trainer/Q1 Predictions Mean      -15.2674
trainer/Q1 Predictions Std         0.754784
trainer/Q1 Predictions Max       -13.7063
trainer/Q1 Predictions Min       -17.0326
trainer/Q2 Predictions Mean      -15.2834
trainer/Q2 Predictions Std         0.727701
trainer/Q2 Predictions Max       -13.7587
trainer/Q2 Predictions Min       -16.9663
trainer/Q Targets Mean           -15.4553
trainer/Q Targets Std              1.60709
trainer/Q Targets Max             -1
trainer/Q Targets Min            -16.8938
trainer/Log Pis Mean              -1.31035
trainer/Log Pis Std                0.386881
trainer/Log Pis Max               -0.635764
trainer/Log Pis Min               -3.24956
trainer/Policy mu Mean             0.0293727
trainer/Policy mu Std              0.20457
trainer/Policy mu Max              0.381504
trainer/Policy mu Min             -0.592137
trainer/Policy log std Mean       -0.26018
trainer/Policy log std Std         0.058605
trainer/Policy log std Max        -0.155288
trainer/Policy log std Min        -0.414264
trainer/Alpha                      0.302321
trainer/Alpha Loss                -3.95907
exploration/num steps total     4400
exploration/num paths total       44
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1
exploration/Rewards Std            0
exploration/Rewards Max           -1
exploration/Rewards Min           -1
exploration/Returns Mean        -100
exploration/Returns Std            0
exploration/Returns Max         -100
exploration/Returns Min         -100
exploration/Actions Mean           0.0671512
exploration/Actions Std            0.548284
exploration/Actions Max            0.99052
exploration/Actions Min           -0.953305
exploration/Num Paths              2
exploration/Average Returns     -100
evaluation/num steps total     21000
evaluation/num paths total       210
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.997599
evaluation/Rewards Std             0.0238298
evaluation/Rewards Max            -0.701652
evaluation/Rewards Min            -1
evaluation/Returns Mean          -99.7599
evaluation/Returns Std             0.720209
evaluation/Returns Max           -97.5993
evaluation/Returns Min          -100
evaluation/Actions Mean            0.0198473
evaluation/Actions Std             0.132474
evaluation/Actions Max             0.336982
evaluation/Actions Min            -0.401631
evaluation/Num Paths              10
evaluation/Average Returns       -99.7599
time/data storing (s)              0.00121802
time/evaluation sampling (s)       0.251836
time/exploration sampling (s)      0.0713529
time/logging (s)                   0.00296594
time/saving (s)                    0.00260003
time/training (s)                  1.01572
time/epoch (s)                     1.34569
time/total (s)                    28.3006
Epoch                             20
-----------------------------  --------------
2019-04-22 20:49:00.292071 PDT | [sac-pointmass-multitask-1_2019_04_22_20_48_30_0000--s-0] Epoch 21 finished
-----------------------------  --------------
replay_buffer/size              4600
trainer/QF1 Loss                   0.0787491
trainer/QF2 Loss                   0.0786146
trainer/Policy Loss               14.6327
trainer/Q1 Predictions Mean      -15.9238
trainer/Q1 Predictions Std         0.791546
trainer/Q1 Predictions Max       -14.4365
trainer/Q1 Predictions Min       -17.9197
trainer/Q2 Predictions Mean      -15.92
trainer/Q2 Predictions Std         0.806926
trainer/Q2 Predictions Max       -14.5034
trainer/Q2 Predictions Min       -17.7688
trainer/Q Targets Mean           -16.0629
trainer/Q Targets Std              0.729424
trainer/Q Targets Max            -14.7754
trainer/Q Targets Min            -17.5802
trainer/Log Pis Mean              -1.26455
trainer/Log Pis Std                0.33954
trainer/Log Pis Max               -0.347868
trainer/Log Pis Min               -2.13922
trainer/Policy mu Mean             0.0565088
trainer/Policy mu Std              0.178957
trainer/Policy mu Max              0.463807
trainer/Policy mu Min             -0.552869
trainer/Policy log std Mean       -0.303628
trainer/Policy log std Std         0.0826552
trainer/Policy log std Max        -0.163478
trainer/Policy log std Min        -0.506061
trainer/Alpha                      0.284977
trainer/Alpha Loss                -4.09718
exploration/num steps total     4600
exploration/num paths total       46
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.920508
exploration/Rewards Std            0.19515
exploration/Rewards Max           -0.17839
exploration/Rewards Min           -1
exploration/Returns Mean         -92.0508
exploration/Returns Std            1.93319
exploration/Returns Max          -90.1177
exploration/Returns Min          -93.984
exploration/Actions Mean           0.028491
exploration/Actions Std            0.531605
exploration/Actions Max            0.967648
exploration/Actions Min           -0.970975
exploration/Num Paths              2
exploration/Average Returns      -92.0508
evaluation/num steps total     22000
evaluation/num paths total       220
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.994347
evaluation/Rewards Std             0.034859
evaluation/Rewards Max            -0.72536
evaluation/Rewards Min            -1
evaluation/Returns Mean          -99.4347
evaluation/Returns Std             1.16485
evaluation/Returns Max           -96.5459
evaluation/Returns Min          -100
evaluation/Actions Mean            0.00124944
evaluation/Actions Std             0.070448
evaluation/Actions Max             0.408975
evaluation/Actions Min            -0.331564
evaluation/Num Paths              10
evaluation/Average Returns       -99.4347
time/data storing (s)              0.00120281
time/evaluation sampling (s)       0.250595
time/exploration sampling (s)      0.0761273
time/logging (s)                   0.00388623
time/saving (s)                    0.00227629
time/training (s)                  1.02915
time/epoch (s)                     1.36324
time/total (s)                    29.6683
Epoch                             21
-----------------------------  --------------
2019-04-22 20:49:01.670693 PDT | [sac-pointmass-multitask-1_2019_04_22_20_48_30_0000--s-0] Epoch 22 finished
-----------------------------  --------------
replay_buffer/size              4800
trainer/QF1 Loss                   0.0667163
trainer/QF2 Loss                   0.0740537
trainer/Policy Loss               15.4424
trainer/Q1 Predictions Mean      -16.6615
trainer/Q1 Predictions Std         0.728388
trainer/Q1 Predictions Max       -15.2622
trainer/Q1 Predictions Min       -18.2781
trainer/Q2 Predictions Mean      -16.6424
trainer/Q2 Predictions Std         0.754228
trainer/Q2 Predictions Max       -15.1756
trainer/Q2 Predictions Min       -18.171
trainer/Q Targets Mean           -16.6489
trainer/Q Targets Std              0.687016
trainer/Q Targets Max            -15.4325
trainer/Q Targets Min            -18.4256
trainer/Log Pis Mean              -1.17856
trainer/Log Pis Std                0.428305
trainer/Log Pis Max               -0.216643
trainer/Log Pis Min               -2.74108
trainer/Policy mu Mean             0.11342
trainer/Policy mu Std              0.208359
trainer/Policy mu Max              0.496381
trainer/Policy mu Min             -0.607592
trainer/Policy log std Mean       -0.305439
trainer/Policy log std Std         0.082731
trainer/Policy log std Max        -0.160063
trainer/Policy log std Min        -0.506898
trainer/Alpha                      0.268653
trainer/Alpha Loss                -4.17675
exploration/num steps total     4800
exploration/num paths total       48
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.955738
exploration/Rewards Std            0.151297
exploration/Rewards Max           -0.165592
exploration/Rewards Min           -1
exploration/Returns Mean         -95.5738
exploration/Returns Std            4.42624
exploration/Returns Max          -91.1475
exploration/Returns Min         -100
exploration/Actions Mean           0.0261329
exploration/Actions Std            0.538704
exploration/Actions Max            0.976194
exploration/Actions Min           -0.95441
exploration/Num Paths              2
exploration/Average Returns      -95.5738
evaluation/num steps total     23000
evaluation/num paths total       230
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.9831
evaluation/Rewards Std             0.0969899
evaluation/Rewards Max            -0.0906805
evaluation/Rewards Min            -1
evaluation/Returns Mean          -98.31
evaluation/Returns Std             2.52808
evaluation/Returns Max           -93.9471
evaluation/Returns Min          -100
evaluation/Actions Mean            0.0909257
evaluation/Actions Std             0.170786
evaluation/Actions Max             0.47225
evaluation/Actions Min            -0.465404
evaluation/Num Paths              10
evaluation/Average Returns       -98.31
time/data storing (s)              0.00144014
time/evaluation sampling (s)       0.24869
time/exploration sampling (s)      0.0693973
time/logging (s)                   0.00363387
time/saving (s)                    0.00244833
time/training (s)                  1.0474
time/epoch (s)                     1.37301
time/total (s)                    31.0455
Epoch                             22
-----------------------------  --------------
2019-04-22 20:49:03.020769 PDT | [sac-pointmass-multitask-1_2019_04_22_20_48_30_0000--s-0] Epoch 23 finished
-----------------------------  --------------
replay_buffer/size              5000
trainer/QF1 Loss                   2.68401
trainer/QF2 Loss                   2.68881
trainer/Policy Loss               15.7833
trainer/Q1 Predictions Mean      -17.0101
trainer/Q1 Predictions Std         0.767216
trainer/Q1 Predictions Max       -15.7012
trainer/Q1 Predictions Min       -18.6591
trainer/Q2 Predictions Mean      -16.9996
trainer/Q2 Predictions Std         0.786962
trainer/Q2 Predictions Max       -15.7619
trainer/Q2 Predictions Min       -18.7174
trainer/Q Targets Mean           -16.9599
trainer/Q Targets Std              1.76442
trainer/Q Targets Max             -1
trainer/Q Targets Min            -18.8012
trainer/Log Pis Mean              -1.1823
trainer/Log Pis Std                0.47893
trainer/Log Pis Max                0.123442
trainer/Log Pis Min               -2.6908
trainer/Policy mu Mean             0.0334438
trainer/Policy mu Std              0.26272
trainer/Policy mu Max              0.621974
trainer/Policy mu Min             -0.765734
trainer/Policy log std Mean       -0.32959
trainer/Policy log std Std         0.0801171
trainer/Policy log std Max        -0.151867
trainer/Policy log std Min        -0.529252
trainer/Alpha                      0.253341
trainer/Alpha Loss                -4.36843
exploration/num steps total     5000
exploration/num paths total       50
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.995023
exploration/Rewards Std            0.0492735
exploration/Rewards Max           -0.337723
exploration/Rewards Min           -1
exploration/Returns Mean         -99.5023
exploration/Returns Std            0.497715
exploration/Returns Max          -99.0046
exploration/Returns Min         -100
exploration/Actions Mean           0.0488714
exploration/Actions Std            0.521162
exploration/Actions Max            0.989641
exploration/Actions Min           -0.966324
exploration/Num Paths              2
exploration/Average Returns      -99.5023
evaluation/num steps total     24000
evaluation/num paths total       240
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.992294
evaluation/Rewards Std             0.0634513
evaluation/Rewards Max            -0.177098
evaluation/Rewards Min            -1
evaluation/Returns Mean          -99.2294
evaluation/Returns Std             1.25192
evaluation/Returns Max           -96.8276
evaluation/Returns Min          -100
evaluation/Actions Mean            0.0230255
evaluation/Actions Std             0.186535
evaluation/Actions Max             0.481711
evaluation/Actions Min            -0.56096
evaluation/Num Paths              10
evaluation/Average Returns       -99.2294
time/data storing (s)              0.0012638
time/evaluation sampling (s)       0.250255
time/exploration sampling (s)      0.0721632
time/logging (s)                   0.00357626
time/saving (s)                    0.00259091
time/training (s)                  1.01509
time/epoch (s)                     1.34494
time/total (s)                    32.3943
Epoch                             23
-----------------------------  --------------
2019-04-22 20:49:04.384308 PDT | [sac-pointmass-multitask-1_2019_04_22_20_48_30_0000--s-0] Epoch 24 finished
-----------------------------  --------------
replay_buffer/size              5200
trainer/QF1 Loss                   2.53301
trainer/QF2 Loss                   2.50299
trainer/Policy Loss               16.5908
trainer/Q1 Predictions Mean      -17.7406
trainer/Q1 Predictions Std         0.893596
trainer/Q1 Predictions Max       -16.1034
trainer/Q1 Predictions Min       -19.7608
trainer/Q2 Predictions Mean      -17.7272
trainer/Q2 Predictions Std         0.894699
trainer/Q2 Predictions Max       -16.1044
trainer/Q2 Predictions Min       -19.7535
trainer/Q Targets Mean           -17.5789
trainer/Q Targets Std              1.8684
trainer/Q Targets Max             -0.952951
trainer/Q Targets Min            -19.6098
trainer/Log Pis Mean              -1.07589
trainer/Log Pis Std                0.552802
trainer/Log Pis Max                0.0233048
trainer/Log Pis Min               -3.54184
trainer/Policy mu Mean             0.0624025
trainer/Policy mu Std              0.306827
trainer/Policy mu Max              0.650103
trainer/Policy mu Min             -0.777571
trainer/Policy log std Mean       -0.361056
trainer/Policy log std Std         0.108569
trainer/Policy log std Max        -0.178729
trainer/Policy log std Min        -0.624092
trainer/Alpha                      0.238943
trainer/Alpha Loss                -4.40233
exploration/num steps total     5200
exploration/num paths total       52
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.949958
exploration/Rewards Std            0.165642
exploration/Rewards Max           -0.0614982
exploration/Rewards Min           -1
exploration/Returns Mean         -94.9958
exploration/Returns Std            2.18257
exploration/Returns Max          -92.8133
exploration/Returns Min          -97.1784
exploration/Actions Mean           0.0989521
exploration/Actions Std            0.525378
exploration/Actions Max            0.966109
exploration/Actions Min           -0.970563
exploration/Num Paths              2
exploration/Average Returns      -94.9958
evaluation/num steps total     25000
evaluation/num paths total       250
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.995177
evaluation/Rewards Std             0.0513136
evaluation/Rewards Max            -0.257589
evaluation/Rewards Min            -1
evaluation/Returns Mean          -99.5177
evaluation/Returns Std             0.964632
evaluation/Returns Max           -97.5815
evaluation/Returns Min          -100
evaluation/Actions Mean            0.0842917
evaluation/Actions Std             0.163757
evaluation/Actions Max             0.547958
evaluation/Actions Min            -0.63157
evaluation/Num Paths              10
evaluation/Average Returns       -99.5177
time/data storing (s)              0.001185
time/evaluation sampling (s)       0.24616
time/exploration sampling (s)      0.0717706
time/logging (s)                   0.00354089
time/saving (s)                    0.00226286
time/training (s)                  1.03324
time/epoch (s)                     1.35816
time/total (s)                    33.7567
Epoch                             24
-----------------------------  --------------
2019-04-22 20:49:05.747677 PDT | [sac-pointmass-multitask-1_2019_04_22_20_48_30_0000--s-0] Epoch 25 finished
-----------------------------  --------------
replay_buffer/size              5400
trainer/QF1 Loss                   4.9628
trainer/QF2 Loss                   5.00347
trainer/Policy Loss               16.8365
trainer/Q1 Predictions Mean      -17.92
trainer/Q1 Predictions Std         0.873659
trainer/Q1 Predictions Max       -16.3481
trainer/Q1 Predictions Min       -19.7127
trainer/Q2 Predictions Mean      -17.9336
trainer/Q2 Predictions Std         0.843175
trainer/Q2 Predictions Max       -16.4612
trainer/Q2 Predictions Min       -19.7924
trainer/Q Targets Mean           -17.8923
trainer/Q Targets Std              2.53531
trainer/Q Targets Max             -1
trainer/Q Targets Min            -19.941
trainer/Log Pis Mean              -1.04014
trainer/Log Pis Std                0.576028
trainer/Log Pis Max                0.211491
trainer/Log Pis Min               -3.13989
trainer/Policy mu Mean             0.0659707
trainer/Policy mu Std              0.350875
trainer/Policy mu Max              0.696222
trainer/Policy mu Min             -0.944147
trainer/Policy log std Mean       -0.369522
trainer/Policy log std Std         0.117703
trainer/Policy log std Max        -0.179778
trainer/Policy log std Min        -0.667217
trainer/Alpha                      0.225391
trainer/Alpha Loss                -4.52868
exploration/num steps total     5400
exploration/num paths total       54
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1
exploration/Rewards Std            0
exploration/Rewards Max           -1
exploration/Rewards Min           -1
exploration/Returns Mean        -100
exploration/Returns Std            0
exploration/Returns Max         -100
exploration/Returns Min         -100
exploration/Actions Mean           0.0472883
exploration/Actions Std            0.534394
exploration/Actions Max            0.981575
exploration/Actions Min           -0.958571
exploration/Num Paths              2
exploration/Average Returns     -100
evaluation/num steps total     26000
evaluation/num paths total       260
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.999154
evaluation/Rewards Std             0.0159392
evaluation/Rewards Max            -0.622575
evaluation/Rewards Min            -1
evaluation/Returns Mean          -99.9154
evaluation/Returns Std             0.253804
evaluation/Returns Max           -99.154
evaluation/Returns Min          -100
evaluation/Actions Mean            0.0410023
evaluation/Actions Std             0.235665
evaluation/Actions Max             0.600509
evaluation/Actions Min            -0.708644
evaluation/Num Paths              10
evaluation/Average Returns       -99.9154
time/data storing (s)              0.00114562
time/evaluation sampling (s)       0.252888
time/exploration sampling (s)      0.0695223
time/logging (s)                   0.00345368
time/saving (s)                    0.00210456
time/training (s)                  1.02861
time/epoch (s)                     1.35772
time/total (s)                    35.1189
Epoch                             25
-----------------------------  --------------
2019-04-22 20:49:07.098113 PDT | [sac-pointmass-multitask-1_2019_04_22_20_48_30_0000--s-0] Epoch 26 finished
-----------------------------  --------------
replay_buffer/size              5600
trainer/QF1 Loss                   2.80315
trainer/QF2 Loss                   2.78568
trainer/Policy Loss               17.3487
trainer/Q1 Predictions Mean      -18.519
trainer/Q1 Predictions Std         1.00001
trainer/Q1 Predictions Max       -16.7106
trainer/Q1 Predictions Min       -20.4608
trainer/Q2 Predictions Mean      -18.5618
trainer/Q2 Predictions Std         0.996516
trainer/Q2 Predictions Max       -16.8597
trainer/Q2 Predictions Min       -20.6464
trainer/Q Targets Mean           -18.5763
trainer/Q Targets Std              1.9588
trainer/Q Targets Max             -1
trainer/Q Targets Min            -20.6089
trainer/Log Pis Mean              -1.13895
trainer/Log Pis Std                0.554285
trainer/Log Pis Max               -0.0977812
trainer/Log Pis Min               -2.82637
trainer/Policy mu Mean             0.104757
trainer/Policy mu Std              0.291958
trainer/Policy mu Max              0.685743
trainer/Policy mu Min             -0.810598
trainer/Policy log std Mean       -0.388554
trainer/Policy log std Std         0.118378
trainer/Policy log std Max        -0.135644
trainer/Policy log std Min        -0.69599
trainer/Alpha                      0.212694
trainer/Alpha Loss                -4.85788
exploration/num steps total     5600
exploration/num paths total       56
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.947244
exploration/Rewards Std            0.156185
exploration/Rewards Max           -0.194547
exploration/Rewards Min           -1
exploration/Returns Mean         -94.7244
exploration/Returns Std            5.27562
exploration/Returns Max          -89.4488
exploration/Returns Min         -100
exploration/Actions Mean           0.0194568
exploration/Actions Std            0.535543
exploration/Actions Max            0.982945
exploration/Actions Min           -0.961603
exploration/Num Paths              2
exploration/Average Returns      -94.7244
evaluation/num steps total     27000
evaluation/num paths total       270
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.999733
evaluation/Rewards Std             0.0040874
evaluation/Rewards Max            -0.917139
evaluation/Rewards Min            -1
evaluation/Returns Mean          -99.9733
evaluation/Returns Std             0.0535462
evaluation/Returns Max           -99.8606
evaluation/Returns Min          -100
evaluation/Actions Mean            0.0746336
evaluation/Actions Std             0.169634
evaluation/Actions Max             0.58458
evaluation/Actions Min            -0.675065
evaluation/Num Paths              10
evaluation/Average Returns       -99.9733
time/data storing (s)              0.00126317
time/evaluation sampling (s)       0.244343
time/exploration sampling (s)      0.0709486
time/logging (s)                   0.0036957
time/saving (s)                    0.00237938
time/training (s)                  1.02254
time/epoch (s)                     1.34517
time/total (s)                    36.4684
Epoch                             26
-----------------------------  --------------
2019-04-22 20:49:08.469063 PDT | [sac-pointmass-multitask-1_2019_04_22_20_48_30_0000--s-0] Epoch 27 finished
-----------------------------  --------------
replay_buffer/size              5800
trainer/QF1 Loss                   3.08989
trainer/QF2 Loss                   3.055
trainer/Policy Loss               17.9443
trainer/Q1 Predictions Mean      -19.0472
trainer/Q1 Predictions Std         0.820847
trainer/Q1 Predictions Max       -17.3313
trainer/Q1 Predictions Min       -20.7292
trainer/Q2 Predictions Mean      -19.0004
trainer/Q2 Predictions Std         0.836908
trainer/Q2 Predictions Max       -17.2822
trainer/Q2 Predictions Min       -20.7789
trainer/Q Targets Mean           -19.1812
trainer/Q Targets Std              2.01912
trainer/Q Targets Max             -1
trainer/Q Targets Min            -21.2268
trainer/Log Pis Mean              -1.03206
trainer/Log Pis Std                0.656669
trainer/Log Pis Max                0.184971
trainer/Log Pis Min               -3.83073
trainer/Policy mu Mean             0.0592624
trainer/Policy mu Std              0.316181
trainer/Policy mu Max              0.799628
trainer/Policy mu Min             -0.795595
trainer/Policy log std Mean       -0.398378
trainer/Policy log std Std         0.110391
trainer/Policy log std Max        -0.163029
trainer/Policy log std Min        -0.75084
trainer/Alpha                      0.200693
trainer/Alpha Loss                -4.86853
exploration/num steps total     5800
exploration/num paths total       58
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1
exploration/Rewards Std            0
exploration/Rewards Max           -1
exploration/Rewards Min           -1
exploration/Returns Mean        -100
exploration/Returns Std            0
exploration/Returns Max         -100
exploration/Returns Min         -100
exploration/Actions Mean           0.0288265
exploration/Actions Std            0.507197
exploration/Actions Max            0.980136
exploration/Actions Min           -0.981464
exploration/Num Paths              2
exploration/Average Returns     -100
evaluation/num steps total     28000
evaluation/num paths total       280
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.99461
evaluation/Rewards Std             0.0555779
evaluation/Rewards Max            -0.115426
evaluation/Rewards Min            -1
evaluation/Returns Mean          -99.461
evaluation/Returns Std             1.27911
evaluation/Returns Max           -95.7655
evaluation/Returns Min          -100
evaluation/Actions Mean            0.0197805
evaluation/Actions Std             0.168612
evaluation/Actions Max             0.670414
evaluation/Actions Min            -0.641161
evaluation/Num Paths              10
evaluation/Average Returns       -99.461
time/data storing (s)              0.0012142
time/evaluation sampling (s)       0.252653
time/exploration sampling (s)      0.0830322
time/logging (s)                   0.0036134
time/saving (s)                    0.00214461
time/training (s)                  1.02256
time/epoch (s)                     1.36522
time/total (s)                    37.8381
Epoch                             27
-----------------------------  --------------
2019-04-22 20:49:09.830017 PDT | [sac-pointmass-multitask-1_2019_04_22_20_48_30_0000--s-0] Epoch 28 finished
-----------------------------  --------------
replay_buffer/size              6000
trainer/QF1 Loss                   6.52851
trainer/QF2 Loss                   6.5603
trainer/Policy Loss               18.3899
trainer/Q1 Predictions Mean      -19.5997
trainer/Q1 Predictions Std         0.943608
trainer/Q1 Predictions Max       -17.8322
trainer/Q1 Predictions Min       -22.0021
trainer/Q2 Predictions Mean      -19.5887
trainer/Q2 Predictions Std         0.929418
trainer/Q2 Predictions Max       -17.877
trainer/Q2 Predictions Min       -21.9427
trainer/Q Targets Mean           -19.4711
trainer/Q Targets Std              2.77032
trainer/Q Targets Max             -1
trainer/Q Targets Min            -21.9641
trainer/Log Pis Mean              -1.15009
trainer/Log Pis Std                0.752093
trainer/Log Pis Max                0.302828
trainer/Log Pis Min               -3.95365
trainer/Policy mu Mean             0.124788
trainer/Policy mu Std              0.36141
trainer/Policy mu Max              0.981493
trainer/Policy mu Min             -0.798002
trainer/Policy log std Mean       -0.42661
trainer/Policy log std Std         0.109039
trainer/Policy log std Max        -0.164174
trainer/Policy log std Min        -0.728949
trainer/Alpha                      0.189425
trainer/Alpha Loss                -5.2401
exploration/num steps total     6000
exploration/num paths total       60
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.97456
exploration/Rewards Std            0.108127
exploration/Rewards Max           -0.2549
exploration/Rewards Min           -1
exploration/Returns Mean         -97.456
exploration/Returns Std            0.639456
exploration/Returns Max          -96.8166
exploration/Returns Min          -98.0955
exploration/Actions Mean           0.0471806
exploration/Actions Std            0.513788
exploration/Actions Max            0.974808
exploration/Actions Min           -0.962748
exploration/Num Paths              2
exploration/Average Returns      -97.456
evaluation/num steps total     29000
evaluation/num paths total       290
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.994899
evaluation/Rewards Std             0.050041
evaluation/Rewards Max            -0.269147
evaluation/Rewards Min            -1
evaluation/Returns Mean          -99.4899
evaluation/Returns Std             1.03844
evaluation/Returns Max           -97.0159
evaluation/Returns Min          -100
evaluation/Actions Mean            0.061699
evaluation/Actions Std             0.132738
evaluation/Actions Max             0.760962
evaluation/Actions Min            -0.284455
evaluation/Num Paths              10
evaluation/Average Returns       -99.4899
time/data storing (s)              0.00120857
time/evaluation sampling (s)       0.247289
time/exploration sampling (s)      0.0717941
time/logging (s)                   0.00358133
time/saving (s)                    0.00237812
time/training (s)                  1.0292
time/epoch (s)                     1.35545
time/total (s)                    39.1979
Epoch                             28
-----------------------------  --------------
2019-04-22 20:49:11.185778 PDT | [sac-pointmass-multitask-1_2019_04_22_20_48_30_0000--s-0] Epoch 29 finished
-----------------------------  --------------
replay_buffer/size              6200
trainer/QF1 Loss                   0.108255
trainer/QF2 Loss                   0.107826
trainer/Policy Loss               19.157
trainer/Q1 Predictions Mean      -20.2382
trainer/Q1 Predictions Std         0.928672
trainer/Q1 Predictions Max       -18.3326
trainer/Q1 Predictions Min       -22.3525
trainer/Q2 Predictions Mean      -20.2493
trainer/Q2 Predictions Std         0.943277
trainer/Q2 Predictions Max       -18.3985
trainer/Q2 Predictions Min       -22.5901
trainer/Q Targets Mean           -20.3661
trainer/Q Targets Std              0.917866
trainer/Q Targets Max            -18.7349
trainer/Q Targets Min            -22.3675
trainer/Log Pis Mean              -1.02766
trainer/Log Pis Std                0.586116
trainer/Log Pis Max                0.0179787
trainer/Log Pis Min               -2.90328
trainer/Policy mu Mean             0.0516125
trainer/Policy mu Std              0.343489
trainer/Policy mu Max              0.961174
trainer/Policy mu Min             -0.729986
trainer/Policy log std Mean       -0.457184
trainer/Policy log std Std         0.125579
trainer/Policy log std Max        -0.159347
trainer/Policy log std Min        -0.811835
trainer/Alpha                      0.178867
trainer/Alpha Loss                -5.21009
exploration/num steps total     6200
exploration/num paths total       62
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1
exploration/Rewards Std            0
exploration/Rewards Max           -1
exploration/Rewards Min           -1
exploration/Returns Mean        -100
exploration/Returns Std            0
exploration/Returns Max         -100
exploration/Returns Min         -100
exploration/Actions Mean           0.0623893
exploration/Actions Std            0.483614
exploration/Actions Max            0.976567
exploration/Actions Min           -0.950068
exploration/Num Paths              2
exploration/Average Returns     -100
evaluation/num steps total     30000
evaluation/num paths total       300
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.971228
evaluation/Rewards Std             0.108011
evaluation/Rewards Max            -0.0465078
evaluation/Rewards Min            -1
evaluation/Returns Mean          -97.1228
evaluation/Returns Std             5.77081
evaluation/Returns Max           -84.3849
evaluation/Returns Min          -100
evaluation/Actions Mean            0.0147917
evaluation/Actions Std             0.144362
evaluation/Actions Max             0.683464
evaluation/Actions Min            -0.665349
evaluation/Num Paths              10
evaluation/Average Returns       -97.1228
time/data storing (s)              0.00124279
time/evaluation sampling (s)       0.248862
time/exploration sampling (s)      0.0711955
time/logging (s)                   0.00379147
time/saving (s)                    0.00258354
time/training (s)                  1.0229
time/epoch (s)                     1.35057
time/total (s)                    40.5527
Epoch                             29
-----------------------------  --------------
2019-04-22 20:49:12.565658 PDT | [sac-pointmass-multitask-1_2019_04_22_20_48_30_0000--s-0] Epoch 30 finished
-----------------------------  --------------
replay_buffer/size              6400
trainer/QF1 Loss                   0.0849064
trainer/QF2 Loss                   0.0953422
trainer/Policy Loss               19.8699
trainer/Q1 Predictions Mean      -20.9339
trainer/Q1 Predictions Std         0.920009
trainer/Q1 Predictions Max       -19.0822
trainer/Q1 Predictions Min       -23.1712
trainer/Q2 Predictions Mean      -20.9523
trainer/Q2 Predictions Std         0.925187
trainer/Q2 Predictions Max       -19.0942
trainer/Q2 Predictions Min       -23.2038
trainer/Q Targets Mean           -20.9123
trainer/Q Targets Std              0.916909
trainer/Q Targets Max            -19.2038
trainer/Q Targets Min            -23.0856
trainer/Log Pis Mean              -0.946192
trainer/Log Pis Std                0.974536
trainer/Log Pis Max                0.936203
trainer/Log Pis Min               -5.25025
trainer/Policy mu Mean             0.0835901
trainer/Policy mu Std              0.468322
trainer/Policy mu Max              0.968029
trainer/Policy mu Min             -1.16086
trainer/Policy log std Mean       -0.47014
trainer/Policy log std Std         0.152628
trainer/Policy log std Max        -0.166443
trainer/Policy log std Min        -0.884361
trainer/Alpha                      0.168927
trainer/Alpha Loss                -5.23836
exploration/num steps total     6400
exploration/num paths total       64
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1
exploration/Rewards Std            0
exploration/Rewards Max           -1
exploration/Rewards Min           -1
exploration/Returns Mean        -100
exploration/Returns Std            0
exploration/Returns Max         -100
exploration/Returns Min         -100
exploration/Actions Mean           0.0977942
exploration/Actions Std            0.480205
exploration/Actions Max            0.952499
exploration/Actions Min           -0.894604
exploration/Num Paths              2
exploration/Average Returns     -100
evaluation/num steps total     31000
evaluation/num paths total       310
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.996202
evaluation/Rewards Std             0.048663
evaluation/Rewards Max            -0.103095
evaluation/Rewards Min            -1
evaluation/Returns Mean          -99.6202
evaluation/Returns Std             0.788766
evaluation/Returns Max           -97.6261
evaluation/Returns Min          -100
evaluation/Actions Mean            0.0277368
evaluation/Actions Std             0.21327
evaluation/Actions Max             0.693208
evaluation/Actions Min            -0.755332
evaluation/Num Paths              10
evaluation/Average Returns       -99.6202
time/data storing (s)              0.00118688
time/evaluation sampling (s)       0.246248
time/exploration sampling (s)      0.0719193
time/logging (s)                   0.00256955
time/saving (s)                    0.010566
time/training (s)                  1.04064
time/epoch (s)                     1.37313
time/total (s)                    41.9301
Epoch                             30
-----------------------------  --------------
2019-04-22 20:49:13.931099 PDT | [sac-pointmass-multitask-1_2019_04_22_20_48_30_0000--s-0] Epoch 31 finished
-----------------------------  --------------
replay_buffer/size              6600
trainer/QF1 Loss                   0.193242
trainer/QF2 Loss                   0.213829
trainer/Policy Loss               19.8504
trainer/Q1 Predictions Mean      -20.9748
trainer/Q1 Predictions Std         0.958547
trainer/Q1 Predictions Max       -18.8574
trainer/Q1 Predictions Min       -22.9954
trainer/Q2 Predictions Mean      -20.9566
trainer/Q2 Predictions Std         0.969626
trainer/Q2 Predictions Max       -18.8484
trainer/Q2 Predictions Min       -23.0236
trainer/Q Targets Mean           -21.1752
trainer/Q Targets Std              0.74972
trainer/Q Targets Max            -19.7428
trainer/Q Targets Min            -23.0011
trainer/Log Pis Mean              -1.07336
trainer/Log Pis Std                0.82342
trainer/Log Pis Max                0.719384
trainer/Log Pis Min               -5.10598
trainer/Policy mu Mean             0.0439444
trainer/Policy mu Std              0.410178
trainer/Policy mu Max              0.926991
trainer/Policy mu Min             -1.06007
trainer/Policy log std Mean       -0.458316
trainer/Policy log std Std         0.122828
trainer/Policy log std Max        -0.194127
trainer/Policy log std Min        -0.836305
trainer/Alpha                      0.15958
trainer/Alpha Loss                -5.63938
exploration/num steps total     6600
exploration/num paths total       66
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1
exploration/Rewards Std            0
exploration/Rewards Max           -1
exploration/Rewards Min           -1
exploration/Returns Mean        -100
exploration/Returns Std            0
exploration/Returns Max         -100
exploration/Returns Min         -100
exploration/Actions Mean           0.0337536
exploration/Actions Std            0.508178
exploration/Actions Max            0.938558
exploration/Actions Min           -0.951012
exploration/Num Paths              2
exploration/Average Returns     -100
evaluation/num steps total     32000
evaluation/num paths total       320
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.99676
evaluation/Rewards Std             0.039471
evaluation/Rewards Max            -0.32966
evaluation/Rewards Min            -1
evaluation/Returns Mean          -99.676
evaluation/Returns Std             0.687733
evaluation/Returns Max           -97.865
evaluation/Returns Min          -100
evaluation/Actions Mean            0.00982303
evaluation/Actions Std             0.123694
evaluation/Actions Max             0.608518
evaluation/Actions Min            -0.744427
evaluation/Num Paths              10
evaluation/Average Returns       -99.676
time/data storing (s)              0.00134789
time/evaluation sampling (s)       0.244058
time/exploration sampling (s)      0.0692922
time/logging (s)                   0.0037179
time/saving (s)                    0.00253892
time/training (s)                  1.04104
time/epoch (s)                     1.362
time/total (s)                    43.2959
Epoch                             31
-----------------------------  --------------
2019-04-22 20:49:15.293711 PDT | [sac-pointmass-multitask-1_2019_04_22_20_48_30_0000--s-0] Epoch 32 finished
-----------------------------  --------------
replay_buffer/size              6800
trainer/QF1 Loss                   4.11747
trainer/QF2 Loss                   4.09049
trainer/Policy Loss               20.9912
trainer/Q1 Predictions Mean      -21.8827
trainer/Q1 Predictions Std         0.995633
trainer/Q1 Predictions Max       -20.1638
trainer/Q1 Predictions Min       -24.6164
trainer/Q2 Predictions Mean      -21.872
trainer/Q2 Predictions Std         1.00728
trainer/Q2 Predictions Max       -20.146
trainer/Q2 Predictions Min       -24.6154
trainer/Q Targets Mean           -21.603
trainer/Q Targets Std              2.28205
trainer/Q Targets Max             -1
trainer/Q Targets Min            -24.0888
trainer/Log Pis Mean              -0.785705
trainer/Log Pis Std                0.629246
trainer/Log Pis Max                0.272345
trainer/Log Pis Min               -2.83348
trainer/Policy mu Mean             0.169275
trainer/Policy mu Std              0.395049
trainer/Policy mu Max              1.14528
trainer/Policy mu Min             -0.958737
trainer/Policy log std Mean       -0.502362
trainer/Policy log std Std         0.183907
trainer/Policy log std Max        -0.16513
trainer/Policy log std Min        -1.01069
trainer/Alpha                      0.150728
trainer/Alpha Loss                -5.27054
exploration/num steps total     6800
exploration/num paths total       68
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.995636
exploration/Rewards Std            0.0339126
exploration/Rewards Max           -0.658992
exploration/Rewards Min           -1
exploration/Returns Mean         -99.5636
exploration/Returns Std            0.436356
exploration/Returns Max          -99.1273
exploration/Returns Min         -100
exploration/Actions Mean           0.0777837
exploration/Actions Std            0.460615
exploration/Actions Max            0.961242
exploration/Actions Min           -0.864198
exploration/Num Paths              2
exploration/Average Returns      -99.5636
evaluation/num steps total     33000
evaluation/num paths total       330
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.992228
evaluation/Rewards Std             0.0640885
evaluation/Rewards Max            -0.145317
evaluation/Rewards Min            -1
evaluation/Returns Mean          -99.2228
evaluation/Returns Std             1.56077
evaluation/Returns Max           -95.7976
evaluation/Returns Min          -100
evaluation/Actions Mean            0.132926
evaluation/Actions Std             0.204813
evaluation/Actions Max             0.764686
evaluation/Actions Min            -0.644142
evaluation/Num Paths              10
evaluation/Average Returns       -99.2228
time/data storing (s)              0.00121606
time/evaluation sampling (s)       0.246446
time/exploration sampling (s)      0.0703919
time/logging (s)                   0.00336745
time/saving (s)                    0.00241111
time/training (s)                  1.03258
time/epoch (s)                     1.35641
time/total (s)                    44.6568
Epoch                             32
-----------------------------  --------------
2019-04-22 20:49:16.651464 PDT | [sac-pointmass-multitask-1_2019_04_22_20_48_30_0000--s-0] Epoch 33 finished
-----------------------------  --------------
replay_buffer/size              7000
trainer/QF1 Loss                   4.53564
trainer/QF2 Loss                   4.55514
trainer/Policy Loss               20.6323
trainer/Q1 Predictions Mean      -21.6285
trainer/Q1 Predictions Std         1.0583
trainer/Q1 Predictions Max       -19.9798
trainer/Q1 Predictions Min       -24.0451
trainer/Q2 Predictions Mean      -21.5721
trainer/Q2 Predictions Std         1.05136
trainer/Q2 Predictions Max       -19.9893
trainer/Q2 Predictions Min       -24.0435
trainer/Q Targets Mean           -21.7752
trainer/Q Targets Std              2.269
trainer/Q Targets Max             -1
trainer/Q Targets Min            -24.574
trainer/Log Pis Mean              -0.921318
trainer/Log Pis Std                0.723704
trainer/Log Pis Max                0.377731
trainer/Log Pis Min               -3.5816
trainer/Policy mu Mean             0.110254
trainer/Policy mu Std              0.409883
trainer/Policy mu Max              1.13592
trainer/Policy mu Min             -1.05631
trainer/Policy log std Mean       -0.573326
trainer/Policy log std Std         0.185291
trainer/Policy log std Max        -0.193788
trainer/Policy log std Min        -0.985196
trainer/Alpha                      0.142487
trainer/Alpha Loss                -5.69139
exploration/num steps total     7000
exploration/num paths total       70
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1
exploration/Rewards Std            0
exploration/Rewards Max           -1
exploration/Rewards Min           -1
exploration/Returns Mean        -100
exploration/Returns Std            0
exploration/Returns Max         -100
exploration/Returns Min         -100
exploration/Actions Mean          -0.00630405
exploration/Actions Std            0.489663
exploration/Actions Max            0.982007
exploration/Actions Min           -0.97141
exploration/Num Paths              2
exploration/Average Returns     -100
evaluation/num steps total     34000
evaluation/num paths total       340
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.993158
evaluation/Rewards Std             0.0608931
evaluation/Rewards Max            -0.114458
evaluation/Rewards Min            -1
evaluation/Returns Mean          -99.3158
evaluation/Returns Std             1.39681
evaluation/Returns Max           -95.9525
evaluation/Returns Min          -100
evaluation/Actions Mean            0.0089668
evaluation/Actions Std             0.118774
evaluation/Actions Max             0.785758
evaluation/Actions Min            -0.80958
evaluation/Num Paths              10
evaluation/Average Returns       -99.3158
time/data storing (s)              0.00127328
time/evaluation sampling (s)       0.24453
time/exploration sampling (s)      0.0719318
time/logging (s)                   0.00378846
time/saving (s)                    0.00242885
time/training (s)                  1.02885
time/epoch (s)                     1.3528
time/total (s)                    46.0139
Epoch                             33
-----------------------------  --------------
2019-04-22 20:49:18.003703 PDT | [sac-pointmass-multitask-1_2019_04_22_20_48_30_0000--s-0] Epoch 34 finished
-----------------------------  --------------
replay_buffer/size              7200
trainer/QF1 Loss                   8.55125
trainer/QF2 Loss                   8.59763
trainer/Policy Loss               21.2663
trainer/Q1 Predictions Mean      -22.2101
trainer/Q1 Predictions Std         0.906677
trainer/Q1 Predictions Max       -20.6938
trainer/Q1 Predictions Min       -24.6505
trainer/Q2 Predictions Mean      -22.2011
trainer/Q2 Predictions Std         0.913184
trainer/Q2 Predictions Max       -20.7847
trainer/Q2 Predictions Min       -24.5433
trainer/Q Targets Mean           -22.1087
trainer/Q Targets Std              3.14498
trainer/Q Targets Max             -1
trainer/Q Targets Min            -25.0631
trainer/Log Pis Mean              -0.854818
trainer/Log Pis Std                0.833408
trainer/Log Pis Max                0.941888
trainer/Log Pis Min               -3.33516
trainer/Policy mu Mean             0.0491016
trainer/Policy mu Std              0.478482
trainer/Policy mu Max              0.994884
trainer/Policy mu Min             -1.22534
trainer/Policy log std Mean       -0.547228
trainer/Policy log std Std         0.147276
trainer/Policy log std Max        -0.147321
trainer/Policy log std Min        -0.892567
trainer/Alpha                      0.134727
trainer/Alpha Loss                -5.72169
exploration/num steps total     7200
exploration/num paths total       72
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1
exploration/Rewards Std            0
exploration/Rewards Max           -1
exploration/Rewards Min           -1
exploration/Returns Mean        -100
exploration/Returns Std            0
exploration/Returns Max         -100
exploration/Returns Min         -100
exploration/Actions Mean          -0.0112612
exploration/Actions Std            0.531991
exploration/Actions Max            0.951574
exploration/Actions Min           -0.948709
exploration/Num Paths              2
exploration/Average Returns     -100
evaluation/num steps total     35000
evaluation/num paths total       350
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.99957
evaluation/Rewards Std             0.00900327
evaluation/Rewards Max            -0.790677
evaluation/Rewards Min            -1
evaluation/Returns Mean          -99.957
evaluation/Returns Std             0.129065
evaluation/Returns Max           -99.5698
evaluation/Returns Min          -100
evaluation/Actions Mean            0.0212151
evaluation/Actions Std             0.258808
evaluation/Actions Max             0.768209
evaluation/Actions Min            -0.5023
evaluation/Num Paths              10
evaluation/Average Returns       -99.957
time/data storing (s)              0.00150944
time/evaluation sampling (s)       0.246875
time/exploration sampling (s)      0.0724215
time/logging (s)                   0.00363041
time/saving (s)                    0.00253854
time/training (s)                  1.01925
time/epoch (s)                     1.34622
time/total (s)                    47.3645
Epoch                             34
-----------------------------  --------------
2019-04-22 20:49:19.352046 PDT | [sac-pointmass-multitask-1_2019_04_22_20_48_30_0000--s-0] Epoch 35 finished
-----------------------------  --------------
replay_buffer/size              7400
trainer/QF1 Loss                   0.178296
trainer/QF2 Loss                   0.177288
trainer/Policy Loss               21.9057
trainer/Q1 Predictions Mean      -22.7383
trainer/Q1 Predictions Std         1.04056
trainer/Q1 Predictions Max       -20.9365
trainer/Q1 Predictions Min       -25.107
trainer/Q2 Predictions Mean      -22.7659
trainer/Q2 Predictions Std         1.05377
trainer/Q2 Predictions Max       -21.052
trainer/Q2 Predictions Min       -25.3132
trainer/Q Targets Mean           -22.9514
trainer/Q Targets Std              0.850042
trainer/Q Targets Max            -21.52
trainer/Q Targets Min            -25.0164
trainer/Log Pis Mean              -0.779198
trainer/Log Pis Std                0.772149
trainer/Log Pis Max                0.761539
trainer/Log Pis Min               -3.03872
trainer/Policy mu Mean             0.0403661
trainer/Policy mu Std              0.431228
trainer/Policy mu Max              1.00344
trainer/Policy mu Min             -1.08185
trainer/Policy log std Mean       -0.598138
trainer/Policy log std Std         0.175303
trainer/Policy log std Max        -0.205059
trainer/Policy log std Min        -1.00806
trainer/Alpha                      0.127356
trainer/Alpha Loss                -5.7265
exploration/num steps total     7400
exploration/num paths total       74
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1
exploration/Rewards Std            0
exploration/Rewards Max           -1
exploration/Rewards Min           -1
exploration/Returns Mean        -100
exploration/Returns Std            0
exploration/Returns Max         -100
exploration/Returns Min         -100
exploration/Actions Mean           0.00641604
exploration/Actions Std            0.450243
exploration/Actions Max            0.906305
exploration/Actions Min           -0.953219
exploration/Num Paths              2
exploration/Average Returns     -100
evaluation/num steps total     36000
evaluation/num paths total       360
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.996505
evaluation/Rewards Std             0.0460364
evaluation/Rewards Max            -0.105305
evaluation/Rewards Min            -1
evaluation/Returns Mean          -99.6505
evaluation/Returns Std             1.04863
evaluation/Returns Max           -96.5046
evaluation/Returns Min          -100
evaluation/Actions Mean            0.0141423
evaluation/Actions Std             0.32943
evaluation/Actions Max             0.750314
evaluation/Actions Min            -0.766267
evaluation/Num Paths              10
evaluation/Average Returns       -99.6505
time/data storing (s)              0.00118468
time/evaluation sampling (s)       0.24517
time/exploration sampling (s)      0.0692105
time/logging (s)                   0.00363851
time/saving (s)                    0.00248915
time/training (s)                  1.02108
time/epoch (s)                     1.34277
time/total (s)                    48.7117
Epoch                             35
-----------------------------  --------------
2019-04-22 20:49:20.705668 PDT | [sac-pointmass-multitask-1_2019_04_22_20_48_30_0000--s-0] Epoch 36 finished
-----------------------------  --------------
replay_buffer/size              7600
trainer/QF1 Loss                   0.163401
trainer/QF2 Loss                   0.160626
trainer/Policy Loss               22.3207
trainer/Q1 Predictions Mean      -23.1003
trainer/Q1 Predictions Std         0.775114
trainer/Q1 Predictions Max       -22.0089
trainer/Q1 Predictions Min       -25.048
trainer/Q2 Predictions Mean      -23.099
trainer/Q2 Predictions Std         0.781644
trainer/Q2 Predictions Max       -21.9851
trainer/Q2 Predictions Min       -25.0977
trainer/Q Targets Mean           -23.1919
trainer/Q Targets Std              0.836502
trainer/Q Targets Max            -21.9046
trainer/Q Targets Min            -25.3136
trainer/Log Pis Mean              -0.703609
trainer/Log Pis Std                0.757258
trainer/Log Pis Max                1.47183
trainer/Log Pis Min               -3.3121
trainer/Policy mu Mean             0.13653
trainer/Policy mu Std              0.463817
trainer/Policy mu Max              1.37635
trainer/Policy mu Min             -1.05186
trainer/Policy log std Mean       -0.632361
trainer/Policy log std Std         0.198967
trainer/Policy log std Max        -0.219837
trainer/Policy log std Min        -1.05134
trainer/Alpha                      0.120351
trainer/Alpha Loss                -5.72371
exploration/num steps total     7600
exploration/num paths total       76
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1
exploration/Rewards Std            0
exploration/Rewards Max           -1
exploration/Rewards Min           -1
exploration/Returns Mean        -100
exploration/Returns Std            0
exploration/Returns Max         -100
exploration/Returns Min         -100
exploration/Actions Mean           0.136985
exploration/Actions Std            0.484065
exploration/Actions Max            0.973545
exploration/Actions Min           -0.966609
exploration/Num Paths              2
exploration/Average Returns     -100
evaluation/num steps total     37000
evaluation/num paths total       370
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.935109
evaluation/Rewards Std             0.108512
evaluation/Rewards Max            -0.491134
evaluation/Rewards Min            -1
evaluation/Returns Mean          -93.5109
evaluation/Returns Std            10.1022
evaluation/Returns Max           -75.5271
evaluation/Returns Min          -100
evaluation/Actions Mean            0.012799
evaluation/Actions Std             0.111859
evaluation/Actions Max             0.864645
evaluation/Actions Min            -0.696087
evaluation/Num Paths              10
evaluation/Average Returns       -93.5109
time/data storing (s)              0.00121623
time/evaluation sampling (s)       0.239855
time/exploration sampling (s)      0.0721078
time/logging (s)                   0.0035398
time/saving (s)                    0.00241024
time/training (s)                  1.02874
time/epoch (s)                     1.34787
time/total (s)                    50.064
Epoch                             36
-----------------------------  --------------
2019-04-22 20:49:22.063877 PDT | [sac-pointmass-multitask-1_2019_04_22_20_48_30_0000--s-0] Epoch 37 finished
-----------------------------  --------------
replay_buffer/size              7800
trainer/QF1 Loss                   0.382904
trainer/QF2 Loss                   0.396237
trainer/Policy Loss               22.91
trainer/Q1 Predictions Mean      -23.6915
trainer/Q1 Predictions Std         1.24812
trainer/Q1 Predictions Max       -20.9526
trainer/Q1 Predictions Min       -26.7388
trainer/Q2 Predictions Mean      -23.6745
trainer/Q2 Predictions Std         1.25085
trainer/Q2 Predictions Max       -20.9992
trainer/Q2 Predictions Min       -26.6083
trainer/Q Targets Mean           -23.947
trainer/Q Targets Std              0.936687
trainer/Q Targets Max            -22.4866
trainer/Q Targets Min            -26.2738
trainer/Log Pis Mean              -0.631973
trainer/Log Pis Std                0.969394
trainer/Log Pis Max                1.07947
trainer/Log Pis Min               -4.3516
trainer/Policy mu Mean             0.098587
trainer/Policy mu Std              0.471653
trainer/Policy mu Max              1.19663
trainer/Policy mu Min             -1.1271
trainer/Policy log std Mean       -0.666651
trainer/Policy log std Std         0.202114
trainer/Policy log std Max        -0.206022
trainer/Policy log std Min        -1.09984
trainer/Alpha                      0.113843
trainer/Alpha Loss                -5.71838
exploration/num steps total     7800
exploration/num paths total       78
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.908121
exploration/Rewards Std            0.211337
exploration/Rewards Max           -0.086026
exploration/Rewards Min           -1
exploration/Returns Mean         -90.8121
exploration/Returns Std            1.90835
exploration/Returns Max          -88.9037
exploration/Returns Min          -92.7204
exploration/Actions Mean           0.006947
exploration/Actions Std            0.411022
exploration/Actions Max            0.928936
exploration/Actions Min           -0.866245
exploration/Num Paths              2
exploration/Average Returns      -90.8121
evaluation/num steps total     38000
evaluation/num paths total       380
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.889201
evaluation/Rewards Std             0.16411
evaluation/Rewards Max            -0.0957536
evaluation/Rewards Min            -1
evaluation/Returns Mean          -88.9201
evaluation/Returns Std            14.7856
evaluation/Returns Max           -65.967
evaluation/Returns Min          -100
evaluation/Actions Mean            0.00214326
evaluation/Actions Std             0.127756
evaluation/Actions Max             0.753844
evaluation/Actions Min            -0.823653
evaluation/Num Paths              10
evaluation/Average Returns       -88.9201
time/data storing (s)              0.00121084
time/evaluation sampling (s)       0.241571
time/exploration sampling (s)      0.0705671
time/logging (s)                   0.00384474
time/saving (s)                    0.00258101
time/training (s)                  1.033
time/epoch (s)                     1.35277
time/total (s)                    51.4211
Epoch                             37
-----------------------------  --------------
2019-04-22 20:49:23.415027 PDT | [sac-pointmass-multitask-1_2019_04_22_20_48_30_0000--s-0] Epoch 38 finished
-----------------------------  --------------
replay_buffer/size              8000
trainer/QF1 Loss                   0.158836
trainer/QF2 Loss                   0.158039
trainer/Policy Loss               22.7364
trainer/Q1 Predictions Mean      -23.6402
trainer/Q1 Predictions Std         0.845448
trainer/Q1 Predictions Max       -22.2185
trainer/Q1 Predictions Min       -26.3754
trainer/Q2 Predictions Mean      -23.6431
trainer/Q2 Predictions Std         0.853506
trainer/Q2 Predictions Max       -22.2771
trainer/Q2 Predictions Min       -26.251
trainer/Q Targets Mean           -23.9532
trainer/Q Targets Std              0.738707
trainer/Q Targets Max            -22.8553
trainer/Q Targets Min            -26.3459
trainer/Log Pis Mean              -0.829019
trainer/Log Pis Std                0.805885
trainer/Log Pis Max                0.644522
trainer/Log Pis Min               -3.7505
trainer/Policy mu Mean             0.11071
trainer/Policy mu Std              0.444056
trainer/Policy mu Max              1.24182
trainer/Policy mu Min             -0.775876
trainer/Policy log std Mean       -0.68035
trainer/Policy log std Std         0.189601
trainer/Policy log std Max        -0.252805
trainer/Policy log std Min        -1.07694
trainer/Alpha                      0.107651
trainer/Alpha Loss                -6.30468
exploration/num steps total     8000
exploration/num paths total       80
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1
exploration/Rewards Std            0
exploration/Rewards Max           -1
exploration/Rewards Min           -1
exploration/Returns Mean        -100
exploration/Returns Std            0
exploration/Returns Max         -100
exploration/Returns Min         -100
exploration/Actions Mean           0.0248741
exploration/Actions Std            0.416378
exploration/Actions Max            0.946615
exploration/Actions Min           -0.957294
exploration/Num Paths              2
exploration/Average Returns     -100
evaluation/num steps total     39000
evaluation/num paths total       390
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.99693
evaluation/Rewards Std             0.0327531
evaluation/Rewards Max            -0.441919
evaluation/Rewards Min            -1
evaluation/Returns Mean          -99.693
evaluation/Returns Std             0.665764
evaluation/Returns Max           -97.8895
evaluation/Returns Min          -100
evaluation/Actions Mean           -0.00734205
evaluation/Actions Std             0.121409
evaluation/Actions Max             0.84836
evaluation/Actions Min            -0.602064
evaluation/Num Paths              10
evaluation/Average Returns       -99.693
time/data storing (s)              0.00131919
time/evaluation sampling (s)       0.243547
time/exploration sampling (s)      0.0702849
time/logging (s)                   0.00371995
time/saving (s)                    0.00254054
time/training (s)                  1.0237
time/epoch (s)                     1.34511
time/total (s)                    52.7708
Epoch                             38
-----------------------------  --------------
2019-04-22 20:49:24.772146 PDT | [sac-pointmass-multitask-1_2019_04_22_20_48_30_0000--s-0] Epoch 39 finished
-----------------------------  ---------------
replay_buffer/size              8200
trainer/QF1 Loss                   5.51471
trainer/QF2 Loss                   5.58113
trainer/Policy Loss               23.6295
trainer/Q1 Predictions Mean      -24.2642
trainer/Q1 Predictions Std         0.853553
trainer/Q1 Predictions Max       -22.7899
trainer/Q1 Predictions Min       -26.2815
trainer/Q2 Predictions Mean      -24.315
trainer/Q2 Predictions Std         0.862276
trainer/Q2 Predictions Max       -23.0611
trainer/Q2 Predictions Min       -26.374
trainer/Q Targets Mean           -24.3681
trainer/Q Targets Std              2.48432
trainer/Q Targets Max             -1
trainer/Q Targets Min            -26.8002
trainer/Log Pis Mean              -0.532734
trainer/Log Pis Std                0.894531
trainer/Log Pis Max                1.27892
trainer/Log Pis Min               -4.48835
trainer/Policy mu Mean             0.116007
trainer/Policy mu Std              0.539044
trainer/Policy mu Max              1.26405
trainer/Policy mu Min             -1.33104
trainer/Policy log std Mean       -0.664497
trainer/Policy log std Std         0.186372
trainer/Policy log std Max        -0.179219
trainer/Policy log std Min        -1.09635
trainer/Alpha                      0.101843
trainer/Alpha Loss                -5.78488
exploration/num steps total     8200
exploration/num paths total       82
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1
exploration/Rewards Std            0
exploration/Rewards Max           -1
exploration/Rewards Min           -1
exploration/Returns Mean        -100
exploration/Returns Std            0
exploration/Returns Max         -100
exploration/Returns Min         -100
exploration/Actions Mean          -0.0474882
exploration/Actions Std            0.483066
exploration/Actions Max            0.94998
exploration/Actions Min           -0.908672
exploration/Num Paths              2
exploration/Average Returns     -100
evaluation/num steps total     40000
evaluation/num paths total       400
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.997962
evaluation/Rewards Std             0.0343751
evaluation/Rewards Max            -0.251387
evaluation/Rewards Min            -1
evaluation/Returns Mean          -99.7962
evaluation/Returns Std             0.611265
evaluation/Returns Max           -97.9624
evaluation/Returns Min          -100
evaluation/Actions Mean            0.000525584
evaluation/Actions Std             0.223824
evaluation/Actions Max             0.815469
evaluation/Actions Min            -0.756067
evaluation/Num Paths              10
evaluation/Average Returns       -99.7962
time/data storing (s)              0.00116329
time/evaluation sampling (s)       0.242726
time/exploration sampling (s)      0.0716141
time/logging (s)                   0.00355481
time/saving (s)                    0.00246241
time/training (s)                  1.0294
time/epoch (s)                     1.35092
time/total (s)                    54.1263
Epoch                             39
-----------------------------  ---------------
2019-04-22 20:49:26.134356 PDT | [sac-pointmass-multitask-1_2019_04_22_20_48_30_0000--s-0] Epoch 40 finished
-----------------------------  --------------
replay_buffer/size              8400
trainer/QF1 Loss                   0.151392
trainer/QF2 Loss                   0.158693
trainer/Policy Loss               24.091
trainer/Q1 Predictions Mean      -24.7357
trainer/Q1 Predictions Std         0.982448
trainer/Q1 Predictions Max       -23.2163
trainer/Q1 Predictions Min       -27.2414
trainer/Q2 Predictions Mean      -24.7367
trainer/Q2 Predictions Std         0.974556
trainer/Q2 Predictions Max       -23.2711
trainer/Q2 Predictions Min       -27.1625
trainer/Q Targets Mean           -25.0007
trainer/Q Targets Std              0.876832
trainer/Q Targets Max            -23.7162
trainer/Q Targets Min            -27.4395
trainer/Log Pis Mean              -0.478826
trainer/Log Pis Std                0.990963
trainer/Log Pis Max                1.44724
trainer/Log Pis Min               -2.91726
trainer/Policy mu Mean             0.0634327
trainer/Policy mu Std              0.589436
trainer/Policy mu Max              1.19002
trainer/Policy mu Min             -1.45226
trainer/Policy log std Mean       -0.701854
trainer/Policy log std Std         0.203352
trainer/Policy log std Max        -0.172652
trainer/Policy log std Min        -1.17204
trainer/Alpha                      0.0963996
trainer/Alpha Loss                -5.79792
exploration/num steps total     8400
exploration/num paths total       84
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.988632
exploration/Rewards Std            0.0814972
exploration/Rewards Max           -0.126006
exploration/Rewards Min           -1
exploration/Returns Mean         -98.8632
exploration/Returns Std            1.13678
exploration/Returns Max          -97.7264
exploration/Returns Min         -100
exploration/Actions Mean          -0.0839152
exploration/Actions Std            0.463983
exploration/Actions Max            0.946527
exploration/Actions Min           -0.923917
exploration/Num Paths              2
exploration/Average Returns      -98.8632
evaluation/num steps total     41000
evaluation/num paths total       410
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.994424
evaluation/Rewards Std             0.0490271
evaluation/Rewards Max            -0.342832
evaluation/Rewards Min            -1
evaluation/Returns Mean          -99.4424
evaluation/Returns Std             0.880984
evaluation/Returns Max           -97.688
evaluation/Returns Min          -100
evaluation/Actions Mean           -0.0613797
evaluation/Actions Std             0.235819
evaluation/Actions Max             0.820551
evaluation/Actions Min            -0.871185
evaluation/Num Paths              10
evaluation/Average Returns       -99.4424
time/data storing (s)              0.00120214
time/evaluation sampling (s)       0.244544
time/exploration sampling (s)      0.0717998
time/logging (s)                   0.00362836
time/saving (s)                    0.00205143
time/training (s)                  1.0332
time/epoch (s)                     1.35643
time/total (s)                    55.4871
Epoch                             40
-----------------------------  --------------
2019-04-22 20:49:27.492024 PDT | [sac-pointmass-multitask-1_2019_04_22_20_48_30_0000--s-0] Epoch 41 finished
-----------------------------  --------------
replay_buffer/size              8600
trainer/QF1 Loss                   0.102431
trainer/QF2 Loss                   0.0975767
trainer/Policy Loss               25.0357
trainer/Q1 Predictions Mean      -25.4202
trainer/Q1 Predictions Std         0.859555
trainer/Q1 Predictions Max       -24.1939
trainer/Q1 Predictions Min       -27.1321
trainer/Q2 Predictions Mean      -25.4155
trainer/Q2 Predictions Std         0.891033
trainer/Q2 Predictions Max       -24.0273
trainer/Q2 Predictions Min       -27.2463
trainer/Q Targets Mean           -25.314
trainer/Q Targets Std              0.851775
trainer/Q Targets Max            -23.9448
trainer/Q Targets Min            -27.1908
trainer/Log Pis Mean              -0.222119
trainer/Log Pis Std                1.07064
trainer/Log Pis Max                2.2019
trainer/Log Pis Min               -3.10434
trainer/Policy mu Mean             0.157628
trainer/Policy mu Std              0.629374
trainer/Policy mu Max              1.29261
trainer/Policy mu Min             -1.40129
trainer/Policy log std Mean       -0.758054
trainer/Policy log std Std         0.227592
trainer/Policy log std Max        -0.206401
trainer/Policy log std Min        -1.24312
trainer/Alpha                      0.0913117
trainer/Alpha Loss                -5.31802
exploration/num steps total     8600
exploration/num paths total       86
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1
exploration/Rewards Std            0
exploration/Rewards Max           -1
exploration/Rewards Min           -1
exploration/Returns Mean        -100
exploration/Returns Std            0
exploration/Returns Max         -100
exploration/Returns Min         -100
exploration/Actions Mean           0.0245584
exploration/Actions Std            0.464127
exploration/Actions Max            0.988512
exploration/Actions Min           -0.840581
exploration/Num Paths              2
exploration/Average Returns     -100
evaluation/num steps total     42000
evaluation/num paths total       420
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1
evaluation/Rewards Std             0
evaluation/Rewards Max            -1
evaluation/Rewards Min            -1
evaluation/Returns Mean         -100
evaluation/Returns Std             0
evaluation/Returns Max          -100
evaluation/Returns Min          -100
evaluation/Actions Mean            0.0321092
evaluation/Actions Std             0.308453
evaluation/Actions Max             0.869936
evaluation/Actions Min            -0.543586
evaluation/Num Paths              10
evaluation/Average Returns      -100
time/data storing (s)              0.00126317
time/evaluation sampling (s)       0.243839
time/exploration sampling (s)      0.0710636
time/logging (s)                   0.00339424
time/saving (s)                    0.00244142
time/training (s)                  1.02973
time/epoch (s)                     1.35173
time/total (s)                    56.8433
Epoch                             41
-----------------------------  --------------
2019-04-22 20:49:28.854597 PDT | [sac-pointmass-multitask-1_2019_04_22_20_48_30_0000--s-0] Epoch 42 finished
-----------------------------  ---------------
replay_buffer/size              8800
trainer/QF1 Loss                  11.6801
trainer/QF2 Loss                  11.7524
trainer/Policy Loss               24.8941
trainer/Q1 Predictions Mean      -25.3288
trainer/Q1 Predictions Std         0.955971
trainer/Q1 Predictions Max       -24.1464
trainer/Q1 Predictions Min       -27.6772
trainer/Q2 Predictions Mean      -25.3219
trainer/Q2 Predictions Std         0.948813
trainer/Q2 Predictions Max       -24.2111
trainer/Q2 Predictions Min       -27.8364
trainer/Q Targets Mean           -25.1035
trainer/Q Targets Std              3.55581
trainer/Q Targets Max             -1
trainer/Q Targets Min            -27.8126
trainer/Log Pis Mean              -0.315535
trainer/Log Pis Std                0.98007
trainer/Log Pis Max                2.03906
trainer/Log Pis Min               -3.6866
trainer/Policy mu Mean             0.205579
trainer/Policy mu Std              0.554476
trainer/Policy mu Max              1.40347
trainer/Policy mu Min             -1.51846
trainer/Policy log std Mean       -0.765605
trainer/Policy log std Std         0.226633
trainer/Policy log std Max        -0.180198
trainer/Policy log std Min        -1.19133
trainer/Alpha                      0.0865942
trainer/Alpha Loss                -5.66442
exploration/num steps total     8800
exploration/num paths total       88
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.996651
exploration/Rewards Std            0.0324118
exploration/Rewards Max           -0.567109
exploration/Rewards Min           -1
exploration/Returns Mean         -99.6651
exploration/Returns Std            0.33491
exploration/Returns Max          -99.3302
exploration/Returns Min         -100
exploration/Actions Mean           0.0941274
exploration/Actions Std            0.4549
exploration/Actions Max            0.97141
exploration/Actions Min           -0.84477
exploration/Num Paths              2
exploration/Average Returns      -99.6651
evaluation/num steps total     43000
evaluation/num paths total       430
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.999988
evaluation/Rewards Std             0.000365227
evaluation/Rewards Max            -0.988445
evaluation/Rewards Min            -1
evaluation/Returns Mean          -99.9988
evaluation/Returns Std             0.00346659
evaluation/Returns Max           -99.9884
evaluation/Returns Min          -100
evaluation/Actions Mean            0.0590988
evaluation/Actions Std             0.300425
evaluation/Actions Max             0.861902
evaluation/Actions Min            -0.873467
evaluation/Num Paths              10
evaluation/Average Returns       -99.9988
time/data storing (s)              0.00121259
time/evaluation sampling (s)       0.245746
time/exploration sampling (s)      0.0740723
time/logging (s)                   0.00381618
time/saving (s)                    0.00261733
time/training (s)                  1.0298
time/epoch (s)                     1.35726
time/total (s)                    58.2049
Epoch                             42
-----------------------------  ---------------
2019-04-22 20:49:30.202213 PDT | [sac-pointmass-multitask-1_2019_04_22_20_48_30_0000--s-0] Epoch 43 finished
-----------------------------  ---------------
replay_buffer/size              9000
trainer/QF1 Loss                   5.86138
trainer/QF2 Loss                   5.65757
trainer/Policy Loss               25.0681
trainer/Q1 Predictions Mean      -25.5545
trainer/Q1 Predictions Std         0.950472
trainer/Q1 Predictions Max       -24.3315
trainer/Q1 Predictions Min       -28.1677
trainer/Q2 Predictions Mean      -25.5872
trainer/Q2 Predictions Std         0.970951
trainer/Q2 Predictions Max       -24.4228
trainer/Q2 Predictions Min       -28.3122
trainer/Q Targets Mean           -25.5819
trainer/Q Targets Std              2.61067
trainer/Q Targets Max             -1
trainer/Q Targets Min            -28.2326
trainer/Log Pis Mean              -0.408847
trainer/Log Pis Std                0.856743
trainer/Log Pis Max                1.9594
trainer/Log Pis Min               -3.27108
trainer/Policy mu Mean            -0.000666003
trainer/Policy mu Std              0.498672
trainer/Policy mu Max              1.47365
trainer/Policy mu Min             -1.26559
trainer/Policy log std Mean       -0.810112
trainer/Policy log std Std         0.25136
trainer/Policy log std Max        -0.191154
trainer/Policy log std Min        -1.2555
trainer/Alpha                      0.0819483
trainer/Alpha Loss                -6.02546
exploration/num steps total     9000
exploration/num paths total       90
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.825761
exploration/Rewards Std            0.258293
exploration/Rewards Max           -0.0867629
exploration/Rewards Min           -1
exploration/Returns Mean         -82.5761
exploration/Returns Std           17.4239
exploration/Returns Max          -65.1522
exploration/Returns Min         -100
exploration/Actions Mean          -0.00339543
exploration/Actions Std            0.352419
exploration/Actions Max            0.976041
exploration/Actions Min           -0.86348
exploration/Num Paths              2
exploration/Average Returns      -82.5761
evaluation/num steps total     44000
evaluation/num paths total       440
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.787463
evaluation/Rewards Std             0.27724
evaluation/Rewards Max            -0.0465261
evaluation/Rewards Min            -1
evaluation/Returns Mean          -78.7463
evaluation/Returns Std            26.3209
evaluation/Returns Max           -42.3574
evaluation/Returns Min          -100
evaluation/Actions Mean            0.000833086
evaluation/Actions Std             0.113551
evaluation/Actions Max             0.902958
evaluation/Actions Min            -0.843944
evaluation/Num Paths              10
evaluation/Average Returns       -78.7463
time/data storing (s)              0.00122916
time/evaluation sampling (s)       0.234856
time/exploration sampling (s)      0.0714392
time/logging (s)                   0.00374973
time/saving (s)                    0.00244504
time/training (s)                  1.02813
time/epoch (s)                     1.34185
time/total (s)                    59.551
Epoch                             43
-----------------------------  ---------------
2019-04-22 20:49:31.549393 PDT | [sac-pointmass-multitask-1_2019_04_22_20_48_30_0000--s-0] Epoch 44 finished
-----------------------------  --------------
replay_buffer/size              9200
trainer/QF1 Loss                   6.89523
trainer/QF2 Loss                   6.92281
trainer/Policy Loss               25.6336
trainer/Q1 Predictions Mean      -26.0246
trainer/Q1 Predictions Std         1.01178
trainer/Q1 Predictions Max       -24.5545
trainer/Q1 Predictions Min       -28.1804
trainer/Q2 Predictions Mean      -25.9768
trainer/Q2 Predictions Std         1.04822
trainer/Q2 Predictions Max       -24.4095
trainer/Q2 Predictions Min       -28.3527
trainer/Q Targets Mean           -25.9835
trainer/Q Targets Std              2.6526
trainer/Q Targets Max             -1
trainer/Q Targets Min            -28.133
trainer/Log Pis Mean              -0.250943
trainer/Log Pis Std                0.870504
trainer/Log Pis Max                2.23758
trainer/Log Pis Min               -2.59762
trainer/Policy mu Mean             0.0847045
trainer/Policy mu Std              0.526692
trainer/Policy mu Max              1.36335
trainer/Policy mu Min             -1.18624
trainer/Policy log std Mean       -0.857789
trainer/Policy log std Std         0.242837
trainer/Policy log std Max        -0.291181
trainer/Policy log std Min        -1.29494
trainer/Alpha                      0.0775915
trainer/Alpha Loss                -5.75347
exploration/num steps total     9200
exploration/num paths total       92
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1
exploration/Rewards Std            0
exploration/Rewards Max           -1
exploration/Rewards Min           -1
exploration/Returns Mean        -100
exploration/Returns Std            0
exploration/Returns Max         -100
exploration/Returns Min         -100
exploration/Actions Mean          -0.0287027
exploration/Actions Std            0.378301
exploration/Actions Max            0.826426
exploration/Actions Min           -0.898045
exploration/Num Paths              2
exploration/Average Returns     -100
evaluation/num steps total     45000
evaluation/num paths total       450
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.961255
evaluation/Rewards Std             0.123618
evaluation/Rewards Max            -0.555208
evaluation/Rewards Min            -1
evaluation/Returns Mean          -96.1255
evaluation/Returns Std            11.6236
evaluation/Returns Max           -61.2546
evaluation/Returns Min          -100
evaluation/Actions Mean            0.0186269
evaluation/Actions Std             0.119407
evaluation/Actions Max             0.904192
evaluation/Actions Min            -0.692287
evaluation/Num Paths              10
evaluation/Average Returns       -96.1255
time/data storing (s)              0.00124099
time/evaluation sampling (s)       0.238996
time/exploration sampling (s)      0.0701186
time/logging (s)                   0.00375446
time/saving (s)                    0.00251312
time/training (s)                  1.02502
time/epoch (s)                     1.34165
time/total (s)                    60.8968
Epoch                             44
-----------------------------  --------------
2019-04-22 20:49:32.895138 PDT | [sac-pointmass-multitask-1_2019_04_22_20_48_30_0000--s-0] Epoch 45 finished
-----------------------------  --------------
replay_buffer/size              9400
trainer/QF1 Loss                   0.153219
trainer/QF2 Loss                   0.184662
trainer/Policy Loss               26.0309
trainer/Q1 Predictions Mean      -26.2649
trainer/Q1 Predictions Std         1.02885
trainer/Q1 Predictions Max       -24.9647
trainer/Q1 Predictions Min       -29.2437
trainer/Q2 Predictions Mean      -26.1968
trainer/Q2 Predictions Std         1.02935
trainer/Q2 Predictions Max       -24.8846
trainer/Q2 Predictions Min       -29.167
trainer/Q Targets Mean           -26.4592
trainer/Q Targets Std              0.8459
trainer/Q Targets Max            -25.375
trainer/Q Targets Min            -28.9491
trainer/Log Pis Mean              -0.0541261
trainer/Log Pis Std                1.05211
trainer/Log Pis Max                2.88154
trainer/Log Pis Min               -4.70437
trainer/Policy mu Mean             0.11451
trainer/Policy mu Std              0.56816
trainer/Policy mu Max              1.68203
trainer/Policy mu Min             -1.31432
trainer/Policy log std Mean       -0.932028
trainer/Policy log std Std         0.243303
trainer/Policy log std Max        -0.478459
trainer/Policy log std Min        -1.34767
trainer/Alpha                      0.0735086
trainer/Alpha Loss                -5.36147
exploration/num steps total     9400
exploration/num paths total       94
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1
exploration/Rewards Std            0
exploration/Rewards Max           -1
exploration/Rewards Min           -1
exploration/Returns Mean        -100
exploration/Returns Std            0
exploration/Returns Max         -100
exploration/Returns Min         -100
exploration/Actions Mean           0.0177373
exploration/Actions Std            0.387603
exploration/Actions Max            0.940863
exploration/Actions Min           -0.940502
exploration/Num Paths              2
exploration/Average Returns     -100
evaluation/num steps total     46000
evaluation/num paths total       460
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.942782
evaluation/Rewards Std             0.0984735
evaluation/Rewards Max            -0.367453
evaluation/Rewards Min            -1
evaluation/Returns Mean          -94.2782
evaluation/Returns Std             8.76398
evaluation/Returns Max           -80.0683
evaluation/Returns Min          -100
evaluation/Actions Mean           -0.0102867
evaluation/Actions Std             0.125937
evaluation/Actions Max             0.915824
evaluation/Actions Min            -0.858288
evaluation/Num Paths              10
evaluation/Average Returns       -94.2782
time/data storing (s)              0.00133174
time/evaluation sampling (s)       0.242266
time/exploration sampling (s)      0.0717029
time/logging (s)                   0.00354182
time/saving (s)                    0.00243281
time/training (s)                  1.01863
time/epoch (s)                     1.33991
time/total (s)                    62.2408
Epoch                             45
-----------------------------  --------------
2019-04-22 20:49:34.258453 PDT | [sac-pointmass-multitask-1_2019_04_22_20_48_30_0000--s-0] Epoch 46 finished
-----------------------------  --------------
replay_buffer/size              9600
trainer/QF1 Loss                   0.171123
trainer/QF2 Loss                   0.155967
trainer/Policy Loss               26.2664
trainer/Q1 Predictions Mean      -26.6463
trainer/Q1 Predictions Std         1.00678
trainer/Q1 Predictions Max       -25.2844
trainer/Q1 Predictions Min       -29.5211
trainer/Q2 Predictions Mean      -26.6822
trainer/Q2 Predictions Std         1.01212
trainer/Q2 Predictions Max       -25.3275
trainer/Q2 Predictions Min       -29.5573
trainer/Q Targets Mean           -26.9717
trainer/Q Targets Std              0.897713
trainer/Q Targets Max            -25.8968
trainer/Q Targets Min            -29.502
trainer/Log Pis Mean              -0.294742
trainer/Log Pis Std                0.901933
trainer/Log Pis Max                1.29479
trainer/Log Pis Min               -3.02838
trainer/Policy mu Mean             0.0359643
trainer/Policy mu Std              0.594158
trainer/Policy mu Max              1.46231
trainer/Policy mu Min             -1.64305
trainer/Policy log std Mean       -0.878123
trainer/Policy log std Std         0.264521
trainer/Policy log std Max        -0.240618
trainer/Policy log std Min        -1.40025
trainer/Alpha                      0.0696613
trainer/Alpha Loss                -6.11283
exploration/num steps total     9600
exploration/num paths total       96
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.981727
exploration/Rewards Std            0.0862191
exploration/Rewards Max           -0.464107
exploration/Rewards Min           -1
exploration/Returns Mean         -98.1727
exploration/Returns Std            1.01199
exploration/Returns Max          -97.1607
exploration/Returns Min          -99.1847
exploration/Actions Mean           0.0358211
exploration/Actions Std            0.325727
exploration/Actions Max            0.915658
exploration/Actions Min           -0.743803
exploration/Num Paths              2
exploration/Average Returns      -98.1727
evaluation/num steps total     47000
evaluation/num paths total       470
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.995154
evaluation/Rewards Std             0.0449298
evaluation/Rewards Max            -0.342711
evaluation/Rewards Min            -1
evaluation/Returns Mean          -99.5154
evaluation/Returns Std             0.706246
evaluation/Returns Max           -97.8444
evaluation/Returns Min          -100
evaluation/Actions Mean            0.00273871
evaluation/Actions Std             0.191893
evaluation/Actions Max             0.813965
evaluation/Actions Min            -0.88017
evaluation/Num Paths              10
evaluation/Average Returns       -99.5154
time/data storing (s)              0.00120465
time/evaluation sampling (s)       0.250737
time/exploration sampling (s)      0.0716568
time/logging (s)                   0.00366435
time/saving (s)                    0.00239988
time/training (s)                  1.0282
time/epoch (s)                     1.35787
time/total (s)                    63.6028
Epoch                             46
-----------------------------  --------------
2019-04-22 20:49:35.610601 PDT | [sac-pointmass-multitask-1_2019_04_22_20_48_30_0000--s-0] Epoch 47 finished
-----------------------------  --------------
replay_buffer/size              9800
trainer/QF1 Loss                  13.2325
trainer/QF2 Loss                  13.3333
trainer/Policy Loss               26.8303
trainer/Q1 Predictions Mean      -27.0966
trainer/Q1 Predictions Std         0.761807
trainer/Q1 Predictions Max       -25.8108
trainer/Q1 Predictions Min       -29.0015
trainer/Q2 Predictions Mean      -27.09
trainer/Q2 Predictions Std         0.789144
trainer/Q2 Predictions Max       -25.8946
trainer/Q2 Predictions Min       -29.0725
trainer/Q Targets Mean           -26.638
trainer/Q Targets Std              3.73797
trainer/Q Targets Max             -1
trainer/Q Targets Min            -29.0887
trainer/Log Pis Mean              -0.166562
trainer/Log Pis Std                0.918539
trainer/Log Pis Max                2.58394
trainer/Log Pis Min               -3.70286
trainer/Policy mu Mean             0.0814219
trainer/Policy mu Std              0.531314
trainer/Policy mu Max              1.58821
trainer/Policy mu Min             -1.17701
trainer/Policy log std Mean       -0.957033
trainer/Policy log std Std         0.305534
trainer/Policy log std Max        -0.279332
trainer/Policy log std Min        -1.45613
trainer/Alpha                      0.0660129
trainer/Alpha Loss                -5.88792
exploration/num steps total     9800
exploration/num paths total       98
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.981759
exploration/Rewards Std            0.0649009
exploration/Rewards Max           -0.393688
exploration/Rewards Min           -1
exploration/Returns Mean         -98.1759
exploration/Returns Std            1.34458
exploration/Returns Max          -96.8313
exploration/Returns Min          -99.5205
exploration/Actions Mean           0.0345842
exploration/Actions Std            0.299499
exploration/Actions Max            0.941859
exploration/Actions Min           -0.745397
exploration/Num Paths              2
exploration/Average Returns      -98.1759
evaluation/num steps total     48000
evaluation/num paths total       480
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.977854
evaluation/Rewards Std             0.10957
evaluation/Rewards Max            -0.0993843
evaluation/Rewards Min            -1
evaluation/Returns Mean          -97.7854
evaluation/Returns Std             2.21493
evaluation/Returns Max           -95.4885
evaluation/Returns Min          -100
evaluation/Actions Mean           -0.0191331
evaluation/Actions Std             0.141263
evaluation/Actions Max             0.910061
evaluation/Actions Min            -0.786904
evaluation/Num Paths              10
evaluation/Average Returns       -97.7854
time/data storing (s)              0.00128868
time/evaluation sampling (s)       0.237322
time/exploration sampling (s)      0.0710453
time/logging (s)                   0.00350519
time/saving (s)                    0.00227538
time/training (s)                  1.03104
time/epoch (s)                     1.34648
time/total (s)                    64.9535
Epoch                             47
-----------------------------  --------------
2019-04-22 20:49:36.974708 PDT | [sac-pointmass-multitask-1_2019_04_22_20_48_30_0000--s-0] Epoch 48 finished
-----------------------------  --------------
replay_buffer/size             10000
trainer/QF1 Loss                   7.09454
trainer/QF2 Loss                   7.26394
trainer/Policy Loss               26.1932
trainer/Q1 Predictions Mean      -26.6125
trainer/Q1 Predictions Std         0.759254
trainer/Q1 Predictions Max       -25.4646
trainer/Q1 Predictions Min       -29.071
trainer/Q2 Predictions Mean      -26.5656
trainer/Q2 Predictions Std         0.735754
trainer/Q2 Predictions Max       -25.4733
trainer/Q2 Predictions Min       -28.8994
trainer/Q Targets Mean           -27.2428
trainer/Q Targets Std              2.75084
trainer/Q Targets Max             -1
trainer/Q Targets Min            -30.4449
trainer/Log Pis Mean              -0.295159
trainer/Log Pis Std                0.978705
trainer/Log Pis Max                1.81475
trainer/Log Pis Min               -5.45584
trainer/Policy mu Mean             0.0183059
trainer/Policy mu Std              0.514416
trainer/Policy mu Max              1.47689
trainer/Policy mu Min             -1.28456
trainer/Policy log std Mean       -0.908687
trainer/Policy log std Std         0.276994
trainer/Policy log std Max        -0.251926
trainer/Policy log std Min        -1.50406
trainer/Alpha                      0.0625116
trainer/Alpha Loss                -6.36247
exploration/num steps total    10000
exploration/num paths total      100
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.88208
exploration/Rewards Std            0.198617
exploration/Rewards Max           -0.112011
exploration/Rewards Min           -1
exploration/Returns Mean         -88.208
exploration/Returns Std           11.792
exploration/Returns Max          -76.4161
exploration/Returns Min         -100
exploration/Actions Mean           0.01054
exploration/Actions Std            0.363089
exploration/Actions Max            0.870076
exploration/Actions Min           -0.897765
exploration/Num Paths              2
exploration/Average Returns      -88.208
evaluation/num steps total     49000
evaluation/num paths total       490
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1
evaluation/Rewards Std             0
evaluation/Rewards Max            -1
evaluation/Rewards Min            -1
evaluation/Returns Mean         -100
evaluation/Returns Std             0
evaluation/Returns Max          -100
evaluation/Returns Min          -100
evaluation/Actions Mean           -0.00404027
evaluation/Actions Std             0.202825
evaluation/Actions Max             0.906019
evaluation/Actions Min            -0.802937
evaluation/Num Paths              10
evaluation/Average Returns      -100
time/data storing (s)              0.00126242
time/evaluation sampling (s)       0.246238
time/exploration sampling (s)      0.0708329
time/logging (s)                   0.00365882
time/saving (s)                    0.00255871
time/training (s)                  1.03433
time/epoch (s)                     1.35888
time/total (s)                    66.3163
Epoch                             48
-----------------------------  --------------
2019-04-22 20:49:38.345638 PDT | [sac-pointmass-multitask-1_2019_04_22_20_48_30_0000--s-0] Epoch 49 finished
-----------------------------  --------------
replay_buffer/size             10200
trainer/QF1 Loss                   7.92929
trainer/QF2 Loss                   7.85825
trainer/Policy Loss               27.439
trainer/Q1 Predictions Mean      -27.7419
trainer/Q1 Predictions Std         0.820338
trainer/Q1 Predictions Max       -26.6384
trainer/Q1 Predictions Min       -29.7499
trainer/Q2 Predictions Mean      -27.6916
trainer/Q2 Predictions Std         0.821186
trainer/Q2 Predictions Max       -26.5822
trainer/Q2 Predictions Min       -29.842
trainer/Q Targets Mean           -27.4792
trainer/Q Targets Std              2.75844
trainer/Q Targets Max             -1
trainer/Q Targets Min            -29.6003
trainer/Log Pis Mean              -0.164621
trainer/Log Pis Std                0.950074
trainer/Log Pis Max                1.68865
trainer/Log Pis Min               -3.30463
trainer/Policy mu Mean            -0.033723
trainer/Policy mu Std              0.543583
trainer/Policy mu Max              1.44396
trainer/Policy mu Min             -1.66839
trainer/Policy log std Mean       -0.998197
trainer/Policy log std Std         0.262039
trainer/Policy log std Max        -0.264177
trainer/Policy log std Min        -1.55445
trainer/Alpha                      0.0591916
trainer/Alpha Loss                -6.11876
exploration/num steps total    10200
exploration/num paths total      102
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1
exploration/Rewards Std            0
exploration/Rewards Max           -1
exploration/Rewards Min           -1
exploration/Returns Mean        -100
exploration/Returns Std            0
exploration/Returns Max         -100
exploration/Returns Min         -100
exploration/Actions Mean          -0.0107894
exploration/Actions Std            0.323236
exploration/Actions Max            0.898133
exploration/Actions Min           -0.807714
exploration/Num Paths              2
exploration/Average Returns     -100
evaluation/num steps total     50000
evaluation/num paths total       500
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.990571
evaluation/Rewards Std             0.0557296
evaluation/Rewards Max            -0.22048
evaluation/Rewards Min            -1
evaluation/Returns Mean          -99.0571
evaluation/Returns Std             2.82879
evaluation/Returns Max           -90.5707
evaluation/Returns Min          -100
evaluation/Actions Mean           -0.0144462
evaluation/Actions Std             0.145914
evaluation/Actions Max             0.871673
evaluation/Actions Min            -0.926817
evaluation/Num Paths              10
evaluation/Average Returns       -99.0571
time/data storing (s)              0.00117442
time/evaluation sampling (s)       0.23911
time/exploration sampling (s)      0.0690475
time/logging (s)                   0.00320652
time/saving (s)                    0.00218036
time/training (s)                  1.04961
time/epoch (s)                     1.36432
time/total (s)                    67.6851
Epoch                             49
-----------------------------  --------------
2019-04-22 20:49:39.698481 PDT | [sac-pointmass-multitask-1_2019_04_22_20_48_30_0000--s-0] Epoch 50 finished
-----------------------------  --------------
replay_buffer/size             10400
trainer/QF1 Loss                  13.3305
trainer/QF2 Loss                  13.3303
trainer/Policy Loss               27.2603
trainer/Q1 Predictions Mean      -27.5112
trainer/Q1 Predictions Std         0.882339
trainer/Q1 Predictions Max       -26.4492
trainer/Q1 Predictions Min       -30.1527
trainer/Q2 Predictions Mean      -27.4715
trainer/Q2 Predictions Std         0.87271
trainer/Q2 Predictions Max       -26.3372
trainer/Q2 Predictions Min       -30.1166
trainer/Q Targets Mean           -27.4105
trainer/Q Targets Std              3.85533
trainer/Q Targets Max             -1
trainer/Q Targets Min            -30.3396
trainer/Log Pis Mean              -0.0820669
trainer/Log Pis Std                1.23383
trainer/Log Pis Max                2.83934
trainer/Log Pis Min               -5.09416
trainer/Policy mu Mean             0.0321752
trainer/Policy mu Std              0.595533
trainer/Policy mu Max              1.42673
trainer/Policy mu Min             -1.65448
trainer/Policy log std Mean       -1.02471
trainer/Policy log std Std         0.247357
trainer/Policy log std Max        -0.516788
trainer/Policy log std Min        -1.62065
trainer/Alpha                      0.0561875
trainer/Alpha Loss                -5.99386
exploration/num steps total    10400
exploration/num paths total      104
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.914409
exploration/Rewards Std            0.182325
exploration/Rewards Max           -0.0447444
exploration/Rewards Min           -1
exploration/Returns Mean         -91.4409
exploration/Returns Std            0.656119
exploration/Returns Max          -90.7848
exploration/Returns Min          -92.097
exploration/Actions Mean           0.00857473
exploration/Actions Std            0.3558
exploration/Actions Max            0.923986
exploration/Actions Min           -0.849008
exploration/Num Paths              2
exploration/Average Returns      -91.4409
evaluation/num steps total     51000
evaluation/num paths total       510
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1
evaluation/Rewards Std             0
evaluation/Rewards Max            -1
evaluation/Rewards Min            -1
evaluation/Returns Mean         -100
evaluation/Returns Std             0
evaluation/Returns Max          -100
evaluation/Returns Min          -100
evaluation/Actions Mean           -0.0640065
evaluation/Actions Std             0.23872
evaluation/Actions Max             0.894618
evaluation/Actions Min            -0.776691
evaluation/Num Paths              10
evaluation/Average Returns      -100
time/data storing (s)              0.00124355
time/evaluation sampling (s)       0.24523
time/exploration sampling (s)      0.0693561
time/logging (s)                   0.00321736
time/saving (s)                    0.00260631
time/training (s)                  1.02535
time/epoch (s)                     1.347
time/total (s)                    69.0364
Epoch                             50
-----------------------------  --------------
2019-04-22 20:49:41.063206 PDT | [sac-pointmass-multitask-1_2019_04_22_20_48_30_0000--s-0] Epoch 51 finished
-----------------------------  --------------
replay_buffer/size             10600
trainer/QF1 Loss                   0.462141
trainer/QF2 Loss                   0.488273
trainer/Policy Loss               27.769
trainer/Q1 Predictions Mean      -27.7354
trainer/Q1 Predictions Std         0.830463
trainer/Q1 Predictions Max       -26.2274
trainer/Q1 Predictions Min       -30.5799
trainer/Q2 Predictions Mean      -27.6976
trainer/Q2 Predictions Std         0.826554
trainer/Q2 Predictions Max       -26.1749
trainer/Q2 Predictions Min       -30.6849
trainer/Q Targets Mean           -28.2838
trainer/Q Targets Std              0.750578
trainer/Q Targets Max            -27.1982
trainer/Q Targets Min            -30.4939
trainer/Log Pis Mean               0.219864
trainer/Log Pis Std                0.994704
trainer/Log Pis Max                2.49887
trainer/Log Pis Min               -5.06184
trainer/Policy mu Mean             0.214139
trainer/Policy mu Std              0.577666
trainer/Policy mu Max              1.67461
trainer/Policy mu Min             -1.77768
trainer/Policy log std Mean       -1.04763
trainer/Policy log std Std         0.235995
trainer/Policy log std Max        -0.289309
trainer/Policy log std Min        -1.64754
trainer/Alpha                      0.0532589
trainer/Alpha Loss                -5.21996
exploration/num steps total    10600
exploration/num paths total      106
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1
exploration/Rewards Std            0
exploration/Rewards Max           -1
exploration/Rewards Min           -1
exploration/Returns Mean        -100
exploration/Returns Std            0
exploration/Returns Max         -100
exploration/Returns Min         -100
exploration/Actions Mean           0.0445653
exploration/Actions Std            0.367435
exploration/Actions Max            0.979164
exploration/Actions Min           -0.687418
exploration/Num Paths              2
exploration/Average Returns     -100
evaluation/num steps total     52000
evaluation/num paths total       520
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.996247
evaluation/Rewards Std             0.0446226
evaluation/Rewards Max            -0.150997
evaluation/Rewards Min            -1
evaluation/Returns Mean          -99.6247
evaluation/Returns Std             0.658832
evaluation/Returns Max           -98.1219
evaluation/Returns Min          -100
evaluation/Actions Mean            0.0493136
evaluation/Actions Std             0.259337
evaluation/Actions Max             0.931052
evaluation/Actions Min            -0.892968
evaluation/Num Paths              10
evaluation/Average Returns       -99.6247
time/data storing (s)              0.00120226
time/evaluation sampling (s)       0.251302
time/exploration sampling (s)      0.0713797
time/logging (s)                   0.00352478
time/saving (s)                    0.00246803
time/training (s)                  1.02963
time/epoch (s)                     1.35951
time/total (s)                    70.4002
Epoch                             51
-----------------------------  --------------
2019-04-22 20:49:42.428610 PDT | [sac-pointmass-multitask-1_2019_04_22_20_48_30_0000--s-0] Epoch 52 finished
-----------------------------  --------------
replay_buffer/size             10800
trainer/QF1 Loss                  21.3641
trainer/QF2 Loss                  21.3053
trainer/Policy Loss               27.9055
trainer/Q1 Predictions Mean      -28.1405
trainer/Q1 Predictions Std         0.775564
trainer/Q1 Predictions Max       -26.6849
trainer/Q1 Predictions Min       -30.0235
trainer/Q2 Predictions Mean      -28.1119
trainer/Q2 Predictions Std         0.783835
trainer/Q2 Predictions Max       -26.6524
trainer/Q2 Predictions Min       -30.0347
trainer/Q Targets Mean           -27.6457
trainer/Q Targets Std              4.72997
trainer/Q Targets Max             -1
trainer/Q Targets Min            -30.0809
trainer/Log Pis Mean              -0.0757473
trainer/Log Pis Std                1.09077
trainer/Log Pis Max                2.06497
trainer/Log Pis Min               -4.55505
trainer/Policy mu Mean            -0.0214083
trainer/Policy mu Std              0.565477
trainer/Policy mu Max              1.43145
trainer/Policy mu Min             -1.90998
trainer/Policy log std Mean       -1.08393
trainer/Policy log std Std         0.246009
trainer/Policy log std Max        -0.503294
trainer/Policy log std Min        -1.7485
trainer/Alpha                      0.0505869
trainer/Alpha Loss                -6.1936
exploration/num steps total    10800
exploration/num paths total      108
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.983473
exploration/Rewards Std            0.0904944
exploration/Rewards Max           -0.137674
exploration/Rewards Min           -1
exploration/Returns Mean         -98.3473
exploration/Returns Std            1.65273
exploration/Returns Max          -96.6945
exploration/Returns Min         -100
exploration/Actions Mean           0.00124514
exploration/Actions Std            0.314851
exploration/Actions Max            0.792622
exploration/Actions Min           -0.714899
exploration/Num Paths              2
exploration/Average Returns      -98.3473
evaluation/num steps total     53000
evaluation/num paths total       530
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.997122
evaluation/Rewards Std             0.0332698
evaluation/Rewards Max            -0.420564
evaluation/Rewards Min            -1
evaluation/Returns Mean          -99.7122
evaluation/Returns Std             0.583843
evaluation/Returns Max           -98.3425
evaluation/Returns Min          -100
evaluation/Actions Mean           -0.0302943
evaluation/Actions Std             0.141134
evaluation/Actions Max             0.850543
evaluation/Actions Min            -0.907333
evaluation/Num Paths              10
evaluation/Average Returns       -99.7122
time/data storing (s)              0.0011925
time/evaluation sampling (s)       0.239328
time/exploration sampling (s)      0.0705704
time/logging (s)                   0.00272859
time/saving (s)                    0.0134944
time/training (s)                  1.03162
time/epoch (s)                     1.35893
time/total (s)                    71.7632
Epoch                             52
-----------------------------  --------------
2019-04-22 20:49:43.762167 PDT | [sac-pointmass-multitask-1_2019_04_22_20_48_30_0000--s-0] Epoch 53 finished
-----------------------------  --------------
replay_buffer/size             11000
trainer/QF1 Loss                   7.29821
trainer/QF2 Loss                   7.3499
trainer/Policy Loss               28.4935
trainer/Q1 Predictions Mean      -28.661
trainer/Q1 Predictions Std         0.703693
trainer/Q1 Predictions Max       -27.3906
trainer/Q1 Predictions Min       -31.3704
trainer/Q2 Predictions Mean      -28.6405
trainer/Q2 Predictions Std         0.728118
trainer/Q2 Predictions Max       -27.3027
trainer/Q2 Predictions Min       -31.4244
trainer/Q Targets Mean           -28.4778
trainer/Q Targets Std              2.84914
trainer/Q Targets Max             -1
trainer/Q Targets Min            -31.3869
trainer/Log Pis Mean              -0.0626676
trainer/Log Pis Std                0.916205
trainer/Log Pis Max                1.91283
trainer/Log Pis Min               -3.44536
trainer/Policy mu Mean             0.0267299
trainer/Policy mu Std              0.503751
trainer/Policy mu Max              1.60959
trainer/Policy mu Min             -1.51992
trainer/Policy log std Mean       -1.07595
trainer/Policy log std Std         0.259892
trainer/Policy log std Max        -0.560806
trainer/Policy log std Min        -1.63552
trainer/Alpha                      0.0479602
trainer/Alpha Loss                -6.26452
exploration/num steps total    11000
exploration/num paths total      110
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.8944
exploration/Rewards Std            0.19227
exploration/Rewards Max           -0.081622
exploration/Rewards Min           -1
exploration/Returns Mean         -89.44
exploration/Returns Std           10.56
exploration/Returns Max          -78.8799
exploration/Returns Min         -100
exploration/Actions Mean           0.027258
exploration/Actions Std            0.326166
exploration/Actions Max            0.945607
exploration/Actions Min           -0.839788
exploration/Num Paths              2
exploration/Average Returns      -89.44
evaluation/num steps total     54000
evaluation/num paths total       540
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.933674
evaluation/Rewards Std             0.0999346
evaluation/Rewards Max            -0.0884558
evaluation/Rewards Min            -1
evaluation/Returns Mean          -93.3674
evaluation/Returns Std             8.13022
evaluation/Returns Max           -82.807
evaluation/Returns Min          -100
evaluation/Actions Mean            0.00698837
evaluation/Actions Std             0.107372
evaluation/Actions Max             0.909386
evaluation/Actions Min            -0.854457
evaluation/Num Paths              10
evaluation/Average Returns       -93.3674
time/data storing (s)              0.00118305
time/evaluation sampling (s)       0.233248
time/exploration sampling (s)      0.0698229
time/logging (s)                   0.00291456
time/saving (s)                    0.00269311
time/training (s)                  1.01921
time/epoch (s)                     1.32907
time/total (s)                    73.0958
Epoch                             53
-----------------------------  --------------
2019-04-22 20:49:45.104640 PDT | [sac-pointmass-multitask-1_2019_04_22_20_48_30_0000--s-0] Epoch 54 finished
-----------------------------  --------------
replay_buffer/size             11200
trainer/QF1 Loss                   0.084632
trainer/QF2 Loss                   0.0898912
trainer/Policy Loss               29.1249
trainer/Q1 Predictions Mean      -28.9738
trainer/Q1 Predictions Std         0.901176
trainer/Q1 Predictions Max       -27.7912
trainer/Q1 Predictions Min       -31.1353
trainer/Q2 Predictions Mean      -28.9593
trainer/Q2 Predictions Std         0.896226
trainer/Q2 Predictions Max       -27.7793
trainer/Q2 Predictions Min       -31.2307
trainer/Q Targets Mean           -29.085
trainer/Q Targets Std              0.795344
trainer/Q Targets Max            -28.0953
trainer/Q Targets Min            -31.255
trainer/Log Pis Mean               0.298316
trainer/Log Pis Std                1.03495
trainer/Log Pis Max                2.35901
trainer/Log Pis Min               -3.1629
trainer/Policy mu Mean             0.199794
trainer/Policy mu Std              0.576912
trainer/Policy mu Max              1.8152
trainer/Policy mu Min             -1.09584
trainer/Policy log std Mean       -1.1071
trainer/Policy log std Std         0.302168
trainer/Policy log std Max        -0.330864
trainer/Policy log std Min        -1.76604
trainer/Alpha                      0.0454618
trainer/Alpha Loss                -5.25926
exploration/num steps total    11200
exploration/num paths total      112
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.953828
exploration/Rewards Std            0.126511
exploration/Rewards Max           -0.279298
exploration/Rewards Min           -1
exploration/Returns Mean         -95.3828
exploration/Returns Std            4.61716
exploration/Returns Max          -90.7657
exploration/Returns Min         -100
exploration/Actions Mean           0.0379278
exploration/Actions Std            0.310642
exploration/Actions Max            0.87258
exploration/Actions Min           -0.710606
exploration/Num Paths              2
exploration/Average Returns      -95.3828
evaluation/num steps total     55000
evaluation/num paths total       550
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.999654
evaluation/Rewards Std             0.00561316
evaluation/Rewards Max            -0.885427
evaluation/Rewards Min            -1
evaluation/Returns Mean          -99.9654
evaluation/Returns Std             0.0984173
evaluation/Returns Max           -99.6705
evaluation/Returns Min          -100
evaluation/Actions Mean            0.0128542
evaluation/Actions Std             0.106152
evaluation/Actions Max             0.944225
evaluation/Actions Min            -0.890994
evaluation/Num Paths              10
evaluation/Average Returns       -99.9654
time/data storing (s)              0.00122901
time/evaluation sampling (s)       0.237876
time/exploration sampling (s)      0.073133
time/logging (s)                   0.00328839
time/saving (s)                    0.00213927
time/training (s)                  1.01921
time/epoch (s)                     1.33687
time/total (s)                    74.4372
Epoch                             54
-----------------------------  --------------
2019-04-22 20:49:46.455384 PDT | [sac-pointmass-multitask-1_2019_04_22_20_48_30_0000--s-0] Epoch 55 finished
-----------------------------  ---------------
replay_buffer/size             11400
trainer/QF1 Loss                   0.302271
trainer/QF2 Loss                   0.312651
trainer/Policy Loss               29.085
trainer/Q1 Predictions Mean      -28.864
trainer/Q1 Predictions Std         0.890999
trainer/Q1 Predictions Max       -27.5774
trainer/Q1 Predictions Min       -31.8329
trainer/Q2 Predictions Mean      -28.8611
trainer/Q2 Predictions Std         0.902573
trainer/Q2 Predictions Max       -27.6328
trainer/Q2 Predictions Min       -32.2074
trainer/Q Targets Mean           -29.3298
trainer/Q Targets Std              0.751132
trainer/Q Targets Max            -28.336
trainer/Q Targets Min            -31.8955
trainer/Log Pis Mean               0.341249
trainer/Log Pis Std                1.01432
trainer/Log Pis Max                2.97578
trainer/Log Pis Min               -3.63819
trainer/Policy mu Mean             0.153532
trainer/Policy mu Std              0.582629
trainer/Policy mu Max              1.81063
trainer/Policy mu Min             -1.72649
trainer/Policy log std Mean       -1.13664
trainer/Policy log std Std         0.287024
trainer/Policy log std Max        -0.399477
trainer/Policy log std Min        -1.68822
trainer/Alpha                      0.0431568
trainer/Alpha Loss                -5.21289
exploration/num steps total    11400
exploration/num paths total      114
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.956137
exploration/Rewards Std            0.110459
exploration/Rewards Max           -0.470216
exploration/Rewards Min           -1
exploration/Returns Mean         -95.6137
exploration/Returns Std            4.38633
exploration/Returns Max          -91.2273
exploration/Returns Min         -100
exploration/Actions Mean           0.00499386
exploration/Actions Std            0.296341
exploration/Actions Max            0.800257
exploration/Actions Min           -0.926711
exploration/Num Paths              2
exploration/Average Returns      -95.6137
evaluation/num steps total     56000
evaluation/num paths total       560
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.997925
evaluation/Rewards Std             0.0332802
evaluation/Rewards Max            -0.210448
evaluation/Rewards Min            -1
evaluation/Returns Mean          -99.7925
evaluation/Returns Std             0.622427
evaluation/Returns Max           -97.9252
evaluation/Returns Min          -100
evaluation/Actions Mean           -0.000513953
evaluation/Actions Std             0.106316
evaluation/Actions Max             0.94963
evaluation/Actions Min            -0.655685
evaluation/Num Paths              10
evaluation/Average Returns       -99.7925
time/data storing (s)              0.00122895
time/evaluation sampling (s)       0.242208
time/exploration sampling (s)      0.0709747
time/logging (s)                   0.00351848
time/saving (s)                    0.00261984
time/training (s)                  1.02454
time/epoch (s)                     1.34509
time/total (s)                    75.7866
Epoch                             55
-----------------------------  ---------------
2019-04-22 20:49:47.800569 PDT | [sac-pointmass-multitask-1_2019_04_22_20_48_30_0000--s-0] Epoch 56 finished
-----------------------------  --------------
replay_buffer/size             11600
trainer/QF1 Loss                  23.8799
trainer/QF2 Loss                  23.9769
trainer/Policy Loss               29.1954
trainer/Q1 Predictions Mean      -29.2019
trainer/Q1 Predictions Std         0.771207
trainer/Q1 Predictions Max       -28.0575
trainer/Q1 Predictions Min       -30.9854
trainer/Q2 Predictions Mean      -29.2514
trainer/Q2 Predictions Std         0.793816
trainer/Q2 Predictions Max       -28.078
trainer/Q2 Predictions Min       -31.4399
trainer/Q Targets Mean           -28.6837
trainer/Q Targets Std              4.92591
trainer/Q Targets Max             -0.885446
trainer/Q Targets Min            -31.5079
trainer/Log Pis Mean               0.090687
trainer/Log Pis Std                1.00103
trainer/Log Pis Max                3.11534
trainer/Log Pis Min               -3.19517
trainer/Policy mu Mean            -0.0658755
trainer/Policy mu Std              0.586882
trainer/Policy mu Max              1.93843
trainer/Policy mu Min             -1.69646
trainer/Policy log std Mean       -1.09579
trainer/Policy log std Std         0.331827
trainer/Policy log std Max        -0.424391
trainer/Policy log std Min        -1.83828
trainer/Alpha                      0.0409353
trainer/Alpha Loss                -6.10122
exploration/num steps total    11600
exploration/num paths total      116
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.886774
exploration/Rewards Std            0.179032
exploration/Rewards Max           -0.307238
exploration/Rewards Min           -1
exploration/Returns Mean         -88.6774
exploration/Returns Std           11.3226
exploration/Returns Max          -77.3548
exploration/Returns Min         -100
exploration/Actions Mean           0.015659
exploration/Actions Std            0.364946
exploration/Actions Max            0.949733
exploration/Actions Min           -0.819801
exploration/Num Paths              2
exploration/Average Returns      -88.6774
evaluation/num steps total     57000
evaluation/num paths total       570
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.926466
evaluation/Rewards Std             0.0961075
evaluation/Rewards Max            -0.164876
evaluation/Rewards Min            -1
evaluation/Returns Mean          -92.6466
evaluation/Returns Std             9.01579
evaluation/Returns Max           -80.765
evaluation/Returns Min          -100
evaluation/Actions Mean           -0.00548165
evaluation/Actions Std             0.095621
evaluation/Actions Max             0.942184
evaluation/Actions Min            -0.918545
evaluation/Num Paths              10
evaluation/Average Returns       -92.6466
time/data storing (s)              0.00118917
time/evaluation sampling (s)       0.235088
time/exploration sampling (s)      0.070401
time/logging (s)                   0.0035916
time/saving (s)                    0.0024072
time/training (s)                  1.02674
time/epoch (s)                     1.33942
time/total (s)                    77.1303
Epoch                             56
-----------------------------  --------------
2019-04-22 20:49:49.135606 PDT | [sac-pointmass-multitask-1_2019_04_22_20_48_30_0000--s-0] Epoch 57 finished
-----------------------------  --------------
replay_buffer/size             11800
trainer/QF1 Loss                  16.9344
trainer/QF2 Loss                  17.0172
trainer/Policy Loss               29.8833
trainer/Q1 Predictions Mean      -29.7119
trainer/Q1 Predictions Std         0.84447
trainer/Q1 Predictions Max       -28.4572
trainer/Q1 Predictions Min       -31.7721
trainer/Q2 Predictions Mean      -29.7158
trainer/Q2 Predictions Std         0.849817
trainer/Q2 Predictions Max       -28.4616
trainer/Q2 Predictions Min       -31.924
trainer/Q Targets Mean           -29.2171
trainer/Q Targets Std              4.09309
trainer/Q Targets Max             -1
trainer/Q Targets Min            -32.0348
trainer/Log Pis Mean               0.313933
trainer/Log Pis Std                1.18386
trainer/Log Pis Max                3.58899
trainer/Log Pis Min               -3.63933
trainer/Policy mu Mean             0.0918006
trainer/Policy mu Std              0.572504
trainer/Policy mu Max              1.75889
trainer/Policy mu Min             -1.4254
trainer/Policy log std Mean       -1.21865
trainer/Policy log std Std         0.286459
trainer/Policy log std Max        -0.389683
trainer/Policy log std Min        -1.69337
trainer/Alpha                      0.0388851
trainer/Alpha Loss                -5.47447
exploration/num steps total    11800
exploration/num paths total      118
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.807004
exploration/Rewards Std            0.259706
exploration/Rewards Max           -0.0924401
exploration/Rewards Min           -1
exploration/Returns Mean         -80.7004
exploration/Returns Std           19.2996
exploration/Returns Max          -61.4009
exploration/Returns Min         -100
exploration/Actions Mean          -0.0151255
exploration/Actions Std            0.282483
exploration/Actions Max            0.767904
exploration/Actions Min           -0.74619
exploration/Num Paths              2
exploration/Average Returns      -80.7004
evaluation/num steps total     58000
evaluation/num paths total       580
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.727384
evaluation/Rewards Std             0.237526
evaluation/Rewards Max            -0.219854
evaluation/Rewards Min            -1
evaluation/Returns Mean          -72.7384
evaluation/Returns Std            22.344
evaluation/Returns Max           -52.3081
evaluation/Returns Min          -100
evaluation/Actions Mean            0.0110426
evaluation/Actions Std             0.117151
evaluation/Actions Max             0.921243
evaluation/Actions Min            -0.947873
evaluation/Num Paths              10
evaluation/Average Returns       -72.7384
time/data storing (s)              0.0012742
time/evaluation sampling (s)       0.236427
time/exploration sampling (s)      0.0694654
time/logging (s)                   0.00353106
time/saving (s)                    0.00234276
time/training (s)                  1.01605
time/epoch (s)                     1.32909
time/total (s)                    78.4637
Epoch                             57
-----------------------------  --------------
2019-04-22 20:49:50.475388 PDT | [sac-pointmass-multitask-1_2019_04_22_20_48_30_0000--s-0] Epoch 58 finished
-----------------------------  --------------
replay_buffer/size             12000
trainer/QF1 Loss                   8.39876
trainer/QF2 Loss                   8.3271
trainer/Policy Loss               30.0807
trainer/Q1 Predictions Mean      -29.9298
trainer/Q1 Predictions Std         0.87222
trainer/Q1 Predictions Max       -28.7433
trainer/Q1 Predictions Min       -33.2414
trainer/Q2 Predictions Mean      -29.9429
trainer/Q2 Predictions Std         0.84501
trainer/Q2 Predictions Max       -28.8291
trainer/Q2 Predictions Min       -32.9815
trainer/Q Targets Mean           -29.8563
trainer/Q Targets Std              2.99057
trainer/Q Targets Max             -1
trainer/Q Targets Min            -32.7
trainer/Log Pis Mean               0.295019
trainer/Log Pis Std                1.09302
trainer/Log Pis Max                2.53819
trainer/Log Pis Min               -4.24259
trainer/Policy mu Mean             0.0842603
trainer/Policy mu Std              0.64088
trainer/Policy mu Max              2.11377
trainer/Policy mu Min             -1.41109
trainer/Policy log std Mean       -1.17245
trainer/Policy log std Std         0.310666
trainer/Policy log std Max        -0.353777
trainer/Policy log std Min        -1.81016
trainer/Alpha                      0.0369726
trainer/Alpha Loss                -5.62186
exploration/num steps total    12000
exploration/num paths total      120
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.748631
exploration/Rewards Std            0.289718
exploration/Rewards Max           -0.0552425
exploration/Rewards Min           -1
exploration/Returns Mean         -74.8631
exploration/Returns Std           25.1369
exploration/Returns Max          -49.7262
exploration/Returns Min         -100
exploration/Actions Mean           0.00376509
exploration/Actions Std            0.307174
exploration/Actions Max            0.932022
exploration/Actions Min           -0.89647
exploration/Num Paths              2
exploration/Average Returns      -74.8631
evaluation/num steps total     59000
evaluation/num paths total       590
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.834043
evaluation/Rewards Std             0.275478
evaluation/Rewards Max            -0.0429404
evaluation/Rewards Min            -1
evaluation/Returns Mean          -83.4043
evaluation/Returns Std            25.4348
evaluation/Returns Max           -40.4873
evaluation/Returns Min          -100
evaluation/Actions Mean            0.0245844
evaluation/Actions Std             0.139026
evaluation/Actions Max             0.953544
evaluation/Actions Min            -0.928667
evaluation/Num Paths              10
evaluation/Average Returns       -83.4043
time/data storing (s)              0.00118722
time/evaluation sampling (s)       0.240133
time/exploration sampling (s)      0.0698395
time/logging (s)                   0.00322663
time/saving (s)                    0.0020426
time/training (s)                  1.01713
time/epoch (s)                     1.33356
time/total (s)                    79.8016
Epoch                             58
-----------------------------  --------------
2019-04-22 20:49:51.810133 PDT | [sac-pointmass-multitask-1_2019_04_22_20_48_30_0000--s-0] Epoch 59 finished
-----------------------------  ---------------
replay_buffer/size             12200
trainer/QF1 Loss                   0.098699
trainer/QF2 Loss                   0.080225
trainer/Policy Loss               30.5261
trainer/Q1 Predictions Mean      -30.2092
trainer/Q1 Predictions Std         0.83189
trainer/Q1 Predictions Max       -28.8836
trainer/Q1 Predictions Min       -32.5147
trainer/Q2 Predictions Mean      -30.2542
trainer/Q2 Predictions Std         0.8294
trainer/Q2 Predictions Max       -28.9603
trainer/Q2 Predictions Min       -32.5556
trainer/Q Targets Mean           -30.2719
trainer/Q Targets Std              0.735818
trainer/Q Targets Max            -29.344
trainer/Q Targets Min            -31.9628
trainer/Log Pis Mean               0.503153
trainer/Log Pis Std                1.22128
trainer/Log Pis Max                3.58458
trainer/Log Pis Min               -3.23068
trainer/Policy mu Mean            -0.09342
trainer/Policy mu Std              0.731798
trainer/Policy mu Max              1.9227
trainer/Policy mu Min             -2.08513
trainer/Policy log std Mean       -1.14852
trainer/Policy log std Std         0.381004
trainer/Policy log std Max        -0.368491
trainer/Policy log std Min        -2.01275
trainer/Alpha                      0.0351732
trainer/Alpha Loss                -5.01031
exploration/num steps total    12200
exploration/num paths total      122
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.881041
exploration/Rewards Std            0.181637
exploration/Rewards Max           -0.121813
exploration/Rewards Min           -1
exploration/Returns Mean         -88.1041
exploration/Returns Std           11.8959
exploration/Returns Max          -76.2081
exploration/Returns Min         -100
exploration/Actions Mean           0.000448143
exploration/Actions Std            0.349209
exploration/Actions Max            0.836848
exploration/Actions Min           -0.954418
exploration/Num Paths              2
exploration/Average Returns      -88.1041
evaluation/num steps total     60000
evaluation/num paths total       600
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.932456
evaluation/Rewards Std             0.110138
evaluation/Rewards Max            -0.536254
evaluation/Rewards Min            -1
evaluation/Returns Mean          -93.2456
evaluation/Returns Std            10.3474
evaluation/Returns Max           -76.1476
evaluation/Returns Min          -100
evaluation/Actions Mean           -0.00729972
evaluation/Actions Std             0.124461
evaluation/Actions Max             0.963691
evaluation/Actions Min            -0.948042
evaluation/Num Paths              10
evaluation/Average Returns       -93.2456
time/data storing (s)              0.0011954
time/evaluation sampling (s)       0.236228
time/exploration sampling (s)      0.0696799
time/logging (s)                   0.00279029
time/saving (s)                    0.0024692
time/training (s)                  1.01624
time/epoch (s)                     1.3286
time/total (s)                    81.1346
Epoch                             59
-----------------------------  ---------------
2019-04-22 20:49:53.146205 PDT | [sac-pointmass-multitask-1_2019_04_22_20_48_30_0000--s-0] Epoch 60 finished
-----------------------------  --------------
replay_buffer/size             12400
trainer/QF1 Loss                   0.235793
trainer/QF2 Loss                   0.278308
trainer/Policy Loss               30.2261
trainer/Q1 Predictions Mean      -30.0665
trainer/Q1 Predictions Std         0.859675
trainer/Q1 Predictions Max       -28.5949
trainer/Q1 Predictions Min       -32.1847
trainer/Q2 Predictions Mean      -29.9892
trainer/Q2 Predictions Std         0.84667
trainer/Q2 Predictions Max       -28.6409
trainer/Q2 Predictions Min       -31.8539
trainer/Q Targets Mean           -30.4427
trainer/Q Targets Std              0.795265
trainer/Q Targets Max            -29.4618
trainer/Q Targets Min            -32.3849
trainer/Log Pis Mean               0.314137
trainer/Log Pis Std                1.27137
trainer/Log Pis Max                2.69427
trainer/Log Pis Min               -4.47929
trainer/Policy mu Mean             0.103723
trainer/Policy mu Std              0.646098
trainer/Policy mu Max              1.95018
trainer/Policy mu Min             -1.51647
trainer/Policy log std Mean       -1.16224
trainer/Policy log std Std         0.344525
trainer/Policy log std Max        -0.326707
trainer/Policy log std Min        -1.92355
trainer/Alpha                      0.0334168
trainer/Alpha Loss                -5.7293
exploration/num steps total    12400
exploration/num paths total      124
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1
exploration/Rewards Std            0
exploration/Rewards Max           -1
exploration/Rewards Min           -1
exploration/Returns Mean        -100
exploration/Returns Std            0
exploration/Returns Max         -100
exploration/Returns Min         -100
exploration/Actions Mean           0.0188697
exploration/Actions Std            0.330459
exploration/Actions Max            0.992032
exploration/Actions Min           -0.930612
exploration/Num Paths              2
exploration/Average Returns     -100
evaluation/num steps total     61000
evaluation/num paths total       610
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.829904
evaluation/Rewards Std             0.215736
evaluation/Rewards Max            -0.154181
evaluation/Rewards Min            -1
evaluation/Returns Mean          -82.9904
evaluation/Returns Std            20.8587
evaluation/Returns Max           -55.5293
evaluation/Returns Min          -100
evaluation/Actions Mean            0.00678301
evaluation/Actions Std             0.115088
evaluation/Actions Max             0.968058
evaluation/Actions Min            -0.807256
evaluation/Num Paths              10
evaluation/Average Returns       -82.9904
time/data storing (s)              0.00122834
time/evaluation sampling (s)       0.24076
time/exploration sampling (s)      0.0697319
time/logging (s)                   0.00320369
time/saving (s)                    0.00236943
time/training (s)                  1.01409
time/epoch (s)                     1.33139
time/total (s)                    82.4696
Epoch                             60
-----------------------------  --------------
2019-04-22 20:49:54.480882 PDT | [sac-pointmass-multitask-1_2019_04_22_20_48_30_0000--s-0] Epoch 61 finished
-----------------------------  --------------
replay_buffer/size             12600
trainer/QF1 Loss                   0.355977
trainer/QF2 Loss                   0.37815
trainer/Policy Loss               30.5114
trainer/Q1 Predictions Mean      -30.0821
trainer/Q1 Predictions Std         0.870811
trainer/Q1 Predictions Max       -28.6166
trainer/Q1 Predictions Min       -32.9056
trainer/Q2 Predictions Mean      -30.0669
trainer/Q2 Predictions Std         0.896917
trainer/Q2 Predictions Max       -28.6783
trainer/Q2 Predictions Min       -33.0369
trainer/Q Targets Mean           -30.5792
trainer/Q Targets Std              0.728036
trainer/Q Targets Max            -29.6985
trainer/Q Targets Min            -33.0411
trainer/Log Pis Mean               0.605523
trainer/Log Pis Std                1.39804
trainer/Log Pis Max                3.55008
trainer/Log Pis Min               -6.29727
trainer/Policy mu Mean            -0.102059
trainer/Policy mu Std              0.639334
trainer/Policy mu Max              1.66335
trainer/Policy mu Min             -2.20535
trainer/Policy log std Mean       -1.29574
trainer/Policy log std Std         0.34801
trainer/Policy log std Max        -0.488484
trainer/Policy log std Min        -2.01009
trainer/Alpha                      0.0318007
trainer/Alpha Loss                -4.80819
exploration/num steps total    12600
exploration/num paths total      126
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.697823
exploration/Rewards Std            0.338955
exploration/Rewards Max           -0.0170567
exploration/Rewards Min           -1
exploration/Returns Mean         -69.7823
exploration/Returns Std           30.2177
exploration/Returns Max          -39.5647
exploration/Returns Min         -100
exploration/Actions Mean           0.00266983
exploration/Actions Std            0.305974
exploration/Actions Max            0.894614
exploration/Actions Min           -0.94048
exploration/Num Paths              2
exploration/Average Returns      -69.7823
evaluation/num steps total     62000
evaluation/num paths total       620
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.836964
evaluation/Rewards Std             0.326328
evaluation/Rewards Max            -0.161807
evaluation/Rewards Min            -1
evaluation/Returns Mean          -83.6964
evaluation/Returns Std            32.6073
evaluation/Returns Max           -18.4047
evaluation/Returns Min          -100
evaluation/Actions Mean            0.00875166
evaluation/Actions Std             0.176913
evaluation/Actions Max             0.942231
evaluation/Actions Min            -0.808878
evaluation/Num Paths              10
evaluation/Average Returns       -83.6964
time/data storing (s)              0.00124077
time/evaluation sampling (s)       0.239347
time/exploration sampling (s)      0.0690264
time/logging (s)                   0.00349918
time/saving (s)                    0.00247083
time/training (s)                  1.01335
time/epoch (s)                     1.32893
time/total (s)                    83.8032
Epoch                             61
-----------------------------  --------------
2019-04-22 20:49:55.819631 PDT | [sac-pointmass-multitask-1_2019_04_22_20_48_30_0000--s-0] Epoch 62 finished
-----------------------------  --------------
replay_buffer/size             12800
trainer/QF1 Loss                   0.255085
trainer/QF2 Loss                   0.27984
trainer/Policy Loss               30.5554
trainer/Q1 Predictions Mean      -30.3274
trainer/Q1 Predictions Std         0.895401
trainer/Q1 Predictions Max       -29.027
trainer/Q1 Predictions Min       -32.606
trainer/Q2 Predictions Mean      -30.2939
trainer/Q2 Predictions Std         0.896042
trainer/Q2 Predictions Max       -28.9745
trainer/Q2 Predictions Min       -32.6595
trainer/Q Targets Mean           -30.7305
trainer/Q Targets Std              0.7847
trainer/Q Targets Max            -29.7434
trainer/Q Targets Min            -33.061
trainer/Log Pis Mean               0.361216
trainer/Log Pis Std                1.13241
trainer/Log Pis Max                3.05378
trainer/Log Pis Min               -3.21044
trainer/Policy mu Mean             0.0603142
trainer/Policy mu Std              0.607777
trainer/Policy mu Max              2.00519
trainer/Policy mu Min             -1.63236
trainer/Policy log std Mean       -1.31856
trainer/Policy log std Std         0.352425
trainer/Policy log std Max        -0.382756
trainer/Policy log std Min        -2.09914
trainer/Alpha                      0.0302114
trainer/Alpha Loss                -5.73455
exploration/num steps total    12800
exploration/num paths total      128
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1
exploration/Rewards Std            0
exploration/Rewards Max           -1
exploration/Rewards Min           -1
exploration/Returns Mean        -100
exploration/Returns Std            0
exploration/Returns Max         -100
exploration/Returns Min         -100
exploration/Actions Mean           0.0513511
exploration/Actions Std            0.364357
exploration/Actions Max            0.949108
exploration/Actions Min           -0.956216
exploration/Num Paths              2
exploration/Average Returns     -100
evaluation/num steps total     63000
evaluation/num paths total       630
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.819434
evaluation/Rewards Std             0.280421
evaluation/Rewards Max            -0.133605
evaluation/Rewards Min            -1
evaluation/Returns Mean          -81.9434
evaluation/Returns Std            27.5838
evaluation/Returns Max           -39.219
evaluation/Returns Min          -100
evaluation/Actions Mean            0.0961764
evaluation/Actions Std             0.283951
evaluation/Actions Max             0.901722
evaluation/Actions Min            -0.343358
evaluation/Num Paths              10
evaluation/Average Returns       -81.9434
time/data storing (s)              0.00118496
time/evaluation sampling (s)       0.246716
time/exploration sampling (s)      0.070817
time/logging (s)                   0.00373985
time/saving (s)                    0.00232227
time/training (s)                  1.0079
time/epoch (s)                     1.33268
time/total (s)                    85.1405
Epoch                             62
-----------------------------  --------------
2019-04-22 20:49:57.156214 PDT | [sac-pointmass-multitask-1_2019_04_22_20_48_30_0000--s-0] Epoch 63 finished
-----------------------------  --------------
replay_buffer/size             13000
trainer/QF1 Loss                   8.33799
trainer/QF2 Loss                   8.31984
trainer/Policy Loss               31.1419
trainer/Q1 Predictions Mean      -30.5041
trainer/Q1 Predictions Std         0.84367
trainer/Q1 Predictions Max       -29.2321
trainer/Q1 Predictions Min       -32.8961
trainer/Q2 Predictions Mean      -30.5227
trainer/Q2 Predictions Std         0.839178
trainer/Q2 Predictions Max       -29.3506
trainer/Q2 Predictions Min       -33.1088
trainer/Q Targets Mean           -30.6644
trainer/Q Targets Std              3.06933
trainer/Q Targets Max             -1
trainer/Q Targets Min            -33.1534
trainer/Log Pis Mean               0.805265
trainer/Log Pis Std                1.15863
trainer/Log Pis Max                4.12274
trainer/Log Pis Min               -2.81463
trainer/Policy mu Mean             0.0643621
trainer/Policy mu Std              0.635477
trainer/Policy mu Max              1.76617
trainer/Policy mu Min             -1.92741
trainer/Policy log std Mean       -1.4185
trainer/Policy log std Std         0.346319
trainer/Policy log std Max        -0.567427
trainer/Policy log std Min        -2.08315
trainer/Alpha                      0.0288113
trainer/Alpha Loss                -4.23744
exploration/num steps total    13000
exploration/num paths total      130
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.843266
exploration/Rewards Std            0.2209
exploration/Rewards Max           -0.185318
exploration/Rewards Min           -1
exploration/Returns Mean         -84.3266
exploration/Returns Std           15.6734
exploration/Returns Max          -68.6532
exploration/Returns Min         -100
exploration/Actions Mean           0.019294
exploration/Actions Std            0.265469
exploration/Actions Max            0.985374
exploration/Actions Min           -0.639537
exploration/Num Paths              2
exploration/Average Returns      -84.3266
evaluation/num steps total     64000
evaluation/num paths total       640
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1
evaluation/Rewards Std             0
evaluation/Rewards Max            -1
evaluation/Rewards Min            -1
evaluation/Returns Mean         -100
evaluation/Returns Std             0
evaluation/Returns Max          -100
evaluation/Returns Min          -100
evaluation/Actions Mean            0.0484286
evaluation/Actions Std             0.231028
evaluation/Actions Max             0.937072
evaluation/Actions Min            -0.897497
evaluation/Num Paths              10
evaluation/Average Returns      -100
time/data storing (s)              0.00135177
time/evaluation sampling (s)       0.240809
time/exploration sampling (s)      0.0703277
time/logging (s)                   0.00355692
time/saving (s)                    0.00257602
time/training (s)                  1.01214
time/epoch (s)                     1.33076
time/total (s)                    86.4753
Epoch                             63
-----------------------------  --------------
2019-04-22 20:49:58.490123 PDT | [sac-pointmass-multitask-1_2019_04_22_20_48_30_0000--s-0] Epoch 64 finished
-----------------------------  --------------
replay_buffer/size             13200
trainer/QF1 Loss                   0.367692
trainer/QF2 Loss                   0.38391
trainer/Policy Loss               31.2857
trainer/Q1 Predictions Mean      -30.6885
trainer/Q1 Predictions Std         0.743816
trainer/Q1 Predictions Max       -29.4917
trainer/Q1 Predictions Min       -32.4609
trainer/Q2 Predictions Mean      -30.7196
trainer/Q2 Predictions Std         0.752842
trainer/Q2 Predictions Max       -29.3909
trainer/Q2 Predictions Min       -32.3246
trainer/Q Targets Mean           -31.1616
trainer/Q Targets Std              0.695483
trainer/Q Targets Max            -30.1174
trainer/Q Targets Min            -32.8665
trainer/Log Pis Mean               0.702306
trainer/Log Pis Std                1.09089
trainer/Log Pis Max                3.05841
trainer/Log Pis Min               -3.1219
trainer/Policy mu Mean             0.134891
trainer/Policy mu Std              0.620078
trainer/Policy mu Max              1.81469
trainer/Policy mu Min             -1.58387
trainer/Policy log std Mean       -1.38492
trainer/Policy log std Std         0.346079
trainer/Policy log std Max        -0.554494
trainer/Policy log std Min        -2.00772
trainer/Alpha                      0.0273897
trainer/Alpha Loss                -4.66825
exploration/num steps total    13200
exploration/num paths total      132
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.851548
exploration/Rewards Std            0.195797
exploration/Rewards Max           -0.287141
exploration/Rewards Min           -1
exploration/Returns Mean         -85.1548
exploration/Returns Std           14.8452
exploration/Returns Max          -70.3096
exploration/Returns Min         -100
exploration/Actions Mean           0.00118819
exploration/Actions Std            0.261866
exploration/Actions Max            0.901591
exploration/Actions Min           -0.952168
exploration/Num Paths              2
exploration/Average Returns      -85.1548
evaluation/num steps total     65000
evaluation/num paths total       650
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.867641
evaluation/Rewards Std             0.164144
evaluation/Rewards Max            -0.431177
evaluation/Rewards Min            -1
evaluation/Returns Mean          -86.7641
evaluation/Returns Std            16.2198
evaluation/Returns Max           -65.5208
evaluation/Returns Min          -100
evaluation/Actions Mean           -0.00424109
evaluation/Actions Std             0.121119
evaluation/Actions Max             0.963212
evaluation/Actions Min            -0.913491
evaluation/Num Paths              10
evaluation/Average Returns       -86.7641
time/data storing (s)              0.00125324
time/evaluation sampling (s)       0.240222
time/exploration sampling (s)      0.0689292
time/logging (s)                   0.00311855
time/saving (s)                    0.00245835
time/training (s)                  1.01159
time/epoch (s)                     1.32757
time/total (s)                    87.807
Epoch                             64
-----------------------------  --------------
2019-04-22 20:49:59.818290 PDT | [sac-pointmass-multitask-1_2019_04_22_20_48_30_0000--s-0] Epoch 65 finished
-----------------------------  --------------
replay_buffer/size             13400
trainer/QF1 Loss                   0.268509
trainer/QF2 Loss                   0.27692
trainer/Policy Loss               31.3546
trainer/Q1 Predictions Mean      -30.8926
trainer/Q1 Predictions Std         0.844392
trainer/Q1 Predictions Max       -29.7138
trainer/Q1 Predictions Min       -33.361
trainer/Q2 Predictions Mean      -30.8782
trainer/Q2 Predictions Std         0.842158
trainer/Q2 Predictions Max       -29.8024
trainer/Q2 Predictions Min       -33.4041
trainer/Q Targets Mean           -31.3456
trainer/Q Targets Std              0.762982
trainer/Q Targets Max            -30.3209
trainer/Q Targets Min            -33.3606
trainer/Log Pis Mean               0.575997
trainer/Log Pis Std                1.01817
trainer/Log Pis Max                3.50081
trainer/Log Pis Min               -3.62896
trainer/Policy mu Mean             0.0507265
trainer/Policy mu Std              0.628561
trainer/Policy mu Max              2.07526
trainer/Policy mu Min             -1.94808
trainer/Policy log std Mean       -1.27852
trainer/Policy log std Std         0.399053
trainer/Policy log std Max        -0.345673
trainer/Policy log std Min        -1.93948
trainer/Alpha                      0.0260795
trainer/Alpha Loss                -5.19239
exploration/num steps total    13400
exploration/num paths total      134
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.878383
exploration/Rewards Std            0.161795
exploration/Rewards Max           -0.392958
exploration/Rewards Min           -1
exploration/Returns Mean         -87.8383
exploration/Returns Std           12.1617
exploration/Returns Max          -75.6765
exploration/Returns Min         -100
exploration/Actions Mean           0.0207714
exploration/Actions Std            0.305308
exploration/Actions Max            0.976932
exploration/Actions Min           -0.810401
exploration/Num Paths              2
exploration/Average Returns      -87.8383
evaluation/num steps total     66000
evaluation/num paths total       660
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1
evaluation/Rewards Std             0
evaluation/Rewards Max            -1
evaluation/Rewards Min            -1
evaluation/Returns Mean         -100
evaluation/Returns Std             0
evaluation/Returns Max          -100
evaluation/Returns Min          -100
evaluation/Actions Mean           -0.00698147
evaluation/Actions Std             0.12644
evaluation/Actions Max             0.986361
evaluation/Actions Min            -0.959283
evaluation/Num Paths              10
evaluation/Average Returns      -100
time/data storing (s)              0.00126303
time/evaluation sampling (s)       0.234118
time/exploration sampling (s)      0.0708808
time/logging (s)                   0.00318278
time/saving (s)                    0.00206572
time/training (s)                  1.0111
time/epoch (s)                     1.32261
time/total (s)                    89.1336
Epoch                             65
-----------------------------  --------------
2019-04-22 20:50:01.155684 PDT | [sac-pointmass-multitask-1_2019_04_22_20_48_30_0000--s-0] Epoch 66 finished
-----------------------------  --------------
replay_buffer/size             13600
trainer/QF1 Loss                  27.5135
trainer/QF2 Loss                  27.7137
trainer/Policy Loss               32.0375
trainer/Q1 Predictions Mean      -31.4377
trainer/Q1 Predictions Std         0.828425
trainer/Q1 Predictions Max       -30.3251
trainer/Q1 Predictions Min       -34.1104
trainer/Q2 Predictions Mean      -31.4709
trainer/Q2 Predictions Std         0.816239
trainer/Q2 Predictions Max       -30.2461
trainer/Q2 Predictions Min       -34.1115
trainer/Q Targets Mean           -30.7758
trainer/Q Targets Std              5.30813
trainer/Q Targets Max             -0.666784
trainer/Q Targets Min            -33.84
trainer/Log Pis Mean               0.741661
trainer/Log Pis Std                1.08072
trainer/Log Pis Max                4.02838
trainer/Log Pis Min               -4.26631
trainer/Policy mu Mean             0.0121594
trainer/Policy mu Std              0.672976
trainer/Policy mu Max              2.31796
trainer/Policy mu Min             -1.63877
trainer/Policy log std Mean       -1.37443
trainer/Policy log std Std         0.418819
trainer/Policy log std Max        -0.528401
trainer/Policy log std Min        -2.19345
trainer/Alpha                      0.024794
trainer/Alpha Loss                -4.65196
exploration/num steps total    13600
exploration/num paths total      136
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.829639
exploration/Rewards Std            0.205271
exploration/Rewards Max           -0.0180549
exploration/Rewards Min           -1
exploration/Returns Mean         -82.9639
exploration/Returns Std           17.0361
exploration/Returns Max          -65.9279
exploration/Returns Min         -100
exploration/Actions Mean           0.0182537
exploration/Actions Std            0.2926
exploration/Actions Max            0.924059
exploration/Actions Min           -0.673411
exploration/Num Paths              2
exploration/Average Returns      -82.9639
evaluation/num steps total     67000
evaluation/num paths total       670
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.925981
evaluation/Rewards Std             0.154694
evaluation/Rewards Max            -0.101387
evaluation/Rewards Min            -1
evaluation/Returns Mean          -92.5981
evaluation/Returns Std            14.8219
evaluation/Returns Max           -61.3518
evaluation/Returns Min          -100
evaluation/Actions Mean            0.00123303
evaluation/Actions Std             0.108927
evaluation/Actions Max             0.974077
evaluation/Actions Min            -0.907363
evaluation/Num Paths              10
evaluation/Average Returns       -92.5981
time/data storing (s)              0.00118883
time/evaluation sampling (s)       0.24469
time/exploration sampling (s)      0.0696823
time/logging (s)                   0.00370013
time/saving (s)                    0.00257745
time/training (s)                  1.01071
time/epoch (s)                     1.33255
time/total (s)                    90.4701
Epoch                             66
-----------------------------  --------------
2019-04-22 20:50:02.522434 PDT | [sac-pointmass-multitask-1_2019_04_22_20_48_30_0000--s-0] Epoch 67 finished
-----------------------------  --------------
replay_buffer/size             13800
trainer/QF1 Loss                   0.0936975
trainer/QF2 Loss                   0.0797629
trainer/Policy Loss               32.5433
trainer/Q1 Predictions Mean      -31.8964
trainer/Q1 Predictions Std         0.85227
trainer/Q1 Predictions Max       -30.4316
trainer/Q1 Predictions Min       -33.8638
trainer/Q2 Predictions Mean      -31.9209
trainer/Q2 Predictions Std         0.846711
trainer/Q2 Predictions Max       -30.4872
trainer/Q2 Predictions Min       -33.9123
trainer/Q Targets Mean           -32.0423
trainer/Q Targets Std              0.72761
trainer/Q Targets Max            -30.8377
trainer/Q Targets Min            -33.8047
trainer/Log Pis Mean               0.789455
trainer/Log Pis Std                1.24485
trainer/Log Pis Max                4.48181
trainer/Log Pis Min               -3.11109
trainer/Policy mu Mean             0.0366311
trainer/Policy mu Std              0.680175
trainer/Policy mu Max              1.96763
trainer/Policy mu Min             -1.88636
trainer/Policy log std Mean       -1.36679
trainer/Policy log std Std         0.383024
trainer/Policy log std Max        -0.416984
trainer/Policy log std Min        -2.16689
trainer/Alpha                      0.0235706
trainer/Alpha Loss                -4.53651
exploration/num steps total    13800
exploration/num paths total      138
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1
exploration/Rewards Std            0
exploration/Rewards Max           -1
exploration/Rewards Min           -1
exploration/Returns Mean        -100
exploration/Returns Std            0
exploration/Returns Max         -100
exploration/Returns Min         -100
exploration/Actions Mean           0.0121015
exploration/Actions Std            0.229113
exploration/Actions Max            0.937317
exploration/Actions Min           -0.551256
exploration/Num Paths              2
exploration/Average Returns     -100
evaluation/num steps total     68000
evaluation/num paths total       680
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.998964
evaluation/Rewards Std             0.0177532
evaluation/Rewards Max            -0.568658
evaluation/Rewards Min            -1
evaluation/Returns Mean          -99.8964
evaluation/Returns Std             0.310891
evaluation/Returns Max           -98.9637
evaluation/Returns Min          -100
evaluation/Actions Mean            0.0272382
evaluation/Actions Std             0.277123
evaluation/Actions Max             0.953275
evaluation/Actions Min            -0.944092
evaluation/Num Paths              10
evaluation/Average Returns       -99.8964
time/data storing (s)              0.0011909
time/evaluation sampling (s)       0.240884
time/exploration sampling (s)      0.0692034
time/logging (s)                   0.00350709
time/saving (s)                    0.00239881
time/training (s)                  1.04324
time/epoch (s)                     1.36043
time/total (s)                    91.8346
Epoch                             67
-----------------------------  --------------
2019-04-22 20:50:03.863534 PDT | [sac-pointmass-multitask-1_2019_04_22_20_48_30_0000--s-0] Epoch 68 finished
-----------------------------  --------------
replay_buffer/size             14000
trainer/QF1 Loss                  18.3355
trainer/QF2 Loss                  18.2959
trainer/Policy Loss               32.2284
trainer/Q1 Predictions Mean      -31.5092
trainer/Q1 Predictions Std         0.809279
trainer/Q1 Predictions Max       -30.0936
trainer/Q1 Predictions Min       -33.5101
trainer/Q2 Predictions Mean      -31.4829
trainer/Q2 Predictions Std         0.807905
trainer/Q2 Predictions Max       -30.1051
trainer/Q2 Predictions Min       -33.5995
trainer/Q Targets Mean           -31.3659
trainer/Q Targets Std              4.39704
trainer/Q Targets Max             -1
trainer/Q Targets Min            -33.9859
trainer/Log Pis Mean               0.850732
trainer/Log Pis Std                1.15801
trainer/Log Pis Max                4.21674
trainer/Log Pis Min               -2.0783
trainer/Policy mu Mean             0.0726652
trainer/Policy mu Std              0.677539
trainer/Policy mu Max              2.01705
trainer/Policy mu Min             -2.01842
trainer/Policy log std Mean       -1.39282
trainer/Policy log std Std         0.373993
trainer/Policy log std Max        -0.53038
trainer/Policy log std Min        -2.09662
trainer/Alpha                      0.0225295
trainer/Alpha Loss                -4.35879
exploration/num steps total    14000
exploration/num paths total      140
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.887342
exploration/Rewards Std            0.170837
exploration/Rewards Max           -0.0888836
exploration/Rewards Min           -1
exploration/Returns Mean         -88.7342
exploration/Returns Std           11.2658
exploration/Returns Max          -77.4684
exploration/Returns Min         -100
exploration/Actions Mean          -0.0183193
exploration/Actions Std            0.257533
exploration/Actions Max            0.625548
exploration/Actions Min           -0.945126
exploration/Num Paths              2
exploration/Average Returns      -88.7342
evaluation/num steps total     69000
evaluation/num paths total       690
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.959221
evaluation/Rewards Std             0.0874669
evaluation/Rewards Max            -0.460524
evaluation/Rewards Min            -1
evaluation/Returns Mean          -95.9221
evaluation/Returns Std             8.15589
evaluation/Returns Max           -79.6027
evaluation/Returns Min          -100
evaluation/Actions Mean            0.0275311
evaluation/Actions Std             0.243613
evaluation/Actions Max             0.961224
evaluation/Actions Min            -0.873232
evaluation/Num Paths              10
evaluation/Average Returns       -95.9221
time/data storing (s)              0.00131717
time/evaluation sampling (s)       0.241597
time/exploration sampling (s)      0.0706163
time/logging (s)                   0.00357003
time/saving (s)                    0.00234939
time/training (s)                  1.01562
time/epoch (s)                     1.33507
time/total (s)                    93.174
Epoch                             68
-----------------------------  --------------
2019-04-22 20:50:05.192082 PDT | [sac-pointmass-multitask-1_2019_04_22_20_48_30_0000--s-0] Epoch 69 finished
-----------------------------  --------------
replay_buffer/size             14200
trainer/QF1 Loss                   0.192649
trainer/QF2 Loss                   0.153249
trainer/Policy Loss               32.6153
trainer/Q1 Predictions Mean      -31.9417
trainer/Q1 Predictions Std         0.841565
trainer/Q1 Predictions Max       -30.3502
trainer/Q1 Predictions Min       -34.407
trainer/Q2 Predictions Mean      -31.9799
trainer/Q2 Predictions Std         0.834394
trainer/Q2 Predictions Max       -30.4761
trainer/Q2 Predictions Min       -34.3629
trainer/Q Targets Mean           -32.2931
trainer/Q Targets Std              0.769949
trainer/Q Targets Max            -31.1197
trainer/Q Targets Min            -34.6947
trainer/Log Pis Mean               0.764059
trainer/Log Pis Std                1.17857
trainer/Log Pis Max                4.42218
trainer/Log Pis Min               -3.90193
trainer/Policy mu Mean            -0.152615
trainer/Policy mu Std              0.5662
trainer/Policy mu Max              1.73615
trainer/Policy mu Min             -1.99212
trainer/Policy log std Mean       -1.42284
trainer/Policy log std Std         0.397726
trainer/Policy log std Max        -0.440212
trainer/Policy log std Min        -2.39789
trainer/Alpha                      0.0214548
trainer/Alpha Loss                -4.74795
exploration/num steps total    14200
exploration/num paths total      142
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1
exploration/Rewards Std            0
exploration/Rewards Max           -1
exploration/Rewards Min           -1
exploration/Returns Mean        -100
exploration/Returns Std            0
exploration/Returns Max         -100
exploration/Returns Min         -100
exploration/Actions Mean          -0.033606
exploration/Actions Std            0.320541
exploration/Actions Max            0.879965
exploration/Actions Min           -0.897825
exploration/Num Paths              2
exploration/Average Returns     -100
evaluation/num steps total     70000
evaluation/num paths total       700
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.946454
evaluation/Rewards Std             0.165767
evaluation/Rewards Max            -0.223934
evaluation/Rewards Min            -1
evaluation/Returns Mean          -94.6454
evaluation/Returns Std            16.0637
evaluation/Returns Max           -46.4542
evaluation/Returns Min          -100
evaluation/Actions Mean           -0.0142818
evaluation/Actions Std             0.0931624
evaluation/Actions Max             0.857638
evaluation/Actions Min            -0.963428
evaluation/Num Paths              10
evaluation/Average Returns       -94.6454
time/data storing (s)              0.00123411
time/evaluation sampling (s)       0.235399
time/exploration sampling (s)      0.0709658
time/logging (s)                   0.00356613
time/saving (s)                    0.00232308
time/training (s)                  1.00941
time/epoch (s)                     1.3229
time/total (s)                    94.5008
Epoch                             69
-----------------------------  --------------
2019-04-22 20:50:06.535035 PDT | [sac-pointmass-multitask-1_2019_04_22_20_48_30_0000--s-0] Epoch 70 finished
-----------------------------  --------------
replay_buffer/size             14400
trainer/QF1 Loss                   0.117066
trainer/QF2 Loss                   0.094747
trainer/Policy Loss               33.259
trainer/Q1 Predictions Mean      -32.5636
trainer/Q1 Predictions Std         0.889392
trainer/Q1 Predictions Max       -30.9683
trainer/Q1 Predictions Min       -35.1759
trainer/Q2 Predictions Mean      -32.5524
trainer/Q2 Predictions Std         0.869387
trainer/Q2 Predictions Max       -30.975
trainer/Q2 Predictions Min       -35.0979
trainer/Q Targets Mean           -32.3536
trainer/Q Targets Std              0.759139
trainer/Q Targets Max            -31.096
trainer/Q Targets Min            -34.4158
trainer/Log Pis Mean               0.841582
trainer/Log Pis Std                0.970575
trainer/Log Pis Max                2.90793
trainer/Log Pis Min               -3.30526
trainer/Policy mu Mean             0.163783
trainer/Policy mu Std              0.569348
trainer/Policy mu Max              2.33684
trainer/Policy mu Min             -1.24603
trainer/Policy log std Mean       -1.50038
trainer/Policy log std Std         0.381479
trainer/Policy log std Max        -0.473921
trainer/Policy log std Min        -2.07404
trainer/Alpha                      0.0204012
trainer/Alpha Loss                -4.50848
exploration/num steps total    14400
exploration/num paths total      144
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1
exploration/Rewards Std            0
exploration/Rewards Max           -1
exploration/Rewards Min           -1
exploration/Returns Mean        -100
exploration/Returns Std            0
exploration/Returns Max         -100
exploration/Returns Min         -100
exploration/Actions Mean           0.0300272
exploration/Actions Std            0.263468
exploration/Actions Max            0.996475
exploration/Actions Min           -0.891962
exploration/Num Paths              2
exploration/Average Returns     -100
evaluation/num steps total     71000
evaluation/num paths total       710
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.994014
evaluation/Rewards Std             0.0473129
evaluation/Rewards Max            -0.197957
evaluation/Rewards Min            -1
evaluation/Returns Mean          -99.4014
evaluation/Returns Std             0.647313
evaluation/Returns Max           -98.1341
evaluation/Returns Min          -100
evaluation/Actions Mean            0.00174669
evaluation/Actions Std             0.157327
evaluation/Actions Max             0.988194
evaluation/Actions Min            -0.964986
evaluation/Num Paths              10
evaluation/Average Returns       -99.4014
time/data storing (s)              0.00115725
time/evaluation sampling (s)       0.252875
time/exploration sampling (s)      0.0719918
time/logging (s)                   0.00347333
time/saving (s)                    0.00232531
time/training (s)                  1.00556
time/epoch (s)                     1.33738
time/total (s)                    95.842
Epoch                             70
-----------------------------  --------------
2019-04-22 20:50:07.874683 PDT | [sac-pointmass-multitask-1_2019_04_22_20_48_30_0000--s-0] Epoch 71 finished
-----------------------------  --------------
replay_buffer/size             14600
trainer/QF1 Loss                   0.270238
trainer/QF2 Loss                   0.260254
trainer/Policy Loss               33.4344
trainer/Q1 Predictions Mean      -32.3696
trainer/Q1 Predictions Std         0.905542
trainer/Q1 Predictions Max       -30.291
trainer/Q1 Predictions Min       -34.8644
trainer/Q2 Predictions Mean      -32.4043
trainer/Q2 Predictions Std         0.935269
trainer/Q2 Predictions Max       -30.4025
trainer/Q2 Predictions Min       -34.9732
trainer/Q Targets Mean           -32.7079
trainer/Q Targets Std              0.765386
trainer/Q Targets Max            -31.3428
trainer/Q Targets Min            -34.6804
trainer/Log Pis Mean               1.18518
trainer/Log Pis Std                1.50028
trainer/Log Pis Max                4.92915
trainer/Log Pis Min               -4.87382
trainer/Policy mu Mean             0.126795
trainer/Policy mu Std              0.70247
trainer/Policy mu Max              2.39912
trainer/Policy mu Min             -2.04653
trainer/Policy log std Mean       -1.58663
trainer/Policy log std Std         0.415742
trainer/Policy log std Max        -0.65169
trainer/Policy log std Min        -2.28238
trainer/Alpha                      0.0195107
trainer/Alpha Loss                -3.20759
exploration/num steps total    14600
exploration/num paths total      146
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1
exploration/Rewards Std            0
exploration/Rewards Max           -1
exploration/Rewards Min           -1
exploration/Returns Mean        -100
exploration/Returns Std            0
exploration/Returns Max         -100
exploration/Returns Min         -100
exploration/Actions Mean           0.0426679
exploration/Actions Std            0.269018
exploration/Actions Max            0.997921
exploration/Actions Min           -0.823985
exploration/Num Paths              2
exploration/Average Returns     -100
evaluation/num steps total     72000
evaluation/num paths total       720
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.992198
evaluation/Rewards Std             0.0309224
evaluation/Rewards Max            -0.534899
evaluation/Rewards Min            -1
evaluation/Returns Mean          -99.2198
evaluation/Returns Std             2.34065
evaluation/Returns Max           -92.1978
evaluation/Returns Min          -100
evaluation/Actions Mean           -0.0358202
evaluation/Actions Std             0.202014
evaluation/Actions Max             0.988501
evaluation/Actions Min            -0.839041
evaluation/Num Paths              10
evaluation/Average Returns       -99.2198
time/data storing (s)              0.0012516
time/evaluation sampling (s)       0.245686
time/exploration sampling (s)      0.0703848
time/logging (s)                   0.00344346
time/saving (s)                    0.00225378
time/training (s)                  1.01085
time/epoch (s)                     1.33387
time/total (s)                    97.1799
Epoch                             71
-----------------------------  --------------
2019-04-22 20:50:09.216527 PDT | [sac-pointmass-multitask-1_2019_04_22_20_48_30_0000--s-0] Epoch 72 finished
-----------------------------  ---------------
replay_buffer/size             14800
trainer/QF1 Loss                   0.215041
trainer/QF2 Loss                   0.228561
trainer/Policy Loss               33.5848
trainer/Q1 Predictions Mean      -32.7044
trainer/Q1 Predictions Std         1.00485
trainer/Q1 Predictions Max       -30.6569
trainer/Q1 Predictions Min       -34.9191
trainer/Q2 Predictions Mean      -32.6812
trainer/Q2 Predictions Std         1.01777
trainer/Q2 Predictions Max       -30.7539
trainer/Q2 Predictions Min       -34.9272
trainer/Q Targets Mean           -33.0319
trainer/Q Targets Std              0.829708
trainer/Q Targets Max            -31.2108
trainer/Q Targets Min            -35.1239
trainer/Log Pis Mean               1.0744
trainer/Log Pis Std                1.33506
trainer/Log Pis Max                4.93873
trainer/Log Pis Min               -2.58429
trainer/Policy mu Mean             0.064755
trainer/Policy mu Std              0.789926
trainer/Policy mu Max              1.83697
trainer/Policy mu Min             -2.27433
trainer/Policy log std Mean       -1.4485
trainer/Policy log std Std         0.424102
trainer/Policy log std Max        -0.578607
trainer/Policy log std Min        -2.24419
trainer/Alpha                      0.0187042
trainer/Alpha Loss                -3.68277
exploration/num steps total    14800
exploration/num paths total      148
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1
exploration/Rewards Std            0
exploration/Rewards Max           -1
exploration/Rewards Min           -1
exploration/Returns Mean        -100
exploration/Returns Std            0
exploration/Returns Max         -100
exploration/Returns Min         -100
exploration/Actions Mean           0.00691422
exploration/Actions Std            0.250144
exploration/Actions Max            0.964772
exploration/Actions Min           -0.975329
exploration/Num Paths              2
exploration/Average Returns     -100
evaluation/num steps total     73000
evaluation/num paths total       730
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.99655
evaluation/Rewards Std             0.0355466
evaluation/Rewards Max            -0.355018
evaluation/Rewards Min            -1
evaluation/Returns Mean          -99.655
evaluation/Returns Std             0.58414
evaluation/Returns Max           -98.2
evaluation/Returns Min          -100
evaluation/Actions Mean            0.000593933
evaluation/Actions Std             0.113807
evaluation/Actions Max             0.943706
evaluation/Actions Min            -0.968318
evaluation/Num Paths              10
evaluation/Average Returns       -99.655
time/data storing (s)              0.00131511
time/evaluation sampling (s)       0.246903
time/exploration sampling (s)      0.0751895
time/logging (s)                   0.00339977
time/saving (s)                    0.00241295
time/training (s)                  1.00686
time/epoch (s)                     1.33608
time/total (s)                    98.5201
Epoch                             72
-----------------------------  ---------------
2019-04-22 20:50:10.542741 PDT | [sac-pointmass-multitask-1_2019_04_22_20_48_30_0000--s-0] Epoch 73 finished
-----------------------------  --------------
replay_buffer/size             15000
trainer/QF1 Loss                   0.189954
trainer/QF2 Loss                   0.168341
trainer/Policy Loss               33.4715
trainer/Q1 Predictions Mean      -32.6726
trainer/Q1 Predictions Std         0.957132
trainer/Q1 Predictions Max       -31.1172
trainer/Q1 Predictions Min       -35.6661
trainer/Q2 Predictions Mean      -32.6901
trainer/Q2 Predictions Std         0.938733
trainer/Q2 Predictions Max       -31.1574
trainer/Q2 Predictions Min       -35.5411
trainer/Q Targets Mean           -32.9749
trainer/Q Targets Std              0.871042
trainer/Q Targets Max            -31.532
trainer/Q Targets Min            -35.4863
trainer/Log Pis Mean               0.975583
trainer/Log Pis Std                1.23878
trainer/Log Pis Max                4.77107
trainer/Log Pis Min               -2.89881
trainer/Policy mu Mean             0.120564
trainer/Policy mu Std              0.678484
trainer/Policy mu Max              2.22737
trainer/Policy mu Min             -1.76986
trainer/Policy log std Mean       -1.52526
trainer/Policy log std Std         0.395796
trainer/Policy log std Max        -0.640982
trainer/Policy log std Min        -2.25007
trainer/Alpha                      0.0177948
trainer/Alpha Loss                -4.12696
exploration/num steps total    15000
exploration/num paths total      150
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1
exploration/Rewards Std            0
exploration/Rewards Max           -1
exploration/Rewards Min           -1
exploration/Returns Mean        -100
exploration/Returns Std            0
exploration/Returns Max         -100
exploration/Returns Min         -100
exploration/Actions Mean           0.0163596
exploration/Actions Std            0.225479
exploration/Actions Max            0.881456
exploration/Actions Min           -0.807148
exploration/Num Paths              2
exploration/Average Returns     -100
evaluation/num steps total     74000
evaluation/num paths total       740
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.997382
evaluation/Rewards Std             0.0316583
evaluation/Rewards Max            -0.340568
evaluation/Rewards Min            -1
evaluation/Returns Mean          -99.7382
evaluation/Returns Std             0.60968
evaluation/Returns Max           -97.9926
evaluation/Returns Min          -100
evaluation/Actions Mean            0.0163541
evaluation/Actions Std             0.234408
evaluation/Actions Max             0.888604
evaluation/Actions Min            -0.955695
evaluation/Num Paths              10
evaluation/Average Returns       -99.7382
time/data storing (s)              0.00149671
time/evaluation sampling (s)       0.239155
time/exploration sampling (s)      0.0696626
time/logging (s)                   0.00357642
time/saving (s)                    0.00189376
time/training (s)                  1.0045
time/epoch (s)                     1.32028
time/total (s)                    99.8445
Epoch                             73
-----------------------------  --------------
2019-04-22 20:50:11.899458 PDT | [sac-pointmass-multitask-1_2019_04_22_20_48_30_0000--s-0] Epoch 74 finished
-----------------------------  --------------
replay_buffer/size             15200
trainer/QF1 Loss                  10.7405
trainer/QF2 Loss                  10.6143
trainer/Policy Loss               33.6106
trainer/Q1 Predictions Mean      -32.4997
trainer/Q1 Predictions Std         1.03179
trainer/Q1 Predictions Max       -30.778
trainer/Q1 Predictions Min       -35.0095
trainer/Q2 Predictions Mean      -32.4861
trainer/Q2 Predictions Std         1.03716
trainer/Q2 Predictions Max       -30.6963
trainer/Q2 Predictions Min       -35.113
trainer/Q Targets Mean           -32.6689
trainer/Q Targets Std              3.30185
trainer/Q Targets Max             -1
trainer/Q Targets Min            -35.3675
trainer/Log Pis Mean               1.28601
trainer/Log Pis Std                1.12267
trainer/Log Pis Max                3.78559
trainer/Log Pis Min               -1.88631
trainer/Policy mu Mean             0.156362
trainer/Policy mu Std              0.633342
trainer/Policy mu Max              2.07675
trainer/Policy mu Min             -1.50342
trainer/Policy log std Mean       -1.66527
trainer/Policy log std Std         0.446107
trainer/Policy log std Max        -0.611421
trainer/Policy log std Min        -2.51064
trainer/Alpha                      0.0170381
trainer/Alpha Loss                -2.90743
exploration/num steps total    15200
exploration/num paths total      152
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.838051
exploration/Rewards Std            0.184784
exploration/Rewards Max           -0.393728
exploration/Rewards Min           -1
exploration/Returns Mean         -83.8051
exploration/Returns Std           16.1949
exploration/Returns Max          -67.6102
exploration/Returns Min         -100
exploration/Actions Mean           0.0307275
exploration/Actions Std            0.216666
exploration/Actions Max            0.922254
exploration/Actions Min           -0.502016
exploration/Num Paths              2
exploration/Average Returns      -83.8051
evaluation/num steps total     75000
evaluation/num paths total       750
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.966333
evaluation/Rewards Std             0.101672
evaluation/Rewards Max            -0.622247
evaluation/Rewards Min            -1
evaluation/Returns Mean          -96.6333
evaluation/Returns Std            10.1
evaluation/Returns Max           -66.3335
evaluation/Returns Min          -100
evaluation/Actions Mean            0.00314423
evaluation/Actions Std             0.127228
evaluation/Actions Max             0.971848
evaluation/Actions Min            -0.788931
evaluation/Num Paths              10
evaluation/Average Returns       -96.6333
time/data storing (s)              0.00134713
time/evaluation sampling (s)       0.23934
time/exploration sampling (s)      0.0701452
time/logging (s)                   0.00273709
time/saving (s)                    0.0157657
time/training (s)                  1.02131
time/epoch (s)                     1.35065
time/total (s)                   101.199
Epoch                             74
-----------------------------  --------------
2019-04-22 20:50:13.227457 PDT | [sac-pointmass-multitask-1_2019_04_22_20_48_30_0000--s-0] Epoch 75 finished
-----------------------------  --------------
replay_buffer/size             15400
trainer/QF1 Loss                  10.1279
trainer/QF2 Loss                  10.1475
trainer/Policy Loss               33.9392
trainer/Q1 Predictions Mean      -32.887
trainer/Q1 Predictions Std         1.02844
trainer/Q1 Predictions Max       -30.7714
trainer/Q1 Predictions Min       -34.9949
trainer/Q2 Predictions Mean      -32.8657
trainer/Q2 Predictions Std         1.00406
trainer/Q2 Predictions Max       -30.8865
trainer/Q2 Predictions Min       -35.0383
trainer/Q Targets Mean           -33.0184
trainer/Q Targets Std              3.33229
trainer/Q Targets Max             -0.885446
trainer/Q Targets Min            -35.2004
trainer/Log Pis Mean               1.21
trainer/Log Pis Std                1.13338
trainer/Log Pis Max                4.27497
trainer/Log Pis Min               -1.89473
trainer/Policy mu Mean             0.0529649
trainer/Policy mu Std              0.676543
trainer/Policy mu Max              2.38701
trainer/Policy mu Min             -1.71391
trainer/Policy log std Mean       -1.69569
trainer/Policy log std Std         0.430553
trainer/Policy log std Max        -0.508084
trainer/Policy log std Min        -2.43533
trainer/Alpha                      0.016369
trainer/Alpha Loss                -3.2486
exploration/num steps total    15400
exploration/num paths total      154
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.963517
exploration/Rewards Std            0.0784944
exploration/Rewards Max           -0.472974
exploration/Rewards Min           -1
exploration/Returns Mean         -96.3517
exploration/Returns Std            3.64826
exploration/Returns Max          -92.7035
exploration/Returns Min         -100
exploration/Actions Mean           0.00224711
exploration/Actions Std            0.203823
exploration/Actions Max            0.955102
exploration/Actions Min           -0.858024
exploration/Num Paths              2
exploration/Average Returns      -96.3517
evaluation/num steps total     76000
evaluation/num paths total       760
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.962143
evaluation/Rewards Std             0.0629399
evaluation/Rewards Max            -0.239819
evaluation/Rewards Min            -1
evaluation/Returns Mean          -96.2143
evaluation/Returns Std             3.11287
evaluation/Returns Max           -93.2406
evaluation/Returns Min          -100
evaluation/Actions Mean            0.020416
evaluation/Actions Std             0.128704
evaluation/Actions Max             0.972856
evaluation/Actions Min            -0.975194
evaluation/Num Paths              10
evaluation/Average Returns       -96.2143
time/data storing (s)              0.0011829
time/evaluation sampling (s)       0.23491
time/exploration sampling (s)      0.070744
time/logging (s)                   0.00339937
time/saving (s)                    0.00241634
time/training (s)                  1.01061
time/epoch (s)                     1.32326
time/total (s)                   102.526
Epoch                             75
-----------------------------  --------------
2019-04-22 20:50:14.556816 PDT | [sac-pointmass-multitask-1_2019_04_22_20_48_30_0000--s-0] Epoch 76 finished
-----------------------------  --------------
replay_buffer/size             15600
trainer/QF1 Loss                   9.5899
trainer/QF2 Loss                   9.61342
trainer/Policy Loss               34.3976
trainer/Q1 Predictions Mean      -33.4578
trainer/Q1 Predictions Std         1.15522
trainer/Q1 Predictions Max       -31.6488
trainer/Q1 Predictions Min       -36.4397
trainer/Q2 Predictions Mean      -33.4535
trainer/Q2 Predictions Std         1.13531
trainer/Q2 Predictions Max       -31.6732
trainer/Q2 Predictions Min       -36.1344
trainer/Q Targets Mean           -33.3107
trainer/Q Targets Std              3.3985
trainer/Q Targets Max             -1
trainer/Q Targets Min            -35.9004
trainer/Log Pis Mean               1.1193
trainer/Log Pis Std                1.50943
trainer/Log Pis Max                5.8387
trainer/Log Pis Min               -3.67303
trainer/Policy mu Mean             0.214008
trainer/Policy mu Std              0.858678
trainer/Policy mu Max              2.75607
trainer/Policy mu Min             -1.93492
trainer/Policy log std Mean       -1.4384
trainer/Policy log std Std         0.474547
trainer/Policy log std Max        -0.351928
trainer/Policy log std Min        -2.32902
trainer/Alpha                      0.0156754
trainer/Alpha Loss                -3.65971
exploration/num steps total    15600
exploration/num paths total      156
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1
exploration/Rewards Std            0
exploration/Rewards Max           -1
exploration/Rewards Min           -1
exploration/Returns Mean        -100
exploration/Returns Std            0
exploration/Returns Max         -100
exploration/Returns Min         -100
exploration/Actions Mean           0.0135023
exploration/Actions Std            0.319094
exploration/Actions Max            0.963854
exploration/Actions Min           -0.994188
exploration/Num Paths              2
exploration/Average Returns     -100
evaluation/num steps total     77000
evaluation/num paths total       770
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.826276
evaluation/Rewards Std             0.150952
evaluation/Rewards Max            -0.111567
evaluation/Rewards Min            -1
evaluation/Returns Mean          -82.6276
evaluation/Returns Std            14.1918
evaluation/Returns Max           -70.2543
evaluation/Returns Min          -100
evaluation/Actions Mean            0.0247421
evaluation/Actions Std             0.14923
evaluation/Actions Max             0.994179
evaluation/Actions Min            -0.937012
evaluation/Num Paths              10
evaluation/Average Returns       -82.6276
time/data storing (s)              0.00124241
time/evaluation sampling (s)       0.239154
time/exploration sampling (s)      0.0691168
time/logging (s)                   0.00342685
time/saving (s)                    0.00243445
time/training (s)                  1.00771
time/epoch (s)                     1.32308
time/total (s)                   103.854
Epoch                             76
-----------------------------  --------------
2019-04-22 20:50:15.897278 PDT | [sac-pointmass-multitask-1_2019_04_22_20_48_30_0000--s-0] Epoch 77 finished
-----------------------------  --------------
replay_buffer/size             15800
trainer/QF1 Loss                  19.8865
trainer/QF2 Loss                  19.912
trainer/Policy Loss               34.8799
trainer/Q1 Predictions Mean      -33.4156
trainer/Q1 Predictions Std         0.98015
trainer/Q1 Predictions Max       -31.6148
trainer/Q1 Predictions Min       -35.8785
trainer/Q2 Predictions Mean      -33.3865
trainer/Q2 Predictions Std         0.984195
trainer/Q2 Predictions Max       -31.577
trainer/Q2 Predictions Min       -35.6695
trainer/Q Targets Mean           -33.0555
trainer/Q Targets Std              4.65279
trainer/Q Targets Max             -1
trainer/Q Targets Min            -35.4985
trainer/Log Pis Mean               1.64658
trainer/Log Pis Std                1.42606
trainer/Log Pis Max                5.36773
trainer/Log Pis Min               -2.6122
trainer/Policy mu Mean             0.329686
trainer/Policy mu Std              0.818399
trainer/Policy mu Max              2.76201
trainer/Policy mu Min             -1.86414
trainer/Policy log std Mean       -1.62616
trainer/Policy log std Std         0.43972
trainer/Policy log std Max        -0.679628
trainer/Policy log std Min        -2.27811
trainer/Alpha                      0.015055
trainer/Alpha Loss                -1.48292
exploration/num steps total    15800
exploration/num paths total      158
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.976397
exploration/Rewards Std            0.0650034
exploration/Rewards Max           -0.599227
exploration/Rewards Min           -1
exploration/Returns Mean         -97.6397
exploration/Returns Std            2.36032
exploration/Returns Max          -95.2794
exploration/Returns Min         -100
exploration/Actions Mean           0.0541097
exploration/Actions Std            0.229105
exploration/Actions Max            0.988515
exploration/Actions Min           -0.562626
exploration/Num Paths              2
exploration/Average Returns      -97.6397
evaluation/num steps total     78000
evaluation/num paths total       780
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.995364
evaluation/Rewards Std             0.0399349
evaluation/Rewards Max            -0.43907
evaluation/Rewards Min            -1
evaluation/Returns Mean          -99.5364
evaluation/Returns Std             0.730424
evaluation/Returns Max           -98.0281
evaluation/Returns Min          -100
evaluation/Actions Mean            0.00275925
evaluation/Actions Std             0.121995
evaluation/Actions Max             0.967442
evaluation/Actions Min            -0.970896
evaluation/Num Paths              10
evaluation/Average Returns       -99.5364
time/data storing (s)              0.00118218
time/evaluation sampling (s)       0.245129
time/exploration sampling (s)      0.0716554
time/logging (s)                   0.0249656
time/saving (s)                    0.00242066
time/training (s)                  1.01133
time/epoch (s)                     1.35668
time/total (s)                   105.214
Epoch                             77
-----------------------------  --------------
2019-04-22 20:50:17.248449 PDT | [sac-pointmass-multitask-1_2019_04_22_20_48_30_0000--s-0] Epoch 78 finished
-----------------------------  --------------
replay_buffer/size             16000
trainer/QF1 Loss                  21.9206
trainer/QF2 Loss                  21.9809
trainer/Policy Loss               34.7711
trainer/Q1 Predictions Mean      -33.5984
trainer/Q1 Predictions Std         0.81454
trainer/Q1 Predictions Max       -32.305
trainer/Q1 Predictions Min       -36.0105
trainer/Q2 Predictions Mean      -33.5962
trainer/Q2 Predictions Std         0.816786
trainer/Q2 Predictions Max       -32.2291
trainer/Q2 Predictions Min       -35.9289
trainer/Q Targets Mean           -33.0107
trainer/Q Targets Std              4.65191
trainer/Q Targets Max             -1
trainer/Q Targets Min            -36.0145
trainer/Log Pis Mean               1.36657
trainer/Log Pis Std                1.54088
trainer/Log Pis Max                5.82309
trainer/Log Pis Min               -5.31917
trainer/Policy mu Mean            -0.0254852
trainer/Policy mu Std              0.799047
trainer/Policy mu Max              2.33837
trainer/Policy mu Min             -2.14128
trainer/Policy log std Mean       -1.65804
trainer/Policy log std Std         0.431574
trainer/Policy log std Max        -0.5062
trainer/Policy log std Min        -2.27514
trainer/Alpha                      0.014491
trainer/Alpha Loss                -2.68192
exploration/num steps total    16000
exploration/num paths total      160
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.832915
exploration/Rewards Std            0.187043
exploration/Rewards Max           -0.354482
exploration/Rewards Min           -1
exploration/Returns Mean         -83.2915
exploration/Returns Std           16.7085
exploration/Returns Max          -66.5831
exploration/Returns Min         -100
exploration/Actions Mean          -0.0253381
exploration/Actions Std            0.207129
exploration/Actions Max            0.649724
exploration/Actions Min           -0.774584
exploration/Num Paths              2
exploration/Average Returns      -83.2915
evaluation/num steps total     79000
evaluation/num paths total       790
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.8348
evaluation/Rewards Std             0.169461
evaluation/Rewards Max            -0.221103
evaluation/Rewards Min            -1
evaluation/Returns Mean          -83.48
evaluation/Returns Std            16.5224
evaluation/Returns Max           -66.1865
evaluation/Returns Min          -100
evaluation/Actions Mean            0.00435063
evaluation/Actions Std             0.140211
evaluation/Actions Max             0.976336
evaluation/Actions Min            -0.900277
evaluation/Num Paths              10
evaluation/Average Returns       -83.48
time/data storing (s)              0.00116386
time/evaluation sampling (s)       0.237924
time/exploration sampling (s)      0.0703044
time/logging (s)                   0.00347136
time/saving (s)                    0.00244726
time/training (s)                  1.00739
time/epoch (s)                     1.3227
time/total (s)                   106.542
Epoch                             78
-----------------------------  --------------
2019-04-22 20:50:18.569767 PDT | [sac-pointmass-multitask-1_2019_04_22_20_48_30_0000--s-0] Epoch 79 finished
-----------------------------  --------------
replay_buffer/size             16200
trainer/QF1 Loss                  11.4746
trainer/QF2 Loss                  11.5626
trainer/Policy Loss               35.2071
trainer/Q1 Predictions Mean      -33.81
trainer/Q1 Predictions Std         0.866697
trainer/Q1 Predictions Max       -32.2536
trainer/Q1 Predictions Min       -36.6775
trainer/Q2 Predictions Mean      -33.8072
trainer/Q2 Predictions Std         0.86716
trainer/Q2 Predictions Max       -32.1616
trainer/Q2 Predictions Min       -36.7277
trainer/Q Targets Mean           -33.6811
trainer/Q Targets Std              3.4157
trainer/Q Targets Max             -1
trainer/Q Targets Min            -36.5142
trainer/Log Pis Mean               1.55204
trainer/Log Pis Std                1.07929
trainer/Log Pis Max                4.80081
trainer/Log Pis Min               -1.02575
trainer/Policy mu Mean            -0.224886
trainer/Policy mu Std              0.710585
trainer/Policy mu Max              1.81733
trainer/Policy mu Min             -2.53026
trainer/Policy log std Mean       -1.64411
trainer/Policy log std Std         0.404804
trainer/Policy log std Max        -0.614569
trainer/Policy log std Min        -2.27373
trainer/Alpha                      0.0138776
trainer/Alpha Loss                -1.91608
exploration/num steps total    16200
exploration/num paths total      162
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.929368
exploration/Rewards Std            0.109783
exploration/Rewards Max           -0.517176
exploration/Rewards Min           -1
exploration/Returns Mean         -92.9368
exploration/Returns Std            7.06324
exploration/Returns Max          -85.8735
exploration/Returns Min         -100
exploration/Actions Mean           0.0113914
exploration/Actions Std            0.261666
exploration/Actions Max            0.993105
exploration/Actions Min           -0.980857
exploration/Num Paths              2
exploration/Average Returns      -92.9368
evaluation/num steps total     80000
evaluation/num paths total       800
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.981849
evaluation/Rewards Std             0.0561967
evaluation/Rewards Max            -0.598928
evaluation/Rewards Min            -1
evaluation/Returns Mean          -98.1849
evaluation/Returns Std             5.44531
evaluation/Returns Max           -81.849
evaluation/Returns Min          -100
evaluation/Actions Mean            0.00438374
evaluation/Actions Std             0.184658
evaluation/Actions Max             0.968915
evaluation/Actions Min            -0.98887
evaluation/Num Paths              10
evaluation/Average Returns       -98.1849
time/data storing (s)              0.0013696
time/evaluation sampling (s)       0.241763
time/exploration sampling (s)      0.0699706
time/logging (s)                   0.00336564
time/saving (s)                    0.00230764
time/training (s)                  0.996562
time/epoch (s)                     1.31534
time/total (s)                   107.861
Epoch                             79
-----------------------------  --------------
2019-04-22 20:50:19.903181 PDT | [sac-pointmass-multitask-1_2019_04_22_20_48_30_0000--s-0] Epoch 80 finished
-----------------------------  --------------
replay_buffer/size             16400
trainer/QF1 Loss                   0.644346
trainer/QF2 Loss                   0.692514
trainer/Policy Loss               34.7097
trainer/Q1 Predictions Mean      -33.325
trainer/Q1 Predictions Std         1.11942
trainer/Q1 Predictions Max       -31.361
trainer/Q1 Predictions Min       -36.7982
trainer/Q2 Predictions Mean      -33.2911
trainer/Q2 Predictions Std         1.10704
trainer/Q2 Predictions Max       -31.4419
trainer/Q2 Predictions Min       -36.5149
trainer/Q Targets Mean           -34.0848
trainer/Q Targets Std              1.0048
trainer/Q Targets Max            -32.3912
trainer/Q Targets Min            -36.9381
trainer/Log Pis Mean               1.51409
trainer/Log Pis Std                1.15166
trainer/Log Pis Max                5.23187
trainer/Log Pis Min               -2.32688
trainer/Policy mu Mean            -0.0109431
trainer/Policy mu Std              0.626028
trainer/Policy mu Max              2.52123
trainer/Policy mu Min             -1.65128
trainer/Policy log std Mean       -1.81918
trainer/Policy log std Std         0.415345
trainer/Policy log std Max        -0.617675
trainer/Policy log std Min        -2.39871
trainer/Alpha                      0.0132678
trainer/Alpha Loss                -2.10022
exploration/num steps total    16400
exploration/num paths total      164
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.892019
exploration/Rewards Std            0.152494
exploration/Rewards Max           -0.0387091
exploration/Rewards Min           -1
exploration/Returns Mean         -89.2019
exploration/Returns Std           10.7981
exploration/Returns Max          -78.4037
exploration/Returns Min         -100
exploration/Actions Mean          -0.0244891
exploration/Actions Std            0.2807
exploration/Actions Max            0.966017
exploration/Actions Min           -0.583914
exploration/Num Paths              2
exploration/Average Returns      -89.2019
evaluation/num steps total     81000
evaluation/num paths total       810
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.96098
evaluation/Rewards Std             0.0800775
evaluation/Rewards Max            -0.628274
evaluation/Rewards Min            -1
evaluation/Returns Mean          -96.098
evaluation/Returns Std             7.81005
evaluation/Returns Max           -79.8038
evaluation/Returns Min          -100
evaluation/Actions Mean           -0.0221541
evaluation/Actions Std             0.175421
evaluation/Actions Max             0.940386
evaluation/Actions Min            -0.967323
evaluation/Num Paths              10
evaluation/Average Returns       -96.098
time/data storing (s)              0.00133614
time/evaluation sampling (s)       0.2406
time/exploration sampling (s)      0.0712429
time/logging (s)                   0.00329149
time/saving (s)                    0.00241879
time/training (s)                  1.00867
time/epoch (s)                     1.32756
time/total (s)                   109.193
Epoch                             80
-----------------------------  --------------
2019-04-22 20:50:21.231597 PDT | [sac-pointmass-multitask-1_2019_04_22_20_48_30_0000--s-0] Epoch 81 finished
-----------------------------  --------------
replay_buffer/size             16600
trainer/QF1 Loss                  10.9472
trainer/QF2 Loss                  10.8832
trainer/Policy Loss               35.8394
trainer/Q1 Predictions Mean      -34.4761
trainer/Q1 Predictions Std         0.995416
trainer/Q1 Predictions Max       -32.7019
trainer/Q1 Predictions Min       -37.2643
trainer/Q2 Predictions Mean      -34.4776
trainer/Q2 Predictions Std         1.04028
trainer/Q2 Predictions Max       -32.6491
trainer/Q2 Predictions Min       -37.0846
trainer/Q Targets Mean           -33.9234
trainer/Q Targets Std              3.45176
trainer/Q Targets Max             -1
trainer/Q Targets Min            -36.5819
trainer/Log Pis Mean               1.5324
trainer/Log Pis Std                1.413
trainer/Log Pis Max                4.75308
trainer/Log Pis Min               -3.0321
trainer/Policy mu Mean             0.121189
trainer/Policy mu Std              0.835603
trainer/Policy mu Max              2.46518
trainer/Policy mu Min             -2.1798
trainer/Policy log std Mean       -1.66312
trainer/Policy log std Std         0.454035
trainer/Policy log std Max        -0.544915
trainer/Policy log std Min        -2.33147
trainer/Alpha                      0.0128365
trainer/Alpha Loss                -2.03653
exploration/num steps total    16600
exploration/num paths total      166
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.72816
exploration/Rewards Std            0.123137
exploration/Rewards Max           -0.16578
exploration/Rewards Min           -1
exploration/Returns Mean         -72.816
exploration/Returns Std            1.76637
exploration/Returns Max          -71.0497
exploration/Returns Min          -74.5824
exploration/Actions Mean           0.0298373
exploration/Actions Std            0.194625
exploration/Actions Max            0.97092
exploration/Actions Min           -0.363466
exploration/Num Paths              2
exploration/Average Returns      -72.816
evaluation/num steps total     82000
evaluation/num paths total       820
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.86089
evaluation/Rewards Std             0.142859
evaluation/Rewards Max            -0.286474
evaluation/Rewards Min            -1
evaluation/Returns Mean          -86.089
evaluation/Returns Std            13.914
evaluation/Returns Max           -71.5799
evaluation/Returns Min          -100
evaluation/Actions Mean            0.00726884
evaluation/Actions Std             0.118503
evaluation/Actions Max             0.993255
evaluation/Actions Min            -0.899681
evaluation/Num Paths              10
evaluation/Average Returns       -86.089
time/data storing (s)              0.0013637
time/evaluation sampling (s)       0.235549
time/exploration sampling (s)      0.070347
time/logging (s)                   0.00343118
time/saving (s)                    0.00231762
time/training (s)                  1.00937
time/epoch (s)                     1.32238
time/total (s)                   110.52
Epoch                             81
-----------------------------  --------------
2019-04-22 20:50:22.572311 PDT | [sac-pointmass-multitask-1_2019_04_22_20_48_30_0000--s-0] Epoch 82 finished
-----------------------------  --------------
replay_buffer/size             16800
trainer/QF1 Loss                  20.7983
trainer/QF2 Loss                  20.5871
trainer/Policy Loss               35.3386
trainer/Q1 Predictions Mean      -33.8028
trainer/Q1 Predictions Std         1.16996
trainer/Q1 Predictions Max       -31.8023
trainer/Q1 Predictions Min       -36.6416
trainer/Q2 Predictions Mean      -33.792
trainer/Q2 Predictions Std         1.142
trainer/Q2 Predictions Max       -31.928
trainer/Q2 Predictions Min       -36.4964
trainer/Q Targets Mean           -33.5156
trainer/Q Targets Std              4.78286
trainer/Q Targets Max             -0.6509
trainer/Q Targets Min            -36.9505
trainer/Log Pis Mean               1.71393
trainer/Log Pis Std                1.35136
trainer/Log Pis Max                4.94665
trainer/Log Pis Min               -4.4553
trainer/Policy mu Mean             0.160697
trainer/Policy mu Std              0.796601
trainer/Policy mu Max              2.70478
trainer/Policy mu Min             -1.77797
trainer/Policy log std Mean       -1.71715
trainer/Policy log std Std         0.450188
trainer/Policy log std Max        -0.47001
trainer/Policy log std Min        -2.47753
trainer/Alpha                      0.0124289
trainer/Alpha Loss                -1.25514
exploration/num steps total    16800
exploration/num paths total      168
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.603286
exploration/Rewards Std            0.0992366
exploration/Rewards Max           -0.397414
exploration/Rewards Min           -0.862155
exploration/Returns Mean         -60.3286
exploration/Returns Std            0.370389
exploration/Returns Max          -59.9582
exploration/Returns Min          -60.699
exploration/Actions Mean           0.00155388
exploration/Actions Std            0.143144
exploration/Actions Max            0.423335
exploration/Actions Min           -0.344768
exploration/Num Paths              2
exploration/Average Returns      -60.3286
evaluation/num steps total     83000
evaluation/num paths total       830
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.877515
evaluation/Rewards Std             0.19115
evaluation/Rewards Max            -0.159679
evaluation/Rewards Min            -1
evaluation/Returns Mean          -87.7515
evaluation/Returns Std            18.7171
evaluation/Returns Max           -57.8897
evaluation/Returns Min          -100
evaluation/Actions Mean            0.0217531
evaluation/Actions Std             0.254344
evaluation/Actions Max             0.974191
evaluation/Actions Min            -0.949915
evaluation/Num Paths              10
evaluation/Average Returns       -87.7515
time/data storing (s)              0.00137685
time/evaluation sampling (s)       0.241453
time/exploration sampling (s)      0.069437
time/logging (s)                   0.00338915
time/saving (s)                    0.00250866
time/training (s)                  1.01643
time/epoch (s)                     1.33459
time/total (s)                   111.858
Epoch                             82
-----------------------------  --------------
2019-04-22 20:50:23.899228 PDT | [sac-pointmass-multitask-1_2019_04_22_20_48_30_0000--s-0] Epoch 83 finished
-----------------------------  --------------
replay_buffer/size             17000
trainer/QF1 Loss                  11.1219
trainer/QF2 Loss                  11.0472
trainer/Policy Loss               35.2492
trainer/Q1 Predictions Mean      -33.9896
trainer/Q1 Predictions Std         1.07578
trainer/Q1 Predictions Max       -32.2338
trainer/Q1 Predictions Min       -38.9527
trainer/Q2 Predictions Mean      -33.9338
trainer/Q2 Predictions Std         1.0395
trainer/Q2 Predictions Max       -32.1434
trainer/Q2 Predictions Min       -37.7219
trainer/Q Targets Mean           -34.1022
trainer/Q Targets Std              3.47554
trainer/Q Targets Max             -1
trainer/Q Targets Min            -37.7685
trainer/Log Pis Mean               1.44229
trainer/Log Pis Std                1.3617
trainer/Log Pis Max                4.5842
trainer/Log Pis Min               -5.65185
trainer/Policy mu Mean             0.0402632
trainer/Policy mu Std              0.71301
trainer/Policy mu Max              2.21836
trainer/Policy mu Min             -1.98539
trainer/Policy log std Mean       -1.70033
trainer/Policy log std Std         0.442485
trainer/Policy log std Max        -0.597938
trainer/Policy log std Min        -2.39632
trainer/Alpha                      0.0119735
trainer/Alpha Loss                -2.46779
exploration/num steps total    17000
exploration/num paths total      170
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.549053
exploration/Rewards Std            0.111414
exploration/Rewards Max           -0.332994
exploration/Rewards Min           -1
exploration/Returns Mean         -54.9053
exploration/Returns Std            0.00649181
exploration/Returns Max          -54.8988
exploration/Returns Min          -54.9118
exploration/Actions Mean           0.0225685
exploration/Actions Std            0.181222
exploration/Actions Max            0.987736
exploration/Actions Min           -0.531469
exploration/Num Paths              2
exploration/Average Returns      -54.9053
evaluation/num steps total     84000
evaluation/num paths total       840
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.76781
evaluation/Rewards Std             0.2401
evaluation/Rewards Max            -0.517521
evaluation/Rewards Min            -1
evaluation/Returns Mean          -76.781
evaluation/Returns Std            23.2253
evaluation/Returns Max           -52.5234
evaluation/Returns Min          -100
evaluation/Actions Mean           -0.00248273
evaluation/Actions Std             0.129466
evaluation/Actions Max             0.982728
evaluation/Actions Min            -0.974439
evaluation/Num Paths              10
evaluation/Average Returns       -76.781
time/data storing (s)              0.00125899
time/evaluation sampling (s)       0.236626
time/exploration sampling (s)      0.0724386
time/logging (s)                   0.00374258
time/saving (s)                    0.00185733
time/training (s)                  1.00532
time/epoch (s)                     1.32124
time/total (s)                   113.184
Epoch                             83
-----------------------------  --------------
2019-04-22 20:50:25.239808 PDT | [sac-pointmass-multitask-1_2019_04_22_20_48_30_0000--s-0] Epoch 84 finished
-----------------------------  --------------
replay_buffer/size             17200
trainer/QF1 Loss                  10.304
trainer/QF2 Loss                  10.3347
trainer/Policy Loss               35.9008
trainer/Q1 Predictions Mean      -34.4147
trainer/Q1 Predictions Std         1.099
trainer/Q1 Predictions Max       -32.7624
trainer/Q1 Predictions Min       -37.0611
trainer/Q2 Predictions Mean      -34.4064
trainer/Q2 Predictions Std         1.10223
trainer/Q2 Predictions Max       -32.6768
trainer/Q2 Predictions Min       -37.1002
trainer/Q Targets Mean           -34.1694
trainer/Q Targets Std              3.53187
trainer/Q Targets Max             -1
trainer/Q Targets Min            -37.213
trainer/Log Pis Mean               1.63307
trainer/Log Pis Std                1.39799
trainer/Log Pis Max                5.69447
trainer/Log Pis Min               -2.47341
trainer/Policy mu Mean             0.104278
trainer/Policy mu Std              0.827729
trainer/Policy mu Max              2.83639
trainer/Policy mu Min             -1.97201
trainer/Policy log std Mean       -1.71185
trainer/Policy log std Std         0.510866
trainer/Policy log std Max        -0.542986
trainer/Policy log std Min        -2.4612
trainer/Alpha                      0.0115598
trainer/Alpha Loss                -1.63651
exploration/num steps total    17200
exploration/num paths total      172
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.789943
exploration/Rewards Std            0.217122
exploration/Rewards Max           -0.413621
exploration/Rewards Min           -1
exploration/Returns Mean         -78.9943
exploration/Returns Std           21.0057
exploration/Returns Max          -57.9886
exploration/Returns Min         -100
exploration/Actions Mean           0.0079299
exploration/Actions Std            0.19531
exploration/Actions Max            0.961322
exploration/Actions Min           -0.972605
exploration/Num Paths              2
exploration/Average Returns      -78.9943
evaluation/num steps total     85000
evaluation/num paths total       850
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.914063
evaluation/Rewards Std             0.176715
evaluation/Rewards Max            -0.0440699
evaluation/Rewards Min            -1
evaluation/Returns Mean          -91.4063
evaluation/Returns Std            17.1945
evaluation/Returns Max           -55.9259
evaluation/Returns Min          -100
evaluation/Actions Mean            0.00668197
evaluation/Actions Std             0.123464
evaluation/Actions Max             0.986864
evaluation/Actions Min            -0.977547
evaluation/Num Paths              10
evaluation/Average Returns       -91.4063
time/data storing (s)              0.00124753
time/evaluation sampling (s)       0.239744
time/exploration sampling (s)      0.0774325
time/logging (s)                   0.00347506
time/saving (s)                    0.00261855
time/training (s)                  1.00978
time/epoch (s)                     1.3343
time/total (s)                   114.522
Epoch                             84
-----------------------------  --------------
2019-04-22 20:50:26.578473 PDT | [sac-pointmass-multitask-1_2019_04_22_20_48_30_0000--s-0] Epoch 85 finished
-----------------------------  --------------
replay_buffer/size             17400
trainer/QF1 Loss                  22.7074
trainer/QF2 Loss                  22.8486
trainer/Policy Loss               36.0139
trainer/Q1 Predictions Mean      -34.567
trainer/Q1 Predictions Std         1.23864
trainer/Q1 Predictions Max       -32.4617
trainer/Q1 Predictions Min       -37.9334
trainer/Q2 Predictions Mean      -34.5436
trainer/Q2 Predictions Std         1.24032
trainer/Q2 Predictions Max       -32.4171
trainer/Q2 Predictions Min       -37.79
trainer/Q Targets Mean           -34.1068
trainer/Q Targets Std              4.88335
trainer/Q Targets Max             -0.666784
trainer/Q Targets Min            -37.7448
trainer/Log Pis Mean               1.60297
trainer/Log Pis Std                1.3165
trainer/Log Pis Max                5.97952
trainer/Log Pis Min               -3.02784
trainer/Policy mu Mean            -0.0497151
trainer/Policy mu Std              0.772596
trainer/Policy mu Max              2.23972
trainer/Policy mu Min             -2.19151
trainer/Policy log std Mean       -1.76674
trainer/Policy log std Std         0.472913
trainer/Policy log std Max        -0.52775
trainer/Policy log std Min        -2.45134
trainer/Alpha                      0.0111627
trainer/Alpha Loss                -1.78464
exploration/num steps total    17400
exploration/num paths total      174
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.813611
exploration/Rewards Std            0.203769
exploration/Rewards Max           -0.106829
exploration/Rewards Min           -1
exploration/Returns Mean         -81.3611
exploration/Returns Std           18.6389
exploration/Returns Max          -62.7221
exploration/Returns Min         -100
exploration/Actions Mean          -0.00535165
exploration/Actions Std            0.234795
exploration/Actions Max            0.984973
exploration/Actions Min           -0.723975
exploration/Num Paths              2
exploration/Average Returns      -81.3611
evaluation/num steps total     86000
evaluation/num paths total       860
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.922963
evaluation/Rewards Std             0.157422
evaluation/Rewards Max            -0.59858
evaluation/Rewards Min            -1
evaluation/Returns Mean          -92.2963
evaluation/Returns Std            15.4073
evaluation/Returns Max           -61.4704
evaluation/Returns Min          -100
evaluation/Actions Mean           -0.0229734
evaluation/Actions Std             0.214911
evaluation/Actions Max             0.991201
evaluation/Actions Min            -0.967215
evaluation/Num Paths              10
evaluation/Average Returns       -92.2963
time/data storing (s)              0.0012845
time/evaluation sampling (s)       0.241446
time/exploration sampling (s)      0.0696902
time/logging (s)                   0.00368614
time/saving (s)                    0.00242663
time/training (s)                  1.01498
time/epoch (s)                     1.33351
time/total (s)                   115.86
Epoch                             85
-----------------------------  --------------
2019-04-22 20:50:27.898149 PDT | [sac-pointmass-multitask-1_2019_04_22_20_48_30_0000--s-0] Epoch 86 finished
-----------------------------  --------------
replay_buffer/size             17600
trainer/QF1 Loss                   0.0598857
trainer/QF2 Loss                   0.0689727
trainer/Policy Loss               36.3308
trainer/Q1 Predictions Mean      -34.8089
trainer/Q1 Predictions Std         1.17357
trainer/Q1 Predictions Max       -32.7804
trainer/Q1 Predictions Min       -37.2766
trainer/Q2 Predictions Mean      -34.8308
trainer/Q2 Predictions Std         1.21997
trainer/Q2 Predictions Max       -32.7594
trainer/Q2 Predictions Min       -37.5268
trainer/Q Targets Mean           -34.7949
trainer/Q Targets Std              1.12465
trainer/Q Targets Max            -32.6649
trainer/Q Targets Min            -37.3314
trainer/Log Pis Mean               1.64547
trainer/Log Pis Std                1.35793
trainer/Log Pis Max                5.57875
trainer/Log Pis Min               -2.48116
trainer/Policy mu Mean             0.0976627
trainer/Policy mu Std              0.755444
trainer/Policy mu Max              2.20966
trainer/Policy mu Min             -2.30249
trainer/Policy log std Mean       -1.7571
trainer/Policy log std Std         0.489186
trainer/Policy log std Max        -0.570333
trainer/Policy log std Min        -2.57133
trainer/Alpha                      0.0108418
trainer/Alpha Loss                -1.60398
exploration/num steps total    17600
exploration/num paths total      176
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1
exploration/Rewards Std            0
exploration/Rewards Max           -1
exploration/Rewards Min           -1
exploration/Returns Mean        -100
exploration/Returns Std            0
exploration/Returns Max         -100
exploration/Returns Min         -100
exploration/Actions Mean          -0.0120324
exploration/Actions Std            0.172456
exploration/Actions Max            0.811387
exploration/Actions Min           -0.73213
exploration/Num Paths              2
exploration/Average Returns     -100
evaluation/num steps total     87000
evaluation/num paths total       870
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.946227
evaluation/Rewards Std             0.0829395
evaluation/Rewards Max            -0.720087
evaluation/Rewards Min            -1
evaluation/Returns Mean          -94.6227
evaluation/Returns Std             8.21419
evaluation/Returns Max           -81.9808
evaluation/Returns Min          -100
evaluation/Actions Mean           -0.011143
evaluation/Actions Std             0.164258
evaluation/Actions Max             0.96907
evaluation/Actions Min            -0.96166
evaluation/Num Paths              10
evaluation/Average Returns       -94.6227
time/data storing (s)              0.00121621
time/evaluation sampling (s)       0.236044
time/exploration sampling (s)      0.070569
time/logging (s)                   0.00342866
time/saving (s)                    0.00192034
time/training (s)                  1.00009
time/epoch (s)                     1.31327
time/total (s)                   117.177
Epoch                             86
-----------------------------  --------------
2019-04-22 20:50:29.240841 PDT | [sac-pointmass-multitask-1_2019_04_22_20_48_30_0000--s-0] Epoch 87 finished
-----------------------------  --------------
replay_buffer/size             17800
trainer/QF1 Loss                  10.5046
trainer/QF2 Loss                  10.4171
trainer/Policy Loss               35.7229
trainer/Q1 Predictions Mean      -34.1084
trainer/Q1 Predictions Std         1.44552
trainer/Q1 Predictions Max       -31.6861
trainer/Q1 Predictions Min       -37.4526
trainer/Q2 Predictions Mean      -34.1269
trainer/Q2 Predictions Std         1.43264
trainer/Q2 Predictions Max       -31.7635
trainer/Q2 Predictions Min       -37.2249
trainer/Q Targets Mean           -34.4752
trainer/Q Targets Std              3.61709
trainer/Q Targets Max             -0.678927
trainer/Q Targets Min            -37.5436
trainer/Log Pis Mean               1.75442
trainer/Log Pis Std                1.10242
trainer/Log Pis Max                5.46651
trainer/Log Pis Min               -1.27438
trainer/Policy mu Mean             0.142135
trainer/Policy mu Std              0.736046
trainer/Policy mu Max              2.51139
trainer/Policy mu Min             -1.8119
trainer/Policy log std Mean       -1.8551
trainer/Policy log std Std         0.508829
trainer/Policy log std Max        -0.529659
trainer/Policy log std Min        -2.56967
trainer/Alpha                      0.0106629
trainer/Alpha Loss                -1.11517
exploration/num steps total    17800
exploration/num paths total      178
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.781501
exploration/Rewards Std            0.0831434
exploration/Rewards Max           -0.535245
exploration/Rewards Min           -1
exploration/Returns Mean         -78.1501
exploration/Returns Std            1.67905
exploration/Returns Max          -76.471
exploration/Returns Min          -79.8291
exploration/Actions Mean          -0.0125379
exploration/Actions Std            0.162357
exploration/Actions Max            0.704542
exploration/Actions Min           -0.987953
exploration/Num Paths              2
exploration/Average Returns      -78.1501
evaluation/num steps total     88000
evaluation/num paths total       880
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1
evaluation/Rewards Std             0
evaluation/Rewards Max            -1
evaluation/Rewards Min            -1
evaluation/Returns Mean         -100
evaluation/Returns Std             0
evaluation/Returns Max          -100
evaluation/Returns Min          -100
evaluation/Actions Mean           -0.0346443
evaluation/Actions Std             0.226796
evaluation/Actions Max             0.976364
evaluation/Actions Min            -0.959904
evaluation/Num Paths              10
evaluation/Average Returns      -100
time/data storing (s)              0.00119852
time/evaluation sampling (s)       0.244695
time/exploration sampling (s)      0.0720575
time/logging (s)                   0.00349533
time/saving (s)                    0.00203531
time/training (s)                  1.01297
time/epoch (s)                     1.33645
time/total (s)                   118.518
Epoch                             87
-----------------------------  --------------
2019-04-22 20:50:30.573735 PDT | [sac-pointmass-multitask-1_2019_04_22_20_48_30_0000--s-0] Epoch 88 finished
-----------------------------  --------------
replay_buffer/size             18000
trainer/QF1 Loss                  23.5814
trainer/QF2 Loss                  23.6361
trainer/Policy Loss               35.9386
trainer/Q1 Predictions Mean      -34.3785
trainer/Q1 Predictions Std         1.31456
trainer/Q1 Predictions Max       -32.4061
trainer/Q1 Predictions Min       -37.4646
trainer/Q2 Predictions Mean      -34.4002
trainer/Q2 Predictions Std         1.30187
trainer/Q2 Predictions Max       -32.4106
trainer/Q2 Predictions Min       -37.4749
trainer/Q Targets Mean           -34.0352
trainer/Q Targets Std              4.86724
trainer/Q Targets Max             -1
trainer/Q Targets Min            -37.1861
trainer/Log Pis Mean               1.71542
trainer/Log Pis Std                1.647
trainer/Log Pis Max                6.27564
trainer/Log Pis Min               -4.17854
trainer/Policy mu Mean             0.323281
trainer/Policy mu Std              0.750922
trainer/Policy mu Max              2.57398
trainer/Policy mu Min             -2.49323
trainer/Policy log std Mean       -1.84607
trainer/Policy log std Std         0.512216
trainer/Policy log std Max        -0.540862
trainer/Policy log std Min        -2.64604
trainer/Alpha                      0.0104798
trainer/Alpha Loss                -1.29718
exploration/num steps total    18000
exploration/num paths total      180
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.98716
exploration/Rewards Std            0.0415602
exploration/Rewards Max           -0.705446
exploration/Rewards Min           -1
exploration/Returns Mean         -98.716
exploration/Returns Std            1.28403
exploration/Returns Max          -97.4319
exploration/Returns Min         -100
exploration/Actions Mean           0.0208392
exploration/Actions Std            0.220318
exploration/Actions Max            0.980391
exploration/Actions Min           -0.972632
exploration/Num Paths              2
exploration/Average Returns      -98.716
evaluation/num steps total     89000
evaluation/num paths total       890
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.993023
evaluation/Rewards Std             0.0496878
evaluation/Rewards Max            -0.312201
evaluation/Rewards Min            -1
evaluation/Returns Mean          -99.3023
evaluation/Returns Std             0.724936
evaluation/Returns Max           -98.2784
evaluation/Returns Min          -100
evaluation/Actions Mean            0.0184083
evaluation/Actions Std             0.16167
evaluation/Actions Max             0.997013
evaluation/Actions Min            -0.701355
evaluation/Num Paths              10
evaluation/Average Returns       -99.3023
time/data storing (s)              0.0011891
time/evaluation sampling (s)       0.239133
time/exploration sampling (s)      0.0698416
time/logging (s)                   0.00335375
time/saving (s)                    0.00235654
time/training (s)                  1.01073
time/epoch (s)                     1.3266
time/total (s)                   119.849
Epoch                             88
-----------------------------  --------------
2019-04-22 20:50:31.901018 PDT | [sac-pointmass-multitask-1_2019_04_22_20_48_30_0000--s-0] Epoch 89 finished
-----------------------------  --------------
replay_buffer/size             18200
trainer/QF1 Loss                  10.8045
trainer/QF2 Loss                  10.8254
trainer/Policy Loss               36.3616
trainer/Q1 Predictions Mean      -34.7019
trainer/Q1 Predictions Std         1.17286
trainer/Q1 Predictions Max       -32.8401
trainer/Q1 Predictions Min       -37.1832
trainer/Q2 Predictions Mean      -34.6824
trainer/Q2 Predictions Std         1.17993
trainer/Q2 Predictions Max       -32.7582
trainer/Q2 Predictions Min       -37.1505
trainer/Q Targets Mean           -34.5759
trainer/Q Targets Std              3.64491
trainer/Q Targets Max             -0.666784
trainer/Q Targets Min            -37.7479
trainer/Log Pis Mean               1.85109
trainer/Log Pis Std                1.38702
trainer/Log Pis Max                5.3402
trainer/Log Pis Min               -4.1322
trainer/Policy mu Mean             0.066303
trainer/Policy mu Std              0.812654
trainer/Policy mu Max              2.80565
trainer/Policy mu Min             -1.98277
trainer/Policy log std Mean       -1.81906
trainer/Policy log std Std         0.479485
trainer/Policy log std Max        -0.476874
trainer/Policy log std Min        -2.59115
trainer/Alpha                      0.0103924
trainer/Alpha Loss                -0.680009
exploration/num steps total    18200
exploration/num paths total      182
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1
exploration/Rewards Std            0
exploration/Rewards Max           -1
exploration/Rewards Min           -1
exploration/Returns Mean        -100
exploration/Returns Std            0
exploration/Returns Max         -100
exploration/Returns Min         -100
exploration/Actions Mean           0.0141118
exploration/Actions Std            0.261283
exploration/Actions Max            0.900648
exploration/Actions Min           -0.889
exploration/Num Paths              2
exploration/Average Returns     -100
evaluation/num steps total     90000
evaluation/num paths total       900
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.964214
evaluation/Rewards Std             0.113827
evaluation/Rewards Max            -0.283897
evaluation/Rewards Min            -1
evaluation/Returns Mean          -96.4214
evaluation/Returns Std            10.7358
evaluation/Returns Max           -64.2141
evaluation/Returns Min          -100
evaluation/Actions Mean            0.0153131
evaluation/Actions Std             0.250312
evaluation/Actions Max             0.958602
evaluation/Actions Min            -0.718639
evaluation/Num Paths              10
evaluation/Average Returns       -96.4214
time/data storing (s)              0.00120969
time/evaluation sampling (s)       0.239508
time/exploration sampling (s)      0.0704273
time/logging (s)                   0.00311123
time/saving (s)                    0.00240804
time/training (s)                  1.00472
time/epoch (s)                     1.32138
time/total (s)                   121.173
Epoch                             89
-----------------------------  --------------
2019-04-22 20:50:33.239942 PDT | [sac-pointmass-multitask-1_2019_04_22_20_48_30_0000--s-0] Epoch 90 finished
-----------------------------  --------------
replay_buffer/size             18400
trainer/QF1 Loss                  23.721
trainer/QF2 Loss                  23.7843
trainer/Policy Loss               36.4508
trainer/Q1 Predictions Mean      -34.69
trainer/Q1 Predictions Std         1.40996
trainer/Q1 Predictions Max       -32.6535
trainer/Q1 Predictions Min       -37.2527
trainer/Q2 Predictions Mean      -34.7158
trainer/Q2 Predictions Std         1.44191
trainer/Q2 Predictions Max       -32.5649
trainer/Q2 Predictions Min       -37.4761
trainer/Q Targets Mean           -34.3049
trainer/Q Targets Std              4.98782
trainer/Q Targets Max             -1
trainer/Q Targets Min            -37.6196
trainer/Log Pis Mean               1.83315
trainer/Log Pis Std                1.52159
trainer/Log Pis Max                4.51285
trainer/Log Pis Min               -6.94046
trainer/Policy mu Mean             0.278501
trainer/Policy mu Std              0.716406
trainer/Policy mu Max              2.61473
trainer/Policy mu Min             -1.73041
trainer/Policy log std Mean       -1.93847
trainer/Policy log std Std         0.510592
trainer/Policy log std Max        -0.643516
trainer/Policy log std Min        -2.64735
trainer/Alpha                      0.0101445
trainer/Alpha Loss                -0.765985
exploration/num steps total    18400
exploration/num paths total      184
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.864322
exploration/Rewards Std            0.149216
exploration/Rewards Max           -0.513106
exploration/Rewards Min           -1
exploration/Returns Mean         -86.4322
exploration/Returns Std           13.5678
exploration/Returns Max          -72.8644
exploration/Returns Min         -100
exploration/Actions Mean          -0.0133837
exploration/Actions Std            0.171485
exploration/Actions Max            0.846746
exploration/Actions Min           -0.87463
exploration/Num Paths              2
exploration/Average Returns      -86.4322
evaluation/num steps total     91000
evaluation/num paths total       910
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.893423
evaluation/Rewards Std             0.13881
evaluation/Rewards Max            -0.358896
evaluation/Rewards Min            -1
evaluation/Returns Mean          -89.3423
evaluation/Returns Std            13.0582
evaluation/Returns Max           -72.5108
evaluation/Returns Min          -100
evaluation/Actions Mean            0.00850532
evaluation/Actions Std             0.177705
evaluation/Actions Max             0.987328
evaluation/Actions Min            -0.524845
evaluation/Num Paths              10
evaluation/Average Returns       -89.3423
time/data storing (s)              0.00118858
time/evaluation sampling (s)       0.248162
time/exploration sampling (s)      0.0708048
time/logging (s)                   0.00339583
time/saving (s)                    0.00256828
time/training (s)                  1.00747
time/epoch (s)                     1.33359
time/total (s)                   122.511
Epoch                             90
-----------------------------  --------------
2019-04-22 20:50:34.571095 PDT | [sac-pointmass-multitask-1_2019_04_22_20_48_30_0000--s-0] Epoch 91 finished
-----------------------------  --------------
replay_buffer/size             18600
trainer/QF1 Loss                  24.5794
trainer/QF2 Loss                  24.6317
trainer/Policy Loss               36.6758
trainer/Q1 Predictions Mean      -34.9323
trainer/Q1 Predictions Std         1.60257
trainer/Q1 Predictions Max       -32.0469
trainer/Q1 Predictions Min       -37.9703
trainer/Q2 Predictions Mean      -34.9137
trainer/Q2 Predictions Std         1.6194
trainer/Q2 Predictions Max       -32.1404
trainer/Q2 Predictions Min       -37.9492
trainer/Q Targets Mean           -34.4505
trainer/Q Targets Std              4.97941
trainer/Q Targets Max             -1
trainer/Q Targets Min            -38.0463
trainer/Log Pis Mean               1.90909
trainer/Log Pis Std                1.24288
trainer/Log Pis Max                5.65547
trainer/Log Pis Min               -1.027
trainer/Policy mu Mean             0.12347
trainer/Policy mu Std              0.761139
trainer/Policy mu Max              2.99856
trainer/Policy mu Min             -2.16129
trainer/Policy log std Mean       -1.86218
trainer/Policy log std Std         0.492705
trainer/Policy log std Max        -0.674475
trainer/Policy log std Min        -2.62354
trainer/Alpha                      0.00999399
trainer/Alpha Loss                -0.418712
exploration/num steps total    18600
exploration/num paths total      186
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1
exploration/Rewards Std            0
exploration/Rewards Max           -1
exploration/Rewards Min           -1
exploration/Returns Mean        -100
exploration/Returns Std            0
exploration/Returns Max         -100
exploration/Returns Min         -100
exploration/Actions Mean          -0.00523892
exploration/Actions Std            0.275387
exploration/Actions Max            0.973256
exploration/Actions Min           -0.935419
exploration/Num Paths              2
exploration/Average Returns     -100
evaluation/num steps total     92000
evaluation/num paths total       920
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.960472
evaluation/Rewards Std             0.0840455
evaluation/Rewards Max            -0.440864
evaluation/Rewards Min            -1
evaluation/Returns Mean          -96.0472
evaluation/Returns Std             7.90925
evaluation/Returns Max           -79.7055
evaluation/Returns Min          -100
evaluation/Actions Mean            0.00548677
evaluation/Actions Std             0.218562
evaluation/Actions Max             0.978489
evaluation/Actions Min            -0.96019
evaluation/Num Paths              10
evaluation/Average Returns       -96.0472
time/data storing (s)              0.00118607
time/evaluation sampling (s)       0.242625
time/exploration sampling (s)      0.0700434
time/logging (s)                   0.00339944
time/saving (s)                    0.00253376
time/training (s)                  1.00541
time/epoch (s)                     1.3252
time/total (s)                   123.841
Epoch                             91
-----------------------------  --------------
2019-04-22 20:50:35.910082 PDT | [sac-pointmass-multitask-1_2019_04_22_20_48_30_0000--s-0] Epoch 92 finished
-----------------------------  --------------
replay_buffer/size             18800
trainer/QF1 Loss                  36.1613
trainer/QF2 Loss                  36.0654
trainer/Policy Loss               36.7644
trainer/Q1 Predictions Mean      -35.0412
trainer/Q1 Predictions Std         1.28803
trainer/Q1 Predictions Max       -32.7802
trainer/Q1 Predictions Min       -37.7294
trainer/Q2 Predictions Mean      -35.032
trainer/Q2 Predictions Std         1.28973
trainer/Q2 Predictions Max       -32.8044
trainer/Q2 Predictions Min       -37.7443
trainer/Q Targets Mean           -34.267
trainer/Q Targets Std              6.02053
trainer/Q Targets Max             -1
trainer/Q Targets Min            -38.3724
trainer/Log Pis Mean               1.8305
trainer/Log Pis Std                1.09149
trainer/Log Pis Max                4.08875
trainer/Log Pis Min               -1.32598
trainer/Policy mu Mean             0.146202
trainer/Policy mu Std              0.670604
trainer/Policy mu Max              2.50213
trainer/Policy mu Min             -1.51181
trainer/Policy log std Mean       -1.93254
trainer/Policy log std Std         0.475433
trainer/Policy log std Max        -0.617044
trainer/Policy log std Min        -2.62344
trainer/Alpha                      0.009907
trainer/Alpha Loss                -0.78216
exploration/num steps total    18800
exploration/num paths total      188
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1
exploration/Rewards Std            0
exploration/Rewards Max           -1
exploration/Rewards Min           -1
exploration/Returns Mean        -100
exploration/Returns Std            0
exploration/Returns Max         -100
exploration/Returns Min         -100
exploration/Actions Mean           0.0226692
exploration/Actions Std            0.235816
exploration/Actions Max            0.968081
exploration/Actions Min           -0.543155
exploration/Num Paths              2
exploration/Average Returns     -100
evaluation/num steps total     93000
evaluation/num paths total       930
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.916791
evaluation/Rewards Std             0.131028
evaluation/Rewards Max            -0.234367
evaluation/Rewards Min            -1
evaluation/Returns Mean          -91.6791
evaluation/Returns Std            12.711
evaluation/Returns Max           -72.0213
evaluation/Returns Min          -100
evaluation/Actions Mean            0.00428453
evaluation/Actions Std             0.296122
evaluation/Actions Max             0.997045
evaluation/Actions Min            -0.942297
evaluation/Num Paths              10
evaluation/Average Returns       -91.6791
time/data storing (s)              0.00119895
time/evaluation sampling (s)       0.247219
time/exploration sampling (s)      0.0703649
time/logging (s)                   0.00344845
time/saving (s)                    0.00235879
time/training (s)                  1.00852
time/epoch (s)                     1.33311
time/total (s)                   125.178
Epoch                             92
-----------------------------  --------------
2019-04-22 20:50:37.257464 PDT | [sac-pointmass-multitask-1_2019_04_22_20_48_30_0000--s-0] Epoch 93 finished
-----------------------------  --------------
replay_buffer/size             19000
trainer/QF1 Loss                   0.222217
trainer/QF2 Loss                   0.198137
trainer/Policy Loss               36.7168
trainer/Q1 Predictions Mean      -34.9812
trainer/Q1 Predictions Std         1.69177
trainer/Q1 Predictions Max       -32.4838
trainer/Q1 Predictions Min       -38.2435
trainer/Q2 Predictions Mean      -35.0001
trainer/Q2 Predictions Std         1.68199
trainer/Q2 Predictions Max       -32.4717
trainer/Q2 Predictions Min       -38.219
trainer/Q Targets Mean           -35.386
trainer/Q Targets Std              1.61749
trainer/Q Targets Max            -32.9364
trainer/Q Targets Min            -38.5428
trainer/Log Pis Mean               1.90064
trainer/Log Pis Std                1.53385
trainer/Log Pis Max                7.27633
trainer/Log Pis Min               -3.02677
trainer/Policy mu Mean             0.366817
trainer/Policy mu Std              0.862095
trainer/Policy mu Max              3.3659
trainer/Policy mu Min             -1.69069
trainer/Policy log std Mean       -1.71892
trainer/Policy log std Std         0.577787
trainer/Policy log std Max        -0.567671
trainer/Policy log std Min        -2.66101
trainer/Alpha                      0.00985477
trainer/Alpha Loss                -0.459004
exploration/num steps total    19000
exploration/num paths total      190
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.964514
exploration/Rewards Std            0.0683365
exploration/Rewards Max           -0.588483
exploration/Rewards Min           -1
exploration/Returns Mean         -96.4514
exploration/Returns Std            1.23994
exploration/Returns Max          -95.2114
exploration/Returns Min          -97.6913
exploration/Actions Mean           0.0201071
exploration/Actions Std            0.211151
exploration/Actions Max            0.993337
exploration/Actions Min           -0.979493
exploration/Num Paths              2
exploration/Average Returns      -96.4514
evaluation/num steps total     94000
evaluation/num paths total       940
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.992594
evaluation/Rewards Std             0.0482159
evaluation/Rewards Max            -0.300871
evaluation/Rewards Min            -1
evaluation/Returns Mean          -99.2594
evaluation/Returns Std             0.751866
evaluation/Returns Max           -98.3338
evaluation/Returns Min          -100
evaluation/Actions Mean            0.0138582
evaluation/Actions Std             0.134398
evaluation/Actions Max             0.994853
evaluation/Actions Min            -0.976823
evaluation/Num Paths              10
evaluation/Average Returns       -99.2594
time/data storing (s)              0.00119193
time/evaluation sampling (s)       0.24345
time/exploration sampling (s)      0.0705884
time/logging (s)                   0.00304499
time/saving (s)                    0.00260791
time/training (s)                  1.01966
time/epoch (s)                     1.34054
time/total (s)                   126.523
Epoch                             93
-----------------------------  --------------
2019-04-22 20:50:38.601302 PDT | [sac-pointmass-multitask-1_2019_04_22_20_48_30_0000--s-0] Epoch 94 finished
-----------------------------  --------------
replay_buffer/size             19200
trainer/QF1 Loss                   0.766892
trainer/QF2 Loss                   0.833105
trainer/Policy Loss               35.7966
trainer/Q1 Predictions Mean      -34.5863
trainer/Q1 Predictions Std         1.68012
trainer/Q1 Predictions Max       -32.1856
trainer/Q1 Predictions Min       -37.8196
trainer/Q2 Predictions Mean      -34.5429
trainer/Q2 Predictions Std         1.63094
trainer/Q2 Predictions Max       -32.131
trainer/Q2 Predictions Min       -37.7861
trainer/Q Targets Mean           -35.4132
trainer/Q Targets Std              1.66619
trainer/Q Targets Max            -32.6687
trainer/Q Targets Min            -38.4724
trainer/Log Pis Mean               1.30664
trainer/Log Pis Std                1.37914
trainer/Log Pis Max                5.70942
trainer/Log Pis Min               -2.93321
trainer/Policy mu Mean             0.211979
trainer/Policy mu Std              0.717785
trainer/Policy mu Max              2.64786
trainer/Policy mu Min             -1.86317
trainer/Policy log std Mean       -1.62851
trainer/Policy log std Std         0.546483
trainer/Policy log std Max        -0.432151
trainer/Policy log std Min        -2.53854
trainer/Alpha                      0.00985914
trainer/Alpha Loss                -3.20261
exploration/num steps total    19200
exploration/num paths total      192
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.83456
exploration/Rewards Std            0.182679
exploration/Rewards Max           -0.116719
exploration/Rewards Min           -1
exploration/Returns Mean         -83.456
exploration/Returns Std           12.8589
exploration/Returns Max          -70.5972
exploration/Returns Min          -96.3149
exploration/Actions Mean           0.0470126
exploration/Actions Std            0.275951
exploration/Actions Max            0.992502
exploration/Actions Min           -0.962823
exploration/Num Paths              2
exploration/Average Returns      -83.456
evaluation/num steps total     95000
evaluation/num paths total       950
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.875635
evaluation/Rewards Std             0.157184
evaluation/Rewards Max            -0.436806
evaluation/Rewards Min            -1
evaluation/Returns Mean          -87.5635
evaluation/Returns Std            15.2344
evaluation/Returns Max           -68.3226
evaluation/Returns Min          -100
evaluation/Actions Mean            0.0171942
evaluation/Actions Std             0.137301
evaluation/Actions Max             0.996068
evaluation/Actions Min            -0.974087
evaluation/Num Paths              10
evaluation/Average Returns       -87.5635
time/data storing (s)              0.00118775
time/evaluation sampling (s)       0.241011
time/exploration sampling (s)      0.071654
time/logging (s)                   0.00330337
time/saving (s)                    0.00255456
time/training (s)                  1.01832
time/epoch (s)                     1.33803
time/total (s)                   127.865
Epoch                             94
-----------------------------  --------------
2019-04-22 20:50:39.951212 PDT | [sac-pointmass-multitask-1_2019_04_22_20_48_30_0000--s-0] Epoch 95 finished
-----------------------------  --------------
replay_buffer/size             19400
trainer/QF1 Loss                  24.69
trainer/QF2 Loss                  24.7108
trainer/Policy Loss               36.6377
trainer/Q1 Predictions Mean      -34.7546
trainer/Q1 Predictions Std         1.64435
trainer/Q1 Predictions Max       -32.4324
trainer/Q1 Predictions Min       -37.7026
trainer/Q2 Predictions Mean      -34.7514
trainer/Q2 Predictions Std         1.60868
trainer/Q2 Predictions Max       -32.372
trainer/Q2 Predictions Min       -37.6003
trainer/Q Targets Mean           -34.7347
trainer/Q Targets Std              5.07681
trainer/Q Targets Max             -1
trainer/Q Targets Min            -38.2585
trainer/Log Pis Mean               2.06553
trainer/Log Pis Std                1.17773
trainer/Log Pis Max                5.32982
trainer/Log Pis Min               -2.51125
trainer/Policy mu Mean             0.0299788
trainer/Policy mu Std              0.783765
trainer/Policy mu Max              2.50011
trainer/Policy mu Min             -1.91055
trainer/Policy log std Mean       -1.92793
trainer/Policy log std Std         0.498709
trainer/Policy log std Max        -0.403992
trainer/Policy log std Min        -2.63339
trainer/Alpha                      0.00978592
trainer/Alpha Loss                 0.303209
exploration/num steps total    19400
exploration/num paths total      194
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.790707
exploration/Rewards Std            0.227981
exploration/Rewards Max           -0.400511
exploration/Rewards Min           -1
exploration/Returns Mean         -79.0707
exploration/Returns Std           20.9293
exploration/Returns Max          -58.1413
exploration/Returns Min         -100
exploration/Actions Mean          -0.00575985
exploration/Actions Std            0.227386
exploration/Actions Max            0.874917
exploration/Actions Min           -0.954516
exploration/Num Paths              2
exploration/Average Returns      -79.0707
evaluation/num steps total     96000
evaluation/num paths total       960
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.865333
evaluation/Rewards Std             0.21007
evaluation/Rewards Max            -0.160635
evaluation/Rewards Min            -1
evaluation/Returns Mean          -86.5333
evaluation/Returns Std            20.5759
evaluation/Returns Max           -54.272
evaluation/Returns Min          -100
evaluation/Actions Mean            0.00286851
evaluation/Actions Std             0.123907
evaluation/Actions Max             0.964219
evaluation/Actions Min            -0.97864
evaluation/Num Paths              10
evaluation/Average Returns       -86.5333
time/data storing (s)              0.00140664
time/evaluation sampling (s)       0.23795
time/exploration sampling (s)      0.071246
time/logging (s)                   0.00332775
time/saving (s)                    0.00246834
time/training (s)                  1.02758
time/epoch (s)                     1.34398
time/total (s)                   129.213
Epoch                             95
-----------------------------  --------------
2019-04-22 20:50:41.300976 PDT | [sac-pointmass-multitask-1_2019_04_22_20_48_30_0000--s-0] Epoch 96 finished
-----------------------------  --------------
replay_buffer/size             19600
trainer/QF1 Loss                   0.568746
trainer/QF2 Loss                   0.554094
trainer/Policy Loss               36.5674
trainer/Q1 Predictions Mean      -34.9952
trainer/Q1 Predictions Std         1.69201
trainer/Q1 Predictions Max       -32.4242
trainer/Q1 Predictions Min       -38.0672
trainer/Q2 Predictions Mean      -35.0033
trainer/Q2 Predictions Std         1.68201
trainer/Q2 Predictions Max       -32.3542
trainer/Q2 Predictions Min       -38.1111
trainer/Q Targets Mean           -35.6912
trainer/Q Targets Std              1.75127
trainer/Q Targets Max            -32.7971
trainer/Q Targets Min            -38.416
trainer/Log Pis Mean               1.73937
trainer/Log Pis Std                1.51771
trainer/Log Pis Max                7.79842
trainer/Log Pis Min               -1.38244
trainer/Policy mu Mean             0.501419
trainer/Policy mu Std              0.808511
trainer/Policy mu Max              3.32196
trainer/Policy mu Min             -2.01818
trainer/Policy log std Mean       -1.66784
trainer/Policy log std Std         0.510544
trainer/Policy log std Max        -0.640128
trainer/Policy log std Min        -2.62519
trainer/Alpha                      0.00970064
trainer/Alpha Loss                -1.20817
exploration/num steps total    19600
exploration/num paths total      196
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.888245
exploration/Rewards Std            0.103929
exploration/Rewards Max           -0.574839
exploration/Rewards Min           -1
exploration/Returns Mean         -88.8245
exploration/Returns Std            0.92274
exploration/Returns Max          -87.9017
exploration/Returns Min          -89.7472
exploration/Actions Mean           0.0384413
exploration/Actions Std            0.273713
exploration/Actions Max            0.997195
exploration/Actions Min           -0.970363
exploration/Num Paths              2
exploration/Average Returns      -88.8245
evaluation/num steps total     97000
evaluation/num paths total       970
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.877219
evaluation/Rewards Std             0.0721637
evaluation/Rewards Max            -0.402985
evaluation/Rewards Min            -1
evaluation/Returns Mean          -87.7219
evaluation/Returns Std             4.15822
evaluation/Returns Max           -85.1316
evaluation/Returns Min          -100
evaluation/Actions Mean            0.0291623
evaluation/Actions Std             0.192791
evaluation/Actions Max             0.997438
evaluation/Actions Min            -0.92753
evaluation/Num Paths              10
evaluation/Average Returns       -87.7219
time/data storing (s)              0.00131389
time/evaluation sampling (s)       0.251787
time/exploration sampling (s)      0.0711966
time/logging (s)                   0.00361395
time/saving (s)                    0.0023478
time/training (s)                  1.01362
time/epoch (s)                     1.34388
time/total (s)                   130.561
Epoch                             96
-----------------------------  --------------
2019-04-22 20:50:42.663371 PDT | [sac-pointmass-multitask-1_2019_04_22_20_48_30_0000--s-0] Epoch 97 finished
-----------------------------  --------------
replay_buffer/size             19800
trainer/QF1 Loss                  22.9866
trainer/QF2 Loss                  23.0114
trainer/Policy Loss               36.4189
trainer/Q1 Predictions Mean      -34.7191
trainer/Q1 Predictions Std         1.84682
trainer/Q1 Predictions Max       -32.3087
trainer/Q1 Predictions Min       -38.0873
trainer/Q2 Predictions Mean      -34.7246
trainer/Q2 Predictions Std         1.84018
trainer/Q2 Predictions Max       -32.4164
trainer/Q2 Predictions Min       -38.1054
trainer/Q Targets Mean           -34.5718
trainer/Q Targets Std              5.10759
trainer/Q Targets Max             -1
trainer/Q Targets Min            -38.6611
trainer/Log Pis Mean               1.85986
trainer/Log Pis Std                1.38865
trainer/Log Pis Max                6.17092
trainer/Log Pis Min               -3.49399
trainer/Policy mu Mean             0.213223
trainer/Policy mu Std              0.798046
trainer/Policy mu Max              3.51884
trainer/Policy mu Min             -2.21177
trainer/Policy log std Mean       -1.88994
trainer/Policy log std Std         0.485689
trainer/Policy log std Max        -0.536397
trainer/Policy log std Min        -2.48576
trainer/Alpha                      0.00949856
trainer/Alpha Loss                -0.652571
exploration/num steps total    19800
exploration/num paths total      198
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.932825
exploration/Rewards Std            0.0855534
exploration/Rewards Max           -0.65737
exploration/Rewards Min           -1
exploration/Returns Mean         -93.2825
exploration/Returns Std            1.89388
exploration/Returns Max          -91.3886
exploration/Returns Min          -95.1764
exploration/Actions Mean           0.0217297
exploration/Actions Std            0.164503
exploration/Actions Max            0.969145
exploration/Actions Min           -0.984645
exploration/Num Paths              2
exploration/Average Returns      -93.2825
evaluation/num steps total     98000
evaluation/num paths total       980
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.990142
evaluation/Rewards Std             0.0566758
evaluation/Rewards Max            -0.418169
evaluation/Rewards Min            -1
evaluation/Returns Mean          -99.0142
evaluation/Returns Std             0.703934
evaluation/Returns Max           -98.1674
evaluation/Returns Min          -100
evaluation/Actions Mean            0.011702
evaluation/Actions Std             0.16613
evaluation/Actions Max             0.99788
evaluation/Actions Min            -0.976583
evaluation/Num Paths              10
evaluation/Average Returns       -99.0142
time/data storing (s)              0.0012951
time/evaluation sampling (s)       0.251166
time/exploration sampling (s)      0.0729955
time/logging (s)                   0.00338892
time/saving (s)                    0.00245856
time/training (s)                  1.02477
time/epoch (s)                     1.35607
time/total (s)                   131.921
Epoch                             97
-----------------------------  --------------
2019-04-22 20:50:43.999518 PDT | [sac-pointmass-multitask-1_2019_04_22_20_48_30_0000--s-0] Epoch 98 finished
-----------------------------  --------------
replay_buffer/size             20000
trainer/QF1 Loss                  11.2864
trainer/QF2 Loss                  11.387
trainer/Policy Loss               37.4886
trainer/Q1 Predictions Mean      -35.7585
trainer/Q1 Predictions Std         1.86593
trainer/Q1 Predictions Max       -33.1032
trainer/Q1 Predictions Min       -39.4502
trainer/Q2 Predictions Mean      -35.7495
trainer/Q2 Predictions Std         1.87474
trainer/Q2 Predictions Max       -33.0146
trainer/Q2 Predictions Min       -39.3301
trainer/Q Targets Mean           -35.6092
trainer/Q Targets Std              3.97054
trainer/Q Targets Max             -1
trainer/Q Targets Min            -39.5181
trainer/Log Pis Mean               1.88435
trainer/Log Pis Std                1.2695
trainer/Log Pis Max                5.71232
trainer/Log Pis Min               -2.38531
trainer/Policy mu Mean             0.283613
trainer/Policy mu Std              0.769307
trainer/Policy mu Max              3.41044
trainer/Policy mu Min             -1.61224
trainer/Policy log std Mean       -1.82601
trainer/Policy log std Std         0.481477
trainer/Policy log std Max        -0.559928
trainer/Policy log std Min        -2.49972
trainer/Alpha                      0.00937897
trainer/Alpha Loss                -0.539988
exploration/num steps total    20000
exploration/num paths total      200
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.955992
exploration/Rewards Std            0.0766938
exploration/Rewards Max           -0.651877
exploration/Rewards Min           -1
exploration/Returns Mean         -95.5992
exploration/Returns Std            4.40076
exploration/Returns Max          -91.1985
exploration/Returns Min         -100
exploration/Actions Mean           0.0062183
exploration/Actions Std            0.192296
exploration/Actions Max            0.785302
exploration/Actions Min           -0.963277
exploration/Num Paths              2
exploration/Average Returns      -95.5992
evaluation/num steps total     99000
evaluation/num paths total       990
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.989088
evaluation/Rewards Std             0.0428057
evaluation/Rewards Max            -0.344943
evaluation/Rewards Min            -1
evaluation/Returns Mean          -98.9088
evaluation/Returns Std             1.67662
evaluation/Returns Max           -96.0036
evaluation/Returns Min          -100
evaluation/Actions Mean            0.0103096
evaluation/Actions Std             0.15624
evaluation/Actions Max             0.992521
evaluation/Actions Min            -0.96718
evaluation/Num Paths              10
evaluation/Average Returns       -98.9088
time/data storing (s)              0.00116735
time/evaluation sampling (s)       0.235224
time/exploration sampling (s)      0.0707011
time/logging (s)                   0.00340934
time/saving (s)                    0.00234705
time/training (s)                  1.01682
time/epoch (s)                     1.32967
time/total (s)                   133.255
Epoch                             98
-----------------------------  --------------
2019-04-22 20:50:45.346491 PDT | [sac-pointmass-multitask-1_2019_04_22_20_48_30_0000--s-0] Epoch 99 finished
-----------------------------  ---------------
replay_buffer/size              20200
trainer/QF1 Loss                   23.2941
trainer/QF2 Loss                   23.4037
trainer/Policy Loss                37.4471
trainer/Q1 Predictions Mean       -35.588
trainer/Q1 Predictions Std          1.805
trainer/Q1 Predictions Max        -32.8498
trainer/Q1 Predictions Min        -38.9829
trainer/Q2 Predictions Mean       -35.6308
trainer/Q2 Predictions Std          1.7856
trainer/Q2 Predictions Max        -32.8877
trainer/Q2 Predictions Min        -39.044
trainer/Q Targets Mean            -35.2519
trainer/Q Targets Std               5.19726
trainer/Q Targets Max              -1
trainer/Q Targets Min             -39.2324
trainer/Log Pis Mean                2.07108
trainer/Log Pis Std                 1.2119
trainer/Log Pis Max                 5.96372
trainer/Log Pis Min                -1.40616
trainer/Policy mu Mean              0.307945
trainer/Policy mu Std               0.787693
trainer/Policy mu Max               2.96298
trainer/Policy mu Min              -2.23424
trainer/Policy log std Mean        -1.88954
trainer/Policy log std Std          0.462385
trainer/Policy log std Max         -0.578986
trainer/Policy log std Min         -2.62954
trainer/Alpha                       0.00930223
trainer/Alpha Loss                  0.332482
exploration/num steps total     20200
exploration/num paths total       202
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.951926
exploration/Rewards Std             0.117446
exploration/Rewards Max            -0.0682967
exploration/Rewards Min            -1
exploration/Returns Mean          -95.1926
exploration/Returns Std             0.23831
exploration/Returns Max           -94.9543
exploration/Returns Min           -95.4309
exploration/Actions Mean            0.0465892
exploration/Actions Std             0.183387
exploration/Actions Max             0.9984
exploration/Actions Min            -0.307589
exploration/Num Paths               2
exploration/Average Returns       -95.1926
evaluation/num steps total     100000
evaluation/num paths total       1000
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.981635
evaluation/Rewards Std              0.0888794
evaluation/Rewards Max             -0.142241
evaluation/Rewards Min             -1
evaluation/Returns Mean           -98.1635
evaluation/Returns Std              0.286517
evaluation/Returns Max            -97.8298
evaluation/Returns Min            -98.5175
evaluation/Actions Mean             0.0549131
evaluation/Actions Std              0.206469
evaluation/Actions Max              0.998402
evaluation/Actions Min             -0.916423
evaluation/Num Paths               10
evaluation/Average Returns        -98.1635
time/data storing (s)               0.00117229
time/evaluation sampling (s)        0.255746
time/exploration sampling (s)       0.0718251
time/logging (s)                    0.00276992
time/saving (s)                     0.00233357
time/training (s)                   1.00594
time/epoch (s)                      1.33979
time/total (s)                    134.599
Epoch                              99
-----------------------------  ---------------
