2019-04-22 20:10:59.092353 PDT | [sac-pointmass-multitask-1_2019_04_22_20_10_57_0000--s-0] Epoch 0 finished
-----------------------------  --------------
replay_buffer/size              400
trainer/QF1 Loss                 23.4151
trainer/QF2 Loss                 23.4147
trainer/Policy Loss              -1.33006
trainer/Q1 Predictions Mean      -0.00104197
trainer/Q1 Predictions Std        0.000541342
trainer/Q1 Predictions Max       -8.6378e-05
trainer/Q1 Predictions Min       -0.00259231
trainer/Q2 Predictions Mean      -0.000957585
trainer/Q2 Predictions Std        0.000234783
trainer/Q2 Predictions Max       -0.000308505
trainer/Q2 Predictions Min       -0.00146725
trainer/Q Targets Mean           -4.54253
trainer/Q Targets Std             1.67007
trainer/Q Targets Max            -0.951543
trainer/Q Targets Min            -8.518
trainer/Log Pis Mean             -1.3313
trainer/Log Pis Std               0.265262
trainer/Log Pis Max              -0.63172
trainer/Log Pis Min              -1.82398
trainer/Policy mu Mean            0.000318046
trainer/Policy mu Std             0.00022739
trainer/Policy mu Max             0.000857455
trainer/Policy mu Min            -0.000192505
trainer/Policy log std Mean       1.93979e-05
trainer/Policy log std Std        0.000305751
trainer/Policy log std Max        0.000516132
trainer/Policy log std Min       -0.000588279
trainer/Alpha                     0.9997
trainer/Alpha Loss               -0
exploration/num steps total     400
exploration/num paths total       4
exploration/path length Mean    100
exploration/path length Std       0
exploration/path length Max     100
exploration/path length Min     100
exploration/Rewards Mean         -4.55821
exploration/Rewards Std           1.68662
exploration/Rewards Max          -0.133616
exploration/Rewards Min          -8.02878
exploration/Returns Mean       -455.821
exploration/Returns Std          55.5469
exploration/Returns Max        -400.274
exploration/Returns Min        -511.368
exploration/Actions Mean          0.0184442
exploration/Actions Std           0.622068
exploration/Actions Max           0.99356
exploration/Actions Min          -0.989041
exploration/Num Paths             2
exploration/Average Returns    -455.821
evaluation/num steps total     1000
evaluation/num paths total       10
evaluation/path length Mean     100
evaluation/path length Std        0
evaluation/path length Max      100
evaluation/path length Min      100
evaluation/Rewards Mean          -4.07875
evaluation/Rewards Std            1.66551
evaluation/Rewards Max           -1.52329
evaluation/Rewards Min           -6.17724
evaluation/Returns Mean        -407.875
evaluation/Returns Std          166.547
evaluation/Returns Max         -154.567
evaluation/Returns Min         -615.405
evaluation/Actions Mean           0.000313722
evaluation/Actions Std            0.000198196
evaluation/Actions Max            0.000693099
evaluation/Actions Min           -6.92695e-05
evaluation/Num Paths             10
evaluation/Average Returns     -407.875
time/data storing (s)             0.00122244
time/evaluation sampling (s)      0.222079
time/exploration sampling (s)     0.0640027
time/logging (s)                  0.00355067
time/saving (s)                   0.00231348
time/training (s)                 1.02511
time/epoch (s)                    1.31828
time/total (s)                    1.66901
Epoch                             0
-----------------------------  --------------
2019-04-22 20:11:00.415168 PDT | [sac-pointmass-multitask-1_2019_04_22_20_10_57_0000--s-0] Epoch 1 finished
-----------------------------  -------------
replay_buffer/size              600
trainer/QF1 Loss                  1.05281
trainer/QF2 Loss                  0.975402
trainer/Policy Loss               3.55718
trainer/Q1 Predictions Mean      -4.90453
trainer/Q1 Predictions Std        1.37974
trainer/Q1 Predictions Max       -2.85502
trainer/Q1 Predictions Min       -8.5085
trainer/Q2 Predictions Mean      -4.90862
trainer/Q2 Predictions Std        1.41564
trainer/Q2 Predictions Max       -2.66617
trainer/Q2 Predictions Min       -8.37502
trainer/Q Targets Mean           -4.86685
trainer/Q Targets Std             2.09291
trainer/Q Targets Max            -1.26056
trainer/Q Targets Min            -9.47516
trainer/Log Pis Mean             -1.36756
trainer/Log Pis Std               0.230891
trainer/Log Pis Max              -0.933648
trainer/Log Pis Min              -2.56306
trainer/Policy mu Mean           -0.0569643
trainer/Policy mu Std             0.0517901
trainer/Policy mu Max             0.0248624
trainer/Policy mu Min            -0.125852
trainer/Policy log std Mean      -0.149195
trainer/Policy log std Std        0.0122607
trainer/Policy log std Max       -0.128933
trainer/Policy log std Min       -0.183391
trainer/Alpha                     0.941471
trainer/Alpha Loss               -0.202094
exploration/num steps total     600
exploration/num paths total       6
exploration/path length Mean    100
exploration/path length Std       0
exploration/path length Max     100
exploration/path length Min     100
exploration/Rewards Mean         -5.12985
exploration/Rewards Std           2.49864
exploration/Rewards Max          -0.682559
exploration/Rewards Min          -8.69371
exploration/Returns Mean       -512.985
exploration/Returns Std         222.29
exploration/Returns Max        -290.695
exploration/Returns Min        -735.275
exploration/Actions Mean         -0.038081
exploration/Actions Std           0.588678
exploration/Actions Max           0.988362
exploration/Actions Min          -0.961664
exploration/Num Paths             2
exploration/Average Returns    -512.985
evaluation/num steps total     2000
evaluation/num paths total       20
evaluation/path length Mean     100
evaluation/path length Std        0
evaluation/path length Max      100
evaluation/path length Min      100
evaluation/Rewards Mean          -5.52455
evaluation/Rewards Std            1.31186
evaluation/Rewards Max           -1.96698
evaluation/Rewards Min           -7.44207
evaluation/Returns Mean        -552.455
evaluation/Returns Std           80.311
evaluation/Returns Max         -392.33
evaluation/Returns Min         -651.594
evaluation/Actions Mean          -0.0554013
evaluation/Actions Std            0.0547086
evaluation/Actions Max            0.0230772
evaluation/Actions Min           -0.126487
evaluation/Num Paths             10
evaluation/Average Returns     -552.455
time/data storing (s)             0.00130678
time/evaluation sampling (s)      0.263313
time/exploration sampling (s)     0.0667204
time/logging (s)                  0.00310582
time/saving (s)                   0.00233117
time/training (s)                 0.979899
time/epoch (s)                    1.31668
time/total (s)                    2.99046
Epoch                             1
-----------------------------  -------------
2019-04-22 20:11:01.708737 PDT | [sac-pointmass-multitask-1_2019_04_22_20_10_57_0000--s-0] Epoch 2 finished
-----------------------------  -------------
replay_buffer/size              800
trainer/QF1 Loss                  0.387904
trainer/QF2 Loss                  0.305489
trainer/Policy Loss               6.00581
trainer/Q1 Predictions Mean      -7.41303
trainer/Q1 Predictions Std        2.69937
trainer/Q1 Predictions Max       -3.50277
trainer/Q1 Predictions Min      -13.7867
trainer/Q2 Predictions Mean      -7.42142
trainer/Q2 Predictions Std        2.71603
trainer/Q2 Predictions Max       -3.24362
trainer/Q2 Predictions Min      -13.7953
trainer/Q Targets Mean           -7.5002
trainer/Q Targets Std             2.93122
trainer/Q Targets Max            -0.665513
trainer/Q Targets Min           -13.2144
trainer/Log Pis Mean             -1.28657
trainer/Log Pis Std               0.426741
trainer/Log Pis Max              -0.0683464
trainer/Log Pis Min              -2.28745
trainer/Policy mu Mean           -0.0294718
trainer/Policy mu Std             0.260469
trainer/Policy mu Max             0.476562
trainer/Policy mu Min            -0.420703
trainer/Policy log std Mean      -0.186709
trainer/Policy log std Std        0.0312537
trainer/Policy log std Max       -0.132711
trainer/Policy log std Min       -0.262636
trainer/Alpha                     0.887133
trainer/Alpha Loss               -0.392641
exploration/num steps total     800
exploration/num paths total       8
exploration/path length Mean    100
exploration/path length Std       0
exploration/path length Max     100
exploration/path length Min     100
exploration/Rewards Mean         -2.85358
exploration/Rewards Std           1.41363
exploration/Rewards Max          -0.126553
exploration/Rewards Min          -6.307
exploration/Returns Mean       -285.358
exploration/Returns Std          51.0525
exploration/Returns Max        -234.306
exploration/Returns Min        -336.411
exploration/Actions Mean          0.0215857
exploration/Actions Std           0.559183
exploration/Actions Max           0.992391
exploration/Actions Min          -0.985961
exploration/Num Paths             2
exploration/Average Returns    -285.358
evaluation/num steps total     3000
evaluation/num paths total       30
evaluation/path length Mean     100
evaluation/path length Std        0
evaluation/path length Max      100
evaluation/path length Min      100
evaluation/Rewards Mean          -1.05714
evaluation/Rewards Std            0.934439
evaluation/Rewards Max           -0.0468765
evaluation/Rewards Min           -7.49919
evaluation/Returns Mean        -105.714
evaluation/Returns Std           18.2034
evaluation/Returns Max          -75.1187
evaluation/Returns Min         -132.582
evaluation/Actions Mean          -0.0193196
evaluation/Actions Std            0.079501
evaluation/Actions Max            0.357567
evaluation/Actions Min           -0.377558
evaluation/Num Paths             10
evaluation/Average Returns     -105.714
time/data storing (s)             0.00119773
time/evaluation sampling (s)      0.246985
time/exploration sampling (s)     0.067346
time/logging (s)                  0.00331045
time/saving (s)                   0.00184456
time/training (s)                 0.968465
time/epoch (s)                    1.28915
time/total (s)                    4.2837
Epoch                             2
-----------------------------  -------------
2019-04-22 20:11:03.003530 PDT | [sac-pointmass-multitask-1_2019_04_22_20_10_57_0000--s-0] Epoch 3 finished
-----------------------------  -------------
replay_buffer/size             1000
trainer/QF1 Loss                  0.260628
trainer/QF2 Loss                  0.241349
trainer/Policy Loss               6.60854
trainer/Q1 Predictions Mean      -8.2372
trainer/Q1 Predictions Std        3.8913
trainer/Q1 Predictions Max       -3.88203
trainer/Q1 Predictions Min      -19.063
trainer/Q2 Predictions Mean      -8.2163
trainer/Q2 Predictions Std        3.92568
trainer/Q2 Predictions Max       -3.71755
trainer/Q2 Predictions Min      -19.1227
trainer/Q Targets Mean           -8.43783
trainer/Q Targets Std             4.07896
trainer/Q Targets Max            -3.43813
trainer/Q Targets Min           -19.0976
trainer/Log Pis Mean             -1.11855
trainer/Log Pis Std               0.87329
trainer/Log Pis Max               1.0625
trainer/Log Pis Min              -4.65112
trainer/Policy mu Mean           -0.010233
trainer/Policy mu Std             0.49222
trainer/Policy mu Max             0.874882
trainer/Policy mu Min            -1.05545
trainer/Policy log std Mean      -0.260397
trainer/Policy log std Std        0.0373953
trainer/Policy log std Max       -0.204326
trainer/Policy log std Min       -0.364142
trainer/Alpha                     0.838038
trainer/Alpha Loss               -0.550151
exploration/num steps total    1000
exploration/num paths total      10
exploration/path length Mean    100
exploration/path length Std       0
exploration/path length Max     100
exploration/path length Min     100
exploration/Rewards Mean         -1.44337
exploration/Rewards Std           1.02657
exploration/Rewards Max          -0.113955
exploration/Rewards Min          -6.26411
exploration/Returns Mean       -144.337
exploration/Returns Std          22.9607
exploration/Returns Max        -121.376
exploration/Returns Min        -167.298
exploration/Actions Mean          0.0187209
exploration/Actions Std           0.571489
exploration/Actions Max           0.983168
exploration/Actions Min          -0.991938
exploration/Num Paths             2
exploration/Average Returns    -144.337
evaluation/num steps total     4000
evaluation/num paths total       40
evaluation/path length Mean     100
evaluation/path length Std        0
evaluation/path length Max      100
evaluation/path length Min      100
evaluation/Rewards Mean          -0.299677
evaluation/Rewards Std            0.820208
evaluation/Rewards Max           -0.0623145
evaluation/Rewards Min           -6.55488
evaluation/Returns Mean         -29.9677
evaluation/Returns Std            8.51459
evaluation/Returns Max          -17.5309
evaluation/Returns Min          -41.8807
evaluation/Actions Mean           0.00243257
evaluation/Actions Std            0.125578
evaluation/Actions Max            0.718505
evaluation/Actions Min           -0.597583
evaluation/Num Paths             10
evaluation/Average Returns      -29.9677
time/data storing (s)             0.00122981
time/evaluation sampling (s)      0.251728
time/exploration sampling (s)     0.0676036
time/logging (s)                  0.00329546
time/saving (s)                   0.00228808
time/training (s)                 0.9637
time/epoch (s)                    1.28984
time/total (s)                    5.57768
Epoch                             3
-----------------------------  -------------
2019-04-22 20:11:04.306797 PDT | [sac-pointmass-multitask-1_2019_04_22_20_10_57_0000--s-0] Epoch 4 finished
-----------------------------  --------------
replay_buffer/size             1200
trainer/QF1 Loss                  0.352936
trainer/QF2 Loss                  0.329447
trainer/Policy Loss               8.86572
trainer/Q1 Predictions Mean     -10.3828
trainer/Q1 Predictions Std        5.61211
trainer/Q1 Predictions Max       -4.00395
trainer/Q1 Predictions Min      -25.2913
trainer/Q2 Predictions Mean     -10.4056
trainer/Q2 Predictions Std        5.61866
trainer/Q2 Predictions Max       -3.99293
trainer/Q2 Predictions Min      -25.2867
trainer/Q Targets Mean          -10.3949
trainer/Q Targets Std             5.7119
trainer/Q Targets Max            -3.81395
trainer/Q Targets Min           -23.8059
trainer/Log Pis Mean             -0.850741
trainer/Log Pis Std               1.10679
trainer/Log Pis Max               1.50538
trainer/Log Pis Min              -3.84632
trainer/Policy mu Mean            0.0754304
trainer/Policy mu Std             0.616665
trainer/Policy mu Max             1.14708
trainer/Policy mu Min            -1.1673
trainer/Policy log std Mean      -0.35741
trainer/Policy log std Std        0.0331541
trainer/Policy log std Max       -0.283278
trainer/Policy log std Min       -0.478355
trainer/Alpha                     0.794302
trainer/Alpha Loss               -0.655766
exploration/num steps total    1200
exploration/num paths total      12
exploration/path length Mean    100
exploration/path length Std       0
exploration/path length Max     100
exploration/path length Min     100
exploration/Rewards Mean         -0.901686
exploration/Rewards Std           0.495003
exploration/Rewards Max          -0.0495929
exploration/Rewards Min          -3.66195
exploration/Returns Mean        -90.1686
exploration/Returns Std           7.69964
exploration/Returns Max         -82.469
exploration/Returns Min         -97.8682
exploration/Actions Mean          0.0163329
exploration/Actions Std           0.560265
exploration/Actions Max           0.988683
exploration/Actions Min          -0.984479
exploration/Num Paths             2
exploration/Average Returns     -90.1686
evaluation/num steps total     5000
evaluation/num paths total       50
evaluation/path length Mean     100
evaluation/path length Std        0
evaluation/path length Max      100
evaluation/path length Min      100
evaluation/Rewards Mean          -0.325799
evaluation/Rewards Std            0.757628
evaluation/Rewards Max           -0.0159472
evaluation/Rewards Min           -6.51962
evaluation/Returns Mean         -32.5799
evaluation/Returns Std            6.49945
evaluation/Returns Max          -22.7405
evaluation/Returns Min          -43.6141
evaluation/Actions Mean          -0.000192215
evaluation/Actions Std            0.143462
evaluation/Actions Max            0.76772
evaluation/Actions Min           -0.793024
evaluation/Num Paths             10
evaluation/Average Returns      -32.5799
time/data storing (s)             0.0012247
time/evaluation sampling (s)      0.248502
time/exploration sampling (s)     0.066846
time/logging (s)                  0.00333157
time/saving (s)                   0.00187172
time/training (s)                 0.977247
time/epoch (s)                    1.29902
time/total (s)                    6.88047
Epoch                             4
-----------------------------  --------------
2019-04-22 20:11:05.607704 PDT | [sac-pointmass-multitask-1_2019_04_22_20_10_57_0000--s-0] Epoch 5 finished
-----------------------------  -------------
replay_buffer/size             1400
trainer/QF1 Loss                  0.928579
trainer/QF2 Loss                  0.914268
trainer/Policy Loss               8.1263
trainer/Q1 Predictions Mean      -9.83291
trainer/Q1 Predictions Std        5.97174
trainer/Q1 Predictions Max       -4.06328
trainer/Q1 Predictions Min      -27.1185
trainer/Q2 Predictions Mean      -9.84143
trainer/Q2 Predictions Std        5.97351
trainer/Q2 Predictions Max       -4.06451
trainer/Q2 Predictions Min      -26.938
trainer/Q Targets Mean           -9.88116
trainer/Q Targets Std             6.10141
trainer/Q Targets Max            -3.30972
trainer/Q Targets Min           -27.6965
trainer/Log Pis Mean             -0.541108
trainer/Log Pis Std               1.03303
trainer/Log Pis Max               1.89769
trainer/Log Pis Min              -4.27809
trainer/Policy mu Mean            0.0515841
trainer/Policy mu Std             0.705376
trainer/Policy mu Max             1.47545
trainer/Policy mu Min            -1.25914
trainer/Policy log std Mean      -0.468162
trainer/Policy log std Std        0.0615979
trainer/Policy log std Max       -0.345417
trainer/Policy log std Min       -0.578359
trainer/Alpha                     0.754567
trainer/Alpha Loss               -0.714971
exploration/num steps total    1400
exploration/num paths total      14
exploration/path length Mean    100
exploration/path length Std       0
exploration/path length Max     100
exploration/path length Min     100
exploration/Rewards Mean         -0.838698
exploration/Rewards Std           0.819715
exploration/Rewards Max          -0.0629401
exploration/Rewards Min          -5.69588
exploration/Returns Mean        -83.8698
exploration/Returns Std           1.0787
exploration/Returns Max         -82.7911
exploration/Returns Min         -84.9485
exploration/Actions Mean         -0.0030949
exploration/Actions Std           0.533804
exploration/Actions Max           0.962467
exploration/Actions Min          -0.976816
exploration/Num Paths             2
exploration/Average Returns     -83.8698
evaluation/num steps total     6000
evaluation/num paths total       60
evaluation/path length Mean     100
evaluation/path length Std        0
evaluation/path length Max      100
evaluation/path length Min      100
evaluation/Rewards Mean          -0.249536
evaluation/Rewards Std            0.656265
evaluation/Rewards Max           -0.0257614
evaluation/Rewards Min           -6.5241
evaluation/Returns Mean         -24.9536
evaluation/Returns Std            6.95016
evaluation/Returns Max          -14.3955
evaluation/Returns Min          -35.9557
evaluation/Actions Mean           0.00272078
evaluation/Actions Std            0.14254
evaluation/Actions Max            0.894111
evaluation/Actions Min           -0.883011
evaluation/Num Paths             10
evaluation/Average Returns      -24.9536
time/data storing (s)             0.00126901
time/evaluation sampling (s)      0.247171
time/exploration sampling (s)     0.0670237
time/logging (s)                  0.00337432
time/saving (s)                   0.00215272
time/training (s)                 0.975462
time/epoch (s)                    1.29645
time/total (s)                    8.18066
Epoch                             5
-----------------------------  -------------
2019-04-22 20:11:06.974777 PDT | [sac-pointmass-multitask-1_2019_04_22_20_10_57_0000--s-0] Epoch 6 finished
-----------------------------  -------------
replay_buffer/size             1600
trainer/QF1 Loss                  0.615896
trainer/QF2 Loss                  0.606931
trainer/Policy Loss               8.1926
trainer/Q1 Predictions Mean      -9.93244
trainer/Q1 Predictions Std        7.34264
trainer/Q1 Predictions Max       -4.0389
trainer/Q1 Predictions Min      -35.2248
trainer/Q2 Predictions Mean      -9.92623
trainer/Q2 Predictions Std        7.35648
trainer/Q2 Predictions Max       -4.02634
trainer/Q2 Predictions Min      -35.1276
trainer/Q Targets Mean           -9.94393
trainer/Q Targets Std             7.30258
trainer/Q Targets Max            -4.0152
trainer/Q Targets Min           -35.5823
trainer/Log Pis Mean             -0.41767
trainer/Log Pis Std               1.04928
trainer/Log Pis Max               2.07281
trainer/Log Pis Min              -3.6688
trainer/Policy mu Mean            0.0138116
trainer/Policy mu Std             0.703689
trainer/Policy mu Max             1.39096
trainer/Policy mu Min            -1.37476
trainer/Policy log std Mean      -0.555132
trainer/Policy log std Std        0.106569
trainer/Policy log std Max       -0.332458
trainer/Policy log std Min       -0.691693
trainer/Alpha                     0.717908
trainer/Alpha Loss               -0.800648
exploration/num steps total    1600
exploration/num paths total      16
exploration/path length Mean    100
exploration/path length Std       0
exploration/path length Max     100
exploration/path length Min     100
exploration/Rewards Mean         -0.68846
exploration/Rewards Std           0.620305
exploration/Rewards Max          -0.041631
exploration/Rewards Min          -4.40466
exploration/Returns Mean        -68.846
exploration/Returns Std           5.08477
exploration/Returns Max         -63.7613
exploration/Returns Min         -73.9308
exploration/Actions Mean          0.0301436
exploration/Actions Std           0.497581
exploration/Actions Max           0.977267
exploration/Actions Min          -0.952039
exploration/Num Paths             2
exploration/Average Returns     -68.846
evaluation/num steps total     7000
evaluation/num paths total       70
evaluation/path length Mean     100
evaluation/path length Std        0
evaluation/path length Max      100
evaluation/path length Min      100
evaluation/Rewards Mean          -0.250547
evaluation/Rewards Std            0.582794
evaluation/Rewards Max           -0.0830989
evaluation/Rewards Min           -5.84953
evaluation/Returns Mean         -25.0547
evaluation/Returns Std            6.27151
evaluation/Returns Max          -16.7911
evaluation/Returns Min          -33.9786
evaluation/Actions Mean          -0.00702404
evaluation/Actions Std            0.143135
evaluation/Actions Max            0.862326
evaluation/Actions Min           -0.878599
evaluation/Num Paths             10
evaluation/Average Returns      -25.0547
time/data storing (s)             0.00119784
time/evaluation sampling (s)      0.252945
time/exploration sampling (s)     0.067087
time/logging (s)                  0.00368045
time/saving (s)                   0.00261486
time/training (s)                 1.03495
time/epoch (s)                    1.36248
time/total (s)                    9.54726
Epoch                             6
-----------------------------  -------------
2019-04-22 20:11:08.392136 PDT | [sac-pointmass-multitask-1_2019_04_22_20_10_57_0000--s-0] Epoch 7 finished
-----------------------------  -------------
replay_buffer/size             1800
trainer/QF1 Loss                  0.742127
trainer/QF2 Loss                  0.790874
trainer/Policy Loss              11.057
trainer/Q1 Predictions Mean     -13.4849
trainer/Q1 Predictions Std       10.0361
trainer/Q1 Predictions Max       -4.28709
trainer/Q1 Predictions Min      -37.812
trainer/Q2 Predictions Mean     -13.4315
trainer/Q2 Predictions Std        9.98429
trainer/Q2 Predictions Max       -4.31833
trainer/Q2 Predictions Min      -37.4501
trainer/Q Targets Mean          -13.5111
trainer/Q Targets Std            10.0885
trainer/Q Targets Max            -4.19653
trainer/Q Targets Min           -36.8544
trainer/Log Pis Mean             -0.239695
trainer/Log Pis Std               1.42438
trainer/Log Pis Max               3.06853
trainer/Log Pis Min              -4.02013
trainer/Policy mu Mean           -0.110137
trainer/Policy mu Std             0.806952
trainer/Policy mu Max             1.54083
trainer/Policy mu Min            -1.43066
trainer/Policy log std Mean      -0.55496
trainer/Policy log std Std        0.124281
trainer/Policy log std Max       -0.325531
trainer/Policy log std Min       -0.714069
trainer/Alpha                     0.683279
trainer/Alpha Loss               -0.852446
exploration/num steps total    1800
exploration/num paths total      18
exploration/path length Mean    100
exploration/path length Std       0
exploration/path length Max     100
exploration/path length Min     100
exploration/Rewards Mean         -0.693287
exploration/Rewards Std           0.763331
exploration/Rewards Max          -0.0245222
exploration/Rewards Min          -5.4248
exploration/Returns Mean        -69.3287
exploration/Returns Std           1.25937
exploration/Returns Max         -68.0693
exploration/Returns Min         -70.588
exploration/Actions Mean         -0.00429921
exploration/Actions Std           0.500747
exploration/Actions Max           0.969992
exploration/Actions Min          -0.938423
exploration/Num Paths             2
exploration/Average Returns     -69.3287
evaluation/num steps total     8000
evaluation/num paths total       80
evaluation/path length Mean     100
evaluation/path length Std        0
evaluation/path length Max      100
evaluation/path length Min      100
evaluation/Rewards Mean          -0.208213
evaluation/Rewards Std            0.555252
evaluation/Rewards Max           -0.0877065
evaluation/Rewards Min           -6.71195
evaluation/Returns Mean         -20.8213
evaluation/Returns Std            7.80348
evaluation/Returns Max          -12.9875
evaluation/Returns Min          -34.9493
evaluation/Actions Mean           0.00915564
evaluation/Actions Std            0.13901
evaluation/Actions Max            0.901987
evaluation/Actions Min           -0.890162
evaluation/Num Paths             10
evaluation/Average Returns      -20.8213
time/data storing (s)             0.00124665
time/evaluation sampling (s)      0.268515
time/exploration sampling (s)     0.0741118
time/logging (s)                  0.00368238
time/saving (s)                   0.0026812
time/training (s)                 1.06207
time/epoch (s)                    1.41231
time/total (s)                   10.9638
Epoch                             7
-----------------------------  -------------
2019-04-22 20:11:09.705183 PDT | [sac-pointmass-multitask-1_2019_04_22_20_10_57_0000--s-0] Epoch 8 finished
-----------------------------  -------------
replay_buffer/size             2000
trainer/QF1 Loss                  2.00596
trainer/QF2 Loss                  1.95835
trainer/Policy Loss               9.87172
trainer/Q1 Predictions Mean     -11.7299
trainer/Q1 Predictions Std        7.88582
trainer/Q1 Predictions Max       -4.80229
trainer/Q1 Predictions Min      -32.8139
trainer/Q2 Predictions Mean     -11.7531
trainer/Q2 Predictions Std        7.89776
trainer/Q2 Predictions Max       -4.89891
trainer/Q2 Predictions Min      -33.0934
trainer/Q Targets Mean          -11.6161
trainer/Q Targets Std             7.88826
trainer/Q Targets Max            -3.30972
trainer/Q Targets Min           -34.9676
trainer/Log Pis Mean             -0.195495
trainer/Log Pis Std               1.34392
trainer/Log Pis Max               3.3775
trainer/Log Pis Min              -4.97066
trainer/Policy mu Mean            0.0305922
trainer/Policy mu Std             0.800872
trainer/Policy mu Max             1.52508
trainer/Policy mu Min            -1.60251
trainer/Policy log std Mean      -0.553192
trainer/Policy log std Std        0.104401
trainer/Policy log std Max       -0.322268
trainer/Policy log std Min       -0.666285
trainer/Alpha                     0.649429
trainer/Alpha Loss               -0.947146
exploration/num steps total    2000
exploration/num paths total      20
exploration/path length Mean    100
exploration/path length Std       0
exploration/path length Max     100
exploration/path length Min     100
exploration/Rewards Mean         -0.621596
exploration/Rewards Std           0.371562
exploration/Rewards Max          -0.0335717
exploration/Rewards Min          -2.89639
exploration/Returns Mean        -62.1596
exploration/Returns Std           0.931434
exploration/Returns Max         -61.2281
exploration/Returns Min         -63.091
exploration/Actions Mean          0.00626351
exploration/Actions Std           0.488575
exploration/Actions Max           0.954141
exploration/Actions Min          -0.970637
exploration/Num Paths             2
exploration/Average Returns     -62.1596
evaluation/num steps total     9000
evaluation/num paths total       90
evaluation/path length Mean     100
evaluation/path length Std        0
evaluation/path length Max      100
evaluation/path length Min      100
evaluation/Rewards Mean          -0.199204
evaluation/Rewards Std            0.436582
evaluation/Rewards Max           -0.0342511
evaluation/Rewards Min           -5.58765
evaluation/Returns Mean         -19.9204
evaluation/Returns Std            5.11588
evaluation/Returns Max          -13.51
evaluation/Returns Min          -29.5953
evaluation/Actions Mean          -0.00439001
evaluation/Actions Std            0.134647
evaluation/Actions Max            0.888775
evaluation/Actions Min           -0.877781
evaluation/Num Paths             10
evaluation/Average Returns      -19.9204
time/data storing (s)             0.00118891
time/evaluation sampling (s)      0.268067
time/exploration sampling (s)     0.0659511
time/logging (s)                  0.00333698
time/saving (s)                   0.00235237
time/training (s)                 0.966451
time/epoch (s)                    1.30735
time/total (s)                   12.2757
Epoch                             8
-----------------------------  -------------
2019-04-22 20:11:11.017497 PDT | [sac-pointmass-multitask-1_2019_04_22_20_10_57_0000--s-0] Epoch 9 finished
-----------------------------  --------------
replay_buffer/size              2200
trainer/QF1 Loss                   0.92197
trainer/QF2 Loss                   0.94267
trainer/Policy Loss                8.61796
trainer/Q1 Predictions Mean      -10.0339
trainer/Q1 Predictions Std         7.41791
trainer/Q1 Predictions Max        -5.04186
trainer/Q1 Predictions Min       -37.8856
trainer/Q2 Predictions Mean      -10.0178
trainer/Q2 Predictions Std         7.40768
trainer/Q2 Predictions Max        -5.02392
trainer/Q2 Predictions Min       -37.607
trainer/Q Targets Mean           -10.1363
trainer/Q Targets Std              7.65999
trainer/Q Targets Max             -1.47083
trainer/Q Targets Min            -39.933
trainer/Log Pis Mean              -0.347341
trainer/Log Pis Std                1.12584
trainer/Log Pis Max                2.72233
trainer/Log Pis Min               -3.94635
trainer/Policy mu Mean             0.125118
trainer/Policy mu Std              0.748483
trainer/Policy mu Max              1.69541
trainer/Policy mu Min             -1.53813
trainer/Policy log std Mean       -0.602908
trainer/Policy log std Std         0.0834821
trainer/Policy log std Max        -0.397927
trainer/Policy log std Min        -0.687561
trainer/Alpha                      0.616392
trainer/Alpha Loss                -1.13521
exploration/num steps total     2200
exploration/num paths total       22
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.693113
exploration/Rewards Std            0.696619
exploration/Rewards Max           -0.0319459
exploration/Rewards Min           -5.52304
exploration/Returns Mean         -69.3113
exploration/Returns Std            2.8499
exploration/Returns Max          -66.4614
exploration/Returns Min          -72.1612
exploration/Actions Mean          -0.0288881
exploration/Actions Std            0.504971
exploration/Actions Max            0.925537
exploration/Actions Min           -0.979517
exploration/Num Paths              2
exploration/Average Returns      -69.3113
evaluation/num steps total     10000
evaluation/num paths total       100
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.169565
evaluation/Rewards Std             0.473209
evaluation/Rewards Max            -0.0376144
evaluation/Rewards Min            -5.66431
evaluation/Returns Mean          -16.9565
evaluation/Returns Std             4.22932
evaluation/Returns Max           -12.4599
evaluation/Returns Min           -27.0472
evaluation/Actions Mean            0.00839885
evaluation/Actions Std             0.143024
evaluation/Actions Max             0.918401
evaluation/Actions Min            -0.925919
evaluation/Num Paths              10
evaluation/Average Returns       -16.9565
time/data storing (s)              0.00119023
time/evaluation sampling (s)       0.256115
time/exploration sampling (s)      0.0676098
time/logging (s)                   0.00290087
time/saving (s)                    0.00230928
time/training (s)                  0.976855
time/epoch (s)                     1.30698
time/total (s)                    13.5867
Epoch                              9
-----------------------------  --------------
2019-04-22 20:11:12.334531 PDT | [sac-pointmass-multitask-1_2019_04_22_20_10_57_0000--s-0] Epoch 10 finished
-----------------------------  --------------
replay_buffer/size              2400
trainer/QF1 Loss                   0.750548
trainer/QF2 Loss                   0.739031
trainer/Policy Loss                7.88527
trainer/Q1 Predictions Mean       -9.33139
trainer/Q1 Predictions Std         6.43371
trainer/Q1 Predictions Max        -5.45449
trainer/Q1 Predictions Min       -42.4137
trainer/Q2 Predictions Mean       -9.39094
trainer/Q2 Predictions Std         6.4441
trainer/Q2 Predictions Max        -5.554
trainer/Q2 Predictions Min       -42.282
trainer/Q Targets Mean            -9.49648
trainer/Q Targets Std              6.59849
trainer/Q Targets Max             -5.29533
trainer/Q Targets Min            -42.9129
trainer/Log Pis Mean              -0.384556
trainer/Log Pis Std                1.15135
trainer/Log Pis Max                3.00225
trainer/Log Pis Min               -3.17482
trainer/Policy mu Mean             0.0483022
trainer/Policy mu Std              0.706442
trainer/Policy mu Max              1.64051
trainer/Policy mu Min             -1.48774
trainer/Policy log std Mean       -0.603147
trainer/Policy log std Std         0.0681478
trainer/Policy log std Max        -0.406268
trainer/Policy log std Min        -0.675227
trainer/Alpha                      0.584102
trainer/Alpha Loss                -1.28148
exploration/num steps total     2400
exploration/num paths total       24
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.69702
exploration/Rewards Std            0.60878
exploration/Rewards Max           -0.0319998
exploration/Rewards Min           -4.53381
exploration/Returns Mean         -69.702
exploration/Returns Std            2.96691
exploration/Returns Max          -66.7351
exploration/Returns Min          -72.6689
exploration/Actions Mean           0.00302607
exploration/Actions Std            0.518716
exploration/Actions Max            0.955324
exploration/Actions Min           -0.945511
exploration/Num Paths              2
exploration/Average Returns      -69.702
evaluation/num steps total     11000
evaluation/num paths total       110
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.1771
evaluation/Rewards Std             0.451142
evaluation/Rewards Max            -0.0550669
evaluation/Rewards Min            -5.94798
evaluation/Returns Mean          -17.71
evaluation/Returns Std             5.38701
evaluation/Returns Max           -12.3001
evaluation/Returns Min           -28.8282
evaluation/Actions Mean           -0.004683
evaluation/Actions Std             0.136178
evaluation/Actions Max             0.921135
evaluation/Actions Min            -0.885038
evaluation/Num Paths              10
evaluation/Average Returns       -17.71
time/data storing (s)              0.00121188
time/evaluation sampling (s)       0.251206
time/exploration sampling (s)      0.0673428
time/logging (s)                   0.00338805
time/saving (s)                    0.00236501
time/training (s)                  0.987209
time/epoch (s)                     1.31272
time/total (s)                    14.9035
Epoch                             10
-----------------------------  --------------
2019-04-22 20:11:13.631690 PDT | [sac-pointmass-multitask-1_2019_04_22_20_10_57_0000--s-0] Epoch 11 finished
-----------------------------  --------------
replay_buffer/size              2600
trainer/QF1 Loss                   1.20566
trainer/QF2 Loss                   1.17352
trainer/Policy Loss               10.8717
trainer/Q1 Predictions Mean      -12.8221
trainer/Q1 Predictions Std         9.6577
trainer/Q1 Predictions Max        -5.87815
trainer/Q1 Predictions Min       -41.3638
trainer/Q2 Predictions Mean      -12.7922
trainer/Q2 Predictions Std         9.67376
trainer/Q2 Predictions Max        -5.81087
trainer/Q2 Predictions Min       -41.0333
trainer/Q Targets Mean           -12.9013
trainer/Q Targets Std              9.86054
trainer/Q Targets Max             -0.34556
trainer/Q Targets Min            -41.5247
trainer/Log Pis Mean               0.00920407
trainer/Log Pis Std                1.28778
trainer/Log Pis Max                3.39184
trainer/Log Pis Min               -3.54795
trainer/Policy mu Mean             0.0974384
trainer/Policy mu Std              0.835286
trainer/Policy mu Max              1.7391
trainer/Policy mu Min             -1.63132
trainer/Policy log std Mean       -0.567014
trainer/Policy log std Std         0.0723811
trainer/Policy log std Max        -0.422088
trainer/Policy log std Min        -0.670482
trainer/Alpha                      0.552572
trainer/Alpha Loss                -1.18033
exploration/num steps total     2600
exploration/num paths total       26
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.680794
exploration/Rewards Std            0.621372
exploration/Rewards Max           -0.112632
exploration/Rewards Min           -5.4981
exploration/Returns Mean         -68.0794
exploration/Returns Std           11.6527
exploration/Returns Max          -56.4267
exploration/Returns Min          -79.7321
exploration/Actions Mean          -0.0258245
exploration/Actions Std            0.493152
exploration/Actions Max            0.951377
exploration/Actions Min           -0.987844
exploration/Num Paths              2
exploration/Average Returns      -68.0794
evaluation/num steps total     12000
evaluation/num paths total       120
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.122529
evaluation/Rewards Std             0.523078
evaluation/Rewards Max            -0.0123516
evaluation/Rewards Min            -5.71301
evaluation/Returns Mean          -12.2529
evaluation/Returns Std             5.35525
evaluation/Returns Max            -4.63873
evaluation/Returns Min           -20.3749
evaluation/Actions Mean           -0.0158941
evaluation/Actions Std             0.144156
evaluation/Actions Max             0.926023
evaluation/Actions Min            -0.920712
evaluation/Num Paths              10
evaluation/Average Returns       -12.2529
time/data storing (s)              0.00126707
time/evaluation sampling (s)       0.243149
time/exploration sampling (s)      0.0675903
time/logging (s)                   0.00351506
time/saving (s)                    0.00229738
time/training (s)                  0.974352
time/epoch (s)                     1.29217
time/total (s)                    16.2
Epoch                             11
-----------------------------  --------------
2019-04-22 20:11:14.932452 PDT | [sac-pointmass-multitask-1_2019_04_22_20_10_57_0000--s-0] Epoch 12 finished
-----------------------------  --------------
replay_buffer/size              2800
trainer/QF1 Loss                   0.79232
trainer/QF2 Loss                   0.794485
trainer/Policy Loss                8.4469
trainer/Q1 Predictions Mean       -9.87363
trainer/Q1 Predictions Std         6.31467
trainer/Q1 Predictions Max        -6.39822
trainer/Q1 Predictions Min       -39.6618
trainer/Q2 Predictions Mean       -9.81588
trainer/Q2 Predictions Std         6.31475
trainer/Q2 Predictions Max        -6.3574
trainer/Q2 Predictions Min       -39.4802
trainer/Q Targets Mean            -9.8005
trainer/Q Targets Std              6.42489
trainer/Q Targets Max             -0.295684
trainer/Q Targets Min            -40.5514
trainer/Log Pis Mean              -0.460154
trainer/Log Pis Std                1.26791
trainer/Log Pis Max                3.82787
trainer/Log Pis Min               -3.37445
trainer/Policy mu Mean             0.0829721
trainer/Policy mu Std              0.692614
trainer/Policy mu Max              1.58697
trainer/Policy mu Min             -1.61962
trainer/Policy log std Mean       -0.588079
trainer/Policy log std Std         0.0510473
trainer/Policy log std Max        -0.454654
trainer/Policy log std Min        -0.634735
trainer/Alpha                      0.522225
trainer/Alpha Loss                -1.59755
exploration/num steps total     2800
exploration/num paths total       28
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.675387
exploration/Rewards Std            0.573566
exploration/Rewards Max           -0.0370478
exploration/Rewards Min           -5.32485
exploration/Returns Mean         -67.5387
exploration/Returns Std            6.91926
exploration/Returns Max          -60.6194
exploration/Returns Min          -74.4579
exploration/Actions Mean           0.00749758
exploration/Actions Std            0.484532
exploration/Actions Max            0.982042
exploration/Actions Min           -0.95056
exploration/Num Paths              2
exploration/Average Returns      -67.5387
evaluation/num steps total     13000
evaluation/num paths total       130
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.161574
evaluation/Rewards Std             0.546538
evaluation/Rewards Max            -0.0251474
evaluation/Rewards Min            -6.58927
evaluation/Returns Mean          -16.1574
evaluation/Returns Std             6.20946
evaluation/Returns Max            -6.80109
evaluation/Returns Min           -28.3103
evaluation/Actions Mean           -0.003165
evaluation/Actions Std             0.144744
evaluation/Actions Max             0.936125
evaluation/Actions Min            -0.921727
evaluation/Num Paths              10
evaluation/Average Returns       -16.1574
time/data storing (s)              0.00117198
time/evaluation sampling (s)       0.24943
time/exploration sampling (s)      0.0665804
time/logging (s)                   0.00344815
time/saving (s)                    0.00241778
time/training (s)                  0.972607
time/epoch (s)                     1.29565
time/total (s)                    17.4998
Epoch                             12
-----------------------------  --------------
2019-04-22 20:11:16.238732 PDT | [sac-pointmass-multitask-1_2019_04_22_20_10_57_0000--s-0] Epoch 13 finished
-----------------------------  ---------------
replay_buffer/size              3000
trainer/QF1 Loss                   1.0953
trainer/QF2 Loss                   1.10502
trainer/Policy Loss               10.6191
trainer/Q1 Predictions Mean      -11.9521
trainer/Q1 Predictions Std         9.01684
trainer/Q1 Predictions Max        -6.88641
trainer/Q1 Predictions Min       -45.8886
trainer/Q2 Predictions Mean      -11.9602
trainer/Q2 Predictions Std         8.98925
trainer/Q2 Predictions Max        -6.91765
trainer/Q2 Predictions Min       -45.2973
trainer/Q Targets Mean           -11.9705
trainer/Q Targets Std              9.22682
trainer/Q Targets Max             -0.664499
trainer/Q Targets Min            -45.4098
trainer/Log Pis Mean              -0.00216798
trainer/Log Pis Std                1.48939
trainer/Log Pis Max                4.14625
trainer/Log Pis Min               -2.36874
trainer/Policy mu Mean             0.147223
trainer/Policy mu Std              0.790995
trainer/Policy mu Max              1.82636
trainer/Policy mu Min             -1.63269
trainer/Policy log std Mean       -0.598717
trainer/Policy log std Std         0.0517148
trainer/Policy log std Max        -0.456709
trainer/Policy log std Min        -0.672035
trainer/Alpha                      0.49279
trainer/Alpha Loss                -1.4163
exploration/num steps total     3000
exploration/num paths total       30
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.701602
exploration/Rewards Std            0.495367
exploration/Rewards Max           -0.0448821
exploration/Rewards Min           -4.50612
exploration/Returns Mean         -70.1602
exploration/Returns Std            1.24198
exploration/Returns Max          -68.9182
exploration/Returns Min          -71.4022
exploration/Actions Mean           0.00396132
exploration/Actions Std            0.519474
exploration/Actions Max            0.978791
exploration/Actions Min           -0.964633
exploration/Num Paths              2
exploration/Average Returns      -70.1602
evaluation/num steps total     14000
evaluation/num paths total       140
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.161043
evaluation/Rewards Std             0.643221
evaluation/Rewards Max            -0.00887109
evaluation/Rewards Min            -5.37967
evaluation/Returns Mean          -16.1043
evaluation/Returns Std             4.87266
evaluation/Returns Max            -4.63143
evaluation/Returns Min           -21.5233
evaluation/Actions Mean            0.000558875
evaluation/Actions Std             0.153622
evaluation/Actions Max             0.950252
evaluation/Actions Min            -0.942719
evaluation/Num Paths              10
evaluation/Average Returns       -16.1043
time/data storing (s)              0.00121541
time/evaluation sampling (s)       0.253404
time/exploration sampling (s)      0.0671432
time/logging (s)                   0.00336509
time/saving (s)                    0.00230297
time/training (s)                  0.974438
time/epoch (s)                     1.30187
time/total (s)                    18.8051
Epoch                             13
-----------------------------  ---------------
2019-04-22 20:11:17.539183 PDT | [sac-pointmass-multitask-1_2019_04_22_20_10_57_0000--s-0] Epoch 14 finished
-----------------------------  --------------
replay_buffer/size              3200
trainer/QF1 Loss                   0.918643
trainer/QF2 Loss                   0.926333
trainer/Policy Loss               10.7418
trainer/Q1 Predictions Mean      -12.3704
trainer/Q1 Predictions Std         9.04077
trainer/Q1 Predictions Max        -7.36783
trainer/Q1 Predictions Min       -48.2205
trainer/Q2 Predictions Mean      -12.3669
trainer/Q2 Predictions Std         8.9943
trainer/Q2 Predictions Max        -7.3642
trainer/Q2 Predictions Min       -47.7413
trainer/Q Targets Mean           -12.2468
trainer/Q Targets Std              9.07664
trainer/Q Targets Max             -0.462711
trainer/Q Targets Min            -44.3612
trainer/Log Pis Mean              -0.364471
trainer/Log Pis Std                1.43445
trainer/Log Pis Max                3.99976
trainer/Log Pis Min               -4.43599
trainer/Policy mu Mean             0.0892686
trainer/Policy mu Std              0.772737
trainer/Policy mu Max              1.87956
trainer/Policy mu Min             -1.78303
trainer/Policy log std Mean       -0.611762
trainer/Policy log std Std         0.0463824
trainer/Policy log std Max        -0.491678
trainer/Policy log std Min        -0.675009
trainer/Alpha                      0.464632
trainer/Alpha Loss                -1.81169
exploration/num steps total     3200
exploration/num paths total       32
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.665965
exploration/Rewards Std            0.672235
exploration/Rewards Max           -0.0196961
exploration/Rewards Min           -5.75981
exploration/Returns Mean         -66.5965
exploration/Returns Std            1.44407
exploration/Returns Max          -65.1524
exploration/Returns Min          -68.0405
exploration/Actions Mean           0.0450325
exploration/Actions Std            0.497944
exploration/Actions Max            0.98831
exploration/Actions Min           -0.925801
exploration/Num Paths              2
exploration/Average Returns      -66.5965
evaluation/num steps total     15000
evaluation/num paths total       150
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.1424
evaluation/Rewards Std             0.627479
evaluation/Rewards Max            -0.0101144
evaluation/Rewards Min            -6.87229
evaluation/Returns Mean          -14.24
evaluation/Returns Std             6.03802
evaluation/Returns Max            -5.03984
evaluation/Returns Min           -25.4505
evaluation/Actions Mean            0.00415024
evaluation/Actions Std             0.165525
evaluation/Actions Max             0.943228
evaluation/Actions Min            -0.942207
evaluation/Num Paths              10
evaluation/Average Returns       -14.24
time/data storing (s)              0.00120483
time/evaluation sampling (s)       0.244245
time/exploration sampling (s)      0.0662001
time/logging (s)                   0.00334762
time/saving (s)                    0.00234492
time/training (s)                  0.978191
time/epoch (s)                     1.29553
time/total (s)                    20.1047
Epoch                             14
-----------------------------  --------------
2019-04-22 20:11:18.851958 PDT | [sac-pointmass-multitask-1_2019_04_22_20_10_57_0000--s-0] Epoch 15 finished
-----------------------------  --------------
replay_buffer/size              3400
trainer/QF1 Loss                   0.860737
trainer/QF2 Loss                   0.910914
trainer/Policy Loss                9.32148
trainer/Q1 Predictions Mean      -10.6892
trainer/Q1 Predictions Std         4.97495
trainer/Q1 Predictions Max        -7.82275
trainer/Q1 Predictions Min       -35.7679
trainer/Q2 Predictions Mean      -10.6589
trainer/Q2 Predictions Std         4.95188
trainer/Q2 Predictions Max        -7.82034
trainer/Q2 Predictions Min       -35.4436
trainer/Q Targets Mean           -10.5494
trainer/Q Targets Std              5.02026
trainer/Q Targets Max             -1.18473
trainer/Q Targets Min            -35.7914
trainer/Log Pis Mean              -0.311963
trainer/Log Pis Std                1.16392
trainer/Log Pis Max                4.173
trainer/Log Pis Min               -2.43381
trainer/Policy mu Mean             0.0346974
trainer/Policy mu Std              0.696528
trainer/Policy mu Max              1.71129
trainer/Policy mu Min             -1.64771
trainer/Policy log std Mean       -0.59452
trainer/Policy log std Std         0.0371662
trainer/Policy log std Max        -0.492704
trainer/Policy log std Min        -0.636391
trainer/Alpha                      0.438007
trainer/Alpha Loss                -1.90789
exploration/num steps total     3400
exploration/num paths total       34
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.74149
exploration/Rewards Std            0.691509
exploration/Rewards Max           -0.0485734
exploration/Rewards Min           -6.43683
exploration/Returns Mean         -74.149
exploration/Returns Std            7.20923
exploration/Returns Max          -66.9398
exploration/Returns Min          -81.3583
exploration/Actions Mean           0.0090395
exploration/Actions Std            0.500525
exploration/Actions Max            0.989434
exploration/Actions Min           -0.957218
exploration/Num Paths              2
exploration/Average Returns      -74.149
evaluation/num steps total     16000
evaluation/num paths total       160
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.137003
evaluation/Rewards Std             0.538056
evaluation/Rewards Max            -0.0307435
evaluation/Rewards Min            -6.09227
evaluation/Returns Mean          -13.7003
evaluation/Returns Std             6.02888
evaluation/Returns Max            -5.15849
evaluation/Returns Min           -23.1516
evaluation/Actions Mean            0.00137307
evaluation/Actions Std             0.140111
evaluation/Actions Max             0.957977
evaluation/Actions Min            -0.942106
evaluation/Num Paths              10
evaluation/Average Returns       -13.7003
time/data storing (s)              0.00123555
time/evaluation sampling (s)       0.250147
time/exploration sampling (s)      0.067272
time/logging (s)                   0.00334709
time/saving (s)                    0.00239255
time/training (s)                  0.983971
time/epoch (s)                     1.30837
time/total (s)                    21.4166
Epoch                             15
-----------------------------  --------------
2019-04-22 20:11:20.156959 PDT | [sac-pointmass-multitask-1_2019_04_22_20_10_57_0000--s-0] Epoch 16 finished
-----------------------------  --------------
replay_buffer/size              3600
trainer/QF1 Loss                   1.56495
trainer/QF2 Loss                   1.59735
trainer/Policy Loss                9.6324
trainer/Q1 Predictions Mean      -10.71
trainer/Q1 Predictions Std         6.38854
trainer/Q1 Predictions Max        -7.94128
trainer/Q1 Predictions Min       -41.5248
trainer/Q2 Predictions Mean      -10.7323
trainer/Q2 Predictions Std         6.41429
trainer/Q2 Predictions Max        -7.97547
trainer/Q2 Predictions Min       -41.5725
trainer/Q Targets Mean           -10.8341
trainer/Q Targets Std              6.69596
trainer/Q Targets Max             -0.34556
trainer/Q Targets Min            -41.0318
trainer/Log Pis Mean              -0.493002
trainer/Log Pis Std                0.992729
trainer/Log Pis Max                3.05333
trainer/Log Pis Min               -3.23802
trainer/Policy mu Mean             0.0129068
trainer/Policy mu Std              0.649233
trainer/Policy mu Max              1.88038
trainer/Policy mu Min             -1.77719
trainer/Policy log std Mean       -0.628998
trainer/Policy log std Std         0.0534653
trainer/Policy log std Max        -0.475613
trainer/Policy log std Min        -0.70109
trainer/Alpha                      0.412768
trainer/Alpha Loss                -2.20523
exploration/num steps total     3600
exploration/num paths total       36
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.690289
exploration/Rewards Std            0.606889
exploration/Rewards Max           -0.0663539
exploration/Rewards Min           -5.2384
exploration/Returns Mean         -69.0289
exploration/Returns Std            3.6181
exploration/Returns Max          -65.4108
exploration/Returns Min          -72.647
exploration/Actions Mean          -0.00963488
exploration/Actions Std            0.499072
exploration/Actions Max            0.95583
exploration/Actions Min           -0.974729
exploration/Num Paths              2
exploration/Average Returns      -69.0289
evaluation/num steps total     17000
evaluation/num paths total       170
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.147917
evaluation/Rewards Std             0.578661
evaluation/Rewards Max            -0.0151984
evaluation/Rewards Min            -6.57618
evaluation/Returns Mean          -14.7917
evaluation/Returns Std             5.63875
evaluation/Returns Max            -4.9979
evaluation/Returns Min           -25.3347
evaluation/Actions Mean            0.00144878
evaluation/Actions Std             0.156481
evaluation/Actions Max             0.951792
evaluation/Actions Min            -0.943033
evaluation/Num Paths              10
evaluation/Average Returns       -14.7917
time/data storing (s)              0.00126943
time/evaluation sampling (s)       0.250193
time/exploration sampling (s)      0.0679373
time/logging (s)                   0.00336505
time/saving (s)                    0.00229929
time/training (s)                  0.974918
time/epoch (s)                     1.29998
time/total (s)                    22.7207
Epoch                             16
-----------------------------  --------------
2019-04-22 20:11:21.482112 PDT | [sac-pointmass-multitask-1_2019_04_22_20_10_57_0000--s-0] Epoch 17 finished
-----------------------------  --------------
replay_buffer/size              3800
trainer/QF1 Loss                   4.31251
trainer/QF2 Loss                   4.29681
trainer/Policy Loss               11.0302
trainer/Q1 Predictions Mean      -12.5288
trainer/Q1 Predictions Std         7.32534
trainer/Q1 Predictions Max        -8.64273
trainer/Q1 Predictions Min       -44.6665
trainer/Q2 Predictions Mean      -12.4959
trainer/Q2 Predictions Std         7.32613
trainer/Q2 Predictions Max        -8.57279
trainer/Q2 Predictions Min       -44.4065
trainer/Q Targets Mean           -12.3782
trainer/Q Targets Std              7.64023
trainer/Q Targets Max             -0.469924
trainer/Q Targets Min            -46.768
trainer/Log Pis Mean              -0.377795
trainer/Log Pis Std                1.30124
trainer/Log Pis Max                3.06098
trainer/Log Pis Min               -3.92647
trainer/Policy mu Mean             0.0514305
trainer/Policy mu Std              0.76032
trainer/Policy mu Max              1.77698
trainer/Policy mu Min             -1.89123
trainer/Policy log std Mean       -0.631659
trainer/Policy log std Std         0.0571962
trainer/Policy log std Max        -0.448137
trainer/Policy log std Min        -0.718137
trainer/Alpha                      0.388922
trainer/Alpha Loss                -2.24482
exploration/num steps total     3800
exploration/num paths total       38
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.666696
exploration/Rewards Std            0.650371
exploration/Rewards Max           -0.0815612
exploration/Rewards Min           -5.06055
exploration/Returns Mean         -66.6696
exploration/Returns Std            0.125494
exploration/Returns Max          -66.5441
exploration/Returns Min          -66.7951
exploration/Actions Mean          -0.00248345
exploration/Actions Std            0.485381
exploration/Actions Max            0.98503
exploration/Actions Min           -0.994294
exploration/Num Paths              2
exploration/Average Returns      -66.6696
evaluation/num steps total     18000
evaluation/num paths total       180
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.196995
evaluation/Rewards Std             0.522367
evaluation/Rewards Max            -0.0702485
evaluation/Rewards Min            -5.78718
evaluation/Returns Mean          -19.6995
evaluation/Returns Std             5.07741
evaluation/Returns Max           -13.4086
evaluation/Returns Min           -27.9946
evaluation/Actions Mean            0.0109999
evaluation/Actions Std             0.151016
evaluation/Actions Max             0.954287
evaluation/Actions Min            -0.932304
evaluation/Num Paths              10
evaluation/Average Returns       -19.6995
time/data storing (s)              0.00116453
time/evaluation sampling (s)       0.253718
time/exploration sampling (s)      0.0687216
time/logging (s)                   0.00343159
time/saving (s)                    0.00233563
time/training (s)                  0.990775
time/epoch (s)                     1.32015
time/total (s)                    24.045
Epoch                             17
-----------------------------  --------------
2019-04-22 20:11:22.803972 PDT | [sac-pointmass-multitask-1_2019_04_22_20_10_57_0000--s-0] Epoch 18 finished
-----------------------------  --------------
replay_buffer/size              4000
trainer/QF1 Loss                   0.945018
trainer/QF2 Loss                   0.994426
trainer/Policy Loss               10.5826
trainer/Q1 Predictions Mean      -11.6177
trainer/Q1 Predictions Std         6.39134
trainer/Q1 Predictions Max        -8.93473
trainer/Q1 Predictions Min       -44.6766
trainer/Q2 Predictions Mean      -11.5543
trainer/Q2 Predictions Std         6.37049
trainer/Q2 Predictions Max        -8.88058
trainer/Q2 Predictions Min       -44.5816
trainer/Q Targets Mean           -11.622
trainer/Q Targets Std              6.58254
trainer/Q Targets Max             -0.462711
trainer/Q Targets Min            -46.1272
trainer/Log Pis Mean              -0.41519
trainer/Log Pis Std                1.42988
trainer/Log Pis Max                4.83458
trainer/Log Pis Min               -5.7384
trainer/Policy mu Mean             0.0809786
trainer/Policy mu Std              0.670972
trainer/Policy mu Max              1.8292
trainer/Policy mu Min             -1.83477
trainer/Policy log std Mean       -0.64649
trainer/Policy log std Std         0.0529229
trainer/Policy log std Max        -0.508747
trainer/Policy log std Min        -0.721272
trainer/Alpha                      0.366464
trainer/Alpha Loss                -2.42379
exploration/num steps total     4000
exploration/num paths total       40
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.655247
exploration/Rewards Std            0.437783
exploration/Rewards Max           -0.0291383
exploration/Rewards Min           -3.89689
exploration/Returns Mean         -65.5247
exploration/Returns Std            0.0405583
exploration/Returns Max          -65.4842
exploration/Returns Min          -65.5653
exploration/Actions Mean          -0.0153308
exploration/Actions Std            0.513412
exploration/Actions Max            0.928655
exploration/Actions Min           -0.992848
exploration/Num Paths              2
exploration/Average Returns      -65.5247
evaluation/num steps total     19000
evaluation/num paths total       190
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.1348
evaluation/Rewards Std             0.481942
evaluation/Rewards Max            -0.00176966
evaluation/Rewards Min            -5.74419
evaluation/Returns Mean          -13.48
evaluation/Returns Std             5.23884
evaluation/Returns Max            -6.21776
evaluation/Returns Min           -21.6538
evaluation/Actions Mean            0.00450257
evaluation/Actions Std             0.148128
evaluation/Actions Max             0.943532
evaluation/Actions Min            -0.934404
evaluation/Num Paths              10
evaluation/Average Returns       -13.48
time/data storing (s)              0.00123334
time/evaluation sampling (s)       0.254351
time/exploration sampling (s)      0.0673634
time/logging (s)                   0.00337221
time/saving (s)                    0.00232364
time/training (s)                  0.988057
time/epoch (s)                     1.3167
time/total (s)                    25.3659
Epoch                             18
-----------------------------  --------------
2019-04-22 20:11:24.119238 PDT | [sac-pointmass-multitask-1_2019_04_22_20_10_57_0000--s-0] Epoch 19 finished
-----------------------------  --------------
replay_buffer/size              4200
trainer/QF1 Loss                   1.11762
trainer/QF2 Loss                   1.15741
trainer/Policy Loss               11.5486
trainer/Q1 Predictions Mean      -12.6874
trainer/Q1 Predictions Std         6.96433
trainer/Q1 Predictions Max        -9.24186
trainer/Q1 Predictions Min       -42.0709
trainer/Q2 Predictions Mean      -12.5886
trainer/Q2 Predictions Std         6.95779
trainer/Q2 Predictions Max        -9.21582
trainer/Q2 Predictions Min       -41.878
trainer/Q Targets Mean           -12.7966
trainer/Q Targets Std              7.31007
trainer/Q Targets Max             -0.43652
trainer/Q Targets Min            -42.3186
trainer/Log Pis Mean              -0.147029
trainer/Log Pis Std                1.30484
trainer/Log Pis Max                4.03351
trainer/Log Pis Min               -3.77668
trainer/Policy mu Mean             0.0275615
trainer/Policy mu Std              0.770905
trainer/Policy mu Max              1.91495
trainer/Policy mu Min             -1.96475
trainer/Policy log std Mean       -0.683253
trainer/Policy log std Std         0.0871582
trainer/Policy log std Max        -0.505055
trainer/Policy log std Min        -0.800947
trainer/Alpha                      0.345486
trainer/Alpha Loss                -2.28126
exploration/num steps total     4200
exploration/num paths total       42
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.637493
exploration/Rewards Std            0.438023
exploration/Rewards Max           -0.0227881
exploration/Rewards Min           -3.42085
exploration/Returns Mean         -63.7493
exploration/Returns Std            1.89997
exploration/Returns Max          -61.8494
exploration/Returns Min          -65.6493
exploration/Actions Mean          -0.0143795
exploration/Actions Std            0.48784
exploration/Actions Max            0.965066
exploration/Actions Min           -0.991775
exploration/Num Paths              2
exploration/Average Returns      -63.7493
evaluation/num steps total     20000
evaluation/num paths total       200
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.143394
evaluation/Rewards Std             0.502366
evaluation/Rewards Max            -0.0313864
evaluation/Rewards Min            -4.81817
evaluation/Returns Mean          -14.3394
evaluation/Returns Std             4.10227
evaluation/Returns Max            -8.17988
evaluation/Returns Min           -20.2131
evaluation/Actions Mean           -0.00421987
evaluation/Actions Std             0.155419
evaluation/Actions Max             0.958215
evaluation/Actions Min            -0.956502
evaluation/Num Paths              10
evaluation/Average Returns       -14.3394
time/data storing (s)              0.00119681
time/evaluation sampling (s)       0.252941
time/exploration sampling (s)      0.0670957
time/logging (s)                   0.00342386
time/saving (s)                    0.00233525
time/training (s)                  0.983144
time/epoch (s)                     1.31014
time/total (s)                    26.6802
Epoch                             19
-----------------------------  --------------
2019-04-22 20:11:25.439002 PDT | [sac-pointmass-multitask-1_2019_04_22_20_10_57_0000--s-0] Epoch 20 finished
-----------------------------  --------------
replay_buffer/size              4400
trainer/QF1 Loss                   1.05331
trainer/QF2 Loss                   1.09751
trainer/Policy Loss               10.5654
trainer/Q1 Predictions Mean      -11.624
trainer/Q1 Predictions Std         4.22884
trainer/Q1 Predictions Max        -9.60317
trainer/Q1 Predictions Min       -30.541
trainer/Q2 Predictions Mean      -11.5925
trainer/Q2 Predictions Std         4.20891
trainer/Q2 Predictions Max        -9.52567
trainer/Q2 Predictions Min       -30.3159
trainer/Q Targets Mean           -11.7402
trainer/Q Targets Std              4.38901
trainer/Q Targets Max             -1.12208
trainer/Q Targets Min            -31.6973
trainer/Log Pis Mean              -0.489374
trainer/Log Pis Std                1.0661
trainer/Log Pis Max                2.42976
trainer/Log Pis Min               -2.94107
trainer/Policy mu Mean             0.0451379
trainer/Policy mu Std              0.662283
trainer/Policy mu Max              1.96057
trainer/Policy mu Min             -1.88241
trainer/Policy log std Mean       -0.670741
trainer/Policy log std Std         0.0590527
trainer/Policy log std Max        -0.526208
trainer/Policy log std Min        -0.748724
trainer/Alpha                      0.3259
trainer/Alpha Loss                -2.79028
exploration/num steps total     4400
exploration/num paths total       44
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.614851
exploration/Rewards Std            0.548918
exploration/Rewards Max           -0.0316607
exploration/Rewards Min           -5.21501
exploration/Returns Mean         -61.4851
exploration/Returns Std           10.3526
exploration/Returns Max          -51.1325
exploration/Returns Min          -71.8377
exploration/Actions Mean          -0.0200774
exploration/Actions Std            0.483435
exploration/Actions Max            0.896387
exploration/Actions Min           -0.976442
exploration/Num Paths              2
exploration/Average Returns      -61.4851
evaluation/num steps total     21000
evaluation/num paths total       210
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.230349
evaluation/Rewards Std             0.49629
evaluation/Rewards Max            -0.0498462
evaluation/Rewards Min            -5.57152
evaluation/Returns Mean          -23.0349
evaluation/Returns Std             4.56779
evaluation/Returns Max           -17.0904
evaluation/Returns Min           -30.5773
evaluation/Actions Mean            0.00419392
evaluation/Actions Std             0.153627
evaluation/Actions Max             0.954598
evaluation/Actions Min            -0.948514
evaluation/Num Paths              10
evaluation/Average Returns       -23.0349
time/data storing (s)              0.00130586
time/evaluation sampling (s)       0.256279
time/exploration sampling (s)      0.0671748
time/logging (s)                   0.00344685
time/saving (s)                    0.00186838
time/training (s)                  0.984646
time/epoch (s)                     1.31472
time/total (s)                    27.9991
Epoch                             20
-----------------------------  --------------
2019-04-22 20:11:26.751220 PDT | [sac-pointmass-multitask-1_2019_04_22_20_10_57_0000--s-0] Epoch 21 finished
-----------------------------  --------------
replay_buffer/size              4600
trainer/QF1 Loss                   0.40261
trainer/QF2 Loss                   0.370582
trainer/Policy Loss               12.8817
trainer/Q1 Predictions Mean      -13.9206
trainer/Q1 Predictions Std         6.31648
trainer/Q1 Predictions Max        -9.95957
trainer/Q1 Predictions Min       -41.2671
trainer/Q2 Predictions Mean      -13.959
trainer/Q2 Predictions Std         6.32955
trainer/Q2 Predictions Max        -9.99683
trainer/Q2 Predictions Min       -41.4248
trainer/Q Targets Mean           -14.1831
trainer/Q Targets Std              6.48652
trainer/Q Targets Max             -9.7515
trainer/Q Targets Min            -42.9014
trainer/Log Pis Mean               0.0702333
trainer/Log Pis Std                1.49762
trainer/Log Pis Max                3.80299
trainer/Log Pis Min               -3.07136
trainer/Policy mu Mean             0.0549223
trainer/Policy mu Std              0.878385
trainer/Policy mu Max              1.95392
trainer/Policy mu Min             -1.9089
trainer/Policy log std Mean       -0.657398
trainer/Policy log std Std         0.0868487
trainer/Policy log std Max        -0.47119
trainer/Policy log std Min        -0.78613
trainer/Alpha                      0.307448
trainer/Alpha Loss                -2.27551
exploration/num steps total     4600
exploration/num paths total       46
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.649027
exploration/Rewards Std            0.594255
exploration/Rewards Max           -0.0540011
exploration/Rewards Min           -4.42709
exploration/Returns Mean         -64.9027
exploration/Returns Std            0.814275
exploration/Returns Max          -64.0884
exploration/Returns Min          -65.717
exploration/Actions Mean          -0.0112767
exploration/Actions Std            0.497599
exploration/Actions Max            0.98034
exploration/Actions Min           -0.963385
exploration/Num Paths              2
exploration/Average Returns      -64.9027
evaluation/num steps total     22000
evaluation/num paths total       220
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.173846
evaluation/Rewards Std             0.527809
evaluation/Rewards Max            -0.0450111
evaluation/Rewards Min            -5.04155
evaluation/Returns Mean          -17.3846
evaluation/Returns Std             4.41197
evaluation/Returns Max            -9.24974
evaluation/Returns Min           -22.6132
evaluation/Actions Mean            0.0148449
evaluation/Actions Std             0.155255
evaluation/Actions Max             0.960526
evaluation/Actions Min            -0.957734
evaluation/Num Paths              10
evaluation/Average Returns       -17.3846
time/data storing (s)              0.00119924
time/evaluation sampling (s)       0.252843
time/exploration sampling (s)      0.0669698
time/logging (s)                   0.00342922
time/saving (s)                    0.00233813
time/training (s)                  0.980364
time/epoch (s)                     1.30714
time/total (s)                    29.3103
Epoch                             21
-----------------------------  --------------
2019-04-22 20:11:28.037750 PDT | [sac-pointmass-multitask-1_2019_04_22_20_10_57_0000--s-0] Epoch 22 finished
-----------------------------  --------------
replay_buffer/size              4800
trainer/QF1 Loss                   0.225982
trainer/QF2 Loss                   0.204627
trainer/Policy Loss               11.7819
trainer/Q1 Predictions Mean      -12.8215
trainer/Q1 Predictions Std         5.35973
trainer/Q1 Predictions Max       -10.4276
trainer/Q1 Predictions Min       -39.5609
trainer/Q2 Predictions Mean      -12.8079
trainer/Q2 Predictions Std         5.38882
trainer/Q2 Predictions Max       -10.4256
trainer/Q2 Predictions Min       -39.5014
trainer/Q Targets Mean           -12.8573
trainer/Q Targets Std              5.45329
trainer/Q Targets Max            -10.1031
trainer/Q Targets Min            -37.677
trainer/Log Pis Mean              -0.289204
trainer/Log Pis Std                1.38071
trainer/Log Pis Max                4.50361
trainer/Log Pis Min               -3.86014
trainer/Policy mu Mean             0.0486643
trainer/Policy mu Std              0.688792
trainer/Policy mu Max              1.94605
trainer/Policy mu Min             -1.92864
trainer/Policy log std Mean       -0.73504
trainer/Policy log std Std         0.0719892
trainer/Policy log std Max        -0.549362
trainer/Policy log std Min        -0.837233
trainer/Alpha                      0.290069
trainer/Alpha Loss                -2.83256
exploration/num steps total     4800
exploration/num paths total       48
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.608736
exploration/Rewards Std            0.564211
exploration/Rewards Max           -0.0311507
exploration/Rewards Min           -5.59259
exploration/Returns Mean         -60.8736
exploration/Returns Std            7.28303
exploration/Returns Max          -53.5906
exploration/Returns Min          -68.1566
exploration/Actions Mean          -0.00162778
exploration/Actions Std            0.46776
exploration/Actions Max            0.985232
exploration/Actions Min           -0.968665
exploration/Num Paths              2
exploration/Average Returns      -60.8736
evaluation/num steps total     23000
evaluation/num paths total       230
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.111972
evaluation/Rewards Std             0.52232
evaluation/Rewards Max            -0.0077346
evaluation/Rewards Min            -5.29516
evaluation/Returns Mean          -11.1972
evaluation/Returns Std             3.99079
evaluation/Returns Max            -4.69436
evaluation/Returns Min           -17.9414
evaluation/Actions Mean           -0.00959486
evaluation/Actions Std             0.156148
evaluation/Actions Max             0.954579
evaluation/Actions Min            -0.963034
evaluation/Num Paths              10
evaluation/Average Returns       -11.1972
time/data storing (s)              0.00124424
time/evaluation sampling (s)       0.253524
time/exploration sampling (s)      0.0664834
time/logging (s)                   0.00335315
time/saving (s)                    0.00229651
time/training (s)                  0.954423
time/epoch (s)                     1.28132
time/total (s)                    30.5958
Epoch                             22
-----------------------------  --------------
2019-04-22 20:11:29.333422 PDT | [sac-pointmass-multitask-1_2019_04_22_20_10_57_0000--s-0] Epoch 23 finished
-----------------------------  --------------
replay_buffer/size              5000
trainer/QF1 Loss                   1.36034
trainer/QF2 Loss                   1.36975
trainer/Policy Loss               11.9075
trainer/Q1 Predictions Mean      -12.8374
trainer/Q1 Predictions Std         4.60404
trainer/Q1 Predictions Max       -10.8806
trainer/Q1 Predictions Min       -41.0943
trainer/Q2 Predictions Mean      -12.8508
trainer/Q2 Predictions Std         4.61649
trainer/Q2 Predictions Max       -10.9012
trainer/Q2 Predictions Min       -41.136
trainer/Q Targets Mean           -12.5753
trainer/Q Targets Std              4.79916
trainer/Q Targets Max             -0.275472
trainer/Q Targets Min            -41.6287
trainer/Log Pis Mean              -0.485179
trainer/Log Pis Std                1.38362
trainer/Log Pis Max                4.23181
trainer/Log Pis Min               -4.34328
trainer/Policy mu Mean             0.0340993
trainer/Policy mu Std              0.666411
trainer/Policy mu Max              1.92364
trainer/Policy mu Min             -1.9495
trainer/Policy log std Mean       -0.719351
trainer/Policy log std Std         0.0920721
trainer/Policy log std Max        -0.505573
trainer/Policy log std Min        -0.834798
trainer/Alpha                      0.273917
trainer/Alpha Loss                -3.2174
exploration/num steps total     5000
exploration/num paths total       50
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.591579
exploration/Rewards Std            0.510922
exploration/Rewards Max           -0.0505886
exploration/Rewards Min           -4.19948
exploration/Returns Mean         -59.1579
exploration/Returns Std            5.00721
exploration/Returns Max          -54.1507
exploration/Returns Min          -64.1651
exploration/Actions Mean           0.00624975
exploration/Actions Std            0.477957
exploration/Actions Max            0.975238
exploration/Actions Min           -0.949039
exploration/Num Paths              2
exploration/Average Returns      -59.1579
evaluation/num steps total     24000
evaluation/num paths total       240
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.114644
evaluation/Rewards Std             0.572491
evaluation/Rewards Max            -0.0132503
evaluation/Rewards Min            -6.54348
evaluation/Returns Mean          -11.4644
evaluation/Returns Std             7.31073
evaluation/Returns Max            -2.21589
evaluation/Returns Min           -22.5868
evaluation/Actions Mean           -0.0059516
evaluation/Actions Std             0.152283
evaluation/Actions Max             0.971208
evaluation/Actions Min            -0.960616
evaluation/Num Paths              10
evaluation/Average Returns       -11.4644
time/data storing (s)              0.00132199
time/evaluation sampling (s)       0.248052
time/exploration sampling (s)      0.066489
time/logging (s)                   0.00345465
time/saving (s)                    0.00255407
time/training (s)                  0.968763
time/epoch (s)                     1.29063
time/total (s)                    31.8906
Epoch                             23
-----------------------------  --------------
2019-04-22 20:11:30.634059 PDT | [sac-pointmass-multitask-1_2019_04_22_20_10_57_0000--s-0] Epoch 24 finished
-----------------------------  --------------
replay_buffer/size              5200
trainer/QF1 Loss                   2.38519
trainer/QF2 Loss                   2.37443
trainer/Policy Loss               12.1998
trainer/Q1 Predictions Mean      -12.8557
trainer/Q1 Predictions Std         4.73333
trainer/Q1 Predictions Max       -10.8945
trainer/Q1 Predictions Min       -38.4735
trainer/Q2 Predictions Mean      -12.8173
trainer/Q2 Predictions Std         4.72072
trainer/Q2 Predictions Max       -10.8856
trainer/Q2 Predictions Min       -38.6186
trainer/Q Targets Mean           -12.752
trainer/Q Targets Std              5.11035
trainer/Q Targets Max             -0.550006
trainer/Q Targets Min            -40.3308
trainer/Log Pis Mean              -0.0714338
trainer/Log Pis Std                1.36123
trainer/Log Pis Max                4.87129
trainer/Log Pis Min               -3.41938
trainer/Policy mu Mean             0.0524375
trainer/Policy mu Std              0.692132
trainer/Policy mu Max              2.18259
trainer/Policy mu Min             -1.92144
trainer/Policy log std Mean       -0.814274
trainer/Policy log std Std         0.124383
trainer/Policy log std Max        -0.531422
trainer/Policy log std Min        -0.971304
trainer/Alpha                      0.258723
trainer/Alpha Loss                -2.79997
exploration/num steps total     5200
exploration/num paths total       52
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.512668
exploration/Rewards Std            0.436539
exploration/Rewards Max           -0.032254
exploration/Rewards Min           -4.57246
exploration/Returns Mean         -51.2668
exploration/Returns Std            2.7464
exploration/Returns Max          -48.5204
exploration/Returns Min          -54.0132
exploration/Actions Mean           0.0224901
exploration/Actions Std            0.442815
exploration/Actions Max            0.97522
exploration/Actions Min           -0.89838
exploration/Num Paths              2
exploration/Average Returns      -51.2668
evaluation/num steps total     25000
evaluation/num paths total       250
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.131088
evaluation/Rewards Std             0.558542
evaluation/Rewards Max            -0.00791375
evaluation/Rewards Min            -5.83699
evaluation/Returns Mean          -13.1088
evaluation/Returns Std             5.04433
evaluation/Returns Max            -4.03543
evaluation/Returns Min           -21.3102
evaluation/Actions Mean           -0.00407546
evaluation/Actions Std             0.157326
evaluation/Actions Max             0.977059
evaluation/Actions Min            -0.966367
evaluation/Num Paths              10
evaluation/Average Returns       -13.1088
time/data storing (s)              0.0012143
time/evaluation sampling (s)       0.249966
time/exploration sampling (s)      0.068279
time/logging (s)                   0.00340464
time/saving (s)                    0.00198612
time/training (s)                  0.97056
time/epoch (s)                     1.29541
time/total (s)                    33.1901
Epoch                             24
-----------------------------  --------------
2019-04-22 20:11:31.946348 PDT | [sac-pointmass-multitask-1_2019_04_22_20_10_57_0000--s-0] Epoch 25 finished
-----------------------------  --------------
replay_buffer/size              5400
trainer/QF1 Loss                   5.10702
trainer/QF2 Loss                   5.02521
trainer/Policy Loss               12.3859
trainer/Q1 Predictions Mean      -13.108
trainer/Q1 Predictions Std         4.57737
trainer/Q1 Predictions Max       -11.0954
trainer/Q1 Predictions Min       -35.3362
trainer/Q2 Predictions Mean      -13.148
trainer/Q2 Predictions Std         4.62812
trainer/Q2 Predictions Max       -11.0678
trainer/Q2 Predictions Min       -35.4754
trainer/Q Targets Mean           -13.0927
trainer/Q Targets Std              4.85931
trainer/Q Targets Max             -0.558071
trainer/Q Targets Min            -37.3268
trainer/Log Pis Mean              -0.0470932
trainer/Log Pis Std                1.18538
trainer/Log Pis Max                3.96108
trainer/Log Pis Min               -4.22261
trainer/Policy mu Mean             0.0279805
trainer/Policy mu Std              0.715452
trainer/Policy mu Max              2.14378
trainer/Policy mu Min             -1.85631
trainer/Policy log std Mean       -0.80078
trainer/Policy log std Std         0.108237
trainer/Policy log std Max        -0.55481
trainer/Policy log std Min        -0.943626
trainer/Alpha                      0.244397
trainer/Alpha Loss                -2.88371
exploration/num steps total     5400
exploration/num paths total       54
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.539026
exploration/Rewards Std            0.563228
exploration/Rewards Max           -0.0248614
exploration/Rewards Min           -5.38051
exploration/Returns Mean         -53.9026
exploration/Returns Std            5.92262
exploration/Returns Max          -47.98
exploration/Returns Min          -59.8253
exploration/Actions Mean          -0.00370743
exploration/Actions Std            0.451514
exploration/Actions Max            0.973128
exploration/Actions Min           -0.956856
exploration/Num Paths              2
exploration/Average Returns      -53.9026
evaluation/num steps total     26000
evaluation/num paths total       260
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.10821
evaluation/Rewards Std             0.452858
evaluation/Rewards Max            -0.0257958
evaluation/Rewards Min            -6.08932
evaluation/Returns Mean          -10.821
evaluation/Returns Std             5.05324
evaluation/Returns Max            -5.39659
evaluation/Returns Min           -22.5798
evaluation/Actions Mean           -0.0016553
evaluation/Actions Std             0.150632
evaluation/Actions Max             0.956845
evaluation/Actions Min            -0.9626
evaluation/Num Paths              10
evaluation/Average Returns       -10.821
time/data storing (s)              0.00121293
time/evaluation sampling (s)       0.249815
time/exploration sampling (s)      0.0681953
time/logging (s)                   0.00342957
time/saving (s)                    0.00232105
time/training (s)                  0.982795
time/epoch (s)                     1.30777
time/total (s)                    34.5014
Epoch                             25
-----------------------------  --------------
2019-04-22 20:11:33.244682 PDT | [sac-pointmass-multitask-1_2019_04_22_20_10_57_0000--s-0] Epoch 26 finished
-----------------------------  --------------
replay_buffer/size              5600
trainer/QF1 Loss                   2.61024
trainer/QF2 Loss                   2.61289
trainer/Policy Loss               12.1321
trainer/Q1 Predictions Mean      -12.9023
trainer/Q1 Predictions Std         3.60075
trainer/Q1 Predictions Max       -11.3967
trainer/Q1 Predictions Min       -33.2953
trainer/Q2 Predictions Mean      -12.9742
trainer/Q2 Predictions Std         3.64451
trainer/Q2 Predictions Max       -11.4954
trainer/Q2 Predictions Min       -33.6969
trainer/Q Targets Mean           -12.7659
trainer/Q Targets Std              4.09797
trainer/Q Targets Max             -0.275472
trainer/Q Targets Min            -33.9437
trainer/Log Pis Mean              -0.204985
trainer/Log Pis Std                0.91681
trainer/Log Pis Max                3.56401
trainer/Log Pis Min               -2.63337
trainer/Policy mu Mean             0.00414678
trainer/Policy mu Std              0.65773
trainer/Policy mu Max              2.02239
trainer/Policy mu Min             -2.03523
trainer/Policy log std Mean       -0.843679
trainer/Policy log std Std         0.127973
trainer/Policy log std Max        -0.509733
trainer/Policy log std Min        -1.00604
trainer/Alpha                      0.230932
trainer/Alpha Loss                -3.23109
exploration/num steps total     5600
exploration/num paths total       56
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.534889
exploration/Rewards Std            0.57127
exploration/Rewards Max           -0.0253245
exploration/Rewards Min           -5.26396
exploration/Returns Mean         -53.4889
exploration/Returns Std            5.71777
exploration/Returns Max          -47.7711
exploration/Returns Min          -59.2067
exploration/Actions Mean           0.0016392
exploration/Actions Std            0.439278
exploration/Actions Max            0.959763
exploration/Actions Min           -0.979033
exploration/Num Paths              2
exploration/Average Returns      -53.4889
evaluation/num steps total     27000
evaluation/num paths total       270
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.14949
evaluation/Rewards Std             0.511745
evaluation/Rewards Max            -0.0322774
evaluation/Rewards Min            -5.84707
evaluation/Returns Mean          -14.949
evaluation/Returns Std             6.12607
evaluation/Returns Max            -7.02882
evaluation/Returns Min           -24.5447
evaluation/Actions Mean           -0.00701694
evaluation/Actions Std             0.149609
evaluation/Actions Max             0.969041
evaluation/Actions Min            -0.964477
evaluation/Num Paths              10
evaluation/Average Returns       -14.949
time/data storing (s)              0.00117974
time/evaluation sampling (s)       0.246551
time/exploration sampling (s)      0.0669799
time/logging (s)                   0.00336489
time/saving (s)                    0.00232021
time/training (s)                  0.972574
time/epoch (s)                     1.29297
time/total (s)                    35.7987
Epoch                             26
-----------------------------  --------------
2019-04-22 20:11:34.523767 PDT | [sac-pointmass-multitask-1_2019_04_22_20_10_57_0000--s-0] Epoch 27 finished
-----------------------------  --------------
replay_buffer/size              5800
trainer/QF1 Loss                   0.11347
trainer/QF2 Loss                   0.098596
trainer/Policy Loss               12.693
trainer/Q1 Predictions Mean      -13.3109
trainer/Q1 Predictions Std         4.66845
trainer/Q1 Predictions Max       -11.5158
trainer/Q1 Predictions Min       -37.9289
trainer/Q2 Predictions Mean      -13.3255
trainer/Q2 Predictions Std         4.68196
trainer/Q2 Predictions Max       -11.5797
trainer/Q2 Predictions Min       -38.228
trainer/Q Targets Mean           -13.4695
trainer/Q Targets Std              4.70457
trainer/Q Targets Max            -11.5445
trainer/Q Targets Min            -39.0467
trainer/Log Pis Mean              -0.0581817
trainer/Log Pis Std                1.36337
trainer/Log Pis Max                4.70284
trainer/Log Pis Min               -5.29667
trainer/Policy mu Mean             0.0313105
trainer/Policy mu Std              0.626043
trainer/Policy mu Max              1.96284
trainer/Policy mu Min             -2.04923
trainer/Policy log std Mean       -0.904928
trainer/Policy log std Std         0.104332
trainer/Policy log std Max        -0.57963
trainer/Policy log std Min        -1.03132
trainer/Alpha                      0.218274
trainer/Alpha Loss                -3.13199
exploration/num steps total     5800
exploration/num paths total       58
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.545881
exploration/Rewards Std            0.568437
exploration/Rewards Max           -0.0667898
exploration/Rewards Min           -5.2822
exploration/Returns Mean         -54.5881
exploration/Returns Std            3.82855
exploration/Returns Max          -50.7595
exploration/Returns Min          -58.4166
exploration/Actions Mean          -0.0102534
exploration/Actions Std            0.442258
exploration/Actions Max            0.977219
exploration/Actions Min           -0.9787
exploration/Num Paths              2
exploration/Average Returns      -54.5881
evaluation/num steps total     28000
evaluation/num paths total       280
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.18388
evaluation/Rewards Std             0.613566
evaluation/Rewards Max            -0.00935167
evaluation/Rewards Min            -6.47324
evaluation/Returns Mean          -18.388
evaluation/Returns Std             4.21973
evaluation/Returns Max           -12.4869
evaluation/Returns Min           -27.0705
evaluation/Actions Mean            0.00432092
evaluation/Actions Std             0.174173
evaluation/Actions Max             0.964893
evaluation/Actions Min            -0.965086
evaluation/Num Paths              10
evaluation/Average Returns       -18.388
time/data storing (s)              0.00117212
time/evaluation sampling (s)       0.251317
time/exploration sampling (s)      0.0650219
time/logging (s)                   0.00333506
time/saving (s)                    0.00230484
time/training (s)                  0.950717
time/epoch (s)                     1.27387
time/total (s)                    37.0766
Epoch                             27
-----------------------------  --------------
2019-04-22 20:11:35.844963 PDT | [sac-pointmass-multitask-1_2019_04_22_20_10_57_0000--s-0] Epoch 28 finished
-----------------------------  --------------
replay_buffer/size              6000
trainer/QF1 Loss                   5.57583
trainer/QF2 Loss                   5.47335
trainer/Policy Loss               13.8749
trainer/Q1 Predictions Mean      -14.3248
trainer/Q1 Predictions Std         4.9825
trainer/Q1 Predictions Max       -11.9254
trainer/Q1 Predictions Min       -36.5543
trainer/Q2 Predictions Mean      -14.3055
trainer/Q2 Predictions Std         4.93228
trainer/Q2 Predictions Max       -11.944
trainer/Q2 Predictions Min       -36.2171
trainer/Q Targets Mean           -14.1673
trainer/Q Targets Std              5.00927
trainer/Q Targets Max             -6.34499
trainer/Q Targets Min            -35.674
trainer/Log Pis Mean               0.286633
trainer/Log Pis Std                1.29381
trainer/Log Pis Max                4.4532
trainer/Log Pis Min               -2.30794
trainer/Policy mu Mean             0.0187906
trainer/Policy mu Std              0.749105
trainer/Policy mu Max              2.11471
trainer/Policy mu Min             -1.91221
trainer/Policy log std Mean       -0.880449
trainer/Policy log std Std         0.144743
trainer/Policy log std Max        -0.554493
trainer/Policy log std Min        -1.06311
trainer/Alpha                      0.206468
trainer/Alpha Loss                -2.70256
exploration/num steps total     6000
exploration/num paths total       60
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.464705
exploration/Rewards Std            0.26453
exploration/Rewards Max           -0.0380115
exploration/Rewards Min           -2.21433
exploration/Returns Mean         -46.4705
exploration/Returns Std            0.0998876
exploration/Returns Max          -46.3706
exploration/Returns Min          -46.5704
exploration/Actions Mean          -0.00224592
exploration/Actions Std            0.430639
exploration/Actions Max            0.887615
exploration/Actions Min           -0.90377
exploration/Num Paths              2
exploration/Average Returns      -46.4705
evaluation/num steps total     29000
evaluation/num paths total       290
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.145555
evaluation/Rewards Std             0.541827
evaluation/Rewards Max            -0.0211129
evaluation/Rewards Min            -5.49613
evaluation/Returns Mean          -14.5555
evaluation/Returns Std             4.46985
evaluation/Returns Max            -8.59343
evaluation/Returns Min           -21.8742
evaluation/Actions Mean            0.0107295
evaluation/Actions Std             0.165002
evaluation/Actions Max             0.975005
evaluation/Actions Min            -0.967017
evaluation/Num Paths              10
evaluation/Average Returns       -14.5555
time/data storing (s)              0.00117443
time/evaluation sampling (s)       0.254305
time/exploration sampling (s)      0.0659726
time/logging (s)                   0.00347951
time/saving (s)                    0.0018169
time/training (s)                  0.989368
time/epoch (s)                     1.31612
time/total (s)                    38.3969
Epoch                             28
-----------------------------  --------------
2019-04-22 20:11:37.151036 PDT | [sac-pointmass-multitask-1_2019_04_22_20_10_57_0000--s-0] Epoch 29 finished
-----------------------------  --------------
replay_buffer/size              6200
trainer/QF1 Loss                   0.149112
trainer/QF2 Loss                   0.13829
trainer/Policy Loss               13.7228
trainer/Q1 Predictions Mean      -14.3002
trainer/Q1 Predictions Std         6.12557
trainer/Q1 Predictions Max       -11.9769
trainer/Q1 Predictions Min       -41.584
trainer/Q2 Predictions Mean      -14.2682
trainer/Q2 Predictions Std         6.13665
trainer/Q2 Predictions Max       -11.9281
trainer/Q2 Predictions Min       -41.5956
trainer/Q Targets Mean           -14.4852
trainer/Q Targets Std              6.13692
trainer/Q Targets Max            -11.9329
trainer/Q Targets Min            -42.7875
trainer/Log Pis Mean               0.141175
trainer/Log Pis Std                1.51272
trainer/Log Pis Max                4.98168
trainer/Log Pis Min               -3.41673
trainer/Policy mu Mean            -0.0070334
trainer/Policy mu Std              0.700941
trainer/Policy mu Max              2.12198
trainer/Policy mu Min             -2.18989
trainer/Policy log std Mean       -0.939614
trainer/Policy log std Std         0.143644
trainer/Policy log std Max        -0.577294
trainer/Policy log std Min        -1.11541
trainer/Alpha                      0.195424
trainer/Alpha Loss                -3.03418
exploration/num steps total     6200
exploration/num paths total       62
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.574268
exploration/Rewards Std            0.755864
exploration/Rewards Max           -0.0406077
exploration/Rewards Min           -5.94109
exploration/Returns Mean         -57.4268
exploration/Returns Std            0.282988
exploration/Returns Max          -57.1438
exploration/Returns Min          -57.7098
exploration/Actions Mean           0.0503474
exploration/Actions Std            0.438986
exploration/Actions Max            0.992127
exploration/Actions Min           -0.974106
exploration/Num Paths              2
exploration/Average Returns      -57.4268
evaluation/num steps total     30000
evaluation/num paths total       300
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.12776
evaluation/Rewards Std             0.533651
evaluation/Rewards Max            -0.0245273
evaluation/Rewards Min            -5.33308
evaluation/Returns Mean          -12.776
evaluation/Returns Std             4.04872
evaluation/Returns Max            -6.26776
evaluation/Returns Min           -18.4252
evaluation/Actions Mean            0.0102194
evaluation/Actions Std             0.164015
evaluation/Actions Max             0.967505
evaluation/Actions Min            -0.970136
evaluation/Num Paths              10
evaluation/Average Returns       -12.776
time/data storing (s)              0.00123632
time/evaluation sampling (s)       0.252109
time/exploration sampling (s)      0.0653151
time/logging (s)                   0.00335064
time/saving (s)                    0.00240128
time/training (s)                  0.976287
time/epoch (s)                     1.3007
time/total (s)                    39.7018
Epoch                             29
-----------------------------  --------------
2019-04-22 20:11:38.461307 PDT | [sac-pointmass-multitask-1_2019_04_22_20_10_57_0000--s-0] Epoch 30 finished
-----------------------------  --------------
replay_buffer/size              6400
trainer/QF1 Loss                   0.103619
trainer/QF2 Loss                   0.109892
trainer/Policy Loss               14.5093
trainer/Q1 Predictions Mean      -14.9346
trainer/Q1 Predictions Std         6.27275
trainer/Q1 Predictions Max       -12.228
trainer/Q1 Predictions Min       -43.2414
trainer/Q2 Predictions Mean      -14.927
trainer/Q2 Predictions Std         6.30004
trainer/Q2 Predictions Max       -12.1461
trainer/Q2 Predictions Min       -43.3482
trainer/Q Targets Mean           -15.0572
trainer/Q Targets Std              6.29341
trainer/Q Targets Max            -12.1356
trainer/Q Targets Min            -42.6964
trainer/Log Pis Mean               0.306761
trainer/Log Pis Std                1.5771
trainer/Log Pis Max                5.42538
trainer/Log Pis Min               -3.11025
trainer/Policy mu Mean             0.0280937
trainer/Policy mu Std              0.80084
trainer/Policy mu Max              2.15997
trainer/Policy mu Min             -2.13001
trainer/Policy log std Mean       -0.938518
trainer/Policy log std Std         0.148045
trainer/Policy log std Max        -0.544442
trainer/Policy log std Min        -1.1217
trainer/Alpha                      0.185085
trainer/Alpha Loss                -2.85594
exploration/num steps total     6400
exploration/num paths total       64
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.461503
exploration/Rewards Std            0.464152
exploration/Rewards Max           -0.0354193
exploration/Rewards Min           -4.51071
exploration/Returns Mean         -46.1503
exploration/Returns Std            2.67763
exploration/Returns Max          -43.4727
exploration/Returns Min          -48.828
exploration/Actions Mean           0.0205405
exploration/Actions Std            0.406517
exploration/Actions Max            0.989489
exploration/Actions Min           -0.798109
exploration/Num Paths              2
exploration/Average Returns      -46.1503
evaluation/num steps total     31000
evaluation/num paths total       310
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.116871
evaluation/Rewards Std             0.585781
evaluation/Rewards Max            -0.00287239
evaluation/Rewards Min            -6.81059
evaluation/Returns Mean          -11.6871
evaluation/Returns Std             5.76019
evaluation/Returns Max            -1.57855
evaluation/Returns Min           -22.8741
evaluation/Actions Mean           -0.0180715
evaluation/Actions Std             0.161469
evaluation/Actions Max             0.968345
evaluation/Actions Min            -0.97318
evaluation/Num Paths              10
evaluation/Average Returns       -11.6871
time/data storing (s)              0.00120016
time/evaluation sampling (s)       0.258918
time/exploration sampling (s)      0.0664228
time/logging (s)                   0.00333001
time/saving (s)                    0.0019825
time/training (s)                  0.973381
time/epoch (s)                     1.30523
time/total (s)                    41.0109
Epoch                             30
-----------------------------  --------------
2019-04-22 20:11:39.765643 PDT | [sac-pointmass-multitask-1_2019_04_22_20_10_57_0000--s-0] Epoch 31 finished
-----------------------------  --------------
replay_buffer/size              6600
trainer/QF1 Loss                   0.0618985
trainer/QF2 Loss                   0.06209
trainer/Policy Loss               13.7779
trainer/Q1 Predictions Mean      -13.983
trainer/Q1 Predictions Std         4.60879
trainer/Q1 Predictions Max       -12.4468
trainer/Q1 Predictions Min       -37.7753
trainer/Q2 Predictions Mean      -14.0502
trainer/Q2 Predictions Std         4.61615
trainer/Q2 Predictions Max       -12.4914
trainer/Q2 Predictions Min       -37.5812
trainer/Q Targets Mean           -13.9859
trainer/Q Targets Std              4.54578
trainer/Q Targets Max            -12.256
trainer/Q Targets Min            -37.2859
trainer/Log Pis Mean               0.0891496
trainer/Log Pis Std                1.27954
trainer/Log Pis Max                5.23858
trainer/Log Pis Min               -4.97645
trainer/Policy mu Mean            -0.057747
trainer/Policy mu Std              0.617853
trainer/Policy mu Max              2.25506
trainer/Policy mu Min             -2.16627
trainer/Policy log std Mean       -0.994161
trainer/Policy log std Std         0.146058
trainer/Policy log std Max        -0.511683
trainer/Policy log std Min        -1.1671
trainer/Alpha                      0.175367
trainer/Alpha Loss                -3.32602
exploration/num steps total     6600
exploration/num paths total       66
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.560147
exploration/Rewards Std            0.70737
exploration/Rewards Max           -0.0532377
exploration/Rewards Min           -5.98102
exploration/Returns Mean         -56.0147
exploration/Returns Std            2.37929
exploration/Returns Max          -53.6354
exploration/Returns Min          -58.394
exploration/Actions Mean          -0.0245789
exploration/Actions Std            0.443252
exploration/Actions Max            0.963841
exploration/Actions Min           -0.993597
exploration/Num Paths              2
exploration/Average Returns      -56.0147
evaluation/num steps total     32000
evaluation/num paths total       320
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.124444
evaluation/Rewards Std             0.374425
evaluation/Rewards Max            -0.0360324
evaluation/Rewards Min            -4.7121
evaluation/Returns Mean          -12.4444
evaluation/Returns Std             3.92096
evaluation/Returns Max            -7.41045
evaluation/Returns Min           -20.2699
evaluation/Actions Mean           -0.00597531
evaluation/Actions Std             0.140024
evaluation/Actions Max             0.95178
evaluation/Actions Min            -0.975954
evaluation/Num Paths              10
evaluation/Average Returns       -12.4444
time/data storing (s)              0.00117874
time/evaluation sampling (s)       0.256015
time/exploration sampling (s)      0.0671127
time/logging (s)                   0.00286357
time/saving (s)                    0.0023477
time/training (s)                  0.969151
time/epoch (s)                     1.29867
time/total (s)                    42.3137
Epoch                             31
-----------------------------  --------------
2019-04-22 20:11:41.067441 PDT | [sac-pointmass-multitask-1_2019_04_22_20_10_57_0000--s-0] Epoch 32 finished
-----------------------------  --------------
replay_buffer/size              6800
trainer/QF1 Loss                   1.99786
trainer/QF2 Loss                   2.00689
trainer/Policy Loss               14.3825
trainer/Q1 Predictions Mean      -14.8681
trainer/Q1 Predictions Std         6.22166
trainer/Q1 Predictions Max       -12.4807
trainer/Q1 Predictions Min       -46.5482
trainer/Q2 Predictions Mean      -14.8758
trainer/Q2 Predictions Std         6.19897
trainer/Q2 Predictions Max       -12.489
trainer/Q2 Predictions Min       -46.4452
trainer/Q Targets Mean           -14.8288
trainer/Q Targets Std              6.03948
trainer/Q Targets Max             -1.12208
trainer/Q Targets Min            -46.4279
trainer/Log Pis Mean               0.313193
trainer/Log Pis Std                1.32477
trainer/Log Pis Max                5.65715
trainer/Log Pis Min               -2.75576
trainer/Policy mu Mean            -0.135054
trainer/Policy mu Std              0.745918
trainer/Policy mu Max              2.10897
trainer/Policy mu Min             -2.10869
trainer/Policy log std Mean       -0.961213
trainer/Policy log std Std         0.178276
trainer/Policy log std Max        -0.502829
trainer/Policy log std Min        -1.17664
trainer/Alpha                      0.166174
trainer/Alpha Loss                -3.0269
exploration/num steps total     6800
exploration/num paths total       68
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.541509
exploration/Rewards Std            0.751327
exploration/Rewards Max           -0.0377223
exploration/Rewards Min           -5.84541
exploration/Returns Mean         -54.1509
exploration/Returns Std            0.950937
exploration/Returns Max          -53.2
exploration/Returns Min          -55.1019
exploration/Actions Mean          -0.00185829
exploration/Actions Std            0.428624
exploration/Actions Max            0.959281
exploration/Actions Min           -0.989046
exploration/Num Paths              2
exploration/Average Returns      -54.1509
evaluation/num steps total     33000
evaluation/num paths total       330
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.120576
evaluation/Rewards Std             0.35772
evaluation/Rewards Max            -0.0512232
evaluation/Rewards Min            -4.66144
evaluation/Returns Mean          -12.0576
evaluation/Returns Std             3.84536
evaluation/Returns Max            -6.84552
evaluation/Returns Min           -20.3138
evaluation/Actions Mean           -0.00730965
evaluation/Actions Std             0.134156
evaluation/Actions Max             0.958103
evaluation/Actions Min            -0.976167
evaluation/Num Paths              10
evaluation/Average Returns       -12.0576
time/data storing (s)              0.00119155
time/evaluation sampling (s)       0.252099
time/exploration sampling (s)      0.0671133
time/logging (s)                   0.00344205
time/saving (s)                    0.00223933
time/training (s)                  0.971269
time/epoch (s)                     1.29735
time/total (s)                    43.6149
Epoch                             32
-----------------------------  --------------
2019-04-22 20:11:42.390479 PDT | [sac-pointmass-multitask-1_2019_04_22_20_10_57_0000--s-0] Epoch 33 finished
-----------------------------  --------------
replay_buffer/size              7000
trainer/QF1 Loss                   3.25995
trainer/QF2 Loss                   3.27611
trainer/Policy Loss               13.7618
trainer/Q1 Predictions Mean      -13.9411
trainer/Q1 Predictions Std         2.48452
trainer/Q1 Predictions Max       -12.8237
trainer/Q1 Predictions Min       -27.9225
trainer/Q2 Predictions Mean      -13.956
trainer/Q2 Predictions Std         2.49385
trainer/Q2 Predictions Max       -12.8442
trainer/Q2 Predictions Min       -27.9209
trainer/Q Targets Mean           -13.5901
trainer/Q Targets Std              3.06715
trainer/Q Targets Max             -0.34556
trainer/Q Targets Min            -27.6661
trainer/Log Pis Mean               0.163166
trainer/Log Pis Std                1.42005
trainer/Log Pis Max                4.29066
trainer/Log Pis Min               -4.14625
trainer/Policy mu Mean             0.0719213
trainer/Policy mu Std              0.667847
trainer/Policy mu Max              1.9976
trainer/Policy mu Min             -1.92329
trainer/Policy log std Mean       -1.06839
trainer/Policy log std Std         0.157247
trainer/Policy log std Max        -0.655377
trainer/Policy log std Min        -1.26811
trainer/Alpha                      0.157558
trainer/Alpha Loss                -3.39392
exploration/num steps total     7000
exploration/num paths total       70
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.455632
exploration/Rewards Std            0.540012
exploration/Rewards Max           -0.01171
exploration/Rewards Min           -4.94741
exploration/Returns Mean         -45.5632
exploration/Returns Std            2.67486
exploration/Returns Max          -42.8884
exploration/Returns Min          -48.2381
exploration/Actions Mean           0.0245488
exploration/Actions Std            0.423356
exploration/Actions Max            0.994755
exploration/Actions Min           -0.971106
exploration/Num Paths              2
exploration/Average Returns      -45.5632
evaluation/num steps total     34000
evaluation/num paths total       340
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.173411
evaluation/Rewards Std             0.637511
evaluation/Rewards Max            -0.0410308
evaluation/Rewards Min            -6.54861
evaluation/Returns Mean          -17.3411
evaluation/Returns Std             4.64642
evaluation/Returns Max            -8.83151
evaluation/Returns Min           -25.3176
evaluation/Actions Mean            0.011163
evaluation/Actions Std             0.181404
evaluation/Actions Max             0.97502
evaluation/Actions Min            -0.974672
evaluation/Num Paths              10
evaluation/Average Returns       -17.3411
time/data storing (s)              0.00120855
time/evaluation sampling (s)       0.251978
time/exploration sampling (s)      0.0669178
time/logging (s)                   0.00336336
time/saving (s)                    0.0116025
time/training (s)                  0.98269
time/epoch (s)                     1.31776
time/total (s)                    44.9368
Epoch                             33
-----------------------------  --------------
2019-04-22 20:11:43.689658 PDT | [sac-pointmass-multitask-1_2019_04_22_20_10_57_0000--s-0] Epoch 34 finished
-----------------------------  --------------
replay_buffer/size              7200
trainer/QF1 Loss                   0.132581
trainer/QF2 Loss                   0.094226
trainer/Policy Loss               14.6886
trainer/Q1 Predictions Mean      -14.8044
trainer/Q1 Predictions Std         5.36838
trainer/Q1 Predictions Max       -12.755
trainer/Q1 Predictions Min       -37.7354
trainer/Q2 Predictions Mean      -14.8532
trainer/Q2 Predictions Std         5.32388
trainer/Q2 Predictions Max       -12.8104
trainer/Q2 Predictions Min       -37.5958
trainer/Q Targets Mean           -14.8381
trainer/Q Targets Std              5.13732
trainer/Q Targets Max            -12.6625
trainer/Q Targets Min            -36.6404
trainer/Log Pis Mean               0.297231
trainer/Log Pis Std                1.34291
trainer/Log Pis Max                5.48341
trainer/Log Pis Min               -2.47951
trainer/Policy mu Mean            -0.103839
trainer/Policy mu Std              0.715579
trainer/Policy mu Max              2.1582
trainer/Policy mu Min             -2.29956
trainer/Policy log std Mean       -1.12657
trainer/Policy log std Std         0.21043
trainer/Policy log std Max        -0.55224
trainer/Policy log std Min        -1.37357
trainer/Alpha                      0.149564
trainer/Alpha Loss                -3.23487
exploration/num steps total     7200
exploration/num paths total       72
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.404794
exploration/Rewards Std            0.482556
exploration/Rewards Max           -0.0407744
exploration/Rewards Min           -4.9105
exploration/Returns Mean         -40.4794
exploration/Returns Std            6.15685
exploration/Returns Max          -34.3226
exploration/Returns Min          -46.6363
exploration/Actions Mean           0.0121215
exploration/Actions Std            0.390213
exploration/Actions Max            0.995392
exploration/Actions Min           -0.899738
exploration/Num Paths              2
exploration/Average Returns      -40.4794
evaluation/num steps total     35000
evaluation/num paths total       350
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.147545
evaluation/Rewards Std             0.516887
evaluation/Rewards Max            -0.0205803
evaluation/Rewards Min            -5.30873
evaluation/Returns Mean          -14.7545
evaluation/Returns Std             5.49436
evaluation/Returns Max            -6.4715
evaluation/Returns Min           -21.5501
evaluation/Actions Mean            0.00554203
evaluation/Actions Std             0.153096
evaluation/Actions Max             0.981716
evaluation/Actions Min            -0.975291
evaluation/Num Paths              10
evaluation/Average Returns       -14.7545
time/data storing (s)              0.0013062
time/evaluation sampling (s)       0.245661
time/exploration sampling (s)      0.0693206
time/logging (s)                   0.00336288
time/saving (s)                    0.00231201
time/training (s)                  0.971445
time/epoch (s)                     1.29341
time/total (s)                    46.2348
Epoch                             34
-----------------------------  --------------
2019-04-22 20:11:44.983919 PDT | [sac-pointmass-multitask-1_2019_04_22_20_10_57_0000--s-0] Epoch 35 finished
-----------------------------  --------------
replay_buffer/size              7400
trainer/QF1 Loss                   4.25106
trainer/QF2 Loss                   4.26575
trainer/Policy Loss               15.1574
trainer/Q1 Predictions Mean      -15.5314
trainer/Q1 Predictions Std         5.89718
trainer/Q1 Predictions Max       -12.6794
trainer/Q1 Predictions Min       -47.7732
trainer/Q2 Predictions Mean      -15.5413
trainer/Q2 Predictions Std         5.89375
trainer/Q2 Predictions Max       -12.6925
trainer/Q2 Predictions Min       -47.4046
trainer/Q Targets Mean           -15.5402
trainer/Q Targets Std              5.80731
trainer/Q Targets Max             -5.3579
trainer/Q Targets Min            -44.8376
trainer/Log Pis Mean               0.41137
trainer/Log Pis Std                1.56853
trainer/Log Pis Max                5.957
trainer/Log Pis Min               -3.38815
trainer/Policy mu Mean            -0.0222309
trainer/Policy mu Std              0.839305
trainer/Policy mu Max              2.27925
trainer/Policy mu Min             -2.31688
trainer/Policy log std Mean       -1.08008
trainer/Policy log std Std         0.209341
trainer/Policy log std Max        -0.545617
trainer/Policy log std Min        -1.32746
trainer/Alpha                      0.142
trainer/Alpha Loss                -3.10049
exploration/num steps total     7400
exploration/num paths total       74
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.472244
exploration/Rewards Std            0.611751
exploration/Rewards Max           -0.0060798
exploration/Rewards Min           -5.97311
exploration/Returns Mean         -47.2244
exploration/Returns Std            4.45154
exploration/Returns Max          -42.7729
exploration/Returns Min          -51.6759
exploration/Actions Mean          -0.00937455
exploration/Actions Std            0.412856
exploration/Actions Max            0.973754
exploration/Actions Min           -0.970478
exploration/Num Paths              2
exploration/Average Returns      -47.2244
evaluation/num steps total     36000
evaluation/num paths total       360
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.207196
evaluation/Rewards Std             0.647038
evaluation/Rewards Max            -0.0336907
evaluation/Rewards Min            -7.03259
evaluation/Returns Mean          -20.7196
evaluation/Returns Std             6.93036
evaluation/Returns Max           -10.1169
evaluation/Returns Min           -31.4526
evaluation/Actions Mean            0.00143551
evaluation/Actions Std             0.178827
evaluation/Actions Max             0.98642
evaluation/Actions Min            -0.978402
evaluation/Num Paths              10
evaluation/Average Returns       -20.7196
time/data storing (s)              0.00118918
time/evaluation sampling (s)       0.250145
time/exploration sampling (s)      0.0670186
time/logging (s)                   0.00339187
time/saving (s)                    0.00232659
time/training (s)                  0.964661
time/epoch (s)                     1.28873
time/total (s)                    47.5279
Epoch                             35
-----------------------------  --------------
2019-04-22 20:11:46.285248 PDT | [sac-pointmass-multitask-1_2019_04_22_20_10_57_0000--s-0] Epoch 36 finished
-----------------------------  --------------
replay_buffer/size              7600
trainer/QF1 Loss                   3.6313
trainer/QF2 Loss                   3.45911
trainer/Policy Loss               14.4898
trainer/Q1 Predictions Mean      -14.7136
trainer/Q1 Predictions Std         4.06873
trainer/Q1 Predictions Max       -13.1123
trainer/Q1 Predictions Min       -43.46
trainer/Q2 Predictions Mean      -14.6716
trainer/Q2 Predictions Std         4.00462
trainer/Q2 Predictions Max       -13.0575
trainer/Q2 Predictions Min       -43.044
trainer/Q Targets Mean           -14.3707
trainer/Q Targets Std              4.36074
trainer/Q Targets Max             -0.421701
trainer/Q Targets Min            -42.0497
trainer/Log Pis Mean               0.336073
trainer/Log Pis Std                1.27725
trainer/Log Pis Max                4.07825
trainer/Log Pis Min               -3.23441
trainer/Policy mu Mean             0.0330713
trainer/Policy mu Std              0.709822
trainer/Policy mu Max              2.05775
trainer/Policy mu Min             -2.40323
trainer/Policy log std Mean       -1.15458
trainer/Policy log std Std         0.192157
trainer/Policy log std Max        -0.564561
trainer/Policy log std Min        -1.3822
trainer/Alpha                      0.134887
trainer/Alpha Loss                -3.33297
exploration/num steps total     7600
exploration/num paths total       76
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.452439
exploration/Rewards Std            0.684772
exploration/Rewards Max           -0.00796191
exploration/Rewards Min           -6.39834
exploration/Returns Mean         -45.2439
exploration/Returns Std            3.18829
exploration/Returns Max          -42.0556
exploration/Returns Min          -48.4322
exploration/Actions Mean          -0.038706
exploration/Actions Std            0.377206
exploration/Actions Max            0.885124
exploration/Actions Min           -0.994372
exploration/Num Paths              2
exploration/Average Returns      -45.2439
evaluation/num steps total     37000
evaluation/num paths total       370
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.134683
evaluation/Rewards Std             0.568256
evaluation/Rewards Max            -0.0318506
evaluation/Rewards Min            -6.34556
evaluation/Returns Mean          -13.4683
evaluation/Returns Std             6.46108
evaluation/Returns Max            -4.34307
evaluation/Returns Min           -23.4706
evaluation/Actions Mean            0.00340177
evaluation/Actions Std             0.165137
evaluation/Actions Max             0.986652
evaluation/Actions Min            -0.970871
evaluation/Num Paths              10
evaluation/Average Returns       -13.4683
time/data storing (s)              0.00121432
time/evaluation sampling (s)       0.249221
time/exploration sampling (s)      0.0671219
time/logging (s)                   0.00334109
time/saving (s)                    0.00229923
time/training (s)                  0.972492
time/epoch (s)                     1.29569
time/total (s)                    48.828
Epoch                             36
-----------------------------  --------------
2019-04-22 20:11:47.582144 PDT | [sac-pointmass-multitask-1_2019_04_22_20_10_57_0000--s-0] Epoch 37 finished
-----------------------------  --------------
replay_buffer/size              7800
trainer/QF1 Loss                   3.93327
trainer/QF2 Loss                   3.95288
trainer/Policy Loss               14.6711
trainer/Q1 Predictions Mean      -15.0344
trainer/Q1 Predictions Std         4.99879
trainer/Q1 Predictions Max       -12.9072
trainer/Q1 Predictions Min       -39.5829
trainer/Q2 Predictions Mean      -15.0425
trainer/Q2 Predictions Std         5.01909
trainer/Q2 Predictions Max       -12.9358
trainer/Q2 Predictions Min       -39.7283
trainer/Q Targets Mean           -15.0664
trainer/Q Targets Std              5.04796
trainer/Q Targets Max             -5.3579
trainer/Q Targets Min            -40.6544
trainer/Log Pis Mean               0.406763
trainer/Log Pis Std                1.30173
trainer/Log Pis Max                4.42026
trainer/Log Pis Min               -4.9969
trainer/Policy mu Mean             0.0121433
trainer/Policy mu Std              0.771131
trainer/Policy mu Max              2.33748
trainer/Policy mu Min             -2.29113
trainer/Policy log std Mean       -1.14742
trainer/Policy log std Std         0.203699
trainer/Policy log std Max        -0.601275
trainer/Policy log std Min        -1.37852
trainer/Alpha                      0.128086
trainer/Alpha Loss                -3.27376
exploration/num steps total     7800
exploration/num paths total       78
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.432633
exploration/Rewards Std            0.59498
exploration/Rewards Max           -0.00279572
exploration/Rewards Min           -5.38849
exploration/Returns Mean         -43.2633
exploration/Returns Std            4.28941
exploration/Returns Max          -38.9739
exploration/Returns Min          -47.5527
exploration/Actions Mean           0.0120682
exploration/Actions Std            0.376686
exploration/Actions Max            0.994596
exploration/Actions Min           -0.941211
exploration/Num Paths              2
exploration/Average Returns      -43.2633
evaluation/num steps total     38000
evaluation/num paths total       380
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.134399
evaluation/Rewards Std             0.50151
evaluation/Rewards Max            -0.0324791
evaluation/Rewards Min            -5.28583
evaluation/Returns Mean          -13.4399
evaluation/Returns Std             4.8735
evaluation/Returns Max            -5.36097
evaluation/Returns Min           -20.8276
evaluation/Actions Mean           -0.00549668
evaluation/Actions Std             0.150299
evaluation/Actions Max             0.982401
evaluation/Actions Min            -0.983783
evaluation/Num Paths              10
evaluation/Average Returns       -13.4399
time/data storing (s)              0.00120215
time/evaluation sampling (s)       0.247268
time/exploration sampling (s)      0.0676386
time/logging (s)                   0.00313208
time/saving (s)                    0.0023065
time/training (s)                  0.96956
time/epoch (s)                     1.29111
time/total (s)                    50.1235
Epoch                             37
-----------------------------  --------------
2019-04-22 20:11:48.865498 PDT | [sac-pointmass-multitask-1_2019_04_22_20_10_57_0000--s-0] Epoch 38 finished
-----------------------------  ---------------
replay_buffer/size              8000
trainer/QF1 Loss                   3.41466
trainer/QF2 Loss                   3.41752
trainer/Policy Loss               15.7777
trainer/Q1 Predictions Mean      -15.7452
trainer/Q1 Predictions Std         5.86504
trainer/Q1 Predictions Max       -13.1788
trainer/Q1 Predictions Min       -43.2595
trainer/Q2 Predictions Mean      -15.7572
trainer/Q2 Predictions Std         5.90265
trainer/Q2 Predictions Max       -13.2061
trainer/Q2 Predictions Min       -43.376
trainer/Q Targets Mean           -15.5022
trainer/Q Targets Std              6.30172
trainer/Q Targets Max             -0.455146
trainer/Q Targets Min            -43.0686
trainer/Log Pis Mean               0.829069
trainer/Log Pis Std                1.6521
trainer/Log Pis Max                6.62342
trainer/Log Pis Min               -2.53163
trainer/Policy mu Mean             0.106856
trainer/Policy mu Std              0.864292
trainer/Policy mu Max              2.35132
trainer/Policy mu Min             -2.39316
trainer/Policy log std Mean       -1.16378
trainer/Policy log std Std         0.229497
trainer/Policy log std Max        -0.605773
trainer/Policy log std Min        -1.42882
trainer/Alpha                      0.121701
trainer/Alpha Loss                -2.46592
exploration/num steps total     8000
exploration/num paths total       80
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.409579
exploration/Rewards Std            0.705893
exploration/Rewards Max           -0.00612631
exploration/Rewards Min           -6.78233
exploration/Returns Mean         -40.9579
exploration/Returns Std            6.41787
exploration/Returns Max          -34.5401
exploration/Returns Min          -47.3758
exploration/Actions Mean          -0.0328176
exploration/Actions Std            0.355701
exploration/Actions Max            0.990296
exploration/Actions Min           -0.986911
exploration/Num Paths              2
exploration/Average Returns      -40.9579
evaluation/num steps total     39000
evaluation/num paths total       390
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.167786
evaluation/Rewards Std             0.58377
evaluation/Rewards Max            -0.0102067
evaluation/Rewards Min            -5.30343
evaluation/Returns Mean          -16.7786
evaluation/Returns Std             4.35861
evaluation/Returns Max            -6.96688
evaluation/Returns Min           -22.6145
evaluation/Actions Mean           -0.000588967
evaluation/Actions Std             0.167941
evaluation/Actions Max             0.981503
evaluation/Actions Min            -0.984012
evaluation/Num Paths              10
evaluation/Average Returns       -16.7786
time/data storing (s)              0.00122247
time/evaluation sampling (s)       0.25573
time/exploration sampling (s)      0.0669599
time/logging (s)                   0.00342095
time/saving (s)                    0.00228717
time/training (s)                  0.94848
time/epoch (s)                     1.2781
time/total (s)                    51.406
Epoch                             38
-----------------------------  ---------------
2019-04-22 20:11:50.184863 PDT | [sac-pointmass-multitask-1_2019_04_22_20_10_57_0000--s-0] Epoch 39 finished
-----------------------------  --------------
replay_buffer/size              8200
trainer/QF1 Loss                   6.71932
trainer/QF2 Loss                   6.72945
trainer/Policy Loss               14.5631
trainer/Q1 Predictions Mean      -14.66
trainer/Q1 Predictions Std         4.24686
trainer/Q1 Predictions Max       -13.086
trainer/Q1 Predictions Min       -41.9005
trainer/Q2 Predictions Mean      -14.6984
trainer/Q2 Predictions Std         4.28433
trainer/Q2 Predictions Max       -13.0786
trainer/Q2 Predictions Min       -42.1432
trainer/Q Targets Mean           -14.3363
trainer/Q Targets Std              5.17098
trainer/Q Targets Max             -0.266988
trainer/Q Targets Min            -43.2974
trainer/Log Pis Mean               0.334845
trainer/Log Pis Std                1.51816
trainer/Log Pis Max                5.03388
trainer/Log Pis Min               -4.78446
trainer/Policy mu Mean             0.00285018
trainer/Policy mu Std              0.745582
trainer/Policy mu Max              2.37077
trainer/Policy mu Min             -2.27359
trainer/Policy log std Mean       -1.22066
trainer/Policy log std Std         0.213943
trainer/Policy log std Max        -0.640102
trainer/Policy log std Min        -1.46933
trainer/Alpha                      0.115678
trainer/Alpha Loss                -3.59121
exploration/num steps total     8200
exploration/num paths total       82
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.456654
exploration/Rewards Std            0.690708
exploration/Rewards Max           -0.0309583
exploration/Rewards Min           -5.589
exploration/Returns Mean         -45.6654
exploration/Returns Std            1.56586
exploration/Returns Max          -44.0996
exploration/Returns Min          -47.2313
exploration/Actions Mean           0.0378049
exploration/Actions Std            0.357307
exploration/Actions Max            0.988293
exploration/Actions Min           -0.835929
exploration/Num Paths              2
exploration/Average Returns      -45.6654
evaluation/num steps total     40000
evaluation/num paths total       400
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.177673
evaluation/Rewards Std             0.507987
evaluation/Rewards Max            -0.0543654
evaluation/Rewards Min            -5.34142
evaluation/Returns Mean          -17.7673
evaluation/Returns Std             4.56233
evaluation/Returns Max           -10.021
evaluation/Returns Min           -25.4773
evaluation/Actions Mean           -0.00353065
evaluation/Actions Std             0.160591
evaluation/Actions Max             0.990526
evaluation/Actions Min            -0.981436
evaluation/Num Paths              10
evaluation/Average Returns       -17.7673
time/data storing (s)              0.00121842
time/evaluation sampling (s)       0.251668
time/exploration sampling (s)      0.0686621
time/logging (s)                   0.00335391
time/saving (s)                    0.00229539
time/training (s)                  0.986622
time/epoch (s)                     1.31382
time/total (s)                    52.7241
Epoch                             39
-----------------------------  --------------
2019-04-22 20:11:51.486628 PDT | [sac-pointmass-multitask-1_2019_04_22_20_10_57_0000--s-0] Epoch 40 finished
-----------------------------  --------------
replay_buffer/size              8400
trainer/QF1 Loss                   1.8392
trainer/QF2 Loss                   1.83098
trainer/Policy Loss               15.1122
trainer/Q1 Predictions Mean      -14.9725
trainer/Q1 Predictions Std         4.22938
trainer/Q1 Predictions Max       -13.3701
trainer/Q1 Predictions Min       -43.5335
trainer/Q2 Predictions Mean      -15.0033
trainer/Q2 Predictions Std         4.24169
trainer/Q2 Predictions Max       -13.3608
trainer/Q2 Predictions Min       -43.4689
trainer/Q Targets Mean           -14.8114
trainer/Q Targets Std              4.5314
trainer/Q Targets Max             -0.111863
trainer/Q Targets Min            -45.0573
trainer/Log Pis Mean               0.635972
trainer/Log Pis Std                1.3453
trainer/Log Pis Max                5.44906
trainer/Log Pis Min               -6.70984
trainer/Policy mu Mean            -0.0463895
trainer/Policy mu Std              0.727144
trainer/Policy mu Max              2.28876
trainer/Policy mu Min             -2.51608
trainer/Policy log std Mean       -1.24041
trainer/Policy log std Std         0.221824
trainer/Policy log std Max        -0.519033
trainer/Policy log std Min        -1.50694
trainer/Alpha                      0.109964
trainer/Alpha Loss                -3.01089
exploration/num steps total     8400
exploration/num paths total       84
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.373075
exploration/Rewards Std            0.450124
exploration/Rewards Max           -0.0235543
exploration/Rewards Min           -4.80167
exploration/Returns Mean         -37.3075
exploration/Returns Std            4.81888
exploration/Returns Max          -32.4886
exploration/Returns Min          -42.1264
exploration/Actions Mean          -0.00124949
exploration/Actions Std            0.337181
exploration/Actions Max            0.991153
exploration/Actions Min           -0.950894
exploration/Num Paths              2
exploration/Average Returns      -37.3075
evaluation/num steps total     41000
evaluation/num paths total       410
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.195532
evaluation/Rewards Std             0.537686
evaluation/Rewards Max            -0.0538074
evaluation/Rewards Min            -6.63768
evaluation/Returns Mean          -19.5532
evaluation/Returns Std             5.87005
evaluation/Returns Max           -11.5096
evaluation/Returns Min           -30.0765
evaluation/Actions Mean            0.00791196
evaluation/Actions Std             0.159757
evaluation/Actions Max             0.982954
evaluation/Actions Min            -0.981571
evaluation/Num Paths              10
evaluation/Average Returns       -19.5532
time/data storing (s)              0.00119849
time/evaluation sampling (s)       0.2479
time/exploration sampling (s)      0.0658043
time/logging (s)                   0.00333978
time/saving (s)                    0.00226413
time/training (s)                  0.975965
time/epoch (s)                     1.29647
time/total (s)                    54.0246
Epoch                             40
-----------------------------  --------------
2019-04-22 20:11:52.783636 PDT | [sac-pointmass-multitask-1_2019_04_22_20_10_57_0000--s-0] Epoch 41 finished
-----------------------------  --------------
replay_buffer/size              8600
trainer/QF1 Loss                   3.51373
trainer/QF2 Loss                   3.53201
trainer/Policy Loss               14.8795
trainer/Q1 Predictions Mean      -14.4903
trainer/Q1 Predictions Std         3.91184
trainer/Q1 Predictions Max       -13.2467
trainer/Q1 Predictions Min       -45.042
trainer/Q2 Predictions Mean      -14.5812
trainer/Q2 Predictions Std         3.89905
trainer/Q2 Predictions Max       -13.3298
trainer/Q2 Predictions Min       -45.027
trainer/Q Targets Mean           -14.3021
trainer/Q Targets Std              4.43702
trainer/Q Targets Max             -0.24969
trainer/Q Targets Min            -46.2305
trainer/Log Pis Mean               0.66479
trainer/Log Pis Std                1.23426
trainer/Log Pis Max                7.14799
trainer/Log Pis Min               -1.85971
trainer/Policy mu Mean             0.0433472
trainer/Policy mu Std              0.672051
trainer/Policy mu Max              2.43897
trainer/Policy mu Min             -2.33414
trainer/Policy log std Mean       -1.35015
trainer/Policy log std Std         0.214036
trainer/Policy log std Max        -0.609276
trainer/Policy log std Min        -1.57651
trainer/Alpha                      0.104602
trainer/Alpha Loss                -3.01403
exploration/num steps total     8600
exploration/num paths total       86
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.345812
exploration/Rewards Std            0.411007
exploration/Rewards Max           -0.0152409
exploration/Rewards Min           -3.36736
exploration/Returns Mean         -34.5812
exploration/Returns Std            0.457102
exploration/Returns Max          -34.1241
exploration/Returns Min          -35.0383
exploration/Actions Mean          -0.00121428
exploration/Actions Std            0.330566
exploration/Actions Max            0.987794
exploration/Actions Min           -0.993989
exploration/Num Paths              2
exploration/Average Returns      -34.5812
evaluation/num steps total     42000
evaluation/num paths total       420
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.141679
evaluation/Rewards Std             0.597596
evaluation/Rewards Max            -0.0104798
evaluation/Rewards Min            -6.86833
evaluation/Returns Mean          -14.1679
evaluation/Returns Std             6.02079
evaluation/Returns Max            -6.66298
evaluation/Returns Min           -24.8658
evaluation/Actions Mean           -0.00108973
evaluation/Actions Std             0.169302
evaluation/Actions Max             0.992852
evaluation/Actions Min            -0.983942
evaluation/Num Paths              10
evaluation/Average Returns       -14.1679
time/data storing (s)              0.0012063
time/evaluation sampling (s)       0.249124
time/exploration sampling (s)      0.0668981
time/logging (s)                   0.00341069
time/saving (s)                    0.00252736
time/training (s)                  0.968596
time/epoch (s)                     1.29176
time/total (s)                    55.3204
Epoch                             41
-----------------------------  --------------
2019-04-22 20:11:54.086240 PDT | [sac-pointmass-multitask-1_2019_04_22_20_10_57_0000--s-0] Epoch 42 finished
-----------------------------  ---------------
replay_buffer/size              8800
trainer/QF1 Loss                   1.7414
trainer/QF2 Loss                   1.74349
trainer/Policy Loss               14.8079
trainer/Q1 Predictions Mean      -14.5087
trainer/Q1 Predictions Std         3.20145
trainer/Q1 Predictions Max       -13.2754
trainer/Q1 Predictions Min       -32.6525
trainer/Q2 Predictions Mean      -14.5464
trainer/Q2 Predictions Std         3.19851
trainer/Q2 Predictions Max       -13.3322
trainer/Q2 Predictions Min       -32.7667
trainer/Q Targets Mean           -14.4435
trainer/Q Targets Std              3.45186
trainer/Q Targets Max             -0.421701
trainer/Q Targets Min            -33.2188
trainer/Log Pis Mean               0.856795
trainer/Log Pis Std                1.30977
trainer/Log Pis Max                4.99861
trainer/Log Pis Min               -2.78341
trainer/Policy mu Mean            -0.0463937
trainer/Policy mu Std              0.683326
trainer/Policy mu Max              2.03913
trainer/Policy mu Min             -2.42965
trainer/Policy log std Mean       -1.38572
trainer/Policy log std Std         0.225128
trainer/Policy log std Max        -0.556302
trainer/Policy log std Min        -1.63941
trainer/Alpha                      0.0996581
trainer/Alpha Loss                -2.63597
exploration/num steps total     8800
exploration/num paths total       88
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.378731
exploration/Rewards Std            0.526212
exploration/Rewards Max           -0.0262371
exploration/Rewards Min           -4.67037
exploration/Returns Mean         -37.8731
exploration/Returns Std            3.15262
exploration/Returns Max          -34.7205
exploration/Returns Min          -41.0257
exploration/Actions Mean           0.000904766
exploration/Actions Std            0.340251
exploration/Actions Max            0.987361
exploration/Actions Min           -0.984297
exploration/Num Paths              2
exploration/Average Returns      -37.8731
evaluation/num steps total     43000
evaluation/num paths total       430
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.17265
evaluation/Rewards Std             0.51285
evaluation/Rewards Max            -0.0198133
evaluation/Rewards Min            -5.09769
evaluation/Returns Mean          -17.265
evaluation/Returns Std             4.30915
evaluation/Returns Max            -8.52793
evaluation/Returns Min           -23.9552
evaluation/Actions Mean            0.0148295
evaluation/Actions Std             0.161117
evaluation/Actions Max             0.98617
evaluation/Actions Min            -0.982016
evaluation/Num Paths              10
evaluation/Average Returns       -17.265
time/data storing (s)              0.00125287
time/evaluation sampling (s)       0.248519
time/exploration sampling (s)      0.066493
time/logging (s)                   0.00334166
time/saving (s)                    0.00226349
time/training (s)                  0.975272
time/epoch (s)                     1.29714
time/total (s)                    56.6217
Epoch                             42
-----------------------------  ---------------
2019-04-22 20:11:55.392653 PDT | [sac-pointmass-multitask-1_2019_04_22_20_10_57_0000--s-0] Epoch 43 finished
-----------------------------  --------------
replay_buffer/size              9000
trainer/QF1 Loss                   1.8797
trainer/QF2 Loss                   1.87221
trainer/Policy Loss               15.2254
trainer/Q1 Predictions Mean      -14.978
trainer/Q1 Predictions Std         3.85313
trainer/Q1 Predictions Max       -13.4114
trainer/Q1 Predictions Min       -39.7013
trainer/Q2 Predictions Mean      -15.032
trainer/Q2 Predictions Std         3.8706
trainer/Q2 Predictions Max       -13.4527
trainer/Q2 Predictions Min       -40.0204
trainer/Q Targets Mean           -14.8402
trainer/Q Targets Std              4.21416
trainer/Q Targets Max             -1.18473
trainer/Q Targets Min            -41.0015
trainer/Log Pis Mean               0.780892
trainer/Log Pis Std                1.24368
trainer/Log Pis Max                5.58448
trainer/Log Pis Min               -2.46897
trainer/Policy mu Mean             0.0383419
trainer/Policy mu Std              0.761693
trainer/Policy mu Max              2.52801
trainer/Policy mu Min             -2.50999
trainer/Policy log std Mean       -1.34983
trainer/Policy log std Std         0.23008
trainer/Policy log std Max        -0.615763
trainer/Policy log std Min        -1.58576
trainer/Alpha                      0.0949396
trainer/Alpha Loss                -2.87011
exploration/num steps total     9000
exploration/num paths total       90
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.311459
exploration/Rewards Std            0.275319
exploration/Rewards Max           -0.0115825
exploration/Rewards Min           -3.15425
exploration/Returns Mean         -31.1459
exploration/Returns Std            1.83924
exploration/Returns Max          -29.3066
exploration/Returns Min          -32.9851
exploration/Actions Mean           0.0124372
exploration/Actions Std            0.326997
exploration/Actions Max            0.984059
exploration/Actions Min           -0.737506
exploration/Num Paths              2
exploration/Average Returns      -31.1459
evaluation/num steps total     44000
evaluation/num paths total       440
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.149528
evaluation/Rewards Std             0.376734
evaluation/Rewards Max            -0.0422516
evaluation/Rewards Min            -4.33668
evaluation/Returns Mean          -14.9528
evaluation/Returns Std             3.09151
evaluation/Returns Max           -10.5214
evaluation/Returns Min           -20.6712
evaluation/Actions Mean           -0.00282925
evaluation/Actions Std             0.148804
evaluation/Actions Max             0.988958
evaluation/Actions Min            -0.975748
evaluation/Num Paths              10
evaluation/Average Returns       -14.9528
time/data storing (s)              0.00124767
time/evaluation sampling (s)       0.245707
time/exploration sampling (s)      0.0656979
time/logging (s)                   0.00335684
time/saving (s)                    0.00213092
time/training (s)                  0.983025
time/epoch (s)                     1.30117
time/total (s)                    57.9269
Epoch                             43
-----------------------------  --------------
2019-04-22 20:11:56.713601 PDT | [sac-pointmass-multitask-1_2019_04_22_20_10_57_0000--s-0] Epoch 44 finished
-----------------------------  --------------
replay_buffer/size              9200
trainer/QF1 Loss                   1.88203
trainer/QF2 Loss                   1.91883
trainer/Policy Loss               15.8021
trainer/Q1 Predictions Mean      -15.6193
trainer/Q1 Predictions Std         5.69826
trainer/Q1 Predictions Max       -13.3029
trainer/Q1 Predictions Min       -47.7297
trainer/Q2 Predictions Mean      -15.6352
trainer/Q2 Predictions Std         5.6577
trainer/Q2 Predictions Max       -13.2959
trainer/Q2 Predictions Min       -47.4804
trainer/Q Targets Mean           -15.6406
trainer/Q Targets Std              6.10647
trainer/Q Targets Max             -0.665513
trainer/Q Targets Min            -47.1646
trainer/Log Pis Mean               0.976154
trainer/Log Pis Std                1.41929
trainer/Log Pis Max                6.55297
trainer/Log Pis Min               -2.11262
trainer/Policy mu Mean             0.0782763
trainer/Policy mu Std              0.844073
trainer/Policy mu Max              2.67749
trainer/Policy mu Min             -2.46818
trainer/Policy log std Mean       -1.35781
trainer/Policy log std Std         0.280936
trainer/Policy log std Max        -0.623656
trainer/Policy log std Min        -1.6873
trainer/Alpha                      0.0903472
trainer/Alpha Loss                -2.46118
exploration/num steps total     9200
exploration/num paths total       92
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.259808
exploration/Rewards Std            0.144855
exploration/Rewards Max           -0.0115483
exploration/Rewards Min           -1.2166
exploration/Returns Mean         -25.9808
exploration/Returns Std            0.954246
exploration/Returns Max          -25.0265
exploration/Returns Min          -26.935
exploration/Actions Mean           0.00453217
exploration/Actions Std            0.292718
exploration/Actions Max            0.970296
exploration/Actions Min           -0.797651
exploration/Num Paths              2
exploration/Average Returns      -25.9808
evaluation/num steps total     45000
evaluation/num paths total       450
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.195101
evaluation/Rewards Std             0.623623
evaluation/Rewards Max            -0.0306691
evaluation/Rewards Min            -5.8829
evaluation/Returns Mean          -19.5101
evaluation/Returns Std             5.37048
evaluation/Returns Max           -11.2648
evaluation/Returns Min           -24.8918
evaluation/Actions Mean            0.00189909
evaluation/Actions Std             0.178713
evaluation/Actions Max             0.991172
evaluation/Actions Min            -0.991092
evaluation/Num Paths              10
evaluation/Average Returns       -19.5101
time/data storing (s)              0.00122727
time/evaluation sampling (s)       0.251566
time/exploration sampling (s)      0.0668182
time/logging (s)                   0.00344617
time/saving (s)                    0.00182482
time/training (s)                  0.990692
time/epoch (s)                     1.31557
time/total (s)                    59.2467
Epoch                             44
-----------------------------  --------------
2019-04-22 20:11:58.015852 PDT | [sac-pointmass-multitask-1_2019_04_22_20_10_57_0000--s-0] Epoch 45 finished
-----------------------------  ---------------
replay_buffer/size              9400
trainer/QF1 Loss                   0.05072
trainer/QF2 Loss                   0.0428246
trainer/Policy Loss               15.1173
trainer/Q1 Predictions Mean      -14.726
trainer/Q1 Predictions Std         3.38109
trainer/Q1 Predictions Max       -13.3281
trainer/Q1 Predictions Min       -34.6167
trainer/Q2 Predictions Mean      -14.7305
trainer/Q2 Predictions Std         3.38373
trainer/Q2 Predictions Max       -13.2985
trainer/Q2 Predictions Min       -34.431
trainer/Q Targets Mean           -14.8269
trainer/Q Targets Std              3.40479
trainer/Q Targets Max            -13.2971
trainer/Q Targets Min            -34.4522
trainer/Log Pis Mean               0.83563
trainer/Log Pis Std                1.45268
trainer/Log Pis Max                6.71691
trainer/Log Pis Min               -3.8483
trainer/Policy mu Mean            -0.0513409
trainer/Policy mu Std              0.725013
trainer/Policy mu Max              2.35706
trainer/Policy mu Min             -2.60277
trainer/Policy log std Mean       -1.42979
trainer/Policy log std Std         0.250846
trainer/Policy log std Max        -0.679289
trainer/Policy log std Min        -1.70036
trainer/Alpha                      0.0859182
trainer/Alpha Loss                -2.8575
exploration/num steps total     9400
exploration/num paths total       94
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.383623
exploration/Rewards Std            0.611796
exploration/Rewards Max           -0.00649253
exploration/Rewards Min           -5.01041
exploration/Returns Mean         -38.3623
exploration/Returns Std            1.57152
exploration/Returns Max          -36.7908
exploration/Returns Min          -39.9338
exploration/Actions Mean          -0.00439397
exploration/Actions Std            0.307413
exploration/Actions Max            0.995599
exploration/Actions Min           -0.990859
exploration/Num Paths              2
exploration/Average Returns      -38.3623
evaluation/num steps total     46000
evaluation/num paths total       460
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.193625
evaluation/Rewards Std             0.466141
evaluation/Rewards Max            -0.0713984
evaluation/Rewards Min            -5.29981
evaluation/Returns Mean          -19.3625
evaluation/Returns Std             5.1561
evaluation/Returns Max           -12.4648
evaluation/Returns Min           -28.7688
evaluation/Actions Mean           -0.000308453
evaluation/Actions Std             0.15726
evaluation/Actions Max             0.986555
evaluation/Actions Min            -0.988459
evaluation/Num Paths              10
evaluation/Average Returns       -19.3625
time/data storing (s)              0.00128108
time/evaluation sampling (s)       0.247054
time/exploration sampling (s)      0.0670448
time/logging (s)                   0.00334586
time/saving (s)                    0.00228458
time/training (s)                  0.975477
time/epoch (s)                     1.29649
time/total (s)                    60.5473
Epoch                             45
-----------------------------  ---------------
2019-04-22 20:11:59.311556 PDT | [sac-pointmass-multitask-1_2019_04_22_20_10_57_0000--s-0] Epoch 46 finished
-----------------------------  --------------
replay_buffer/size              9600
trainer/QF1 Loss                   1.72065
trainer/QF2 Loss                   1.71507
trainer/Policy Loss               15.5738
trainer/Q1 Predictions Mean      -14.8528
trainer/Q1 Predictions Std         3.88056
trainer/Q1 Predictions Max       -13.2962
trainer/Q1 Predictions Min       -36.3117
trainer/Q2 Predictions Mean      -14.8108
trainer/Q2 Predictions Std         3.90957
trainer/Q2 Predictions Max       -13.1964
trainer/Q2 Predictions Min       -35.7796
trainer/Q Targets Mean           -14.8582
trainer/Q Targets Std              4.19035
trainer/Q Targets Max             -0.587949
trainer/Q Targets Min            -36.5398
trainer/Log Pis Mean               1.05004
trainer/Log Pis Std                1.36578
trainer/Log Pis Max                6.28375
trainer/Log Pis Min               -1.89197
trainer/Policy mu Mean             0.00982344
trainer/Policy mu Std              0.754228
trainer/Policy mu Max              2.6658
trainer/Policy mu Min             -2.49228
trainer/Policy log std Mean       -1.43101
trainer/Policy log std Std         0.27715
trainer/Policy log std Max        -0.633646
trainer/Policy log std Min        -1.7244
trainer/Alpha                      0.0818205
trainer/Alpha Loss                -2.37773
exploration/num steps total     9600
exploration/num paths total       96
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.350359
exploration/Rewards Std            0.518503
exploration/Rewards Max           -0.0278303
exploration/Rewards Min           -4.7177
exploration/Returns Mean         -35.0359
exploration/Returns Std            3.48248
exploration/Returns Max          -31.5534
exploration/Returns Min          -38.5184
exploration/Actions Mean          -0.0108422
exploration/Actions Std            0.321846
exploration/Actions Max            0.992143
exploration/Actions Min           -0.993155
exploration/Num Paths              2
exploration/Average Returns      -35.0359
evaluation/num steps total     47000
evaluation/num paths total       470
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.159072
evaluation/Rewards Std             0.468209
evaluation/Rewards Max            -0.0763372
evaluation/Rewards Min            -5.74945
evaluation/Returns Mean          -15.9072
evaluation/Returns Std             5.40262
evaluation/Returns Max            -8.71728
evaluation/Returns Min           -26.5367
evaluation/Actions Mean            0.00838201
evaluation/Actions Std             0.145571
evaluation/Actions Max             0.993705
evaluation/Actions Min            -0.985132
evaluation/Num Paths              10
evaluation/Average Returns       -15.9072
time/data storing (s)              0.00121695
time/evaluation sampling (s)       0.244605
time/exploration sampling (s)      0.0660716
time/logging (s)                   0.00336213
time/saving (s)                    0.00183077
time/training (s)                  0.97323
time/epoch (s)                     1.29032
time/total (s)                    61.8417
Epoch                             46
-----------------------------  --------------
2019-04-22 20:12:00.597206 PDT | [sac-pointmass-multitask-1_2019_04_22_20_10_57_0000--s-0] Epoch 47 finished
-----------------------------  --------------
replay_buffer/size              9800
trainer/QF1 Loss                   1.84651
trainer/QF2 Loss                   1.84358
trainer/Policy Loss               15.4864
trainer/Q1 Predictions Mean      -14.8596
trainer/Q1 Predictions Std         3.55337
trainer/Q1 Predictions Max       -13.3531
trainer/Q1 Predictions Min       -33.7221
trainer/Q2 Predictions Mean      -14.8585
trainer/Q2 Predictions Std         3.58348
trainer/Q2 Predictions Max       -13.3317
trainer/Q2 Predictions Min       -33.6666
trainer/Q Targets Mean           -14.7708
trainer/Q Targets Std              3.90035
trainer/Q Targets Max             -0.130089
trainer/Q Targets Min            -33.8318
trainer/Log Pis Mean               1.15094
trainer/Log Pis Std                1.45627
trainer/Log Pis Max                6.90446
trainer/Log Pis Min               -3.31854
trainer/Policy mu Mean            -0.0130446
trainer/Policy mu Std              0.771139
trainer/Policy mu Max              2.47862
trainer/Policy mu Min             -2.71888
trainer/Policy log std Mean       -1.48586
trainer/Policy log std Std         0.273348
trainer/Policy log std Max        -0.646778
trainer/Policy log std Min        -1.77107
trainer/Alpha                      0.0781073
trainer/Alpha Loss                -2.16463
exploration/num steps total     9800
exploration/num paths total       98
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.26769
exploration/Rewards Std            0.158515
exploration/Rewards Max           -0.0164022
exploration/Rewards Min           -1.53747
exploration/Returns Mean         -26.769
exploration/Returns Std            0.663062
exploration/Returns Max          -26.1059
exploration/Returns Min          -27.432
exploration/Actions Mean          -0.00813936
exploration/Actions Std            0.266826
exploration/Actions Max            0.670042
exploration/Actions Min           -0.954998
exploration/Num Paths              2
exploration/Average Returns      -26.769
evaluation/num steps total     48000
evaluation/num paths total       480
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.208295
evaluation/Rewards Std             0.531985
evaluation/Rewards Max            -0.0750691
evaluation/Rewards Min            -6.92871
evaluation/Returns Mean          -20.8295
evaluation/Returns Std             6.26637
evaluation/Returns Max           -12.5981
evaluation/Returns Min           -33.0637
evaluation/Actions Mean           -0.00516974
evaluation/Actions Std             0.165061
evaluation/Actions Max             0.974749
evaluation/Actions Min            -0.992373
evaluation/Num Paths              10
evaluation/Average Returns       -20.8295
time/data storing (s)              0.00126045
time/evaluation sampling (s)       0.249095
time/exploration sampling (s)      0.067633
time/logging (s)                   0.00355391
time/saving (s)                    0.00230116
time/training (s)                  0.956287
time/epoch (s)                     1.28013
time/total (s)                    63.1262
Epoch                             47
-----------------------------  --------------
2019-04-22 20:12:01.906766 PDT | [sac-pointmass-multitask-1_2019_04_22_20_10_57_0000--s-0] Epoch 48 finished
-----------------------------  --------------
replay_buffer/size             10000
trainer/QF1 Loss                   1.77135
trainer/QF2 Loss                   1.79154
trainer/Policy Loss               15.2274
trainer/Q1 Predictions Mean      -14.9552
trainer/Q1 Predictions Std         4.07833
trainer/Q1 Predictions Max       -13.2409
trainer/Q1 Predictions Min       -33.3928
trainer/Q2 Predictions Mean      -14.9594
trainer/Q2 Predictions Std         4.09791
trainer/Q2 Predictions Max       -13.2329
trainer/Q2 Predictions Min       -33.3328
trainer/Q Targets Mean           -14.8911
trainer/Q Targets Std              4.25434
trainer/Q Targets Max             -0.739387
trainer/Q Targets Min            -33.6492
trainer/Log Pis Mean               0.94498
trainer/Log Pis Std                1.33145
trainer/Log Pis Max                5.68395
trainer/Log Pis Min               -5.7744
trainer/Policy mu Mean             0.0271918
trainer/Policy mu Std              0.729695
trainer/Policy mu Max              2.48918
trainer/Policy mu Min             -2.31691
trainer/Policy log std Mean       -1.51865
trainer/Policy log std Std         0.272561
trainer/Policy log std Max        -0.608303
trainer/Policy log std Min        -1.74962
trainer/Alpha                      0.074607
trainer/Alpha Loss                -2.7381
exploration/num steps total    10000
exploration/num paths total      100
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.319615
exploration/Rewards Std            0.458375
exploration/Rewards Max           -0.0209497
exploration/Rewards Min           -3.91957
exploration/Returns Mean         -31.9615
exploration/Returns Std            1.85114
exploration/Returns Max          -30.1104
exploration/Returns Min          -33.8126
exploration/Actions Mean           0.0315961
exploration/Actions Std            0.294754
exploration/Actions Max            0.990289
exploration/Actions Min           -0.656788
exploration/Num Paths              2
exploration/Average Returns      -31.9615
evaluation/num steps total     49000
evaluation/num paths total       490
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.131855
evaluation/Rewards Std             0.427836
evaluation/Rewards Max            -0.0165384
evaluation/Rewards Min            -4.73406
evaluation/Returns Mean          -13.1855
evaluation/Returns Std             4.74232
evaluation/Returns Max            -6.88953
evaluation/Returns Min           -19.7396
evaluation/Actions Mean            0.00526408
evaluation/Actions Std             0.144934
evaluation/Actions Max             0.987823
evaluation/Actions Min            -0.985279
evaluation/Num Paths              10
evaluation/Average Returns       -13.1855
time/data storing (s)              0.00120971
time/evaluation sampling (s)       0.251863
time/exploration sampling (s)      0.0662949
time/logging (s)                   0.00338059
time/saving (s)                    0.0023135
time/training (s)                  0.978934
time/epoch (s)                     1.304
time/total (s)                    64.4343
Epoch                             48
-----------------------------  --------------
2019-04-22 20:12:03.207768 PDT | [sac-pointmass-multitask-1_2019_04_22_20_10_57_0000--s-0] Epoch 49 finished
-----------------------------  --------------
replay_buffer/size             10200
trainer/QF1 Loss                   0.146542
trainer/QF2 Loss                   0.123468
trainer/Policy Loss               15.0964
trainer/Q1 Predictions Mean      -14.5947
trainer/Q1 Predictions Std         4.33605
trainer/Q1 Predictions Max       -13.2798
trainer/Q1 Predictions Min       -48.7415
trainer/Q2 Predictions Mean      -14.5524
trainer/Q2 Predictions Std         4.28714
trainer/Q2 Predictions Max       -13.2932
trainer/Q2 Predictions Min       -48.2473
trainer/Q Targets Mean           -14.5662
trainer/Q Targets Std              4.0491
trainer/Q Targets Max            -13.2348
trainer/Q Targets Min            -45.2424
trainer/Log Pis Mean               0.885576
trainer/Log Pis Std                1.27433
trainer/Log Pis Max                6.42759
trainer/Log Pis Min               -3.01785
trainer/Policy mu Mean             0.0636984
trainer/Policy mu Std              0.671175
trainer/Policy mu Max              2.63454
trainer/Policy mu Min             -2.76837
trainer/Policy log std Mean       -1.58889
trainer/Policy log std Std         0.2575
trainer/Policy log std Max        -0.597253
trainer/Policy log std Min        -1.84161
trainer/Alpha                      0.0712783
trainer/Alpha Loss                -2.94311
exploration/num steps total    10200
exploration/num paths total      102
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.327158
exploration/Rewards Std            0.56644
exploration/Rewards Max           -0.0217293
exploration/Rewards Min           -4.72595
exploration/Returns Mean         -32.7158
exploration/Returns Std            0.0373746
exploration/Returns Max          -32.6784
exploration/Returns Min          -32.7531
exploration/Actions Mean           0.0119973
exploration/Actions Std            0.294211
exploration/Actions Max            0.998244
exploration/Actions Min           -0.94468
exploration/Num Paths              2
exploration/Average Returns      -32.7158
evaluation/num steps total     50000
evaluation/num paths total       500
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.113466
evaluation/Rewards Std             0.513265
evaluation/Rewards Max            -0.00539976
evaluation/Rewards Min            -4.99773
evaluation/Returns Mean          -11.3466
evaluation/Returns Std             3.38995
evaluation/Returns Max            -4.11655
evaluation/Returns Min           -15.904
evaluation/Actions Mean            0.00803624
evaluation/Actions Std             0.16662
evaluation/Actions Max             0.988388
evaluation/Actions Min            -0.989832
evaluation/Num Paths              10
evaluation/Average Returns       -11.3466
time/data storing (s)              0.00117942
time/evaluation sampling (s)       0.247675
time/exploration sampling (s)      0.0656758
time/logging (s)                   0.00335569
time/saving (s)                    0.00229003
time/training (s)                  0.975739
time/epoch (s)                     1.29591
time/total (s)                    65.7339
Epoch                             49
-----------------------------  --------------
2019-04-22 20:12:04.510021 PDT | [sac-pointmass-multitask-1_2019_04_22_20_10_57_0000--s-0] Epoch 50 finished
-----------------------------  --------------
replay_buffer/size             10400
trainer/QF1 Loss                   0.271743
trainer/QF2 Loss                   0.235136
trainer/Policy Loss               15.1684
trainer/Q1 Predictions Mean      -14.4701
trainer/Q1 Predictions Std         4.37988
trainer/Q1 Predictions Max       -12.9919
trainer/Q1 Predictions Min       -48.5508
trainer/Q2 Predictions Mean      -14.4701
trainer/Q2 Predictions Std         4.3585
trainer/Q2 Predictions Max       -13.0536
trainer/Q2 Predictions Min       -48.1512
trainer/Q Targets Mean           -14.7564
trainer/Q Targets Std              4.20214
trainer/Q Targets Max            -13.2236
trainer/Q Targets Min            -45.3281
trainer/Log Pis Mean               1.19407
trainer/Log Pis Std                1.26015
trainer/Log Pis Max                7.4527
trainer/Log Pis Min               -1.62025
trainer/Policy mu Mean             0.00933525
trainer/Policy mu Std              0.719549
trainer/Policy mu Max              2.56791
trainer/Policy mu Min             -2.67558
trainer/Policy log std Mean       -1.62401
trainer/Policy log std Std         0.282309
trainer/Policy log std Max        -0.743383
trainer/Policy log std Min        -1.89402
trainer/Alpha                      0.0681802
trainer/Alpha Loss                -2.16421
exploration/num steps total    10400
exploration/num paths total      104
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.370831
exploration/Rewards Std            0.712973
exploration/Rewards Max           -0.00838586
exploration/Rewards Min           -5.76148
exploration/Returns Mean         -37.0831
exploration/Returns Std            2.75404
exploration/Returns Max          -34.3291
exploration/Returns Min          -39.8371
exploration/Actions Mean           0.0170142
exploration/Actions Std            0.306614
exploration/Actions Max            0.983422
exploration/Actions Min           -0.99114
exploration/Num Paths              2
exploration/Average Returns      -37.0831
evaluation/num steps total     51000
evaluation/num paths total       510
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.184533
evaluation/Rewards Std             0.545137
evaluation/Rewards Max            -0.0420986
evaluation/Rewards Min            -5.49696
evaluation/Returns Mean          -18.4533
evaluation/Returns Std             5.2825
evaluation/Returns Max            -9.72714
evaluation/Returns Min           -25.1125
evaluation/Actions Mean           -0.0105182
evaluation/Actions Std             0.164733
evaluation/Actions Max             0.987628
evaluation/Actions Min            -0.991527
evaluation/Num Paths              10
evaluation/Average Returns       -18.4533
time/data storing (s)              0.00119771
time/evaluation sampling (s)       0.250929
time/exploration sampling (s)      0.066749
time/logging (s)                   0.00335827
time/saving (s)                    0.00228341
time/training (s)                  0.972325
time/epoch (s)                     1.29684
time/total (s)                    67.0348
Epoch                             50
-----------------------------  --------------
2019-04-22 20:12:05.817649 PDT | [sac-pointmass-multitask-1_2019_04_22_20_10_57_0000--s-0] Epoch 51 finished
-----------------------------  ---------------
replay_buffer/size             10600
trainer/QF1 Loss                   0.093887
trainer/QF2 Loss                   0.0733842
trainer/Policy Loss               15.3845
trainer/Q1 Predictions Mean      -14.6847
trainer/Q1 Predictions Std         3.74557
trainer/Q1 Predictions Max       -13.0546
trainer/Q1 Predictions Min       -29.4828
trainer/Q2 Predictions Mean      -14.6845
trainer/Q2 Predictions Std         3.74486
trainer/Q2 Predictions Max       -13.0662
trainer/Q2 Predictions Min       -30.0852
trainer/Q Targets Mean           -14.8682
trainer/Q Targets Std              3.79497
trainer/Q Targets Max            -13.181
trainer/Q Targets Min            -31.3922
trainer/Log Pis Mean               1.3163
trainer/Log Pis Std                1.47637
trainer/Log Pis Max                6.93005
trainer/Log Pis Min               -2.1359
trainer/Policy mu Mean             0.0306547
trainer/Policy mu Std              0.749611
trainer/Policy mu Max              2.86069
trainer/Policy mu Min             -2.74362
trainer/Policy log std Mean       -1.65164
trainer/Policy log std Std         0.304485
trainer/Policy log std Max        -0.679636
trainer/Policy log std Min        -1.94299
trainer/Alpha                      0.0652269
trainer/Alpha Loss                -1.86626
exploration/num steps total    10600
exploration/num paths total      106
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.274294
exploration/Rewards Std            0.391412
exploration/Rewards Max           -0.000962979
exploration/Rewards Min           -3.80991
exploration/Returns Mean         -27.4294
exploration/Returns Std            2.92262
exploration/Returns Max          -24.5068
exploration/Returns Min          -30.352
exploration/Actions Mean          -0.0129495
exploration/Actions Std            0.268542
exploration/Actions Max            0.976932
exploration/Actions Min           -0.988879
exploration/Num Paths              2
exploration/Average Returns      -27.4294
evaluation/num steps total     52000
evaluation/num paths total       520
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.136766
evaluation/Rewards Std             0.604364
evaluation/Rewards Max            -0.00624472
evaluation/Rewards Min            -5.96151
evaluation/Returns Mean          -13.6766
evaluation/Returns Std             5.17339
evaluation/Returns Max            -4.36875
evaluation/Returns Min           -19.2222
evaluation/Actions Mean            0.00765473
evaluation/Actions Std             0.172052
evaluation/Actions Max             0.994886
evaluation/Actions Min            -0.985186
evaluation/Num Paths              10
evaluation/Average Returns       -13.6766
time/data storing (s)              0.00126232
time/evaluation sampling (s)       0.251549
time/exploration sampling (s)      0.0665119
time/logging (s)                   0.00336729
time/saving (s)                    0.00231172
time/training (s)                  0.977478
time/epoch (s)                     1.30248
time/total (s)                    68.3411
Epoch                             51
-----------------------------  ---------------
2019-04-22 20:12:07.111059 PDT | [sac-pointmass-multitask-1_2019_04_22_20_10_57_0000--s-0] Epoch 52 finished
-----------------------------  --------------
replay_buffer/size             10800
trainer/QF1 Loss                   0.148169
trainer/QF2 Loss                   0.170975
trainer/Policy Loss               15.427
trainer/Q1 Predictions Mean      -14.8791
trainer/Q1 Predictions Std         5.09563
trainer/Q1 Predictions Max       -13.0316
trainer/Q1 Predictions Min       -41.8013
trainer/Q2 Predictions Mean      -14.8412
trainer/Q2 Predictions Std         5.10314
trainer/Q2 Predictions Max       -13.0804
trainer/Q2 Predictions Min       -41.689
trainer/Q Targets Mean           -14.9955
trainer/Q Targets Std              5.01584
trainer/Q Targets Max            -13.0622
trainer/Q Targets Min            -42.3668
trainer/Log Pis Mean               1.33314
trainer/Log Pis Std                1.25031
trainer/Log Pis Max                6.93113
trainer/Log Pis Min               -2.20968
trainer/Policy mu Mean             0.0603658
trainer/Policy mu Std              0.714044
trainer/Policy mu Max              2.95266
trainer/Policy mu Min             -2.69874
trainer/Policy log std Mean       -1.65838
trainer/Policy log std Std         0.296202
trainer/Policy log std Max        -0.616272
trainer/Policy log std Min        -1.95526
trainer/Alpha                      0.062524
trainer/Alpha Loss                -1.84852
exploration/num steps total    10800
exploration/num paths total      108
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.281713
exploration/Rewards Std            0.436529
exploration/Rewards Max           -0.0181083
exploration/Rewards Min           -4.28217
exploration/Returns Mean         -28.1713
exploration/Returns Std            4.47474
exploration/Returns Max          -23.6966
exploration/Returns Min          -32.646
exploration/Actions Mean          -0.0256057
exploration/Actions Std            0.258117
exploration/Actions Max            0.710979
exploration/Actions Min           -0.983803
exploration/Num Paths              2
exploration/Average Returns      -28.1713
evaluation/num steps total     53000
evaluation/num paths total       530
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.175167
evaluation/Rewards Std             0.452394
evaluation/Rewards Max            -0.0195877
evaluation/Rewards Min            -5.39302
evaluation/Returns Mean          -17.5167
evaluation/Returns Std             5.11671
evaluation/Returns Max           -10.5991
evaluation/Returns Min           -26.535
evaluation/Actions Mean           -0.00475229
evaluation/Actions Std             0.151594
evaluation/Actions Max             0.992661
evaluation/Actions Min            -0.991055
evaluation/Num Paths              10
evaluation/Average Returns       -17.5167
time/data storing (s)              0.00121697
time/evaluation sampling (s)       0.247714
time/exploration sampling (s)      0.0663835
time/logging (s)                   0.0033413
time/saving (s)                    0.00225958
time/training (s)                  0.967009
time/epoch (s)                     1.28792
time/total (s)                    69.6331
Epoch                             52
-----------------------------  --------------
2019-04-22 20:12:08.406548 PDT | [sac-pointmass-multitask-1_2019_04_22_20_10_57_0000--s-0] Epoch 53 finished
-----------------------------  --------------
replay_buffer/size             11000
trainer/QF1 Loss                   3.41453
trainer/QF2 Loss                   3.43008
trainer/Policy Loss               15.3244
trainer/Q1 Predictions Mean      -14.6179
trainer/Q1 Predictions Std         4.40394
trainer/Q1 Predictions Max       -13.1123
trainer/Q1 Predictions Min       -40.1142
trainer/Q2 Predictions Mean      -14.6025
trainer/Q2 Predictions Std         4.38871
trainer/Q2 Predictions Max       -13.1307
trainer/Q2 Predictions Min       -39.9839
trainer/Q Targets Mean           -14.406
trainer/Q Targets Std              4.79922
trainer/Q Targets Max             -0.675304
trainer/Q Targets Min            -41.2264
trainer/Log Pis Mean               1.38114
trainer/Log Pis Std                1.42552
trainer/Log Pis Max                7.47447
trainer/Log Pis Min               -1.56609
trainer/Policy mu Mean            -0.0202573
trainer/Policy mu Std              0.698635
trainer/Policy mu Max              2.53921
trainer/Policy mu Min             -2.57435
trainer/Policy log std Mean       -1.70235
trainer/Policy log std Std         0.27149
trainer/Policy log std Max        -0.679623
trainer/Policy log std Min        -1.93729
trainer/Alpha                      0.0599531
trainer/Alpha Loss                -1.74147
exploration/num steps total    11000
exploration/num paths total      110
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.302033
exploration/Rewards Std            0.598589
exploration/Rewards Max           -0.0169887
exploration/Rewards Min           -4.65183
exploration/Returns Mean         -30.2033
exploration/Returns Std            0.568673
exploration/Returns Max          -29.6346
exploration/Returns Min          -30.7719
exploration/Actions Mean          -0.0201256
exploration/Actions Std            0.268644
exploration/Actions Max            0.940004
exploration/Actions Min           -0.996895
exploration/Num Paths              2
exploration/Average Returns      -30.2033
evaluation/num steps total     54000
evaluation/num paths total       540
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.1357
evaluation/Rewards Std             0.587854
evaluation/Rewards Max            -0.00675413
evaluation/Rewards Min            -6.71269
evaluation/Returns Mean          -13.57
evaluation/Returns Std             4.31857
evaluation/Returns Max            -7.40123
evaluation/Returns Min           -23.3744
evaluation/Actions Mean           -0.00262615
evaluation/Actions Std             0.174832
evaluation/Actions Max             0.991108
evaluation/Actions Min            -0.989498
evaluation/Num Paths              10
evaluation/Average Returns       -13.57
time/data storing (s)              0.00120449
time/evaluation sampling (s)       0.252697
time/exploration sampling (s)      0.0667186
time/logging (s)                   0.00337037
time/saving (s)                    0.00234966
time/training (s)                  0.963659
time/epoch (s)                     1.29
time/total (s)                    70.9272
Epoch                             53
-----------------------------  --------------
2019-04-22 20:12:09.711578 PDT | [sac-pointmass-multitask-1_2019_04_22_20_10_57_0000--s-0] Epoch 54 finished
-----------------------------  --------------
replay_buffer/size             11200
trainer/QF1 Loss                   3.33786
trainer/QF2 Loss                   3.36964
trainer/Policy Loss               15.5925
trainer/Q1 Predictions Mean      -14.8439
trainer/Q1 Predictions Std         4.86671
trainer/Q1 Predictions Max       -12.9869
trainer/Q1 Predictions Min       -41.4772
trainer/Q2 Predictions Mean      -14.864
trainer/Q2 Predictions Std         4.8765
trainer/Q2 Predictions Max       -13.0287
trainer/Q2 Predictions Min       -41.4924
trainer/Q Targets Mean           -14.7048
trainer/Q Targets Std              5.27484
trainer/Q Targets Max             -0.130089
trainer/Q Targets Min            -42.1452
trainer/Log Pis Mean               1.34361
trainer/Log Pis Std                1.54877
trainer/Log Pis Max                6.55729
trainer/Log Pis Min               -3.6744
trainer/Policy mu Mean             0.144516
trainer/Policy mu Std              0.79966
trainer/Policy mu Max              2.94261
trainer/Policy mu Min             -2.67934
trainer/Policy log std Mean       -1.60311
trainer/Policy log std Std         0.31102
trainer/Policy log std Max        -0.642541
trainer/Policy log std Min        -1.84402
trainer/Alpha                      0.0574923
trainer/Alpha Loss                -1.87458
exploration/num steps total    11200
exploration/num paths total      112
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.260942
exploration/Rewards Std            0.34258
exploration/Rewards Max           -0.0123399
exploration/Rewards Min           -3.86577
exploration/Returns Mean         -26.0942
exploration/Returns Std            3.02352
exploration/Returns Max          -23.0707
exploration/Returns Min          -29.1177
exploration/Actions Mean          -0.0259558
exploration/Actions Std            0.264369
exploration/Actions Max            0.713564
exploration/Actions Min           -0.977731
exploration/Num Paths              2
exploration/Average Returns      -26.0942
evaluation/num steps total     55000
evaluation/num paths total       550
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.139052
evaluation/Rewards Std             0.444849
evaluation/Rewards Max            -0.00878185
evaluation/Rewards Min            -5.69209
evaluation/Returns Mean          -13.9052
evaluation/Returns Std             5.21851
evaluation/Returns Max            -7.81437
evaluation/Returns Min           -23.4601
evaluation/Actions Mean           -0.0141872
evaluation/Actions Std             0.153792
evaluation/Actions Max             0.995799
evaluation/Actions Min            -0.993628
evaluation/Num Paths              10
evaluation/Average Returns       -13.9052
time/data storing (s)              0.00119767
time/evaluation sampling (s)       0.248908
time/exploration sampling (s)      0.0677154
time/logging (s)                   0.00337511
time/saving (s)                    0.00230246
time/training (s)                  0.976057
time/epoch (s)                     1.29956
time/total (s)                    72.2308
Epoch                             54
-----------------------------  --------------
2019-04-22 20:12:11.007947 PDT | [sac-pointmass-multitask-1_2019_04_22_20_10_57_0000--s-0] Epoch 55 finished
-----------------------------  --------------
replay_buffer/size             11400
trainer/QF1 Loss                   3.31583
trainer/QF2 Loss                   3.32446
trainer/Policy Loss               15.2175
trainer/Q1 Predictions Mean      -14.0957
trainer/Q1 Predictions Std         3.53464
trainer/Q1 Predictions Max       -12.844
trainer/Q1 Predictions Min       -38.752
trainer/Q2 Predictions Mean      -14.1033
trainer/Q2 Predictions Std         3.51084
trainer/Q2 Predictions Max       -12.8457
trainer/Q2 Predictions Min       -38.5615
trainer/Q Targets Mean           -14.0912
trainer/Q Targets Std              4.07402
trainer/Q Targets Max             -0.23341
trainer/Q Targets Min            -38.9203
trainer/Log Pis Mean               1.48069
trainer/Log Pis Std                1.49623
trainer/Log Pis Max                7.22723
trainer/Log Pis Min               -3.53238
trainer/Policy mu Mean             0.0294477
trainer/Policy mu Std              0.747928
trainer/Policy mu Max              2.75924
trainer/Policy mu Min             -2.68124
trainer/Policy log std Mean       -1.72772
trainer/Policy log std Std         0.288607
trainer/Policy log std Max        -0.719029
trainer/Policy log std Min        -1.97195
trainer/Alpha                      0.0550606
trainer/Alpha Loss                -1.50552
exploration/num steps total    11400
exploration/num paths total      114
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.306616
exploration/Rewards Std            0.58213
exploration/Rewards Max           -0.0107877
exploration/Rewards Min           -4.74335
exploration/Returns Mean         -30.6616
exploration/Returns Std            1.72658
exploration/Returns Max          -28.9351
exploration/Returns Min          -32.3882
exploration/Actions Mean           0.0134132
exploration/Actions Std            0.273157
exploration/Actions Max            0.997172
exploration/Actions Min           -0.988715
exploration/Num Paths              2
exploration/Average Returns      -30.6616
evaluation/num steps total     56000
evaluation/num paths total       560
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.127313
evaluation/Rewards Std             0.420049
evaluation/Rewards Max            -0.0520052
evaluation/Rewards Min            -5.14729
evaluation/Returns Mean          -12.7313
evaluation/Returns Std             4.42126
evaluation/Returns Max            -6.72514
evaluation/Returns Min           -22.1438
evaluation/Actions Mean           -0.00249839
evaluation/Actions Std             0.146638
evaluation/Actions Max             0.993967
evaluation/Actions Min            -0.988964
evaluation/Num Paths              10
evaluation/Average Returns       -12.7313
time/data storing (s)              0.00119095
time/evaluation sampling (s)       0.253482
time/exploration sampling (s)      0.0678419
time/logging (s)                   0.00339662
time/saving (s)                    0.0023105
time/training (s)                  0.962579
time/epoch (s)                     1.2908
time/total (s)                    73.5258
Epoch                             55
-----------------------------  --------------
2019-04-22 20:12:12.324842 PDT | [sac-pointmass-multitask-1_2019_04_22_20_10_57_0000--s-0] Epoch 56 finished
-----------------------------  --------------
replay_buffer/size             11600
trainer/QF1 Loss                   4.56925
trainer/QF2 Loss                   4.74741
trainer/Policy Loss               15.0138
trainer/Q1 Predictions Mean      -14.1549
trainer/Q1 Predictions Std         2.94335
trainer/Q1 Predictions Max       -12.9826
trainer/Q1 Predictions Min       -29.8781
trainer/Q2 Predictions Mean      -14.1841
trainer/Q2 Predictions Std         3.02193
trainer/Q2 Predictions Max       -12.9792
trainer/Q2 Predictions Min       -30.0557
trainer/Q Targets Mean           -14.0064
trainer/Q Targets Std              2.77443
trainer/Q Targets Max             -5.72197
trainer/Q Targets Min            -29.6902
trainer/Log Pis Mean               1.21465
trainer/Log Pis Std                1.4269
trainer/Log Pis Max                6.14567
trainer/Log Pis Min               -3.88449
trainer/Policy mu Mean             0.00389607
trainer/Policy mu Std              0.709988
trainer/Policy mu Max              2.89495
trainer/Policy mu Min             -2.74145
trainer/Policy log std Mean       -1.72874
trainer/Policy log std Std         0.313489
trainer/Policy log std Max        -0.654527
trainer/Policy log std Min        -2.05779
trainer/Alpha                      0.0528467
trainer/Alpha Loss                -2.30903
exploration/num steps total    11600
exploration/num paths total      116
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.295065
exploration/Rewards Std            0.547978
exploration/Rewards Max           -0.0196005
exploration/Rewards Min           -4.56932
exploration/Returns Mean         -29.5065
exploration/Returns Std            0.762519
exploration/Returns Max          -28.744
exploration/Returns Min          -30.2691
exploration/Actions Mean          -0.00476597
exploration/Actions Std            0.270354
exploration/Actions Max            0.998733
exploration/Actions Min           -0.978431
exploration/Num Paths              2
exploration/Average Returns      -29.5065
evaluation/num steps total     57000
evaluation/num paths total       570
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.114195
evaluation/Rewards Std             0.467363
evaluation/Rewards Max            -0.0162459
evaluation/Rewards Min            -5.25495
evaluation/Returns Mean          -11.4195
evaluation/Returns Std             5.31976
evaluation/Returns Max            -4.4869
evaluation/Returns Min           -20.8626
evaluation/Actions Mean            0.00691567
evaluation/Actions Std             0.150609
evaluation/Actions Max             0.994035
evaluation/Actions Min            -0.986463
evaluation/Num Paths              10
evaluation/Average Returns       -11.4195
time/data storing (s)              0.00125832
time/evaluation sampling (s)       0.252183
time/exploration sampling (s)      0.0674421
time/logging (s)                   0.00338686
time/saving (s)                    0.0105617
time/training (s)                  0.976379
time/epoch (s)                     1.31121
time/total (s)                    74.8412
Epoch                             56
-----------------------------  --------------
2019-04-22 20:12:13.635650 PDT | [sac-pointmass-multitask-1_2019_04_22_20_10_57_0000--s-0] Epoch 57 finished
-----------------------------  --------------
replay_buffer/size             11800
trainer/QF1 Loss                   1.81938
trainer/QF2 Loss                   1.77425
trainer/Policy Loss               15.2908
trainer/Q1 Predictions Mean      -14.3167
trainer/Q1 Predictions Std         3.63931
trainer/Q1 Predictions Max       -13.0069
trainer/Q1 Predictions Min       -39.7475
trainer/Q2 Predictions Mean      -14.265
trainer/Q2 Predictions Std         3.6324
trainer/Q2 Predictions Max       -12.9464
trainer/Q2 Predictions Min       -39.6588
trainer/Q Targets Mean           -14.2087
trainer/Q Targets Std              4.02659
trainer/Q Targets Max             -0.0483617
trainer/Q Targets Min            -40.4748
trainer/Log Pis Mean               1.51562
trainer/Log Pis Std                1.44484
trainer/Log Pis Max                7.95678
trainer/Log Pis Min               -2.18272
trainer/Policy mu Mean             0.0713899
trainer/Policy mu Std              0.710399
trainer/Policy mu Max              2.77128
trainer/Policy mu Min             -2.6358
trainer/Policy log std Mean       -1.77344
trainer/Policy log std Std         0.305096
trainer/Policy log std Max        -0.72527
trainer/Policy log std Min        -2.03361
trainer/Alpha                      0.0507834
trainer/Alpha Loss                -1.44346
exploration/num steps total    11800
exploration/num paths total      118
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.264538
exploration/Rewards Std            0.515656
exploration/Rewards Max           -0.0183891
exploration/Rewards Min           -4.90207
exploration/Returns Mean         -26.4538
exploration/Returns Std            4.54995
exploration/Returns Max          -21.9038
exploration/Returns Min          -31.0037
exploration/Actions Mean          -0.0300872
exploration/Actions Std            0.247999
exploration/Actions Max            0.683945
exploration/Actions Min           -0.995325
exploration/Num Paths              2
exploration/Average Returns      -26.4538
evaluation/num steps total     58000
evaluation/num paths total       580
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.147734
evaluation/Rewards Std             0.674994
evaluation/Rewards Max            -0.018995
evaluation/Rewards Min            -6.71374
evaluation/Returns Mean          -14.7734
evaluation/Returns Std             5.3245
evaluation/Returns Max            -5.85548
evaluation/Returns Min           -22.3672
evaluation/Actions Mean           -0.00961945
evaluation/Actions Std             0.184466
evaluation/Actions Max             0.993506
evaluation/Actions Min            -0.99505
evaluation/Num Paths              10
evaluation/Average Returns       -14.7734
time/data storing (s)              0.00133549
time/evaluation sampling (s)       0.249736
time/exploration sampling (s)      0.0674407
time/logging (s)                   0.00340809
time/saving (s)                    0.00215609
time/training (s)                  0.980908
time/epoch (s)                     1.30498
time/total (s)                    76.1506
Epoch                             57
-----------------------------  --------------
2019-04-22 20:12:14.939160 PDT | [sac-pointmass-multitask-1_2019_04_22_20_10_57_0000--s-0] Epoch 58 finished
-----------------------------  --------------
replay_buffer/size             12000
trainer/QF1 Loss                   1.67657
trainer/QF2 Loss                   1.66731
trainer/Policy Loss               15.8084
trainer/Q1 Predictions Mean      -14.7793
trainer/Q1 Predictions Std         5.37299
trainer/Q1 Predictions Max       -12.8573
trainer/Q1 Predictions Min       -43.7719
trainer/Q2 Predictions Mean      -14.7464
trainer/Q2 Predictions Std         5.37061
trainer/Q2 Predictions Max       -12.8308
trainer/Q2 Predictions Min       -43.9368
trainer/Q Targets Mean           -14.7369
trainer/Q Targets Std              5.4539
trainer/Q Targets Max             -0.580064
trainer/Q Targets Min            -44.3713
trainer/Log Pis Mean               1.7041
trainer/Log Pis Std                1.44134
trainer/Log Pis Max                6.85281
trainer/Log Pis Min               -1.53959
trainer/Policy mu Mean             0.0226826
trainer/Policy mu Std              0.856246
trainer/Policy mu Max              2.88568
trainer/Policy mu Min             -2.98093
trainer/Policy log std Mean       -1.78915
trainer/Policy log std Std         0.385913
trainer/Policy log std Max        -0.464826
trainer/Policy log std Min        -2.17426
trainer/Alpha                      0.0488732
trainer/Alpha Loss                -0.893141
exploration/num steps total    12000
exploration/num paths total      120
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.216736
exploration/Rewards Std            0.28748
exploration/Rewards Max           -0.00802325
exploration/Rewards Min           -3.07407
exploration/Returns Mean         -21.6736
exploration/Returns Std            1.27842
exploration/Returns Max          -20.3952
exploration/Returns Min          -22.952
exploration/Actions Mean          -0.0174951
exploration/Actions Std            0.232684
exploration/Actions Max            0.971681
exploration/Actions Min           -0.986633
exploration/Num Paths              2
exploration/Average Returns      -21.6736
evaluation/num steps total     59000
evaluation/num paths total       590
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.145268
evaluation/Rewards Std             0.410651
evaluation/Rewards Max            -0.0298585
evaluation/Rewards Min            -4.66522
evaluation/Returns Mean          -14.5268
evaluation/Returns Std             3.36962
evaluation/Returns Max            -8.83976
evaluation/Returns Min           -21.1016
evaluation/Actions Mean           -0.0118198
evaluation/Actions Std             0.15366
evaluation/Actions Max             0.988652
evaluation/Actions Min            -0.99268
evaluation/Num Paths              10
evaluation/Average Returns       -14.5268
time/data storing (s)              0.00117253
time/evaluation sampling (s)       0.248501
time/exploration sampling (s)      0.0658938
time/logging (s)                   0.00334078
time/saving (s)                    0.00188232
time/training (s)                  0.977043
time/epoch (s)                     1.29783
time/total (s)                    77.4526
Epoch                             58
-----------------------------  --------------
2019-04-22 20:12:16.240176 PDT | [sac-pointmass-multitask-1_2019_04_22_20_10_57_0000--s-0] Epoch 59 finished
-----------------------------  --------------
replay_buffer/size             12200
trainer/QF1 Loss                   1.63828
trainer/QF2 Loss                   1.64125
trainer/Policy Loss               15.8011
trainer/Q1 Predictions Mean      -14.553
trainer/Q1 Predictions Std         5.34525
trainer/Q1 Predictions Max       -12.6761
trainer/Q1 Predictions Min       -43.1385
trainer/Q2 Predictions Mean      -14.5509
trainer/Q2 Predictions Std         5.358
trainer/Q2 Predictions Max       -12.6852
trainer/Q2 Predictions Min       -43.0981
trainer/Q Targets Mean           -14.6016
trainer/Q Targets Std              5.52458
trainer/Q Targets Max             -0.699818
trainer/Q Targets Min            -43.0963
trainer/Log Pis Mean               1.98482
trainer/Log Pis Std                1.54944
trainer/Log Pis Max                9.00965
trainer/Log Pis Min               -1.75027
trainer/Policy mu Mean             0.12986
trainer/Policy mu Std              0.853937
trainer/Policy mu Max              2.92531
trainer/Policy mu Min             -2.56074
trainer/Policy log std Mean       -1.87709
trainer/Policy log std Std         0.371809
trainer/Policy log std Max        -0.645678
trainer/Policy log std Min        -2.19963
trainer/Alpha                      0.0471171
trainer/Alpha Loss                -0.0463839
exploration/num steps total    12200
exploration/num paths total      122
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.234326
exploration/Rewards Std            0.369147
exploration/Rewards Max           -0.00603376
exploration/Rewards Min           -4.01325
exploration/Returns Mean         -23.4326
exploration/Returns Std            4.19889
exploration/Returns Max          -19.2337
exploration/Returns Min          -27.6315
exploration/Actions Mean          -0.0079385
exploration/Actions Std            0.227823
exploration/Actions Max            0.956979
exploration/Actions Min           -0.977055
exploration/Num Paths              2
exploration/Average Returns      -23.4326
evaluation/num steps total     60000
evaluation/num paths total       600
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.156131
evaluation/Rewards Std             0.407081
evaluation/Rewards Max            -0.0106297
evaluation/Rewards Min            -6.10602
evaluation/Returns Mean          -15.6131
evaluation/Returns Std             4.56274
evaluation/Returns Max            -9.92613
evaluation/Returns Min           -26.3636
evaluation/Actions Mean            0.00704254
evaluation/Actions Std             0.147853
evaluation/Actions Max             0.992981
evaluation/Actions Min            -0.988434
evaluation/Num Paths              10
evaluation/Average Returns       -15.6131
time/data storing (s)              0.00126583
time/evaluation sampling (s)       0.251257
time/exploration sampling (s)      0.0665753
time/logging (s)                   0.00332388
time/saving (s)                    0.00181277
time/training (s)                  0.97106
time/epoch (s)                     1.2953
time/total (s)                    78.752
Epoch                             59
-----------------------------  --------------
2019-04-22 20:12:17.550041 PDT | [sac-pointmass-multitask-1_2019_04_22_20_10_57_0000--s-0] Epoch 60 finished
-----------------------------  --------------
replay_buffer/size             12400
trainer/QF1 Loss                   3.27429
trainer/QF2 Loss                   3.29053
trainer/Policy Loss               15.1444
trainer/Q1 Predictions Mean      -13.999
trainer/Q1 Predictions Std         3.43598
trainer/Q1 Predictions Max       -12.7549
trainer/Q1 Predictions Min       -32.4838
trainer/Q2 Predictions Mean      -14.0256
trainer/Q2 Predictions Std         3.48053
trainer/Q2 Predictions Max       -12.7809
trainer/Q2 Predictions Min       -32.6836
trainer/Q Targets Mean           -13.779
trainer/Q Targets Std              3.94225
trainer/Q Targets Max             -0.111863
trainer/Q Targets Min            -31.6681
trainer/Log Pis Mean               1.63518
trainer/Log Pis Std                1.26514
trainer/Log Pis Max                7.97489
trainer/Log Pis Min               -0.898813
trainer/Policy mu Mean            -0.111584
trainer/Policy mu Std              0.66264
trainer/Policy mu Max              2.67879
trainer/Policy mu Min             -2.96552
trainer/Policy log std Mean       -1.8635
trainer/Policy log std Std         0.305464
trainer/Policy log std Max        -0.703567
trainer/Policy log std Min        -2.11323
trainer/Alpha                      0.0454521
trainer/Alpha Loss                -1.12764
exploration/num steps total    12400
exploration/num paths total      124
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.295902
exploration/Rewards Std            0.601149
exploration/Rewards Max           -0.00886655
exploration/Rewards Min           -5.33745
exploration/Returns Mean         -29.5902
exploration/Returns Std            3.78333
exploration/Returns Max          -25.8069
exploration/Returns Min          -33.3735
exploration/Actions Mean          -0.0273793
exploration/Actions Std            0.250469
exploration/Actions Max            0.948012
exploration/Actions Min           -0.994092
exploration/Num Paths              2
exploration/Average Returns      -29.5902
evaluation/num steps total     61000
evaluation/num paths total       610
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.137604
evaluation/Rewards Std             0.379919
evaluation/Rewards Max            -0.072478
evaluation/Rewards Min            -4.81205
evaluation/Returns Mean          -13.7604
evaluation/Returns Std             4.45024
evaluation/Returns Max            -9.1848
evaluation/Returns Min           -22.2665
evaluation/Actions Mean            0.00121364
evaluation/Actions Std             0.141133
evaluation/Actions Max             0.993774
evaluation/Actions Min            -0.989841
evaluation/Num Paths              10
evaluation/Average Returns       -13.7604
time/data storing (s)              0.00119912
time/evaluation sampling (s)       0.251597
time/exploration sampling (s)      0.0660429
time/logging (s)                   0.00335351
time/saving (s)                    0.00185547
time/training (s)                  0.980332
time/epoch (s)                     1.30438
time/total (s)                    80.0605
Epoch                             60
-----------------------------  --------------
2019-04-22 20:12:18.846685 PDT | [sac-pointmass-multitask-1_2019_04_22_20_10_57_0000--s-0] Epoch 61 finished
-----------------------------  --------------
replay_buffer/size             12600
trainer/QF1 Loss                   0.288165
trainer/QF2 Loss                   0.266652
trainer/Policy Loss               14.9354
trainer/Q1 Predictions Mean      -13.8623
trainer/Q1 Predictions Std         4.44269
trainer/Q1 Predictions Max       -12.4043
trainer/Q1 Predictions Min       -46.5367
trainer/Q2 Predictions Mean      -13.8535
trainer/Q2 Predictions Std         4.42647
trainer/Q2 Predictions Max       -12.3913
trainer/Q2 Predictions Min       -46.0676
trainer/Q Targets Mean           -14.28
trainer/Q Targets Std              4.37767
trainer/Q Targets Max            -12.6748
trainer/Q Targets Min            -44.3816
trainer/Log Pis Mean               1.60537
trainer/Log Pis Std                1.47092
trainer/Log Pis Max                7.14622
trainer/Log Pis Min               -1.72283
trainer/Policy mu Mean            -0.055461
trainer/Policy mu Std              0.762493
trainer/Policy mu Max              2.96407
trainer/Policy mu Min             -2.82683
trainer/Policy log std Mean       -1.82732
trainer/Policy log std Std         0.340199
trainer/Policy log std Max        -0.639385
trainer/Policy log std Min        -2.0642
trainer/Alpha                      0.0437309
trainer/Alpha Loss                -1.235
exploration/num steps total    12600
exploration/num paths total      126
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.216924
exploration/Rewards Std            0.395746
exploration/Rewards Max           -0.0127454
exploration/Rewards Min           -4.22929
exploration/Returns Mean         -21.6924
exploration/Returns Std            5.15344
exploration/Returns Max          -16.539
exploration/Returns Min          -26.8459
exploration/Actions Mean           0.0118999
exploration/Actions Std            0.217586
exploration/Actions Max            0.981581
exploration/Actions Min           -0.951505
exploration/Num Paths              2
exploration/Average Returns      -21.6924
evaluation/num steps total     62000
evaluation/num paths total       620
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.104794
evaluation/Rewards Std             0.484051
evaluation/Rewards Max            -0.0221257
evaluation/Rewards Min            -5.93798
evaluation/Returns Mean          -10.4794
evaluation/Returns Std             5.27503
evaluation/Returns Max            -3.44251
evaluation/Returns Min           -20.0171
evaluation/Actions Mean           -0.00233544
evaluation/Actions Std             0.159972
evaluation/Actions Max             0.992027
evaluation/Actions Min            -0.995332
evaluation/Num Paths              10
evaluation/Average Returns       -10.4794
time/data storing (s)              0.00120807
time/evaluation sampling (s)       0.248736
time/exploration sampling (s)      0.0672864
time/logging (s)                   0.00336873
time/saving (s)                    0.00182512
time/training (s)                  0.968592
time/epoch (s)                     1.29102
time/total (s)                    81.3556
Epoch                             61
-----------------------------  --------------
2019-04-22 20:12:20.167571 PDT | [sac-pointmass-multitask-1_2019_04_22_20_10_57_0000--s-0] Epoch 62 finished
-----------------------------  ---------------
replay_buffer/size             12800
trainer/QF1 Loss                   0.0785013
trainer/QF2 Loss                   0.0971991
trainer/Policy Loss               14.665
trainer/Q1 Predictions Mean      -13.43
trainer/Q1 Predictions Std         3.05811
trainer/Q1 Predictions Max       -12.5018
trainer/Q1 Predictions Min       -38.1823
trainer/Q2 Predictions Mean      -13.41
trainer/Q2 Predictions Std         3.03932
trainer/Q2 Predictions Max       -12.4696
trainer/Q2 Predictions Min       -37.6495
trainer/Q Targets Mean           -13.6526
trainer/Q Targets Std              3.14442
trainer/Q Targets Max            -12.5997
trainer/Q Targets Min            -39.4141
trainer/Log Pis Mean               1.57991
trainer/Log Pis Std                1.29905
trainer/Log Pis Max                9.041
trainer/Log Pis Min               -3.26781
trainer/Policy mu Mean             0.0138868
trainer/Policy mu Std              0.600869
trainer/Policy mu Max              2.70551
trainer/Policy mu Min             -2.94546
trainer/Policy log std Mean       -1.96292
trainer/Policy log std Std         0.300718
trainer/Policy log std Max        -0.611925
trainer/Policy log std Min        -2.1382
trainer/Alpha                      0.0422015
trainer/Alpha Loss                -1.32962
exploration/num steps total    12800
exploration/num paths total      128
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.240443
exploration/Rewards Std            0.472044
exploration/Rewards Max           -0.0160973
exploration/Rewards Min           -4.70257
exploration/Returns Mean         -24.0443
exploration/Returns Std            6.16123
exploration/Returns Max          -17.8831
exploration/Returns Min          -30.2056
exploration/Actions Mean          -0.00923047
exploration/Actions Std            0.218362
exploration/Actions Max            0.971577
exploration/Actions Min           -0.990056
exploration/Num Paths              2
exploration/Average Returns      -24.0443
evaluation/num steps total     63000
evaluation/num paths total       630
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0986544
evaluation/Rewards Std             0.451154
evaluation/Rewards Max            -0.0177445
evaluation/Rewards Min            -5.42943
evaluation/Returns Mean           -9.86544
evaluation/Returns Std             4.52168
evaluation/Returns Max            -3.55111
evaluation/Returns Min           -18.3904
evaluation/Actions Mean            0.000249581
evaluation/Actions Std             0.155626
evaluation/Actions Max             0.99295
evaluation/Actions Min            -0.995529
evaluation/Num Paths              10
evaluation/Average Returns        -9.86544
time/data storing (s)              0.00119412
time/evaluation sampling (s)       0.250573
time/exploration sampling (s)      0.0672776
time/logging (s)                   0.00341265
time/saving (s)                    0.00197477
time/training (s)                  0.990875
time/epoch (s)                     1.31531
time/total (s)                    82.675
Epoch                             62
-----------------------------  ---------------
2019-04-22 20:12:21.469494 PDT | [sac-pointmass-multitask-1_2019_04_22_20_10_57_0000--s-0] Epoch 63 finished
-----------------------------  --------------
replay_buffer/size             13000
trainer/QF1 Loss                   0.0267815
trainer/QF2 Loss                   0.0204325
trainer/Policy Loss               15.0457
trainer/Q1 Predictions Mean      -13.9853
trainer/Q1 Predictions Std         4.48961
trainer/Q1 Predictions Max       -12.6678
trainer/Q1 Predictions Min       -40.9873
trainer/Q2 Predictions Mean      -14.0457
trainer/Q2 Predictions Std         4.55028
trainer/Q2 Predictions Max       -12.7148
trainer/Q2 Predictions Min       -41.3435
trainer/Q Targets Mean           -13.9987
trainer/Q Targets Std              4.50056
trainer/Q Targets Max            -12.5644
trainer/Q Targets Min            -41.0041
trainer/Log Pis Mean               1.51646
trainer/Log Pis Std                1.40831
trainer/Log Pis Max                8.80511
trainer/Log Pis Min               -2.2711
trainer/Policy mu Mean             0.0638481
trainer/Policy mu Std              0.681033
trainer/Policy mu Max              2.96029
trainer/Policy mu Min             -1.18083
trainer/Policy log std Mean       -1.89762
trainer/Policy log std Std         0.308908
trainer/Policy log std Max        -0.671659
trainer/Policy log std Min        -2.13078
trainer/Alpha                      0.0408708
trainer/Alpha Loss                -1.54596
exploration/num steps total    13000
exploration/num paths total      130
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.218145
exploration/Rewards Std            0.291166
exploration/Rewards Max           -0.014815
exploration/Rewards Min           -3.24947
exploration/Returns Mean         -21.8145
exploration/Returns Std            2.11563
exploration/Returns Max          -19.6988
exploration/Returns Min          -23.9301
exploration/Actions Mean          -0.00939691
exploration/Actions Std            0.206156
exploration/Actions Max            0.747285
exploration/Actions Min           -0.997936
exploration/Num Paths              2
exploration/Average Returns      -21.8145
evaluation/num steps total     64000
evaluation/num paths total       640
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.163716
evaluation/Rewards Std             0.489588
evaluation/Rewards Max            -0.0527343
evaluation/Rewards Min            -5.31665
evaluation/Returns Mean          -16.3716
evaluation/Returns Std             4.39922
evaluation/Returns Max            -9.32713
evaluation/Returns Min           -23.7999
evaluation/Actions Mean            0.0033565
evaluation/Actions Std             0.162162
evaluation/Actions Max             0.994235
evaluation/Actions Min            -0.995765
evaluation/Num Paths              10
evaluation/Average Returns       -16.3716
time/data storing (s)              0.00122497
time/evaluation sampling (s)       0.247492
time/exploration sampling (s)      0.0664058
time/logging (s)                   0.00335456
time/saving (s)                    0.00208952
time/training (s)                  0.97573
time/epoch (s)                     1.2963
time/total (s)                    83.9753
Epoch                             63
-----------------------------  --------------
2019-04-22 20:12:22.770853 PDT | [sac-pointmass-multitask-1_2019_04_22_20_10_57_0000--s-0] Epoch 64 finished
-----------------------------  --------------
replay_buffer/size             13200
trainer/QF1 Loss                   0.0355088
trainer/QF2 Loss                   0.0409166
trainer/Policy Loss               14.7423
trainer/Q1 Predictions Mean      -13.5193
trainer/Q1 Predictions Std         2.46852
trainer/Q1 Predictions Max       -12.5409
trainer/Q1 Predictions Min       -33.7853
trainer/Q2 Predictions Mean      -13.499
trainer/Q2 Predictions Std         2.46905
trainer/Q2 Predictions Max       -12.5333
trainer/Q2 Predictions Min       -33.8619
trainer/Q Targets Mean           -13.5137
trainer/Q Targets Std              2.36071
trainer/Q Targets Max            -12.5178
trainer/Q Targets Min            -33.0709
trainer/Log Pis Mean               1.5134
trainer/Log Pis Std                1.29476
trainer/Log Pis Max                6.53402
trainer/Log Pis Min               -1.53697
trainer/Policy mu Mean             0.00319581
trainer/Policy mu Std              0.736895
trainer/Policy mu Max              2.61618
trainer/Policy mu Min             -2.96652
trainer/Policy log std Mean       -1.84831
trainer/Policy log std Std         0.337531
trainer/Policy log std Max        -0.668976
trainer/Policy log std Min        -2.11758
trainer/Alpha                      0.0396692
trainer/Alpha Loss                -1.57029
exploration/num steps total    13200
exploration/num paths total      132
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.241192
exploration/Rewards Std            0.488589
exploration/Rewards Max           -0.0179495
exploration/Rewards Min           -5.25279
exploration/Returns Mean         -24.1192
exploration/Returns Std            5.706
exploration/Returns Max          -18.4132
exploration/Returns Min          -29.8252
exploration/Actions Mean           0.0160986
exploration/Actions Std            0.241863
exploration/Actions Max            0.995106
exploration/Actions Min           -0.965576
exploration/Num Paths              2
exploration/Average Returns      -24.1192
evaluation/num steps total     65000
evaluation/num paths total       650
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.1401
evaluation/Rewards Std             0.499004
evaluation/Rewards Max            -0.0255755
evaluation/Rewards Min            -5.23518
evaluation/Returns Mean          -14.01
evaluation/Returns Std             4.27713
evaluation/Returns Max            -7.57309
evaluation/Returns Min           -20.0342
evaluation/Actions Mean           -0.011394
evaluation/Actions Std             0.157934
evaluation/Actions Max             0.98965
evaluation/Actions Min            -0.995611
evaluation/Num Paths              10
evaluation/Average Returns       -14.01
time/data storing (s)              0.0011789
time/evaluation sampling (s)       0.250841
time/exploration sampling (s)      0.0665147
time/logging (s)                   0.00251938
time/saving (s)                    0.00232379
time/training (s)                  0.971589
time/epoch (s)                     1.29497
time/total (s)                    85.2742
Epoch                             64
-----------------------------  --------------
2019-04-22 20:12:24.069101 PDT | [sac-pointmass-multitask-1_2019_04_22_20_10_57_0000--s-0] Epoch 65 finished
-----------------------------  --------------
replay_buffer/size             13400
trainer/QF1 Loss                   1.87473
trainer/QF2 Loss                   1.8163
trainer/Policy Loss               16.3605
trainer/Q1 Predictions Mean      -15.1357
trainer/Q1 Predictions Std         6.61459
trainer/Q1 Predictions Max       -12.436
trainer/Q1 Predictions Min       -46.3334
trainer/Q2 Predictions Mean      -15.1349
trainer/Q2 Predictions Std         6.62691
trainer/Q2 Predictions Max       -12.4631
trainer/Q2 Predictions Min       -46.109
trainer/Q Targets Mean           -15.1593
trainer/Q Targets Std              6.78507
trainer/Q Targets Max             -0.311623
trainer/Q Targets Min            -42.2981
trainer/Log Pis Mean               2.1205
trainer/Log Pis Std                1.98403
trainer/Log Pis Max                8.99937
trainer/Log Pis Min               -2.66582
trainer/Policy mu Mean            -0.0502226
trainer/Policy mu Std              1.00494
trainer/Policy mu Max              3.27967
trainer/Policy mu Min             -3.09943
trainer/Policy log std Mean       -1.8463
trainer/Policy log std Std         0.454319
trainer/Policy log std Max        -0.60408
trainer/Policy log std Min        -2.22913
trainer/Alpha                      0.0385373
trainer/Alpha Loss                 0.392362
exploration/num steps total    13400
exploration/num paths total      134
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.292907
exploration/Rewards Std            0.749998
exploration/Rewards Max           -0.0112853
exploration/Rewards Min           -6.49254
exploration/Returns Mean         -29.2907
exploration/Returns Std            4.199
exploration/Returns Max          -25.0917
exploration/Returns Min          -33.4897
exploration/Actions Mean           0.00715129
exploration/Actions Std            0.259705
exploration/Actions Max            0.997617
exploration/Actions Min           -0.993244
exploration/Num Paths              2
exploration/Average Returns      -29.2907
evaluation/num steps total     66000
evaluation/num paths total       660
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.151269
evaluation/Rewards Std             0.525642
evaluation/Rewards Max            -0.0164083
evaluation/Rewards Min            -5.29823
evaluation/Returns Mean          -15.1269
evaluation/Returns Std             3.35541
evaluation/Returns Max            -7.32186
evaluation/Returns Min           -19.0973
evaluation/Actions Mean           -0.00432537
evaluation/Actions Std             0.169082
evaluation/Actions Max             0.995089
evaluation/Actions Min            -0.994188
evaluation/Num Paths              10
evaluation/Average Returns       -15.1269
time/data storing (s)              0.00120321
time/evaluation sampling (s)       0.249319
time/exploration sampling (s)      0.0666523
time/logging (s)                   0.00338965
time/saving (s)                    0.00234407
time/training (s)                  0.971032
time/epoch (s)                     1.29394
time/total (s)                    86.5723
Epoch                             65
-----------------------------  --------------
2019-04-22 20:12:25.365625 PDT | [sac-pointmass-multitask-1_2019_04_22_20_10_57_0000--s-0] Epoch 66 finished
-----------------------------  --------------
replay_buffer/size             13600
trainer/QF1 Loss                   4.57286
trainer/QF2 Loss                   4.51991
trainer/Policy Loss               14.8823
trainer/Q1 Predictions Mean      -13.7411
trainer/Q1 Predictions Std         3.80484
trainer/Q1 Predictions Max       -12.3552
trainer/Q1 Predictions Min       -36.2881
trainer/Q2 Predictions Mean      -13.6936
trainer/Q2 Predictions Std         3.84276
trainer/Q2 Predictions Max       -12.3022
trainer/Q2 Predictions Min       -36.2813
trainer/Q Targets Mean           -13.5259
trainer/Q Targets Std              4.50614
trainer/Q Targets Max             -0.229827
trainer/Q Targets Min            -36.2163
trainer/Log Pis Mean               1.75194
trainer/Log Pis Std                1.46035
trainer/Log Pis Max                7.60137
trainer/Log Pis Min               -2.77487
trainer/Policy mu Mean             0.17285
trainer/Policy mu Std              0.732198
trainer/Policy mu Max              2.90601
trainer/Policy mu Min             -2.90199
trainer/Policy log std Mean       -1.93549
trainer/Policy log std Std         0.373358
trainer/Policy log std Max        -0.684076
trainer/Policy log std Min        -2.22831
trainer/Alpha                      0.0377
trainer/Alpha Loss                -0.813134
exploration/num steps total    13600
exploration/num paths total      136
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.276133
exploration/Rewards Std            0.482974
exploration/Rewards Max           -0.0172078
exploration/Rewards Min           -4.29801
exploration/Returns Mean         -27.6133
exploration/Returns Std            3.55728
exploration/Returns Max          -24.0561
exploration/Returns Min          -31.1706
exploration/Actions Mean          -0.0315252
exploration/Actions Std            0.215747
exploration/Actions Max            0.404321
exploration/Actions Min           -0.995223
exploration/Num Paths              2
exploration/Average Returns      -27.6133
evaluation/num steps total     67000
evaluation/num paths total       670
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.238296
evaluation/Rewards Std             0.593617
evaluation/Rewards Max            -0.0503422
evaluation/Rewards Min            -5.50434
evaluation/Returns Mean          -23.8296
evaluation/Returns Std             3.47878
evaluation/Returns Max           -17.8436
evaluation/Returns Min           -28.608
evaluation/Actions Mean            0.0139155
evaluation/Actions Std             0.178632
evaluation/Actions Max             0.996431
evaluation/Actions Min            -0.995351
evaluation/Num Paths              10
evaluation/Average Returns       -23.8296
time/data storing (s)              0.00119406
time/evaluation sampling (s)       0.249281
time/exploration sampling (s)      0.0654351
time/logging (s)                   0.00338122
time/saving (s)                    0.00233187
time/training (s)                  0.969254
time/epoch (s)                     1.29088
time/total (s)                    87.8672
Epoch                             66
-----------------------------  --------------
2019-04-22 20:12:26.658222 PDT | [sac-pointmass-multitask-1_2019_04_22_20_10_57_0000--s-0] Epoch 67 finished
-----------------------------  --------------
replay_buffer/size             13800
trainer/QF1 Loss                   4.53223
trainer/QF2 Loss                   4.50698
trainer/Policy Loss               14.4976
trainer/Q1 Predictions Mean      -13.2076
trainer/Q1 Predictions Std         2.13445
trainer/Q1 Predictions Max       -12.328
trainer/Q1 Predictions Min       -26.2874
trainer/Q2 Predictions Mean      -13.1798
trainer/Q2 Predictions Std         2.1093
trainer/Q2 Predictions Max       -12.3124
trainer/Q2 Predictions Min       -25.7847
trainer/Q Targets Mean           -12.9121
trainer/Q Targets Std              3.07842
trainer/Q Targets Max             -0.286065
trainer/Q Targets Min            -26.8011
trainer/Log Pis Mean               1.67674
trainer/Log Pis Std                1.08263
trainer/Log Pis Max                6.30373
trainer/Log Pis Min               -0.825656
trainer/Policy mu Mean             0.0594886
trainer/Policy mu Std              0.639731
trainer/Policy mu Max              2.66185
trainer/Policy mu Min             -3.01345
trainer/Policy log std Mean       -1.98417
trainer/Policy log std Std         0.327602
trainer/Policy log std Max        -0.377038
trainer/Policy log std Min        -2.24344
trainer/Alpha                      0.0368591
trainer/Alpha Loss                -1.0669
exploration/num steps total    13800
exploration/num paths total      138
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.297148
exploration/Rewards Std            0.724873
exploration/Rewards Max           -0.00753251
exploration/Rewards Min           -5.34079
exploration/Returns Mean         -29.7148
exploration/Returns Std            0.459687
exploration/Returns Max          -29.2551
exploration/Returns Min          -30.1744
exploration/Actions Mean          -0.0443496
exploration/Actions Std            0.242937
exploration/Actions Max            0.458481
exploration/Actions Min           -0.997701
exploration/Num Paths              2
exploration/Average Returns      -29.7148
evaluation/num steps total     68000
evaluation/num paths total       680
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.104599
evaluation/Rewards Std             0.332943
evaluation/Rewards Max            -0.0213975
evaluation/Rewards Min            -4.35768
evaluation/Returns Mean          -10.4599
evaluation/Returns Std             2.93876
evaluation/Returns Max            -6.64825
evaluation/Returns Min           -17.0334
evaluation/Actions Mean            0.00369098
evaluation/Actions Std             0.140536
evaluation/Actions Max             0.993522
evaluation/Actions Min            -0.988416
evaluation/Num Paths              10
evaluation/Average Returns       -10.4599
time/data storing (s)              0.00125482
time/evaluation sampling (s)       0.253856
time/exploration sampling (s)      0.0680276
time/logging (s)                   0.00335186
time/saving (s)                    0.00233353
time/training (s)                  0.957943
time/epoch (s)                     1.28677
time/total (s)                    89.1582
Epoch                             67
-----------------------------  --------------
2019-04-22 20:12:27.966955 PDT | [sac-pointmass-multitask-1_2019_04_22_20_10_57_0000--s-0] Epoch 68 finished
-----------------------------  --------------
replay_buffer/size             14000
trainer/QF1 Loss                   1.50318
trainer/QF2 Loss                   1.50049
trainer/Policy Loss               14.4604
trainer/Q1 Predictions Mean      -12.8744
trainer/Q1 Predictions Std         1.8353
trainer/Q1 Predictions Max       -12.3116
trainer/Q1 Predictions Min       -28.0752
trainer/Q2 Predictions Mean      -12.8839
trainer/Q2 Predictions Std         1.83556
trainer/Q2 Predictions Max       -12.3258
trainer/Q2 Predictions Min       -28.2592
trainer/Q Targets Mean           -12.791
trainer/Q Targets Std              2.25368
trainer/Q Targets Max             -0.205968
trainer/Q Targets Min            -28.8633
trainer/Log Pis Mean               1.77719
trainer/Log Pis Std                1.08635
trainer/Log Pis Max                6.09912
trainer/Log Pis Min               -1.73927
trainer/Policy mu Mean             0.0948835
trainer/Policy mu Std              0.489412
trainer/Policy mu Max              3.03151
trainer/Policy mu Min             -2.46279
trainer/Policy log std Mean       -2.08802
trainer/Policy log std Std         0.250463
trainer/Policy log std Max        -0.743564
trainer/Policy log std Min        -2.26364
trainer/Alpha                      0.0359925
trainer/Alpha Loss                -0.740695
exploration/num steps total    14000
exploration/num paths total      140
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.268899
exploration/Rewards Std            0.577105
exploration/Rewards Max           -0.0253694
exploration/Rewards Min           -5.24046
exploration/Returns Mean         -26.8899
exploration/Returns Std            3.12614
exploration/Returns Max          -23.7637
exploration/Returns Min          -30.016
exploration/Actions Mean           0.0107496
exploration/Actions Std            0.236476
exploration/Actions Max            0.993697
exploration/Actions Min           -0.998056
exploration/Num Paths              2
exploration/Average Returns      -26.8899
evaluation/num steps total     69000
evaluation/num paths total       690
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.16424
evaluation/Rewards Std             0.449535
evaluation/Rewards Max            -0.0327879
evaluation/Rewards Min            -6.12837
evaluation/Returns Mean          -16.424
evaluation/Returns Std             4.52848
evaluation/Returns Max            -9.76698
evaluation/Returns Min           -26.9437
evaluation/Actions Mean            0.00114242
evaluation/Actions Std             0.157353
evaluation/Actions Max             0.995895
evaluation/Actions Min            -0.993677
evaluation/Num Paths              10
evaluation/Average Returns       -16.424
time/data storing (s)              0.00121655
time/evaluation sampling (s)       0.250056
time/exploration sampling (s)      0.0665258
time/logging (s)                   0.0030742
time/saving (s)                    0.00236339
time/training (s)                  0.979542
time/epoch (s)                     1.30278
time/total (s)                    90.4651
Epoch                             68
-----------------------------  --------------
2019-04-22 20:12:29.250897 PDT | [sac-pointmass-multitask-1_2019_04_22_20_10_57_0000--s-0] Epoch 69 finished
-----------------------------  --------------
replay_buffer/size             14200
trainer/QF1 Loss                   0.0668392
trainer/QF2 Loss                   0.0339574
trainer/Policy Loss               14.9532
trainer/Q1 Predictions Mean      -13.3204
trainer/Q1 Predictions Std         3.89623
trainer/Q1 Predictions Max       -12.1097
trainer/Q1 Predictions Min       -36.7801
trainer/Q2 Predictions Mean      -13.3732
trainer/Q2 Predictions Std         3.84452
trainer/Q2 Predictions Max       -12.1951
trainer/Q2 Predictions Min       -36.0913
trainer/Q Targets Mean           -13.4622
trainer/Q Targets Std              3.77043
trainer/Q Targets Max            -12.2025
trainer/Q Targets Min            -35.0551
trainer/Log Pis Mean               1.96156
trainer/Log Pis Std                1.63819
trainer/Log Pis Max                8.31415
trainer/Log Pis Min               -4.55642
trainer/Policy mu Mean            -0.0165612
trainer/Policy mu Std              0.734172
trainer/Policy mu Max              3.21543
trainer/Policy mu Min             -3.26027
trainer/Policy log std Mean       -2.05405
trainer/Policy log std Std         0.36271
trainer/Policy log std Max        -0.58597
trainer/Policy log std Min        -2.3328
trainer/Alpha                      0.0353204
trainer/Alpha Loss                -0.128503
exploration/num steps total    14200
exploration/num paths total      142
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.23028
exploration/Rewards Std            0.482146
exploration/Rewards Max           -0.00283037
exploration/Rewards Min           -4.77047
exploration/Returns Mean         -23.028
exploration/Returns Std            5.31069
exploration/Returns Max          -17.7173
exploration/Returns Min          -28.3387
exploration/Actions Mean          -0.0203871
exploration/Actions Std            0.206163
exploration/Actions Max            0.845421
exploration/Actions Min           -0.999474
exploration/Num Paths              2
exploration/Average Returns      -23.028
evaluation/num steps total     70000
evaluation/num paths total       700
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.219558
evaluation/Rewards Std             0.636387
evaluation/Rewards Max            -0.0300492
evaluation/Rewards Min            -7.38709
evaluation/Returns Mean          -21.9558
evaluation/Returns Std             6.45279
evaluation/Returns Max           -11.6436
evaluation/Returns Min           -34.2079
evaluation/Actions Mean            0.00261812
evaluation/Actions Std             0.184324
evaluation/Actions Max             0.997378
evaluation/Actions Min            -0.99779
evaluation/Num Paths              10
evaluation/Average Returns       -21.9558
time/data storing (s)              0.00122194
time/evaluation sampling (s)       0.243182
time/exploration sampling (s)      0.0656267
time/logging (s)                   0.00343377
time/saving (s)                    0.00232191
time/training (s)                  0.962771
time/epoch (s)                     1.27856
time/total (s)                    91.7477
Epoch                             69
-----------------------------  --------------
2019-04-22 20:12:30.552269 PDT | [sac-pointmass-multitask-1_2019_04_22_20_10_57_0000--s-0] Epoch 70 finished
-----------------------------  --------------
replay_buffer/size             14400
trainer/QF1 Loss                   0.104539
trainer/QF2 Loss                   0.0993527
trainer/Policy Loss               15.9478
trainer/Q1 Predictions Mean      -14.257
trainer/Q1 Predictions Std         5.88089
trainer/Q1 Predictions Max       -12.1516
trainer/Q1 Predictions Min       -42.5282
trainer/Q2 Predictions Mean      -14.3252
trainer/Q2 Predictions Std         5.88386
trainer/Q2 Predictions Max       -12.1973
trainer/Q2 Predictions Min       -42.4873
trainer/Q Targets Mean           -14.363
trainer/Q Targets Std              6.01557
trainer/Q Targets Max            -12.1365
trainer/Q Targets Min            -43.1944
trainer/Log Pis Mean               2.21161
trainer/Log Pis Std                1.71129
trainer/Log Pis Max                9.94676
trainer/Log Pis Min               -1.02416
trainer/Policy mu Mean             0.096081
trainer/Policy mu Std              0.957649
trainer/Policy mu Max              3.21868
trainer/Policy mu Min             -3.27074
trainer/Policy log std Mean       -1.92513
trainer/Policy log std Std         0.450463
trainer/Policy log std Max        -0.522852
trainer/Policy log std Min        -2.2801
trainer/Alpha                      0.0345652
trainer/Alpha Loss                 0.712021
exploration/num steps total    14400
exploration/num paths total      144
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.227181
exploration/Rewards Std            0.514477
exploration/Rewards Max           -0.0125469
exploration/Rewards Min           -4.88883
exploration/Returns Mean         -22.7181
exploration/Returns Std            6.495
exploration/Returns Max          -16.2231
exploration/Returns Min          -29.2131
exploration/Actions Mean          -0.0163811
exploration/Actions Std            0.214116
exploration/Actions Max            0.921906
exploration/Actions Min           -0.998622
exploration/Num Paths              2
exploration/Average Returns      -22.7181
evaluation/num steps total     71000
evaluation/num paths total       710
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.108617
evaluation/Rewards Std             0.458262
evaluation/Rewards Max            -0.00918233
evaluation/Rewards Min            -6.0776
evaluation/Returns Mean          -10.8617
evaluation/Returns Std             4.87893
evaluation/Returns Max            -4.35408
evaluation/Returns Min           -20.6137
evaluation/Actions Mean           -0.00505479
evaluation/Actions Std             0.159582
evaluation/Actions Max             0.997566
evaluation/Actions Min            -0.995755
evaluation/Num Paths              10
evaluation/Average Returns       -10.8617
time/data storing (s)              0.00122083
time/evaluation sampling (s)       0.251015
time/exploration sampling (s)      0.0676227
time/logging (s)                   0.00316987
time/saving (s)                    0.00214555
time/training (s)                  0.970693
time/epoch (s)                     1.29587
time/total (s)                    93.0473
Epoch                             70
-----------------------------  --------------
2019-04-22 20:12:31.855596 PDT | [sac-pointmass-multitask-1_2019_04_22_20_10_57_0000--s-0] Epoch 71 finished
-----------------------------  --------------
replay_buffer/size             14600
trainer/QF1 Loss                   2.85985
trainer/QF2 Loss                   2.86144
trainer/Policy Loss               14.2312
trainer/Q1 Predictions Mean      -12.8242
trainer/Q1 Predictions Std         1.56461
trainer/Q1 Predictions Max       -12.0486
trainer/Q1 Predictions Min       -21.9144
trainer/Q2 Predictions Mean      -12.8458
trainer/Q2 Predictions Std         1.55213
trainer/Q2 Predictions Max       -12.1117
trainer/Q2 Predictions Min       -22.0357
trainer/Q Targets Mean           -12.6534
trainer/Q Targets Std              2.26953
trainer/Q Targets Max             -0.501123
trainer/Q Targets Min            -22.1111
trainer/Log Pis Mean               1.77491
trainer/Log Pis Std                1.11922
trainer/Log Pis Max                6.52757
trainer/Log Pis Min               -1.46796
trainer/Policy mu Mean            -0.0438515
trainer/Policy mu Std              0.613869
trainer/Policy mu Max              2.625
trainer/Policy mu Min             -2.63075
trainer/Policy log std Mean       -2.03398
trainer/Policy log std Std         0.324746
trainer/Policy log std Max        -0.684924
trainer/Policy log std Min        -2.28778
trainer/Alpha                      0.0337894
trainer/Alpha Loss                -0.762483
exploration/num steps total    14600
exploration/num paths total      146
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.215745
exploration/Rewards Std            0.509875
exploration/Rewards Max           -0.00802478
exploration/Rewards Min           -5.03113
exploration/Returns Mean         -21.5745
exploration/Returns Std            7.80767
exploration/Returns Max          -13.7668
exploration/Returns Min          -29.3822
exploration/Actions Mean          -0.0090811
exploration/Actions Std            0.200889
exploration/Actions Max            0.94232
exploration/Actions Min           -0.999632
exploration/Num Paths              2
exploration/Average Returns      -21.5745
evaluation/num steps total     72000
evaluation/num paths total       720
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.157278
evaluation/Rewards Std             0.539882
evaluation/Rewards Max            -0.0578395
evaluation/Rewards Min            -6.6799
evaluation/Returns Mean          -15.7278
evaluation/Returns Std             5.59738
evaluation/Returns Max            -7.22149
evaluation/Returns Min           -26.3368
evaluation/Actions Mean           -0.00467047
evaluation/Actions Std             0.163882
evaluation/Actions Max             0.997058
evaluation/Actions Min            -0.997345
evaluation/Num Paths              10
evaluation/Average Returns       -15.7278
time/data storing (s)              0.00119934
time/evaluation sampling (s)       0.249507
time/exploration sampling (s)      0.0674248
time/logging (s)                   0.00336474
time/saving (s)                    0.00231197
time/training (s)                  0.973934
time/epoch (s)                     1.29774
time/total (s)                    94.3492
Epoch                             71
-----------------------------  --------------
2019-04-22 20:12:33.148602 PDT | [sac-pointmass-multitask-1_2019_04_22_20_10_57_0000--s-0] Epoch 72 finished
-----------------------------  --------------
replay_buffer/size             14800
trainer/QF1 Loss                   1.5034
trainer/QF2 Loss                   1.49004
trainer/Policy Loss               14.7424
trainer/Q1 Predictions Mean      -12.9656
trainer/Q1 Predictions Std         3.233
trainer/Q1 Predictions Max       -11.9598
trainer/Q1 Predictions Min       -35.2242
trainer/Q2 Predictions Mean      -13.0109
trainer/Q2 Predictions Std         3.23833
trainer/Q2 Predictions Max       -12.0021
trainer/Q2 Predictions Min       -35.2181
trainer/Q Targets Mean           -13.019
trainer/Q Targets Std              3.53364
trainer/Q Targets Max             -0.103862
trainer/Q Targets Min            -36.4631
trainer/Log Pis Mean               2.11958
trainer/Log Pis Std                1.3025
trainer/Log Pis Max                9.43535
trainer/Log Pis Min               -3.05324
trainer/Policy mu Mean             0.121483
trainer/Policy mu Std              0.692333
trainer/Policy mu Max              3.12121
trainer/Policy mu Min             -2.53107
trainer/Policy log std Mean       -2.08561
trainer/Policy log std Std         0.340497
trainer/Policy log std Max        -0.559752
trainer/Policy log std Min        -2.32906
trainer/Alpha                      0.0332807
trainer/Alpha Loss                 0.406901
exploration/num steps total    14800
exploration/num paths total      148
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.201582
exploration/Rewards Std            0.399968
exploration/Rewards Max           -0.00982334
exploration/Rewards Min           -4.55366
exploration/Returns Mean         -20.1582
exploration/Returns Std            4.50779
exploration/Returns Max          -15.6504
exploration/Returns Min          -24.666
exploration/Actions Mean          -0.0192228
exploration/Actions Std            0.203809
exploration/Actions Max            0.945713
exploration/Actions Min           -0.995814
exploration/Num Paths              2
exploration/Average Returns      -20.1582
evaluation/num steps total     73000
evaluation/num paths total       730
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.19339
evaluation/Rewards Std             0.553575
evaluation/Rewards Max            -0.0244549
evaluation/Rewards Min            -5.56443
evaluation/Returns Mean          -19.339
evaluation/Returns Std             4.78757
evaluation/Returns Max           -10.0545
evaluation/Returns Min           -25.6236
evaluation/Actions Mean           -0.0108287
evaluation/Actions Std             0.161943
evaluation/Actions Max             0.998435
evaluation/Actions Min            -0.997091
evaluation/Num Paths              10
evaluation/Average Returns       -19.339
time/data storing (s)              0.00115153
time/evaluation sampling (s)       0.24824
time/exploration sampling (s)      0.0660485
time/logging (s)                   0.0034385
time/saving (s)                    0.00209934
time/training (s)                  0.96631
time/epoch (s)                     1.28729
time/total (s)                    95.6406
Epoch                             72
-----------------------------  --------------
2019-04-22 20:12:34.463081 PDT | [sac-pointmass-multitask-1_2019_04_22_20_10_57_0000--s-0] Epoch 73 finished
-----------------------------  --------------
replay_buffer/size             15000
trainer/QF1 Loss                   4.31895
trainer/QF2 Loss                   4.30031
trainer/Policy Loss               15.2782
trainer/Q1 Predictions Mean      -13.9304
trainer/Q1 Predictions Std         5.02159
trainer/Q1 Predictions Max       -11.8966
trainer/Q1 Predictions Min       -35.8924
trainer/Q2 Predictions Mean      -13.9612
trainer/Q2 Predictions Std         5.0789
trainer/Q2 Predictions Max       -11.9082
trainer/Q2 Predictions Min       -36.3266
trainer/Q Targets Mean           -13.7915
trainer/Q Targets Std              5.70046
trainer/Q Targets Max             -0.0905146
trainer/Q Targets Min            -36.0611
trainer/Log Pis Mean               2.08412
trainer/Log Pis Std                1.55998
trainer/Log Pis Max                9.4999
trainer/Log Pis Min               -1.71144
trainer/Policy mu Mean            -0.018248
trainer/Policy mu Std              0.929898
trainer/Policy mu Max              3.19986
trainer/Policy mu Min             -3.32515
trainer/Policy log std Mean       -1.9627
trainer/Policy log std Std         0.490778
trainer/Policy log std Max        -0.364087
trainer/Policy log std Min        -2.35976
trainer/Alpha                      0.0331111
trainer/Alpha Loss                 0.286679
exploration/num steps total    15000
exploration/num paths total      150
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.197136
exploration/Rewards Std            0.399991
exploration/Rewards Max           -0.0102382
exploration/Rewards Min           -4.48916
exploration/Returns Mean         -19.7136
exploration/Returns Std            3.85075
exploration/Returns Max          -15.8629
exploration/Returns Min          -23.5644
exploration/Actions Mean           0.0223002
exploration/Actions Std            0.203093
exploration/Actions Max            0.983552
exploration/Actions Min           -0.444193
exploration/Num Paths              2
exploration/Average Returns      -19.7136
evaluation/num steps total     74000
evaluation/num paths total       740
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.154638
evaluation/Rewards Std             0.517633
evaluation/Rewards Max            -0.050556
evaluation/Rewards Min            -5.21742
evaluation/Returns Mean          -15.4638
evaluation/Returns Std             3.98014
evaluation/Returns Max            -9.66276
evaluation/Returns Min           -22.517
evaluation/Actions Mean            0.00181905
evaluation/Actions Std             0.166783
evaluation/Actions Max             0.997119
evaluation/Actions Min            -0.997175
evaluation/Num Paths              10
evaluation/Average Returns       -15.4638
time/data storing (s)              0.00141015
time/evaluation sampling (s)       0.256906
time/exploration sampling (s)      0.0666989
time/logging (s)                   0.00290534
time/saving (s)                    0.00231306
time/training (s)                  0.977967
time/epoch (s)                     1.3082
time/total (s)                    96.9528
Epoch                             73
-----------------------------  --------------
2019-04-22 20:12:35.772020 PDT | [sac-pointmass-multitask-1_2019_04_22_20_10_57_0000--s-0] Epoch 74 finished
-----------------------------  --------------
replay_buffer/size             15200
trainer/QF1 Loss                   0.0560798
trainer/QF2 Loss                   0.0523758
trainer/Policy Loss               14.6666
trainer/Q1 Predictions Mean      -12.7852
trainer/Q1 Predictions Std         3.71493
trainer/Q1 Predictions Max       -11.7882
trainer/Q1 Predictions Min       -37.8985
trainer/Q2 Predictions Mean      -12.824
trainer/Q2 Predictions Std         3.67266
trainer/Q2 Predictions Max       -11.8094
trainer/Q2 Predictions Min       -37.5815
trainer/Q Targets Mean           -12.9897
trainer/Q Targets Std              3.71373
trainer/Q Targets Max            -11.901
trainer/Q Targets Min            -38.4835
trainer/Log Pis Mean               2.19456
trainer/Log Pis Std                1.33824
trainer/Log Pis Max                8.81382
trainer/Log Pis Min               -0.936856
trainer/Policy mu Mean            -0.0998081
trainer/Policy mu Std              0.669494
trainer/Policy mu Max              2.48073
trainer/Policy mu Min             -3.17174
trainer/Policy log std Mean       -2.11508
trainer/Policy log std Std         0.365322
trainer/Policy log std Max        -0.616036
trainer/Policy log std Min        -2.36502
trainer/Alpha                      0.0328752
trainer/Alpha Loss                 0.664437
exploration/num steps total    15200
exploration/num paths total      152
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.26222
exploration/Rewards Std            0.654616
exploration/Rewards Max           -0.0179627
exploration/Rewards Min           -4.79358
exploration/Returns Mean         -26.222
exploration/Returns Std            0.282546
exploration/Returns Max          -25.9395
exploration/Returns Min          -26.5046
exploration/Actions Mean          -0.0291654
exploration/Actions Std            0.232251
exploration/Actions Max            0.971719
exploration/Actions Min           -0.999284
exploration/Num Paths              2
exploration/Average Returns      -26.222
evaluation/num steps total     75000
evaluation/num paths total       750
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.145997
evaluation/Rewards Std             0.543821
evaluation/Rewards Max            -0.0288269
evaluation/Rewards Min            -6.01066
evaluation/Returns Mean          -14.5997
evaluation/Returns Std             3.33415
evaluation/Returns Max            -9.46646
evaluation/Returns Min           -21.9643
evaluation/Actions Mean            0.0155661
evaluation/Actions Std             0.181716
evaluation/Actions Max             0.994839
evaluation/Actions Min            -0.994452
evaluation/Num Paths              10
evaluation/Average Returns       -14.5997
time/data storing (s)              0.00118223
time/evaluation sampling (s)       0.248876
time/exploration sampling (s)      0.0680335
time/logging (s)                   0.00264529
time/saving (s)                    0.002093
time/training (s)                  0.980501
time/epoch (s)                     1.30333
time/total (s)                    98.2601
Epoch                             74
-----------------------------  --------------
2019-04-22 20:12:37.087836 PDT | [sac-pointmass-multitask-1_2019_04_22_20_10_57_0000--s-0] Epoch 75 finished
-----------------------------  --------------
replay_buffer/size             15400
trainer/QF1 Loss                   0.022309
trainer/QF2 Loss                   0.0200289
trainer/Policy Loss               14.6396
trainer/Q1 Predictions Mean      -12.9473
trainer/Q1 Predictions Std         3.0993
trainer/Q1 Predictions Max       -11.9341
trainer/Q1 Predictions Min       -32.3385
trainer/Q2 Predictions Mean      -12.9198
trainer/Q2 Predictions Std         3.11017
trainer/Q2 Predictions Max       -11.8985
trainer/Q2 Predictions Min       -32.4309
trainer/Q Targets Mean           -12.957
trainer/Q Targets Std              3.03875
trainer/Q Targets Max            -11.8472
trainer/Q Targets Min            -32.398
trainer/Log Pis Mean               2.0233
trainer/Log Pis Std                1.37433
trainer/Log Pis Max                7.72286
trainer/Log Pis Min               -1.32592
trainer/Policy mu Mean            -0.0886826
trainer/Policy mu Std              0.714169
trainer/Policy mu Max              2.97089
trainer/Policy mu Min             -2.95495
trainer/Policy log std Mean       -2.04777
trainer/Policy log std Std         0.381391
trainer/Policy log std Max        -0.424753
trainer/Policy log std Min        -2.35715
trainer/Alpha                      0.0327373
trainer/Alpha Loss                 0.0796608
exploration/num steps total    15400
exploration/num paths total      154
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.221888
exploration/Rewards Std            0.515092
exploration/Rewards Max           -0.00932861
exploration/Rewards Min           -5.35587
exploration/Returns Mean         -22.1888
exploration/Returns Std            4.80261
exploration/Returns Max          -17.3862
exploration/Returns Min          -26.9914
exploration/Actions Mean          -0.00920135
exploration/Actions Std            0.224595
exploration/Actions Max            0.996648
exploration/Actions Min           -0.997231
exploration/Num Paths              2
exploration/Average Returns      -22.1888
evaluation/num steps total     76000
evaluation/num paths total       760
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.117168
evaluation/Rewards Std             0.336528
evaluation/Rewards Max            -0.018575
evaluation/Rewards Min            -4.52163
evaluation/Returns Mean          -11.7168
evaluation/Returns Std             3.64405
evaluation/Returns Max            -7.71819
evaluation/Returns Min           -19.4981
evaluation/Actions Mean           -0.00326915
evaluation/Actions Std             0.141086
evaluation/Actions Max             0.988553
evaluation/Actions Min            -0.996354
evaluation/Num Paths              10
evaluation/Average Returns       -11.7168
time/data storing (s)              0.00137
time/evaluation sampling (s)       0.260944
time/exploration sampling (s)      0.0688523
time/logging (s)                   0.00338021
time/saving (s)                    0.00181483
time/training (s)                  0.975224
time/epoch (s)                     1.31159
time/total (s)                    99.5755
Epoch                             75
-----------------------------  --------------
2019-04-22 20:12:38.385748 PDT | [sac-pointmass-multitask-1_2019_04_22_20_10_57_0000--s-0] Epoch 76 finished
-----------------------------  --------------
replay_buffer/size             15600
trainer/QF1 Loss                   0.0469274
trainer/QF2 Loss                   0.0445686
trainer/Policy Loss               14.2129
trainer/Q1 Predictions Mean      -12.4557
trainer/Q1 Predictions Std         2.24312
trainer/Q1 Predictions Max       -11.6683
trainer/Q1 Predictions Min       -26.9244
trainer/Q2 Predictions Mean      -12.4612
trainer/Q2 Predictions Std         2.22352
trainer/Q2 Predictions Max       -11.7168
trainer/Q2 Predictions Min       -26.9665
trainer/Q Targets Mean           -12.6452
trainer/Q Targets Std              2.18871
trainer/Q Targets Max            -11.8084
trainer/Q Targets Min            -26.6821
trainer/Log Pis Mean               2.09825
trainer/Log Pis Std                1.28614
trainer/Log Pis Max                6.67179
trainer/Log Pis Min               -2.02563
trainer/Policy mu Mean             0.0807202
trainer/Policy mu Std              0.642143
trainer/Policy mu Max              2.87164
trainer/Policy mu Min             -2.41861
trainer/Policy log std Mean       -2.12185
trainer/Policy log std Std         0.353343
trainer/Policy log std Max        -0.674941
trainer/Policy log std Min        -2.39475
trainer/Alpha                      0.0325483
trainer/Alpha Loss                 0.336527
exploration/num steps total    15600
exploration/num paths total      156
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.232155
exploration/Rewards Std            0.618829
exploration/Rewards Max           -0.00488638
exploration/Rewards Min           -5.87521
exploration/Returns Mean         -23.2155
exploration/Returns Std            5.59488
exploration/Returns Max          -17.6206
exploration/Returns Min          -28.8104
exploration/Actions Mean          -0.0361309
exploration/Actions Std            0.216256
exploration/Actions Max            0.412499
exploration/Actions Min           -0.997273
exploration/Num Paths              2
exploration/Average Returns      -23.2155
evaluation/num steps total     77000
evaluation/num paths total       770
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.125608
evaluation/Rewards Std             0.513644
evaluation/Rewards Max            -0.015309
evaluation/Rewards Min            -5.72407
evaluation/Returns Mean          -12.5608
evaluation/Returns Std             6.2503
evaluation/Returns Max            -4.69342
evaluation/Returns Min           -20.3847
evaluation/Actions Mean            0.00347938
evaluation/Actions Std             0.156078
evaluation/Actions Max             0.996806
evaluation/Actions Min            -0.998114
evaluation/Num Paths              10
evaluation/Average Returns       -12.5608
time/data storing (s)              0.00138422
time/evaluation sampling (s)       0.249448
time/exploration sampling (s)      0.0678156
time/logging (s)                   0.00336115
time/saving (s)                    0.00234914
time/training (s)                  0.967767
time/epoch (s)                     1.29213
time/total (s)                   100.872
Epoch                             76
-----------------------------  --------------
2019-04-22 20:12:39.696726 PDT | [sac-pointmass-multitask-1_2019_04_22_20_10_57_0000--s-0] Epoch 77 finished
-----------------------------  --------------
replay_buffer/size             15800
trainer/QF1 Loss                   0.120131
trainer/QF2 Loss                   0.0781655
trainer/Policy Loss               14.8173
trainer/Q1 Predictions Mean      -12.9979
trainer/Q1 Predictions Std         3.76586
trainer/Q1 Predictions Max       -11.805
trainer/Q1 Predictions Min       -46.079
trainer/Q2 Predictions Mean      -12.9833
trainer/Q2 Predictions Std         3.71136
trainer/Q2 Predictions Max       -11.7972
trainer/Q2 Predictions Min       -45.3269
trainer/Q Targets Mean           -12.9277
trainer/Q Targets Std              3.46786
trainer/Q Targets Max            -11.7294
trainer/Q Targets Min            -42.9276
trainer/Log Pis Mean               2.27472
trainer/Log Pis Std                1.3342
trainer/Log Pis Max                8.00182
trainer/Log Pis Min               -1.09707
trainer/Policy mu Mean            -0.0855426
trainer/Policy mu Std              0.758917
trainer/Policy mu Max              3.32019
trainer/Policy mu Min             -2.87039
trainer/Policy log std Mean       -2.11273
trainer/Policy log std Std         0.414142
trainer/Policy log std Max        -0.682804
trainer/Policy log std Min        -2.41277
trainer/Alpha                      0.0327853
trainer/Alpha Loss                 0.93895
exploration/num steps total    15800
exploration/num paths total      158
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.246123
exploration/Rewards Std            0.360186
exploration/Rewards Max           -0.0208812
exploration/Rewards Min           -3.68172
exploration/Returns Mean         -24.6123
exploration/Returns Std            3.08095
exploration/Returns Max          -21.5314
exploration/Returns Min          -27.6933
exploration/Actions Mean          -0.0106041
exploration/Actions Std            0.18654
exploration/Actions Max            0.979449
exploration/Actions Min           -0.99404
exploration/Num Paths              2
exploration/Average Returns      -24.6123
evaluation/num steps total     78000
evaluation/num paths total       780
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.274355
evaluation/Rewards Std             0.571945
evaluation/Rewards Max            -0.171968
evaluation/Rewards Min            -5.63398
evaluation/Returns Mean          -27.4355
evaluation/Returns Std             4.90861
evaluation/Returns Max           -18.0109
evaluation/Returns Min           -32.8234
evaluation/Actions Mean           -0.00101731
evaluation/Actions Std             0.168183
evaluation/Actions Max             0.997901
evaluation/Actions Min            -0.997455
evaluation/Num Paths              10
evaluation/Average Returns       -27.4355
time/data storing (s)              0.00120496
time/evaluation sampling (s)       0.250165
time/exploration sampling (s)      0.0667054
time/logging (s)                   0.00347905
time/saving (s)                    0.00228728
time/training (s)                  0.98149
time/epoch (s)                     1.30533
time/total (s)                   102.181
Epoch                             77
-----------------------------  --------------
2019-04-22 20:12:41.009927 PDT | [sac-pointmass-multitask-1_2019_04_22_20_10_57_0000--s-0] Epoch 78 finished
-----------------------------  --------------
replay_buffer/size             16000
trainer/QF1 Loss                   2.71453
trainer/QF2 Loss                   2.69644
trainer/Policy Loss               14.0673
trainer/Q1 Predictions Mean      -12.4081
trainer/Q1 Predictions Std         2.65733
trainer/Q1 Predictions Max       -11.6547
trainer/Q1 Predictions Min       -33.4217
trainer/Q2 Predictions Mean      -12.3784
trainer/Q2 Predictions Std         2.68252
trainer/Q2 Predictions Max       -11.636
trainer/Q2 Predictions Min       -33.7614
trainer/Q Targets Mean           -12.2746
trainer/Q Targets Std              3.2041
trainer/Q Targets Max             -0.313349
trainer/Q Targets Min            -33.311
trainer/Log Pis Mean               1.92008
trainer/Log Pis Std                1.34973
trainer/Log Pis Max                6.86591
trainer/Log Pis Min               -1.52428
trainer/Policy mu Mean            -0.0213523
trainer/Policy mu Std              0.638158
trainer/Policy mu Max              2.99467
trainer/Policy mu Min             -2.5259
trainer/Policy log std Mean       -2.09359
trainer/Policy log std Std         0.350025
trainer/Policy log std Max        -0.549841
trainer/Policy log std Min        -2.36403
trainer/Alpha                      0.0325716
trainer/Alpha Loss                -0.273681
exploration/num steps total    16000
exploration/num paths total      160
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.197986
exploration/Rewards Std            0.425098
exploration/Rewards Max           -0.00346136
exploration/Rewards Min           -4.26761
exploration/Returns Mean         -19.7986
exploration/Returns Std            4.20619
exploration/Returns Max          -15.5924
exploration/Returns Min          -24.0048
exploration/Actions Mean          -0.0119071
exploration/Actions Std            0.200052
exploration/Actions Max            0.989982
exploration/Actions Min           -0.998517
exploration/Num Paths              2
exploration/Average Returns      -19.7986
evaluation/num steps total     79000
evaluation/num paths total       790
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.113199
evaluation/Rewards Std             0.522563
evaluation/Rewards Max            -0.00280884
evaluation/Rewards Min            -5.46709
evaluation/Returns Mean          -11.3199
evaluation/Returns Std             3.80613
evaluation/Returns Max            -4.70997
evaluation/Returns Min           -16.3315
evaluation/Actions Mean           -0.00631993
evaluation/Actions Std             0.162088
evaluation/Actions Max             0.996785
evaluation/Actions Min            -0.996543
evaluation/Num Paths              10
evaluation/Average Returns       -11.3199
time/data storing (s)              0.00121039
time/evaluation sampling (s)       0.253392
time/exploration sampling (s)      0.068502
time/logging (s)                   0.00350019
time/saving (s)                    0.0022638
time/training (s)                  0.978465
time/epoch (s)                     1.30733
time/total (s)                   103.493
Epoch                             78
-----------------------------  --------------
2019-04-22 20:12:42.336416 PDT | [sac-pointmass-multitask-1_2019_04_22_20_10_57_0000--s-0] Epoch 79 finished
-----------------------------  --------------
replay_buffer/size             16200
trainer/QF1 Loss                   1.51873
trainer/QF2 Loss                   1.46072
trainer/Policy Loss               14.4985
trainer/Q1 Predictions Mean      -13.1166
trainer/Q1 Predictions Std         4.86688
trainer/Q1 Predictions Max       -11.5728
trainer/Q1 Predictions Min       -45.7442
trainer/Q2 Predictions Mean      -13.1337
trainer/Q2 Predictions Std         4.82148
trainer/Q2 Predictions Max       -11.5928
trainer/Q2 Predictions Min       -44.8667
trainer/Q Targets Mean           -13.1164
trainer/Q Targets Std              4.8818
trainer/Q Targets Max             -0.615477
trainer/Q Targets Min            -42.5429
trainer/Log Pis Mean               1.97496
trainer/Log Pis Std                1.25427
trainer/Log Pis Max                5.48777
trainer/Log Pis Min               -2.85386
trainer/Policy mu Mean            -0.0432187
trainer/Policy mu Std              0.766228
trainer/Policy mu Max              3.18361
trainer/Policy mu Min             -3.10288
trainer/Policy log std Mean       -2.05946
trainer/Policy log std Std         0.401644
trainer/Policy log std Max        -0.418753
trainer/Policy log std Min        -2.38076
trainer/Alpha                      0.0323941
trainer/Alpha Loss                -0.0858774
exploration/num steps total    16200
exploration/num paths total      162
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.248635
exploration/Rewards Std            0.653432
exploration/Rewards Max           -0.00324098
exploration/Rewards Min           -6.08216
exploration/Returns Mean         -24.8635
exploration/Returns Std            4.3329
exploration/Returns Max          -20.5306
exploration/Returns Min          -29.1963
exploration/Actions Mean           0.0164701
exploration/Actions Std            0.23251
exploration/Actions Max            0.996174
exploration/Actions Min           -0.987081
exploration/Num Paths              2
exploration/Average Returns      -24.8635
evaluation/num steps total     80000
evaluation/num paths total       800
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.155277
evaluation/Rewards Std             0.610528
evaluation/Rewards Max            -0.0508346
evaluation/Rewards Min            -6.15268
evaluation/Returns Mean          -15.5277
evaluation/Returns Std             6.63791
evaluation/Returns Max            -5.57856
evaluation/Returns Min           -23.1492
evaluation/Actions Mean            0.00404121
evaluation/Actions Std             0.17384
evaluation/Actions Max             0.997036
evaluation/Actions Min            -0.997849
evaluation/Num Paths              10
evaluation/Average Returns       -15.5277
time/data storing (s)              0.00118333
time/evaluation sampling (s)       0.250009
time/exploration sampling (s)      0.0693257
time/logging (s)                   0.00338494
time/saving (s)                    0.0109059
time/training (s)                  0.985561
time/epoch (s)                     1.32037
time/total (s)                   104.817
Epoch                             79
-----------------------------  --------------
2019-04-22 20:12:43.648799 PDT | [sac-pointmass-multitask-1_2019_04_22_20_10_57_0000--s-0] Epoch 80 finished
-----------------------------  ---------------
replay_buffer/size             16400
trainer/QF1 Loss                   2.69559
trainer/QF2 Loss                   2.64814
trainer/Policy Loss               14.7521
trainer/Q1 Predictions Mean      -12.8651
trainer/Q1 Predictions Std         4.07468
trainer/Q1 Predictions Max       -11.4188
trainer/Q1 Predictions Min       -37.1012
trainer/Q2 Predictions Mean      -12.9075
trainer/Q2 Predictions Std         4.09923
trainer/Q2 Predictions Max       -11.4417
trainer/Q2 Predictions Min       -36.4614
trainer/Q Targets Mean           -12.7793
trainer/Q Targets Std              4.33157
trainer/Q Targets Max             -0.481936
trainer/Q Targets Min            -34.6688
trainer/Log Pis Mean               2.3828
trainer/Log Pis Std                1.60371
trainer/Log Pis Max                8.66069
trainer/Log Pis Min               -1.67817
trainer/Policy mu Mean            -0.0907275
trainer/Policy mu Std              0.787334
trainer/Policy mu Max              3.13285
trainer/Policy mu Min             -3.41663
trainer/Policy log std Mean       -2.21017
trainer/Policy log std Std         0.453065
trainer/Policy log std Max        -0.53509
trainer/Policy log std Min        -2.53272
trainer/Alpha                      0.0326472
trainer/Alpha Loss                 1.30997
exploration/num steps total    16400
exploration/num paths total      164
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.164678
exploration/Rewards Std            0.144824
exploration/Rewards Max           -0.00111026
exploration/Rewards Min           -1.5921
exploration/Returns Mean         -16.4678
exploration/Returns Std            0.111206
exploration/Returns Max          -16.3566
exploration/Returns Min          -16.579
exploration/Actions Mean          -0.000809171
exploration/Actions Std            0.167159
exploration/Actions Max            0.980548
exploration/Actions Min           -0.971909
exploration/Num Paths              2
exploration/Average Returns      -16.4678
evaluation/num steps total     81000
evaluation/num paths total       810
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.20931
evaluation/Rewards Std             0.573471
evaluation/Rewards Max            -0.0355784
evaluation/Rewards Min            -6.52939
evaluation/Returns Mean          -20.931
evaluation/Returns Std             6.21776
evaluation/Returns Max           -11.6476
evaluation/Returns Min           -30.5904
evaluation/Actions Mean           -0.0128022
evaluation/Actions Std             0.167122
evaluation/Actions Max             0.995601
evaluation/Actions Min            -0.997762
evaluation/Num Paths              10
evaluation/Average Returns       -20.931
time/data storing (s)              0.00122006
time/evaluation sampling (s)       0.252838
time/exploration sampling (s)      0.0667464
time/logging (s)                   0.00340616
time/saving (s)                    0.00242737
time/training (s)                  0.97955
time/epoch (s)                     1.30619
time/total (s)                   106.128
Epoch                             80
-----------------------------  ---------------
2019-04-22 20:12:44.952387 PDT | [sac-pointmass-multitask-1_2019_04_22_20_10_57_0000--s-0] Epoch 81 finished
-----------------------------  --------------
replay_buffer/size             16600
trainer/QF1 Loss                   1.75486
trainer/QF2 Loss                   1.57157
trainer/Policy Loss               14.396
trainer/Q1 Predictions Mean      -12.614
trainer/Q1 Predictions Std         3.08271
trainer/Q1 Predictions Max       -11.5529
trainer/Q1 Predictions Min       -32.7634
trainer/Q2 Predictions Mean      -12.6586
trainer/Q2 Predictions Std         3.09372
trainer/Q2 Predictions Max       -11.6125
trainer/Q2 Predictions Min       -32.6773
trainer/Q Targets Mean           -12.4892
trainer/Q Targets Std              3.41429
trainer/Q Targets Max             -2.69405
trainer/Q Targets Min            -32.7237
trainer/Log Pis Mean               2.07699
trainer/Log Pis Std                1.4855
trainer/Log Pis Max                7.53637
trainer/Log Pis Min               -4.21502
trainer/Policy mu Mean             0.0652619
trainer/Policy mu Std              0.704959
trainer/Policy mu Max              3.36154
trainer/Policy mu Min             -2.89938
trainer/Policy log std Mean       -2.13665
trainer/Policy log std Std         0.391484
trainer/Policy log std Max        -0.628369
trainer/Policy log std Min        -2.42891
trainer/Alpha                      0.0329454
trainer/Alpha Loss                 0.262755
exploration/num steps total    16600
exploration/num paths total      166
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.217773
exploration/Rewards Std            0.507845
exploration/Rewards Max           -0.00725975
exploration/Rewards Min           -5.16345
exploration/Returns Mean         -21.7773
exploration/Returns Std            5.92205
exploration/Returns Max          -15.8552
exploration/Returns Min          -27.6993
exploration/Actions Mean          -0.0152672
exploration/Actions Std            0.206223
exploration/Actions Max            0.965499
exploration/Actions Min           -0.999638
exploration/Num Paths              2
exploration/Average Returns      -21.7773
evaluation/num steps total     82000
evaluation/num paths total       820
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.131168
evaluation/Rewards Std             0.401711
evaluation/Rewards Max            -0.0173443
evaluation/Rewards Min            -5.43793
evaluation/Returns Mean          -13.1168
evaluation/Returns Std             4.48379
evaluation/Returns Max            -8.10079
evaluation/Returns Min           -22.5743
evaluation/Actions Mean           -0.00850577
evaluation/Actions Std             0.147416
evaluation/Actions Max             0.997313
evaluation/Actions Min            -0.995866
evaluation/Num Paths              10
evaluation/Average Returns       -13.1168
time/data storing (s)              0.00119732
time/evaluation sampling (s)       0.25172
time/exploration sampling (s)      0.0681896
time/logging (s)                   0.0033788
time/saving (s)                    0.00249462
time/training (s)                  0.970184
time/epoch (s)                     1.29716
time/total (s)                   107.43
Epoch                             81
-----------------------------  --------------
2019-04-22 20:12:46.262830 PDT | [sac-pointmass-multitask-1_2019_04_22_20_10_57_0000--s-0] Epoch 82 finished
-----------------------------  ---------------
replay_buffer/size             16800
trainer/QF1 Loss                   1.31539
trainer/QF2 Loss                   1.3275
trainer/Policy Loss               13.9022
trainer/Q1 Predictions Mean      -12.3547
trainer/Q1 Predictions Std         3.61527
trainer/Q1 Predictions Max       -11.4009
trainer/Q1 Predictions Min       -39.7457
trainer/Q2 Predictions Mean      -12.3127
trainer/Q2 Predictions Std         3.64827
trainer/Q2 Predictions Max       -11.3512
trainer/Q2 Predictions Min       -40.3042
trainer/Q Targets Mean           -12.3491
trainer/Q Targets Std              3.90206
trainer/Q Targets Max             -0.14758
trainer/Q Targets Min            -40.6148
trainer/Log Pis Mean               1.99717
trainer/Log Pis Std                1.42485
trainer/Log Pis Max                8.30784
trainer/Log Pis Min               -4.40378
trainer/Policy mu Mean             0.0546682
trainer/Policy mu Std              0.578035
trainer/Policy mu Max              3.25242
trainer/Policy mu Min             -2.83793
trainer/Policy log std Mean       -2.14453
trainer/Policy log std Std         0.35202
trainer/Policy log std Max        -0.459046
trainer/Policy log std Min        -2.39087
trainer/Alpha                      0.0330997
trainer/Alpha Loss                -0.0096517
exploration/num steps total    16800
exploration/num paths total      168
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.213918
exploration/Rewards Std            0.441733
exploration/Rewards Max           -0.00992613
exploration/Rewards Min           -3.74943
exploration/Returns Mean         -21.3918
exploration/Returns Std            1.07687
exploration/Returns Max          -20.3149
exploration/Returns Min          -22.4687
exploration/Actions Mean           0.000843818
exploration/Actions Std            0.205679
exploration/Actions Max            0.997613
exploration/Actions Min           -0.997478
exploration/Num Paths              2
exploration/Average Returns      -21.3918
evaluation/num steps total     83000
evaluation/num paths total       830
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.146371
evaluation/Rewards Std             0.589735
evaluation/Rewards Max            -0.0339942
evaluation/Rewards Min            -5.69643
evaluation/Returns Mean          -14.6371
evaluation/Returns Std             4.73927
evaluation/Returns Max            -4.47511
evaluation/Returns Min           -20.5363
evaluation/Actions Mean           -0.0140973
evaluation/Actions Std             0.168506
evaluation/Actions Max             0.997734
evaluation/Actions Min            -0.997951
evaluation/Num Paths              10
evaluation/Average Returns       -14.6371
time/data storing (s)              0.00119731
time/evaluation sampling (s)       0.248544
time/exploration sampling (s)      0.0675114
time/logging (s)                   0.003451
time/saving (s)                    0.00230481
time/training (s)                  0.981314
time/epoch (s)                     1.30432
time/total (s)                   108.738
Epoch                             82
-----------------------------  ---------------
2019-04-22 20:12:47.577142 PDT | [sac-pointmass-multitask-1_2019_04_22_20_10_57_0000--s-0] Epoch 83 finished
-----------------------------  --------------
replay_buffer/size             17000
trainer/QF1 Loss                   0.0384453
trainer/QF2 Loss                   0.0567986
trainer/Policy Loss               13.7983
trainer/Q1 Predictions Mean      -12.0632
trainer/Q1 Predictions Std         2.76803
trainer/Q1 Predictions Max       -11.247
trainer/Q1 Predictions Min       -30.7438
trainer/Q2 Predictions Mean      -12.0223
trainer/Q2 Predictions Std         2.79199
trainer/Q2 Predictions Max       -11.1994
trainer/Q2 Predictions Min       -30.8548
trainer/Q Targets Mean           -12.2202
trainer/Q Targets Std              2.74832
trainer/Q Targets Max            -11.2988
trainer/Q Targets Min            -30.4529
trainer/Log Pis Mean               1.9336
trainer/Log Pis Std                1.40789
trainer/Log Pis Max                8.85223
trainer/Log Pis Min               -1.18915
trainer/Policy mu Mean            -0.0207664
trainer/Policy mu Std              0.651683
trainer/Policy mu Max              3.49393
trainer/Policy mu Min             -3.27587
trainer/Policy log std Mean       -2.11564
trainer/Policy log std Std         0.353855
trainer/Policy log std Max        -0.468194
trainer/Policy log std Min        -2.38324
trainer/Alpha                      0.0333008
trainer/Alpha Loss                -0.22591
exploration/num steps total    17000
exploration/num paths total      170
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.238885
exploration/Rewards Std            0.547689
exploration/Rewards Max           -0.0196066
exploration/Rewards Min           -4.25652
exploration/Returns Mean         -23.8885
exploration/Returns Std            0.79731
exploration/Returns Max          -23.0912
exploration/Returns Min          -24.6858
exploration/Actions Mean           0.00107515
exploration/Actions Std            0.205842
exploration/Actions Max            0.996103
exploration/Actions Min           -0.994854
exploration/Num Paths              2
exploration/Average Returns      -23.8885
evaluation/num steps total     84000
evaluation/num paths total       840
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.12009
evaluation/Rewards Std             0.539732
evaluation/Rewards Max            -0.028366
evaluation/Rewards Min            -6.84936
evaluation/Returns Mean          -12.009
evaluation/Returns Std             6.01357
evaluation/Returns Max            -3.60787
evaluation/Returns Min           -24.0019
evaluation/Actions Mean           -0.00580961
evaluation/Actions Std             0.163961
evaluation/Actions Max             0.99823
evaluation/Actions Min            -0.997478
evaluation/Num Paths              10
evaluation/Average Returns       -12.009
time/data storing (s)              0.00120429
time/evaluation sampling (s)       0.251899
time/exploration sampling (s)      0.0660115
time/logging (s)                   0.00324881
time/saving (s)                    0.00220022
time/training (s)                  0.983388
time/epoch (s)                     1.30795
time/total (s)                   110.051
Epoch                             83
-----------------------------  --------------
2019-04-22 20:12:48.871624 PDT | [sac-pointmass-multitask-1_2019_04_22_20_10_57_0000--s-0] Epoch 84 finished
-----------------------------  --------------
replay_buffer/size             17200
trainer/QF1 Loss                   1.3505
trainer/QF2 Loss                   1.34959
trainer/Policy Loss               14.4182
trainer/Q1 Predictions Mean      -13.1038
trainer/Q1 Predictions Std         4.74065
trainer/Q1 Predictions Max       -11.2184
trainer/Q1 Predictions Min       -36.6533
trainer/Q2 Predictions Mean      -13.17
trainer/Q2 Predictions Std         4.78205
trainer/Q2 Predictions Max       -11.297
trainer/Q2 Predictions Min       -36.6971
trainer/Q Targets Mean           -13.0729
trainer/Q Targets Std              4.78426
trainer/Q Targets Max             -0.213486
trainer/Q Targets Min            -33.902
trainer/Log Pis Mean               1.8474
trainer/Log Pis Std                1.65235
trainer/Log Pis Max                7.52305
trainer/Log Pis Min               -4.76446
trainer/Policy mu Mean             0.115105
trainer/Policy mu Std              0.883928
trainer/Policy mu Max              3.32742
trainer/Policy mu Min             -3.23231
trainer/Policy log std Mean       -2.03104
trainer/Policy log std Std         0.498738
trainer/Policy log std Max        -0.503032
trainer/Policy log std Min        -2.40976
trainer/Alpha                      0.0335275
trainer/Alpha Loss                -0.518145
exploration/num steps total    17200
exploration/num paths total      172
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.271294
exploration/Rewards Std            0.715322
exploration/Rewards Max           -0.00463959
exploration/Rewards Min           -6.68185
exploration/Returns Mean         -27.1294
exploration/Returns Std            6.52372
exploration/Returns Max          -20.6057
exploration/Returns Min          -33.6532
exploration/Actions Mean           0.0452198
exploration/Actions Std            0.232913
exploration/Actions Max            0.999321
exploration/Actions Min           -0.306644
exploration/Num Paths              2
exploration/Average Returns      -27.1294
evaluation/num steps total     85000
evaluation/num paths total       850
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.167391
evaluation/Rewards Std             0.42715
evaluation/Rewards Max            -0.0454333
evaluation/Rewards Min            -5.62598
evaluation/Returns Mean          -16.7391
evaluation/Returns Std             5.32465
evaluation/Returns Max           -11.2678
evaluation/Returns Min           -26.1968
evaluation/Actions Mean           -0.00840726
evaluation/Actions Std             0.152414
evaluation/Actions Max             0.998426
evaluation/Actions Min            -0.997234
evaluation/Num Paths              10
evaluation/Average Returns       -16.7391
time/data storing (s)              0.00118124
time/evaluation sampling (s)       0.251537
time/exploration sampling (s)      0.0655746
time/logging (s)                   0.00335942
time/saving (s)                    0.00233486
time/training (s)                  0.964133
time/epoch (s)                     1.28812
time/total (s)                   111.344
Epoch                             84
-----------------------------  --------------
2019-04-22 20:12:50.176944 PDT | [sac-pointmass-multitask-1_2019_04_22_20_10_57_0000--s-0] Epoch 85 finished
-----------------------------  --------------
replay_buffer/size             17400
trainer/QF1 Loss                   1.30072
trainer/QF2 Loss                   1.30799
trainer/Policy Loss               13.734
trainer/Q1 Predictions Mean      -12.1844
trainer/Q1 Predictions Std         3.2276
trainer/Q1 Predictions Max       -11.0914
trainer/Q1 Predictions Min       -36.3189
trainer/Q2 Predictions Mean      -12.1529
trainer/Q2 Predictions Std         3.19273
trainer/Q2 Predictions Max       -11.073
trainer/Q2 Predictions Min       -36.2006
trainer/Q Targets Mean           -12.1878
trainer/Q Targets Std              3.21411
trainer/Q Targets Max             -0.225111
trainer/Q Targets Min            -33.8877
trainer/Log Pis Mean               1.96283
trainer/Log Pis Std                1.34298
trainer/Log Pis Max                7.29441
trainer/Log Pis Min               -1.88214
trainer/Policy mu Mean             0.077216
trainer/Policy mu Std              0.74883
trainer/Policy mu Max              3.23793
trainer/Policy mu Min             -2.78875
trainer/Policy log std Mean       -2.06878
trainer/Policy log std Std         0.425537
trainer/Policy log std Max        -0.602379
trainer/Policy log std Min        -2.3992
trainer/Alpha                      0.0335474
trainer/Alpha Loss                -0.12617
exploration/num steps total    17400
exploration/num paths total      174
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.188493
exploration/Rewards Std            0.378817
exploration/Rewards Max           -0.00541552
exploration/Rewards Min           -3.90768
exploration/Returns Mean         -18.8493
exploration/Returns Std            3.09129
exploration/Returns Max          -15.758
exploration/Returns Min          -21.9406
exploration/Actions Mean           0.0029028
exploration/Actions Std            0.200099
exploration/Actions Max            0.998938
exploration/Actions Min           -0.967578
exploration/Num Paths              2
exploration/Average Returns      -18.8493
evaluation/num steps total     86000
evaluation/num paths total       860
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.12984
evaluation/Rewards Std             0.61969
evaluation/Rewards Max            -0.0149738
evaluation/Rewards Min            -7.3247
evaluation/Returns Mean          -12.984
evaluation/Returns Std             5.92746
evaluation/Returns Max            -3.24257
evaluation/Returns Min           -25.6094
evaluation/Actions Mean            0.00957294
evaluation/Actions Std             0.174788
evaluation/Actions Max             0.998532
evaluation/Actions Min            -0.996324
evaluation/Num Paths              10
evaluation/Average Returns       -12.984
time/data storing (s)              0.00120207
time/evaluation sampling (s)       0.249461
time/exploration sampling (s)      0.0689585
time/logging (s)                   0.00337538
time/saving (s)                    0.00232143
time/training (s)                  0.97365
time/epoch (s)                     1.29897
time/total (s)                   112.647
Epoch                             85
-----------------------------  --------------
2019-04-22 20:12:51.483958 PDT | [sac-pointmass-multitask-1_2019_04_22_20_10_57_0000--s-0] Epoch 86 finished
-----------------------------  --------------
replay_buffer/size             17600
trainer/QF1 Loss                   1.25325
trainer/QF2 Loss                   1.24292
trainer/Policy Loss               13.3738
trainer/Q1 Predictions Mean      -11.7337
trainer/Q1 Predictions Std         2.02924
trainer/Q1 Predictions Max       -10.9568
trainer/Q1 Predictions Min       -22.9941
trainer/Q2 Predictions Mean      -11.7709
trainer/Q2 Predictions Std         2.03064
trainer/Q2 Predictions Max       -11.0006
trainer/Q2 Predictions Min       -22.9879
trainer/Q Targets Mean           -11.8415
trainer/Q Targets Std              2.26687
trainer/Q Targets Max             -0.312526
trainer/Q Targets Min            -22.3623
trainer/Log Pis Mean               1.88574
trainer/Log Pis Std                1.436
trainer/Log Pis Max                6.39312
trainer/Log Pis Min               -3.81686
trainer/Policy mu Mean             0.0493885
trainer/Policy mu Std              0.635944
trainer/Policy mu Max              2.99029
trainer/Policy mu Min             -2.75069
trainer/Policy log std Mean       -2.15114
trainer/Policy log std Std         0.372008
trainer/Policy log std Max        -0.695973
trainer/Policy log std Min        -2.43315
trainer/Alpha                      0.0340658
trainer/Alpha Loss                -0.386147
exploration/num steps total    17600
exploration/num paths total      176
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.241
exploration/Rewards Std            0.541022
exploration/Rewards Max           -0.0180845
exploration/Rewards Min           -4.97554
exploration/Returns Mean         -24.1
exploration/Returns Std            3.32976
exploration/Returns Max          -20.7703
exploration/Returns Min          -27.4298
exploration/Actions Mean          -0.02478
exploration/Actions Std            0.212211
exploration/Actions Max            0.959897
exploration/Actions Min           -0.99627
exploration/Num Paths              2
exploration/Average Returns      -24.1
evaluation/num steps total     87000
evaluation/num paths total       870
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.163663
evaluation/Rewards Std             0.462239
evaluation/Rewards Max            -0.0173292
evaluation/Rewards Min            -5.75375
evaluation/Returns Mean          -16.3663
evaluation/Returns Std             5.32475
evaluation/Returns Max            -9.79183
evaluation/Returns Min           -25.3663
evaluation/Actions Mean            0.0112086
evaluation/Actions Std             0.155211
evaluation/Actions Max             0.997367
evaluation/Actions Min            -0.996607
evaluation/Num Paths              10
evaluation/Average Returns       -16.3663
time/data storing (s)              0.00118652
time/evaluation sampling (s)       0.249488
time/exploration sampling (s)      0.066503
time/logging (s)                   0.00324895
time/saving (s)                    0.00230762
time/training (s)                  0.977924
time/epoch (s)                     1.30066
time/total (s)                   113.952
Epoch                             86
-----------------------------  --------------
2019-04-22 20:12:52.777418 PDT | [sac-pointmass-multitask-1_2019_04_22_20_10_57_0000--s-0] Epoch 87 finished
-----------------------------  ---------------
replay_buffer/size             17800
trainer/QF1 Loss                   1.23079
trainer/QF2 Loss                   1.24539
trainer/Policy Loss               13.1699
trainer/Q1 Predictions Mean      -11.5018
trainer/Q1 Predictions Std         1.64166
trainer/Q1 Predictions Max       -10.9727
trainer/Q1 Predictions Min       -25.2226
trainer/Q2 Predictions Mean      -11.4575
trainer/Q2 Predictions Std         1.64787
trainer/Q2 Predictions Max       -10.9331
trainer/Q2 Predictions Min       -25.2818
trainer/Q Targets Mean           -11.5772
trainer/Q Targets Std              2.05707
trainer/Q Targets Max             -0.125489
trainer/Q Targets Min            -26.1191
trainer/Log Pis Mean               1.89163
trainer/Log Pis Std                1.04537
trainer/Log Pis Max                6.66356
trainer/Log Pis Min               -0.56873
trainer/Policy mu Mean            -0.0342901
trainer/Policy mu Std              0.527421
trainer/Policy mu Max              2.40495
trainer/Policy mu Min             -3.35942
trainer/Policy log std Mean       -2.11233
trainer/Policy log std Std         0.324155
trainer/Policy log std Max        -0.398109
trainer/Policy log std Min        -2.35086
trainer/Alpha                      0.0341985
trainer/Alpha Loss                -0.365798
exploration/num steps total    17800
exploration/num paths total      178
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.265044
exploration/Rewards Std            0.645583
exploration/Rewards Max           -0.0163127
exploration/Rewards Min           -4.99516
exploration/Returns Mean         -26.5044
exploration/Returns Std            1.56303
exploration/Returns Max          -24.9414
exploration/Returns Min          -28.0675
exploration/Actions Mean          -0.0407309
exploration/Actions Std            0.2315
exploration/Actions Max            0.435521
exploration/Actions Min           -0.995655
exploration/Num Paths              2
exploration/Average Returns      -26.5044
evaluation/num steps total     88000
evaluation/num paths total       880
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.110071
evaluation/Rewards Std             0.502204
evaluation/Rewards Max            -0.0167225
evaluation/Rewards Min            -6.13595
evaluation/Returns Mean          -11.0071
evaluation/Returns Std             5.32912
evaluation/Returns Max            -3.19058
evaluation/Returns Min           -20.5631
evaluation/Actions Mean           -0.000606003
evaluation/Actions Std             0.163712
evaluation/Actions Max             0.995683
evaluation/Actions Min            -0.998099
evaluation/Num Paths              10
evaluation/Average Returns       -11.0071
time/data storing (s)              0.00117794
time/evaluation sampling (s)       0.252043
time/exploration sampling (s)      0.0656789
time/logging (s)                   0.00334804
time/saving (s)                    0.00229634
time/training (s)                  0.962704
time/epoch (s)                     1.28725
time/total (s)                   115.244
Epoch                             87
-----------------------------  ---------------
2019-04-22 20:12:54.082526 PDT | [sac-pointmass-multitask-1_2019_04_22_20_10_57_0000--s-0] Epoch 88 finished
-----------------------------  --------------
replay_buffer/size             18000
trainer/QF1 Loss                   0.0185583
trainer/QF2 Loss                   0.0198343
trainer/Policy Loss               13.6482
trainer/Q1 Predictions Mean      -11.7848
trainer/Q1 Predictions Std         2.14639
trainer/Q1 Predictions Max       -10.9654
trainer/Q1 Predictions Min       -24.8405
trainer/Q2 Predictions Mean      -11.7759
trainer/Q2 Predictions Std         2.14172
trainer/Q2 Predictions Max       -10.9317
trainer/Q2 Predictions Min       -24.5837
trainer/Q Targets Mean           -11.879
trainer/Q Targets Std              2.10366
trainer/Q Targets Max            -10.9999
trainer/Q Targets Min            -24.6289
trainer/Log Pis Mean               2.13124
trainer/Log Pis Std                1.62764
trainer/Log Pis Max                7.71762
trainer/Log Pis Min               -3.4802
trainer/Policy mu Mean            -0.0561788
trainer/Policy mu Std              0.717564
trainer/Policy mu Max              3.56174
trainer/Policy mu Min             -3.0993
trainer/Policy log std Mean       -2.17697
trainer/Policy log std Std         0.402464
trainer/Policy log std Max        -0.663165
trainer/Policy log std Min        -2.47869
trainer/Alpha                      0.0346332
trainer/Alpha Loss                 0.441382
exploration/num steps total    18000
exploration/num paths total      180
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.157951
exploration/Rewards Std            0.345446
exploration/Rewards Max           -0.00942864
exploration/Rewards Min           -3.74741
exploration/Returns Mean         -15.7951
exploration/Returns Std            3.85416
exploration/Returns Max          -11.941
exploration/Returns Min          -19.6493
exploration/Actions Mean          -0.0221647
exploration/Actions Std            0.174482
exploration/Actions Max            0.390637
exploration/Actions Min           -0.997837
exploration/Num Paths              2
exploration/Average Returns      -15.7951
evaluation/num steps total     89000
evaluation/num paths total       890
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0689958
evaluation/Rewards Std             0.363966
evaluation/Rewards Max            -0.00510357
evaluation/Rewards Min            -4.496
evaluation/Returns Mean           -6.89958
evaluation/Returns Std             4.5068
evaluation/Returns Max            -2.15317
evaluation/Returns Min           -14.5373
evaluation/Actions Mean            0.00526393
evaluation/Actions Std             0.131575
evaluation/Actions Max             0.996848
evaluation/Actions Min            -0.996508
evaluation/Num Paths              10
evaluation/Average Returns        -6.89958
time/data storing (s)              0.0012441
time/evaluation sampling (s)       0.250603
time/exploration sampling (s)      0.0655662
time/logging (s)                   0.00334437
time/saving (s)                    0.00232894
time/training (s)                  0.975788
time/epoch (s)                     1.29887
time/total (s)                   116.547
Epoch                             88
-----------------------------  --------------
2019-04-22 20:12:55.388790 PDT | [sac-pointmass-multitask-1_2019_04_22_20_10_57_0000--s-0] Epoch 89 finished
-----------------------------  --------------
replay_buffer/size             18200
trainer/QF1 Loss                   2.52437
trainer/QF2 Loss                   2.51005
trainer/Policy Loss               13.435
trainer/Q1 Predictions Mean      -11.7114
trainer/Q1 Predictions Std         2.93029
trainer/Q1 Predictions Max       -10.9883
trainer/Q1 Predictions Min       -34.6805
trainer/Q2 Predictions Mean      -11.7081
trainer/Q2 Predictions Std         2.94516
trainer/Q2 Predictions Max       -10.9777
trainer/Q2 Predictions Min       -34.7083
trainer/Q Targets Mean           -11.5615
trainer/Q Targets Std              3.45138
trainer/Q Targets Max             -0.128177
trainer/Q Targets Min            -34.384
trainer/Log Pis Mean               1.91694
trainer/Log Pis Std                1.52976
trainer/Log Pis Max               10.0985
trainer/Log Pis Min               -3.67057
trainer/Policy mu Mean            -0.0301109
trainer/Policy mu Std              0.607864
trainer/Policy mu Max              3.41807
trainer/Policy mu Min             -3.58598
trainer/Policy log std Mean       -2.19059
trainer/Policy log std Std         0.333185
trainer/Policy log std Max        -0.437103
trainer/Policy log std Min        -2.49706
trainer/Alpha                      0.0349826
trainer/Alpha Loss                -0.278484
exploration/num steps total    18200
exploration/num paths total      182
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.217653
exploration/Rewards Std            0.554349
exploration/Rewards Max           -0.0136255
exploration/Rewards Min           -4.64005
exploration/Returns Mean         -21.7653
exploration/Returns Std            0.27366
exploration/Returns Max          -21.4916
exploration/Returns Min          -22.039
exploration/Actions Mean          -0.04081
exploration/Actions Std            0.224581
exploration/Actions Max            0.375488
exploration/Actions Min           -0.999497
exploration/Num Paths              2
exploration/Average Returns      -21.7653
evaluation/num steps total     90000
evaluation/num paths total       900
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.106984
evaluation/Rewards Std             0.519893
evaluation/Rewards Max            -0.0077239
evaluation/Rewards Min            -5.51935
evaluation/Returns Mean          -10.6984
evaluation/Returns Std             4.09333
evaluation/Returns Max            -4.45255
evaluation/Returns Min           -17.8582
evaluation/Actions Mean            0.0029824
evaluation/Actions Std             0.169782
evaluation/Actions Max             0.998445
evaluation/Actions Min            -0.997354
evaluation/Num Paths              10
evaluation/Average Returns       -10.6984
time/data storing (s)              0.00125189
time/evaluation sampling (s)       0.244785
time/exploration sampling (s)      0.0668751
time/logging (s)                   0.00334581
time/saving (s)                    0.00232326
time/training (s)                  0.982049
time/epoch (s)                     1.30063
time/total (s)                   117.851
Epoch                             89
-----------------------------  --------------
2019-04-22 20:12:56.684305 PDT | [sac-pointmass-multitask-1_2019_04_22_20_10_57_0000--s-0] Epoch 90 finished
-----------------------------  --------------
replay_buffer/size             18400
trainer/QF1 Loss                   1.1966
trainer/QF2 Loss                   1.19695
trainer/Policy Loss               13.5601
trainer/Q1 Predictions Mean      -11.6715
trainer/Q1 Predictions Std         2.69688
trainer/Q1 Predictions Max       -10.8914
trainer/Q1 Predictions Min       -29.0511
trainer/Q2 Predictions Mean      -11.7164
trainer/Q2 Predictions Std         2.70691
trainer/Q2 Predictions Max       -10.9334
trainer/Q2 Predictions Min       -29.2452
trainer/Q Targets Mean           -11.6151
trainer/Q Targets Std              2.87785
trainer/Q Targets Max             -0.111307
trainer/Q Targets Min            -28.7786
trainer/Log Pis Mean               2.13634
trainer/Log Pis Std                1.37871
trainer/Log Pis Max               10.4419
trainer/Log Pis Min               -1.39448
trainer/Policy mu Mean             0.00259922
trainer/Policy mu Std              0.618182
trainer/Policy mu Max              3.40515
trainer/Policy mu Min             -2.9712
trainer/Policy log std Mean       -2.18906
trainer/Policy log std Std         0.364213
trainer/Policy log std Max        -0.596831
trainer/Policy log std Min        -2.47951
trainer/Alpha                      0.0347145
trainer/Alpha Loss                 0.45819
exploration/num steps total    18400
exploration/num paths total      184
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.25758
exploration/Rewards Std            0.765246
exploration/Rewards Max           -0.00723937
exploration/Rewards Min           -6.77928
exploration/Returns Mean         -25.758
exploration/Returns Std            5.23014
exploration/Returns Max          -20.5278
exploration/Returns Min          -30.9881
exploration/Actions Mean           0.00959337
exploration/Actions Std            0.23323
exploration/Actions Max            0.999093
exploration/Actions Min           -0.997503
exploration/Num Paths              2
exploration/Average Returns      -25.758
evaluation/num steps total     91000
evaluation/num paths total       910
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.130127
evaluation/Rewards Std             0.49374
evaluation/Rewards Max            -0.012097
evaluation/Rewards Min            -6.19309
evaluation/Returns Mean          -13.0127
evaluation/Returns Std             5.09052
evaluation/Returns Max            -6.26632
evaluation/Returns Min           -22.2176
evaluation/Actions Mean           -0.0123914
evaluation/Actions Std             0.153755
evaluation/Actions Max             0.997638
evaluation/Actions Min            -0.997397
evaluation/Num Paths              10
evaluation/Average Returns       -13.0127
time/data storing (s)              0.00132756
time/evaluation sampling (s)       0.247805
time/exploration sampling (s)      0.067611
time/logging (s)                   0.00308651
time/saving (s)                    0.00217471
time/training (s)                  0.966913
time/epoch (s)                     1.28892
time/total (s)                   119.145
Epoch                             90
-----------------------------  --------------
2019-04-22 20:12:57.993156 PDT | [sac-pointmass-multitask-1_2019_04_22_20_10_57_0000--s-0] Epoch 91 finished
-----------------------------  --------------
replay_buffer/size             18600
trainer/QF1 Loss                   2.36995
trainer/QF2 Loss                   2.35799
trainer/Policy Loss               14.2153
trainer/Q1 Predictions Mean      -12.5833
trainer/Q1 Predictions Std         5.1651
trainer/Q1 Predictions Max       -10.7742
trainer/Q1 Predictions Min       -43.5033
trainer/Q2 Predictions Mean      -12.632
trainer/Q2 Predictions Std         5.13096
trainer/Q2 Predictions Max       -10.8362
trainer/Q2 Predictions Min       -42.9591
trainer/Q Targets Mean           -12.4819
trainer/Q Targets Std              5.36804
trainer/Q Targets Max             -0.071728
trainer/Q Targets Min            -41.7077
trainer/Log Pis Mean               2.14548
trainer/Log Pis Std                1.84421
trainer/Log Pis Max                9.35526
trainer/Log Pis Min               -3.65022
trainer/Policy mu Mean            -0.0638777
trainer/Policy mu Std              0.919623
trainer/Policy mu Max              3.56961
trainer/Policy mu Min             -3.12322
trainer/Policy log std Mean       -2.00932
trainer/Policy log std Std         0.480403
trainer/Policy log std Max        -0.445921
trainer/Policy log std Min        -2.41983
trainer/Alpha                      0.0350919
trainer/Alpha Loss                 0.487307
exploration/num steps total    18600
exploration/num paths total      186
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.267721
exploration/Rewards Std            0.663881
exploration/Rewards Max           -0.0110846
exploration/Rewards Min           -5.66048
exploration/Returns Mean         -26.7721
exploration/Returns Std            1.88481
exploration/Returns Max          -24.8873
exploration/Returns Min          -28.6569
exploration/Actions Mean           0.0196208
exploration/Actions Std            0.229949
exploration/Actions Max            0.999114
exploration/Actions Min           -0.990449
exploration/Num Paths              2
exploration/Average Returns      -26.7721
evaluation/num steps total     92000
evaluation/num paths total       920
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.15904
evaluation/Rewards Std             0.389738
evaluation/Rewards Max            -0.0179928
evaluation/Rewards Min            -4.80388
evaluation/Returns Mean          -15.904
evaluation/Returns Std             4.23665
evaluation/Returns Max           -10.7081
evaluation/Returns Min           -23.4469
evaluation/Actions Mean           -0.00543713
evaluation/Actions Std             0.146719
evaluation/Actions Max             0.989235
evaluation/Actions Min            -0.997572
evaluation/Num Paths              10
evaluation/Average Returns       -15.904
time/data storing (s)              0.00116025
time/evaluation sampling (s)       0.249241
time/exploration sampling (s)      0.0664447
time/logging (s)                   0.00334337
time/saving (s)                    0.00234362
time/training (s)                  0.98047
time/epoch (s)                     1.303
time/total (s)                   120.452
Epoch                             91
-----------------------------  --------------
2019-04-22 20:12:59.291237 PDT | [sac-pointmass-multitask-1_2019_04_22_20_10_57_0000--s-0] Epoch 92 finished
-----------------------------  --------------
replay_buffer/size             18800
trainer/QF1 Loss                   1.15569
trainer/QF2 Loss                   1.18693
trainer/Policy Loss               13.9372
trainer/Q1 Predictions Mean      -12.1065
trainer/Q1 Predictions Std         4.52714
trainer/Q1 Predictions Max       -10.7672
trainer/Q1 Predictions Min       -40.4667
trainer/Q2 Predictions Mean      -12.1655
trainer/Q2 Predictions Std         4.49524
trainer/Q2 Predictions Max       -10.8171
trainer/Q2 Predictions Min       -40.1635
trainer/Q Targets Mean           -12.0562
trainer/Q Targets Std              4.78967
trainer/Q Targets Max             -0.160368
trainer/Q Targets Min            -41.3869
trainer/Log Pis Mean               2.26357
trainer/Log Pis Std                1.51753
trainer/Log Pis Max                9.8171
trainer/Log Pis Min               -1.89976
trainer/Policy mu Mean             0.0280103
trainer/Policy mu Std              0.772467
trainer/Policy mu Max              3.1178
trainer/Policy mu Min             -3.42467
trainer/Policy log std Mean       -2.16837
trainer/Policy log std Std         0.436008
trainer/Policy log std Max        -0.445899
trainer/Policy log std Min        -2.536
trainer/Alpha                      0.0349383
trainer/Alpha Loss                 0.884093
exploration/num steps total    18800
exploration/num paths total      188
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.232669
exploration/Rewards Std            0.57795
exploration/Rewards Max           -0.00513953
exploration/Rewards Min           -4.98053
exploration/Returns Mean         -23.2669
exploration/Returns Std            4.34027
exploration/Returns Max          -18.9266
exploration/Returns Min          -27.6071
exploration/Actions Mean          -0.0310367
exploration/Actions Std            0.204636
exploration/Actions Max            0.80033
exploration/Actions Min           -0.99875
exploration/Num Paths              2
exploration/Average Returns      -23.2669
evaluation/num steps total     93000
evaluation/num paths total       930
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.160115
evaluation/Rewards Std             0.527986
evaluation/Rewards Max            -0.0474247
evaluation/Rewards Min            -6.42218
evaluation/Returns Mean          -16.0115
evaluation/Returns Std             5.53845
evaluation/Returns Max            -7.48455
evaluation/Returns Min           -26.0122
evaluation/Actions Mean           -0.00157359
evaluation/Actions Std             0.165792
evaluation/Actions Max             0.998702
evaluation/Actions Min            -0.99659
evaluation/Num Paths              10
evaluation/Average Returns       -16.0115
time/data storing (s)              0.0012834
time/evaluation sampling (s)       0.24505
time/exploration sampling (s)      0.0666704
time/logging (s)                   0.00338171
time/saving (s)                    0.00232407
time/training (s)                  0.973203
time/epoch (s)                     1.29191
time/total (s)                   121.749
Epoch                             92
-----------------------------  --------------
2019-04-22 20:13:00.589785 PDT | [sac-pointmass-multitask-1_2019_04_22_20_10_57_0000--s-0] Epoch 93 finished
-----------------------------  --------------
replay_buffer/size             19000
trainer/QF1 Loss                   0.106679
trainer/QF2 Loss                   0.106237
trainer/Policy Loss               13.836
trainer/Q1 Predictions Mean      -11.988
trainer/Q1 Predictions Std         3.99717
trainer/Q1 Predictions Max       -10.6333
trainer/Q1 Predictions Min       -34.6319
trainer/Q2 Predictions Mean      -12.0063
trainer/Q2 Predictions Std         4.01076
trainer/Q2 Predictions Max       -10.6475
trainer/Q2 Predictions Min       -34.6547
trainer/Q Targets Mean           -12.0596
trainer/Q Targets Std              3.95488
trainer/Q Targets Max            -10.6615
trainer/Q Targets Min            -32.9604
trainer/Log Pis Mean               2.1763
trainer/Log Pis Std                1.71005
trainer/Log Pis Max                9.47317
trainer/Log Pis Min               -3.03628
trainer/Policy mu Mean             0.0285571
trainer/Policy mu Std              0.795039
trainer/Policy mu Max              3.64389
trainer/Policy mu Min             -2.85213
trainer/Policy log std Mean       -2.09917
trainer/Policy log std Std         0.447048
trainer/Policy log std Max        -0.397715
trainer/Policy log std Min        -2.4389
trainer/Alpha                      0.0355484
trainer/Alpha Loss                 0.588286
exploration/num steps total    19000
exploration/num paths total      190
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.151433
exploration/Rewards Std            0.234724
exploration/Rewards Max           -0.00603006
exploration/Rewards Min           -2.56408
exploration/Returns Mean         -15.1433
exploration/Returns Std            1.04079
exploration/Returns Max          -14.1025
exploration/Returns Min          -16.184
exploration/Actions Mean           0.0104234
exploration/Actions Std            0.172156
exploration/Actions Max            0.992139
exploration/Actions Min           -0.466197
exploration/Num Paths              2
exploration/Average Returns      -15.1433
evaluation/num steps total     94000
evaluation/num paths total       940
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.135681
evaluation/Rewards Std             0.576959
evaluation/Rewards Max            -0.0179545
evaluation/Rewards Min            -6.11971
evaluation/Returns Mean          -13.5681
evaluation/Returns Std             5.37289
evaluation/Returns Max            -4.28068
evaluation/Returns Min           -20.4983
evaluation/Actions Mean            0.00288025
evaluation/Actions Std             0.170155
evaluation/Actions Max             0.998403
evaluation/Actions Min            -0.995701
evaluation/Num Paths              10
evaluation/Average Returns       -13.5681
time/data storing (s)              0.00128893
time/evaluation sampling (s)       0.250388
time/exploration sampling (s)      0.0661667
time/logging (s)                   0.00335405
time/saving (s)                    0.0023042
time/training (s)                  0.968642
time/epoch (s)                     1.29214
time/total (s)                   123.045
Epoch                             93
-----------------------------  --------------
2019-04-22 20:13:01.897314 PDT | [sac-pointmass-multitask-1_2019_04_22_20_10_57_0000--s-0] Epoch 94 finished
-----------------------------  --------------
replay_buffer/size             19200
trainer/QF1 Loss                   0.0323607
trainer/QF2 Loss                   0.0294863
trainer/Policy Loss               13.0781
trainer/Q1 Predictions Mean      -11.4278
trainer/Q1 Predictions Std         2.36758
trainer/Q1 Predictions Max       -10.5887
trainer/Q1 Predictions Min       -25.6077
trainer/Q2 Predictions Mean      -11.4165
trainer/Q2 Predictions Std         2.39631
trainer/Q2 Predictions Max       -10.5737
trainer/Q2 Predictions Min       -25.735
trainer/Q Targets Mean           -11.5246
trainer/Q Targets Std              2.42597
trainer/Q Targets Max            -10.6037
trainer/Q Targets Min            -26.7399
trainer/Log Pis Mean               2.00068
trainer/Log Pis Std                1.31627
trainer/Log Pis Max                7.03425
trainer/Log Pis Min               -2.13062
trainer/Policy mu Mean            -0.0548734
trainer/Policy mu Std              0.6086
trainer/Policy mu Max              2.15009
trainer/Policy mu Min             -3.3718
trainer/Policy log std Mean       -2.1276
trainer/Policy log std Std         0.387137
trainer/Policy log std Max        -0.314859
trainer/Policy log std Min        -2.47355
trainer/Alpha                      0.0361673
trainer/Alpha Loss                 0.00224128
exploration/num steps total    19200
exploration/num paths total      192
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.27407
exploration/Rewards Std            0.642381
exploration/Rewards Max           -0.0120734
exploration/Rewards Min           -5.73165
exploration/Returns Mean         -27.407
exploration/Returns Std            4.12663
exploration/Returns Max          -23.2803
exploration/Returns Min          -31.5336
exploration/Actions Mean          -0.0133547
exploration/Actions Std            0.239965
exploration/Actions Max            0.999661
exploration/Actions Min           -0.997475
exploration/Num Paths              2
exploration/Average Returns      -27.407
evaluation/num steps total     95000
evaluation/num paths total       950
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.16171
evaluation/Rewards Std             0.471642
evaluation/Rewards Max            -0.0171016
evaluation/Rewards Min            -6.36914
evaluation/Returns Mean          -16.171
evaluation/Returns Std             5.53333
evaluation/Returns Max            -9.33282
evaluation/Returns Min           -27.7525
evaluation/Actions Mean            0.00594728
evaluation/Actions Std             0.153648
evaluation/Actions Max             0.997733
evaluation/Actions Min            -0.996916
evaluation/Num Paths              10
evaluation/Average Returns       -16.171
time/data storing (s)              0.00118651
time/evaluation sampling (s)       0.250692
time/exploration sampling (s)      0.0665921
time/logging (s)                   0.00339925
time/saving (s)                    0.00187668
time/training (s)                  0.977461
time/epoch (s)                     1.30121
time/total (s)                   124.351
Epoch                             94
-----------------------------  --------------
2019-04-22 20:13:03.195437 PDT | [sac-pointmass-multitask-1_2019_04_22_20_10_57_0000--s-0] Epoch 95 finished
-----------------------------  --------------
replay_buffer/size             19400
trainer/QF1 Loss                   2.25086
trainer/QF2 Loss                   2.25757
trainer/Policy Loss               13.3128
trainer/Q1 Predictions Mean      -11.3713
trainer/Q1 Predictions Std         2.19994
trainer/Q1 Predictions Max       -10.5353
trainer/Q1 Predictions Min       -24.5292
trainer/Q2 Predictions Mean      -11.3664
trainer/Q2 Predictions Std         2.21254
trainer/Q2 Predictions Max       -10.5714
trainer/Q2 Predictions Min       -24.7247
trainer/Q Targets Mean           -11.1758
trainer/Q Targets Std              2.73373
trainer/Q Targets Max             -0.0507443
trainer/Q Targets Min            -25.2274
trainer/Log Pis Mean               2.18338
trainer/Log Pis Std                1.32718
trainer/Log Pis Max                7.256
trainer/Log Pis Min               -3.08349
trainer/Policy mu Mean            -0.0243739
trainer/Policy mu Std              0.671687
trainer/Policy mu Max              3.13576
trainer/Policy mu Min             -3.19908
trainer/Policy log std Mean       -2.13382
trainer/Policy log std Std         0.432225
trainer/Policy log std Max        -0.323543
trainer/Policy log std Min        -2.48005
trainer/Alpha                      0.0369872
trainer/Alpha Loss                 0.604644
exploration/num steps total    19400
exploration/num paths total      194
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.177916
exploration/Rewards Std            0.395747
exploration/Rewards Max           -0.00790543
exploration/Rewards Min           -3.6222
exploration/Returns Mean         -17.7916
exploration/Returns Std            0.649271
exploration/Returns Max          -17.1423
exploration/Returns Min          -18.4409
exploration/Actions Mean          -0.00400464
exploration/Actions Std            0.191754
exploration/Actions Max            0.997711
exploration/Actions Min           -0.987153
exploration/Num Paths              2
exploration/Average Returns      -17.7916
evaluation/num steps total     96000
evaluation/num paths total       960
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.126605
evaluation/Rewards Std             0.638791
evaluation/Rewards Max            -0.0151654
evaluation/Rewards Min            -7.05484
evaluation/Returns Mean          -12.6605
evaluation/Returns Std             6.91971
evaluation/Returns Max            -3.55573
evaluation/Returns Min           -23.5084
evaluation/Actions Mean            0.00560416
evaluation/Actions Std             0.177541
evaluation/Actions Max             0.998419
evaluation/Actions Min            -0.997321
evaluation/Num Paths              10
evaluation/Average Returns       -12.6605
time/data storing (s)              0.00119007
time/evaluation sampling (s)       0.250563
time/exploration sampling (s)      0.0654905
time/logging (s)                   0.00346135
time/saving (s)                    0.00231725
time/training (s)                  0.969759
time/epoch (s)                     1.29278
time/total (s)                   125.647
Epoch                             95
-----------------------------  --------------
2019-04-22 20:13:04.486368 PDT | [sac-pointmass-multitask-1_2019_04_22_20_10_57_0000--s-0] Epoch 96 finished
-----------------------------  --------------
replay_buffer/size             19600
trainer/QF1 Loss                   2.18247
trainer/QF2 Loss                   2.17016
trainer/Policy Loss               13.1431
trainer/Q1 Predictions Mean      -11.616
trainer/Q1 Predictions Std         3.41651
trainer/Q1 Predictions Max       -10.3073
trainer/Q1 Predictions Min       -31.4419
trainer/Q2 Predictions Mean      -11.5963
trainer/Q2 Predictions Std         3.44147
trainer/Q2 Predictions Max       -10.288
trainer/Q2 Predictions Min       -31.8697
trainer/Q Targets Mean           -11.7156
trainer/Q Targets Std              3.88808
trainer/Q Targets Max             -0.416806
trainer/Q Targets Min            -32.9734
trainer/Log Pis Mean               1.94471
trainer/Log Pis Std                1.47528
trainer/Log Pis Max                6.40618
trainer/Log Pis Min               -1.73853
trainer/Policy mu Mean            -0.0555407
trainer/Policy mu Std              0.828961
trainer/Policy mu Max              3.55809
trainer/Policy mu Min             -3.00983
trainer/Policy log std Mean       -1.98892
trainer/Policy log std Std         0.453934
trainer/Policy log std Max        -0.473522
trainer/Policy log std Min        -2.35139
trainer/Alpha                      0.0374723
trainer/Alpha Loss                -0.181587
exploration/num steps total    19600
exploration/num paths total      196
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.247304
exploration/Rewards Std            0.600627
exploration/Rewards Max           -0.0134743
exploration/Rewards Min           -4.80628
exploration/Returns Mean         -24.7304
exploration/Returns Std            0.0976638
exploration/Returns Max          -24.6327
exploration/Returns Min          -24.828
exploration/Actions Mean           0.0204877
exploration/Actions Std            0.228745
exploration/Actions Max            0.999305
exploration/Actions Min           -0.956854
exploration/Num Paths              2
exploration/Average Returns      -24.7304
evaluation/num steps total     97000
evaluation/num paths total       970
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0948242
evaluation/Rewards Std             0.464314
evaluation/Rewards Max            -0.0145357
evaluation/Rewards Min            -5.66249
evaluation/Returns Mean           -9.48242
evaluation/Returns Std             5.2006
evaluation/Returns Max            -2.53726
evaluation/Returns Min           -18.1196
evaluation/Actions Mean            0.00156812
evaluation/Actions Std             0.156175
evaluation/Actions Max             0.996746
evaluation/Actions Min            -0.997357
evaluation/Num Paths              10
evaluation/Average Returns        -9.48242
time/data storing (s)              0.00115431
time/evaluation sampling (s)       0.248372
time/exploration sampling (s)      0.0660941
time/logging (s)                   0.00334673
time/saving (s)                    0.00233583
time/training (s)                  0.963854
time/epoch (s)                     1.28516
time/total (s)                   126.936
Epoch                             96
-----------------------------  --------------
2019-04-22 20:13:05.786800 PDT | [sac-pointmass-multitask-1_2019_04_22_20_10_57_0000--s-0] Epoch 97 finished
-----------------------------  --------------
replay_buffer/size             19800
trainer/QF1 Loss                   1.0742
trainer/QF2 Loss                   1.07972
trainer/Policy Loss               12.9633
trainer/Q1 Predictions Mean      -11.0602
trainer/Q1 Predictions Std         2.37088
trainer/Q1 Predictions Max       -10.416
trainer/Q1 Predictions Min       -27.0093
trainer/Q2 Predictions Mean      -11.0605
trainer/Q2 Predictions Std         2.38172
trainer/Q2 Predictions Max       -10.4111
trainer/Q2 Predictions Min       -27.0698
trainer/Q Targets Mean           -10.9954
trainer/Q Targets Std              2.5484
trainer/Q Targets Max             -0.495378
trainer/Q Targets Min            -26.4787
trainer/Log Pis Mean               2.0644
trainer/Log Pis Std                1.18332
trainer/Log Pis Max                8.80795
trainer/Log Pis Min               -1.05611
trainer/Policy mu Mean             0.0282499
trainer/Policy mu Std              0.579801
trainer/Policy mu Max              3.17278
trainer/Policy mu Min             -2.73707
trainer/Policy log std Mean       -2.18176
trainer/Policy log std Std         0.354569
trainer/Policy log std Max        -0.536882
trainer/Policy log std Min        -2.46523
trainer/Alpha                      0.0369651
trainer/Alpha Loss                 0.212379
exploration/num steps total    19800
exploration/num paths total      198
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.18318
exploration/Rewards Std            0.412509
exploration/Rewards Max           -0.00567554
exploration/Rewards Min           -4.46307
exploration/Returns Mean         -18.318
exploration/Returns Std            3.77915
exploration/Returns Max          -14.5388
exploration/Returns Min          -22.0971
exploration/Actions Mean           0.0259157
exploration/Actions Std            0.198565
exploration/Actions Max            0.991221
exploration/Actions Min           -0.421195
exploration/Num Paths              2
exploration/Average Returns      -18.318
evaluation/num steps total     98000
evaluation/num paths total       980
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.115722
evaluation/Rewards Std             0.570054
evaluation/Rewards Max            -0.00908655
evaluation/Rewards Min            -6.2593
evaluation/Returns Mean          -11.5722
evaluation/Returns Std             4.72301
evaluation/Returns Max            -3.00034
evaluation/Returns Min           -19.965
evaluation/Actions Mean           -0.0108006
evaluation/Actions Std             0.176561
evaluation/Actions Max             0.996532
evaluation/Actions Min            -0.997449
evaluation/Num Paths              10
evaluation/Average Returns       -11.5722
time/data storing (s)              0.00128615
time/evaluation sampling (s)       0.250598
time/exploration sampling (s)      0.0673592
time/logging (s)                   0.00335507
time/saving (s)                    0.00235032
time/training (s)                  0.969421
time/epoch (s)                     1.29437
time/total (s)                   128.234
Epoch                             97
-----------------------------  --------------
2019-04-22 20:13:07.126607 PDT | [sac-pointmass-multitask-1_2019_04_22_20_10_57_0000--s-0] Epoch 98 finished
-----------------------------  --------------
replay_buffer/size             20000
trainer/QF1 Loss                   0.103596
trainer/QF2 Loss                   0.163615
trainer/Policy Loss               13.5567
trainer/Q1 Predictions Mean      -11.6706
trainer/Q1 Predictions Std         4.45343
trainer/Q1 Predictions Max       -10.3445
trainer/Q1 Predictions Min       -39.8777
trainer/Q2 Predictions Mean      -11.6491
trainer/Q2 Predictions Std         4.45248
trainer/Q2 Predictions Max       -10.3157
trainer/Q2 Predictions Min       -39.8227
trainer/Q Targets Mean           -11.765
trainer/Q Targets Std              4.55312
trainer/Q Targets Max            -10.3402
trainer/Q Targets Min            -40.1865
trainer/Log Pis Mean               2.2932
trainer/Log Pis Std                1.51305
trainer/Log Pis Max                9.96946
trainer/Log Pis Min               -1.16705
trainer/Policy mu Mean             0.0662603
trainer/Policy mu Std              0.740889
trainer/Policy mu Max              3.20655
trainer/Policy mu Min             -2.94775
trainer/Policy log std Mean       -2.15222
trainer/Policy log std Std         0.417307
trainer/Policy log std Max        -0.582045
trainer/Policy log std Min        -2.45127
trainer/Alpha                      0.0378799
trainer/Alpha Loss                 0.959794
exploration/num steps total    20000
exploration/num paths total      200
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.176384
exploration/Rewards Std            0.376551
exploration/Rewards Max           -0.0131307
exploration/Rewards Min           -4.00449
exploration/Returns Mean         -17.6384
exploration/Returns Std            4.14471
exploration/Returns Max          -13.4937
exploration/Returns Min          -21.7831
exploration/Actions Mean          -0.0192022
exploration/Actions Std            0.181692
exploration/Actions Max            0.569473
exploration/Actions Min           -0.998438
exploration/Num Paths              2
exploration/Average Returns      -17.6384
evaluation/num steps total     99000
evaluation/num paths total       990
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.132932
evaluation/Rewards Std             0.544007
evaluation/Rewards Max            -0.0240172
evaluation/Rewards Min            -5.4172
evaluation/Returns Mean          -13.2932
evaluation/Returns Std             4.6735
evaluation/Returns Max            -5.37744
evaluation/Returns Min           -19.7724
evaluation/Actions Mean            0.0109012
evaluation/Actions Std             0.171748
evaluation/Actions Max             0.997993
evaluation/Actions Min            -0.996455
evaluation/Num Paths              10
evaluation/Average Returns       -13.2932
time/data storing (s)              0.00144946
time/evaluation sampling (s)       0.251973
time/exploration sampling (s)      0.0683938
time/logging (s)                   0.00335553
time/saving (s)                    0.00234219
time/training (s)                  1.00614
time/epoch (s)                     1.33366
time/total (s)                   129.572
Epoch                             98
-----------------------------  --------------
2019-04-22 20:13:08.418623 PDT | [sac-pointmass-multitask-1_2019_04_22_20_10_57_0000--s-0] Epoch 99 finished
-----------------------------  ---------------
replay_buffer/size              20200
trainer/QF1 Loss                    0.0255272
trainer/QF2 Loss                    0.0257591
trainer/Policy Loss                13.3728
trainer/Q1 Predictions Mean       -11.6523
trainer/Q1 Predictions Std          4.28777
trainer/Q1 Predictions Max        -10.2982
trainer/Q1 Predictions Min        -34.3404
trainer/Q2 Predictions Mean       -11.6778
trainer/Q2 Predictions Std          4.30193
trainer/Q2 Predictions Max        -10.3181
trainer/Q2 Predictions Min        -34.5072
trainer/Q Targets Mean            -11.6839
trainer/Q Targets Std               4.2314
trainer/Q Targets Max             -10.2668
trainer/Q Targets Min             -33.6155
trainer/Log Pis Mean                2.14689
trainer/Log Pis Std                 1.58958
trainer/Log Pis Max                 8.85273
trainer/Log Pis Min                -1.52474
trainer/Policy mu Mean              0.0196177
trainer/Policy mu Std               0.747332
trainer/Policy mu Max               3.41133
trainer/Policy mu Min              -3.49661
trainer/Policy log std Mean        -2.12992
trainer/Policy log std Std          0.42377
trainer/Policy log std Max         -0.479069
trainer/Policy log std Min         -2.52171
trainer/Alpha                       0.0386195
trainer/Alpha Loss                  0.477981
exploration/num steps total     20200
exploration/num paths total       202
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.251516
exploration/Rewards Std             0.69371
exploration/Rewards Max            -0.00824032
exploration/Rewards Min            -5.26747
exploration/Returns Mean          -25.1516
exploration/Returns Std             1.48153
exploration/Returns Max           -23.67
exploration/Returns Min           -26.6331
exploration/Actions Mean            0.00782028
exploration/Actions Std             0.234024
exploration/Actions Max             0.999209
exploration/Actions Min            -0.992839
exploration/Num Paths               2
exploration/Average Returns       -25.1516
evaluation/num steps total     100000
evaluation/num paths total       1000
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.123594
evaluation/Rewards Std              0.546383
evaluation/Rewards Max             -0.0370825
evaluation/Rewards Min             -6.82182
evaluation/Returns Mean           -12.3594
evaluation/Returns Std              6.62518
evaluation/Returns Max             -4.39445
evaluation/Returns Min            -23.9211
evaluation/Actions Mean            -0.00134836
evaluation/Actions Std              0.159924
evaluation/Actions Max              0.998272
evaluation/Actions Min             -0.997693
evaluation/Num Paths               10
evaluation/Average Returns        -12.3594
time/data storing (s)               0.00118569
time/evaluation sampling (s)        0.247388
time/exploration sampling (s)       0.0658784
time/logging (s)                    0.00334187
time/saving (s)                     0.0023362
time/training (s)                   0.965493
time/epoch (s)                      1.28562
time/total (s)                    130.862
Epoch                              99
-----------------------------  ---------------
