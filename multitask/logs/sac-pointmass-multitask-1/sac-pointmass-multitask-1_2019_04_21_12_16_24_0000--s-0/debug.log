2019-04-21 12:16:25.989037 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 0 finished
-----------------------------  ---------------
replay_buffer/size               400
trainer/QF1 Loss                  46.6257
trainer/QF2 Loss                  46.5979
trainer/Policy Loss               -1.33144
trainer/Q1 Predictions Mean       -0.00119869
trainer/Q1 Predictions Std         0.00084576
trainer/Q1 Predictions Max         0.000237399
trainer/Q1 Predictions Min        -0.0027965
trainer/Q2 Predictions Mean       -0.00298288
trainer/Q2 Predictions Std         0.000529317
trainer/Q2 Predictions Max        -0.00166706
trainer/Q2 Predictions Min        -0.00469048
trainer/Q Targets Mean            -6.44756
trainer/Q Targets Std              2.25099
trainer/Q Targets Max             -1.24278
trainer/Q Targets Min            -11.4521
trainer/Log Pis Mean              -1.33446
trainer/Log Pis Std                0.314372
trainer/Log Pis Max               -0.5809
trainer/Log Pis Min               -1.83682
trainer/Policy mu Mean            -0.000442269
trainer/Policy mu Std              0.000261682
trainer/Policy mu Max              0.000201061
trainer/Policy mu Min             -0.00105414
trainer/Policy log std Mean       -7.9973e-06
trainer/Policy log std Std         0.000367739
trainer/Policy log std Max         0.000453579
trainer/Policy log std Min        -0.000655646
trainer/Alpha                      0.9997
trainer/Alpha Loss                -0
exploration/num steps total      400
exploration/num paths total        4
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -8.2044
exploration/Rewards Std            2.00469
exploration/Rewards Max           -2.69968
exploration/Rewards Min          -11.5882
exploration/Returns Mean        -820.44
exploration/Returns Std          126.811
exploration/Returns Max         -693.629
exploration/Returns Min         -947.251
exploration/Actions Mean          -0.010385
exploration/Actions Std            0.620339
exploration/Actions Max            0.991854
exploration/Actions Min           -0.989885
exploration/Num Paths              2
exploration/Average Returns     -820.44
evaluation/num steps total      1000
evaluation/num paths total        10
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -7.39292
evaluation/Rewards Std             2.82003
evaluation/Rewards Max            -2.42431
evaluation/Rewards Min           -10.5651
evaluation/Returns Mean         -739.292
evaluation/Returns Std           282
evaluation/Returns Max          -242.93
evaluation/Returns Min         -1054.41
evaluation/Actions Mean           -0.000575832
evaluation/Actions Std             0.00034719
evaluation/Actions Max             0.000115335
evaluation/Actions Min            -0.00109713
evaluation/Num Paths              10
evaluation/Average Returns      -739.292
time/data storing (s)              0.00119552
time/evaluation sampling (s)       0.216928
time/exploration sampling (s)      0.06174
time/logging (s)                   0.00360444
time/saving (s)                    0.00286415
time/training (s)                  1.01371
time/epoch (s)                     1.30004
time/total (s)                     1.53438
Epoch                              0
-----------------------------  ---------------
2019-04-21 12:16:27.315176 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 1 finished
-----------------------------  -------------
replay_buffer/size              600
trainer/QF1 Loss                  0.458344
trainer/QF2 Loss                  0.475184
trainer/Policy Loss               5.53356
trainer/Q1 Predictions Mean      -6.82398
trainer/Q1 Predictions Std        2.37685
trainer/Q1 Predictions Max       -3.62832
trainer/Q1 Predictions Min      -13.2919
trainer/Q2 Predictions Mean      -6.84873
trainer/Q2 Predictions Std        2.34616
trainer/Q2 Predictions Max       -3.68142
trainer/Q2 Predictions Min      -13.4104
trainer/Q Targets Mean           -6.89917
trainer/Q Targets Std             2.51003
trainer/Q Targets Max            -1.89332
trainer/Q Targets Min           -12.4424
trainer/Log Pis Mean             -1.31503
trainer/Log Pis Std               0.292278
trainer/Log Pis Max              -0.645286
trainer/Log Pis Min              -1.86134
trainer/Policy mu Mean            0.10375
trainer/Policy mu Std             0.138742
trainer/Policy mu Max             0.318926
trainer/Policy mu Min            -0.0549832
trainer/Policy log std Mean      -0.136856
trainer/Policy log std Std        0.0136503
trainer/Policy log std Max       -0.117278
trainer/Policy log std Min       -0.175651
trainer/Alpha                     0.941555
trainer/Alpha Loss               -0.198648
exploration/num steps total     600
exploration/num paths total       6
exploration/path length Mean    100
exploration/path length Std       0
exploration/path length Max     100
exploration/path length Min     100
exploration/Rewards Mean         -4.99774
exploration/Rewards Std           1.41336
exploration/Rewards Max          -2.20375
exploration/Rewards Min          -9.49187
exploration/Returns Mean       -499.774
exploration/Returns Std          96.884
exploration/Returns Max        -402.89
exploration/Returns Min        -596.658
exploration/Actions Mean          0.0756425
exploration/Actions Std           0.591623
exploration/Actions Max           0.996065
exploration/Actions Min          -0.990558
exploration/Num Paths             2
exploration/Average Returns    -499.774
evaluation/num steps total     2000
evaluation/num paths total       20
evaluation/path length Mean     100
evaluation/path length Std        0
evaluation/path length Max      100
evaluation/path length Min      100
evaluation/Rewards Mean          -4.57825
evaluation/Rewards Std            2.5515
evaluation/Rewards Max           -0.0984889
evaluation/Rewards Min          -11.0464
evaluation/Returns Mean        -457.825
evaluation/Returns Std          244.31
evaluation/Returns Max         -118.73
evaluation/Returns Min         -869.88
evaluation/Actions Mean           0.0995899
evaluation/Actions Std            0.127726
evaluation/Actions Max            0.302157
evaluation/Actions Min           -0.0567463
evaluation/Num Paths             10
evaluation/Average Returns     -457.825
time/data storing (s)             0.00115773
time/evaluation sampling (s)      0.270102
time/exploration sampling (s)     0.0684504
time/logging (s)                  0.00343381
time/saving (s)                   0.00237485
time/training (s)                 0.975009
time/epoch (s)                    1.32053
time/total (s)                    2.85958
Epoch                             1
-----------------------------  -------------
2019-04-21 12:16:28.636457 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 2 finished
-----------------------------  -------------
replay_buffer/size              800
trainer/QF1 Loss                  0.807403
trainer/QF2 Loss                  0.810201
trainer/Policy Loss               7.31485
trainer/Q1 Predictions Mean      -8.65179
trainer/Q1 Predictions Std        3.23166
trainer/Q1 Predictions Max       -4.84155
trainer/Q1 Predictions Min      -18.1903
trainer/Q2 Predictions Mean      -8.63448
trainer/Q2 Predictions Std        3.21561
trainer/Q2 Predictions Max       -5.00417
trainer/Q2 Predictions Min      -18.1645
trainer/Q Targets Mean           -8.34689
trainer/Q Targets Std             3.66223
trainer/Q Targets Max            -2.68097
trainer/Q Targets Min           -18.1643
trainer/Log Pis Mean             -1.33244
trainer/Log Pis Std               0.572111
trainer/Log Pis Max               0.204717
trainer/Log Pis Min              -2.76746
trainer/Policy mu Mean            0.210116
trainer/Policy mu Std             0.256698
trainer/Policy mu Max             0.716338
trainer/Policy mu Min            -0.405766
trainer/Policy log std Mean      -0.160223
trainer/Policy log std Std        0.0365155
trainer/Policy log std Max       -0.106026
trainer/Policy log std Min       -0.258025
trainer/Alpha                     0.887612
trainer/Alpha Loss               -0.39632
exploration/num steps total     800
exploration/num paths total       8
exploration/path length Mean    100
exploration/path length Std       0
exploration/path length Max     100
exploration/path length Min     100
exploration/Rewards Mean         -1.65693
exploration/Rewards Std           0.781702
exploration/Rewards Max          -0.0154423
exploration/Rewards Min          -4.63263
exploration/Returns Mean       -165.693
exploration/Returns Std           9.27737
exploration/Returns Max        -156.415
exploration/Returns Min        -174.97
exploration/Actions Mean          0.122726
exploration/Actions Std           0.610534
exploration/Actions Max           0.996063
exploration/Actions Min          -0.9884
exploration/Num Paths             2
exploration/Average Returns    -165.693
evaluation/num steps total     3000
evaluation/num paths total       30
evaluation/path length Mean     100
evaluation/path length Std        0
evaluation/path length Max      100
evaluation/path length Min      100
evaluation/Rewards Mean          -1.88607
evaluation/Rewards Std            1.46304
evaluation/Rewards Max           -0.136835
evaluation/Rewards Min          -12.0508
evaluation/Returns Mean        -188.607
evaluation/Returns Std           46.8857
evaluation/Returns Max         -136.914
evaluation/Returns Min         -294.618
evaluation/Actions Mean           0.120394
evaluation/Actions Std            0.132817
evaluation/Actions Max            0.641893
evaluation/Actions Min           -0.445285
evaluation/Num Paths             10
evaluation/Average Returns     -188.607
time/data storing (s)             0.00130389
time/evaluation sampling (s)      0.271658
time/exploration sampling (s)     0.0701678
time/logging (s)                  0.00345729
time/saving (s)                   0.0023472
time/training (s)                 0.967332
time/epoch (s)                    1.31627
time/total (s)                    4.18014
Epoch                             2
-----------------------------  -------------
2019-04-21 12:16:29.942805 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 3 finished
-----------------------------  -------------
replay_buffer/size             1000
trainer/QF1 Loss                  0.326902
trainer/QF2 Loss                  0.336899
trainer/Policy Loss               9.56455
trainer/Q1 Predictions Mean     -11.1183
trainer/Q1 Predictions Std        5.88563
trainer/Q1 Predictions Max       -4.71835
trainer/Q1 Predictions Min      -27.2189
trainer/Q2 Predictions Mean     -11.1302
trainer/Q2 Predictions Std        5.8609
trainer/Q2 Predictions Max       -4.80362
trainer/Q2 Predictions Min      -27.2921
trainer/Q Targets Mean          -11.1504
trainer/Q Targets Std             5.87104
trainer/Q Targets Max            -4.25907
trainer/Q Targets Min           -25.9327
trainer/Log Pis Mean             -0.944491
trainer/Log Pis Std               0.70781
trainer/Log Pis Max               0.78836
trainer/Log Pis Min              -2.99892
trainer/Policy mu Mean            0.164254
trainer/Policy mu Std             0.470184
trainer/Policy mu Max             1.09702
trainer/Policy mu Min            -0.941356
trainer/Policy log std Mean      -0.242718
trainer/Policy log std Std        0.0654549
trainer/Policy log std Max       -0.131472
trainer/Policy log std Min       -0.383152
trainer/Alpha                     0.838209
trainer/Alpha Loss               -0.518846
exploration/num steps total    1000
exploration/num paths total      10
exploration/path length Mean    100
exploration/path length Std       0
exploration/path length Max     100
exploration/path length Min     100
exploration/Rewards Mean         -1.7642
exploration/Rewards Std           1.62523
exploration/Rewards Max          -0.0959329
exploration/Rewards Min          -9.44949
exploration/Returns Mean       -176.42
exploration/Returns Std          39.1242
exploration/Returns Max        -137.295
exploration/Returns Min        -215.544
exploration/Actions Mean          0.0439584
exploration/Actions Std           0.57864
exploration/Actions Max           0.984956
exploration/Actions Min          -0.989271
exploration/Num Paths             2
exploration/Average Returns    -176.42
evaluation/num steps total     4000
evaluation/num paths total       40
evaluation/path length Mean     100
evaluation/path length Std        0
evaluation/path length Max      100
evaluation/path length Min      100
evaluation/Rewards Mean          -0.737736
evaluation/Rewards Std            1.25873
evaluation/Rewards Max           -0.0862167
evaluation/Rewards Min          -10.2872
evaluation/Returns Mean         -73.7736
evaluation/Returns Std           28.636
evaluation/Returns Max          -41.6719
evaluation/Returns Min         -121.027
evaluation/Actions Mean           0.0216769
evaluation/Actions Std            0.121958
evaluation/Actions Max            0.79479
evaluation/Actions Min           -0.679894
evaluation/Num Paths             10
evaluation/Average Returns      -73.7736
time/data storing (s)             0.00116306
time/evaluation sampling (s)      0.263009
time/exploration sampling (s)     0.0699428
time/logging (s)                  0.00338911
time/saving (s)                   0.00229711
time/training (s)                 0.961585
time/epoch (s)                    1.30139
time/total (s)                    5.48568
Epoch                             3
-----------------------------  -------------
2019-04-21 12:16:31.260602 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 4 finished
-----------------------------  -------------
replay_buffer/size             1200
trainer/QF1 Loss                  1.36098
trainer/QF2 Loss                  1.37189
trainer/Policy Loss              10.627
trainer/Q1 Predictions Mean     -12.3869
trainer/Q1 Predictions Std        7.39745
trainer/Q1 Predictions Max       -5.20652
trainer/Q1 Predictions Min      -33.21
trainer/Q2 Predictions Mean     -12.3773
trainer/Q2 Predictions Std        7.37911
trainer/Q2 Predictions Max       -5.25182
trainer/Q2 Predictions Min      -33.3235
trainer/Q Targets Mean          -12.3581
trainer/Q Targets Std             7.47928
trainer/Q Targets Max            -0.77632
trainer/Q Targets Min           -32.9776
trainer/Log Pis Mean             -0.985921
trainer/Log Pis Std               0.979682
trainer/Log Pis Max               1.08126
trainer/Log Pis Min              -4.96808
trainer/Policy mu Mean            0.302544
trainer/Policy mu Std             0.531366
trainer/Policy mu Max             1.26792
trainer/Policy mu Min            -1.0626
trainer/Policy log std Mean      -0.27727
trainer/Policy log std Std        0.0708404
trainer/Policy log std Max       -0.152994
trainer/Policy log std Min       -0.417005
trainer/Alpha                     0.793408
trainer/Alpha Loss               -0.690192
exploration/num steps total    1200
exploration/num paths total      12
exploration/path length Mean    100
exploration/path length Std       0
exploration/path length Max     100
exploration/path length Min     100
exploration/Rewards Mean         -1.51719
exploration/Rewards Std           0.792407
exploration/Rewards Max          -0.0732847
exploration/Rewards Min          -4.2213
exploration/Returns Mean       -151.719
exploration/Returns Std          14.9941
exploration/Returns Max        -136.725
exploration/Returns Min        -166.713
exploration/Actions Mean          0.0182574
exploration/Actions Std           0.569443
exploration/Actions Max           0.992752
exploration/Actions Min          -0.98636
exploration/Num Paths             2
exploration/Average Returns    -151.719
evaluation/num steps total     5000
evaluation/num paths total       50
evaluation/path length Mean     100
evaluation/path length Std        0
evaluation/path length Max      100
evaluation/path length Min      100
evaluation/Rewards Mean          -0.676908
evaluation/Rewards Std            0.55506
evaluation/Rewards Max           -0.0370664
evaluation/Rewards Min           -6.84595
evaluation/Returns Mean         -67.6908
evaluation/Returns Std           12.3221
evaluation/Returns Max          -55.5303
evaluation/Returns Min          -91.719
evaluation/Actions Mean           0.0160981
evaluation/Actions Std            0.101376
evaluation/Actions Max            0.810325
evaluation/Actions Min           -0.589301
evaluation/Num Paths             10
evaluation/Average Returns      -67.6908
time/data storing (s)             0.00137458
time/evaluation sampling (s)      0.259183
time/exploration sampling (s)     0.0670304
time/logging (s)                  0.00343432
time/saving (s)                   0.00252644
time/training (s)                 0.979517
time/epoch (s)                    1.31307
time/total (s)                    6.80277
Epoch                             4
-----------------------------  -------------
2019-04-21 12:16:32.543365 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 5 finished
-----------------------------  -------------
replay_buffer/size             1400
trainer/QF1 Loss                  6.44541
trainer/QF2 Loss                  6.5368
trainer/Policy Loss              12.5335
trainer/Q1 Predictions Mean     -14.522
trainer/Q1 Predictions Std        8.9513
trainer/Q1 Predictions Max       -6.44835
trainer/Q1 Predictions Min      -40.2343
trainer/Q2 Predictions Mean     -14.4922
trainer/Q2 Predictions Std        8.98679
trainer/Q2 Predictions Max       -6.42887
trainer/Q2 Predictions Min      -40.5303
trainer/Q Targets Mean          -13.834
trainer/Q Targets Std             8.69916
trainer/Q Targets Max            -1.27149
trainer/Q Targets Min           -39.7737
trainer/Log Pis Mean             -0.615279
trainer/Log Pis Std               1.03972
trainer/Log Pis Max               1.82092
trainer/Log Pis Min              -3.71893
trainer/Policy mu Mean            0.241864
trainer/Policy mu Std             0.638044
trainer/Policy mu Max             1.34357
trainer/Policy mu Min            -1.3027
trainer/Policy log std Mean      -0.357759
trainer/Policy log std Std        0.0762866
trainer/Policy log std Max       -0.218991
trainer/Policy log std Min       -0.527689
trainer/Alpha                     0.752439
trainer/Alpha Loss               -0.743197
exploration/num steps total    1400
exploration/num paths total      14
exploration/path length Mean    100
exploration/path length Std       0
exploration/path length Max     100
exploration/path length Min     100
exploration/Rewards Mean         -1.34858
exploration/Rewards Std           1.39655
exploration/Rewards Max          -0.136242
exploration/Rewards Min          -9.62948
exploration/Returns Mean       -134.858
exploration/Returns Std          14.5219
exploration/Returns Max        -120.336
exploration/Returns Min        -149.38
exploration/Actions Mean          0.0479008
exploration/Actions Std           0.571291
exploration/Actions Max           0.995994
exploration/Actions Min          -0.987611
exploration/Num Paths             2
exploration/Average Returns    -134.858
evaluation/num steps total     6000
evaluation/num paths total       60
evaluation/path length Mean     100
evaluation/path length Std        0
evaluation/path length Max      100
evaluation/path length Min      100
evaluation/Rewards Mean          -0.490831
evaluation/Rewards Std            0.951009
evaluation/Rewards Max           -0.0635838
evaluation/Rewards Min          -10.0944
evaluation/Returns Mean         -49.0831
evaluation/Returns Std           18.0683
evaluation/Returns Max          -31.27
evaluation/Returns Min          -86.1089
evaluation/Actions Mean           0.0289558
evaluation/Actions Std            0.140274
evaluation/Actions Max            0.875034
evaluation/Actions Min           -0.668252
evaluation/Num Paths             10
evaluation/Average Returns      -49.0831
time/data storing (s)             0.00167313
time/evaluation sampling (s)      0.258011
time/exploration sampling (s)     0.0686921
time/logging (s)                  0.00341864
time/saving (s)                   0.00186339
time/training (s)                 0.944201
time/epoch (s)                    1.27786
time/total (s)                    8.08476
Epoch                             5
-----------------------------  -------------
2019-04-21 12:16:33.849845 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 6 finished
-----------------------------  -------------
replay_buffer/size             1600
trainer/QF1 Loss                  5.82872
trainer/QF2 Loss                  6.02236
trainer/Policy Loss              12.6036
trainer/Q1 Predictions Mean     -14.5206
trainer/Q1 Predictions Std       10.1671
trainer/Q1 Predictions Max       -6.24772
trainer/Q1 Predictions Min      -48.1364
trainer/Q2 Predictions Mean     -14.5308
trainer/Q2 Predictions Std       10.1495
trainer/Q2 Predictions Max       -6.34394
trainer/Q2 Predictions Min      -48.0662
trainer/Q Targets Mean          -14.3844
trainer/Q Targets Std            10.0024
trainer/Q Targets Max            -3.72961
trainer/Q Targets Min           -46.0313
trainer/Log Pis Mean             -0.617178
trainer/Log Pis Std               1.05969
trainer/Log Pis Max               2.04278
trainer/Log Pis Min              -2.5088
trainer/Policy mu Mean            0.209107
trainer/Policy mu Std             0.67274
trainer/Policy mu Max             1.47745
trainer/Policy mu Min            -1.32954
trainer/Policy log std Mean      -0.40562
trainer/Policy log std Std        0.0841408
trainer/Policy log std Max       -0.233018
trainer/Policy log std Min       -0.571972
trainer/Alpha                     0.714055
trainer/Alpha Loss               -0.880783
exploration/num steps total    1600
exploration/num paths total      16
exploration/path length Mean    100
exploration/path length Std       0
exploration/path length Max     100
exploration/path length Min     100
exploration/Rewards Mean         -1.22246
exploration/Rewards Std           1.25145
exploration/Rewards Max          -0.0936763
exploration/Rewards Min          -8.42938
exploration/Returns Mean       -122.246
exploration/Returns Std           7.36274
exploration/Returns Max        -114.884
exploration/Returns Min        -129.609
exploration/Actions Mean          0.070882
exploration/Actions Std           0.544241
exploration/Actions Max           0.988958
exploration/Actions Min          -0.959115
exploration/Num Paths             2
exploration/Average Returns    -122.246
evaluation/num steps total     7000
evaluation/num paths total       70
evaluation/path length Mean     100
evaluation/path length Std        0
evaluation/path length Max      100
evaluation/path length Min      100
evaluation/Rewards Mean          -0.372555
evaluation/Rewards Std            0.951953
evaluation/Rewards Max           -0.0127685
evaluation/Rewards Min          -10.2182
evaluation/Returns Mean         -37.2555
evaluation/Returns Std           20.1973
evaluation/Returns Max          -20.5787
evaluation/Returns Min          -81.6782
evaluation/Actions Mean           0.0195002
evaluation/Actions Std            0.141584
evaluation/Actions Max            0.904699
evaluation/Actions Min           -0.816897
evaluation/Num Paths             10
evaluation/Average Returns      -37.2555
time/data storing (s)             0.00122796
time/evaluation sampling (s)      0.254985
time/exploration sampling (s)     0.0667423
time/logging (s)                  0.00347436
time/saving (s)                   0.00233938
time/training (s)                 0.972958
time/epoch (s)                    1.30173
time/total (s)                    9.39047
Epoch                             6
-----------------------------  -------------
2019-04-21 12:16:35.148256 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 7 finished
-----------------------------  -------------
replay_buffer/size             1800
trainer/QF1 Loss                  0.690498
trainer/QF2 Loss                  0.683636
trainer/Policy Loss              11.8057
trainer/Q1 Predictions Mean     -13.5882
trainer/Q1 Predictions Std        9.11565
trainer/Q1 Predictions Max       -7.03457
trainer/Q1 Predictions Min      -44.2375
trainer/Q2 Predictions Mean     -13.5877
trainer/Q2 Predictions Std        9.10222
trainer/Q2 Predictions Max       -7.06014
trainer/Q2 Predictions Min      -43.8354
trainer/Q Targets Mean          -13.7455
trainer/Q Targets Std             9.32696
trainer/Q Targets Max            -6.83509
trainer/Q Targets Min           -44.437
trainer/Log Pis Mean             -0.650137
trainer/Log Pis Std               1.19699
trainer/Log Pis Max               2.3781
trainer/Log Pis Min              -6.15004
trainer/Policy mu Mean            0.192732
trainer/Policy mu Std             0.652017
trainer/Policy mu Max             1.5532
trainer/Policy mu Min            -1.35371
trainer/Policy log std Mean      -0.425428
trainer/Policy log std Std        0.0875143
trainer/Policy log std Max       -0.270648
trainer/Policy log std Min       -0.583561
trainer/Alpha                     0.677664
trainer/Alpha Loss               -1.03048
exploration/num steps total    1800
exploration/num paths total      18
exploration/path length Mean    100
exploration/path length Std       0
exploration/path length Max     100
exploration/path length Min     100
exploration/Rewards Mean         -0.957961
exploration/Rewards Std           0.787504
exploration/Rewards Max          -0.0481981
exploration/Rewards Min          -5.09847
exploration/Returns Mean        -95.7961
exploration/Returns Std           5.44466
exploration/Returns Max         -90.3515
exploration/Returns Min        -101.241
exploration/Actions Mean          0.0169167
exploration/Actions Std           0.55013
exploration/Actions Max           0.970341
exploration/Actions Min          -0.957437
exploration/Num Paths             2
exploration/Average Returns     -95.7961
evaluation/num steps total     8000
evaluation/num paths total       80
evaluation/path length Mean     100
evaluation/path length Std        0
evaluation/path length Max      100
evaluation/path length Min      100
evaluation/Rewards Mean          -0.322231
evaluation/Rewards Std            1.17365
evaluation/Rewards Max           -0.0225941
evaluation/Rewards Min           -9.43488
evaluation/Returns Mean         -32.2231
evaluation/Returns Std           15.9619
evaluation/Returns Max           -7.01298
evaluation/Returns Min          -56.9725
evaluation/Actions Mean           0.0295472
evaluation/Actions Std            0.176962
evaluation/Actions Max            0.918364
evaluation/Actions Min           -0.875553
evaluation/Num Paths             10
evaluation/Average Returns      -32.2231
time/data storing (s)             0.00114028
time/evaluation sampling (s)      0.254514
time/exploration sampling (s)     0.0674047
time/logging (s)                  0.0037091
time/saving (s)                   0.00234186
time/training (s)                 0.965341
time/epoch (s)                    1.29445
time/total (s)                   10.6884
Epoch                             7
-----------------------------  -------------
2019-04-21 12:16:36.473572 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 8 finished
-----------------------------  -------------
replay_buffer/size             2000
trainer/QF1 Loss                  0.502405
trainer/QF2 Loss                  0.506538
trainer/Policy Loss              11.4395
trainer/Q1 Predictions Mean     -13.1055
trainer/Q1 Predictions Std        9.19546
trainer/Q1 Predictions Max       -7.84967
trainer/Q1 Predictions Min      -50.3944
trainer/Q2 Predictions Mean     -13.0825
trainer/Q2 Predictions Std        9.17061
trainer/Q2 Predictions Max       -7.80435
trainer/Q2 Predictions Min      -50.081
trainer/Q Targets Mean          -13.1055
trainer/Q Targets Std             9.27794
trainer/Q Targets Max            -7.53453
trainer/Q Targets Min           -51.278
trainer/Log Pis Mean             -0.730118
trainer/Log Pis Std               1.24584
trainer/Log Pis Max               2.11468
trainer/Log Pis Min              -5.2638
trainer/Policy mu Mean            0.225355
trainer/Policy mu Std             0.611323
trainer/Policy mu Max             1.59111
trainer/Policy mu Min            -1.14905
trainer/Policy log std Mean      -0.44154
trainer/Policy log std Std        0.0866356
trainer/Policy log std Max       -0.251659
trainer/Policy log std Min       -0.652261
trainer/Alpha                     0.642851
trainer/Alpha Loss               -1.20555
exploration/num steps total    2000
exploration/num paths total      20
exploration/path length Mean    100
exploration/path length Std       0
exploration/path length Max     100
exploration/path length Min     100
exploration/Rewards Mean         -0.978341
exploration/Rewards Std           0.990725
exploration/Rewards Max          -0.0751406
exploration/Rewards Min          -7.77922
exploration/Returns Mean        -97.8341
exploration/Returns Std          15.4152
exploration/Returns Max         -82.4189
exploration/Returns Min        -113.249
exploration/Actions Mean          0.0228695
exploration/Actions Std           0.536695
exploration/Actions Max           0.980243
exploration/Actions Min          -0.974782
exploration/Num Paths             2
exploration/Average Returns     -97.8341
evaluation/num steps total     9000
evaluation/num paths total       90
evaluation/path length Mean     100
evaluation/path length Std        0
evaluation/path length Max      100
evaluation/path length Min      100
evaluation/Rewards Mean          -0.525595
evaluation/Rewards Std            1.11769
evaluation/Rewards Max           -0.174584
evaluation/Rewards Min          -10.9005
evaluation/Returns Mean         -52.5595
evaluation/Returns Std           15.8189
evaluation/Returns Max          -38.4843
evaluation/Returns Min          -87.5609
evaluation/Actions Mean           0.0444399
evaluation/Actions Std            0.179621
evaluation/Actions Max            0.923948
evaluation/Actions Min           -0.83836
evaluation/Num Paths             10
evaluation/Average Returns      -52.5595
time/data storing (s)             0.00113519
time/evaluation sampling (s)      0.257708
time/exploration sampling (s)     0.0725812
time/logging (s)                  0.00258176
time/saving (s)                   0.00205305
time/training (s)                 0.983641
time/epoch (s)                    1.3197
time/total (s)                   12.0121
Epoch                             8
-----------------------------  -------------
2019-04-21 12:16:37.783913 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 9 finished
-----------------------------  --------------
replay_buffer/size              2200
trainer/QF1 Loss                   2.12941
trainer/QF2 Loss                   2.16219
trainer/Policy Loss               14.4193
trainer/Q1 Predictions Mean      -15.9508
trainer/Q1 Predictions Std        11.4605
trainer/Q1 Predictions Max        -8.36275
trainer/Q1 Predictions Min       -62.588
trainer/Q2 Predictions Mean      -15.9165
trainer/Q2 Predictions Std        11.4489
trainer/Q2 Predictions Max        -8.29479
trainer/Q2 Predictions Min       -62.7786
trainer/Q Targets Mean           -15.7019
trainer/Q Targets Std             11.6638
trainer/Q Targets Max             -0.345402
trainer/Q Targets Min            -61.0808
trainer/Log Pis Mean              -0.511539
trainer/Log Pis Std                1.37941
trainer/Log Pis Max                3.19812
trainer/Log Pis Min               -3.89032
trainer/Policy mu Mean             0.180019
trainer/Policy mu Std              0.745259
trainer/Policy mu Max              1.6905
trainer/Policy mu Min             -1.49355
trainer/Policy log std Mean       -0.48922
trainer/Policy log std Std         0.0968182
trainer/Policy log std Max        -0.235085
trainer/Policy log std Min        -0.643817
trainer/Alpha                      0.609423
trainer/Alpha Loss                -1.24315
exploration/num steps total     2200
exploration/num paths total       22
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.968129
exploration/Rewards Std            0.91593
exploration/Rewards Max           -0.141926
exploration/Rewards Min           -7.97191
exploration/Returns Mean         -96.8129
exploration/Returns Std            8.22492
exploration/Returns Max          -88.588
exploration/Returns Min         -105.038
exploration/Actions Mean           0.0414409
exploration/Actions Std            0.536303
exploration/Actions Max            0.971003
exploration/Actions Min           -0.991448
exploration/Num Paths              2
exploration/Average Returns      -96.8129
evaluation/num steps total     10000
evaluation/num paths total       100
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.295518
evaluation/Rewards Std             1.07122
evaluation/Rewards Max            -0.0371354
evaluation/Rewards Min           -11.5231
evaluation/Returns Mean          -29.5518
evaluation/Returns Std            20.2558
evaluation/Returns Max            -8.38843
evaluation/Returns Min           -74.9221
evaluation/Actions Mean            0.0312582
evaluation/Actions Std             0.16166
evaluation/Actions Max             0.940913
evaluation/Actions Min            -0.84348
evaluation/Num Paths              10
evaluation/Average Returns       -29.5518
time/data storing (s)              0.00129049
time/evaluation sampling (s)       0.256046
time/exploration sampling (s)      0.0681499
time/logging (s)                   0.00342902
time/saving (s)                    0.00216729
time/training (s)                  0.975137
time/epoch (s)                     1.30622
time/total (s)                    13.3224
Epoch                              9
-----------------------------  --------------
2019-04-21 12:16:39.086967 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 10 finished
-----------------------------  --------------
replay_buffer/size              2400
trainer/QF1 Loss                   1.47054
trainer/QF2 Loss                   1.51411
trainer/Policy Loss               12.6757
trainer/Q1 Predictions Mean      -14.4782
trainer/Q1 Predictions Std        10.4506
trainer/Q1 Predictions Max        -8.59338
trainer/Q1 Predictions Min       -67.4292
trainer/Q2 Predictions Mean      -14.5115
trainer/Q2 Predictions Std        10.4852
trainer/Q2 Predictions Max        -8.61113
trainer/Q2 Predictions Min       -67.5793
trainer/Q Targets Mean           -14.3756
trainer/Q Targets Std             10.3406
trainer/Q Targets Max             -0.735893
trainer/Q Targets Min            -64.4594
trainer/Log Pis Mean              -0.628559
trainer/Log Pis Std                1.17322
trainer/Log Pis Max                3.39529
trainer/Log Pis Min               -2.96653
trainer/Policy mu Mean             0.125406
trainer/Policy mu Std              0.700734
trainer/Policy mu Max              1.81933
trainer/Policy mu Min             -1.64576
trainer/Policy log std Mean       -0.493014
trainer/Policy log std Std         0.10883
trainer/Policy log std Max        -0.226262
trainer/Policy log std Min        -0.651111
trainer/Alpha                      0.577229
trainer/Alpha Loss                -1.44371
exploration/num steps total     2400
exploration/num paths total       24
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.1098
exploration/Rewards Std            1.28948
exploration/Rewards Max           -0.069143
exploration/Rewards Min          -10.2654
exploration/Returns Mean        -110.98
exploration/Returns Std           27.2478
exploration/Returns Max          -83.7322
exploration/Returns Min         -138.228
exploration/Actions Mean           0.027903
exploration/Actions Std            0.531412
exploration/Actions Max            0.983823
exploration/Actions Min           -0.980929
exploration/Num Paths              2
exploration/Average Returns     -110.98
evaluation/num steps total     11000
evaluation/num paths total       110
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.487378
evaluation/Rewards Std             1.24699
evaluation/Rewards Max            -0.153503
evaluation/Rewards Min           -10.5309
evaluation/Returns Mean          -48.7378
evaluation/Returns Std            17.5598
evaluation/Returns Max           -23.567
evaluation/Returns Min           -77.9831
evaluation/Actions Mean            0.0310067
evaluation/Actions Std             0.19266
evaluation/Actions Max             0.94784
evaluation/Actions Min            -0.90556
evaluation/Num Paths              10
evaluation/Average Returns       -48.7378
time/data storing (s)              0.00125357
time/evaluation sampling (s)       0.250333
time/exploration sampling (s)      0.069313
time/logging (s)                   0.00342433
time/saving (s)                    0.0023798
time/training (s)                  0.971493
time/epoch (s)                     1.2982
time/total (s)                    14.6246
Epoch                             10
-----------------------------  --------------
2019-04-21 12:16:40.398832 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 11 finished
-----------------------------  --------------
replay_buffer/size              2600
trainer/QF1 Loss                   1.00673
trainer/QF2 Loss                   1.1011
trainer/Policy Loss               14.8567
trainer/Q1 Predictions Mean      -16.2755
trainer/Q1 Predictions Std        11.7243
trainer/Q1 Predictions Max        -9.00463
trainer/Q1 Predictions Min       -56.386
trainer/Q2 Predictions Mean      -16.339
trainer/Q2 Predictions Std        11.699
trainer/Q2 Predictions Max        -9.06523
trainer/Q2 Predictions Min       -56.2456
trainer/Q Targets Mean           -16.2141
trainer/Q Targets Std             11.4422
trainer/Q Targets Max             -8.88682
trainer/Q Targets Min            -56.4169
trainer/Log Pis Mean              -0.0900156
trainer/Log Pis Std                1.61149
trainer/Log Pis Max                3.46921
trainer/Log Pis Min               -6.02971
trainer/Policy mu Mean             0.305533
trainer/Policy mu Std              0.769703
trainer/Policy mu Max              1.90918
trainer/Policy mu Min             -1.57006
trainer/Policy log std Mean       -0.557399
trainer/Policy log std Std         0.0857603
trainer/Policy log std Max        -0.257632
trainer/Policy log std Min        -0.684148
trainer/Alpha                      0.546501
trainer/Alpha Loss                -1.26227
exploration/num steps total     2600
exploration/num paths total       26
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.821313
exploration/Rewards Std            0.758171
exploration/Rewards Max           -0.0335634
exploration/Rewards Min           -6.66035
exploration/Returns Mean         -82.1313
exploration/Returns Std           10.3344
exploration/Returns Max          -71.7969
exploration/Returns Min          -92.4657
exploration/Actions Mean           0.0300756
exploration/Actions Std            0.52091
exploration/Actions Max            0.992945
exploration/Actions Min           -0.96521
exploration/Num Paths              2
exploration/Average Returns      -82.1313
evaluation/num steps total     12000
evaluation/num paths total       120
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.562803
evaluation/Rewards Std             0.735602
evaluation/Rewards Max            -0.0662057
evaluation/Rewards Min            -7.91689
evaluation/Returns Mean          -56.2803
evaluation/Returns Std             9.84246
evaluation/Returns Max           -45.3445
evaluation/Returns Min           -74.3516
evaluation/Actions Mean            0.0247874
evaluation/Actions Std             0.170778
evaluation/Actions Max             0.953194
evaluation/Actions Min            -0.932432
evaluation/Num Paths              10
evaluation/Average Returns       -56.2803
time/data storing (s)              0.0011881
time/evaluation sampling (s)       0.256619
time/exploration sampling (s)      0.0671092
time/logging (s)                   0.00337499
time/saving (s)                    0.00233502
time/training (s)                  0.976213
time/epoch (s)                     1.30684
time/total (s)                    15.9356
Epoch                             11
-----------------------------  --------------
2019-04-21 12:16:41.711474 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 12 finished
-----------------------------  --------------
replay_buffer/size              2800
trainer/QF1 Loss                   0.744236
trainer/QF2 Loss                   0.7749
trainer/Policy Loss               14.8253
trainer/Q1 Predictions Mean      -16.5243
trainer/Q1 Predictions Std        11.7702
trainer/Q1 Predictions Max        -9.55645
trainer/Q1 Predictions Min       -72.0725
trainer/Q2 Predictions Mean      -16.5563
trainer/Q2 Predictions Std        11.7898
trainer/Q2 Predictions Max        -9.59432
trainer/Q2 Predictions Min       -72.2185
trainer/Q Targets Mean           -16.6426
trainer/Q Targets Std             11.7651
trainer/Q Targets Max             -9.3644
trainer/Q Targets Min            -69.8604
trainer/Log Pis Mean              -0.323144
trainer/Log Pis Std                1.4036
trainer/Log Pis Max                3.69317
trainer/Log Pis Min               -4.09562
trainer/Policy mu Mean             0.183883
trainer/Policy mu Std              0.778196
trainer/Policy mu Max              2.0246
trainer/Policy mu Min             -1.66613
trainer/Policy log std Mean       -0.537928
trainer/Policy log std Std         0.0940933
trainer/Policy log std Max        -0.256161
trainer/Policy log std Min        -0.705509
trainer/Alpha                      0.517203
trainer/Alpha Loss                -1.53104
exploration/num steps total     2800
exploration/num paths total       28
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.05121
exploration/Rewards Std            1.37203
exploration/Rewards Max           -0.0509817
exploration/Rewards Min           -8.76838
exploration/Returns Mean        -105.121
exploration/Returns Std            1.46882
exploration/Returns Max         -103.652
exploration/Returns Min         -106.59
exploration/Actions Mean           0.0425867
exploration/Actions Std            0.5388
exploration/Actions Max            0.979616
exploration/Actions Min           -0.96186
exploration/Num Paths              2
exploration/Average Returns     -105.121
evaluation/num steps total     13000
evaluation/num paths total       130
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.456271
evaluation/Rewards Std             1.43411
evaluation/Rewards Max            -0.0693635
evaluation/Rewards Min            -9.54293
evaluation/Returns Mean          -45.6271
evaluation/Returns Std            11.9556
evaluation/Returns Max           -19.0963
evaluation/Returns Min           -60.6341
evaluation/Actions Mean            0.0352947
evaluation/Actions Std             0.207791
evaluation/Actions Max             0.964688
evaluation/Actions Min            -0.929115
evaluation/Num Paths              10
evaluation/Average Returns       -45.6271
time/data storing (s)              0.00119738
time/evaluation sampling (s)       0.260026
time/exploration sampling (s)      0.067473
time/logging (s)                   0.00347456
time/saving (s)                    0.00195594
time/training (s)                  0.973699
time/epoch (s)                     1.30783
time/total (s)                    17.2475
Epoch                             12
-----------------------------  --------------
2019-04-21 12:16:43.006409 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 13 finished
-----------------------------  --------------
replay_buffer/size              3000
trainer/QF1 Loss                   3.20564
trainer/QF2 Loss                   3.30913
trainer/Policy Loss               13.9737
trainer/Q1 Predictions Mean      -15.5807
trainer/Q1 Predictions Std         9.84987
trainer/Q1 Predictions Max       -10.0334
trainer/Q1 Predictions Min       -62.7543
trainer/Q2 Predictions Mean      -15.4992
trainer/Q2 Predictions Std         9.86549
trainer/Q2 Predictions Max        -9.9003
trainer/Q2 Predictions Min       -62.4006
trainer/Q Targets Mean           -15.4456
trainer/Q Targets Std              9.75454
trainer/Q Targets Max             -3.09622
trainer/Q Targets Min            -64.2737
trainer/Log Pis Mean              -0.252615
trainer/Log Pis Std                1.24255
trainer/Log Pis Max                3.64838
trainer/Log Pis Min               -2.7399
trainer/Policy mu Mean             0.168647
trainer/Policy mu Std              0.757065
trainer/Policy mu Max              2.02026
trainer/Policy mu Min             -1.68009
trainer/Policy log std Mean       -0.57488
trainer/Policy log std Std         0.079786
trainer/Policy log std Max        -0.289684
trainer/Policy log std Min        -0.716946
trainer/Alpha                      0.489011
trainer/Alpha Loss                -1.61083
exploration/num steps total     3000
exploration/num paths total       30
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.689678
exploration/Rewards Std            0.453633
exploration/Rewards Max           -0.073347
exploration/Rewards Min           -4.11452
exploration/Returns Mean         -68.9678
exploration/Returns Std            2.39375
exploration/Returns Max          -66.5741
exploration/Returns Min          -71.3616
exploration/Actions Mean           0.0292451
exploration/Actions Std            0.515557
exploration/Actions Max            0.971767
exploration/Actions Min           -0.959263
exploration/Num Paths              2
exploration/Average Returns      -68.9678
evaluation/num steps total     14000
evaluation/num paths total       140
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.24137
evaluation/Rewards Std             0.864013
evaluation/Rewards Max            -0.0692734
evaluation/Rewards Min            -9.68949
evaluation/Returns Mean          -24.137
evaluation/Returns Std            13.8526
evaluation/Returns Max            -7.7498
evaluation/Returns Min           -59.3537
evaluation/Actions Mean            0.0202888
evaluation/Actions Std             0.166012
evaluation/Actions Max             0.968246
evaluation/Actions Min            -0.93488
evaluation/Num Paths              10
evaluation/Average Returns       -24.137
time/data storing (s)              0.0013801
time/evaluation sampling (s)       0.252378
time/exploration sampling (s)      0.0691473
time/logging (s)                   0.00347238
time/saving (s)                    0.00231652
time/training (s)                  0.961289
time/epoch (s)                     1.28998
time/total (s)                    18.5415
Epoch                             13
-----------------------------  --------------
2019-04-21 12:16:44.317875 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 14 finished
-----------------------------  --------------
replay_buffer/size              3200
trainer/QF1 Loss                   1.60255
trainer/QF2 Loss                   1.60338
trainer/Policy Loss               14.413
trainer/Q1 Predictions Mean      -16.1764
trainer/Q1 Predictions Std         9.90738
trainer/Q1 Predictions Max       -10.1631
trainer/Q1 Predictions Min       -49.5073
trainer/Q2 Predictions Mean      -16.1477
trainer/Q2 Predictions Std         9.85746
trainer/Q2 Predictions Max       -10.1282
trainer/Q2 Predictions Min       -49.6737
trainer/Q Targets Mean           -16.1575
trainer/Q Targets Std              9.83213
trainer/Q Targets Max             -0.234636
trainer/Q Targets Min            -49.3733
trainer/Log Pis Mean              -0.460168
trainer/Log Pis Std                1.25811
trainer/Log Pis Max                3.72532
trainer/Log Pis Min               -3.44065
trainer/Policy mu Mean             0.249118
trainer/Policy mu Std              0.747952
trainer/Policy mu Max              1.95493
trainer/Policy mu Min             -1.86824
trainer/Policy log std Mean       -0.618001
trainer/Policy log std Std         0.0976127
trainer/Policy log std Max        -0.302117
trainer/Policy log std Min        -0.760664
trainer/Alpha                      0.46234
trainer/Alpha Loss                -1.89723
exploration/num steps total     3200
exploration/num paths total       32
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.768356
exploration/Rewards Std            0.856107
exploration/Rewards Max           -0.0445019
exploration/Rewards Min           -6.3023
exploration/Returns Mean         -76.8356
exploration/Returns Std            2.55801
exploration/Returns Max          -74.2776
exploration/Returns Min          -79.3937
exploration/Actions Mean           0.0210336
exploration/Actions Std            0.497887
exploration/Actions Max            0.981704
exploration/Actions Min           -0.960291
exploration/Num Paths              2
exploration/Average Returns      -76.8356
evaluation/num steps total     15000
evaluation/num paths total       150
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.281448
evaluation/Rewards Std             0.924501
evaluation/Rewards Max            -0.0418155
evaluation/Rewards Min           -10.0818
evaluation/Returns Mean          -28.1448
evaluation/Returns Std            17.5965
evaluation/Returns Max           -11.3789
evaluation/Returns Min           -67.5337
evaluation/Actions Mean            0.0197651
evaluation/Actions Std             0.162045
evaluation/Actions Max             0.96058
evaluation/Actions Min            -0.947048
evaluation/Num Paths              10
evaluation/Average Returns       -28.1448
time/data storing (s)              0.00128643
time/evaluation sampling (s)       0.273557
time/exploration sampling (s)      0.0668641
time/logging (s)                   0.00342988
time/saving (s)                    0.0101975
time/training (s)                  0.95117
time/epoch (s)                     1.30651
time/total (s)                    19.8521
Epoch                             14
-----------------------------  --------------
2019-04-21 12:16:45.621863 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 15 finished
-----------------------------  --------------
replay_buffer/size              3400
trainer/QF1 Loss                   1.55542
trainer/QF2 Loss                   1.57083
trainer/Policy Loss               14.0053
trainer/Q1 Predictions Mean      -15.3008
trainer/Q1 Predictions Std        10.6042
trainer/Q1 Predictions Max       -10.5283
trainer/Q1 Predictions Min       -66.9523
trainer/Q2 Predictions Mean      -15.2909
trainer/Q2 Predictions Std        10.6066
trainer/Q2 Predictions Max       -10.571
trainer/Q2 Predictions Min       -66.9455
trainer/Q Targets Mean           -15.4871
trainer/Q Targets Std             10.8314
trainer/Q Targets Max             -0.392902
trainer/Q Targets Min            -68.6523
trainer/Log Pis Mean              -0.419354
trainer/Log Pis Std                1.23818
trainer/Log Pis Max                3.31386
trainer/Log Pis Min               -3.20899
trainer/Policy mu Mean             0.176357
trainer/Policy mu Std              0.662534
trainer/Policy mu Max              2.13484
trainer/Policy mu Min             -1.77354
trainer/Policy log std Mean       -0.624376
trainer/Policy log std Std         0.131521
trainer/Policy log std Max        -0.268233
trainer/Policy log std Min        -0.822067
trainer/Alpha                      0.437028
trainer/Alpha Loss                -2.00195
exploration/num steps total     3400
exploration/num paths total       34
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.896118
exploration/Rewards Std            1.27977
exploration/Rewards Max           -0.0863429
exploration/Rewards Min           -8.72941
exploration/Returns Mean         -89.6118
exploration/Returns Std            8.97634
exploration/Returns Max          -80.6355
exploration/Returns Min          -98.5881
exploration/Actions Mean           0.0186862
exploration/Actions Std            0.515567
exploration/Actions Max            0.997857
exploration/Actions Min           -0.985626
exploration/Num Paths              2
exploration/Average Returns      -89.6118
evaluation/num steps total     16000
evaluation/num paths total       160
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.358814
evaluation/Rewards Std             1.11853
evaluation/Rewards Max            -0.00773978
evaluation/Rewards Min            -9.24177
evaluation/Returns Mean          -35.8814
evaluation/Returns Std            14.7687
evaluation/Returns Max           -12.1715
evaluation/Returns Min           -52.4733
evaluation/Actions Mean            0.03883
evaluation/Actions Std             0.186004
evaluation/Actions Max             0.96703
evaluation/Actions Min            -0.914914
evaluation/Num Paths              10
evaluation/Average Returns       -35.8814
time/data storing (s)              0.0012174
time/evaluation sampling (s)       0.251257
time/exploration sampling (s)      0.0702303
time/logging (s)                   0.0040937
time/saving (s)                    0.00267892
time/training (s)                  0.97015
time/epoch (s)                     1.29963
time/total (s)                    21.1559
Epoch                             15
-----------------------------  --------------
2019-04-21 12:16:46.944961 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 16 finished
-----------------------------  --------------
replay_buffer/size              3600
trainer/QF1 Loss                   2.22704
trainer/QF2 Loss                   2.31862
trainer/Policy Loss               15.4796
trainer/Q1 Predictions Mean      -17.1477
trainer/Q1 Predictions Std         9.67763
trainer/Q1 Predictions Max       -11.1256
trainer/Q1 Predictions Min       -54.4631
trainer/Q2 Predictions Mean      -17.1542
trainer/Q2 Predictions Std         9.63074
trainer/Q2 Predictions Max       -11.1352
trainer/Q2 Predictions Min       -54.8972
trainer/Q Targets Mean           -17.2974
trainer/Q Targets Std              9.83266
trainer/Q Targets Max             -0.345402
trainer/Q Targets Min            -54.5934
trainer/Log Pis Mean              -0.307364
trainer/Log Pis Std                1.36135
trainer/Log Pis Max                4.01964
trainer/Log Pis Min               -3.40795
trainer/Policy mu Mean             0.216657
trainer/Policy mu Std              0.779206
trainer/Policy mu Max              1.96136
trainer/Policy mu Min             -1.76534
trainer/Policy log std Mean       -0.582306
trainer/Policy log std Std         0.119644
trainer/Policy log std Max        -0.27149
trainer/Policy log std Min        -0.761686
trainer/Alpha                      0.412821
trainer/Alpha Loss                -2.04075
exploration/num steps total     3600
exploration/num paths total       36
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.862192
exploration/Rewards Std            1.17648
exploration/Rewards Max           -0.0240091
exploration/Rewards Min           -8.92142
exploration/Returns Mean         -86.2192
exploration/Returns Std           14.8948
exploration/Returns Max          -71.3244
exploration/Returns Min         -101.114
exploration/Actions Mean           0.0246712
exploration/Actions Std            0.516231
exploration/Actions Max            0.977784
exploration/Actions Min           -0.982843
exploration/Num Paths              2
exploration/Average Returns      -86.2192
evaluation/num steps total     17000
evaluation/num paths total       170
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.379132
evaluation/Rewards Std             1.2785
evaluation/Rewards Max            -0.0379777
evaluation/Rewards Min           -10.2122
evaluation/Returns Mean          -37.9132
evaluation/Returns Std            20.7474
evaluation/Returns Max           -12.0425
evaluation/Returns Min           -65.2913
evaluation/Actions Mean            0.0245744
evaluation/Actions Std             0.194571
evaluation/Actions Max             0.961414
evaluation/Actions Min            -0.927357
evaluation/Num Paths              10
evaluation/Average Returns       -37.9132
time/data storing (s)              0.00118204
time/evaluation sampling (s)       0.260418
time/exploration sampling (s)      0.0685967
time/logging (s)                   0.00342286
time/saving (s)                    0.00244862
time/training (s)                  0.980434
time/epoch (s)                     1.3165
time/total (s)                    22.4771
Epoch                             16
-----------------------------  --------------
2019-04-21 12:16:48.244287 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 17 finished
-----------------------------  --------------
replay_buffer/size              3800
trainer/QF1 Loss                   0.501574
trainer/QF2 Loss                   0.518568
trainer/Policy Loss               15.7435
trainer/Q1 Predictions Mean      -17.4849
trainer/Q1 Predictions Std        11.9269
trainer/Q1 Predictions Max       -11.5158
trainer/Q1 Predictions Min       -72.555
trainer/Q2 Predictions Mean      -17.4882
trainer/Q2 Predictions Std        11.9017
trainer/Q2 Predictions Max       -11.4587
trainer/Q2 Predictions Min       -72.545
trainer/Q Targets Mean           -17.7794
trainer/Q Targets Std             12.2074
trainer/Q Targets Max            -11.1954
trainer/Q Targets Min            -75.313
trainer/Log Pis Mean              -0.412988
trainer/Log Pis Std                1.29646
trainer/Log Pis Max                3.85223
trainer/Log Pis Min               -3.3705
trainer/Policy mu Mean             0.267311
trainer/Policy mu Std              0.74701
trainer/Policy mu Max              2.27125
trainer/Policy mu Min             -1.70517
trainer/Policy log std Mean       -0.613276
trainer/Policy log std Std         0.094055
trainer/Policy log std Max        -0.322435
trainer/Policy log std Min        -0.767153
trainer/Alpha                      0.389819
trainer/Alpha Loss                -2.27251
exploration/num steps total     3800
exploration/num paths total       38
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.8668
exploration/Rewards Std            1.27505
exploration/Rewards Max           -0.0608334
exploration/Rewards Min           -9.79346
exploration/Returns Mean         -86.68
exploration/Returns Std           20.0857
exploration/Returns Max          -66.5943
exploration/Returns Min         -106.766
exploration/Actions Mean           0.0351158
exploration/Actions Std            0.500949
exploration/Actions Max            0.993555
exploration/Actions Min           -0.959165
exploration/Num Paths              2
exploration/Average Returns      -86.68
evaluation/num steps total     18000
evaluation/num paths total       180
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.408847
evaluation/Rewards Std             1.03462
evaluation/Rewards Max            -0.109641
evaluation/Rewards Min           -10.233
evaluation/Returns Mean          -40.8847
evaluation/Returns Std            15.0651
evaluation/Returns Max           -23.969
evaluation/Returns Min           -67.2025
evaluation/Actions Mean            0.0261843
evaluation/Actions Std             0.188693
evaluation/Actions Max             0.976894
evaluation/Actions Min            -0.945046
evaluation/Num Paths              10
evaluation/Average Returns       -40.8847
time/data storing (s)              0.00134261
time/evaluation sampling (s)       0.257655
time/exploration sampling (s)      0.0697648
time/logging (s)                   0.00258517
time/saving (s)                    0.00232932
time/training (s)                  0.959673
time/epoch (s)                     1.29335
time/total (s)                    23.7746
Epoch                             17
-----------------------------  --------------
2019-04-21 12:16:49.543523 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 18 finished
-----------------------------  --------------
replay_buffer/size              4000
trainer/QF1 Loss                   4.19485
trainer/QF2 Loss                   4.62309
trainer/Policy Loss               18.8979
trainer/Q1 Predictions Mean      -20.7611
trainer/Q1 Predictions Std        15.805
trainer/Q1 Predictions Max       -12.0401
trainer/Q1 Predictions Min       -79.4483
trainer/Q2 Predictions Mean      -20.8349
trainer/Q2 Predictions Std        15.9353
trainer/Q2 Predictions Max       -11.9841
trainer/Q2 Predictions Min       -79.7262
trainer/Q Targets Mean           -20.4646
trainer/Q Targets Std             15.6955
trainer/Q Targets Max             -0.436759
trainer/Q Targets Min            -76.4837
trainer/Log Pis Mean              -0.026384
trainer/Log Pis Std                1.62808
trainer/Log Pis Max                4.13779
trainer/Log Pis Min               -5.73452
trainer/Policy mu Mean             0.283295
trainer/Policy mu Std              0.875514
trainer/Policy mu Max              2.27015
trainer/Policy mu Min             -1.85486
trainer/Policy log std Mean       -0.646052
trainer/Policy log std Std         0.0806182
trainer/Policy log std Max        -0.363677
trainer/Policy log std Min        -0.772692
trainer/Alpha                      0.367971
trainer/Alpha Loss                -2.0253
exploration/num steps total     4000
exploration/num paths total       40
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.826156
exploration/Rewards Std            1.15445
exploration/Rewards Max           -0.0621232
exploration/Rewards Min           -9.50798
exploration/Returns Mean         -82.6156
exploration/Returns Std           26.6442
exploration/Returns Max          -55.9713
exploration/Returns Min         -109.26
exploration/Actions Mean           0.0456013
exploration/Actions Std            0.468858
exploration/Actions Max            0.991277
exploration/Actions Min           -0.949628
exploration/Num Paths              2
exploration/Average Returns      -82.6156
evaluation/num steps total     19000
evaluation/num paths total       190
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.416577
evaluation/Rewards Std             0.96003
evaluation/Rewards Max            -0.0221042
evaluation/Rewards Min            -9.27951
evaluation/Returns Mean          -41.6577
evaluation/Returns Std            15.3754
evaluation/Returns Max           -22.887
evaluation/Returns Min           -68.5312
evaluation/Actions Mean            0.0301292
evaluation/Actions Std             0.170634
evaluation/Actions Max             0.978733
evaluation/Actions Min            -0.906415
evaluation/Num Paths              10
evaluation/Average Returns       -41.6577
time/data storing (s)              0.00130246
time/evaluation sampling (s)       0.254055
time/exploration sampling (s)      0.06729
time/logging (s)                   0.00341645
time/saving (s)                    0.00231532
time/training (s)                  0.967666
time/epoch (s)                     1.29605
time/total (s)                    25.074
Epoch                             18
-----------------------------  --------------
2019-04-21 12:16:50.844749 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 19 finished
-----------------------------  --------------
replay_buffer/size              4200
trainer/QF1 Loss                   0.277618
trainer/QF2 Loss                   0.272212
trainer/Policy Loss               14.967
trainer/Q1 Predictions Mean      -16.1634
trainer/Q1 Predictions Std         8.01675
trainer/Q1 Predictions Max       -12.2775
trainer/Q1 Predictions Min       -49.2491
trainer/Q2 Predictions Mean      -16.1437
trainer/Q2 Predictions Std         8.04919
trainer/Q2 Predictions Max       -12.1805
trainer/Q2 Predictions Min       -49.4797
trainer/Q Targets Mean           -16.1046
trainer/Q Targets Std              8.00224
trainer/Q Targets Max            -11.989
trainer/Q Targets Min            -49.2511
trainer/Log Pis Mean              -0.247552
trainer/Log Pis Std                1.23769
trainer/Log Pis Max                3.93263
trainer/Log Pis Min               -4.12485
trainer/Policy mu Mean             0.0816984
trainer/Policy mu Std              0.720266
trainer/Policy mu Max              2.05681
trainer/Policy mu Min             -1.90484
trainer/Policy log std Mean       -0.665194
trainer/Policy log std Std         0.0985273
trainer/Policy log std Max        -0.385506
trainer/Policy log std Min        -0.844474
trainer/Alpha                      0.347495
trainer/Alpha Loss                -2.37504
exploration/num steps total     4200
exploration/num paths total       42
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.698506
exploration/Rewards Std            0.698794
exploration/Rewards Max           -0.0573465
exploration/Rewards Min           -6.05138
exploration/Returns Mean         -69.8506
exploration/Returns Std           10.1609
exploration/Returns Max          -59.6897
exploration/Returns Min          -80.0115
exploration/Actions Mean           0.0300236
exploration/Actions Std            0.502901
exploration/Actions Max            0.979338
exploration/Actions Min           -0.959004
exploration/Num Paths              2
exploration/Average Returns      -69.8506
evaluation/num steps total     20000
evaluation/num paths total       200
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.330001
evaluation/Rewards Std             1.04512
evaluation/Rewards Max            -0.0757073
evaluation/Rewards Min           -10.1425
evaluation/Returns Mean          -33.0001
evaluation/Returns Std            16.3498
evaluation/Returns Max           -11.7691
evaluation/Returns Min           -69.0596
evaluation/Actions Mean            0.0212097
evaluation/Actions Std             0.179943
evaluation/Actions Max             0.976049
evaluation/Actions Min            -0.951538
evaluation/Num Paths              10
evaluation/Average Returns       -33.0001
time/data storing (s)              0.00115684
time/evaluation sampling (s)       0.252669
time/exploration sampling (s)      0.0680737
time/logging (s)                   0.00346886
time/saving (s)                    0.00231808
time/training (s)                  0.968556
time/epoch (s)                     1.29624
time/total (s)                    26.3744
Epoch                             19
-----------------------------  --------------
2019-04-21 12:16:52.154802 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 20 finished
-----------------------------  --------------
replay_buffer/size              4400
trainer/QF1 Loss                   1.8132
trainer/QF2 Loss                   1.82078
trainer/Policy Loss               14.2152
trainer/Q1 Predictions Mean      -15.137
trainer/Q1 Predictions Std         7.42664
trainer/Q1 Predictions Max       -12.524
trainer/Q1 Predictions Min       -73.3509
trainer/Q2 Predictions Mean      -15.1634
trainer/Q2 Predictions Std         7.40065
trainer/Q2 Predictions Max       -12.4774
trainer/Q2 Predictions Min       -73.1799
trainer/Q Targets Mean           -15.0917
trainer/Q Targets Std              7.67544
trainer/Q Targets Max             -1.19542
trainer/Q Targets Min            -75.5655
trainer/Log Pis Mean              -0.368695
trainer/Log Pis Std                1.10018
trainer/Log Pis Max                3.30557
trainer/Log Pis Min               -3.23581
trainer/Policy mu Mean             0.14282
trainer/Policy mu Std              0.65856
trainer/Policy mu Max              2.38851
trainer/Policy mu Min             -1.60184
trainer/Policy log std Mean       -0.69606
trainer/Policy log std Std         0.09675
trainer/Policy log std Max        -0.378882
trainer/Policy log std Min        -0.877618
trainer/Alpha                      0.328121
trainer/Alpha Loss                -2.63893
exploration/num steps total     4400
exploration/num paths total       44
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.655634
exploration/Rewards Std            0.73497
exploration/Rewards Max           -0.016577
exploration/Rewards Min           -6.65885
exploration/Returns Mean         -65.5634
exploration/Returns Std            8.16604
exploration/Returns Max          -57.3974
exploration/Returns Min          -73.7295
exploration/Actions Mean           0.0254362
exploration/Actions Std            0.479511
exploration/Actions Max            0.989363
exploration/Actions Min           -0.954068
exploration/Num Paths              2
exploration/Average Returns      -65.5634
evaluation/num steps total     21000
evaluation/num paths total       210
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.409828
evaluation/Rewards Std             1.1164
evaluation/Rewards Max            -0.139207
evaluation/Rewards Min           -10.7944
evaluation/Returns Mean          -40.9828
evaluation/Returns Std            15.622
evaluation/Returns Max           -19.5027
evaluation/Returns Min           -70.427
evaluation/Actions Mean            0.0240179
evaluation/Actions Std             0.19437
evaluation/Actions Max             0.978475
evaluation/Actions Min            -0.952934
evaluation/Num Paths              10
evaluation/Average Returns       -40.9828
time/data storing (s)              0.00129241
time/evaluation sampling (s)       0.258415
time/exploration sampling (s)      0.068403
time/logging (s)                   0.00342273
time/saving (s)                    0.00233608
time/training (s)                  0.971137
time/epoch (s)                     1.30501
time/total (s)                    27.6834
Epoch                             20
-----------------------------  --------------
2019-04-21 12:16:53.469844 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 21 finished
-----------------------------  --------------
replay_buffer/size              4600
trainer/QF1 Loss                   0.292194
trainer/QF2 Loss                   0.293125
trainer/Policy Loss               15.4935
trainer/Q1 Predictions Mean      -16.3884
trainer/Q1 Predictions Std         7.84654
trainer/Q1 Predictions Max       -12.6401
trainer/Q1 Predictions Min       -52.8517
trainer/Q2 Predictions Mean      -16.3932
trainer/Q2 Predictions Std         7.84525
trainer/Q2 Predictions Max       -12.6246
trainer/Q2 Predictions Min       -52.8207
trainer/Q Targets Mean           -16.5712
trainer/Q Targets Std              7.7567
trainer/Q Targets Max            -12.5619
trainer/Q Targets Min            -52.2221
trainer/Log Pis Mean              -0.151543
trainer/Log Pis Std                1.24027
trainer/Log Pis Max                4.22382
trainer/Log Pis Min               -3.06586
trainer/Policy mu Mean             0.153061
trainer/Policy mu Std              0.727263
trainer/Policy mu Max              2.25774
trainer/Policy mu Min             -1.84793
trainer/Policy log std Mean       -0.677261
trainer/Policy log std Std         0.100344
trainer/Policy log std Max        -0.339051
trainer/Policy log std Min        -0.840436
trainer/Alpha                      0.310078
trainer/Alpha Loss                -2.51869
exploration/num steps total     4600
exploration/num paths total       46
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.823625
exploration/Rewards Std            1.17488
exploration/Rewards Max           -0.0318686
exploration/Rewards Min           -7.9811
exploration/Returns Mean         -82.3625
exploration/Returns Std            2.90173
exploration/Returns Max          -79.4608
exploration/Returns Min          -85.2643
exploration/Actions Mean           0.0391655
exploration/Actions Std            0.504912
exploration/Actions Max            0.997069
exploration/Actions Min           -0.981928
exploration/Num Paths              2
exploration/Average Returns      -82.3625
evaluation/num steps total     22000
evaluation/num paths total       220
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.223183
evaluation/Rewards Std             0.657107
evaluation/Rewards Max            -0.0902753
evaluation/Rewards Min            -9.22617
evaluation/Returns Mean          -22.3183
evaluation/Returns Std            12.7433
evaluation/Returns Max           -13.5665
evaluation/Returns Min           -59.2471
evaluation/Actions Mean            0.0148911
evaluation/Actions Std             0.147954
evaluation/Actions Max             0.980302
evaluation/Actions Min            -0.950072
evaluation/Num Paths              10
evaluation/Average Returns       -22.3183
time/data storing (s)              0.00112555
time/evaluation sampling (s)       0.264286
time/exploration sampling (s)      0.0682458
time/logging (s)                   0.00342924
time/saving (s)                    0.00234207
time/training (s)                  0.970722
time/epoch (s)                     1.31015
time/total (s)                    28.9975
Epoch                             21
-----------------------------  --------------
2019-04-21 12:16:54.779768 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 22 finished
-----------------------------  --------------
replay_buffer/size              4800
trainer/QF1 Loss                   1.97757
trainer/QF2 Loss                   1.98884
trainer/Policy Loss               16.8355
trainer/Q1 Predictions Mean      -17.8053
trainer/Q1 Predictions Std        11.7656
trainer/Q1 Predictions Max       -12.8614
trainer/Q1 Predictions Min       -76.5724
trainer/Q2 Predictions Mean      -17.931
trainer/Q2 Predictions Std        11.7248
trainer/Q2 Predictions Max       -12.9567
trainer/Q2 Predictions Min       -76.4852
trainer/Q Targets Mean           -17.9775
trainer/Q Targets Std             12.093
trainer/Q Targets Max             -0.725031
trainer/Q Targets Min            -76.5522
trainer/Log Pis Mean               0.0320041
trainer/Log Pis Std                1.31904
trainer/Log Pis Max                4.15666
trainer/Log Pis Min               -2.84539
trainer/Policy mu Mean             0.238427
trainer/Policy mu Std              0.758654
trainer/Policy mu Max              2.29541
trainer/Policy mu Min             -1.84818
trainer/Policy log std Mean       -0.742461
trainer/Policy log std Std         0.0867569
trainer/Policy log std Max        -0.426847
trainer/Policy log std Min        -0.863856
trainer/Alpha                      0.292901
trainer/Alpha Loss                -2.41599
exploration/num steps total     4800
exploration/num paths total       48
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.662884
exploration/Rewards Std            0.651154
exploration/Rewards Max           -0.0751847
exploration/Rewards Min           -6.27383
exploration/Returns Mean         -66.2884
exploration/Returns Std            8.39861
exploration/Returns Max          -57.8898
exploration/Returns Min          -74.687
exploration/Actions Mean           0.00680822
exploration/Actions Std            0.478546
exploration/Actions Max            0.956679
exploration/Actions Min           -0.970803
exploration/Num Paths              2
exploration/Average Returns      -66.2884
evaluation/num steps total     23000
evaluation/num paths total       230
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.48575
evaluation/Rewards Std             1.04888
evaluation/Rewards Max            -0.10606
evaluation/Rewards Min            -9.26132
evaluation/Returns Mean          -48.575
evaluation/Returns Std            13.781
evaluation/Returns Max           -29.9732
evaluation/Returns Min           -71.1612
evaluation/Actions Mean            0.0405378
evaluation/Actions Std             0.193271
evaluation/Actions Max             0.978394
evaluation/Actions Min            -0.913493
evaluation/Num Paths              10
evaluation/Average Returns       -48.575
time/data storing (s)              0.00114494
time/evaluation sampling (s)       0.253659
time/exploration sampling (s)      0.0659288
time/logging (s)                   0.00262937
time/saving (s)                    0.00232362
time/training (s)                  0.978549
time/epoch (s)                     1.30424
time/total (s)                    30.3056
Epoch                             22
-----------------------------  --------------
2019-04-21 12:16:56.116533 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 23 finished
-----------------------------  --------------
replay_buffer/size              5000
trainer/QF1 Loss                   2.19078
trainer/QF2 Loss                   2.17295
trainer/Policy Loss               15.7863
trainer/Q1 Predictions Mean      -16.7015
trainer/Q1 Predictions Std         9.68674
trainer/Q1 Predictions Max       -13.0918
trainer/Q1 Predictions Min       -80.8716
trainer/Q2 Predictions Mean      -16.6952
trainer/Q2 Predictions Std         9.66869
trainer/Q2 Predictions Max       -13.1088
trainer/Q2 Predictions Min       -80.5624
trainer/Q Targets Mean           -16.5154
trainer/Q Targets Std              9.4756
trainer/Q Targets Max             -0.62431
trainer/Q Targets Min            -77.1708
trainer/Log Pis Mean              -0.19259
trainer/Log Pis Std                1.22183
trainer/Log Pis Max                3.3262
trainer/Log Pis Min               -4.89835
trainer/Policy mu Mean             0.0416497
trainer/Policy mu Std              0.740918
trainer/Policy mu Max              2.30684
trainer/Policy mu Min             -1.92643
trainer/Policy log std Mean       -0.769792
trainer/Policy log std Std         0.0977312
trainer/Policy log std Max        -0.483913
trainer/Policy log std Min        -0.94865
trainer/Alpha                      0.276753
trainer/Alpha Loss                -2.81605
exploration/num steps total     5000
exploration/num paths total       50
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.738875
exploration/Rewards Std            1.17398
exploration/Rewards Max           -0.0393529
exploration/Rewards Min           -9.75122
exploration/Returns Mean         -73.8875
exploration/Returns Std           19.7671
exploration/Returns Max          -54.1204
exploration/Returns Min          -93.6546
exploration/Actions Mean           0.00341758
exploration/Actions Std            0.510459
exploration/Actions Max            0.995637
exploration/Actions Min           -0.98986
exploration/Num Paths              2
exploration/Average Returns      -73.8875
evaluation/num steps total     24000
evaluation/num paths total       240
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.279588
evaluation/Rewards Std             1.18946
evaluation/Rewards Max            -0.0263939
evaluation/Rewards Min           -10.0579
evaluation/Returns Mean          -27.9588
evaluation/Returns Std            20.9806
evaluation/Returns Max            -3.75374
evaluation/Returns Min           -56.6997
evaluation/Actions Mean            0.0295859
evaluation/Actions Std             0.18349
evaluation/Actions Max             0.98044
evaluation/Actions Min            -0.937401
evaluation/Num Paths              10
evaluation/Average Returns       -27.9588
time/data storing (s)              0.00120928
time/evaluation sampling (s)       0.253117
time/exploration sampling (s)      0.0671426
time/logging (s)                   0.0039134
time/saving (s)                    0.00245611
time/training (s)                  1.00539
time/epoch (s)                     1.33323
time/total (s)                    31.6429
Epoch                             23
-----------------------------  --------------
2019-04-21 12:16:57.414350 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 24 finished
-----------------------------  --------------
replay_buffer/size              5200
trainer/QF1 Loss                   0.346076
trainer/QF2 Loss                   0.365649
trainer/Policy Loss               16.2107
trainer/Q1 Predictions Mean      -17.2417
trainer/Q1 Predictions Std        11.2066
trainer/Q1 Predictions Max       -13.2042
trainer/Q1 Predictions Min       -77.4615
trainer/Q2 Predictions Mean      -17.2764
trainer/Q2 Predictions Std        11.1671
trainer/Q2 Predictions Max       -13.2587
trainer/Q2 Predictions Min       -77.454
trainer/Q Targets Mean           -17.4268
trainer/Q Targets Std             11.1245
trainer/Q Targets Max            -13.2842
trainer/Q Targets Min            -76.5965
trainer/Log Pis Mean              -0.0909729
trainer/Log Pis Std                1.1487
trainer/Log Pis Max                3.54468
trainer/Log Pis Min               -3.8523
trainer/Policy mu Mean             0.02923
trainer/Policy mu Std              0.702196
trainer/Policy mu Max              2.43556
trainer/Policy mu Min             -2.14956
trainer/Policy log std Mean       -0.791337
trainer/Policy log std Std         0.107223
trainer/Policy log std Max        -0.412928
trainer/Policy log std Min        -0.971643
trainer/Alpha                      0.26185
trainer/Alpha Loss                -2.80127
exploration/num steps total     5200
exploration/num paths total       52
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.555804
exploration/Rewards Std            0.528601
exploration/Rewards Max           -0.00503494
exploration/Rewards Min           -4.43811
exploration/Returns Mean         -55.5804
exploration/Returns Std            1.79928
exploration/Returns Max          -53.7811
exploration/Returns Min          -57.3797
exploration/Actions Mean          -0.00945979
exploration/Actions Std            0.484854
exploration/Actions Max            0.926834
exploration/Actions Min           -0.979338
exploration/Num Paths              2
exploration/Average Returns      -55.5804
evaluation/num steps total     25000
evaluation/num paths total       250
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.249401
evaluation/Rewards Std             1.0852
evaluation/Rewards Max            -0.0112116
evaluation/Rewards Min            -9.51968
evaluation/Returns Mean          -24.9401
evaluation/Returns Std            17.172
evaluation/Returns Max            -2.19242
evaluation/Returns Min           -52.1286
evaluation/Actions Mean            0.0286186
evaluation/Actions Std             0.184769
evaluation/Actions Max             0.983218
evaluation/Actions Min            -0.966317
evaluation/Num Paths              10
evaluation/Average Returns       -24.9401
time/data storing (s)              0.00114452
time/evaluation sampling (s)       0.253943
time/exploration sampling (s)      0.0676756
time/logging (s)                   0.00341224
time/saving (s)                    0.00200907
time/training (s)                  0.963685
time/epoch (s)                     1.29187
time/total (s)                    32.9392
Epoch                             24
-----------------------------  --------------
2019-04-21 12:16:58.723875 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 25 finished
-----------------------------  --------------
replay_buffer/size              5400
trainer/QF1 Loss                   0.252753
trainer/QF2 Loss                   0.303624
trainer/Policy Loss               16.4239
trainer/Q1 Predictions Mean      -17.1277
trainer/Q1 Predictions Std         8.91034
trainer/Q1 Predictions Max       -13.618
trainer/Q1 Predictions Min       -64.968
trainer/Q2 Predictions Mean      -17.0347
trainer/Q2 Predictions Std         8.94481
trainer/Q2 Predictions Max       -13.4583
trainer/Q2 Predictions Min       -64.9581
trainer/Q Targets Mean           -17.2686
trainer/Q Targets Std              9.06574
trainer/Q Targets Max            -13.3799
trainer/Q Targets Min            -66.9523
trainer/Log Pis Mean               0.0142669
trainer/Log Pis Std                1.42824
trainer/Log Pis Max                4.13838
trainer/Log Pis Min               -4.26658
trainer/Policy mu Mean             0.207856
trainer/Policy mu Std              0.75951
trainer/Policy mu Max              2.48364
trainer/Policy mu Min             -1.97485
trainer/Policy log std Mean       -0.808624
trainer/Policy log std Std         0.100525
trainer/Policy log std Max        -0.541438
trainer/Policy log std Min        -0.995913
trainer/Alpha                      0.24748
trainer/Alpha Loss                -2.77237
exploration/num steps total     5400
exploration/num paths total       54
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.91429
exploration/Rewards Std            1.64567
exploration/Rewards Max           -0.0319922
exploration/Rewards Min           -9.89721
exploration/Returns Mean         -91.429
exploration/Returns Std            1.72126
exploration/Returns Max          -89.7077
exploration/Returns Min          -93.1503
exploration/Actions Mean           0.01919
exploration/Actions Std            0.477688
exploration/Actions Max            0.995752
exploration/Actions Min           -0.971078
exploration/Num Paths              2
exploration/Average Returns      -91.429
evaluation/num steps total     26000
evaluation/num paths total       260
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.2932
evaluation/Rewards Std             0.858257
evaluation/Rewards Max            -0.119844
evaluation/Rewards Min            -9.68019
evaluation/Returns Mean          -29.32
evaluation/Returns Std            15.4735
evaluation/Returns Max           -15.0452
evaluation/Returns Min           -63.5189
evaluation/Actions Mean            0.0264896
evaluation/Actions Std             0.168661
evaluation/Actions Max             0.98551
evaluation/Actions Min            -0.944317
evaluation/Num Paths              10
evaluation/Average Returns       -29.32
time/data storing (s)              0.00118185
time/evaluation sampling (s)       0.258941
time/exploration sampling (s)      0.0685795
time/logging (s)                   0.00370892
time/saving (s)                    0.00231223
time/training (s)                  0.969975
time/epoch (s)                     1.3047
time/total (s)                    34.248
Epoch                             25
-----------------------------  --------------
2019-04-21 12:17:00.032131 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 26 finished
-----------------------------  --------------
replay_buffer/size              5600
trainer/QF1 Loss                   0.399231
trainer/QF2 Loss                   0.464439
trainer/Policy Loss               17.1377
trainer/Q1 Predictions Mean      -18.0565
trainer/Q1 Predictions Std         9.19522
trainer/Q1 Predictions Max       -13.4736
trainer/Q1 Predictions Min       -66.3898
trainer/Q2 Predictions Mean      -18.0156
trainer/Q2 Predictions Std         9.16604
trainer/Q2 Predictions Max       -13.4778
trainer/Q2 Predictions Min       -65.8929
trainer/Q Targets Mean           -18.3668
trainer/Q Targets Std              9.13863
trainer/Q Targets Max            -13.6608
trainer/Q Targets Min            -67.8171
trainer/Log Pis Mean               0.178217
trainer/Log Pis Std                1.54229
trainer/Log Pis Max                5.27466
trainer/Log Pis Min               -3.21594
trainer/Policy mu Mean             0.331537
trainer/Policy mu Std              0.825236
trainer/Policy mu Max              2.43905
trainer/Policy mu Min             -1.92727
trainer/Policy log std Mean       -0.807441
trainer/Policy log std Std         0.13093
trainer/Policy log std Max        -0.436151
trainer/Policy log std Min        -1.03467
trainer/Alpha                      0.234219
trainer/Alpha Loss                -2.6438
exploration/num steps total     5600
exploration/num paths total       56
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.541847
exploration/Rewards Std            0.291747
exploration/Rewards Max           -0.0679061
exploration/Rewards Min           -2.02349
exploration/Returns Mean         -54.1847
exploration/Returns Std            2.23129
exploration/Returns Max          -51.9534
exploration/Returns Min          -56.416
exploration/Actions Mean           0.0176662
exploration/Actions Std            0.463295
exploration/Actions Max            0.987263
exploration/Actions Min           -0.930664
exploration/Num Paths              2
exploration/Average Returns      -54.1847
evaluation/num steps total     27000
evaluation/num paths total       270
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.458742
evaluation/Rewards Std             0.916173
evaluation/Rewards Max            -0.15729
evaluation/Rewards Min            -8.9436
evaluation/Returns Mean          -45.8742
evaluation/Returns Std            13.2354
evaluation/Returns Max           -27.8295
evaluation/Returns Min           -69.2525
evaluation/Actions Mean            0.035228
evaluation/Actions Std             0.176482
evaluation/Actions Max             0.98673
evaluation/Actions Min            -0.6676
evaluation/Num Paths              10
evaluation/Average Returns       -45.8742
time/data storing (s)              0.00128263
time/evaluation sampling (s)       0.249994
time/exploration sampling (s)      0.0693783
time/logging (s)                   0.00362629
time/saving (s)                    0.00273658
time/training (s)                  0.975957
time/epoch (s)                     1.30297
time/total (s)                    35.5551
Epoch                             26
-----------------------------  --------------
2019-04-21 12:17:01.339931 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 27 finished
-----------------------------  --------------
replay_buffer/size              5800
trainer/QF1 Loss                   0.883784
trainer/QF2 Loss                   0.887646
trainer/Policy Loss               17.6198
trainer/Q1 Predictions Mean      -18.946
trainer/Q1 Predictions Std        13.7926
trainer/Q1 Predictions Max       -13.3335
trainer/Q1 Predictions Min       -81.3076
trainer/Q2 Predictions Mean      -18.9598
trainer/Q2 Predictions Std        13.7567
trainer/Q2 Predictions Max       -13.3609
trainer/Q2 Predictions Min       -81.3777
trainer/Q Targets Mean           -19.466
trainer/Q Targets Std             13.694
trainer/Q Targets Max            -13.8524
trainer/Q Targets Min            -77.2093
trainer/Log Pis Mean              -0.0163922
trainer/Log Pis Std                1.49064
trainer/Log Pis Max                3.73454
trainer/Log Pis Min               -4.20681
trainer/Policy mu Mean             0.206065
trainer/Policy mu Std              0.816876
trainer/Policy mu Max              2.52532
trainer/Policy mu Min             -2.06796
trainer/Policy log std Mean       -0.78951
trainer/Policy log std Std         0.137568
trainer/Policy log std Max        -0.35698
trainer/Policy log std Min        -1.00868
trainer/Alpha                      0.221719
trainer/Alpha Loss                -3.03684
exploration/num steps total     5800
exploration/num paths total       58
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.517927
exploration/Rewards Std            0.541612
exploration/Rewards Max           -0.0288748
exploration/Rewards Min           -5.47029
exploration/Returns Mean         -51.7927
exploration/Returns Std            6.87849
exploration/Returns Max          -44.9142
exploration/Returns Min          -58.6712
exploration/Actions Mean           0.00281581
exploration/Actions Std            0.476752
exploration/Actions Max            0.956488
exploration/Actions Min           -0.927048
exploration/Num Paths              2
exploration/Average Returns      -51.7927
evaluation/num steps total     28000
evaluation/num paths total       280
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.269288
evaluation/Rewards Std             0.679978
evaluation/Rewards Max            -0.0908702
evaluation/Rewards Min            -7.8555
evaluation/Returns Mean          -26.9288
evaluation/Returns Std             9.40264
evaluation/Returns Max           -15.5697
evaluation/Returns Min           -45.2556
evaluation/Actions Mean            0.0190549
evaluation/Actions Std             0.162708
evaluation/Actions Max             0.97475
evaluation/Actions Min            -0.956817
evaluation/Num Paths              10
evaluation/Average Returns       -26.9288
time/data storing (s)              0.00117892
time/evaluation sampling (s)       0.258006
time/exploration sampling (s)      0.0680614
time/logging (s)                   0.00341408
time/saving (s)                    0.00230498
time/training (s)                  0.969479
time/epoch (s)                     1.30244
time/total (s)                    36.8616
Epoch                             27
-----------------------------  --------------
2019-04-21 12:17:02.657612 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 28 finished
-----------------------------  --------------
replay_buffer/size              6000
trainer/QF1 Loss                   3.94946
trainer/QF2 Loss                   4.03692
trainer/Policy Loss               16.7968
trainer/Q1 Predictions Mean      -17.4554
trainer/Q1 Predictions Std         7.66837
trainer/Q1 Predictions Max       -14.0451
trainer/Q1 Predictions Min       -52.5275
trainer/Q2 Predictions Mean      -17.4968
trainer/Q2 Predictions Std         7.72639
trainer/Q2 Predictions Max       -14.0562
trainer/Q2 Predictions Min       -52.8628
trainer/Q Targets Mean           -17.2777
trainer/Q Targets Std              8.10449
trainer/Q Targets Max             -0.512884
trainer/Q Targets Min            -52.3989
trainer/Log Pis Mean               0.139343
trainer/Log Pis Std                1.62929
trainer/Log Pis Max                5.38838
trainer/Log Pis Min               -3.656
trainer/Policy mu Mean             0.0562942
trainer/Policy mu Std              0.811015
trainer/Policy mu Max              2.30185
trainer/Policy mu Min             -2.12089
trainer/Policy log std Mean       -0.86596
trainer/Policy log std Std         0.139451
trainer/Policy log std Max        -0.512983
trainer/Policy log std Min        -1.1323
trainer/Alpha                      0.209839
trainer/Alpha Loss                -2.90475
exploration/num steps total     6000
exploration/num paths total       60
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.809545
exploration/Rewards Std            1.49872
exploration/Rewards Max           -0.00783339
exploration/Rewards Min          -10.383
exploration/Returns Mean         -80.9545
exploration/Returns Std           17.6243
exploration/Returns Max          -63.3302
exploration/Returns Min          -98.5789
exploration/Actions Mean           0.0610646
exploration/Actions Std            0.46938
exploration/Actions Max            0.99389
exploration/Actions Min           -0.861987
exploration/Num Paths              2
exploration/Average Returns      -80.9545
evaluation/num steps total     29000
evaluation/num paths total       290
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.248436
evaluation/Rewards Std             1.04367
evaluation/Rewards Max            -0.0235628
evaluation/Rewards Min           -10.0807
evaluation/Returns Mean          -24.8436
evaluation/Returns Std            16.7964
evaluation/Returns Max            -4.50952
evaluation/Returns Min           -54.1132
evaluation/Actions Mean            0.0242872
evaluation/Actions Std             0.189037
evaluation/Actions Max             0.988856
evaluation/Actions Min            -0.945819
evaluation/Num Paths              10
evaluation/Average Returns       -24.8436
time/data storing (s)              0.00121447
time/evaluation sampling (s)       0.258658
time/exploration sampling (s)      0.0720635
time/logging (s)                   0.00349589
time/saving (s)                    0.00233846
time/training (s)                  0.974887
time/epoch (s)                     1.31266
time/total (s)                    38.1783
Epoch                             28
-----------------------------  --------------
2019-04-21 12:17:03.970190 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 29 finished
-----------------------------  --------------
replay_buffer/size              6200
trainer/QF1 Loss                   0.499922
trainer/QF2 Loss                   0.383349
trainer/Policy Loss               16.7568
trainer/Q1 Predictions Mean      -17.1587
trainer/Q1 Predictions Std         8.54213
trainer/Q1 Predictions Max       -14.0094
trainer/Q1 Predictions Min       -54.311
trainer/Q2 Predictions Mean      -17.1779
trainer/Q2 Predictions Std         8.59029
trainer/Q2 Predictions Max       -14.074
trainer/Q2 Predictions Min       -54.6089
trainer/Q Targets Mean           -17.5078
trainer/Q Targets Std              8.8998
trainer/Q Targets Max            -14.0028
trainer/Q Targets Min            -56.4778
trainer/Log Pis Mean               0.121279
trainer/Log Pis Std                1.4584
trainer/Log Pis Max                5.91019
trainer/Log Pis Min               -4.10405
trainer/Policy mu Mean             0.0435053
trainer/Policy mu Std              0.785699
trainer/Policy mu Max              2.49744
trainer/Policy mu Min             -2.14513
trainer/Policy log std Mean       -0.908279
trainer/Policy log std Std         0.12913
trainer/Policy log std Max        -0.415948
trainer/Policy log std Min        -1.1296
trainer/Alpha                      0.198717
trainer/Alpha Loss                -3.03528
exploration/num steps total     6200
exploration/num paths total       62
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.545899
exploration/Rewards Std            0.794505
exploration/Rewards Max           -0.0901167
exploration/Rewards Min           -7.46544
exploration/Returns Mean         -54.5899
exploration/Returns Std           12.0058
exploration/Returns Max          -42.5841
exploration/Returns Min          -66.5957
exploration/Actions Mean           0.0082852
exploration/Actions Std            0.461929
exploration/Actions Max            0.991429
exploration/Actions Min           -0.976379
exploration/Num Paths              2
exploration/Average Returns      -54.5899
evaluation/num steps total     30000
evaluation/num paths total       300
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.225554
evaluation/Rewards Std             0.719383
evaluation/Rewards Max            -0.0473728
evaluation/Rewards Min            -7.80948
evaluation/Returns Mean          -22.5554
evaluation/Returns Std            10.2361
evaluation/Returns Max           -10.1108
evaluation/Returns Min           -39.664
evaluation/Actions Mean            0.016974
evaluation/Actions Std             0.166743
evaluation/Actions Max             0.981175
evaluation/Actions Min            -0.980404
evaluation/Num Paths              10
evaluation/Average Returns       -22.5554
time/data storing (s)              0.00118011
time/evaluation sampling (s)       0.256037
time/exploration sampling (s)      0.0675968
time/logging (s)                   0.00344651
time/saving (s)                    0.00231113
time/training (s)                  0.976683
time/epoch (s)                     1.30725
time/total (s)                    39.4898
Epoch                             29
-----------------------------  --------------
2019-04-21 12:17:05.282045 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 30 finished
-----------------------------  --------------
replay_buffer/size              6400
trainer/QF1 Loss                   2.15319
trainer/QF2 Loss                   2.16059
trainer/Policy Loss               15.4785
trainer/Q1 Predictions Mean      -15.9888
trainer/Q1 Predictions Std         4.248
trainer/Q1 Predictions Max       -14.3398
trainer/Q1 Predictions Min       -48.0258
trainer/Q2 Predictions Mean      -16.0235
trainer/Q2 Predictions Std         4.2281
trainer/Q2 Predictions Max       -14.414
trainer/Q2 Predictions Min       -47.9431
trainer/Q Targets Mean           -15.8398
trainer/Q Targets Std              4.29797
trainer/Q Targets Max             -0.436759
trainer/Q Targets Min            -45.761
trainer/Log Pis Mean              -0.0678465
trainer/Log Pis Std                1.42816
trainer/Log Pis Max                3.81538
trainer/Log Pis Min               -4.80636
trainer/Policy mu Mean             0.131457
trainer/Policy mu Std              0.703146
trainer/Policy mu Max              2.24447
trainer/Policy mu Min             -1.80617
trainer/Policy log std Mean       -0.94521
trainer/Policy log std Std         0.130252
trainer/Policy log std Max        -0.575889
trainer/Policy log std Min        -1.19915
trainer/Alpha                      0.188105
trainer/Alpha Loss                -3.45429
exploration/num steps total     6400
exploration/num paths total       64
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.744011
exploration/Rewards Std            1.43502
exploration/Rewards Max           -0.0681353
exploration/Rewards Min          -10.8382
exploration/Returns Mean         -74.4011
exploration/Returns Std           21.6434
exploration/Returns Max          -52.7577
exploration/Returns Min          -96.0445
exploration/Actions Mean           0.0582142
exploration/Actions Std            0.462143
exploration/Actions Max            0.99176
exploration/Actions Min           -0.928372
exploration/Num Paths              2
exploration/Average Returns      -74.4011
evaluation/num steps total     31000
evaluation/num paths total       310
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.642733
evaluation/Rewards Std             1.61791
evaluation/Rewards Max            -0.0173146
evaluation/Rewards Min            -8.06638
evaluation/Returns Mean          -64.2733
evaluation/Returns Std           147.266
evaluation/Returns Max            -2.75455
evaluation/Returns Min          -505.206
evaluation/Actions Mean           -0.0128045
evaluation/Actions Std             0.286517
evaluation/Actions Max             0.984312
evaluation/Actions Min            -0.981189
evaluation/Num Paths              10
evaluation/Average Returns       -64.2733
time/data storing (s)              0.00113526
time/evaluation sampling (s)       0.261012
time/exploration sampling (s)      0.0682568
time/logging (s)                   0.00358692
time/saving (s)                    0.00188031
time/training (s)                  0.970739
time/epoch (s)                     1.30661
time/total (s)                    40.8005
Epoch                             30
-----------------------------  --------------
2019-04-21 12:17:06.600640 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 31 finished
-----------------------------  --------------
replay_buffer/size              6600
trainer/QF1 Loss                   0.232908
trainer/QF2 Loss                   0.235361
trainer/Policy Loss               16.277
trainer/Q1 Predictions Mean      -16.4016
trainer/Q1 Predictions Std         5.19358
trainer/Q1 Predictions Max       -14.2961
trainer/Q1 Predictions Min       -48.3891
trainer/Q2 Predictions Mean      -16.4639
trainer/Q2 Predictions Std         5.20924
trainer/Q2 Predictions Max       -14.3757
trainer/Q2 Predictions Min       -48.7785
trainer/Q Targets Mean           -16.6102
trainer/Q Targets Std              5.09137
trainer/Q Targets Max            -14.3512
trainer/Q Targets Min            -47.8651
trainer/Log Pis Mean               0.219544
trainer/Log Pis Std                1.28031
trainer/Log Pis Max                4.88013
trainer/Log Pis Min               -4.92927
trainer/Policy mu Mean             0.10968
trainer/Policy mu Std              0.716133
trainer/Policy mu Max              2.29322
trainer/Policy mu Min             -1.72143
trainer/Policy log std Mean       -0.89793
trainer/Policy log std Std         0.157643
trainer/Policy log std Max        -0.388623
trainer/Policy log std Min        -1.14275
trainer/Alpha                      0.178147
trainer/Alpha Loss                -3.07106
exploration/num steps total     6600
exploration/num paths total       66
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.462249
exploration/Rewards Std            0.402709
exploration/Rewards Max           -0.00970503
exploration/Rewards Min           -4.18518
exploration/Returns Mean         -46.2249
exploration/Returns Std            4.29925
exploration/Returns Max          -41.9257
exploration/Returns Min          -50.5242
exploration/Actions Mean           0.0237685
exploration/Actions Std            0.458714
exploration/Actions Max            0.987726
exploration/Actions Min           -0.919192
exploration/Num Paths              2
exploration/Average Returns      -46.2249
evaluation/num steps total     32000
evaluation/num paths total       320
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.262774
evaluation/Rewards Std             1.05192
evaluation/Rewards Max            -0.0279683
evaluation/Rewards Min           -10.5574
evaluation/Returns Mean          -26.2774
evaluation/Returns Std            17.5803
evaluation/Returns Max            -5.45724
evaluation/Returns Min           -60.8666
evaluation/Actions Mean            0.0178411
evaluation/Actions Std             0.182377
evaluation/Actions Max             0.987718
evaluation/Actions Min            -0.966692
evaluation/Num Paths              10
evaluation/Average Returns       -26.2774
time/data storing (s)              0.00128942
time/evaluation sampling (s)       0.259956
time/exploration sampling (s)      0.0679249
time/logging (s)                   0.00356398
time/saving (s)                    0.00230685
time/training (s)                  0.978595
time/epoch (s)                     1.31364
time/total (s)                    42.1182
Epoch                             31
-----------------------------  --------------
2019-04-21 12:17:07.913722 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 32 finished
-----------------------------  --------------
replay_buffer/size              6800
trainer/QF1 Loss                   5.70591
trainer/QF2 Loss                   5.79011
trainer/Policy Loss               17.7716
trainer/Q1 Predictions Mean      -18.1876
trainer/Q1 Predictions Std         8.0563
trainer/Q1 Predictions Max       -14.6778
trainer/Q1 Predictions Min       -59.9716
trainer/Q2 Predictions Mean      -18.3148
trainer/Q2 Predictions Std         8.07397
trainer/Q2 Predictions Max       -14.783
trainer/Q2 Predictions Min       -60.059
trainer/Q Targets Mean           -17.903
trainer/Q Targets Std              8.44734
trainer/Q Targets Max             -0.95266
trainer/Q Targets Min            -60.6787
trainer/Log Pis Mean               0.185034
trainer/Log Pis Std                1.69658
trainer/Log Pis Max                5.25935
trainer/Log Pis Min               -6.75752
trainer/Policy mu Mean             0.0051033
trainer/Policy mu Std              0.836183
trainer/Policy mu Max              2.5863
trainer/Policy mu Min             -2.35464
trainer/Policy log std Mean       -0.903481
trainer/Policy log std Std         0.143036
trainer/Policy log std Max        -0.483934
trainer/Policy log std Min        -1.17825
trainer/Alpha                      0.168549
trainer/Alpha Loss                -3.23111
exploration/num steps total     6800
exploration/num paths total       68
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.569735
exploration/Rewards Std            0.763037
exploration/Rewards Max           -0.025282
exploration/Rewards Min           -6.89492
exploration/Returns Mean         -56.9735
exploration/Returns Std            7.88254
exploration/Returns Max          -49.0909
exploration/Returns Min          -64.856
exploration/Actions Mean           0.040681
exploration/Actions Std            0.460132
exploration/Actions Max            0.996306
exploration/Actions Min           -0.92228
exploration/Num Paths              2
exploration/Average Returns      -56.9735
evaluation/num steps total     33000
evaluation/num paths total       330
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.243539
evaluation/Rewards Std             0.537821
evaluation/Rewards Max            -0.0462959
evaluation/Rewards Min            -6.14758
evaluation/Returns Mean          -24.3539
evaluation/Returns Std             6.56603
evaluation/Returns Max           -15.9087
evaluation/Returns Min           -35.9912
evaluation/Actions Mean            0.00531795
evaluation/Actions Std             0.156217
evaluation/Actions Max             0.97843
evaluation/Actions Min            -0.981918
evaluation/Num Paths              10
evaluation/Average Returns       -24.3539
time/data storing (s)              0.00117558
time/evaluation sampling (s)       0.25823
time/exploration sampling (s)      0.0670603
time/logging (s)                   0.00340988
time/saving (s)                    0.00241219
time/training (s)                  0.975466
time/epoch (s)                     1.30775
time/total (s)                    43.43
Epoch                             32
-----------------------------  --------------
2019-04-21 12:17:09.224038 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 33 finished
-----------------------------  --------------
replay_buffer/size              7000
trainer/QF1 Loss                   0.451632
trainer/QF2 Loss                   0.501882
trainer/Policy Loss               17.8491
trainer/Q1 Predictions Mean      -18.3498
trainer/Q1 Predictions Std         9.90693
trainer/Q1 Predictions Max       -14.5346
trainer/Q1 Predictions Min       -77.6274
trainer/Q2 Predictions Mean      -18.4223
trainer/Q2 Predictions Std         9.91288
trainer/Q2 Predictions Max       -14.5825
trainer/Q2 Predictions Min       -77.698
trainer/Q Targets Mean           -18.6636
trainer/Q Targets Std              9.79549
trainer/Q Targets Max            -14.4881
trainer/Q Targets Min            -77.5063
trainer/Log Pis Mean               0.438474
trainer/Log Pis Std                1.47527
trainer/Log Pis Max                4.85186
trainer/Log Pis Min               -3.16979
trainer/Policy mu Mean             0.239772
trainer/Policy mu Std              0.811974
trainer/Policy mu Max              2.64069
trainer/Policy mu Min             -2.05119
trainer/Policy log std Mean       -0.951279
trainer/Policy log std Std         0.163043
trainer/Policy log std Max        -0.465111
trainer/Policy log std Min        -1.207
trainer/Alpha                      0.159613
trainer/Alpha Loss                -2.86499
exploration/num steps total     7000
exploration/num paths total       70
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.467149
exploration/Rewards Std            0.422922
exploration/Rewards Max           -0.079769
exploration/Rewards Min           -3.53738
exploration/Returns Mean         -46.7149
exploration/Returns Std            0.33738
exploration/Returns Max          -46.3775
exploration/Returns Min          -47.0522
exploration/Actions Mean           0.0238354
exploration/Actions Std            0.424538
exploration/Actions Max            0.995145
exploration/Actions Min           -0.831117
exploration/Num Paths              2
exploration/Average Returns      -46.7149
evaluation/num steps total     34000
evaluation/num paths total       340
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.305376
evaluation/Rewards Std             0.731962
evaluation/Rewards Max            -0.0807989
evaluation/Rewards Min            -7.60541
evaluation/Returns Mean          -30.5376
evaluation/Returns Std             8.99002
evaluation/Returns Max           -17.4526
evaluation/Returns Min           -42.2949
evaluation/Actions Mean            0.0217095
evaluation/Actions Std             0.171361
evaluation/Actions Max             0.985026
evaluation/Actions Min            -0.974626
evaluation/Num Paths              10
evaluation/Average Returns       -30.5376
time/data storing (s)              0.00118396
time/evaluation sampling (s)       0.254446
time/exploration sampling (s)      0.0676057
time/logging (s)                   0.00348365
time/saving (s)                    0.00233159
time/training (s)                  0.97588
time/epoch (s)                     1.30493
time/total (s)                    44.7393
Epoch                             33
-----------------------------  --------------
2019-04-21 12:17:10.529147 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 34 finished
-----------------------------  --------------
replay_buffer/size              7200
trainer/QF1 Loss                   2.48182
trainer/QF2 Loss                   2.48197
trainer/Policy Loss               19.3121
trainer/Q1 Predictions Mean      -19.9865
trainer/Q1 Predictions Std        12.3374
trainer/Q1 Predictions Max       -14.8257
trainer/Q1 Predictions Min       -81.8514
trainer/Q2 Predictions Mean      -19.8931
trainer/Q2 Predictions Std        12.3071
trainer/Q2 Predictions Max       -14.7287
trainer/Q2 Predictions Min       -81.688
trainer/Q Targets Mean           -19.784
trainer/Q Targets Std             12.3654
trainer/Q Targets Max             -0.355934
trainer/Q Targets Min            -79.3109
trainer/Log Pis Mean               0.357669
trainer/Log Pis Std                1.46047
trainer/Log Pis Max                4.74978
trainer/Log Pis Min               -3.38953
trainer/Policy mu Mean             0.135559
trainer/Policy mu Std              0.855086
trainer/Policy mu Max              2.59504
trainer/Policy mu Min             -2.33006
trainer/Policy log std Mean       -0.971617
trainer/Policy log std Std         0.170608
trainer/Policy log std Max        -0.502667
trainer/Policy log std Min        -1.2143
trainer/Alpha                      0.151305
trainer/Alpha Loss                -3.10104
exploration/num steps total     7200
exploration/num paths total       72
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.529142
exploration/Rewards Std            0.844832
exploration/Rewards Max           -0.0489163
exploration/Rewards Min           -7.22951
exploration/Returns Mean         -52.9142
exploration/Returns Std           14.2446
exploration/Returns Max          -38.6696
exploration/Returns Min          -67.1588
exploration/Actions Mean           0.0258987
exploration/Actions Std            0.418936
exploration/Actions Max            0.99085
exploration/Actions Min           -0.921453
exploration/Num Paths              2
exploration/Average Returns      -52.9142
evaluation/num steps total     35000
evaluation/num paths total       350
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.334404
evaluation/Rewards Std             1.28608
evaluation/Rewards Max            -0.0282119
evaluation/Rewards Min            -9.99414
evaluation/Returns Mean          -33.4404
evaluation/Returns Std            16.7732
evaluation/Returns Max            -7.8448
evaluation/Returns Min           -59.2898
evaluation/Actions Mean            0.0387683
evaluation/Actions Std             0.210624
evaluation/Actions Max             0.98969
evaluation/Actions Min            -0.952556
evaluation/Num Paths              10
evaluation/Average Returns       -33.4404
time/data storing (s)              0.00130312
time/evaluation sampling (s)       0.256195
time/exploration sampling (s)      0.0669226
time/logging (s)                   0.00345215
time/saving (s)                    0.00234974
time/training (s)                  0.969436
time/epoch (s)                     1.29966
time/total (s)                    46.0432
Epoch                             34
-----------------------------  --------------
2019-04-21 12:17:11.826759 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 35 finished
-----------------------------  --------------
replay_buffer/size              7400
trainer/QF1 Loss                   4.42104
trainer/QF2 Loss                   4.42922
trainer/Policy Loss               16.8712
trainer/Q1 Predictions Mean      -16.93
trainer/Q1 Predictions Std         5.60123
trainer/Q1 Predictions Max       -14.7592
trainer/Q1 Predictions Min       -48.4679
trainer/Q2 Predictions Mean      -16.9279
trainer/Q2 Predictions Std         5.62849
trainer/Q2 Predictions Max       -14.7801
trainer/Q2 Predictions Min       -48.7187
trainer/Q Targets Mean           -16.7514
trainer/Q Targets Std              6.17137
trainer/Q Targets Max             -0.449239
trainer/Q Targets Min            -50.4069
trainer/Log Pis Mean               0.567661
trainer/Log Pis Std                1.37069
trainer/Log Pis Max                6.66829
trainer/Log Pis Min               -3.96079
trainer/Policy mu Mean             0.0888634
trainer/Policy mu Std              0.761692
trainer/Policy mu Max              2.35949
trainer/Policy mu Min             -2.30333
trainer/Policy log std Mean       -1.06549
trainer/Policy log std Std         0.168506
trainer/Policy log std Max        -0.510553
trainer/Policy log std Min        -1.31642
trainer/Alpha                      0.143579
trainer/Alpha Loss                -2.7796
exploration/num steps total     7400
exploration/num paths total       74
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.375858
exploration/Rewards Std            0.313158
exploration/Rewards Max           -0.0534308
exploration/Rewards Min           -3.44972
exploration/Returns Mean         -37.5858
exploration/Returns Std            5.18067
exploration/Returns Max          -32.4052
exploration/Returns Min          -42.7665
exploration/Actions Mean           0.011068
exploration/Actions Std            0.374103
exploration/Actions Max            0.989921
exploration/Actions Min           -0.953108
exploration/Num Paths              2
exploration/Average Returns      -37.5858
evaluation/num steps total     36000
evaluation/num paths total       360
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.725952
evaluation/Rewards Std             1.59947
evaluation/Rewards Max            -0.0333739
evaluation/Rewards Min            -9.61708
evaluation/Returns Mean          -72.5952
evaluation/Returns Std           131.9
evaluation/Returns Max           -10.8428
evaluation/Returns Min          -465.791
evaluation/Actions Mean           -0.0054879
evaluation/Actions Std             0.29164
evaluation/Actions Max             0.989895
evaluation/Actions Min            -0.978331
evaluation/Num Paths              10
evaluation/Average Returns       -72.5952
time/data storing (s)              0.00115299
time/evaluation sampling (s)       0.259143
time/exploration sampling (s)      0.0663368
time/logging (s)                   0.00266271
time/saving (s)                    0.00231606
time/training (s)                  0.960047
time/epoch (s)                     1.29166
time/total (s)                    47.3388
Epoch                             35
-----------------------------  --------------
2019-04-21 12:17:13.152658 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 36 finished
-----------------------------  --------------
replay_buffer/size              7600
trainer/QF1 Loss                   2.50623
trainer/QF2 Loss                   2.54551
trainer/Policy Loss               18.3354
trainer/Q1 Predictions Mean      -18.9545
trainer/Q1 Predictions Std        10.0844
trainer/Q1 Predictions Max       -14.7209
trainer/Q1 Predictions Min       -67.431
trainer/Q2 Predictions Mean      -18.979
trainer/Q2 Predictions Std        10.0647
trainer/Q2 Predictions Max       -14.7308
trainer/Q2 Predictions Min       -67.1282
trainer/Q Targets Mean           -19.0427
trainer/Q Targets Std             10.2966
trainer/Q Targets Max             -0.345402
trainer/Q Targets Min            -69.3596
trainer/Log Pis Mean               0.54555
trainer/Log Pis Std                1.54337
trainer/Log Pis Max                6.36326
trainer/Log Pis Min               -3.09425
trainer/Policy mu Mean             0.171031
trainer/Policy mu Std              0.88907
trainer/Policy mu Max              2.62927
trainer/Policy mu Min             -2.10716
trainer/Policy log std Mean       -1.03369
trainer/Policy log std Std         0.208146
trainer/Policy log std Max        -0.52136
trainer/Policy log std Min        -1.34387
trainer/Alpha                      0.136351
trainer/Alpha Loss                -2.89764
exploration/num steps total     7600
exploration/num paths total       76
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.562299
exploration/Rewards Std            1.06144
exploration/Rewards Max           -0.0358745
exploration/Rewards Min           -8.57921
exploration/Returns Mean         -56.2299
exploration/Returns Std           18.6794
exploration/Returns Max          -37.5504
exploration/Returns Min          -74.9093
exploration/Actions Mean           0.0278606
exploration/Actions Std            0.415394
exploration/Actions Max            0.991245
exploration/Actions Min           -0.824453
exploration/Num Paths              2
exploration/Average Returns      -56.2299
evaluation/num steps total     37000
evaluation/num paths total       370
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.353112
evaluation/Rewards Std             1.32701
evaluation/Rewards Max            -0.0503219
evaluation/Rewards Min           -11.2391
evaluation/Returns Mean          -35.3112
evaluation/Returns Std            21.2112
evaluation/Returns Max            -9.62595
evaluation/Returns Min           -65.4392
evaluation/Actions Mean            0.0373529
evaluation/Actions Std             0.217755
evaluation/Actions Max             0.992712
evaluation/Actions Min            -0.980512
evaluation/Num Paths              10
evaluation/Average Returns       -35.3112
time/data storing (s)              0.00128046
time/evaluation sampling (s)       0.253885
time/exploration sampling (s)      0.0662732
time/logging (s)                   0.00354803
time/saving (s)                    0.00252146
time/training (s)                  0.995233
time/epoch (s)                     1.32274
time/total (s)                    48.6648
Epoch                             36
-----------------------------  --------------
2019-04-21 12:17:14.469402 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 37 finished
-----------------------------  --------------
replay_buffer/size              7800
trainer/QF1 Loss                   2.29816
trainer/QF2 Loss                   2.30758
trainer/Policy Loss               17.8276
trainer/Q1 Predictions Mean      -17.8298
trainer/Q1 Predictions Std         8.69327
trainer/Q1 Predictions Max       -14.8133
trainer/Q1 Predictions Min       -79.8605
trainer/Q2 Predictions Mean      -17.8584
trainer/Q2 Predictions Std         8.74626
trainer/Q2 Predictions Max       -14.7973
trainer/Q2 Predictions Min       -80.0646
trainer/Q Targets Mean           -17.9041
trainer/Q Targets Std              8.73117
trainer/Q Targets Max             -0.489007
trainer/Q Targets Min            -78.1329
trainer/Log Pis Mean               0.656048
trainer/Log Pis Std                1.52165
trainer/Log Pis Max                6.23078
trainer/Log Pis Min               -3.86877
trainer/Policy mu Mean             0.0522427
trainer/Policy mu Std              0.852891
trainer/Policy mu Max              2.67801
trainer/Policy mu Min             -2.50072
trainer/Policy log std Mean       -1.07466
trainer/Policy log std Std         0.174639
trainer/Policy log std Max        -0.536967
trainer/Policy log std Min        -1.31035
trainer/Alpha                      0.129473
trainer/Alpha Loss                -2.74708
exploration/num steps total     7800
exploration/num paths total       78
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.446893
exploration/Rewards Std            0.530457
exploration/Rewards Max           -0.0155655
exploration/Rewards Min           -5.12597
exploration/Returns Mean         -44.6893
exploration/Returns Std            5.33611
exploration/Returns Max          -39.3531
exploration/Returns Min          -50.0254
exploration/Actions Mean           0.0245727
exploration/Actions Std            0.431178
exploration/Actions Max            0.992101
exploration/Actions Min           -0.837226
exploration/Num Paths              2
exploration/Average Returns      -44.6893
evaluation/num steps total     38000
evaluation/num paths total       380
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.239665
evaluation/Rewards Std             1.01826
evaluation/Rewards Max            -0.0316309
evaluation/Rewards Min            -9.73503
evaluation/Returns Mean          -23.9665
evaluation/Returns Std            17.9529
evaluation/Returns Max            -4.96725
evaluation/Returns Min           -57.079
evaluation/Actions Mean            0.0326113
evaluation/Actions Std             0.178797
evaluation/Actions Max             0.990523
evaluation/Actions Min            -0.977409
evaluation/Num Paths              10
evaluation/Average Returns       -23.9665
time/data storing (s)              0.00135222
time/evaluation sampling (s)       0.254981
time/exploration sampling (s)      0.0675477
time/logging (s)                   0.00342566
time/saving (s)                    0.00237846
time/training (s)                  0.975387
time/epoch (s)                     1.30507
time/total (s)                    49.9798
Epoch                             37
-----------------------------  --------------
2019-04-21 12:17:15.780084 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 38 finished
-----------------------------  --------------
replay_buffer/size              8000
trainer/QF1 Loss                   0.297254
trainer/QF2 Loss                   0.29231
trainer/Policy Loss               18.1733
trainer/Q1 Predictions Mean      -18.2083
trainer/Q1 Predictions Std         9.8463
trainer/Q1 Predictions Max       -14.7068
trainer/Q1 Predictions Min       -70.545
trainer/Q2 Predictions Mean      -18.2827
trainer/Q2 Predictions Std         9.81623
trainer/Q2 Predictions Max       -14.7827
trainer/Q2 Predictions Min       -70.2319
trainer/Q Targets Mean           -18.5162
trainer/Q Targets Std              9.94767
trainer/Q Targets Max            -14.784
trainer/Q Targets Min            -71.9856
trainer/Log Pis Mean               0.474028
trainer/Log Pis Std                1.35212
trainer/Log Pis Max                5.23921
trainer/Log Pis Min               -2.54945
trainer/Policy mu Mean             0.0417483
trainer/Policy mu Std              0.813587
trainer/Policy mu Max              2.9238
trainer/Policy mu Min             -2.64469
trainer/Policy log std Mean       -1.10636
trainer/Policy log std Std         0.202479
trainer/Policy log std Max        -0.496942
trainer/Policy log std Min        -1.39757
trainer/Alpha                      0.123174
trainer/Alpha Loss                -3.19524
exploration/num steps total     8000
exploration/num paths total       80
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.442011
exploration/Rewards Std            0.589955
exploration/Rewards Max           -0.0189479
exploration/Rewards Min           -5.9164
exploration/Returns Mean         -44.2011
exploration/Returns Std            7.20718
exploration/Returns Max          -36.9939
exploration/Returns Min          -51.4083
exploration/Actions Mean           0.00512109
exploration/Actions Std            0.400835
exploration/Actions Max            0.994781
exploration/Actions Min           -0.982893
exploration/Num Paths              2
exploration/Average Returns      -44.2011
evaluation/num steps total     39000
evaluation/num paths total       390
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.346884
evaluation/Rewards Std             1.058
evaluation/Rewards Max            -0.0932757
evaluation/Rewards Min            -9.8763
evaluation/Returns Mean          -34.6884
evaluation/Returns Std            17.2614
evaluation/Returns Max           -15.4403
evaluation/Returns Min           -64.4821
evaluation/Actions Mean            0.0294844
evaluation/Actions Std             0.189266
evaluation/Actions Max             0.993652
evaluation/Actions Min            -0.98012
evaluation/Num Paths              10
evaluation/Average Returns       -34.6884
time/data storing (s)              0.00127988
time/evaluation sampling (s)       0.259017
time/exploration sampling (s)      0.0707749
time/logging (s)                   0.00339652
time/saving (s)                    0.00236508
time/training (s)                  0.968014
time/epoch (s)                     1.30485
time/total (s)                    51.2893
Epoch                             38
-----------------------------  --------------
2019-04-21 12:17:17.120978 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 39 finished
-----------------------------  --------------
replay_buffer/size              8200
trainer/QF1 Loss                   2.42142
trainer/QF2 Loss                   2.46849
trainer/Policy Loss               17.6591
trainer/Q1 Predictions Mean      -17.6853
trainer/Q1 Predictions Std         7.46977
trainer/Q1 Predictions Max       -14.7057
trainer/Q1 Predictions Min       -56.5136
trainer/Q2 Predictions Mean      -17.5737
trainer/Q2 Predictions Std         7.43942
trainer/Q2 Predictions Max       -14.6022
trainer/Q2 Predictions Min       -56.0952
trainer/Q Targets Mean           -17.796
trainer/Q Targets Std              7.53406
trainer/Q Targets Max             -0.95266
trainer/Q Targets Min            -56.1045
trainer/Log Pis Mean               0.760788
trainer/Log Pis Std                1.39113
trainer/Log Pis Max                5.62002
trainer/Log Pis Min               -3.57207
trainer/Policy mu Mean             0.0333342
trainer/Policy mu Std              0.833692
trainer/Policy mu Max              2.60611
trainer/Policy mu Min             -2.41801
trainer/Policy log std Mean       -1.15814
trainer/Policy log std Std         0.206831
trainer/Policy log std Max        -0.528803
trainer/Policy log std Min        -1.43217
trainer/Alpha                      0.117126
trainer/Alpha Loss                -2.65721
exploration/num steps total     8200
exploration/num paths total       82
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.528568
exploration/Rewards Std            0.949884
exploration/Rewards Max           -0.0149902
exploration/Rewards Min           -7.96937
exploration/Returns Mean         -52.8568
exploration/Returns Std            9.47157
exploration/Returns Max          -43.3852
exploration/Returns Min          -62.3284
exploration/Actions Mean           0.0197443
exploration/Actions Std            0.400492
exploration/Actions Max            0.992822
exploration/Actions Min           -0.990626
exploration/Num Paths              2
exploration/Average Returns      -52.8568
evaluation/num steps total     40000
evaluation/num paths total       400
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.329164
evaluation/Rewards Std             0.974595
evaluation/Rewards Max            -0.132272
evaluation/Rewards Min            -8.71928
evaluation/Returns Mean          -32.9164
evaluation/Returns Std            14.2572
evaluation/Returns Max           -13.5778
evaluation/Returns Min           -54.2982
evaluation/Actions Mean            0.0314477
evaluation/Actions Std             0.188312
evaluation/Actions Max             0.989656
evaluation/Actions Min            -0.980499
evaluation/Num Paths              10
evaluation/Average Returns       -32.9164
time/data storing (s)              0.00128306
time/evaluation sampling (s)       0.256062
time/exploration sampling (s)      0.068666
time/logging (s)                   0.00351625
time/saving (s)                    0.00271647
time/training (s)                  1.00191
time/epoch (s)                     1.33415
time/total (s)                    52.629
Epoch                             39
-----------------------------  --------------
2019-04-21 12:17:18.494303 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 40 finished
-----------------------------  --------------
replay_buffer/size              8400
trainer/QF1 Loss                   0.15389
trainer/QF2 Loss                   0.1387
trainer/Policy Loss               17.7328
trainer/Q1 Predictions Mean      -17.791
trainer/Q1 Predictions Std         8.50344
trainer/Q1 Predictions Max       -14.822
trainer/Q1 Predictions Min       -80.2185
trainer/Q2 Predictions Mean      -17.7756
trainer/Q2 Predictions Std         8.50691
trainer/Q2 Predictions Max       -14.7792
trainer/Q2 Predictions Min       -80.2599
trainer/Q Targets Mean           -17.9448
trainer/Q Targets Std              8.57412
trainer/Q Targets Max            -14.9103
trainer/Q Targets Min            -80.6001
trainer/Log Pis Mean               0.775607
trainer/Log Pis Std                1.5616
trainer/Log Pis Max                6.39219
trainer/Log Pis Min               -2.88706
trainer/Policy mu Mean             0.108994
trainer/Policy mu Std              0.849676
trainer/Policy mu Max              2.85453
trainer/Policy mu Min             -2.19414
trainer/Policy log std Mean       -1.2205
trainer/Policy log std Std         0.201438
trainer/Policy log std Max        -0.530173
trainer/Policy log std Min        -1.49765
trainer/Alpha                      0.11152
trainer/Alpha Loss                -2.68548
exploration/num steps total     8400
exploration/num paths total       84
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.790357
exploration/Rewards Std            1.71704
exploration/Rewards Max           -0.0233688
exploration/Rewards Min          -10.0702
exploration/Returns Mean         -79.0357
exploration/Returns Std            2.38353
exploration/Returns Max          -76.6521
exploration/Returns Min          -81.4192
exploration/Actions Mean           0.0292498
exploration/Actions Std            0.407208
exploration/Actions Max            0.998764
exploration/Actions Min           -0.923315
exploration/Num Paths              2
exploration/Average Returns      -79.0357
evaluation/num steps total     41000
evaluation/num paths total       410
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.136759
evaluation/Rewards Std             0.687842
evaluation/Rewards Max            -0.0117031
evaluation/Rewards Min            -7.31786
evaluation/Returns Mean          -13.6759
evaluation/Returns Std             7.73006
evaluation/Returns Max            -2.36904
evaluation/Returns Min           -26.5039
evaluation/Actions Mean            0.0249074
evaluation/Actions Std             0.180456
evaluation/Actions Max             0.989647
evaluation/Actions Min            -0.97671
evaluation/Num Paths              10
evaluation/Average Returns       -13.6759
time/data storing (s)              0.001134
time/evaluation sampling (s)       0.275818
time/exploration sampling (s)      0.0680959
time/logging (s)                   0.00311684
time/saving (s)                    0.00231533
time/training (s)                  1.01684
time/epoch (s)                     1.36732
time/total (s)                    54.0007
Epoch                             40
-----------------------------  --------------
2019-04-21 12:17:19.834280 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 41 finished
-----------------------------  --------------
replay_buffer/size              8600
trainer/QF1 Loss                   2.27791
trainer/QF2 Loss                   2.25962
trainer/Policy Loss               16.9118
trainer/Q1 Predictions Mean      -16.8108
trainer/Q1 Predictions Std         4.62353
trainer/Q1 Predictions Max       -14.7326
trainer/Q1 Predictions Min       -47.5022
trainer/Q2 Predictions Mean      -16.8517
trainer/Q2 Predictions Std         4.61006
trainer/Q2 Predictions Max       -14.7632
trainer/Q2 Predictions Min       -47.307
trainer/Q Targets Mean           -16.8933
trainer/Q Targets Std              4.80104
trainer/Q Targets Max             -1.26615
trainer/Q Targets Min            -47.2795
trainer/Log Pis Mean               0.732547
trainer/Log Pis Std                1.4118
trainer/Log Pis Max                4.90635
trainer/Log Pis Min               -3.07129
trainer/Policy mu Mean             0.0897687
trainer/Policy mu Std              0.855184
trainer/Policy mu Max              2.34849
trainer/Policy mu Min             -2.39371
trainer/Policy log std Mean       -1.21384
trainer/Policy log std Std         0.223656
trainer/Policy log std Max        -0.595141
trainer/Policy log std Min        -1.49341
trainer/Alpha                      0.106272
trainer/Alpha Loss                -2.84102
exploration/num steps total     8600
exploration/num paths total       86
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.442779
exploration/Rewards Std            0.638851
exploration/Rewards Max           -0.0172768
exploration/Rewards Min           -5.42776
exploration/Returns Mean         -44.2779
exploration/Returns Std            1.72754
exploration/Returns Max          -42.5504
exploration/Returns Min          -46.0055
exploration/Actions Mean           0.00268602
exploration/Actions Std            0.382088
exploration/Actions Max            0.9846
exploration/Actions Min           -0.996075
exploration/Num Paths              2
exploration/Average Returns      -44.2779
evaluation/num steps total     42000
evaluation/num paths total       420
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.226294
evaluation/Rewards Std             0.865889
evaluation/Rewards Max            -0.0613483
evaluation/Rewards Min           -10.0553
evaluation/Returns Mean          -22.6294
evaluation/Returns Std            14.2762
evaluation/Returns Max            -8.46423
evaluation/Returns Min           -58.6301
evaluation/Actions Mean            0.0199062
evaluation/Actions Std             0.18542
evaluation/Actions Max             0.993032
evaluation/Actions Min            -0.984177
evaluation/Num Paths              10
evaluation/Average Returns       -22.6294
time/data storing (s)              0.00118592
time/evaluation sampling (s)       0.260099
time/exploration sampling (s)      0.071894
time/logging (s)                   0.00485259
time/saving (s)                    0.00233335
time/training (s)                  0.996155
time/epoch (s)                     1.33652
time/total (s)                    55.3412
Epoch                             41
-----------------------------  --------------
2019-04-21 12:17:21.165148 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 42 finished
-----------------------------  --------------
replay_buffer/size              8800
trainer/QF1 Loss                   2.34965
trainer/QF2 Loss                   2.35207
trainer/Policy Loss               18.5008
trainer/Q1 Predictions Mean      -18.2162
trainer/Q1 Predictions Std         9.87054
trainer/Q1 Predictions Max       -15.0277
trainer/Q1 Predictions Min       -81.8548
trainer/Q2 Predictions Mean      -18.281
trainer/Q2 Predictions Std         9.8243
trainer/Q2 Predictions Max       -15.1099
trainer/Q2 Predictions Min       -81.5952
trainer/Q Targets Mean           -18.0052
trainer/Q Targets Std              9.80496
trainer/Q Targets Max             -0.817901
trainer/Q Targets Min            -78.984
trainer/Log Pis Mean               0.808755
trainer/Log Pis Std                1.38547
trainer/Log Pis Max                5.89164
trainer/Log Pis Min               -2.6953
trainer/Policy mu Mean             0.0365043
trainer/Policy mu Std              0.842941
trainer/Policy mu Max              2.90206
trainer/Policy mu Min             -2.53374
trainer/Policy log std Mean       -1.24281
trainer/Policy log std Std         0.216902
trainer/Policy log std Max        -0.557184
trainer/Policy log std Min        -1.54981
trainer/Alpha                      0.101121
trainer/Alpha Loss                -2.72938
exploration/num steps total     8800
exploration/num paths total       88
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.602111
exploration/Rewards Std            1.32027
exploration/Rewards Max           -0.0315249
exploration/Rewards Min           -9.54299
exploration/Returns Mean         -60.2111
exploration/Returns Std            9.08335
exploration/Returns Max          -51.1278
exploration/Returns Min          -69.2945
exploration/Actions Mean           0.0261633
exploration/Actions Std            0.372187
exploration/Actions Max            0.997895
exploration/Actions Min           -0.967662
exploration/Num Paths              2
exploration/Average Returns      -60.2111
evaluation/num steps total     43000
evaluation/num paths total       430
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.198606
evaluation/Rewards Std             0.786448
evaluation/Rewards Max            -0.0256607
evaluation/Rewards Min            -8.4189
evaluation/Returns Mean          -19.8606
evaluation/Returns Std            10.667
evaluation/Returns Max            -5.70879
evaluation/Returns Min           -38.4806
evaluation/Actions Mean            0.0247729
evaluation/Actions Std             0.18159
evaluation/Actions Max             0.989784
evaluation/Actions Min            -0.979285
evaluation/Num Paths              10
evaluation/Average Returns       -19.8606
time/data storing (s)              0.00116254
time/evaluation sampling (s)       0.268437
time/exploration sampling (s)      0.0681707
time/logging (s)                   0.00339358
time/saving (s)                    0.00233897
time/training (s)                  0.980539
time/epoch (s)                     1.32404
time/total (s)                    56.6694
Epoch                             42
-----------------------------  --------------
2019-04-21 12:17:22.481882 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 43 finished
-----------------------------  --------------
replay_buffer/size              9000
trainer/QF1 Loss                   2.47679
trainer/QF2 Loss                   2.49385
trainer/Policy Loss               18.3131
trainer/Q1 Predictions Mean      -18.3102
trainer/Q1 Predictions Std         8.60474
trainer/Q1 Predictions Max       -14.7374
trainer/Q1 Predictions Min       -64.2065
trainer/Q2 Predictions Mean      -18.3633
trainer/Q2 Predictions Std         8.69061
trainer/Q2 Predictions Max       -14.738
trainer/Q2 Predictions Min       -64.6193
trainer/Q Targets Mean           -18.4094
trainer/Q Targets Std              8.78016
trainer/Q Targets Max             -1.22088
trainer/Q Targets Min            -65.7
trainer/Log Pis Mean               0.816404
trainer/Log Pis Std                1.55691
trainer/Log Pis Max                7.00338
trainer/Log Pis Min               -4.94985
trainer/Policy mu Mean             0.169753
trainer/Policy mu Std              0.898602
trainer/Policy mu Max              2.79257
trainer/Policy mu Min             -2.28227
trainer/Policy log std Mean       -1.22336
trainer/Policy log std Std         0.239832
trainer/Policy log std Max        -0.571477
trainer/Policy log std Min        -1.52696
trainer/Alpha                      0.0962055
trainer/Alpha Loss                -2.77082
exploration/num steps total     9000
exploration/num paths total       90
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.394928
exploration/Rewards Std            0.571726
exploration/Rewards Max           -0.0196499
exploration/Rewards Min           -4.40766
exploration/Returns Mean         -39.4928
exploration/Returns Std            0.845843
exploration/Returns Max          -38.647
exploration/Returns Min          -40.3387
exploration/Actions Mean           0.0316451
exploration/Actions Std            0.357171
exploration/Actions Max            0.993135
exploration/Actions Min           -0.834804
exploration/Num Paths              2
exploration/Average Returns      -39.4928
evaluation/num steps total     44000
evaluation/num paths total       440
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.931575
evaluation/Rewards Std             1.68264
evaluation/Rewards Max            -0.0131077
evaluation/Rewards Min           -10.44
evaluation/Returns Mean          -93.1575
evaluation/Returns Std           143.605
evaluation/Returns Max            -6.71685
evaluation/Returns Min          -398.388
evaluation/Actions Mean           -0.054804
evaluation/Actions Std             0.35619
evaluation/Actions Max             0.994521
evaluation/Actions Min            -0.990426
evaluation/Num Paths              10
evaluation/Average Returns       -93.1575
time/data storing (s)              0.00113001
time/evaluation sampling (s)       0.257943
time/exploration sampling (s)      0.0678485
time/logging (s)                   0.00343256
time/saving (s)                    0.00235174
time/training (s)                  0.978495
time/epoch (s)                     1.3112
time/total (s)                    57.9848
Epoch                             43
-----------------------------  --------------
2019-04-21 12:17:23.794648 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 44 finished
-----------------------------  --------------
replay_buffer/size              9200
trainer/QF1 Loss                   4.84425
trainer/QF2 Loss                   5.04284
trainer/Policy Loss               18.4615
trainer/Q1 Predictions Mean      -18.2786
trainer/Q1 Predictions Std        10.3307
trainer/Q1 Predictions Max       -14.9918
trainer/Q1 Predictions Min       -79.9368
trainer/Q2 Predictions Mean      -18.2731
trainer/Q2 Predictions Std        10.343
trainer/Q2 Predictions Max       -14.9293
trainer/Q2 Predictions Min       -79.6088
trainer/Q Targets Mean           -18.0102
trainer/Q Targets Std             10.3977
trainer/Q Targets Max             -0.60285
trainer/Q Targets Min            -78.6455
trainer/Log Pis Mean               0.847043
trainer/Log Pis Std                1.47275
trainer/Log Pis Max                6.57259
trainer/Log Pis Min               -4.22342
trainer/Policy mu Mean             0.222167
trainer/Policy mu Std              0.829594
trainer/Policy mu Max              2.98482
trainer/Policy mu Min             -1.26465
trainer/Policy log std Mean       -1.30265
trainer/Policy log std Std         0.221735
trainer/Policy log std Max        -0.608289
trainer/Policy log std Min        -1.58605
trainer/Alpha                      0.0915665
trainer/Alpha Loss                -2.75609
exploration/num steps total     9200
exploration/num paths total       92
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.525869
exploration/Rewards Std            1.08662
exploration/Rewards Max           -0.0265299
exploration/Rewards Min           -7.83298
exploration/Returns Mean         -52.5869
exploration/Returns Std            7.49998
exploration/Returns Max          -45.0869
exploration/Returns Min          -60.0869
exploration/Actions Mean           0.0381301
exploration/Actions Std            0.369544
exploration/Actions Max            0.993565
exploration/Actions Min           -0.988276
exploration/Num Paths              2
exploration/Average Returns      -52.5869
evaluation/num steps total     45000
evaluation/num paths total       450
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.281952
evaluation/Rewards Std             1.10661
evaluation/Rewards Max            -0.0390154
evaluation/Rewards Min           -10.6763
evaluation/Returns Mean          -28.1952
evaluation/Returns Std            18.3496
evaluation/Returns Max            -7.36795
evaluation/Returns Min           -64.3493
evaluation/Actions Mean            0.035748
evaluation/Actions Std             0.191629
evaluation/Actions Max             0.995776
evaluation/Actions Min            -0.889019
evaluation/Num Paths              10
evaluation/Average Returns       -28.1952
time/data storing (s)              0.00116872
time/evaluation sampling (s)       0.262067
time/exploration sampling (s)      0.0677279
time/logging (s)                   0.00333878
time/saving (s)                    0.00233178
time/training (s)                  0.970638
time/epoch (s)                     1.30727
time/total (s)                    59.2961
Epoch                             44
-----------------------------  --------------
2019-04-21 12:17:25.111054 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 45 finished
-----------------------------  --------------
replay_buffer/size              9400
trainer/QF1 Loss                   0.117694
trainer/QF2 Loss                   0.0802359
trainer/Policy Loss               18.2614
trainer/Q1 Predictions Mean      -17.9324
trainer/Q1 Predictions Std         8.44212
trainer/Q1 Predictions Max       -14.9446
trainer/Q1 Predictions Min       -62.665
trainer/Q2 Predictions Mean      -18.0071
trainer/Q2 Predictions Std         8.48493
trainer/Q2 Predictions Max       -14.9693
trainer/Q2 Predictions Min       -63.5555
trainer/Q Targets Mean           -18.041
trainer/Q Targets Std              8.53005
trainer/Q Targets Max            -14.9271
trainer/Q Targets Min            -63.817
trainer/Log Pis Mean               1.03556
trainer/Log Pis Std                1.73643
trainer/Log Pis Max                6.83802
trainer/Log Pis Min               -1.68556
trainer/Policy mu Mean             0.110384
trainer/Policy mu Std              0.915907
trainer/Policy mu Max              3.05357
trainer/Policy mu Min             -2.4188
trainer/Policy log std Mean       -1.25456
trainer/Policy log std Std         0.220113
trainer/Policy log std Max        -0.605365
trainer/Policy log std Min        -1.54
trainer/Alpha                      0.0870641
trainer/Alpha Loss                -2.35405
exploration/num steps total     9400
exploration/num paths total       94
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.480383
exploration/Rewards Std            0.921502
exploration/Rewards Max           -0.0186326
exploration/Rewards Min           -7.45293
exploration/Returns Mean         -48.0383
exploration/Returns Std            5.14921
exploration/Returns Max          -42.8891
exploration/Returns Min          -53.1875
exploration/Actions Mean           0.0274493
exploration/Actions Std            0.383601
exploration/Actions Max            0.988591
exploration/Actions Min           -0.990173
exploration/Num Paths              2
exploration/Average Returns      -48.0383
evaluation/num steps total     46000
evaluation/num paths total       460
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.267175
evaluation/Rewards Std             1.08289
evaluation/Rewards Max            -0.0315654
evaluation/Rewards Min            -9.33127
evaluation/Returns Mean          -26.7175
evaluation/Returns Std            16.6031
evaluation/Returns Max           -10.4637
evaluation/Returns Min           -51.5114
evaluation/Actions Mean            0.0250404
evaluation/Actions Std             0.198548
evaluation/Actions Max             0.99485
evaluation/Actions Min            -0.985543
evaluation/Num Paths              10
evaluation/Average Returns       -26.7175
time/data storing (s)              0.00122862
time/evaluation sampling (s)       0.258271
time/exploration sampling (s)      0.0699671
time/logging (s)                   0.00343665
time/saving (s)                    0.00238989
time/training (s)                  0.976542
time/epoch (s)                     1.31183
time/total (s)                    60.6117
Epoch                             45
-----------------------------  --------------
2019-04-21 12:17:26.422016 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 46 finished
-----------------------------  --------------
replay_buffer/size              9600
trainer/QF1 Loss                  27.3849
trainer/QF2 Loss                  28.0577
trainer/Policy Loss               18.6468
trainer/Q1 Predictions Mean      -18.0213
trainer/Q1 Predictions Std         7.19189
trainer/Q1 Predictions Max       -15.1216
trainer/Q1 Predictions Min       -57.7677
trainer/Q2 Predictions Mean      -17.9879
trainer/Q2 Predictions Std         7.26791
trainer/Q2 Predictions Max       -15.066
trainer/Q2 Predictions Min       -58.5112
trainer/Q Targets Mean           -17.0988
trainer/Q Targets Std              6.33353
trainer/Q Targets Max             -0.134602
trainer/Q Targets Min            -48.742
trainer/Log Pis Mean               1.16513
trainer/Log Pis Std                1.46714
trainer/Log Pis Max                6.16618
trainer/Log Pis Min               -1.32217
trainer/Policy mu Mean             0.0784765
trainer/Policy mu Std              0.952321
trainer/Policy mu Max              3.01892
trainer/Policy mu Min             -2.59199
trainer/Policy log std Mean       -1.26573
trainer/Policy log std Std         0.285039
trainer/Policy log std Max        -0.552084
trainer/Policy log std Min        -1.60201
trainer/Alpha                      0.0830488
trainer/Alpha Loss                -2.07723
exploration/num steps total     9600
exploration/num paths total       96
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.593521
exploration/Rewards Std            1.19481
exploration/Rewards Max           -0.0485772
exploration/Rewards Min           -8.58121
exploration/Returns Mean         -59.3521
exploration/Returns Std            9.54352
exploration/Returns Max          -49.8086
exploration/Returns Min          -68.8956
exploration/Actions Mean           0.0042247
exploration/Actions Std            0.372649
exploration/Actions Max            0.999373
exploration/Actions Min           -0.996294
exploration/Num Paths              2
exploration/Average Returns      -59.3521
evaluation/num steps total     47000
evaluation/num paths total       470
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.247877
evaluation/Rewards Std             0.861381
evaluation/Rewards Max            -0.0362251
evaluation/Rewards Min            -9.17493
evaluation/Returns Mean          -24.7877
evaluation/Returns Std            13.9523
evaluation/Returns Max           -11.2563
evaluation/Returns Min           -51.8706
evaluation/Actions Mean            0.0188654
evaluation/Actions Std             0.187371
evaluation/Actions Max             0.994739
evaluation/Actions Min            -0.992741
evaluation/Num Paths              10
evaluation/Average Returns       -24.7877
time/data storing (s)              0.00120267
time/evaluation sampling (s)       0.256865
time/exploration sampling (s)      0.0690118
time/logging (s)                   0.00375348
time/saving (s)                    0.00193949
time/training (s)                  0.972968
time/epoch (s)                     1.30574
time/total (s)                    61.9217
Epoch                             46
-----------------------------  --------------
2019-04-21 12:17:27.727419 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 47 finished
-----------------------------  --------------
replay_buffer/size              9800
trainer/QF1 Loss                   4.68073
trainer/QF2 Loss                   4.68036
trainer/Policy Loss               18.522
trainer/Q1 Predictions Mean      -18.0612
trainer/Q1 Predictions Std         8.33243
trainer/Q1 Predictions Max       -15.1428
trainer/Q1 Predictions Min       -72.6141
trainer/Q2 Predictions Mean      -17.9804
trainer/Q2 Predictions Std         8.3053
trainer/Q2 Predictions Max       -15.0373
trainer/Q2 Predictions Min       -72.6732
trainer/Q Targets Mean           -17.6672
trainer/Q Targets Std              8.78687
trainer/Q Targets Max             -0.307175
trainer/Q Targets Min            -73.5648
trainer/Log Pis Mean               1.25003
trainer/Log Pis Std                1.49854
trainer/Log Pis Max                7.37722
trainer/Log Pis Min               -2.36937
trainer/Policy mu Mean             0.047999
trainer/Policy mu Std              0.90545
trainer/Policy mu Max              3.25073
trainer/Policy mu Min             -3.00828
trainer/Policy log std Mean       -1.35781
trainer/Policy log std Std         0.261577
trainer/Policy log std Max        -0.532806
trainer/Policy log std Min        -1.68266
trainer/Alpha                      0.0792955
trainer/Alpha Loss                -1.9007
exploration/num steps total     9800
exploration/num paths total       98
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.339018
exploration/Rewards Std            0.558436
exploration/Rewards Max           -0.00830603
exploration/Rewards Min           -5.80578
exploration/Returns Mean         -33.9018
exploration/Returns Std            5.82863
exploration/Returns Max          -28.0732
exploration/Returns Min          -39.7305
exploration/Actions Mean          -0.00398843
exploration/Actions Std            0.324381
exploration/Actions Max            0.987857
exploration/Actions Min           -0.998023
exploration/Num Paths              2
exploration/Average Returns      -33.9018
evaluation/num steps total     48000
evaluation/num paths total       480
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.195096
evaluation/Rewards Std             0.698903
evaluation/Rewards Max            -0.0602853
evaluation/Rewards Min            -7.85278
evaluation/Returns Mean          -19.5096
evaluation/Returns Std             8.91914
evaluation/Returns Max            -9.30865
evaluation/Returns Min           -33.9533
evaluation/Actions Mean            0.00667714
evaluation/Actions Std             0.177958
evaluation/Actions Max             0.992929
evaluation/Actions Min            -0.993263
evaluation/Num Paths              10
evaluation/Average Returns       -19.5096
time/data storing (s)              0.00128852
time/evaluation sampling (s)       0.255441
time/exploration sampling (s)      0.0683751
time/logging (s)                   0.00341465
time/saving (s)                    0.0023224
time/training (s)                  0.968385
time/epoch (s)                     1.29923
time/total (s)                    63.2255
Epoch                             47
-----------------------------  --------------
2019-04-21 12:17:29.025203 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 48 finished
-----------------------------  --------------
replay_buffer/size             10000
trainer/QF1 Loss                   2.25854
trainer/QF2 Loss                   2.30655
trainer/Policy Loss               17.7143
trainer/Q1 Predictions Mean      -17.3457
trainer/Q1 Predictions Std         6.66073
trainer/Q1 Predictions Max       -14.7754
trainer/Q1 Predictions Min       -58.9307
trainer/Q2 Predictions Mean      -17.2802
trainer/Q2 Predictions Std         6.65113
trainer/Q2 Predictions Max       -14.7137
trainer/Q2 Predictions Min       -58.9408
trainer/Q Targets Mean           -17.3674
trainer/Q Targets Std              6.82984
trainer/Q Targets Max             -0.355934
trainer/Q Targets Min            -58.8318
trainer/Log Pis Mean               0.997837
trainer/Log Pis Std                1.42835
trainer/Log Pis Max                7.62697
trainer/Log Pis Min               -4.62655
trainer/Policy mu Mean             0.154197
trainer/Policy mu Std              0.907278
trainer/Policy mu Max              2.81517
trainer/Policy mu Min             -2.92647
trainer/Policy log std Mean       -1.33711
trainer/Policy log std Std         0.277924
trainer/Policy log std Max        -0.502731
trainer/Policy log std Min        -1.60378
trainer/Alpha                      0.0757117
trainer/Alpha Loss                -2.58616
exploration/num steps total    10000
exploration/num paths total      100
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.439637
exploration/Rewards Std            0.764313
exploration/Rewards Max           -0.0337846
exploration/Rewards Min           -5.50932
exploration/Returns Mean         -43.9637
exploration/Returns Std            1.62929
exploration/Returns Max          -42.3345
exploration/Returns Min          -45.593
exploration/Actions Mean           0.00764362
exploration/Actions Std            0.35948
exploration/Actions Max            0.993014
exploration/Actions Min           -0.997685
exploration/Num Paths              2
exploration/Average Returns      -43.9637
evaluation/num steps total     49000
evaluation/num paths total       490
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.842705
evaluation/Rewards Std             1.73842
evaluation/Rewards Max            -0.113638
evaluation/Rewards Min           -10.1776
evaluation/Returns Mean          -84.2705
evaluation/Returns Std           124.492
evaluation/Returns Max           -20.0237
evaluation/Returns Min          -454.432
evaluation/Actions Mean           -0.00870387
evaluation/Actions Std             0.310599
evaluation/Actions Max             0.995549
evaluation/Actions Min            -0.993621
evaluation/Num Paths              10
evaluation/Average Returns       -84.2705
time/data storing (s)              0.00114148
time/evaluation sampling (s)       0.25685
time/exploration sampling (s)      0.0665015
time/logging (s)                   0.00340321
time/saving (s)                    0.0024209
time/training (s)                  0.962031
time/epoch (s)                     1.29235
time/total (s)                    64.522
Epoch                             48
-----------------------------  --------------
2019-04-21 12:17:30.328012 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 49 finished
-----------------------------  --------------
replay_buffer/size             10200
trainer/QF1 Loss                   2.24821
trainer/QF2 Loss                   2.2569
trainer/Policy Loss               16.9398
trainer/Q1 Predictions Mean      -16.6147
trainer/Q1 Predictions Std         5.00479
trainer/Q1 Predictions Max       -14.8519
trainer/Q1 Predictions Min       -43.8736
trainer/Q2 Predictions Mean      -16.6199
trainer/Q2 Predictions Std         5.00599
trainer/Q2 Predictions Max       -14.7867
trainer/Q2 Predictions Min       -43.8525
trainer/Q Targets Mean           -16.6617
trainer/Q Targets Std              5.32407
trainer/Q Targets Max             -0.53242
trainer/Q Targets Min            -44.1456
trainer/Log Pis Mean               0.894333
trainer/Log Pis Std                1.37493
trainer/Log Pis Max                5.38638
trainer/Log Pis Min               -4.14888
trainer/Policy mu Mean             0.0773183
trainer/Policy mu Std              0.796853
trainer/Policy mu Max              2.90244
trainer/Policy mu Min             -2.37638
trainer/Policy log std Mean       -1.42934
trainer/Policy log std Std         0.228163
trainer/Policy log std Max        -0.542249
trainer/Policy log std Min        -1.69728
trainer/Alpha                      0.0720116
trainer/Alpha Loss                -2.90866
exploration/num steps total    10200
exploration/num paths total      102
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.47854
exploration/Rewards Std            1.01914
exploration/Rewards Max           -0.0227367
exploration/Rewards Min           -8.63079
exploration/Returns Mean         -47.854
exploration/Returns Std           13.2341
exploration/Returns Max          -34.6199
exploration/Returns Min          -61.088
exploration/Actions Mean           0.042532
exploration/Actions Std            0.356706
exploration/Actions Max            0.996346
exploration/Actions Min           -0.795704
exploration/Num Paths              2
exploration/Average Returns      -47.854
evaluation/num steps total     50000
evaluation/num paths total       500
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.355527
evaluation/Rewards Std             1.16403
evaluation/Rewards Max            -0.0788188
evaluation/Rewards Min           -10.46
evaluation/Returns Mean          -35.5527
evaluation/Returns Std            16.7503
evaluation/Returns Max           -10.5726
evaluation/Returns Min           -63.8495
evaluation/Actions Mean            0.0477612
evaluation/Actions Std             0.206045
evaluation/Actions Max             0.995132
evaluation/Actions Min            -0.783634
evaluation/Num Paths              10
evaluation/Average Returns       -35.5527
time/data storing (s)              0.00123262
time/evaluation sampling (s)       0.257923
time/exploration sampling (s)      0.0719184
time/logging (s)                   0.00343193
time/saving (s)                    0.00251427
time/training (s)                  0.959979
time/epoch (s)                     1.297
time/total (s)                    65.8235
Epoch                             49
-----------------------------  --------------
2019-04-21 12:17:31.765776 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 50 finished
-----------------------------  ---------------
replay_buffer/size             10400
trainer/QF1 Loss                   0.106645
trainer/QF2 Loss                   0.112859
trainer/Policy Loss               17.5666
trainer/Q1 Predictions Mean      -16.7655
trainer/Q1 Predictions Std         4.69805
trainer/Q1 Predictions Max       -14.7931
trainer/Q1 Predictions Min       -39.4531
trainer/Q2 Predictions Mean      -16.7343
trainer/Q2 Predictions Std         4.67796
trainer/Q2 Predictions Max       -14.7516
trainer/Q2 Predictions Min       -39.5341
trainer/Q Targets Mean           -16.839
trainer/Q Targets Std              4.62072
trainer/Q Targets Max            -14.825
trainer/Q Targets Min            -39.4116
trainer/Log Pis Mean               1.3348
trainer/Log Pis Std                1.30019
trainer/Log Pis Max                6.35342
trainer/Log Pis Min               -3.27653
trainer/Policy mu Mean             0.0477762
trainer/Policy mu Std              0.842595
trainer/Policy mu Max              2.99883
trainer/Policy mu Min             -2.90255
trainer/Policy log std Mean       -1.5006
trainer/Policy log std Std         0.313958
trainer/Policy log std Max        -0.533661
trainer/Policy log std Min        -1.79989
trainer/Alpha                      0.0690329
trainer/Alpha Loss                -1.77807
exploration/num steps total    10400
exploration/num paths total      104
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.43446
exploration/Rewards Std            1.04603
exploration/Rewards Max           -0.0162307
exploration/Rewards Min           -8.82735
exploration/Returns Mean         -43.446
exploration/Returns Std           16.0094
exploration/Returns Max          -27.4366
exploration/Returns Min          -59.4554
exploration/Actions Mean           0.041619
exploration/Actions Std            0.327602
exploration/Actions Max            0.99786
exploration/Actions Min           -0.766015
exploration/Num Paths              2
exploration/Average Returns      -43.446
evaluation/num steps total     51000
evaluation/num paths total       510
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.500145
evaluation/Rewards Std             1.29873
evaluation/Rewards Max            -0.000487435
evaluation/Rewards Min            -8.90573
evaluation/Returns Mean          -50.0145
evaluation/Returns Std           108.039
evaluation/Returns Max            -0.569095
evaluation/Returns Min          -372.6
evaluation/Actions Mean           -0.03053
evaluation/Actions Std             0.273697
evaluation/Actions Max             0.994833
evaluation/Actions Min            -0.99384
evaluation/Num Paths              10
evaluation/Average Returns       -50.0145
time/data storing (s)              0.00121055
time/evaluation sampling (s)       0.26151
time/exploration sampling (s)      0.0740176
time/logging (s)                   0.00372378
time/saving (s)                    0.00268072
time/training (s)                  1.08918
time/epoch (s)                     1.43232
time/total (s)                    67.2602
Epoch                             50
-----------------------------  ---------------
2019-04-21 12:17:33.423914 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 51 finished
-----------------------------  --------------
replay_buffer/size             10600
trainer/QF1 Loss                   4.45875
trainer/QF2 Loss                   4.49253
trainer/Policy Loss               18.8941
trainer/Q1 Predictions Mean      -18.0982
trainer/Q1 Predictions Std         9.2328
trainer/Q1 Predictions Max       -14.614
trainer/Q1 Predictions Min       -62.376
trainer/Q2 Predictions Mean      -18.1835
trainer/Q2 Predictions Std         9.21917
trainer/Q2 Predictions Max       -14.6563
trainer/Q2 Predictions Min       -62.3843
trainer/Q Targets Mean           -18.0595
trainer/Q Targets Std              9.54597
trainer/Q Targets Max             -0.558678
trainer/Q Targets Min            -63.1915
trainer/Log Pis Mean               1.22493
trainer/Log Pis Std                1.48305
trainer/Log Pis Max                6.25484
trainer/Log Pis Min               -2.57379
trainer/Policy mu Mean             0.0220189
trainer/Policy mu Std              0.928553
trainer/Policy mu Max              3.07481
trainer/Policy mu Min             -2.55342
trainer/Policy log std Mean       -1.45094
trainer/Policy log std Std         0.310272
trainer/Policy log std Max        -0.589957
trainer/Policy log std Min        -1.73629
trainer/Alpha                      0.0662018
trainer/Alpha Loss                -2.10419
exploration/num steps total    10600
exploration/num paths total      106
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.512819
exploration/Rewards Std            1.19445
exploration/Rewards Max           -0.00870345
exploration/Rewards Min           -9.05758
exploration/Returns Mean         -51.2819
exploration/Returns Std           18.2267
exploration/Returns Max          -33.0551
exploration/Returns Min          -69.5086
exploration/Actions Mean           0.0215375
exploration/Actions Std            0.330705
exploration/Actions Max            0.998745
exploration/Actions Min           -0.997135
exploration/Num Paths              2
exploration/Average Returns      -51.2819
evaluation/num steps total     52000
evaluation/num paths total       520
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.318464
evaluation/Rewards Std             1.11378
evaluation/Rewards Max            -0.0795948
evaluation/Rewards Min            -9.55358
evaluation/Returns Mean          -31.8464
evaluation/Returns Std            17.0494
evaluation/Returns Max           -10.4761
evaluation/Returns Min           -57.5648
evaluation/Actions Mean            0.0362898
evaluation/Actions Std             0.19846
evaluation/Actions Max             0.996071
evaluation/Actions Min            -0.984037
evaluation/Num Paths              10
evaluation/Average Returns       -31.8464
time/data storing (s)              0.00131031
time/evaluation sampling (s)       0.404629
time/exploration sampling (s)      0.0946547
time/logging (s)                   0.00355576
time/saving (s)                    0.00255562
time/training (s)                  1.14528
time/epoch (s)                     1.65198
time/total (s)                    68.9164
Epoch                             51
-----------------------------  --------------
2019-04-21 12:17:34.817174 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 52 finished
-----------------------------  --------------
replay_buffer/size             10800
trainer/QF1 Loss                   2.44485
trainer/QF2 Loss                   2.51198
trainer/Policy Loss               18.2654
trainer/Q1 Predictions Mean      -17.7948
trainer/Q1 Predictions Std         8.33017
trainer/Q1 Predictions Max       -14.6996
trainer/Q1 Predictions Min       -68.9395
trainer/Q2 Predictions Mean      -17.7412
trainer/Q2 Predictions Std         8.31337
trainer/Q2 Predictions Max       -14.6048
trainer/Q2 Predictions Min       -68.2499
trainer/Q Targets Mean           -17.9347
trainer/Q Targets Std              8.91471
trainer/Q Targets Max             -0.306191
trainer/Q Targets Min            -72.9311
trainer/Log Pis Mean               1.10289
trainer/Log Pis Std                1.56349
trainer/Log Pis Max                7.29209
trainer/Log Pis Min               -2.99737
trainer/Policy mu Mean             0.223371
trainer/Policy mu Std              0.883793
trainer/Policy mu Max              3.12604
trainer/Policy mu Min             -2.70234
trainer/Policy log std Mean       -1.45713
trainer/Policy log std Std         0.315285
trainer/Policy log std Max        -0.460182
trainer/Policy log std Min        -1.76281
trainer/Alpha                      0.0633295
trainer/Alpha Loss                -2.47528
exploration/num steps total    10800
exploration/num paths total      108
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.397943
exploration/Rewards Std            0.85934
exploration/Rewards Max           -0.0115371
exploration/Rewards Min           -7.44467
exploration/Returns Mean         -39.7943
exploration/Returns Std           14.5686
exploration/Returns Max          -25.2257
exploration/Returns Min          -54.3628
exploration/Actions Mean           0.0251373
exploration/Actions Std            0.320604
exploration/Actions Max            0.998279
exploration/Actions Min           -0.871353
exploration/Num Paths              2
exploration/Average Returns      -39.7943
evaluation/num steps total     53000
evaluation/num paths total       530
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.207833
evaluation/Rewards Std             0.941369
evaluation/Rewards Max            -0.0145369
evaluation/Rewards Min            -9.52191
evaluation/Returns Mean          -20.7833
evaluation/Returns Std            18.9029
evaluation/Returns Max            -5.58323
evaluation/Returns Min           -52.4736
evaluation/Actions Mean            0.0216453
evaluation/Actions Std             0.173821
evaluation/Actions Max             0.996643
evaluation/Actions Min            -0.971302
evaluation/Num Paths              10
evaluation/Average Returns       -20.7833
time/data storing (s)              0.00114828
time/evaluation sampling (s)       0.279355
time/exploration sampling (s)      0.0678
time/logging (s)                   0.0039552
time/saving (s)                    0.00253046
time/training (s)                  1.03338
time/epoch (s)                     1.38817
time/total (s)                    70.3088
Epoch                             52
-----------------------------  --------------
2019-04-21 12:17:36.426546 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 53 finished
-----------------------------  ---------------
replay_buffer/size             11000
trainer/QF1 Loss                   0.0718799
trainer/QF2 Loss                   0.0980557
trainer/Policy Loss               18.4044
trainer/Q1 Predictions Mean      -17.3707
trainer/Q1 Predictions Std         6.30113
trainer/Q1 Predictions Max       -14.7458
trainer/Q1 Predictions Min       -48.4655
trainer/Q2 Predictions Mean      -17.3815
trainer/Q2 Predictions Std         6.33533
trainer/Q2 Predictions Max       -14.6963
trainer/Q2 Predictions Min       -48.6946
trainer/Q Targets Mean           -17.314
trainer/Q Targets Std              6.25217
trainer/Q Targets Max            -14.6062
trainer/Q Targets Min            -47.9644
trainer/Log Pis Mean               1.578
trainer/Log Pis Std                1.68087
trainer/Log Pis Max                7.93431
trainer/Log Pis Min               -1.94882
trainer/Policy mu Mean             0.221721
trainer/Policy mu Std              0.91165
trainer/Policy mu Max              2.87931
trainer/Policy mu Min             -2.43584
trainer/Policy log std Mean       -1.57786
trainer/Policy log std Std         0.348193
trainer/Policy log std Max        -0.540551
trainer/Policy log std Min        -1.89238
trainer/Alpha                      0.0606716
trainer/Alpha Loss                -1.18249
exploration/num steps total    11000
exploration/num paths total      110
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.243344
exploration/Rewards Std            0.354941
exploration/Rewards Max           -0.0147955
exploration/Rewards Min           -3.83114
exploration/Returns Mean         -24.3344
exploration/Returns Std            1.66435
exploration/Returns Max          -22.6701
exploration/Returns Min          -25.9988
exploration/Actions Mean           0.00720463
exploration/Actions Std            0.251543
exploration/Actions Max            0.996409
exploration/Actions Min           -0.980826
exploration/Num Paths              2
exploration/Average Returns      -24.3344
evaluation/num steps total     54000
evaluation/num paths total       540
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.69092
evaluation/Rewards Std             1.82664
evaluation/Rewards Max            -0.000987894
evaluation/Rewards Min            -9.77225
evaluation/Returns Mean          -69.092
evaluation/Returns Std           165.778
evaluation/Returns Max            -0.1923
evaluation/Returns Min          -564.568
evaluation/Actions Mean           -0.0120033
evaluation/Actions Std             0.286478
evaluation/Actions Max             0.996098
evaluation/Actions Min            -0.994982
evaluation/Num Paths              10
evaluation/Average Returns       -69.092
time/data storing (s)              0.0011091
time/evaluation sampling (s)       0.304215
time/exploration sampling (s)      0.0659539
time/logging (s)                   0.00344321
time/saving (s)                    0.00234361
time/training (s)                  1.22421
time/epoch (s)                     1.60128
time/total (s)                    71.9158
Epoch                             53
-----------------------------  ---------------
2019-04-21 12:17:37.747839 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 54 finished
-----------------------------  --------------
replay_buffer/size             11200
trainer/QF1 Loss                   0.129319
trainer/QF2 Loss                   0.146254
trainer/Policy Loss               17.2751
trainer/Q1 Predictions Mean      -16.1484
trainer/Q1 Predictions Std         4.39455
trainer/Q1 Predictions Max       -14.5019
trainer/Q1 Predictions Min       -40.7906
trainer/Q2 Predictions Mean      -16.1526
trainer/Q2 Predictions Std         4.35806
trainer/Q2 Predictions Max       -14.49
trainer/Q2 Predictions Min       -41.2304
trainer/Q Targets Mean           -16.3398
trainer/Q Targets Std              4.34323
trainer/Q Targets Max            -14.5356
trainer/Q Targets Min            -40.0895
trainer/Log Pis Mean               1.5531
trainer/Log Pis Std                1.223
trainer/Log Pis Max                6.98118
trainer/Log Pis Min               -1.97924
trainer/Policy mu Mean             0.107734
trainer/Policy mu Std              0.82106
trainer/Policy mu Max              2.92224
trainer/Policy mu Min             -2.38316
trainer/Policy log std Mean       -1.60626
trainer/Policy log std Std         0.284421
trainer/Policy log std Max        -0.563103
trainer/Policy log std Min        -1.88015
trainer/Alpha                      0.0584133
trainer/Alpha Loss                -1.26918
exploration/num steps total    11200
exploration/num paths total      112
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.35092
exploration/Rewards Std            0.712296
exploration/Rewards Max           -0.0226857
exploration/Rewards Min           -5.55768
exploration/Returns Mean         -35.092
exploration/Returns Std            1.31451
exploration/Returns Max          -33.7775
exploration/Returns Min          -36.4065
exploration/Actions Mean           0.0303798
exploration/Actions Std            0.282575
exploration/Actions Max            0.999301
exploration/Actions Min           -0.56585
exploration/Num Paths              2
exploration/Average Returns      -35.092
evaluation/num steps total     55000
evaluation/num paths total       550
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.343304
evaluation/Rewards Std             1.28183
evaluation/Rewards Max            -0.050629
evaluation/Rewards Min           -10.1206
evaluation/Returns Mean          -34.3304
evaluation/Returns Std            17.6164
evaluation/Returns Max           -10.7304
evaluation/Returns Min           -61.4587
evaluation/Actions Mean            0.0420741
evaluation/Actions Std             0.209197
evaluation/Actions Max             0.996737
evaluation/Actions Min            -0.994726
evaluation/Num Paths              10
evaluation/Average Returns       -34.3304
time/data storing (s)              0.00121859
time/evaluation sampling (s)       0.25903
time/exploration sampling (s)      0.0710951
time/logging (s)                   0.00344882
time/saving (s)                    0.00232243
time/training (s)                  0.978769
time/epoch (s)                     1.31588
time/total (s)                    73.2358
Epoch                             54
-----------------------------  --------------
2019-04-21 12:17:39.305372 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 55 finished
-----------------------------  --------------
replay_buffer/size             11400
trainer/QF1 Loss                   2.34745
trainer/QF2 Loss                   2.3796
trainer/Policy Loss               18.9495
trainer/Q1 Predictions Mean      -18.1429
trainer/Q1 Predictions Std        11.2094
trainer/Q1 Predictions Max       -14.5877
trainer/Q1 Predictions Min       -76.2007
trainer/Q2 Predictions Mean      -18.2016
trainer/Q2 Predictions Std        11.1192
trainer/Q2 Predictions Max       -14.6265
trainer/Q2 Predictions Min       -75.0355
trainer/Q Targets Mean           -18.1405
trainer/Q Targets Std             11.5261
trainer/Q Targets Max             -0.171539
trainer/Q Targets Min            -77.1988
trainer/Log Pis Mean               1.59403
trainer/Log Pis Std                1.59599
trainer/Log Pis Max                8.13254
trainer/Log Pis Min               -1.5278
trainer/Policy mu Mean             0.0918702
trainer/Policy mu Std              0.896004
trainer/Policy mu Max              3.32807
trainer/Policy mu Min             -2.84201
trainer/Policy log std Mean       -1.60123
trainer/Policy log std Std         0.324168
trainer/Policy log std Max        -0.527904
trainer/Policy log std Min        -1.89596
trainer/Alpha                      0.056196
trainer/Alpha Loss                -1.16868
exploration/num steps total    11400
exploration/num paths total      114
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.256595
exploration/Rewards Std            0.3232
exploration/Rewards Max           -0.0295813
exploration/Rewards Min           -2.83175
exploration/Returns Mean         -25.6595
exploration/Returns Std            0.153858
exploration/Returns Max          -25.5057
exploration/Returns Min          -25.8134
exploration/Actions Mean           0.0202307
exploration/Actions Std            0.262413
exploration/Actions Max            0.991286
exploration/Actions Min           -0.636846
exploration/Num Paths              2
exploration/Average Returns      -25.6595
evaluation/num steps total     56000
evaluation/num paths total       560
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.224787
evaluation/Rewards Std             0.908147
evaluation/Rewards Max            -0.0313515
evaluation/Rewards Min            -9.2092
evaluation/Returns Mean          -22.4787
evaluation/Returns Std            14.5515
evaluation/Returns Max            -6.00705
evaluation/Returns Min           -52.2201
evaluation/Actions Mean            0.0263684
evaluation/Actions Std             0.180945
evaluation/Actions Max             0.996656
evaluation/Actions Min            -0.99412
evaluation/Num Paths              10
evaluation/Average Returns       -22.4787
time/data storing (s)              0.00124785
time/evaluation sampling (s)       0.274679
time/exploration sampling (s)      0.0785554
time/logging (s)                   0.00363724
time/saving (s)                    0.00185286
time/training (s)                  1.19194
time/epoch (s)                     1.55191
time/total (s)                    74.792
Epoch                             55
-----------------------------  --------------
2019-04-21 12:17:40.877634 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 56 finished
-----------------------------  --------------
replay_buffer/size             11600
trainer/QF1 Loss                   4.19478
trainer/QF2 Loss                   4.2102
trainer/Policy Loss               16.8784
trainer/Q1 Predictions Mean      -15.8696
trainer/Q1 Predictions Std         7.17948
trainer/Q1 Predictions Max       -14.1594
trainer/Q1 Predictions Min       -78.4395
trainer/Q2 Predictions Mean      -15.9249
trainer/Q2 Predictions Std         7.14171
trainer/Q2 Predictions Max       -14.1759
trainer/Q2 Predictions Min       -77.8987
trainer/Q Targets Mean           -15.9137
trainer/Q Targets Std              7.49886
trainer/Q Targets Max             -0.0586386
trainer/Q Targets Min            -79.5135
trainer/Log Pis Mean               1.47081
trainer/Log Pis Std                1.47881
trainer/Log Pis Max                6.58774
trainer/Log Pis Min               -4.65368
trainer/Policy mu Mean             0.109534
trainer/Policy mu Std              0.721217
trainer/Policy mu Max              3.2631
trainer/Policy mu Min             -1.70238
trainer/Policy log std Mean       -1.73745
trainer/Policy log std Std         0.293524
trainer/Policy log std Max        -0.605637
trainer/Policy log std Min        -1.98475
trainer/Alpha                      0.0540909
trainer/Alpha Loss                -1.54358
exploration/num steps total    11600
exploration/num paths total      116
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.401692
exploration/Rewards Std            0.958577
exploration/Rewards Max           -0.002488
exploration/Rewards Min           -7.27435
exploration/Returns Mean         -40.1692
exploration/Returns Std            6.82899
exploration/Returns Max          -33.3402
exploration/Returns Min          -46.9982
exploration/Actions Mean           0.0133483
exploration/Actions Std            0.287361
exploration/Actions Max            0.998257
exploration/Actions Min           -0.991985
exploration/Num Paths              2
exploration/Average Returns      -40.1692
evaluation/num steps total     57000
evaluation/num paths total       570
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.127991
evaluation/Rewards Std             0.736366
evaluation/Rewards Max            -0.0124211
evaluation/Rewards Min            -9.18737
evaluation/Returns Mean          -12.7991
evaluation/Returns Std            13.2466
evaluation/Returns Max            -1.25776
evaluation/Returns Min           -41.859
evaluation/Actions Mean            0.0066279
evaluation/Actions Std             0.163234
evaluation/Actions Max             0.994793
evaluation/Actions Min            -0.991564
evaluation/Num Paths              10
evaluation/Average Returns       -12.7991
time/data storing (s)              0.00162016
time/evaluation sampling (s)       0.271254
time/exploration sampling (s)      0.130457
time/logging (s)                   0.0032993
time/saving (s)                    0.00183981
time/training (s)                  1.15794
time/epoch (s)                     1.56641
time/total (s)                    76.3624
Epoch                             56
-----------------------------  --------------
2019-04-21 12:17:42.432348 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 57 finished
-----------------------------  --------------
replay_buffer/size             11800
trainer/QF1 Loss                   0.0623387
trainer/QF2 Loss                   0.0616674
trainer/Policy Loss               17.5854
trainer/Q1 Predictions Mean      -16.6043
trainer/Q1 Predictions Std         6.47926
trainer/Q1 Predictions Max       -14.3657
trainer/Q1 Predictions Min       -55.1723
trainer/Q2 Predictions Mean      -16.5585
trainer/Q2 Predictions Std         6.53368
trainer/Q2 Predictions Max       -14.2674
trainer/Q2 Predictions Min       -55.5363
trainer/Q Targets Mean           -16.7126
trainer/Q Targets Std              6.56126
trainer/Q Targets Max            -14.3289
trainer/Q Targets Min            -55.6645
trainer/Log Pis Mean               1.56373
trainer/Log Pis Std                1.47358
trainer/Log Pis Max                7.26498
trainer/Log Pis Min               -2.58762
trainer/Policy mu Mean            -0.0820256
trainer/Policy mu Std              0.84258
trainer/Policy mu Max              3.05487
trainer/Policy mu Min             -3.17308
trainer/Policy log std Mean       -1.74348
trainer/Policy log std Std         0.364246
trainer/Policy log std Max        -0.517573
trainer/Policy log std Min        -2.03634
trainer/Alpha                      0.0526358
trainer/Alpha Loss                -1.28446
exploration/num steps total    11800
exploration/num paths total      118
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.332651
exploration/Rewards Std            0.719399
exploration/Rewards Max           -0.0203499
exploration/Rewards Min           -6.12887
exploration/Returns Mean         -33.2651
exploration/Returns Std            3.47461
exploration/Returns Max          -29.7905
exploration/Returns Min          -36.7397
exploration/Actions Mean          -0.00918803
exploration/Actions Std            0.277524
exploration/Actions Max            0.995961
exploration/Actions Min           -0.992599
exploration/Num Paths              2
exploration/Average Returns      -33.2651
evaluation/num steps total     58000
evaluation/num paths total       580
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.2709
evaluation/Rewards Std             0.97102
evaluation/Rewards Max            -0.0550712
evaluation/Rewards Min           -10.1854
evaluation/Returns Mean          -27.09
evaluation/Returns Std            16.9648
evaluation/Returns Max            -9.82289
evaluation/Returns Min           -61.3448
evaluation/Actions Mean            0.0278599
evaluation/Actions Std             0.189762
evaluation/Actions Max             0.997246
evaluation/Actions Min            -0.992278
evaluation/Num Paths              10
evaluation/Average Returns       -27.09
time/data storing (s)              0.00117473
time/evaluation sampling (s)       0.26136
time/exploration sampling (s)      0.0699253
time/logging (s)                   0.00359432
time/saving (s)                    0.00235343
time/training (s)                  1.21185
time/epoch (s)                     1.55025
time/total (s)                    77.9164
Epoch                             57
-----------------------------  --------------
2019-04-21 12:17:43.911281 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 58 finished
-----------------------------  --------------
replay_buffer/size             12000
trainer/QF1 Loss                   0.339177
trainer/QF2 Loss                   0.350445
trainer/Policy Loss               19.1452
trainer/Q1 Predictions Mean      -18.1468
trainer/Q1 Predictions Std         9.63618
trainer/Q1 Predictions Max       -14.38
trainer/Q1 Predictions Min       -72.2885
trainer/Q2 Predictions Mean      -18.126
trainer/Q2 Predictions Std         9.67037
trainer/Q2 Predictions Max       -14.316
trainer/Q2 Predictions Min       -72.5185
trainer/Q Targets Mean           -18.3109
trainer/Q Targets Std              9.87824
trainer/Q Targets Max            -14.2103
trainer/Q Targets Min            -73.3911
trainer/Log Pis Mean               1.85012
trainer/Log Pis Std                1.66807
trainer/Log Pis Max                7.47865
trainer/Log Pis Min               -4.92044
trainer/Policy mu Mean             0.217596
trainer/Policy mu Std              0.995077
trainer/Policy mu Max              3.12795
trainer/Policy mu Min             -2.51124
trainer/Policy log std Mean       -1.61771
trainer/Policy log std Std         0.421098
trainer/Policy log std Max        -0.36749
trainer/Policy log std Min        -1.96546
trainer/Alpha                      0.0510072
trainer/Alpha Loss                -0.445999
exploration/num steps total    12000
exploration/num paths total      120
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.402748
exploration/Rewards Std            1.0048
exploration/Rewards Max           -0.0158233
exploration/Rewards Min           -7.03925
exploration/Returns Mean         -40.2748
exploration/Returns Std            0.148153
exploration/Returns Max          -40.1267
exploration/Returns Min          -40.423
exploration/Actions Mean           0.00528468
exploration/Actions Std            0.313934
exploration/Actions Max            0.996962
exploration/Actions Min           -0.996019
exploration/Num Paths              2
exploration/Average Returns      -40.2748
evaluation/num steps total     59000
evaluation/num paths total       590
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.153977
evaluation/Rewards Std             0.752568
evaluation/Rewards Max            -0.0126913
evaluation/Rewards Min            -9.15132
evaluation/Returns Mean          -15.3977
evaluation/Returns Std            11.2384
evaluation/Returns Max            -2.78955
evaluation/Returns Min           -41.8745
evaluation/Actions Mean            0.0138968
evaluation/Actions Std             0.175924
evaluation/Actions Max             0.994677
evaluation/Actions Min            -0.99533
evaluation/Num Paths              10
evaluation/Average Returns       -15.3977
time/data storing (s)              0.00118437
time/evaluation sampling (s)       0.257008
time/exploration sampling (s)      0.0685621
time/logging (s)                   0.00349389
time/saving (s)                    0.00200041
time/training (s)                  1.14098
time/epoch (s)                     1.47323
time/total (s)                    79.3938
Epoch                             58
-----------------------------  --------------
2019-04-21 12:17:45.456301 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 59 finished
-----------------------------  --------------
replay_buffer/size             12200
trainer/QF1 Loss                   0.134973
trainer/QF2 Loss                   0.119547
trainer/Policy Loss               17.1395
trainer/Q1 Predictions Mean      -16.0603
trainer/Q1 Predictions Std         5.50286
trainer/Q1 Predictions Max       -14.0236
trainer/Q1 Predictions Min       -47.1573
trainer/Q2 Predictions Mean      -16.1281
trainer/Q2 Predictions Std         5.41345
trainer/Q2 Predictions Max       -14.1177
trainer/Q2 Predictions Min       -46.4565
trainer/Q Targets Mean           -16.3061
trainer/Q Targets Std              5.54733
trainer/Q Targets Max            -14.1487
trainer/Q Targets Min            -46.7119
trainer/Log Pis Mean               1.60702
trainer/Log Pis Std                1.47981
trainer/Log Pis Max                6.56597
trainer/Log Pis Min               -4.35771
trainer/Policy mu Mean             0.0415583
trainer/Policy mu Std              0.81529
trainer/Policy mu Max              3.12758
trainer/Policy mu Min             -2.15057
trainer/Policy log std Mean       -1.77166
trainer/Policy log std Std         0.339604
trainer/Policy log std Max        -0.47215
trainer/Policy log std Min        -2.06093
trainer/Alpha                      0.0494285
trainer/Alpha Loss                -1.18173
exploration/num steps total    12200
exploration/num paths total      122
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.226151
exploration/Rewards Std            0.332551
exploration/Rewards Max           -0.00891667
exploration/Rewards Min           -2.93915
exploration/Returns Mean         -22.6151
exploration/Returns Std            0.46404
exploration/Returns Max          -22.151
exploration/Returns Min          -23.0791
exploration/Actions Mean           0.0244289
exploration/Actions Std            0.243868
exploration/Actions Max            0.993484
exploration/Actions Min           -0.511259
exploration/Num Paths              2
exploration/Average Returns      -22.6151
evaluation/num steps total     60000
evaluation/num paths total       600
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.151872
evaluation/Rewards Std             0.804679
evaluation/Rewards Max            -0.0130591
evaluation/Rewards Min           -10.3839
evaluation/Returns Mean          -15.1872
evaluation/Returns Std            16.81
evaluation/Returns Max            -2.99592
evaluation/Returns Min           -54.5028
evaluation/Actions Mean            0.0124613
evaluation/Actions Std             0.158407
evaluation/Actions Max             0.997915
evaluation/Actions Min            -0.995323
evaluation/Num Paths              10
evaluation/Average Returns       -15.1872
time/data storing (s)              0.00163812
time/evaluation sampling (s)       0.261781
time/exploration sampling (s)      0.079898
time/logging (s)                   0.00545723
time/saving (s)                    0.00260265
time/training (s)                  1.18989
time/epoch (s)                     1.54126
time/total (s)                    80.9394
Epoch                             59
-----------------------------  --------------
2019-04-21 12:17:47.120945 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 60 finished
-----------------------------  --------------
replay_buffer/size             12400
trainer/QF1 Loss                   0.0478878
trainer/QF2 Loss                   0.0632004
trainer/Policy Loss               16.7717
trainer/Q1 Predictions Mean      -15.5298
trainer/Q1 Predictions Std         5.81715
trainer/Q1 Predictions Max       -14.0622
trainer/Q1 Predictions Min       -65.0096
trainer/Q2 Predictions Mean      -15.5067
trainer/Q2 Predictions Std         5.77925
trainer/Q2 Predictions Max       -14.041
trainer/Q2 Predictions Min       -64.5733
trainer/Q Targets Mean           -15.64
trainer/Q Targets Std              5.85155
trainer/Q Targets Max            -14.0396
trainer/Q Targets Min            -65.3353
trainer/Log Pis Mean               1.54551
trainer/Log Pis Std                1.31547
trainer/Log Pis Max                6.13339
trainer/Log Pis Min               -3.19383
trainer/Policy mu Mean             0.00500925
trainer/Policy mu Std              0.731755
trainer/Policy mu Max              3.44547
trainer/Policy mu Min             -3.22255
trainer/Policy log std Mean       -1.84335
trainer/Policy log std Std         0.301157
trainer/Policy log std Max        -0.573978
trainer/Policy log std Min        -2.06034
trainer/Alpha                      0.0481395
trainer/Alpha Loss                -1.37872
exploration/num steps total    12400
exploration/num paths total      124
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.479978
exploration/Rewards Std            1.26951
exploration/Rewards Max           -0.0184189
exploration/Rewards Min           -9.30081
exploration/Returns Mean         -47.9978
exploration/Returns Std           15.4222
exploration/Returns Max          -32.5757
exploration/Returns Min          -63.42
exploration/Actions Mean           0.0376912
exploration/Actions Std            0.28226
exploration/Actions Max            0.999147
exploration/Actions Min           -0.795303
exploration/Num Paths              2
exploration/Average Returns      -47.9978
evaluation/num steps total     61000
evaluation/num paths total       610
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.295732
evaluation/Rewards Std             1.11948
evaluation/Rewards Max            -0.0602856
evaluation/Rewards Min           -10.1702
evaluation/Returns Mean          -29.5732
evaluation/Returns Std            17.8228
evaluation/Returns Max            -6.40555
evaluation/Returns Min           -62.5766
evaluation/Actions Mean            0.0308389
evaluation/Actions Std             0.186921
evaluation/Actions Max             0.997246
evaluation/Actions Min            -0.995981
evaluation/Num Paths              10
evaluation/Average Returns       -29.5732
time/data storing (s)              0.00153221
time/evaluation sampling (s)       0.351027
time/exploration sampling (s)      0.0649558
time/logging (s)                   0.00338876
time/saving (s)                    0.00229186
time/training (s)                  1.23002
time/epoch (s)                     1.65321
time/total (s)                    82.6
Epoch                             60
-----------------------------  --------------
2019-04-21 12:17:48.775708 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 61 finished
-----------------------------  --------------
replay_buffer/size             12600
trainer/QF1 Loss                   5.75719
trainer/QF2 Loss                   5.76767
trainer/Policy Loss               17.7463
trainer/Q1 Predictions Mean      -16.3505
trainer/Q1 Predictions Std         8.23408
trainer/Q1 Predictions Max       -13.887
trainer/Q1 Predictions Min       -80.8443
trainer/Q2 Predictions Mean      -16.4147
trainer/Q2 Predictions Std         8.19826
trainer/Q2 Predictions Max       -13.9513
trainer/Q2 Predictions Min       -80.468
trainer/Q Targets Mean           -16.1375
trainer/Q Targets Std              8.55022
trainer/Q Targets Max             -0.210924
trainer/Q Targets Min            -79.1466
trainer/Log Pis Mean               2.00802
trainer/Log Pis Std                1.49133
trainer/Log Pis Max                8.07757
trainer/Log Pis Min               -2.67214
trainer/Policy mu Mean             0.107301
trainer/Policy mu Std              0.866687
trainer/Policy mu Max              3.29935
trainer/Policy mu Min             -3.20555
trainer/Policy log std Mean       -1.87922
trainer/Policy log std Std         0.361801
trainer/Policy log std Max        -0.622251
trainer/Policy log std Min        -2.24925
trainer/Alpha                      0.0471878
trainer/Alpha Loss                 0.024476
exploration/num steps total    12600
exploration/num paths total      126
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.546415
exploration/Rewards Std            1.55538
exploration/Rewards Max           -0.00848383
exploration/Rewards Min          -10.7797
exploration/Returns Mean         -54.6415
exploration/Returns Std           11.208
exploration/Returns Max          -43.4336
exploration/Returns Min          -65.8495
exploration/Actions Mean           0.0682279
exploration/Actions Std            0.296735
exploration/Actions Max            0.99849
exploration/Actions Min           -0.457966
exploration/Num Paths              2
exploration/Average Returns      -54.6415
evaluation/num steps total     62000
evaluation/num paths total       620
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.164151
evaluation/Rewards Std             0.784611
evaluation/Rewards Max            -0.002667
evaluation/Rewards Min            -7.89716
evaluation/Returns Mean          -16.4151
evaluation/Returns Std             7.94742
evaluation/Returns Max            -1.63547
evaluation/Returns Min           -30.2838
evaluation/Actions Mean            0.0155071
evaluation/Actions Std             0.194215
evaluation/Actions Max             0.994872
evaluation/Actions Min            -0.994358
evaluation/Num Paths              10
evaluation/Average Returns       -16.4151
time/data storing (s)              0.00153233
time/evaluation sampling (s)       0.360158
time/exploration sampling (s)      0.119306
time/logging (s)                   0.00343713
time/saving (s)                    0.00207604
time/training (s)                  1.16244
time/epoch (s)                     1.64895
time/total (s)                    84.2533
Epoch                             61
-----------------------------  --------------
2019-04-21 12:17:50.090134 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 62 finished
-----------------------------  --------------
replay_buffer/size             12800
trainer/QF1 Loss                   0.249779
trainer/QF2 Loss                   0.274105
trainer/Policy Loss               17.2251
trainer/Q1 Predictions Mean      -16.0387
trainer/Q1 Predictions Std         6.39735
trainer/Q1 Predictions Max       -13.9797
trainer/Q1 Predictions Min       -54.2062
trainer/Q2 Predictions Mean      -16.0245
trainer/Q2 Predictions Std         6.43073
trainer/Q2 Predictions Max       -13.9388
trainer/Q2 Predictions Min       -54.4726
trainer/Q Targets Mean           -15.9541
trainer/Q Targets Std              6.11698
trainer/Q Targets Max            -13.8324
trainer/Q Targets Min            -49.8051
trainer/Log Pis Mean               1.90722
trainer/Log Pis Std                1.45504
trainer/Log Pis Max                8.48157
trainer/Log Pis Min               -2.04877
trainer/Policy mu Mean             0.0458191
trainer/Policy mu Std              0.864253
trainer/Policy mu Max              3.41973
trainer/Policy mu Min             -2.25194
trainer/Policy log std Mean       -1.86118
trainer/Policy log std Std         0.402227
trainer/Policy log std Max        -0.513887
trainer/Policy log std Min        -2.23599
trainer/Alpha                      0.0463611
trainer/Alpha Loss                -0.284945
exploration/num steps total    12800
exploration/num paths total      128
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.436613
exploration/Rewards Std            1.29254
exploration/Rewards Max           -0.0130138
exploration/Rewards Min           -9.66811
exploration/Returns Mean         -43.6613
exploration/Returns Std           22.5364
exploration/Returns Max          -21.1249
exploration/Returns Min          -66.1978
exploration/Actions Mean           0.0175129
exploration/Actions Std            0.26123
exploration/Actions Max            0.998699
exploration/Actions Min           -0.996731
exploration/Num Paths              2
exploration/Average Returns      -43.6613
evaluation/num steps total     63000
evaluation/num paths total       630
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.216224
evaluation/Rewards Std             0.866869
evaluation/Rewards Max            -0.0503525
evaluation/Rewards Min            -8.65457
evaluation/Returns Mean          -21.6224
evaluation/Returns Std            13.0769
evaluation/Returns Max            -5.12403
evaluation/Returns Min           -46.3983
evaluation/Actions Mean            0.0179984
evaluation/Actions Std             0.178913
evaluation/Actions Max             0.996763
evaluation/Actions Min            -0.996451
evaluation/Num Paths              10
evaluation/Average Returns       -21.6224
time/data storing (s)              0.00120678
time/evaluation sampling (s)       0.262103
time/exploration sampling (s)      0.0704204
time/logging (s)                   0.00341445
time/saving (s)                    0.00236347
time/training (s)                  0.969073
time/epoch (s)                     1.30858
time/total (s)                    85.5661
Epoch                             62
-----------------------------  --------------
2019-04-21 12:17:51.750879 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 63 finished
-----------------------------  --------------
replay_buffer/size             13000
trainer/QF1 Loss                   3.81819
trainer/QF2 Loss                   3.80857
trainer/Policy Loss               17.0565
trainer/Q1 Predictions Mean      -15.7253
trainer/Q1 Predictions Std         6.28967
trainer/Q1 Predictions Max       -13.7985
trainer/Q1 Predictions Min       -58.9179
trainer/Q2 Predictions Mean      -15.7135
trainer/Q2 Predictions Std         6.3586
trainer/Q2 Predictions Max       -13.7788
trainer/Q2 Predictions Min       -59.7145
trainer/Q Targets Mean           -15.5855
trainer/Q Targets Std              6.77529
trainer/Q Targets Max             -0.817901
trainer/Q Targets Min            -60.5002
trainer/Log Pis Mean               2.09771
trainer/Log Pis Std                1.58822
trainer/Log Pis Max                9.14967
trainer/Log Pis Min               -1.50147
trainer/Policy mu Mean             0.075187
trainer/Policy mu Std              0.839493
trainer/Policy mu Max              3.0814
trainer/Policy mu Min             -2.85382
trainer/Policy log std Mean       -1.96613
trainer/Policy log std Std         0.408705
trainer/Policy log std Max        -0.491822
trainer/Policy log std Min        -2.2918
trainer/Alpha                      0.0460322
trainer/Alpha Loss                 0.300794
exploration/num steps total    13000
exploration/num paths total      130
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.37209
exploration/Rewards Std            0.969756
exploration/Rewards Max           -0.014429
exploration/Rewards Min           -8.17304
exploration/Returns Mean         -37.209
exploration/Returns Std           13.2342
exploration/Returns Max          -23.9748
exploration/Returns Min          -50.4432
exploration/Actions Mean           0.0448349
exploration/Actions Std            0.254313
exploration/Actions Max            0.99817
exploration/Actions Min           -0.403872
exploration/Num Paths              2
exploration/Average Returns      -37.209
evaluation/num steps total     64000
evaluation/num paths total       640
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.316577
evaluation/Rewards Std             0.961832
evaluation/Rewards Max            -0.0555447
evaluation/Rewards Min            -9.27082
evaluation/Returns Mean          -31.6577
evaluation/Returns Std            13.7205
evaluation/Returns Max           -12.8692
evaluation/Returns Min           -59.1131
evaluation/Actions Mean            0.0246448
evaluation/Actions Std             0.188975
evaluation/Actions Max             0.99794
evaluation/Actions Min            -0.996835
evaluation/Num Paths              10
evaluation/Average Returns       -31.6577
time/data storing (s)              0.00156384
time/evaluation sampling (s)       0.407661
time/exploration sampling (s)      0.119459
time/logging (s)                   0.00281566
time/saving (s)                    0.00232645
time/training (s)                  1.12148
time/epoch (s)                     1.65531
time/total (s)                    87.225
Epoch                             63
-----------------------------  --------------
2019-04-21 12:17:53.295038 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 64 finished
-----------------------------  --------------
replay_buffer/size             13200
trainer/QF1 Loss                   0.0458188
trainer/QF2 Loss                   0.0377317
trainer/Policy Loss               16.7069
trainer/Q1 Predictions Mean      -15.5681
trainer/Q1 Predictions Std         7.61173
trainer/Q1 Predictions Max       -13.5967
trainer/Q1 Predictions Min       -75.2572
trainer/Q2 Predictions Mean      -15.637
trainer/Q2 Predictions Std         7.57558
trainer/Q2 Predictions Max       -13.6991
trainer/Q2 Predictions Min       -75.0569
trainer/Q Targets Mean           -15.6792
trainer/Q Targets Std              7.65531
trainer/Q Targets Max            -13.6849
trainer/Q Targets Min            -75.8753
trainer/Log Pis Mean               1.63431
trainer/Log Pis Std                1.70171
trainer/Log Pis Max                9.56273
trainer/Log Pis Min               -3.83566
trainer/Policy mu Mean             0.0476951
trainer/Policy mu Std              0.781957
trainer/Policy mu Max              3.36149
trainer/Policy mu Min             -2.71794
trainer/Policy log std Mean       -1.90738
trainer/Policy log std Std         0.348097
trainer/Policy log std Max        -0.387224
trainer/Policy log std Min        -2.1744
trainer/Alpha                      0.0454901
trainer/Alpha Loss                -1.13006
exploration/num steps total    13200
exploration/num paths total      132
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.397493
exploration/Rewards Std            1.00347
exploration/Rewards Max           -0.0161416
exploration/Rewards Min           -6.86307
exploration/Returns Mean         -39.7493
exploration/Returns Std            4.29604
exploration/Returns Max          -35.4532
exploration/Returns Min          -44.0453
exploration/Actions Mean           0.0256995
exploration/Actions Std            0.278797
exploration/Actions Max            0.999631
exploration/Actions Min           -0.985337
exploration/Num Paths              2
exploration/Average Returns      -39.7493
evaluation/num steps total     65000
evaluation/num paths total       650
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.304644
evaluation/Rewards Std             1.17078
evaluation/Rewards Max            -0.0550144
evaluation/Rewards Min           -10.3781
evaluation/Returns Mean          -30.4644
evaluation/Returns Std            20.6727
evaluation/Returns Max            -8.46274
evaluation/Returns Min           -60.7278
evaluation/Actions Mean            0.0294599
evaluation/Actions Std             0.199924
evaluation/Actions Max             0.99871
evaluation/Actions Min            -0.978096
evaluation/Num Paths              10
evaluation/Average Returns       -30.4644
time/data storing (s)              0.00157571
time/evaluation sampling (s)       0.273023
time/exploration sampling (s)      0.129757
time/logging (s)                   0.00403286
time/saving (s)                    0.00281819
time/training (s)                  1.12917
time/epoch (s)                     1.54037
time/total (s)                    88.7694
Epoch                             64
-----------------------------  --------------
2019-04-21 12:17:54.844149 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 65 finished
-----------------------------  ---------------
replay_buffer/size             13400
trainer/QF1 Loss                   1.86198
trainer/QF2 Loss                   1.87083
trainer/Policy Loss               16.0153
trainer/Q1 Predictions Mean      -14.5862
trainer/Q1 Predictions Std         3.60215
trainer/Q1 Predictions Max       -13.5106
trainer/Q1 Predictions Min       -42.6193
trainer/Q2 Predictions Mean      -14.5698
trainer/Q2 Predictions Std         3.60276
trainer/Q2 Predictions Max       -13.4789
trainer/Q2 Predictions Min       -42.8404
trainer/Q Targets Mean           -14.5788
trainer/Q Targets Std              3.7727
trainer/Q Targets Max             -0.345402
trainer/Q Targets Min            -41.9417
trainer/Log Pis Mean               1.76548
trainer/Log Pis Std                1.11556
trainer/Log Pis Max                6.07969
trainer/Log Pis Min               -3.62939
trainer/Policy mu Mean             0.0935611
trainer/Policy mu Std              0.663866
trainer/Policy mu Max              2.93871
trainer/Policy mu Min             -1.86832
trainer/Policy log std Mean       -1.99057
trainer/Policy log std Std         0.349054
trainer/Policy log std Max        -0.581165
trainer/Policy log std Min        -2.25817
trainer/Alpha                      0.0446428
trainer/Alpha Loss                -0.72912
exploration/num steps total    13400
exploration/num paths total      134
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.326132
exploration/Rewards Std            0.883073
exploration/Rewards Max           -0.0062807
exploration/Rewards Min           -6.88714
exploration/Returns Mean         -32.6132
exploration/Returns Std            3.92972
exploration/Returns Max          -28.6834
exploration/Returns Min          -36.5429
exploration/Actions Mean           0.000769815
exploration/Actions Std            0.265618
exploration/Actions Max            0.995945
exploration/Actions Min           -0.998708
exploration/Num Paths              2
exploration/Average Returns      -32.6132
evaluation/num steps total     66000
evaluation/num paths total       660
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.217882
evaluation/Rewards Std             0.991243
evaluation/Rewards Max            -0.0344368
evaluation/Rewards Min           -10.6294
evaluation/Returns Mean          -21.7882
evaluation/Returns Std            16.7971
evaluation/Returns Max            -5.09578
evaluation/Returns Min           -54.7848
evaluation/Actions Mean            0.0373654
evaluation/Actions Std             0.195318
evaluation/Actions Max             0.997462
evaluation/Actions Min            -0.984546
evaluation/Num Paths              10
evaluation/Average Returns       -21.7882
time/data storing (s)              0.00113817
time/evaluation sampling (s)       0.349547
time/exploration sampling (s)      0.0691
time/logging (s)                   0.00347093
time/saving (s)                    0.00248365
time/training (s)                  1.11648
time/epoch (s)                     1.54222
time/total (s)                    90.3164
Epoch                             65
-----------------------------  ---------------
2019-04-21 12:17:56.787838 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 66 finished
-----------------------------  --------------
replay_buffer/size             13600
trainer/QF1 Loss                   3.65107
trainer/QF2 Loss                   3.67604
trainer/Policy Loss               16.8141
trainer/Q1 Predictions Mean      -15.522
trainer/Q1 Predictions Std         5.98379
trainer/Q1 Predictions Max       -13.5859
trainer/Q1 Predictions Min       -53.2375
trainer/Q2 Predictions Mean      -15.5609
trainer/Q2 Predictions Std         5.9823
trainer/Q2 Predictions Max       -13.6008
trainer/Q2 Predictions Min       -53.2633
trainer/Q Targets Mean           -15.2629
trainer/Q Targets Std              6.42788
trainer/Q Targets Max             -0.451139
trainer/Q Targets Min            -54.0339
trainer/Log Pis Mean               1.92756
trainer/Log Pis Std                1.12877
trainer/Log Pis Max                5.3833
trainer/Log Pis Min               -2.04985
trainer/Policy mu Mean             0.10575
trainer/Policy mu Std              0.773838
trainer/Policy mu Max              3.15947
trainer/Policy mu Min             -2.87283
trainer/Policy log std Mean       -1.9435
trainer/Policy log std Std         0.37602
trainer/Policy log std Max        -0.479704
trainer/Policy log std Min        -2.25131
trainer/Alpha                      0.0442978
trainer/Alpha Loss                -0.225768
exploration/num steps total    13600
exploration/num paths total      136
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.351361
exploration/Rewards Std            0.990634
exploration/Rewards Max           -0.00847559
exploration/Rewards Min           -7.99671
exploration/Returns Mean         -35.1361
exploration/Returns Std           11.1952
exploration/Returns Max          -23.9409
exploration/Returns Min          -46.3313
exploration/Actions Mean           0.0272977
exploration/Actions Std            0.253052
exploration/Actions Max            0.994426
exploration/Actions Min           -0.938357
exploration/Num Paths              2
exploration/Average Returns      -35.1361
evaluation/num steps total     67000
evaluation/num paths total       670
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.231086
evaluation/Rewards Std             1.00698
evaluation/Rewards Max            -0.0135496
evaluation/Rewards Min            -8.95454
evaluation/Returns Mean          -23.1086
evaluation/Returns Std            16.0995
evaluation/Returns Max            -3.74369
evaluation/Returns Min           -46.6463
evaluation/Actions Mean            0.025875
evaluation/Actions Std             0.186777
evaluation/Actions Max             0.998118
evaluation/Actions Min            -0.995218
evaluation/Num Paths              10
evaluation/Average Returns       -23.1086
time/data storing (s)              0.00297331
time/evaluation sampling (s)       0.402611
time/exploration sampling (s)      0.0901679
time/logging (s)                   0.00501338
time/saving (s)                    0.00277878
time/training (s)                  1.43472
time/epoch (s)                     1.93827
time/total (s)                    92.26
Epoch                             66
-----------------------------  --------------
2019-04-21 12:17:58.995063 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 67 finished
-----------------------------  --------------
replay_buffer/size             13800
trainer/QF1 Loss                   5.23005
trainer/QF2 Loss                   5.29531
trainer/Policy Loss               15.928
trainer/Q1 Predictions Mean      -14.324
trainer/Q1 Predictions Std         3.17891
trainer/Q1 Predictions Max       -13.2732
trainer/Q1 Predictions Min       -33.0233
trainer/Q2 Predictions Mean      -14.3717
trainer/Q2 Predictions Std         3.09611
trainer/Q2 Predictions Max       -13.3282
trainer/Q2 Predictions Min       -32.9631
trainer/Q Targets Mean           -14.0735
trainer/Q Targets Std              4.00663
trainer/Q Targets Max             -0.157683
trainer/Q Targets Min            -33.9911
trainer/Log Pis Mean               1.96335
trainer/Log Pis Std                1.36072
trainer/Log Pis Max                5.25366
trainer/Log Pis Min               -4.44471
trainer/Policy mu Mean             0.0615624
trainer/Policy mu Std              0.712649
trainer/Policy mu Max              3.27612
trainer/Policy mu Min             -2.01687
trainer/Policy log std Mean       -2.0178
trainer/Policy log std Std         0.385144
trainer/Policy log std Max        -0.437134
trainer/Policy log std Min        -2.34453
trainer/Alpha                      0.0445416
trainer/Alpha Loss                -0.114021
exploration/num steps total    13800
exploration/num paths total      138
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.2823
exploration/Rewards Std            0.702038
exploration/Rewards Max           -0.0148936
exploration/Rewards Min           -5.18096
exploration/Returns Mean         -28.23
exploration/Returns Std            0.582321
exploration/Returns Max          -27.6477
exploration/Returns Min          -28.8123
exploration/Actions Mean           0.0352901
exploration/Actions Std            0.228773
exploration/Actions Max            0.998014
exploration/Actions Min           -0.654715
exploration/Num Paths              2
exploration/Average Returns      -28.23
evaluation/num steps total     68000
evaluation/num paths total       680
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.766274
evaluation/Rewards Std             1.80113
evaluation/Rewards Max            -0.0122596
evaluation/Rewards Min            -9.88272
evaluation/Returns Mean          -76.6274
evaluation/Returns Std           154.419
evaluation/Returns Max            -7.01154
evaluation/Returns Min          -537.305
evaluation/Actions Mean            0.0679308
evaluation/Actions Std             0.273507
evaluation/Actions Max             0.997643
evaluation/Actions Min            -0.994404
evaluation/Num Paths              10
evaluation/Average Returns       -76.6274
time/data storing (s)              0.00156795
time/evaluation sampling (s)       0.402797
time/exploration sampling (s)      0.126783
time/logging (s)                   0.0035579
time/saving (s)                    0.00243315
time/training (s)                  1.66114
time/epoch (s)                     2.19827
time/total (s)                    94.4638
Epoch                             67
-----------------------------  --------------
2019-04-21 12:18:00.954822 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 68 finished
-----------------------------  --------------
replay_buffer/size             14000
trainer/QF1 Loss                   0.145362
trainer/QF2 Loss                   0.155058
trainer/Policy Loss               17.1926
trainer/Q1 Predictions Mean      -15.5185
trainer/Q1 Predictions Std         7.28127
trainer/Q1 Predictions Max       -13.0029
trainer/Q1 Predictions Min       -52.6785
trainer/Q2 Predictions Mean      -15.5192
trainer/Q2 Predictions Std         7.24344
trainer/Q2 Predictions Max       -13.0187
trainer/Q2 Predictions Min       -52.1235
trainer/Q Targets Mean           -15.7998
trainer/Q Targets Std              7.30573
trainer/Q Targets Max            -13.2061
trainer/Q Targets Min            -52.1067
trainer/Log Pis Mean               2.06446
trainer/Log Pis Std                1.35787
trainer/Log Pis Max                7.74472
trainer/Log Pis Min               -2.32105
trainer/Policy mu Mean             0.166079
trainer/Policy mu Std              0.877519
trainer/Policy mu Max              3.31422
trainer/Policy mu Min             -3.19094
trainer/Policy log std Mean       -1.93719
trainer/Policy log std Std         0.44579
trainer/Policy log std Max        -0.296383
trainer/Policy log std Min        -2.28844
trainer/Alpha                      0.0453522
trainer/Alpha Loss                 0.199405
exploration/num steps total    14000
exploration/num paths total      140
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.676749
exploration/Rewards Std            1.85995
exploration/Rewards Max           -0.00192249
exploration/Rewards Min          -10.9345
exploration/Returns Mean         -67.6749
exploration/Returns Std            3.3026
exploration/Returns Max          -64.3723
exploration/Returns Min          -70.9775
exploration/Actions Mean           0.0584738
exploration/Actions Std            0.283909
exploration/Actions Max            0.999181
exploration/Actions Min           -0.804628
exploration/Num Paths              2
exploration/Average Returns      -67.6749
evaluation/num steps total     69000
evaluation/num paths total       690
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.268637
evaluation/Rewards Std             1.04448
evaluation/Rewards Max            -0.0544214
evaluation/Rewards Min           -10.6515
evaluation/Returns Mean          -26.8637
evaluation/Returns Std            16.1361
evaluation/Returns Max            -5.98933
evaluation/Returns Min           -62.5646
evaluation/Actions Mean            0.0307202
evaluation/Actions Std             0.196209
evaluation/Actions Max             0.997712
evaluation/Actions Min            -0.988101
evaluation/Num Paths              10
evaluation/Average Returns       -26.8637
time/data storing (s)              0.00269665
time/evaluation sampling (s)       0.387324
time/exploration sampling (s)      0.139205
time/logging (s)                   0.00453232
time/saving (s)                    0.00242638
time/training (s)                  1.41856
time/epoch (s)                     1.95475
time/total (s)                    96.423
Epoch                             68
-----------------------------  --------------
2019-04-21 12:18:02.810665 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 69 finished
-----------------------------  --------------
replay_buffer/size             14200
trainer/QF1 Loss                   0.10046
trainer/QF2 Loss                   0.090975
trainer/Policy Loss               16.0281
trainer/Q1 Predictions Mean      -14.4149
trainer/Q1 Predictions Std         4.90463
trainer/Q1 Predictions Max       -12.9252
trainer/Q1 Predictions Min       -53.4018
trainer/Q2 Predictions Mean      -14.4576
trainer/Q2 Predictions Std         4.97452
trainer/Q2 Predictions Max       -12.9428
trainer/Q2 Predictions Min       -54.1305
trainer/Q Targets Mean           -14.6869
trainer/Q Targets Std              4.89653
trainer/Q Targets Max            -13.0689
trainer/Q Targets Min            -53.526
trainer/Log Pis Mean               1.97544
trainer/Log Pis Std                1.26226
trainer/Log Pis Max                5.42743
trainer/Log Pis Min               -1.47434
trainer/Policy mu Mean             0.0260757
trainer/Policy mu Std              0.794432
trainer/Policy mu Max              3.11235
trainer/Policy mu Min             -3.02005
trainer/Policy log std Mean       -1.96691
trainer/Policy log std Std         0.426802
trainer/Policy log std Max        -0.444364
trainer/Policy log std Min        -2.31633
trainer/Alpha                      0.0454211
trainer/Alpha Loss                -0.0759405
exploration/num steps total    14200
exploration/num paths total      142
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.237825
exploration/Rewards Std            0.59271
exploration/Rewards Max           -0.014309
exploration/Rewards Min           -5.85872
exploration/Returns Mean         -23.7825
exploration/Returns Std            8.4686
exploration/Returns Max          -15.3139
exploration/Returns Min          -32.2511
exploration/Actions Mean           0.00598281
exploration/Actions Std            0.227614
exploration/Actions Max            0.994729
exploration/Actions Min           -0.972642
exploration/Num Paths              2
exploration/Average Returns      -23.7825
evaluation/num steps total     70000
evaluation/num paths total       700
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.19684
evaluation/Rewards Std             0.803974
evaluation/Rewards Max            -0.0207706
evaluation/Rewards Min            -7.45074
evaluation/Returns Mean          -19.684
evaluation/Returns Std            10.5826
evaluation/Returns Max            -5.39444
evaluation/Returns Min           -34.3859
evaluation/Actions Mean            0.0301268
evaluation/Actions Std             0.179571
evaluation/Actions Max             0.996241
evaluation/Actions Min            -0.97697
evaluation/Num Paths              10
evaluation/Average Returns       -19.684
time/data storing (s)              0.0011985
time/evaluation sampling (s)       0.329958
time/exploration sampling (s)      0.0699947
time/logging (s)                   0.00339756
time/saving (s)                    0.0111362
time/training (s)                  1.4323
time/epoch (s)                     1.84799
time/total (s)                    98.2757
Epoch                             69
-----------------------------  --------------
2019-04-21 12:18:04.237249 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 70 finished
-----------------------------  --------------
replay_buffer/size             14400
trainer/QF1 Loss                   3.39904
trainer/QF2 Loss                   3.3759
trainer/Policy Loss               15.0419
trainer/Q1 Predictions Mean      -13.6379
trainer/Q1 Predictions Std         1.49183
trainer/Q1 Predictions Max       -13.0098
trainer/Q1 Predictions Min       -24.4909
trainer/Q2 Predictions Mean      -13.593
trainer/Q2 Predictions Std         1.50937
trainer/Q2 Predictions Max       -12.9541
trainer/Q2 Predictions Min       -24.5359
trainer/Q Targets Mean           -13.4646
trainer/Q Targets Std              2.50244
trainer/Q Targets Max             -0.0983733
trainer/Q Targets Min            -25.0114
trainer/Log Pis Mean               1.67306
trainer/Log Pis Std                0.929592
trainer/Log Pis Max                4.22848
trainer/Log Pis Min               -0.666217
trainer/Policy mu Mean             0.0416969
trainer/Policy mu Std              0.604714
trainer/Policy mu Max              2.68583
trainer/Policy mu Min             -2.21378
trainer/Policy log std Mean       -1.9735
trainer/Policy log std Std         0.311408
trainer/Policy log std Max        -0.515648
trainer/Policy log std Min        -2.19248
trainer/Alpha                      0.0455741
trainer/Alpha Loss                -1.00967
exploration/num steps total    14400
exploration/num paths total      144
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.550047
exploration/Rewards Std            1.48119
exploration/Rewards Max           -0.0199102
exploration/Rewards Min           -8.87554
exploration/Returns Mean         -55.0047
exploration/Returns Std            0.975915
exploration/Returns Max          -54.0288
exploration/Returns Min          -55.9806
exploration/Actions Mean           0.0489257
exploration/Actions Std            0.279825
exploration/Actions Max            0.998274
exploration/Actions Min           -0.838859
exploration/Num Paths              2
exploration/Average Returns      -55.0047
evaluation/num steps total     71000
evaluation/num paths total       710
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.235792
evaluation/Rewards Std             0.984007
evaluation/Rewards Max            -0.0383336
evaluation/Rewards Min           -10.3977
evaluation/Returns Mean          -23.5792
evaluation/Returns Std            17.7701
evaluation/Returns Max            -5.78827
evaluation/Returns Min           -57.2941
evaluation/Actions Mean            0.0196437
evaluation/Actions Std             0.188848
evaluation/Actions Max             0.997451
evaluation/Actions Min            -0.997144
evaluation/Num Paths              10
evaluation/Average Returns       -23.5792
time/data storing (s)              0.00129942
time/evaluation sampling (s)       0.25312
time/exploration sampling (s)      0.0739765
time/logging (s)                   0.00360253
time/saving (s)                    0.00192239
time/training (s)                  1.08636
time/epoch (s)                     1.42028
time/total (s)                    99.7009
Epoch                             70
-----------------------------  --------------
2019-04-21 12:18:05.638105 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 71 finished
-----------------------------  --------------
replay_buffer/size             14600
trainer/QF1 Loss                   6.73652
trainer/QF2 Loss                   6.7079
trainer/Policy Loss               15.8773
trainer/Q1 Predictions Mean      -14.6418
trainer/Q1 Predictions Std         6.37264
trainer/Q1 Predictions Max       -12.9037
trainer/Q1 Predictions Min       -59.2072
trainer/Q2 Predictions Mean      -14.6255
trainer/Q2 Predictions Std         6.38538
trainer/Q2 Predictions Max       -12.8816
trainer/Q2 Predictions Min       -59.3997
trainer/Q Targets Mean           -14.1689
trainer/Q Targets Std              6.99959
trainer/Q Targets Max             -0.300826
trainer/Q Targets Min            -58.8252
trainer/Log Pis Mean               1.74027
trainer/Log Pis Std                1.46634
trainer/Log Pis Max                6.82847
trainer/Log Pis Min               -4.55232
trainer/Policy mu Mean             0.0482017
trainer/Policy mu Std              0.748837
trainer/Policy mu Max              3.15939
trainer/Policy mu Min             -1.96968
trainer/Policy log std Mean       -1.942
trainer/Policy log std Std         0.385427
trainer/Policy log std Max        -0.375112
trainer/Policy log std Min        -2.2485
trainer/Alpha                      0.0458949
trainer/Alpha Loss                -0.800319
exploration/num steps total    14600
exploration/num paths total      146
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.222838
exploration/Rewards Std            0.457744
exploration/Rewards Max           -0.0154488
exploration/Rewards Min           -4.82204
exploration/Returns Mean         -22.2838
exploration/Returns Std            4.78882
exploration/Returns Max          -17.495
exploration/Returns Min          -27.0726
exploration/Actions Mean          -0.00247168
exploration/Actions Std            0.224972
exploration/Actions Max            0.991984
exploration/Actions Min           -0.968228
exploration/Num Paths              2
exploration/Average Returns      -22.2838
evaluation/num steps total     72000
evaluation/num paths total       720
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.146942
evaluation/Rewards Std             0.598844
evaluation/Rewards Max            -0.0595664
evaluation/Rewards Min            -8.1339
evaluation/Returns Mean          -14.6942
evaluation/Returns Std            10.6691
evaluation/Returns Max            -6.43966
evaluation/Returns Min           -42.9878
evaluation/Actions Mean            0.0133283
evaluation/Actions Std             0.157725
evaluation/Actions Max             0.994838
evaluation/Actions Min            -0.994564
evaluation/Num Paths              10
evaluation/Average Returns       -14.6942
time/data storing (s)              0.00125094
time/evaluation sampling (s)       0.277033
time/exploration sampling (s)      0.0932676
time/logging (s)                   0.00357095
time/saving (s)                    0.00271716
time/training (s)                  1.01636
time/epoch (s)                     1.3942
time/total (s)                   101.1
Epoch                             71
-----------------------------  --------------
2019-04-21 12:18:06.988247 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 72 finished
-----------------------------  --------------
replay_buffer/size             14800
trainer/QF1 Loss                   0.0663196
trainer/QF2 Loss                   0.0612688
trainer/Policy Loss               15.8372
trainer/Q1 Predictions Mean      -14.5288
trainer/Q1 Predictions Std         5.71793
trainer/Q1 Predictions Max       -12.8353
trainer/Q1 Predictions Min       -59.1137
trainer/Q2 Predictions Mean      -14.5236
trainer/Q2 Predictions Std         5.71595
trainer/Q2 Predictions Max       -12.8252
trainer/Q2 Predictions Min       -58.8506
trainer/Q Targets Mean           -14.6181
trainer/Q Targets Std              5.87381
trainer/Q Targets Max            -12.7861
trainer/Q Targets Min            -60.5013
trainer/Log Pis Mean               1.6248
trainer/Log Pis Std                1.5743
trainer/Log Pis Max                8.31612
trainer/Log Pis Min               -4.40506
trainer/Policy mu Mean             0.0487326
trainer/Policy mu Std              0.730835
trainer/Policy mu Max              3.07805
trainer/Policy mu Min             -2.48012
trainer/Policy log std Mean       -2.01225
trainer/Policy log std Std         0.41646
trainer/Policy log std Max        -0.518271
trainer/Policy log std Min        -2.28589
trainer/Alpha                      0.0455844
trainer/Alpha Loss                -1.15864
exploration/num steps total    14800
exploration/num paths total      148
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.243933
exploration/Rewards Std            0.556339
exploration/Rewards Max           -0.0181999
exploration/Rewards Min           -4.54691
exploration/Returns Mean         -24.3933
exploration/Returns Std            1.67299
exploration/Returns Max          -22.7203
exploration/Returns Min          -26.0663
exploration/Actions Mean           0.0311938
exploration/Actions Std            0.218965
exploration/Actions Max            0.99905
exploration/Actions Min           -0.438862
exploration/Num Paths              2
exploration/Average Returns      -24.3933
evaluation/num steps total     73000
evaluation/num paths total       730
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.201699
evaluation/Rewards Std             0.963288
evaluation/Rewards Max            -0.0137322
evaluation/Rewards Min            -9.99653
evaluation/Returns Mean          -20.1699
evaluation/Returns Std            19.0274
evaluation/Returns Max            -3.48815
evaluation/Returns Min           -58.6485
evaluation/Actions Mean            0.0223488
evaluation/Actions Std             0.175012
evaluation/Actions Max             0.996281
evaluation/Actions Min            -0.98942
evaluation/Num Paths              10
evaluation/Average Returns       -20.1699
time/data storing (s)              0.00124567
time/evaluation sampling (s)       0.261472
time/exploration sampling (s)      0.071658
time/logging (s)                   0.00364759
time/saving (s)                    0.00232752
time/training (s)                  1.00355
time/epoch (s)                     1.3439
time/total (s)                   102.449
Epoch                             72
-----------------------------  --------------
2019-04-21 12:18:08.525106 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 73 finished
-----------------------------  --------------
replay_buffer/size             15000
trainer/QF1 Loss                   4.8724
trainer/QF2 Loss                   4.73943
trainer/Policy Loss               16.7785
trainer/Q1 Predictions Mean      -15.2222
trainer/Q1 Predictions Std         8.8004
trainer/Q1 Predictions Max       -12.6575
trainer/Q1 Predictions Min       -79.6406
trainer/Q2 Predictions Mean      -15.0635
trainer/Q2 Predictions Std         8.7995
trainer/Q2 Predictions Max       -12.4684
trainer/Q2 Predictions Min       -78.7817
trainer/Q Targets Mean           -14.9279
trainer/Q Targets Std              9.06979
trainer/Q Targets Max             -0.242127
trainer/Q Targets Min            -78.0615
trainer/Log Pis Mean               1.96969
trainer/Log Pis Std                1.65955
trainer/Log Pis Max                8.77386
trainer/Log Pis Min               -2.07334
trainer/Policy mu Mean             0.0440342
trainer/Policy mu Std              0.888276
trainer/Policy mu Max              3.22433
trainer/Policy mu Min             -3.31833
trainer/Policy log std Mean       -1.93151
trainer/Policy log std Std         0.446987
trainer/Policy log std Max        -0.46743
trainer/Policy log std Min        -2.2212
trainer/Alpha                      0.0447544
trainer/Alpha Loss                -0.0941705
exploration/num steps total    15000
exploration/num paths total      150
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.41241
exploration/Rewards Std            1.08699
exploration/Rewards Max           -0.0144921
exploration/Rewards Min           -7.37304
exploration/Returns Mean         -41.241
exploration/Returns Std            0.269818
exploration/Returns Max          -40.9712
exploration/Returns Min          -41.5108
exploration/Actions Mean           0.0467637
exploration/Actions Std            0.258596
exploration/Actions Max            0.9963
exploration/Actions Min           -0.546192
exploration/Num Paths              2
exploration/Average Returns      -41.241
evaluation/num steps total     74000
evaluation/num paths total       740
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.269882
evaluation/Rewards Std             0.963206
evaluation/Rewards Max            -0.0740061
evaluation/Rewards Min            -8.87372
evaluation/Returns Mean          -26.9882
evaluation/Returns Std            13.4138
evaluation/Returns Max            -9.58405
evaluation/Returns Min           -48.2726
evaluation/Actions Mean            0.0256565
evaluation/Actions Std             0.195907
evaluation/Actions Max             0.99779
evaluation/Actions Min            -0.983128
evaluation/Num Paths              10
evaluation/Average Returns       -26.9882
time/data storing (s)              0.00117466
time/evaluation sampling (s)       0.264988
time/exploration sampling (s)      0.0676446
time/logging (s)                   0.00445693
time/saving (s)                    0.00318716
time/training (s)                  1.18922
time/epoch (s)                     1.53067
time/total (s)                   103.985
Epoch                             73
-----------------------------  --------------
2019-04-21 12:18:10.244397 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 74 finished
-----------------------------  --------------
replay_buffer/size             15200
trainer/QF1 Loss                   1.72546
trainer/QF2 Loss                   1.71976
trainer/Policy Loss               16.5974
trainer/Q1 Predictions Mean      -14.9783
trainer/Q1 Predictions Std         7.62366
trainer/Q1 Predictions Max       -12.3143
trainer/Q1 Predictions Min       -66.7522
trainer/Q2 Predictions Mean      -15.0105
trainer/Q2 Predictions Std         7.61639
trainer/Q2 Predictions Max       -12.3596
trainer/Q2 Predictions Min       -66.9777
trainer/Q Targets Mean           -15.1656
trainer/Q Targets Std              7.74938
trainer/Q Targets Max             -0.281726
trainer/Q Targets Min            -68.2765
trainer/Log Pis Mean               2.34834
trainer/Log Pis Std                1.66995
trainer/Log Pis Max                9.24467
trainer/Log Pis Min               -3.02897
trainer/Policy mu Mean             0.0505537
trainer/Policy mu Std              0.987848
trainer/Policy mu Max              3.26822
trainer/Policy mu Min             -3.12282
trainer/Policy log std Mean       -1.91654
trainer/Policy log std Std         0.528123
trainer/Policy log std Max        -0.451543
trainer/Policy log std Min        -2.31099
trainer/Alpha                      0.0445588
trainer/Alpha Loss                 1.08369
exploration/num steps total    15200
exploration/num paths total      152
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.230316
exploration/Rewards Std            0.489653
exploration/Rewards Max           -0.0174175
exploration/Rewards Min           -4.1605
exploration/Returns Mean         -23.0316
exploration/Returns Std            1.1896
exploration/Returns Max          -21.8421
exploration/Returns Min          -24.2212
exploration/Actions Mean           0.0219188
exploration/Actions Std            0.216753
exploration/Actions Max            0.998658
exploration/Actions Min           -0.681785
exploration/Num Paths              2
exploration/Average Returns      -23.0316
evaluation/num steps total     75000
evaluation/num paths total       750
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.253037
evaluation/Rewards Std             1.06066
evaluation/Rewards Max            -0.0559788
evaluation/Rewards Min           -11.0822
evaluation/Returns Mean          -25.3037
evaluation/Returns Std            22.2392
evaluation/Returns Max            -6.90045
evaluation/Returns Min           -65.5384
evaluation/Actions Mean            0.0228625
evaluation/Actions Std             0.169782
evaluation/Actions Max             0.998241
evaluation/Actions Min            -0.981786
evaluation/Num Paths              10
evaluation/Average Returns       -25.3037
time/data storing (s)              0.00119044
time/evaluation sampling (s)       0.299147
time/exploration sampling (s)      0.0711443
time/logging (s)                   0.00366541
time/saving (s)                    0.00239499
time/training (s)                  1.33263
time/epoch (s)                     1.71017
time/total (s)                   105.701
Epoch                             74
-----------------------------  --------------
2019-04-21 12:18:11.790167 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 75 finished
-----------------------------  --------------
replay_buffer/size             15400
trainer/QF1 Loss                   0.185992
trainer/QF2 Loss                   0.198163
trainer/Policy Loss               14.5108
trainer/Q1 Predictions Mean      -13.1949
trainer/Q1 Predictions Std         2.83246
trainer/Q1 Predictions Max       -12.206
trainer/Q1 Predictions Min       -31.4364
trainer/Q2 Predictions Mean      -13.1737
trainer/Q2 Predictions Std         2.81573
trainer/Q2 Predictions Max       -12.1903
trainer/Q2 Predictions Min       -31.2259
trainer/Q Targets Mean           -13.5748
trainer/Q Targets Std              2.84577
trainer/Q Targets Max            -12.4698
trainer/Q Targets Min            -31.171
trainer/Log Pis Mean               1.70692
trainer/Log Pis Std                1.04004
trainer/Log Pis Max                5.14806
trainer/Log Pis Min               -1.77718
trainer/Policy mu Mean             0.0225851
trainer/Policy mu Std              0.69936
trainer/Policy mu Max              3.13078
trainer/Policy mu Min             -2.99511
trainer/Policy log std Mean       -1.94888
trainer/Policy log std Std         0.382297
trainer/Policy log std Max        -0.481818
trainer/Policy log std Min        -2.21889
trainer/Alpha                      0.0449778
trainer/Alpha Loss                -0.908976
exploration/num steps total    15400
exploration/num paths total      154
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.330277
exploration/Rewards Std            1.03922
exploration/Rewards Max           -0.00600864
exploration/Rewards Min           -8.49302
exploration/Returns Mean         -33.0277
exploration/Returns Std           19.2455
exploration/Returns Max          -13.7822
exploration/Returns Min          -52.2732
exploration/Actions Mean           0.0278317
exploration/Actions Std            0.216317
exploration/Actions Max            0.998743
exploration/Actions Min           -0.692374
exploration/Num Paths              2
exploration/Average Returns      -33.0277
evaluation/num steps total     76000
evaluation/num paths total       760
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.686555
evaluation/Rewards Std             1.62775
evaluation/Rewards Max            -0.0383709
evaluation/Rewards Min            -9.9891
evaluation/Returns Mean          -68.6555
evaluation/Returns Std           113.059
evaluation/Returns Max            -6.94681
evaluation/Returns Min          -402.939
evaluation/Actions Mean           -0.0126852
evaluation/Actions Std             0.29204
evaluation/Actions Max             0.997332
evaluation/Actions Min            -0.99528
evaluation/Num Paths              10
evaluation/Average Returns       -68.6555
time/data storing (s)              0.00134769
time/evaluation sampling (s)       0.276876
time/exploration sampling (s)      0.104022
time/logging (s)                   0.00416141
time/saving (s)                    0.00234916
time/training (s)                  1.15082
time/epoch (s)                     1.53957
time/total (s)                   107.245
Epoch                             75
-----------------------------  --------------
2019-04-21 12:18:13.302347 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 76 finished
-----------------------------  --------------
replay_buffer/size             15600
trainer/QF1 Loss                   1.62401
trainer/QF2 Loss                   1.65385
trainer/Policy Loss               15.4168
trainer/Q1 Predictions Mean      -13.7845
trainer/Q1 Predictions Std         6.10479
trainer/Q1 Predictions Max       -12.3134
trainer/Q1 Predictions Min       -68.7585
trainer/Q2 Predictions Mean      -13.7622
trainer/Q2 Predictions Std         6.03709
trainer/Q2 Predictions Max       -12.2818
trainer/Q2 Predictions Min       -68.0814
trainer/Q Targets Mean           -13.8722
trainer/Q Targets Std              6.41098
trainer/Q Targets Max             -0.0841152
trainer/Q Targets Min            -70.8357
trainer/Log Pis Mean               1.88079
trainer/Log Pis Std                0.97189
trainer/Log Pis Max                4.86775
trainer/Log Pis Min               -1.64774
trainer/Policy mu Mean             0.0457746
trainer/Policy mu Std              0.72076
trainer/Policy mu Max              3.24955
trainer/Policy mu Min             -3.25112
trainer/Policy log std Mean       -1.9842
trainer/Policy log std Std         0.386011
trainer/Policy log std Max        -0.409806
trainer/Policy log std Min        -2.22
trainer/Alpha                      0.0445345
trainer/Alpha Loss                -0.370914
exploration/num steps total    15600
exploration/num paths total      156
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.336485
exploration/Rewards Std            0.91518
exploration/Rewards Max           -0.0107572
exploration/Rewards Min           -6.70129
exploration/Returns Mean         -33.6485
exploration/Returns Std            4.14288
exploration/Returns Max          -29.5056
exploration/Returns Min          -37.7914
exploration/Actions Mean           0.0269621
exploration/Actions Std            0.260446
exploration/Actions Max            0.998209
exploration/Actions Min           -0.99851
exploration/Num Paths              2
exploration/Average Returns      -33.6485
evaluation/num steps total     77000
evaluation/num paths total       770
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.236598
evaluation/Rewards Std             0.922196
evaluation/Rewards Max            -0.0400634
evaluation/Rewards Min            -9.30322
evaluation/Returns Mean          -23.6598
evaluation/Returns Std            14.7146
evaluation/Returns Max            -7.3714
evaluation/Returns Min           -53.8104
evaluation/Actions Mean            0.00883605
evaluation/Actions Std             0.191405
evaluation/Actions Max             0.996435
evaluation/Actions Min            -0.997271
evaluation/Num Paths              10
evaluation/Average Returns       -23.6598
time/data storing (s)              0.00125091
time/evaluation sampling (s)       0.286232
time/exploration sampling (s)      0.0716852
time/logging (s)                   0.00361252
time/saving (s)                    0.00233236
time/training (s)                  1.14029
time/epoch (s)                     1.5054
time/total (s)                   108.755
Epoch                             76
-----------------------------  --------------
2019-04-21 12:18:14.928636 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 77 finished
-----------------------------  --------------
replay_buffer/size             15800
trainer/QF1 Loss                   1.86403
trainer/QF2 Loss                   1.91354
trainer/Policy Loss               16.8251
trainer/Q1 Predictions Mean      -15.1668
trainer/Q1 Predictions Std         7.59248
trainer/Q1 Predictions Max       -12.198
trainer/Q1 Predictions Min       -53.6322
trainer/Q2 Predictions Mean      -15.1915
trainer/Q2 Predictions Std         7.61749
trainer/Q2 Predictions Max       -12.1987
trainer/Q2 Predictions Min       -54.2924
trainer/Q Targets Mean           -15.1763
trainer/Q Targets Std              7.31841
trainer/Q Targets Max             -0.122639
trainer/Q Targets Min            -48.2896
trainer/Log Pis Mean               2.26349
trainer/Log Pis Std                1.1479
trainer/Log Pis Max                5.89984
trainer/Log Pis Min               -0.577992
trainer/Policy mu Mean             0.140694
trainer/Policy mu Std              0.943034
trainer/Policy mu Max              3.2838
trainer/Policy mu Min             -2.90578
trainer/Policy log std Mean       -1.95915
trainer/Policy log std Std         0.531012
trainer/Policy log std Max        -0.4283
trainer/Policy log std Min        -2.35015
trainer/Alpha                      0.0444866
trainer/Alpha Loss                 0.820153
exploration/num steps total    15800
exploration/num paths total      158
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.353569
exploration/Rewards Std            0.993277
exploration/Rewards Max           -0.00571336
exploration/Rewards Min           -7.08221
exploration/Returns Mean         -35.3569
exploration/Returns Std            1.02432
exploration/Returns Max          -34.3325
exploration/Returns Min          -36.3812
exploration/Actions Mean           0.0322006
exploration/Actions Std            0.264128
exploration/Actions Max            0.99836
exploration/Actions Min           -0.970202
exploration/Num Paths              2
exploration/Average Returns      -35.3569
evaluation/num steps total     78000
evaluation/num paths total       780
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.2151
evaluation/Rewards Std             0.928687
evaluation/Rewards Max            -0.0164893
evaluation/Rewards Min            -9.48224
evaluation/Returns Mean          -21.51
evaluation/Returns Std            12.9606
evaluation/Returns Max            -3.93395
evaluation/Returns Min           -48.7683
evaluation/Actions Mean            0.0239571
evaluation/Actions Std             0.194016
evaluation/Actions Max             0.996708
evaluation/Actions Min            -0.996146
evaluation/Num Paths              10
evaluation/Average Returns       -21.51
time/data storing (s)              0.00149976
time/evaluation sampling (s)       0.301559
time/exploration sampling (s)      0.0918997
time/logging (s)                   0.00375118
time/saving (s)                    0.0023219
time/training (s)                  1.21849
time/epoch (s)                     1.61952
time/total (s)                   110.379
Epoch                             77
-----------------------------  --------------
2019-04-21 12:18:16.555840 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 78 finished
-----------------------------  --------------
replay_buffer/size             16000
trainer/QF1 Loss                   1.53572
trainer/QF2 Loss                   1.54139
trainer/Policy Loss               16.091
trainer/Q1 Predictions Mean      -14.727
trainer/Q1 Predictions Std         7.61958
trainer/Q1 Predictions Max       -12.3009
trainer/Q1 Predictions Min       -58.1868
trainer/Q2 Predictions Mean      -14.7548
trainer/Q2 Predictions Std         7.62726
trainer/Q2 Predictions Max       -12.3044
trainer/Q2 Predictions Min       -58.5529
trainer/Q Targets Mean           -14.6002
trainer/Q Targets Std              7.75323
trainer/Q Targets Max             -0.670314
trainer/Q Targets Min            -58.5202
trainer/Log Pis Mean               1.95078
trainer/Log Pis Std                1.47475
trainer/Log Pis Max                8.6499
trainer/Log Pis Min               -2.39978
trainer/Policy mu Mean             0.0924946
trainer/Policy mu Std              0.83135
trainer/Policy mu Max              3.10547
trainer/Policy mu Min             -3.16592
trainer/Policy log std Mean       -1.97073
trainer/Policy log std Std         0.438054
trainer/Policy log std Max        -0.499619
trainer/Policy log std Min        -2.30551
trainer/Alpha                      0.0453734
trainer/Alpha Loss                -0.152216
exploration/num steps total    16000
exploration/num paths total      160
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.155033
exploration/Rewards Std            0.254052
exploration/Rewards Max           -0.00107747
exploration/Rewards Min           -2.88603
exploration/Returns Mean         -15.5033
exploration/Returns Std            1.74767
exploration/Returns Max          -13.7556
exploration/Returns Min          -17.2509
exploration/Actions Mean           0.0198925
exploration/Actions Std            0.196707
exploration/Actions Max            0.984193
exploration/Actions Min           -0.642545
exploration/Num Paths              2
exploration/Average Returns      -15.5033
evaluation/num steps total     79000
evaluation/num paths total       790
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.619573
evaluation/Rewards Std             1.59066
evaluation/Rewards Max            -0.0204235
evaluation/Rewards Min            -7.81365
evaluation/Returns Mean          -61.9573
evaluation/Returns Std           147.741
evaluation/Returns Max            -2.58493
evaluation/Returns Min          -504.256
evaluation/Actions Mean           -0.0172382
evaluation/Actions Std             0.275899
evaluation/Actions Max             0.9956
evaluation/Actions Min            -0.997723
evaluation/Num Paths              10
evaluation/Average Returns       -61.9573
time/data storing (s)              0.00118929
time/evaluation sampling (s)       0.26706
time/exploration sampling (s)      0.0725497
time/logging (s)                   0.00365279
time/saving (s)                    0.00287462
time/training (s)                  1.27311
time/epoch (s)                     1.62044
time/total (s)                   112.005
Epoch                             78
-----------------------------  --------------
2019-04-21 12:18:18.434113 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 79 finished
-----------------------------  --------------
replay_buffer/size             16200
trainer/QF1 Loss                   1.63783
trainer/QF2 Loss                   1.70467
trainer/Policy Loss               15.767
trainer/Q1 Predictions Mean      -14.4545
trainer/Q1 Predictions Std         7.77617
trainer/Q1 Predictions Max       -12.1782
trainer/Q1 Predictions Min       -69.5922
trainer/Q2 Predictions Mean      -14.4431
trainer/Q2 Predictions Std         7.69285
trainer/Q2 Predictions Max       -12.1427
trainer/Q2 Predictions Min       -68.7233
trainer/Q Targets Mean           -14.5111
trainer/Q Targets Std              8.22227
trainer/Q Targets Max             -0.0609903
trainer/Q Targets Min            -71.4488
trainer/Log Pis Mean               1.86546
trainer/Log Pis Std                1.4727
trainer/Log Pis Max                7.3348
trainer/Log Pis Min               -2.33372
trainer/Policy mu Mean             0.133737
trainer/Policy mu Std              0.786346
trainer/Policy mu Max              3.39036
trainer/Policy mu Min             -2.52513
trainer/Policy log std Mean       -1.96831
trainer/Policy log std Std         0.431489
trainer/Policy log std Max        -0.389159
trainer/Policy log std Min        -2.2437
trainer/Alpha                      0.0460471
trainer/Alpha Loss                -0.41412
exploration/num steps total    16200
exploration/num paths total      162
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.327286
exploration/Rewards Std            0.886926
exploration/Rewards Max           -0.018325
exploration/Rewards Min           -6.17249
exploration/Returns Mean         -32.7286
exploration/Returns Std            2.65159
exploration/Returns Max          -30.077
exploration/Returns Min          -35.3802
exploration/Actions Mean           0.0407281
exploration/Actions Std            0.247959
exploration/Actions Max            0.998382
exploration/Actions Min           -0.540018
exploration/Num Paths              2
exploration/Average Returns      -32.7286
evaluation/num steps total     80000
evaluation/num paths total       800
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.255641
evaluation/Rewards Std             0.963159
evaluation/Rewards Max            -0.0569621
evaluation/Rewards Min            -9.39551
evaluation/Returns Mean          -25.5641
evaluation/Returns Std            13.3549
evaluation/Returns Max            -6.84862
evaluation/Returns Min           -54.2412
evaluation/Actions Mean            0.0257131
evaluation/Actions Std             0.192296
evaluation/Actions Max             0.997034
evaluation/Actions Min            -0.995796
evaluation/Num Paths              10
evaluation/Average Returns       -25.5641
time/data storing (s)              0.00127651
time/evaluation sampling (s)       0.316024
time/exploration sampling (s)      0.0877866
time/logging (s)                   0.00439412
time/saving (s)                    0.00297402
time/training (s)                  1.45956
time/epoch (s)                     1.87202
time/total (s)                   113.882
Epoch                             79
-----------------------------  --------------
2019-04-21 12:18:20.608771 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 80 finished
-----------------------------  --------------
replay_buffer/size             16400
trainer/QF1 Loss                   1.63698
trainer/QF2 Loss                   1.61955
trainer/Policy Loss               15.4944
trainer/Q1 Predictions Mean      -13.9669
trainer/Q1 Predictions Std         5.82036
trainer/Q1 Predictions Max       -12.1932
trainer/Q1 Predictions Min       -49.6787
trainer/Q2 Predictions Mean      -13.9565
trainer/Q2 Predictions Std         5.79649
trainer/Q2 Predictions Max       -12.1522
trainer/Q2 Predictions Min       -49.8454
trainer/Q Targets Mean           -13.8776
trainer/Q Targets Std              5.96383
trainer/Q Targets Max             -0.130196
trainer/Q Targets Min            -49.098
trainer/Log Pis Mean               1.86089
trainer/Log Pis Std                1.2719
trainer/Log Pis Max                5.06952
trainer/Log Pis Min               -3.95953
trainer/Policy mu Mean             0.0481663
trainer/Policy mu Std              0.747249
trainer/Policy mu Max              3.12185
trainer/Policy mu Min             -2.96374
trainer/Policy log std Mean       -2.00904
trainer/Policy log std Std         0.416014
trainer/Policy log std Max        -0.449305
trainer/Policy log std Min        -2.29412
trainer/Alpha                      0.0464893
trainer/Alpha Loss                -0.426844
exploration/num steps total    16400
exploration/num paths total      164
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.25989
exploration/Rewards Std            0.637215
exploration/Rewards Max           -0.0113117
exploration/Rewards Min           -5.35827
exploration/Returns Mean         -25.989
exploration/Returns Std            0.897076
exploration/Returns Max          -25.0919
exploration/Returns Min          -26.8861
exploration/Actions Mean          -0.00844375
exploration/Actions Std            0.255155
exploration/Actions Max            0.983942
exploration/Actions Min           -0.9986
exploration/Num Paths              2
exploration/Average Returns      -25.989
evaluation/num steps total     81000
evaluation/num paths total       810
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.222598
evaluation/Rewards Std             1.00379
evaluation/Rewards Max            -0.030402
evaluation/Rewards Min           -10.5939
evaluation/Returns Mean          -22.2598
evaluation/Returns Std            18.1926
evaluation/Returns Max            -4.81211
evaluation/Returns Min           -60.0182
evaluation/Actions Mean            0.0243692
evaluation/Actions Std             0.18458
evaluation/Actions Max             0.997561
evaluation/Actions Min            -0.994116
evaluation/Num Paths              10
evaluation/Average Returns       -22.2598
time/data storing (s)              0.00303472
time/evaluation sampling (s)       0.34765
time/exploration sampling (s)      0.341192
time/logging (s)                   0.00317562
time/saving (s)                    0.00263105
time/training (s)                  1.46677
time/epoch (s)                     2.16446
time/total (s)                   116.053
Epoch                             80
-----------------------------  --------------
2019-04-21 12:18:21.935203 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 81 finished
-----------------------------  --------------
replay_buffer/size             16600
trainer/QF1 Loss                   0.0892204
trainer/QF2 Loss                   0.141053
trainer/Policy Loss               15.6183
trainer/Q1 Predictions Mean      -13.9601
trainer/Q1 Predictions Std         5.72161
trainer/Q1 Predictions Max       -12.1536
trainer/Q1 Predictions Min       -51.7571
trainer/Q2 Predictions Mean      -13.8762
trainer/Q2 Predictions Std         5.65243
trainer/Q2 Predictions Max       -12.0802
trainer/Q2 Predictions Min       -50.4605
trainer/Q Targets Mean           -13.9594
trainer/Q Targets Std              5.91552
trainer/Q Targets Max            -11.9865
trainer/Q Targets Min            -52.742
trainer/Log Pis Mean               1.98933
trainer/Log Pis Std                1.36143
trainer/Log Pis Max                7.82646
trainer/Log Pis Min               -1.63371
trainer/Policy mu Mean             0.0806244
trainer/Policy mu Std              0.773551
trainer/Policy mu Max              3.07949
trainer/Policy mu Min             -2.84083
trainer/Policy log std Mean       -2.01213
trainer/Policy log std Std         0.437752
trainer/Policy log std Max        -0.490658
trainer/Policy log std Min        -2.325
trainer/Alpha                      0.0463366
trainer/Alpha Loss                -0.0327759
exploration/num steps total    16600
exploration/num paths total      166
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.4183
exploration/Rewards Std            1.33005
exploration/Rewards Max           -0.0201541
exploration/Rewards Min          -10.4972
exploration/Returns Mean         -41.83
exploration/Returns Std           25.0484
exploration/Returns Max          -16.7816
exploration/Returns Min          -66.8784
exploration/Actions Mean           0.0177804
exploration/Actions Std            0.245668
exploration/Actions Max            0.99912
exploration/Actions Min           -0.988982
exploration/Num Paths              2
exploration/Average Returns      -41.83
evaluation/num steps total     82000
evaluation/num paths total       820
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.213187
evaluation/Rewards Std             0.677551
evaluation/Rewards Max            -0.0211217
evaluation/Rewards Min            -7.15151
evaluation/Returns Mean          -21.3187
evaluation/Returns Std             6.9765
evaluation/Returns Max            -9.43802
evaluation/Returns Min           -32.4722
evaluation/Actions Mean            0.0249511
evaluation/Actions Std             0.175134
evaluation/Actions Max             0.997888
evaluation/Actions Min            -0.997501
evaluation/Num Paths              10
evaluation/Average Returns       -21.3187
time/data storing (s)              0.00116766
time/evaluation sampling (s)       0.257849
time/exploration sampling (s)      0.0703974
time/logging (s)                   0.00361542
time/saving (s)                    0.00232497
time/training (s)                  0.985314
time/epoch (s)                     1.32067
time/total (s)                   117.378
Epoch                             81
-----------------------------  --------------
2019-04-21 12:18:23.270869 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 82 finished
-----------------------------  --------------
replay_buffer/size             16800
trainer/QF1 Loss                   2.98581
trainer/QF2 Loss                   2.97086
trainer/Policy Loss               15.7708
trainer/Q1 Predictions Mean      -14.1355
trainer/Q1 Predictions Std         8.54462
trainer/Q1 Predictions Max       -12.0576
trainer/Q1 Predictions Min       -75.3678
trainer/Q2 Predictions Mean      -14.1205
trainer/Q2 Predictions Std         8.5538
trainer/Q2 Predictions Max       -12.0345
trainer/Q2 Predictions Min       -74.9006
trainer/Q Targets Mean           -13.8154
trainer/Q Targets Std              8.94717
trainer/Q Targets Max             -0.0702438
trainer/Q Targets Min            -76.9383
trainer/Log Pis Mean               1.96375
trainer/Log Pis Std                1.25425
trainer/Log Pis Max                6.26638
trainer/Log Pis Min               -3.03447
trainer/Policy mu Mean             0.116731
trainer/Policy mu Std              0.688078
trainer/Policy mu Max              3.26535
trainer/Policy mu Min             -1.98332
trainer/Policy log std Mean       -2.11707
trainer/Policy log std Std         0.393028
trainer/Policy log std Max        -0.565635
trainer/Policy log std Min        -2.38932
trainer/Alpha                      0.04707
trainer/Alpha Loss                -0.110788
exploration/num steps total    16800
exploration/num paths total      168
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.394404
exploration/Rewards Std            1.13751
exploration/Rewards Max           -0.0202364
exploration/Rewards Min           -8.3788
exploration/Returns Mean         -39.4404
exploration/Returns Std           12.3875
exploration/Returns Max          -27.0529
exploration/Returns Min          -51.8279
exploration/Actions Mean           0.0166364
exploration/Actions Std            0.241547
exploration/Actions Max            0.998758
exploration/Actions Min           -0.998457
exploration/Num Paths              2
exploration/Average Returns      -39.4404
evaluation/num steps total     83000
evaluation/num paths total       830
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.133194
evaluation/Rewards Std             0.532604
evaluation/Rewards Max            -0.00641802
evaluation/Rewards Min            -6.96303
evaluation/Returns Mean          -13.3194
evaluation/Returns Std             8.14262
evaluation/Returns Max            -5.98652
evaluation/Returns Min           -30.0581
evaluation/Actions Mean            0.0127563
evaluation/Actions Std             0.151949
evaluation/Actions Max             0.995629
evaluation/Actions Min            -0.995998
evaluation/Num Paths              10
evaluation/Average Returns       -13.3194
time/data storing (s)              0.00115645
time/evaluation sampling (s)       0.262796
time/exploration sampling (s)      0.0704299
time/logging (s)                   0.00348515
time/saving (s)                    0.0025058
time/training (s)                  0.988785
time/epoch (s)                     1.32916
time/total (s)                   118.712
Epoch                             82
-----------------------------  --------------
2019-04-21 12:18:24.638390 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 83 finished
-----------------------------  --------------
replay_buffer/size             17000
trainer/QF1 Loss                   4.27142
trainer/QF2 Loss                   4.31211
trainer/Policy Loss               15.0275
trainer/Q1 Predictions Mean      -13.4047
trainer/Q1 Predictions Std         5.73014
trainer/Q1 Predictions Max       -11.8847
trainer/Q1 Predictions Min       -57.4778
trainer/Q2 Predictions Mean      -13.458
trainer/Q2 Predictions Std         5.67677
trainer/Q2 Predictions Max       -11.9363
trainer/Q2 Predictions Min       -56.8023
trainer/Q Targets Mean           -13.0253
trainer/Q Targets Std              6.1121
trainer/Q Targets Max             -0.0848831
trainer/Q Targets Min            -58.0039
trainer/Log Pis Mean               1.8392
trainer/Log Pis Std                1.28703
trainer/Log Pis Max                5.9692
trainer/Log Pis Min               -1.25944
trainer/Policy mu Mean             0.0598604
trainer/Policy mu Std              0.671048
trainer/Policy mu Max              3.20351
trainer/Policy mu Min             -2.43956
trainer/Policy log std Mean       -2.07609
trainer/Policy log std Std         0.39802
trainer/Policy log std Max        -0.466503
trainer/Policy log std Min        -2.37826
trainer/Alpha                      0.0484069
trainer/Alpha Loss                -0.486909
exploration/num steps total    17000
exploration/num paths total      170
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.457532
exploration/Rewards Std            1.43883
exploration/Rewards Max           -0.00611591
exploration/Rewards Min          -10.5505
exploration/Returns Mean         -45.7532
exploration/Returns Std           24.5649
exploration/Returns Max          -21.1882
exploration/Returns Min          -70.3181
exploration/Actions Mean           0.037676
exploration/Actions Std            0.253001
exploration/Actions Max            0.998288
exploration/Actions Min           -0.734936
exploration/Num Paths              2
exploration/Average Returns      -45.7532
evaluation/num steps total     84000
evaluation/num paths total       840
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.275857
evaluation/Rewards Std             1.17726
evaluation/Rewards Max            -0.0311577
evaluation/Rewards Min           -10.2757
evaluation/Returns Mean          -27.5857
evaluation/Returns Std            21.7676
evaluation/Returns Max            -4.1998
evaluation/Returns Min           -58.6154
evaluation/Actions Mean            0.0299859
evaluation/Actions Std             0.182342
evaluation/Actions Max             0.997351
evaluation/Actions Min            -0.994062
evaluation/Num Paths              10
evaluation/Average Returns       -27.5857
time/data storing (s)              0.00116821
time/evaluation sampling (s)       0.252638
time/exploration sampling (s)      0.0680093
time/logging (s)                   0.00356098
time/saving (s)                    0.00275187
time/training (s)                  1.03293
time/epoch (s)                     1.36106
time/total (s)                   120.078
Epoch                             83
-----------------------------  --------------
2019-04-21 12:18:25.992280 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 84 finished
-----------------------------  --------------
replay_buffer/size             17200
trainer/QF1 Loss                   2.78284
trainer/QF2 Loss                   2.7699
trainer/Policy Loss               15.3987
trainer/Q1 Predictions Mean      -13.6147
trainer/Q1 Predictions Std         5.94
trainer/Q1 Predictions Max       -11.5929
trainer/Q1 Predictions Min       -44.0473
trainer/Q2 Predictions Mean      -13.6806
trainer/Q2 Predictions Std         5.94255
trainer/Q2 Predictions Max       -11.6552
trainer/Q2 Predictions Min       -44.7013
trainer/Q Targets Mean           -13.5739
trainer/Q Targets Std              6.23664
trainer/Q Targets Max             -0.395245
trainer/Q Targets Min            -44.3734
trainer/Log Pis Mean               2.04075
trainer/Log Pis Std                1.3188
trainer/Log Pis Max                5.93506
trainer/Log Pis Min               -2.58538
trainer/Policy mu Mean             0.187659
trainer/Policy mu Std              0.799042
trainer/Policy mu Max              3.19048
trainer/Policy mu Min             -1.87961
trainer/Policy log std Mean       -2.06252
trainer/Policy log std Std         0.481571
trainer/Policy log std Max        -0.466722
trainer/Policy log std Min        -2.43626
trainer/Alpha                      0.0479247
trainer/Alpha Loss                 0.123802
exploration/num steps total    17200
exploration/num paths total      172
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.614172
exploration/Rewards Std            1.76768
exploration/Rewards Max           -0.0117498
exploration/Rewards Min          -10.6429
exploration/Returns Mean         -61.4172
exploration/Returns Std            1.93469
exploration/Returns Max          -59.4825
exploration/Returns Min          -63.3519
exploration/Actions Mean           0.0722773
exploration/Actions Std            0.277791
exploration/Actions Max            0.999134
exploration/Actions Min           -0.436992
exploration/Num Paths              2
exploration/Average Returns      -61.4172
evaluation/num steps total     85000
evaluation/num paths total       850
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.208974
evaluation/Rewards Std             0.949534
evaluation/Rewards Max            -0.0241226
evaluation/Rewards Min           -10.2626
evaluation/Returns Mean          -20.8974
evaluation/Returns Std            14.5699
evaluation/Returns Max            -5.87871
evaluation/Returns Min           -51.9968
evaluation/Actions Mean            0.0327301
evaluation/Actions Std             0.187159
evaluation/Actions Max             0.997154
evaluation/Actions Min            -0.964699
evaluation/Num Paths              10
evaluation/Average Returns       -20.8974
time/data storing (s)              0.00118834
time/evaluation sampling (s)       0.264442
time/exploration sampling (s)      0.0695499
time/logging (s)                   0.00349857
time/saving (s)                    0.00258578
time/training (s)                  1.00622
time/epoch (s)                     1.34748
time/total (s)                   121.43
Epoch                             84
-----------------------------  --------------
2019-04-21 12:18:27.481618 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 85 finished
-----------------------------  --------------
replay_buffer/size             17400
trainer/QF1 Loss                   1.35814
trainer/QF2 Loss                   1.39318
trainer/Policy Loss               14.3837
trainer/Q1 Predictions Mean      -12.73
trainer/Q1 Predictions Std         4.67652
trainer/Q1 Predictions Max       -11.4914
trainer/Q1 Predictions Min       -52.5787
trainer/Q2 Predictions Mean      -12.6575
trainer/Q2 Predictions Std         4.70789
trainer/Q2 Predictions Max       -11.4326
trainer/Q2 Predictions Min       -52.9946
trainer/Q Targets Mean           -12.8078
trainer/Q Targets Std              4.80363
trainer/Q Targets Max             -0.11174
trainer/Q Targets Min            -52.073
trainer/Log Pis Mean               2.08738
trainer/Log Pis Std                1.09929
trainer/Log Pis Max                6.65009
trainer/Log Pis Min               -1.51022
trainer/Policy mu Mean             0.0967937
trainer/Policy mu Std              0.676456
trainer/Policy mu Max              3.14019
trainer/Policy mu Min             -3.19704
trainer/Policy log std Mean       -2.05239
trainer/Policy log std Std         0.40531
trainer/Policy log std Max        -0.550021
trainer/Policy log std Min        -2.31765
trainer/Alpha                      0.0496672
trainer/Alpha Loss                 0.262369
exploration/num steps total    17400
exploration/num paths total      174
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.226392
exploration/Rewards Std            0.581072
exploration/Rewards Max           -0.00736252
exploration/Rewards Min           -5.78697
exploration/Returns Mean         -22.6392
exploration/Returns Std            5.99882
exploration/Returns Max          -16.6404
exploration/Returns Min          -28.638
exploration/Actions Mean           0.0316851
exploration/Actions Std            0.225599
exploration/Actions Max            0.995401
exploration/Actions Min           -0.471767
exploration/Num Paths              2
exploration/Average Returns      -22.6392
evaluation/num steps total     86000
evaluation/num paths total       860
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.274922
evaluation/Rewards Std             1.13828
evaluation/Rewards Max            -0.0221182
evaluation/Rewards Min           -10.477
evaluation/Returns Mean          -27.4922
evaluation/Returns Std            17.849
evaluation/Returns Max            -5.33444
evaluation/Returns Min           -56.5492
evaluation/Actions Mean            0.0337576
evaluation/Actions Std             0.197645
evaluation/Actions Max             0.997304
evaluation/Actions Min            -0.986663
evaluation/Num Paths              10
evaluation/Average Returns       -27.4922
time/data storing (s)              0.00115037
time/evaluation sampling (s)       0.267989
time/exploration sampling (s)      0.0702276
time/logging (s)                   0.00886561
time/saving (s)                    0.00234909
time/training (s)                  1.13705
time/epoch (s)                     1.48763
time/total (s)                   122.923
Epoch                             85
-----------------------------  --------------
2019-04-21 12:18:29.012263 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 86 finished
-----------------------------  --------------
replay_buffer/size             17600
trainer/QF1 Loss                   1.31909
trainer/QF2 Loss                   1.2986
trainer/Policy Loss               13.9051
trainer/Q1 Predictions Mean      -12.4225
trainer/Q1 Predictions Std         3.20917
trainer/Q1 Predictions Max       -11.6082
trainer/Q1 Predictions Min       -37.8225
trainer/Q2 Predictions Mean      -12.3816
trainer/Q2 Predictions Std         3.2021
trainer/Q2 Predictions Max       -11.5823
trainer/Q2 Predictions Min       -37.2197
trainer/Q Targets Mean           -12.2733
trainer/Q Targets Std              3.38128
trainer/Q Targets Max             -0.650433
trainer/Q Targets Min            -37.4647
trainer/Log Pis Mean               1.75025
trainer/Log Pis Std                1.19805
trainer/Log Pis Max                6.91403
trainer/Log Pis Min               -1.69849
trainer/Policy mu Mean            -0.0168667
trainer/Policy mu Std              0.580646
trainer/Policy mu Max              2.91643
trainer/Policy mu Min             -3.2291
trainer/Policy log std Mean       -2.16258
trainer/Policy log std Std         0.325157
trainer/Policy log std Max        -0.667897
trainer/Policy log std Min        -2.39433
trainer/Alpha                      0.0495657
trainer/Alpha Loss                -0.750342
exploration/num steps total    17600
exploration/num paths total      176
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.191435
exploration/Rewards Std            0.364853
exploration/Rewards Max           -0.0129637
exploration/Rewards Min           -3.63374
exploration/Returns Mean         -19.1435
exploration/Returns Std            2.25879
exploration/Returns Max          -16.8847
exploration/Returns Min          -21.4023
exploration/Actions Mean           0.0279935
exploration/Actions Std            0.197908
exploration/Actions Max            0.995418
exploration/Actions Min           -0.38056
exploration/Num Paths              2
exploration/Average Returns      -19.1435
evaluation/num steps total     87000
evaluation/num paths total       870
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.295051
evaluation/Rewards Std             1.13273
evaluation/Rewards Max            -0.0108842
evaluation/Rewards Min           -10.1629
evaluation/Returns Mean          -29.5051
evaluation/Returns Std            18.6665
evaluation/Returns Max            -6.85126
evaluation/Returns Min           -57.4737
evaluation/Actions Mean            0.0357716
evaluation/Actions Std             0.194736
evaluation/Actions Max             0.997062
evaluation/Actions Min            -0.988173
evaluation/Num Paths              10
evaluation/Average Returns       -29.5051
time/data storing (s)              0.00116685
time/evaluation sampling (s)       0.257301
time/exploration sampling (s)      0.0699273
time/logging (s)                   0.0034098
time/saving (s)                    0.00249803
time/training (s)                  1.18445
time/epoch (s)                     1.51875
time/total (s)                   124.446
Epoch                             86
-----------------------------  --------------
2019-04-21 12:18:30.680768 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 87 finished
-----------------------------  --------------
replay_buffer/size             17800
trainer/QF1 Loss                   1.42119
trainer/QF2 Loss                   1.49281
trainer/Policy Loss               14.6724
trainer/Q1 Predictions Mean      -12.9626
trainer/Q1 Predictions Std         5.4556
trainer/Q1 Predictions Max       -11.5047
trainer/Q1 Predictions Min       -48.0903
trainer/Q2 Predictions Mean      -13.0037
trainer/Q2 Predictions Std         5.5251
trainer/Q2 Predictions Max       -11.5526
trainer/Q2 Predictions Min       -48.3924
trainer/Q Targets Mean           -12.8014
trainer/Q Targets Std              5.45947
trainer/Q Targets Max             -1.30665
trainer/Q Targets Min            -48.3627
trainer/Log Pis Mean               2.02292
trainer/Log Pis Std                1.20122
trainer/Log Pis Max                6.56062
trainer/Log Pis Min               -2.38085
trainer/Policy mu Mean            -0.00526273
trainer/Policy mu Std              0.665196
trainer/Policy mu Max              3.35481
trainer/Policy mu Min             -2.12305
trainer/Policy log std Mean       -2.11611
trainer/Policy log std Std         0.384545
trainer/Policy log std Max        -0.475719
trainer/Policy log std Min        -2.39304
trainer/Alpha                      0.0499909
trainer/Alpha Loss                 0.0686704
exploration/num steps total    17800
exploration/num paths total      178
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.351222
exploration/Rewards Std            0.959379
exploration/Rewards Max           -0.0152714
exploration/Rewards Min           -7.01196
exploration/Returns Mean         -35.1222
exploration/Returns Std            6.90946
exploration/Returns Max          -28.2127
exploration/Returns Min          -42.0316
exploration/Actions Mean           0.0168505
exploration/Actions Std            0.247416
exploration/Actions Max            0.994533
exploration/Actions Min           -0.993891
exploration/Num Paths              2
exploration/Average Returns      -35.1222
evaluation/num steps total     88000
evaluation/num paths total       880
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.256373
evaluation/Rewards Std             0.980729
evaluation/Rewards Max            -0.0656989
evaluation/Rewards Min           -10.0852
evaluation/Returns Mean          -25.6373
evaluation/Returns Std            17.8182
evaluation/Returns Max            -8.66764
evaluation/Returns Min           -56.5521
evaluation/Actions Mean            0.0192172
evaluation/Actions Std             0.187572
evaluation/Actions Max             0.996843
evaluation/Actions Min            -0.992138
evaluation/Num Paths              10
evaluation/Average Returns       -25.6373
time/data storing (s)              0.00144896
time/evaluation sampling (s)       0.260445
time/exploration sampling (s)      0.07297
time/logging (s)                   0.00350569
time/saving (s)                    0.00238576
time/training (s)                  1.32272
time/epoch (s)                     1.66347
time/total (s)                   126.114
Epoch                             87
-----------------------------  --------------
2019-04-21 12:18:32.344551 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 88 finished
-----------------------------  --------------
replay_buffer/size             18000
trainer/QF1 Loss                   2.67621
trainer/QF2 Loss                   2.65071
trainer/Policy Loss               14.6325
trainer/Q1 Predictions Mean      -12.8417
trainer/Q1 Predictions Std         4.93679
trainer/Q1 Predictions Max       -11.4727
trainer/Q1 Predictions Min       -49.0726
trainer/Q2 Predictions Mean      -12.7913
trainer/Q2 Predictions Std         5.02156
trainer/Q2 Predictions Max       -11.3767
trainer/Q2 Predictions Min       -49.5605
trainer/Q Targets Mean           -12.5726
trainer/Q Targets Std              5.19697
trainer/Q Targets Max             -0.0702438
trainer/Q Targets Min            -48.2453
trainer/Log Pis Mean               2.11934
trainer/Log Pis Std                1.20652
trainer/Log Pis Max                7.57136
trainer/Log Pis Min               -2.70804
trainer/Policy mu Mean             0.186219
trainer/Policy mu Std              0.664023
trainer/Policy mu Max              3.24525
trainer/Policy mu Min             -1.83012
trainer/Policy log std Mean       -2.07453
trainer/Policy log std Std         0.420104
trainer/Policy log std Max        -0.441241
trainer/Policy log std Min        -2.35739
trainer/Alpha                      0.0492547
trainer/Alpha Loss                 0.359293
exploration/num steps total    18000
exploration/num paths total      180
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.264431
exploration/Rewards Std            0.635135
exploration/Rewards Max           -0.0210892
exploration/Rewards Min           -5.21255
exploration/Returns Mean         -26.4431
exploration/Returns Std            2.89908
exploration/Returns Max          -23.544
exploration/Returns Min          -29.3422
exploration/Actions Mean           0.0364916
exploration/Actions Std            0.225439
exploration/Actions Max            0.996757
exploration/Actions Min           -0.495049
exploration/Num Paths              2
exploration/Average Returns      -26.4431
evaluation/num steps total     89000
evaluation/num paths total       890
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.142629
evaluation/Rewards Std             0.589406
evaluation/Rewards Max            -0.0259022
evaluation/Rewards Min            -7.55106
evaluation/Returns Mean          -14.2629
evaluation/Returns Std            10.0849
evaluation/Returns Max            -6.23129
evaluation/Returns Min           -35.1804
evaluation/Actions Mean            0.017893
evaluation/Actions Std             0.159697
evaluation/Actions Max             0.996376
evaluation/Actions Min            -0.978293
evaluation/Num Paths              10
evaluation/Average Returns       -14.2629
time/data storing (s)              0.00141165
time/evaluation sampling (s)       0.293711
time/exploration sampling (s)      0.0912062
time/logging (s)                   0.00342088
time/saving (s)                    0.00234026
time/training (s)                  1.26457
time/epoch (s)                     1.65666
time/total (s)                   127.775
Epoch                             88
-----------------------------  --------------
2019-04-21 12:18:34.431789 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 89 finished
-----------------------------  --------------
replay_buffer/size             18200
trainer/QF1 Loss                   2.66419
trainer/QF2 Loss                   2.65114
trainer/Policy Loss               14.2088
trainer/Q1 Predictions Mean      -12.5789
trainer/Q1 Predictions Std         3.96725
trainer/Q1 Predictions Max       -11.4057
trainer/Q1 Predictions Min       -41.5007
trainer/Q2 Predictions Mean      -12.5708
trainer/Q2 Predictions Std         3.91302
trainer/Q2 Predictions Max       -11.4144
trainer/Q2 Predictions Min       -41.2299
trainer/Q Targets Mean           -12.3185
trainer/Q Targets Std              4.3744
trainer/Q Targets Max             -0.046676
trainer/Q Targets Min            -42.7176
trainer/Log Pis Mean               1.96758
trainer/Log Pis Std                1.33077
trainer/Log Pis Max                7.13489
trainer/Log Pis Min               -2.08029
trainer/Policy mu Mean             0.0514792
trainer/Policy mu Std              0.764678
trainer/Policy mu Max              3.1788
trainer/Policy mu Min             -3.13945
trainer/Policy log std Mean       -1.97836
trainer/Policy log std Std         0.417581
trainer/Policy log std Max        -0.521923
trainer/Policy log std Min        -2.30345
trainer/Alpha                      0.0489439
trainer/Alpha Loss                -0.0978127
exploration/num steps total    18200
exploration/num paths total      182
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.226413
exploration/Rewards Std            0.632477
exploration/Rewards Max           -0.00688168
exploration/Rewards Min           -6.27961
exploration/Returns Mean         -22.6413
exploration/Returns Std            9.39193
exploration/Returns Max          -13.2493
exploration/Returns Min          -32.0332
exploration/Actions Mean           0.00137096
exploration/Actions Std            0.216814
exploration/Actions Max            0.995509
exploration/Actions Min           -0.978841
exploration/Num Paths              2
exploration/Average Returns      -22.6413
evaluation/num steps total     90000
evaluation/num paths total       900
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.228448
evaluation/Rewards Std             0.912637
evaluation/Rewards Max            -0.044883
evaluation/Rewards Min            -9.72726
evaluation/Returns Mean          -22.8448
evaluation/Returns Std            15.5823
evaluation/Returns Max            -7.68548
evaluation/Returns Min           -57.3015
evaluation/Actions Mean            0.0215253
evaluation/Actions Std             0.181474
evaluation/Actions Max             0.997082
evaluation/Actions Min            -0.997781
evaluation/Num Paths              10
evaluation/Average Returns       -22.8448
time/data storing (s)              0.00147623
time/evaluation sampling (s)       0.295606
time/exploration sampling (s)      0.109438
time/logging (s)                   0.00488843
time/saving (s)                    0.00418196
time/training (s)                  1.66624
time/epoch (s)                     2.08184
time/total (s)                   129.862
Epoch                             89
-----------------------------  --------------
2019-04-21 12:18:36.302086 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 90 finished
-----------------------------  --------------
replay_buffer/size             18400
trainer/QF1 Loss                   2.42357
trainer/QF2 Loss                   2.44708
trainer/Policy Loss               12.9665
trainer/Q1 Predictions Mean      -11.4191
trainer/Q1 Predictions Std         0.698057
trainer/Q1 Predictions Max       -11.0717
trainer/Q1 Predictions Min       -15.6938
trainer/Q2 Predictions Mean      -11.4542
trainer/Q2 Predictions Std         0.693324
trainer/Q2 Predictions Max       -11.085
trainer/Q2 Predictions Min       -15.6927
trainer/Q Targets Mean           -11.4059
trainer/Q Targets Std              1.67636
trainer/Q Targets Max             -0.428417
trainer/Q Targets Min            -15.6833
trainer/Log Pis Mean               1.67704
trainer/Log Pis Std                1.18054
trainer/Log Pis Max                4.67297
trainer/Log Pis Min               -2.58368
trainer/Policy mu Mean            -0.0497226
trainer/Policy mu Std              0.485507
trainer/Policy mu Max              2.64807
trainer/Policy mu Min             -1.81425
trainer/Policy log std Mean       -2.13146
trainer/Policy log std Std         0.297926
trainer/Policy log std Max        -0.665068
trainer/Policy log std Min        -2.29582
trainer/Alpha                      0.0482965
trainer/Alpha Loss                -0.978601
exploration/num steps total    18400
exploration/num paths total      184
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.292535
exploration/Rewards Std            0.839406
exploration/Rewards Max           -0.00729409
exploration/Rewards Min           -7.47451
exploration/Returns Mean         -29.2535
exploration/Returns Std           11.6389
exploration/Returns Max          -17.6146
exploration/Returns Min          -40.8924
exploration/Actions Mean           0.00425559
exploration/Actions Std            0.236868
exploration/Actions Max            0.999192
exploration/Actions Min           -0.994557
exploration/Num Paths              2
exploration/Average Returns      -29.2535
evaluation/num steps total     91000
evaluation/num paths total       910
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.211129
evaluation/Rewards Std             0.869408
evaluation/Rewards Max            -0.0242073
evaluation/Rewards Min            -9.26963
evaluation/Returns Mean          -21.1129
evaluation/Returns Std            14.0988
evaluation/Returns Max            -6.27666
evaluation/Returns Min           -45.8629
evaluation/Actions Mean            0.0278551
evaluation/Actions Std             0.177559
evaluation/Actions Max             0.996534
evaluation/Actions Min            -0.969496
evaluation/Num Paths              10
evaluation/Average Returns       -21.1129
time/data storing (s)              0.00163392
time/evaluation sampling (s)       0.443602
time/exploration sampling (s)      0.120024
time/logging (s)                   0.00493556
time/saving (s)                    0.00234106
time/training (s)                  1.28873
time/epoch (s)                     1.86127
time/total (s)                   131.73
Epoch                             90
-----------------------------  --------------
2019-04-21 12:18:37.738579 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 91 finished
-----------------------------  --------------
replay_buffer/size             18600
trainer/QF1 Loss                   2.55191
trainer/QF2 Loss                   2.65174
trainer/Policy Loss               14.7887
trainer/Q1 Predictions Mean      -13.368
trainer/Q1 Predictions Std         8.18871
trainer/Q1 Predictions Max       -11.1493
trainer/Q1 Predictions Min       -79.746
trainer/Q2 Predictions Mean      -13.3138
trainer/Q2 Predictions Std         8.17962
trainer/Q2 Predictions Max       -11.1067
trainer/Q2 Predictions Min       -80.1889
trainer/Q Targets Mean           -13.223
trainer/Q Targets Std              8.26274
trainer/Q Targets Max             -0.168816
trainer/Q Targets Min            -77.8791
trainer/Log Pis Mean               1.93155
trainer/Log Pis Std                1.27422
trainer/Log Pis Max                7.347
trainer/Log Pis Min               -2.48854
trainer/Policy mu Mean             0.0805062
trainer/Policy mu Std              0.769583
trainer/Policy mu Max              3.219
trainer/Policy mu Min             -2.69398
trainer/Policy log std Mean       -1.98209
trainer/Policy log std Std         0.429676
trainer/Policy log std Max        -0.486089
trainer/Policy log std Min        -2.27163
trainer/Alpha                      0.0467235
trainer/Alpha Loss                -0.209678
exploration/num steps total    18600
exploration/num paths total      186
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.462395
exploration/Rewards Std            1.2864
exploration/Rewards Max           -0.0162811
exploration/Rewards Min           -8.77447
exploration/Returns Mean         -46.2395
exploration/Returns Std            9.902
exploration/Returns Max          -36.3375
exploration/Returns Min          -56.1415
exploration/Actions Mean           0.0470457
exploration/Actions Std            0.251905
exploration/Actions Max            0.998682
exploration/Actions Min           -0.435386
exploration/Num Paths              2
exploration/Average Returns      -46.2395
evaluation/num steps total     92000
evaluation/num paths total       920
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.223208
evaluation/Rewards Std             0.973961
evaluation/Rewards Max            -0.0388952
evaluation/Rewards Min           -10.0452
evaluation/Returns Mean          -22.3208
evaluation/Returns Std            17.504
evaluation/Returns Max            -4.7325
evaluation/Returns Min           -56.0198
evaluation/Actions Mean            0.0155899
evaluation/Actions Std             0.187626
evaluation/Actions Max             0.997276
evaluation/Actions Min            -0.994692
evaluation/Num Paths              10
evaluation/Average Returns       -22.3208
time/data storing (s)              0.00115141
time/evaluation sampling (s)       0.264835
time/exploration sampling (s)      0.0682158
time/logging (s)                   0.00359698
time/saving (s)                    0.00251243
time/training (s)                  1.08878
time/epoch (s)                     1.42909
time/total (s)                   133.163
Epoch                             91
-----------------------------  --------------
2019-04-21 12:18:39.187684 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 92 finished
-----------------------------  --------------
replay_buffer/size             18800
trainer/QF1 Loss                   1.26923
trainer/QF2 Loss                   1.27842
trainer/Policy Loss               13.6751
trainer/Q1 Predictions Mean      -12.0181
trainer/Q1 Predictions Std         4.51327
trainer/Q1 Predictions Max       -10.8893
trainer/Q1 Predictions Min       -50.1857
trainer/Q2 Predictions Mean      -12.0235
trainer/Q2 Predictions Std         4.49958
trainer/Q2 Predictions Max       -10.8929
trainer/Q2 Predictions Min       -50.1777
trainer/Q Targets Mean           -12.2005
trainer/Q Targets Std              4.69584
trainer/Q Targets Max             -0.136832
trainer/Q Targets Min            -50.4994
trainer/Log Pis Mean               1.83883
trainer/Log Pis Std                1.45576
trainer/Log Pis Max                7.00981
trainer/Log Pis Min               -4.03161
trainer/Policy mu Mean             0.107412
trainer/Policy mu Std              0.65258
trainer/Policy mu Max              2.96278
trainer/Policy mu Min             -1.56527
trainer/Policy log std Mean       -2.04139
trainer/Policy log std Std         0.373938
trainer/Policy log std Max        -0.657491
trainer/Policy log std Min        -2.28902
trainer/Alpha                      0.0450965
trainer/Alpha Loss                -0.499444
exploration/num steps total    18800
exploration/num paths total      188
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.304221
exploration/Rewards Std            0.74448
exploration/Rewards Max           -0.0147347
exploration/Rewards Min           -6.37873
exploration/Returns Mean         -30.4221
exploration/Returns Std            5.11469
exploration/Returns Max          -25.3074
exploration/Returns Min          -35.5368
exploration/Actions Mean           0.0173981
exploration/Actions Std            0.246567
exploration/Actions Max            0.98842
exploration/Actions Min           -0.996449
exploration/Num Paths              2
exploration/Average Returns      -30.4221
evaluation/num steps total     93000
evaluation/num paths total       930
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.265476
evaluation/Rewards Std             0.928481
evaluation/Rewards Max            -0.0594572
evaluation/Rewards Min            -8.43121
evaluation/Returns Mean          -26.5476
evaluation/Returns Std            13.3128
evaluation/Returns Max           -10.2867
evaluation/Returns Min           -47.9977
evaluation/Actions Mean            0.0231967
evaluation/Actions Std             0.186513
evaluation/Actions Max             0.994562
evaluation/Actions Min            -0.995024
evaluation/Num Paths              10
evaluation/Average Returns       -26.5476
time/data storing (s)              0.00121458
time/evaluation sampling (s)       0.252109
time/exploration sampling (s)      0.0687938
time/logging (s)                   0.00392355
time/saving (s)                    0.0023374
time/training (s)                  1.11461
time/epoch (s)                     1.44299
time/total (s)                   134.61
Epoch                             92
-----------------------------  --------------
2019-04-21 12:18:40.547859 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 93 finished
-----------------------------  --------------
replay_buffer/size             19000
trainer/QF1 Loss                   0.0544929
trainer/QF2 Loss                   0.0857792
trainer/Policy Loss               14.8177
trainer/Q1 Predictions Mean      -12.9902
trainer/Q1 Predictions Std         6.88939
trainer/Q1 Predictions Max       -10.8792
trainer/Q1 Predictions Min       -62.4044
trainer/Q2 Predictions Mean      -12.893
trainer/Q2 Predictions Std         6.80181
trainer/Q2 Predictions Max       -10.7959
trainer/Q2 Predictions Min       -61.9354
trainer/Q Targets Mean           -13.137
trainer/Q Targets Std              6.85077
trainer/Q Targets Max            -10.9773
trainer/Q Targets Min            -62.6168
trainer/Log Pis Mean               2.29159
trainer/Log Pis Std                1.50826
trainer/Log Pis Max                9.10208
trainer/Log Pis Min               -2.79655
trainer/Policy mu Mean             0.113099
trainer/Policy mu Std              0.832775
trainer/Policy mu Max              3.35392
trainer/Policy mu Min             -2.31047
trainer/Policy log std Mean       -2.06985
trainer/Policy log std Std         0.482642
trainer/Policy log std Max        -0.549073
trainer/Policy log std Min        -2.3899
trainer/Alpha                      0.0471074
trainer/Alpha Loss                 0.890999
exploration/num steps total    19000
exploration/num paths total      190
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.193209
exploration/Rewards Std            0.501464
exploration/Rewards Max           -0.00473833
exploration/Rewards Min           -4.96025
exploration/Returns Mean         -19.3209
exploration/Returns Std            7.19723
exploration/Returns Max          -12.1236
exploration/Returns Min          -26.5181
exploration/Actions Mean           0.0140662
exploration/Actions Std            0.189635
exploration/Actions Max            0.993748
exploration/Actions Min           -0.625025
exploration/Num Paths              2
exploration/Average Returns      -19.3209
evaluation/num steps total     94000
evaluation/num paths total       940
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.189538
evaluation/Rewards Std             0.949341
evaluation/Rewards Max            -0.01661
evaluation/Rewards Min            -9.14903
evaluation/Returns Mean          -18.9538
evaluation/Returns Std            17.8915
evaluation/Returns Max            -2.30121
evaluation/Returns Min           -46.5111
evaluation/Actions Mean            0.0237597
evaluation/Actions Std             0.169647
evaluation/Actions Max             0.997254
evaluation/Actions Min            -0.969661
evaluation/Num Paths              10
evaluation/Average Returns       -18.9538
time/data storing (s)              0.00152252
time/evaluation sampling (s)       0.272312
time/exploration sampling (s)      0.0678804
time/logging (s)                   0.00405582
time/saving (s)                    0.00298042
time/training (s)                  1.00461
time/epoch (s)                     1.35336
time/total (s)                   135.968
Epoch                             93
-----------------------------  --------------
2019-04-21 12:18:42.053529 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 94 finished
-----------------------------  --------------
replay_buffer/size             19200
trainer/QF1 Loss                   2.48878
trainer/QF2 Loss                   2.47476
trainer/Policy Loss               14.7876
trainer/Q1 Predictions Mean      -13.1016
trainer/Q1 Predictions Std         7.46247
trainer/Q1 Predictions Max       -10.8374
trainer/Q1 Predictions Min       -54.8276
trainer/Q2 Predictions Mean      -13.1446
trainer/Q2 Predictions Std         7.52551
trainer/Q2 Predictions Max       -10.9067
trainer/Q2 Predictions Min       -55.175
trainer/Q Targets Mean           -13.0292
trainer/Q Targets Std              7.84876
trainer/Q Targets Max             -0.0711684
trainer/Q Targets Min            -56.6731
trainer/Log Pis Mean               2.33878
trainer/Log Pis Std                1.35338
trainer/Log Pis Max                7.90227
trainer/Log Pis Min               -1.81188
trainer/Policy mu Mean             0.127322
trainer/Policy mu Std              0.770727
trainer/Policy mu Max              3.27804
trainer/Policy mu Min             -2.28898
trainer/Policy log std Mean       -2.01981
trainer/Policy log std Std         0.466061
trainer/Policy log std Max        -0.491246
trainer/Policy log std Min        -2.3362
trainer/Alpha                      0.0482336
trainer/Alpha Loss                 1.02708
exploration/num steps total    19200
exploration/num paths total      192
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.375018
exploration/Rewards Std            1.02442
exploration/Rewards Max           -0.0118567
exploration/Rewards Min           -7.47832
exploration/Returns Mean         -37.5018
exploration/Returns Std            6.95202
exploration/Returns Max          -30.5498
exploration/Returns Min          -44.4538
exploration/Actions Mean           0.0386567
exploration/Actions Std            0.246062
exploration/Actions Max            0.999198
exploration/Actions Min           -0.678337
exploration/Num Paths              2
exploration/Average Returns      -37.5018
evaluation/num steps total     95000
evaluation/num paths total       950
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.226102
evaluation/Rewards Std             0.870696
evaluation/Rewards Max            -0.0576631
evaluation/Rewards Min            -8.93662
evaluation/Returns Mean          -22.6102
evaluation/Returns Std            11.0448
evaluation/Returns Max            -6.32085
evaluation/Returns Min           -43.38
evaluation/Actions Mean            0.0304456
evaluation/Actions Std             0.18777
evaluation/Actions Max             0.99717
evaluation/Actions Min            -0.981493
evaluation/Num Paths              10
evaluation/Average Returns       -22.6102
time/data storing (s)              0.00167479
time/evaluation sampling (s)       0.31519
time/exploration sampling (s)      0.0933266
time/logging (s)                   0.00354646
time/saving (s)                    0.00247383
time/training (s)                  1.08119
time/epoch (s)                     1.4974
time/total (s)                   137.471
Epoch                             94
-----------------------------  --------------
2019-04-21 12:18:43.452887 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 95 finished
-----------------------------  --------------
replay_buffer/size             19400
trainer/QF1 Loss                   1.19104
trainer/QF2 Loss                   1.19046
trainer/Policy Loss               13.6445
trainer/Q1 Predictions Mean      -11.6732
trainer/Q1 Predictions Std         3.61234
trainer/Q1 Predictions Max       -10.6538
trainer/Q1 Predictions Min       -35.1037
trainer/Q2 Predictions Mean      -11.6439
trainer/Q2 Predictions Std         3.60701
trainer/Q2 Predictions Max       -10.6266
trainer/Q2 Predictions Min       -34.7766
trainer/Q Targets Mean           -11.7469
trainer/Q Targets Std              3.78255
trainer/Q Targets Max             -0.132749
trainer/Q Targets Min            -34.5518
trainer/Log Pis Mean               2.11801
trainer/Log Pis Std                1.2454
trainer/Log Pis Max                8.49377
trainer/Log Pis Min               -1.01044
trainer/Policy mu Mean             0.124013
trainer/Policy mu Std              0.64917
trainer/Policy mu Max              2.98802
trainer/Policy mu Min             -2.52677
trainer/Policy log std Mean       -2.14327
trainer/Policy log std Std         0.368814
trainer/Policy log std Max        -0.653564
trainer/Policy log std Min        -2.391
trainer/Alpha                      0.0493065
trainer/Alpha Loss                 0.355189
exploration/num steps total    19400
exploration/num paths total      194
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.33465
exploration/Rewards Std            0.882396
exploration/Rewards Max           -0.0109423
exploration/Rewards Min           -6.90079
exploration/Returns Mean         -33.465
exploration/Returns Std            2.73952
exploration/Returns Max          -30.7255
exploration/Returns Min          -36.2045
exploration/Actions Mean           0.0417514
exploration/Actions Std            0.242052
exploration/Actions Max            0.998122
exploration/Actions Min           -0.678103
exploration/Num Paths              2
exploration/Average Returns      -33.465
evaluation/num steps total     96000
evaluation/num paths total       960
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.331634
evaluation/Rewards Std             1.1369
evaluation/Rewards Max            -0.0296934
evaluation/Rewards Min            -9.51877
evaluation/Returns Mean          -33.1634
evaluation/Returns Std            16.0283
evaluation/Returns Max           -12.2681
evaluation/Returns Min           -57.1444
evaluation/Actions Mean            0.0275045
evaluation/Actions Std             0.202966
evaluation/Actions Max             0.997174
evaluation/Actions Min            -0.991016
evaluation/Num Paths              10
evaluation/Average Returns       -33.1634
time/data storing (s)              0.00124713
time/evaluation sampling (s)       0.253625
time/exploration sampling (s)      0.0670583
time/logging (s)                   0.00411477
time/saving (s)                    0.00241772
time/training (s)                  1.06514
time/epoch (s)                     1.39361
time/total (s)                   138.869
Epoch                             95
-----------------------------  --------------
2019-04-21 12:18:45.076299 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 96 finished
-----------------------------  --------------
replay_buffer/size             19600
trainer/QF1 Loss                   0.391217
trainer/QF2 Loss                   0.328925
trainer/Policy Loss               13.3776
trainer/Q1 Predictions Mean      -11.7584
trainer/Q1 Predictions Std         4.02389
trainer/Q1 Predictions Max       -10.4819
trainer/Q1 Predictions Min       -33.5007
trainer/Q2 Predictions Mean      -11.8034
trainer/Q2 Predictions Std         4.05596
trainer/Q2 Predictions Max       -10.5043
trainer/Q2 Predictions Min       -34.1019
trainer/Q Targets Mean           -12.1426
trainer/Q Targets Std              4.1718
trainer/Q Targets Max            -10.7456
trainer/Q Targets Min            -34.0279
trainer/Log Pis Mean               1.86878
trainer/Log Pis Std                1.36771
trainer/Log Pis Max                7.71153
trainer/Log Pis Min               -2.887
trainer/Policy mu Mean             0.0112413
trainer/Policy mu Std              0.659755
trainer/Policy mu Max              2.97674
trainer/Policy mu Min             -3.19723
trainer/Policy log std Mean       -2.07857
trainer/Policy log std Std         0.397205
trainer/Policy log std Max        -0.505678
trainer/Policy log std Min        -2.33913
trainer/Alpha                      0.0498047
trainer/Alpha Loss                -0.393623
exploration/num steps total    19600
exploration/num paths total      196
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.389799
exploration/Rewards Std            1.28963
exploration/Rewards Max           -0.0131705
exploration/Rewards Min           -9.68979
exploration/Returns Mean         -38.9799
exploration/Returns Std           24.0969
exploration/Returns Max          -14.883
exploration/Returns Min          -63.0768
exploration/Actions Mean           0.04117
exploration/Actions Std            0.227901
exploration/Actions Max            0.996058
exploration/Actions Min           -0.374643
exploration/Num Paths              2
exploration/Average Returns      -38.9799
evaluation/num steps total     97000
evaluation/num paths total       970
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.270439
evaluation/Rewards Std             1.14741
evaluation/Rewards Max            -0.016088
evaluation/Rewards Min           -10.0624
evaluation/Returns Mean          -27.0439
evaluation/Returns Std            15.9309
evaluation/Returns Max            -4.46451
evaluation/Returns Min           -52.9841
evaluation/Actions Mean            0.022195
evaluation/Actions Std             0.200406
evaluation/Actions Max             0.996124
evaluation/Actions Min            -0.987265
evaluation/Num Paths              10
evaluation/Average Returns       -27.0439
time/data storing (s)              0.00126086
time/evaluation sampling (s)       0.297092
time/exploration sampling (s)      0.0819066
time/logging (s)                   0.00355187
time/saving (s)                    0.00275564
time/training (s)                  1.22942
time/epoch (s)                     1.61599
time/total (s)                   140.49
Epoch                             96
-----------------------------  --------------
2019-04-21 12:18:46.587397 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 97 finished
-----------------------------  --------------
replay_buffer/size             19800
trainer/QF1 Loss                   2.25734
trainer/QF2 Loss                   2.30262
trainer/Policy Loss               14.2048
trainer/Q1 Predictions Mean      -12.7141
trainer/Q1 Predictions Std         6.71126
trainer/Q1 Predictions Max       -10.455
trainer/Q1 Predictions Min       -49.8583
trainer/Q2 Predictions Mean      -12.8317
trainer/Q2 Predictions Std         6.80172
trainer/Q2 Predictions Max       -10.5226
trainer/Q2 Predictions Min       -50.071
trainer/Q Targets Mean           -12.7499
trainer/Q Targets Std              6.7842
trainer/Q Targets Max             -0.122639
trainer/Q Targets Min            -49.6875
trainer/Log Pis Mean               2.10278
trainer/Log Pis Std                1.41071
trainer/Log Pis Max                8.55084
trainer/Log Pis Min               -1.05459
trainer/Policy mu Mean             0.0829521
trainer/Policy mu Std              0.884039
trainer/Policy mu Max              3.53192
trainer/Policy mu Min             -3.18734
trainer/Policy log std Mean       -2.00512
trainer/Policy log std Std         0.505432
trainer/Policy log std Max        -0.394062
trainer/Policy log std Min        -2.36747
trainer/Alpha                      0.0495364
trainer/Alpha Loss                 0.308868
exploration/num steps total    19800
exploration/num paths total      198
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.235324
exploration/Rewards Std            0.620601
exploration/Rewards Max           -0.00403103
exploration/Rewards Min           -5.96541
exploration/Returns Mean         -23.5324
exploration/Returns Std            7.26438
exploration/Returns Max          -16.268
exploration/Returns Min          -30.7968
exploration/Actions Mean           0.019264
exploration/Actions Std            0.230094
exploration/Actions Max            0.996556
exploration/Actions Min           -0.986989
exploration/Num Paths              2
exploration/Average Returns      -23.5324
evaluation/num steps total     98000
evaluation/num paths total       980
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.204269
evaluation/Rewards Std             0.86619
evaluation/Rewards Max            -0.0109854
evaluation/Rewards Min            -9.19071
evaluation/Returns Mean          -20.4269
evaluation/Returns Std            14.2369
evaluation/Returns Max            -5.34145
evaluation/Returns Min           -50.2226
evaluation/Actions Mean            0.0208304
evaluation/Actions Std             0.17757
evaluation/Actions Max             0.997234
evaluation/Actions Min            -0.997416
evaluation/Num Paths              10
evaluation/Average Returns       -20.4269
time/data storing (s)              0.00116489
time/evaluation sampling (s)       0.307201
time/exploration sampling (s)      0.0671132
time/logging (s)                   0.00350037
time/saving (s)                    0.00244732
time/training (s)                  1.12132
time/epoch (s)                     1.50275
time/total (s)                   141.999
Epoch                             97
-----------------------------  --------------
2019-04-21 12:18:48.046084 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 98 finished
-----------------------------  --------------
replay_buffer/size             20000
trainer/QF1 Loss                   0.0414537
trainer/QF2 Loss                   0.03817
trainer/Policy Loss               13.4612
trainer/Q1 Predictions Mean      -11.6695
trainer/Q1 Predictions Std         3.55407
trainer/Q1 Predictions Max       -10.5749
trainer/Q1 Predictions Min       -30.3151
trainer/Q2 Predictions Mean      -11.6288
trainer/Q2 Predictions Std         3.52441
trainer/Q2 Predictions Max       -10.5342
trainer/Q2 Predictions Min       -30.2601
trainer/Q Targets Mean           -11.6841
trainer/Q Targets Std              3.44508
trainer/Q Targets Max            -10.542
trainer/Q Targets Min            -29.9544
trainer/Log Pis Mean               2.15342
trainer/Log Pis Std                1.00197
trainer/Log Pis Max                5.19903
trainer/Log Pis Min               -3.33708
trainer/Policy mu Mean            -0.0364319
trainer/Policy mu Std              0.64371
trainer/Policy mu Max              3.04616
trainer/Policy mu Min             -2.11506
trainer/Policy log std Mean       -2.15069
trainer/Policy log std Std         0.397763
trainer/Policy log std Max        -0.628521
trainer/Policy log std Min        -2.41151
trainer/Alpha                      0.0503089
trainer/Alpha Loss                 0.458679
exploration/num steps total    20000
exploration/num paths total      200
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.269964
exploration/Rewards Std            0.780385
exploration/Rewards Max           -0.00935189
exploration/Rewards Min           -7.01597
exploration/Returns Mean         -26.9964
exploration/Returns Std           12.0815
exploration/Returns Max          -14.9148
exploration/Returns Min          -39.0779
exploration/Actions Mean           0.00187948
exploration/Actions Std            0.220302
exploration/Actions Max            0.997868
exploration/Actions Min           -0.997287
exploration/Num Paths              2
exploration/Average Returns      -26.9964
evaluation/num steps total     99000
evaluation/num paths total       990
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.64919
evaluation/Rewards Std             1.53588
evaluation/Rewards Max            -0.0665393
evaluation/Rewards Min            -9.80489
evaluation/Returns Mean          -64.919
evaluation/Returns Std           130.989
evaluation/Returns Max            -8.53477
evaluation/Returns Min          -455.429
evaluation/Actions Mean           -0.0253538
evaluation/Actions Std             0.281323
evaluation/Actions Max             0.996875
evaluation/Actions Min            -0.998085
evaluation/Num Paths              10
evaluation/Average Returns       -64.919
time/data storing (s)              0.00114121
time/evaluation sampling (s)       0.251882
time/exploration sampling (s)      0.0677602
time/logging (s)                   0.00364762
time/saving (s)                    0.00370868
time/training (s)                  1.12471
time/epoch (s)                     1.45285
time/total (s)                   143.456
Epoch                             98
-----------------------------  --------------
2019-04-21 12:18:49.530755 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 99 finished
-----------------------------  ----------------
replay_buffer/size              20200
trainer/QF1 Loss                    1.29435
trainer/QF2 Loss                    1.23909
trainer/Policy Loss                12.8431
trainer/Q1 Predictions Mean       -11.3997
trainer/Q1 Predictions Std          2.752
trainer/Q1 Predictions Max        -10.5408
trainer/Q1 Predictions Min        -29.4158
trainer/Q2 Predictions Mean       -11.4267
trainer/Q2 Predictions Std          2.76641
trainer/Q2 Predictions Max        -10.5368
trainer/Q2 Predictions Min        -29.484
trainer/Q Targets Mean            -11.3536
trainer/Q Targets Std               3.04833
trainer/Q Targets Max              -0.355847
trainer/Q Targets Min             -29.3113
trainer/Log Pis Mean                1.7309
trainer/Log Pis Std                 1.28293
trainer/Log Pis Max                 6.33762
trainer/Log Pis Min                -1.3638
trainer/Policy mu Mean              0.0597616
trainer/Policy mu Std               0.60847
trainer/Policy mu Max               3.00572
trainer/Policy mu Min              -2.65487
trainer/Policy log std Mean        -2.13175
trainer/Policy log std Std          0.402348
trainer/Policy log std Max         -0.499589
trainer/Policy log std Min         -2.41694
trainer/Alpha                       0.0514323
trainer/Alpha Loss                 -0.798548
exploration/num steps total     20200
exploration/num paths total       202
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.331828
exploration/Rewards Std             0.924017
exploration/Rewards Max            -0.00356438
exploration/Rewards Min            -7.26053
exploration/Returns Mean          -33.1828
exploration/Returns Std             6.46076
exploration/Returns Max           -26.722
exploration/Returns Min           -39.6435
exploration/Actions Mean            0.0172181
exploration/Actions Std             0.24791
exploration/Actions Max             0.999283
exploration/Actions Min            -0.951656
exploration/Num Paths               2
exploration/Average Returns       -33.1828
evaluation/num steps total     100000
evaluation/num paths total       1000
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.120293
evaluation/Rewards Std              0.451279
evaluation/Rewards Max             -0.0226288
evaluation/Rewards Min             -5.96845
evaluation/Returns Mean           -12.0293
evaluation/Returns Std              6.05046
evaluation/Returns Max             -5.76891
evaluation/Returns Min            -23.0835
evaluation/Actions Mean             0.000720313
evaluation/Actions Std              0.146524
evaluation/Actions Max              0.998259
evaluation/Actions Min             -0.997825
evaluation/Num Paths               10
evaluation/Average Returns        -12.0293
time/data storing (s)               0.00124192
time/evaluation sampling (s)        0.278875
time/exploration sampling (s)       0.0678682
time/logging (s)                    0.00343969
time/saving (s)                     0.00233601
time/training (s)                   1.12298
time/epoch (s)                      1.47674
time/total (s)                    144.938
Epoch                              99
-----------------------------  ----------------
2019-04-21 12:18:50.977958 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 100 finished
-----------------------------  ---------------
replay_buffer/size              20400
trainer/QF1 Loss                    0.165014
trainer/QF2 Loss                    0.155687
trainer/Policy Loss                13.3316
trainer/Q1 Predictions Mean       -11.7296
trainer/Q1 Predictions Std          7.33683
trainer/Q1 Predictions Max        -10.1086
trainer/Q1 Predictions Min        -78.6837
trainer/Q2 Predictions Mean       -11.7787
trainer/Q2 Predictions Std          7.38439
trainer/Q2 Predictions Max        -10.1493
trainer/Q2 Predictions Min        -79.2009
trainer/Q Targets Mean            -12.0757
trainer/Q Targets Std               7.16461
trainer/Q Targets Max             -10.4049
trainer/Q Targets Min             -77.1845
trainer/Log Pis Mean                1.90561
trainer/Log Pis Std                 1.09258
trainer/Log Pis Max                 5.01217
trainer/Log Pis Min                -1.51516
trainer/Policy mu Mean              0.0545954
trainer/Policy mu Std               0.612677
trainer/Policy mu Max               3.12497
trainer/Policy mu Min              -2.92336
trainer/Policy log std Mean        -2.15572
trainer/Policy log std Std          0.402029
trainer/Policy log std Max         -0.467352
trainer/Policy log std Min         -2.39883
trainer/Alpha                       0.0520041
trainer/Alpha Loss                 -0.279085
exploration/num steps total     20400
exploration/num paths total       204
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.432221
exploration/Rewards Std             1.32088
exploration/Rewards Max            -0.00538767
exploration/Rewards Min            -9.5435
exploration/Returns Mean          -43.2221
exploration/Returns Std            18.2409
exploration/Returns Max           -24.9812
exploration/Returns Min           -61.463
exploration/Actions Mean            0.0242096
exploration/Actions Std             0.255366
exploration/Actions Max             0.998708
exploration/Actions Min            -0.965181
exploration/Num Paths               2
exploration/Average Returns       -43.2221
evaluation/num steps total     101000
evaluation/num paths total       1010
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.233101
evaluation/Rewards Std              0.966031
evaluation/Rewards Max             -0.0309767
evaluation/Rewards Min            -10.006
evaluation/Returns Mean           -23.3101
evaluation/Returns Std             11.7384
evaluation/Returns Max             -4.21794
evaluation/Returns Min            -50.2834
evaluation/Actions Mean             0.0312071
evaluation/Actions Std              0.19452
evaluation/Actions Max              0.997257
evaluation/Actions Min             -0.996359
evaluation/Num Paths               10
evaluation/Average Returns        -23.3101
time/data storing (s)               0.00137616
time/evaluation sampling (s)        0.254188
time/exploration sampling (s)       0.070224
time/logging (s)                    0.00633398
time/saving (s)                     0.00378609
time/training (s)                   1.10757
time/epoch (s)                      1.44347
time/total (s)                    146.386
Epoch                             100
-----------------------------  ---------------
2019-04-21 12:18:52.487979 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 101 finished
-----------------------------  ---------------
replay_buffer/size              20600
trainer/QF1 Loss                    2.21274
trainer/QF2 Loss                    2.21203
trainer/Policy Loss                14.4763
trainer/Q1 Predictions Mean       -12.8208
trainer/Q1 Predictions Std          7.93774
trainer/Q1 Predictions Max        -10.4175
trainer/Q1 Predictions Min        -62.5303
trainer/Q2 Predictions Mean       -12.7779
trainer/Q2 Predictions Std          7.90339
trainer/Q2 Predictions Max        -10.3925
trainer/Q2 Predictions Min        -62.4364
trainer/Q Targets Mean            -12.6481
trainer/Q Targets Std               8.24066
trainer/Q Targets Max              -0.0453797
trainer/Q Targets Min             -63.1638
trainer/Log Pis Mean                2.11361
trainer/Log Pis Std                 1.52764
trainer/Log Pis Max                 8.42371
trainer/Log Pis Min                -1.84348
trainer/Policy mu Mean              0.144287
trainer/Policy mu Std               0.802575
trainer/Policy mu Max               3.15564
trainer/Policy mu Min              -2.17981
trainer/Policy log std Mean        -1.99202
trainer/Policy log std Std          0.486259
trainer/Policy log std Max         -0.523223
trainer/Policy log std Min         -2.35596
trainer/Alpha                       0.0519668
trainer/Alpha Loss                  0.335941
exploration/num steps total     20600
exploration/num paths total       206
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.370931
exploration/Rewards Std             1.16057
exploration/Rewards Max            -0.00694164
exploration/Rewards Min            -9.15205
exploration/Returns Mean          -37.0931
exploration/Returns Std            16.3182
exploration/Returns Max           -20.7748
exploration/Returns Min           -53.4113
exploration/Actions Mean            0.0288002
exploration/Actions Std             0.24457
exploration/Actions Max             0.999291
exploration/Actions Min            -0.980514
exploration/Num Paths               2
exploration/Average Returns       -37.0931
evaluation/num steps total     102000
evaluation/num paths total       1020
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.266364
evaluation/Rewards Std              1.1677
evaluation/Rewards Max             -0.0134596
evaluation/Rewards Min             -9.58448
evaluation/Returns Mean           -26.6364
evaluation/Returns Std             17.3916
evaluation/Returns Max             -2.25657
evaluation/Returns Min            -48.8412
evaluation/Actions Mean             0.0305088
evaluation/Actions Std              0.1996
evaluation/Actions Max              0.996976
evaluation/Actions Min             -0.995247
evaluation/Num Paths               10
evaluation/Average Returns        -26.6364
time/data storing (s)               0.00116712
time/evaluation sampling (s)        0.27794
time/exploration sampling (s)       0.0674248
time/logging (s)                    0.00355241
time/saving (s)                     0.00232041
time/training (s)                   1.14566
time/epoch (s)                      1.49806
time/total (s)                    147.89
Epoch                             101
-----------------------------  ---------------
2019-04-21 12:18:54.056969 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 102 finished
-----------------------------  ---------------
replay_buffer/size              20800
trainer/QF1 Loss                    1.13121
trainer/QF2 Loss                    1.13087
trainer/Policy Loss                14.4307
trainer/Q1 Predictions Mean       -12.6055
trainer/Q1 Predictions Std          7.42646
trainer/Q1 Predictions Max        -10.1393
trainer/Q1 Predictions Min        -56.3919
trainer/Q2 Predictions Mean       -12.5437
trainer/Q2 Predictions Std          7.41372
trainer/Q2 Predictions Max        -10.0886
trainer/Q2 Predictions Min        -56.6921
trainer/Q Targets Mean            -12.6808
trainer/Q Targets Std               7.4629
trainer/Q Targets Max              -0.168816
trainer/Q Targets Min             -56.2699
trainer/Log Pis Mean                2.13527
trainer/Log Pis Std                 1.3046
trainer/Log Pis Max                 6.43632
trainer/Log Pis Min                -2.28296
trainer/Policy mu Mean              0.0564343
trainer/Policy mu Std               0.831453
trainer/Policy mu Max               3.31068
trainer/Policy mu Min              -2.8474
trainer/Policy log std Mean        -2.01286
trainer/Policy log std Std          0.445412
trainer/Policy log std Max         -0.441388
trainer/Policy log std Min         -2.33484
trainer/Alpha                       0.0508772
trainer/Alpha Loss                  0.402873
exploration/num steps total     20800
exploration/num paths total       208
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.329791
exploration/Rewards Std             0.907094
exploration/Rewards Max            -0.023175
exploration/Rewards Min            -6.73674
exploration/Returns Mean          -32.9791
exploration/Returns Std             6.09285
exploration/Returns Max           -26.8862
exploration/Returns Min           -39.0719
exploration/Actions Mean            0.042889
exploration/Actions Std             0.228201
exploration/Actions Max             0.999632
exploration/Actions Min            -0.365137
exploration/Num Paths               2
exploration/Average Returns       -32.9791
evaluation/num steps total     103000
evaluation/num paths total       1030
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.296396
evaluation/Rewards Std              1.16603
evaluation/Rewards Max             -0.0297809
evaluation/Rewards Min            -11.0224
evaluation/Returns Mean           -29.6396
evaluation/Returns Std             21.1295
evaluation/Returns Max             -6.56081
evaluation/Returns Min            -65.2469
evaluation/Actions Mean             0.031526
evaluation/Actions Std              0.195854
evaluation/Actions Max              0.99858
evaluation/Actions Min             -0.992323
evaluation/Num Paths               10
evaluation/Average Returns        -29.6396
time/data storing (s)               0.00121296
time/evaluation sampling (s)        0.296358
time/exploration sampling (s)       0.084738
time/logging (s)                    0.00353787
time/saving (s)                     0.00243252
time/training (s)                   1.17521
time/epoch (s)                      1.56349
time/total (s)                    149.458
Epoch                             102
-----------------------------  ---------------
2019-04-21 12:18:55.572304 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 103 finished
-----------------------------  ---------------
replay_buffer/size              21000
trainer/QF1 Loss                    4.20014
trainer/QF2 Loss                    4.25035
trainer/Policy Loss                13.2689
trainer/Q1 Predictions Mean       -11.5698
trainer/Q1 Predictions Std          5.74538
trainer/Q1 Predictions Max        -10.1969
trainer/Q1 Predictions Min        -55.0378
trainer/Q2 Predictions Mean       -11.6337
trainer/Q2 Predictions Std          5.83895
trainer/Q2 Predictions Max        -10.2508
trainer/Q2 Predictions Min        -56.0964
trainer/Q Targets Mean            -11.3013
trainer/Q Targets Std               6.2246
trainer/Q Targets Max              -0.0147347
trainer/Q Targets Min             -57.0156
trainer/Log Pis Mean                1.93168
trainer/Log Pis Std                 1.32175
trainer/Log Pis Max                 7.81918
trainer/Log Pis Min                -2.41969
trainer/Policy mu Mean              0.0178575
trainer/Policy mu Std               0.738348
trainer/Policy mu Max               3.15382
trainer/Policy mu Min              -2.51199
trainer/Policy log std Mean        -1.99319
trainer/Policy log std Std          0.475458
trainer/Policy log std Max         -0.531214
trainer/Policy log std Min         -2.3333
trainer/Alpha                       0.0498899
trainer/Alpha Loss                 -0.204816
exploration/num steps total     21000
exploration/num paths total       210
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.241411
exploration/Rewards Std             0.652197
exploration/Rewards Max            -0.00528882
exploration/Rewards Min            -5.90728
exploration/Returns Mean          -24.1411
exploration/Returns Std             7.50935
exploration/Returns Max           -16.6318
exploration/Returns Min           -31.6505
exploration/Actions Mean            0.0152088
exploration/Actions Std             0.209928
exploration/Actions Max             0.99922
exploration/Actions Min            -0.99809
exploration/Num Paths               2
exploration/Average Returns       -24.1411
evaluation/num steps total     104000
evaluation/num paths total       1040
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.306362
evaluation/Rewards Std              1.28036
evaluation/Rewards Max             -0.0116429
evaluation/Rewards Min            -10.0408
evaluation/Returns Mean           -30.6362
evaluation/Returns Std             16.3896
evaluation/Returns Max             -3.13104
evaluation/Returns Min            -53.9214
evaluation/Actions Mean             0.0354536
evaluation/Actions Std              0.217666
evaluation/Actions Max              0.997856
evaluation/Actions Min             -0.99685
evaluation/Num Paths               10
evaluation/Average Returns        -30.6362
time/data storing (s)               0.00188457
time/evaluation sampling (s)        0.314532
time/exploration sampling (s)       0.0914777
time/logging (s)                    0.0033728
time/saving (s)                     0.00244519
time/training (s)                   1.09506
time/epoch (s)                      1.50877
time/total (s)                    150.971
Epoch                             103
-----------------------------  ---------------
2019-04-21 12:18:56.937751 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 104 finished
-----------------------------  ---------------
replay_buffer/size              21200
trainer/QF1 Loss                    0.0809663
trainer/QF2 Loss                    0.0589981
trainer/Policy Loss                13.4181
trainer/Q1 Predictions Mean       -11.5912
trainer/Q1 Predictions Std          5.2887
trainer/Q1 Predictions Max        -10.0532
trainer/Q1 Predictions Min        -42.5258
trainer/Q2 Predictions Mean       -11.6462
trainer/Q2 Predictions Std          5.29208
trainer/Q2 Predictions Max        -10.106
trainer/Q2 Predictions Min        -41.9357
trainer/Q Targets Mean            -11.7229
trainer/Q Targets Std               5.13509
trainer/Q Targets Max             -10.088
trainer/Q Targets Min             -40.7583
trainer/Log Pis Mean                2.06559
trainer/Log Pis Std                 1.03749
trainer/Log Pis Max                 7.08936
trainer/Log Pis Min                -0.0203874
trainer/Policy mu Mean              0.0809093
trainer/Policy mu Std               0.667596
trainer/Policy mu Max               3.09762
trainer/Policy mu Min              -1.71581
trainer/Policy log std Mean        -2.09596
trainer/Policy log std Std          0.392242
trainer/Policy log std Max         -0.593806
trainer/Policy log std Min         -2.37549
trainer/Alpha                       0.0495489
trainer/Alpha Loss                  0.197079
exploration/num steps total     21200
exploration/num paths total       212
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.302971
exploration/Rewards Std             0.95826
exploration/Rewards Max            -0.00771314
exploration/Rewards Min            -7.93435
exploration/Returns Mean          -30.2971
exploration/Returns Std            16.691
exploration/Returns Max           -13.6061
exploration/Returns Min           -46.9881
exploration/Actions Mean            0.0347567
exploration/Actions Std             0.223159
exploration/Actions Max             0.997871
exploration/Actions Min            -0.489383
exploration/Num Paths               2
exploration/Average Returns       -30.2971
evaluation/num steps total     105000
evaluation/num paths total       1050
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.235869
evaluation/Rewards Std              1.01864
evaluation/Rewards Max             -0.037719
evaluation/Rewards Min            -10.0935
evaluation/Returns Mean           -23.5869
evaluation/Returns Std             15.9324
evaluation/Returns Max             -4.78128
evaluation/Returns Min            -56.3208
evaluation/Actions Mean             0.0233012
evaluation/Actions Std              0.196542
evaluation/Actions Max              0.997281
evaluation/Actions Min             -0.994785
evaluation/Num Paths               10
evaluation/Average Returns        -23.5869
time/data storing (s)               0.00134712
time/evaluation sampling (s)        0.26014
time/exploration sampling (s)       0.0718866
time/logging (s)                    0.00407323
time/saving (s)                     0.00272618
time/training (s)                   1.01967
time/epoch (s)                      1.35985
time/total (s)                    152.335
Epoch                             104
-----------------------------  ---------------
2019-04-21 12:18:58.292336 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 105 finished
-----------------------------  ---------------
replay_buffer/size              21400
trainer/QF1 Loss                    1.08194
trainer/QF2 Loss                    1.13582
trainer/Policy Loss                13.7859
trainer/Q1 Predictions Mean       -12.2869
trainer/Q1 Predictions Std          7.46952
trainer/Q1 Predictions Max        -10.2045
trainer/Q1 Predictions Min        -57.0313
trainer/Q2 Predictions Mean       -12.3863
trainer/Q2 Predictions Std          7.41918
trainer/Q2 Predictions Max        -10.3194
trainer/Q2 Predictions Min        -57.1554
trainer/Q Targets Mean            -12.2341
trainer/Q Targets Std               7.70755
trainer/Q Targets Max              -0.182875
trainer/Q Targets Min             -57.7874
trainer/Log Pis Mean                1.92924
trainer/Log Pis Std                 1.29665
trainer/Log Pis Max                 7.21254
trainer/Log Pis Min                -0.784037
trainer/Policy mu Mean              0.108563
trainer/Policy mu Std               0.732159
trainer/Policy mu Max               3.26109
trainer/Policy mu Min              -2.30904
trainer/Policy log std Mean        -1.99427
trainer/Policy log std Std          0.423135
trainer/Policy log std Max         -0.52446
trainer/Policy log std Min         -2.2794
trainer/Alpha                       0.0487529
trainer/Alpha Loss                 -0.213741
exploration/num steps total     21400
exploration/num paths total       214
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.659532
exploration/Rewards Std             1.79246
exploration/Rewards Max            -0.0088554
exploration/Rewards Min            -9.84737
exploration/Returns Mean          -65.9532
exploration/Returns Std             0.253208
exploration/Returns Max           -65.7
exploration/Returns Min           -66.2064
exploration/Actions Mean            0.0576488
exploration/Actions Std             0.275672
exploration/Actions Max             0.998832
exploration/Actions Min            -0.505114
exploration/Num Paths               2
exploration/Average Returns       -65.9532
evaluation/num steps total     106000
evaluation/num paths total       1060
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.180115
evaluation/Rewards Std              0.800368
evaluation/Rewards Max             -0.0214121
evaluation/Rewards Min             -7.62497
evaluation/Returns Mean           -18.0115
evaluation/Returns Std             10.8439
evaluation/Returns Max             -3.75735
evaluation/Returns Min            -36.1455
evaluation/Actions Mean             0.0260122
evaluation/Actions Std              0.179286
evaluation/Actions Max              0.996991
evaluation/Actions Min             -0.99307
evaluation/Num Paths               10
evaluation/Average Returns        -18.0115
time/data storing (s)               0.00118982
time/evaluation sampling (s)        0.255539
time/exploration sampling (s)       0.067382
time/logging (s)                    0.00437544
time/saving (s)                     0.00448126
time/training (s)                   1.0153
time/epoch (s)                      1.34827
time/total (s)                    153.688
Epoch                             105
-----------------------------  ---------------
2019-04-21 12:18:59.783677 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 106 finished
-----------------------------  ---------------
replay_buffer/size              21600
trainer/QF1 Loss                    0.0330227
trainer/QF2 Loss                    0.0290205
trainer/Policy Loss                12.9523
trainer/Q1 Predictions Mean       -11.061
trainer/Q1 Predictions Std          3.09695
trainer/Q1 Predictions Max         -9.99764
trainer/Q1 Predictions Min        -31.7539
trainer/Q2 Predictions Mean       -11.0513
trainer/Q2 Predictions Std          3.10247
trainer/Q2 Predictions Max         -9.98684
trainer/Q2 Predictions Min        -31.9249
trainer/Q Targets Mean            -11.1762
trainer/Q Targets Std               3.1395
trainer/Q Targets Max             -10.0537
trainer/Q Targets Min             -32.3998
trainer/Log Pis Mean                2.05742
trainer/Log Pis Std                 1.23894
trainer/Log Pis Max                 5.9463
trainer/Log Pis Min                -3.56623
trainer/Policy mu Mean              0.128644
trainer/Policy mu Std               0.736861
trainer/Policy mu Max               3.0717
trainer/Policy mu Min              -1.92102
trainer/Policy log std Mean        -2.09541
trainer/Policy log std Std          0.472488
trainer/Policy log std Max         -0.560295
trainer/Policy log std Min         -2.42219
trainer/Alpha                       0.0484107
trainer/Alpha Loss                  0.173858
exploration/num steps total     21600
exploration/num paths total       216
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.547488
exploration/Rewards Std             1.5831
exploration/Rewards Max            -0.0116686
exploration/Rewards Min           -10.0796
exploration/Returns Mean          -54.7488
exploration/Returns Std             8.7264
exploration/Returns Max           -46.0224
exploration/Returns Min           -63.4752
exploration/Actions Mean            0.0715496
exploration/Actions Std             0.280052
exploration/Actions Max             0.99936
exploration/Actions Min            -0.543402
exploration/Num Paths               2
exploration/Average Returns       -54.7488
evaluation/num steps total     107000
evaluation/num paths total       1070
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.366762
evaluation/Rewards Std              1.36204
evaluation/Rewards Max             -0.0276207
evaluation/Rewards Min             -9.70759
evaluation/Returns Mean           -36.6762
evaluation/Returns Std             20.7678
evaluation/Returns Max             -6.00594
evaluation/Returns Min            -57.0529
evaluation/Actions Mean             0.0349611
evaluation/Actions Std              0.203679
evaluation/Actions Max              0.997819
evaluation/Actions Min             -0.974589
evaluation/Num Paths               10
evaluation/Average Returns        -36.6762
time/data storing (s)               0.00129124
time/evaluation sampling (s)        0.302046
time/exploration sampling (s)       0.0686663
time/logging (s)                    0.00341148
time/saving (s)                     0.00225496
time/training (s)                   1.10511
time/epoch (s)                      1.48278
time/total (s)                    155.176
Epoch                             106
-----------------------------  ---------------
2019-04-21 12:19:01.234556 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 107 finished
-----------------------------  ---------------
replay_buffer/size              21800
trainer/QF1 Loss                    1.1945
trainer/QF2 Loss                    1.14158
trainer/Policy Loss                14.5533
trainer/Q1 Predictions Mean       -12.4908
trainer/Q1 Predictions Std          7.11052
trainer/Q1 Predictions Max         -9.86204
trainer/Q1 Predictions Min        -50.1826
trainer/Q2 Predictions Mean       -12.5973
trainer/Q2 Predictions Std          7.13645
trainer/Q2 Predictions Max         -9.97208
trainer/Q2 Predictions Min        -50.2962
trainer/Q Targets Mean            -12.5584
trainer/Q Targets Std               7.17594
trainer/Q Targets Max              -0.702055
trainer/Q Targets Min             -48.9719
trainer/Log Pis Mean                2.28907
trainer/Log Pis Std                 1.32117
trainer/Log Pis Max                 6.7581
trainer/Log Pis Min                -1.45441
trainer/Policy mu Mean              0.228998
trainer/Policy mu Std               0.855002
trainer/Policy mu Max               3.14383
trainer/Policy mu Min              -3.19322
trainer/Policy log std Mean        -2.04222
trainer/Policy log std Std          0.562666
trainer/Policy log std Max         -0.44375
trainer/Policy log std Min         -2.45738
trainer/Alpha                       0.0497824
trainer/Alpha Loss                  0.867279
exploration/num steps total     21800
exploration/num paths total       218
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.187829
exploration/Rewards Std             0.499851
exploration/Rewards Max            -0.00491175
exploration/Rewards Min            -5.29825
exploration/Returns Mean          -18.7829
exploration/Returns Std             6.31958
exploration/Returns Max           -12.4633
exploration/Returns Min           -25.1025
exploration/Actions Mean            0.0208954
exploration/Actions Std             0.197871
exploration/Actions Max             0.999612
exploration/Actions Min            -0.936231
exploration/Num Paths               2
exploration/Average Returns       -18.7829
evaluation/num steps total     108000
evaluation/num paths total       1080
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.231608
evaluation/Rewards Std              1.09292
evaluation/Rewards Max             -0.0204386
evaluation/Rewards Min            -10.4322
evaluation/Returns Mean           -23.1608
evaluation/Returns Std             18.7132
evaluation/Returns Max             -2.45366
evaluation/Returns Min            -52.1475
evaluation/Actions Mean             0.0197361
evaluation/Actions Std              0.193676
evaluation/Actions Max              0.996404
evaluation/Actions Min             -0.98989
evaluation/Num Paths               10
evaluation/Average Returns        -23.1608
time/data storing (s)               0.00142091
time/evaluation sampling (s)        0.253065
time/exploration sampling (s)       0.0766405
time/logging (s)                    0.00348373
time/saving (s)                     0.00249969
time/training (s)                   1.10719
time/epoch (s)                      1.4443
time/total (s)                    156.625
Epoch                             107
-----------------------------  ---------------
2019-04-21 12:19:03.335571 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 108 finished
-----------------------------  ---------------
replay_buffer/size              22000
trainer/QF1 Loss                    1.0376
trainer/QF2 Loss                    1.0294
trainer/Policy Loss                12.6074
trainer/Q1 Predictions Mean       -10.6986
trainer/Q1 Predictions Std          3.57068
trainer/Q1 Predictions Max         -9.63437
trainer/Q1 Predictions Min        -35.6829
trainer/Q2 Predictions Mean       -10.7159
trainer/Q2 Predictions Std          3.54032
trainer/Q2 Predictions Max         -9.65913
trainer/Q2 Predictions Min        -35.4466
trainer/Q Targets Mean            -10.8625
trainer/Q Targets Std               3.60391
trainer/Q Targets Max              -0.355934
trainer/Q Targets Min             -35.3024
trainer/Log Pis Mean                2.14482
trainer/Log Pis Std                 1.03477
trainer/Log Pis Max                 5.15844
trainer/Log Pis Min                -1.21834
trainer/Policy mu Mean              0.0966312
trainer/Policy mu Std               0.627274
trainer/Policy mu Max               3.15031
trainer/Policy mu Min              -2.62124
trainer/Policy log std Mean        -2.14649
trainer/Policy log std Std          0.411753
trainer/Policy log std Max         -0.486517
trainer/Policy log std Min         -2.4172
trainer/Alpha                       0.0509875
trainer/Alpha Loss                  0.431026
exploration/num steps total     22000
exploration/num paths total       220
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.262495
exploration/Rewards Std             0.823325
exploration/Rewards Max            -0.0049449
exploration/Rewards Min            -7.54127
exploration/Returns Mean          -26.2495
exploration/Returns Std            12.1995
exploration/Returns Max           -14.0501
exploration/Returns Min           -38.449
exploration/Actions Mean            0.00891557
exploration/Actions Std             0.223021
exploration/Actions Max             0.995736
exploration/Actions Min            -0.99086
exploration/Num Paths               2
exploration/Average Returns       -26.2495
evaluation/num steps total     109000
evaluation/num paths total       1090
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.259855
evaluation/Rewards Std              1.02494
evaluation/Rewards Max             -0.0480108
evaluation/Rewards Min             -9.83383
evaluation/Returns Mean           -25.9855
evaluation/Returns Std             17.1068
evaluation/Returns Max             -5.87138
evaluation/Returns Min            -58.7045
evaluation/Actions Mean             0.0194859
evaluation/Actions Std              0.196964
evaluation/Actions Max              0.997337
evaluation/Actions Min             -0.997113
evaluation/Num Paths               10
evaluation/Average Returns        -25.9855
time/data storing (s)               0.00124809
time/evaluation sampling (s)        0.329239
time/exploration sampling (s)       0.0795252
time/logging (s)                    0.0043778
time/saving (s)                     0.00311303
time/training (s)                   1.67774
time/epoch (s)                      2.09525
time/total (s)                    158.725
Epoch                             108
-----------------------------  ---------------
2019-04-21 12:19:04.904691 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 109 finished
-----------------------------  ---------------
replay_buffer/size              22200
trainer/QF1 Loss                    1.97249
trainer/QF2 Loss                    2.04158
trainer/Policy Loss                12.6176
trainer/Q1 Predictions Mean       -11.0635
trainer/Q1 Predictions Std          4.70099
trainer/Q1 Predictions Max         -9.8074
trainer/Q1 Predictions Min        -48.5181
trainer/Q2 Predictions Mean       -11.0866
trainer/Q2 Predictions Std          4.55904
trainer/Q2 Predictions Max         -9.86415
trainer/Q2 Predictions Min        -47.2491
trainer/Q Targets Mean            -10.9706
trainer/Q Targets Std               5.03353
trainer/Q Targets Max              -0.158362
trainer/Q Targets Min             -49.3437
trainer/Log Pis Mean                1.75555
trainer/Log Pis Std                 1.10811
trainer/Log Pis Max                 5.84846
trainer/Log Pis Min                -0.636894
trainer/Policy mu Mean              0.0236779
trainer/Policy mu Std               0.582958
trainer/Policy mu Max               2.92283
trainer/Policy mu Min              -1.78912
trainer/Policy log std Mean        -2.06174
trainer/Policy log std Std          0.370177
trainer/Policy log std Max         -0.509317
trainer/Policy log std Min         -2.30216
trainer/Alpha                       0.0512478
trainer/Alpha Loss                 -0.726278
exploration/num steps total     22200
exploration/num paths total       222
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.258504
exploration/Rewards Std             0.609461
exploration/Rewards Max            -0.0139746
exploration/Rewards Min            -4.77863
exploration/Returns Mean          -25.8504
exploration/Returns Std             0.684129
exploration/Returns Max           -25.1663
exploration/Returns Min           -26.5345
exploration/Actions Mean            0.0307471
exploration/Actions Std             0.237732
exploration/Actions Max             0.995346
exploration/Actions Min            -0.615539
exploration/Num Paths               2
exploration/Average Returns       -25.8504
evaluation/num steps total     110000
evaluation/num paths total       1100
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.183853
evaluation/Rewards Std              0.851859
evaluation/Rewards Max             -0.0423257
evaluation/Rewards Min            -10.4299
evaluation/Returns Mean           -18.3853
evaluation/Returns Std             16.2087
evaluation/Returns Max             -5.17069
evaluation/Returns Min            -56.8871
evaluation/Actions Mean             0.0136805
evaluation/Actions Std              0.17432
evaluation/Actions Max              0.995697
evaluation/Actions Min             -0.989365
evaluation/Num Paths               10
evaluation/Average Returns        -18.3853
time/data storing (s)               0.00137699
time/evaluation sampling (s)        0.317496
time/exploration sampling (s)       0.0959595
time/logging (s)                    0.00386635
time/saving (s)                     0.00269582
time/training (s)                   1.14006
time/epoch (s)                      1.56145
time/total (s)                    160.291
Epoch                             109
-----------------------------  ---------------
2019-04-21 12:19:06.393457 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 110 finished
-----------------------------  ---------------
replay_buffer/size              22400
trainer/QF1 Loss                    0.108315
trainer/QF2 Loss                    0.161895
trainer/Policy Loss                12.7543
trainer/Q1 Predictions Mean       -11.5085
trainer/Q1 Predictions Std          5.94527
trainer/Q1 Predictions Max         -9.72879
trainer/Q1 Predictions Min        -48.4088
trainer/Q2 Predictions Mean       -11.4608
trainer/Q2 Predictions Std          6.0005
trainer/Q2 Predictions Max         -9.67957
trainer/Q2 Predictions Min        -49.03
trainer/Q Targets Mean            -11.6407
trainer/Q Targets Std               5.98442
trainer/Q Targets Max              -9.79348
trainer/Q Targets Min             -49.5059
trainer/Log Pis Mean                1.73886
trainer/Log Pis Std                 1.24446
trainer/Log Pis Max                 6.26155
trainer/Log Pis Min                -2.52022
trainer/Policy mu Mean             -0.0385453
trainer/Policy mu Std               0.677521
trainer/Policy mu Max               3.50185
trainer/Policy mu Min              -3.19342
trainer/Policy log std Mean        -2.0686
trainer/Policy log std Std          0.422676
trainer/Policy log std Max         -0.437293
trainer/Policy log std Min         -2.37601
trainer/Alpha                       0.0504902
trainer/Alpha Loss                 -0.779755
exploration/num steps total     22400
exploration/num paths total       224
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.439997
exploration/Rewards Std             1.41466
exploration/Rewards Max            -0.0176567
exploration/Rewards Min           -10.6317
exploration/Returns Mean          -43.9997
exploration/Returns Std            27.4902
exploration/Returns Max           -16.5095
exploration/Returns Min           -71.4899
exploration/Actions Mean            0.0231212
exploration/Actions Std             0.2402
exploration/Actions Max             0.998058
exploration/Actions Min            -0.749964
exploration/Num Paths               2
exploration/Average Returns       -43.9997
evaluation/num steps total     111000
evaluation/num paths total       1110
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.17139
evaluation/Rewards Std              0.721845
evaluation/Rewards Max             -0.0388253
evaluation/Rewards Min             -9.24897
evaluation/Returns Mean           -17.139
evaluation/Returns Std             13.7461
evaluation/Returns Max             -6.41659
evaluation/Returns Min            -48.7543
evaluation/Actions Mean             0.012735
evaluation/Actions Std              0.152862
evaluation/Actions Max              0.995198
evaluation/Actions Min             -0.992419
evaluation/Num Paths               10
evaluation/Average Returns        -17.139
time/data storing (s)               0.00119008
time/evaluation sampling (s)        0.274501
time/exploration sampling (s)       0.0695747
time/logging (s)                    0.00946738
time/saving (s)                     0.0030987
time/training (s)                   1.12967
time/epoch (s)                      1.4875
time/total (s)                    161.783
Epoch                             110
-----------------------------  ---------------
2019-04-21 12:19:07.770098 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 111 finished
-----------------------------  ---------------
replay_buffer/size              22600
trainer/QF1 Loss                    1.02706
trainer/QF2 Loss                    0.961474
trainer/Policy Loss                12.9795
trainer/Q1 Predictions Mean       -11.1286
trainer/Q1 Predictions Std          6.24639
trainer/Q1 Predictions Max         -9.68183
trainer/Q1 Predictions Min        -54.7739
trainer/Q2 Predictions Mean       -11.0997
trainer/Q2 Predictions Std          6.42483
trainer/Q2 Predictions Max         -9.62468
trainer/Q2 Predictions Min        -56.8184
trainer/Q Targets Mean            -11.1514
trainer/Q Targets Std               6.54006
trainer/Q Targets Max              -0.226498
trainer/Q Targets Min             -57.6959
trainer/Log Pis Mean                2.06251
trainer/Log Pis Std                 1.09718
trainer/Log Pis Max                 6.27689
trainer/Log Pis Min                -1.46753
trainer/Policy mu Mean              0.101371
trainer/Policy mu Std               0.601192
trainer/Policy mu Max               3.20069
trainer/Policy mu Min              -1.88189
trainer/Policy log std Mean        -2.2006
trainer/Policy log std Std          0.386839
trainer/Policy log std Max         -0.592724
trainer/Policy log std Min         -2.41151
trainer/Alpha                       0.0503155
trainer/Alpha Loss                  0.186881
exploration/num steps total     22600
exploration/num paths total       226
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.161099
exploration/Rewards Std             0.262074
exploration/Rewards Max            -0.00981596
exploration/Rewards Min            -2.61078
exploration/Returns Mean          -16.1099
exploration/Returns Std             1.73444
exploration/Returns Max           -14.3755
exploration/Returns Min           -17.8443
exploration/Actions Mean            0.018547
exploration/Actions Std             0.184211
exploration/Actions Max             0.988444
exploration/Actions Min            -0.835986
exploration/Num Paths               2
exploration/Average Returns       -16.1099
evaluation/num steps total     112000
evaluation/num paths total       1120
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.205705
evaluation/Rewards Std              0.896858
evaluation/Rewards Max             -0.0197234
evaluation/Rewards Min             -9.17109
evaluation/Returns Mean           -20.5705
evaluation/Returns Std             17.1835
evaluation/Returns Max             -5.07817
evaluation/Returns Min            -50.2506
evaluation/Actions Mean             0.019855
evaluation/Actions Std              0.159272
evaluation/Actions Max              0.996318
evaluation/Actions Min             -0.971996
evaluation/Num Paths               10
evaluation/Average Returns        -20.5705
time/data storing (s)               0.00115536
time/evaluation sampling (s)        0.251462
time/exploration sampling (s)       0.0709676
time/logging (s)                    0.00359526
time/saving (s)                     0.00288872
time/training (s)                   1.03276
time/epoch (s)                      1.36283
time/total (s)                    163.151
Epoch                             111
-----------------------------  ---------------
2019-04-21 12:19:09.133524 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 112 finished
-----------------------------  ---------------
replay_buffer/size              22800
trainer/QF1 Loss                    0.21449
trainer/QF2 Loss                    0.174025
trainer/Policy Loss                12.1172
trainer/Q1 Predictions Mean       -10.2832
trainer/Q1 Predictions Std          3.02173
trainer/Q1 Predictions Max         -9.40462
trainer/Q1 Predictions Min        -30.1888
trainer/Q2 Predictions Mean       -10.3013
trainer/Q2 Predictions Std          3.04075
trainer/Q2 Predictions Max         -9.41844
trainer/Q2 Predictions Min        -30.4016
trainer/Q Targets Mean            -10.6124
trainer/Q Targets Std               3.18877
trainer/Q Targets Max              -9.62171
trainer/Q Targets Min             -31.0052
trainer/Log Pis Mean                2.08765
trainer/Log Pis Std                 1.01297
trainer/Log Pis Max                 6.1141
trainer/Log Pis Min                -1.74982
trainer/Policy mu Mean              0.0492779
trainer/Policy mu Std               0.570315
trainer/Policy mu Max               2.97082
trainer/Policy mu Min              -1.74903
trainer/Policy log std Mean        -2.20737
trainer/Policy log std Std          0.366355
trainer/Policy log std Max         -0.672436
trainer/Policy log std Min         -2.42051
trainer/Alpha                       0.0514526
trainer/Alpha Loss                  0.260065
exploration/num steps total     22800
exploration/num paths total       228
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.190448
exploration/Rewards Std             0.470183
exploration/Rewards Max            -0.00473871
exploration/Rewards Min            -4.64284
exploration/Returns Mean          -19.0448
exploration/Returns Std             2.50758
exploration/Returns Max           -16.5372
exploration/Returns Min           -21.5524
exploration/Actions Mean            0.00504662
exploration/Actions Std             0.201649
exploration/Actions Max             0.997314
exploration/Actions Min            -0.998683
exploration/Num Paths               2
exploration/Average Returns       -19.0448
evaluation/num steps total     113000
evaluation/num paths total       1130
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.150139
evaluation/Rewards Std              0.737426
evaluation/Rewards Max             -0.0289529
evaluation/Rewards Min             -9.95181
evaluation/Returns Mean           -15.0139
evaluation/Returns Std             13.8297
evaluation/Returns Max             -4.29734
evaluation/Returns Min            -52.079
evaluation/Actions Mean             0.0206343
evaluation/Actions Std              0.164329
evaluation/Actions Max              0.997188
evaluation/Actions Min             -0.989021
evaluation/Num Paths               10
evaluation/Average Returns        -15.0139
time/data storing (s)               0.0011502
time/evaluation sampling (s)        0.248643
time/exploration sampling (s)       0.0679865
time/logging (s)                    0.00367125
time/saving (s)                     0.00251223
time/training (s)                   1.0324
time/epoch (s)                      1.35637
time/total (s)                    164.512
Epoch                             112
-----------------------------  ---------------
2019-04-21 12:19:10.516249 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 113 finished
-----------------------------  ---------------
replay_buffer/size              23000
trainer/QF1 Loss                    0.218537
trainer/QF2 Loss                    0.1876
trainer/Policy Loss                13.0728
trainer/Q1 Predictions Mean       -11.218
trainer/Q1 Predictions Std          7.88369
trainer/Q1 Predictions Max         -9.44218
trainer/Q1 Predictions Min        -79.8526
trainer/Q2 Predictions Mean       -11.2359
trainer/Q2 Predictions Std          7.88319
trainer/Q2 Predictions Max         -9.45886
trainer/Q2 Predictions Min        -79.6745
trainer/Q Targets Mean            -11.4067
trainer/Q Targets Std               7.58772
trainer/Q Targets Max              -9.53567
trainer/Q Targets Min             -76.1472
trainer/Log Pis Mean                2.20965
trainer/Log Pis Std                 0.93538
trainer/Log Pis Max                 5.32274
trainer/Log Pis Min                -1.17548
trainer/Policy mu Mean              0.0644677
trainer/Policy mu Std               0.698978
trainer/Policy mu Max               3.04534
trainer/Policy mu Min              -3.08742
trainer/Policy log std Mean        -2.07996
trainer/Policy log std Std          0.455219
trainer/Policy log std Max         -0.473818
trainer/Policy log std Min         -2.36138
trainer/Alpha                       0.0517548
trainer/Alpha Loss                  0.620825
exploration/num steps total     23000
exploration/num paths total       230
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.292228
exploration/Rewards Std             0.810024
exploration/Rewards Max            -0.0123762
exploration/Rewards Min            -6.2889
exploration/Returns Mean          -29.2228
exploration/Returns Std             5.71068
exploration/Returns Max           -23.5122
exploration/Returns Min           -34.9335
exploration/Actions Mean            0.030985
exploration/Actions Std             0.224233
exploration/Actions Max             0.999543
exploration/Actions Min            -0.753277
exploration/Num Paths               2
exploration/Average Returns       -29.2228
evaluation/num steps total     114000
evaluation/num paths total       1140
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.228864
evaluation/Rewards Std              1.09919
evaluation/Rewards Max             -0.0133722
evaluation/Rewards Min             -9.8852
evaluation/Returns Mean           -22.8864
evaluation/Returns Std             19.6743
evaluation/Returns Max             -1.81967
evaluation/Returns Min            -48.0241
evaluation/Actions Mean             0.0220958
evaluation/Actions Std              0.18165
evaluation/Actions Max              0.996309
evaluation/Actions Min             -0.977566
evaluation/Num Paths               10
evaluation/Average Returns        -22.8864
time/data storing (s)               0.00137044
time/evaluation sampling (s)        0.255696
time/exploration sampling (s)       0.0662612
time/logging (s)                    0.00409341
time/saving (s)                     0.00285129
time/training (s)                   1.04598
time/epoch (s)                      1.37625
time/total (s)                    165.893
Epoch                             113
-----------------------------  ---------------
2019-04-21 12:19:11.913957 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 114 finished
-----------------------------  ---------------
replay_buffer/size              23200
trainer/QF1 Loss                    0.0656357
trainer/QF2 Loss                    0.0422543
trainer/Policy Loss                12.3354
trainer/Q1 Predictions Mean       -10.5326
trainer/Q1 Predictions Std          3.75751
trainer/Q1 Predictions Max         -9.39747
trainer/Q1 Predictions Min        -39.6166
trainer/Q2 Predictions Mean       -10.5839
trainer/Q2 Predictions Std          3.72051
trainer/Q2 Predictions Max         -9.48923
trainer/Q2 Predictions Min        -39.5231
trainer/Q Targets Mean            -10.7219
trainer/Q Targets Std               3.67857
trainer/Q Targets Max              -9.50443
trainer/Q Targets Min             -39.1228
trainer/Log Pis Mean                1.98624
trainer/Log Pis Std                 1.20639
trainer/Log Pis Max                 5.03878
trainer/Log Pis Min                -2.24437
trainer/Policy mu Mean              0.0875734
trainer/Policy mu Std               0.674726
trainer/Policy mu Max               3.14331
trainer/Policy mu Min              -1.69231
trainer/Policy log std Mean        -2.08321
trainer/Policy log std Std          0.438246
trainer/Policy log std Max         -0.397946
trainer/Policy log std Min         -2.34151
trainer/Alpha                       0.0508953
trainer/Alpha Loss                 -0.0409824
exploration/num steps total     23200
exploration/num paths total       232
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.469021
exploration/Rewards Std             1.36641
exploration/Rewards Max            -0.00819752
exploration/Rewards Min            -9.58302
exploration/Returns Mean          -46.9021
exploration/Returns Std            15.8586
exploration/Returns Max           -31.0435
exploration/Returns Min           -62.7607
exploration/Actions Mean            0.0573528
exploration/Actions Std             0.260385
exploration/Actions Max             0.999292
exploration/Actions Min            -0.440593
exploration/Num Paths               2
exploration/Average Returns       -46.9021
evaluation/num steps total     115000
evaluation/num paths total       1150
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.214942
evaluation/Rewards Std              0.926342
evaluation/Rewards Max             -0.0185471
evaluation/Rewards Min             -8.97143
evaluation/Returns Mean           -21.4942
evaluation/Returns Std             12.1315
evaluation/Returns Max             -4.33364
evaluation/Returns Min            -45.5044
evaluation/Actions Mean             0.0321806
evaluation/Actions Std              0.188715
evaluation/Actions Max              0.996903
evaluation/Actions Min             -0.996953
evaluation/Num Paths               10
evaluation/Average Returns        -21.4942
time/data storing (s)               0.00124767
time/evaluation sampling (s)        0.270998
time/exploration sampling (s)       0.069332
time/logging (s)                    0.00351058
time/saving (s)                     0.00261944
time/training (s)                   1.04256
time/epoch (s)                      1.39027
time/total (s)                    167.288
Epoch                             114
-----------------------------  ---------------
2019-04-21 12:19:13.670300 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 115 finished
-----------------------------  ---------------
replay_buffer/size              23400
trainer/QF1 Loss                    1.82975
trainer/QF2 Loss                    1.79758
trainer/Policy Loss                13.2015
trainer/Q1 Predictions Mean       -11.6728
trainer/Q1 Predictions Std          6.89292
trainer/Q1 Predictions Max         -9.47984
trainer/Q1 Predictions Min        -52.5374
trainer/Q2 Predictions Mean       -11.6629
trainer/Q2 Predictions Std          6.96908
trainer/Q2 Predictions Max         -9.44818
trainer/Q2 Predictions Min        -52.5793
trainer/Q Targets Mean            -11.5909
trainer/Q Targets Std               7.14738
trainer/Q Targets Max              -0.157764
trainer/Q Targets Min             -52.7949
trainer/Log Pis Mean                1.91725
trainer/Log Pis Std                 1.21497
trainer/Log Pis Max                 6.06096
trainer/Log Pis Min                -1.64099
trainer/Policy mu Mean              0.0666514
trainer/Policy mu Std               0.744626
trainer/Policy mu Max               3.20481
trainer/Policy mu Min              -3.15819
trainer/Policy log std Mean        -2.03837
trainer/Policy log std Std          0.433699
trainer/Policy log std Max         -0.379507
trainer/Policy log std Min         -2.33246
trainer/Alpha                       0.0511128
trainer/Alpha Loss                 -0.246074
exploration/num steps total     23400
exploration/num paths total       234
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.602436
exploration/Rewards Std             1.73906
exploration/Rewards Max            -0.0138528
exploration/Rewards Min           -10.644
exploration/Returns Mean          -60.2436
exploration/Returns Std             8.82056
exploration/Returns Max           -51.4231
exploration/Returns Min           -69.0642
exploration/Actions Mean            0.0233444
exploration/Actions Std             0.291305
exploration/Actions Max             0.99927
exploration/Actions Min            -0.973917
exploration/Num Paths               2
exploration/Average Returns       -60.2436
evaluation/num steps total     116000
evaluation/num paths total       1160
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.182411
evaluation/Rewards Std              0.847471
evaluation/Rewards Max             -0.0270953
evaluation/Rewards Min             -9.11521
evaluation/Returns Mean           -18.2411
evaluation/Returns Std             13.9253
evaluation/Returns Max             -3.3247
evaluation/Returns Min            -44.5389
evaluation/Actions Mean             0.0192017
evaluation/Actions Std              0.176362
evaluation/Actions Max              0.99632
evaluation/Actions Min             -0.995952
evaluation/Num Paths               10
evaluation/Average Returns        -18.2411
time/data storing (s)               0.00164856
time/evaluation sampling (s)        0.281278
time/exploration sampling (s)       0.10185
time/logging (s)                    0.00515644
time/saving (s)                     0.00357294
time/training (s)                   1.35767
time/epoch (s)                      1.75117
time/total (s)                    169.044
Epoch                             115
-----------------------------  ---------------
2019-04-21 12:19:15.562379 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 116 finished
-----------------------------  ---------------
replay_buffer/size              23600
trainer/QF1 Loss                    0.94419
trainer/QF2 Loss                    0.940222
trainer/Policy Loss                12.545
trainer/Q1 Predictions Mean       -10.7059
trainer/Q1 Predictions Std          4.30729
trainer/Q1 Predictions Max         -9.55843
trainer/Q1 Predictions Min        -38.1281
trainer/Q2 Predictions Mean       -10.6892
trainer/Q2 Predictions Std          4.36666
trainer/Q2 Predictions Max         -9.54154
trainer/Q2 Predictions Min        -38.704
trainer/Q Targets Mean            -10.5389
trainer/Q Targets Std               4.45368
trainer/Q Targets Max              -0.244168
trainer/Q Targets Min             -38.007
trainer/Log Pis Mean                2.18119
trainer/Log Pis Std                 1.14196
trainer/Log Pis Max                 6.43792
trainer/Log Pis Min                -1.37964
trainer/Policy mu Mean              0.10048
trainer/Policy mu Std               0.609865
trainer/Policy mu Max               3.13238
trainer/Policy mu Min              -2.45293
trainer/Policy log std Mean        -2.19869
trainer/Policy log std Std          0.398017
trainer/Policy log std Max         -0.401948
trainer/Policy log std Min         -2.40033
trainer/Alpha                       0.0515405
trainer/Alpha Loss                  0.537309
exploration/num steps total     23600
exploration/num paths total       236
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.202156
exploration/Rewards Std             0.40805
exploration/Rewards Max            -0.0102009
exploration/Rewards Min            -4.13963
exploration/Returns Mean          -20.2156
exploration/Returns Std             2.29019
exploration/Returns Max           -17.9254
exploration/Returns Min           -22.5058
exploration/Actions Mean            0.0122877
exploration/Actions Std             0.208586
exploration/Actions Max             0.984956
exploration/Actions Min            -0.988877
exploration/Num Paths               2
exploration/Average Returns       -20.2156
evaluation/num steps total     117000
evaluation/num paths total       1170
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.288888
evaluation/Rewards Std              1.00373
evaluation/Rewards Max             -0.00730581
evaluation/Rewards Min            -10.2987
evaluation/Returns Mean           -28.8888
evaluation/Returns Std             14.7089
evaluation/Returns Max            -10.3498
evaluation/Returns Min            -63.5383
evaluation/Actions Mean             0.0279922
evaluation/Actions Std              0.195842
evaluation/Actions Max              0.99808
evaluation/Actions Min             -0.990927
evaluation/Num Paths               10
evaluation/Average Returns        -28.8888
time/data storing (s)               0.00163551
time/evaluation sampling (s)        0.303727
time/exploration sampling (s)       0.164422
time/logging (s)                    0.00344967
time/saving (s)                     0.00241007
time/training (s)                   1.4062
time/epoch (s)                      1.88184
time/total (s)                    170.93
Epoch                             116
-----------------------------  ---------------
2019-04-21 12:19:17.088075 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 117 finished
-----------------------------  ---------------
replay_buffer/size              23800
trainer/QF1 Loss                    0.0585214
trainer/QF2 Loss                    0.058914
trainer/Policy Loss                12.2115
trainer/Q1 Predictions Mean       -10.9669
trainer/Q1 Predictions Std          5.11691
trainer/Q1 Predictions Max         -9.48455
trainer/Q1 Predictions Min        -50.7828
trainer/Q2 Predictions Mean       -10.9017
trainer/Q2 Predictions Std          5.17251
trainer/Q2 Predictions Max         -9.40829
trainer/Q2 Predictions Min        -50.9258
trainer/Q Targets Mean            -10.9376
trainer/Q Targets Std               5.27016
trainer/Q Targets Max              -9.35886
trainer/Q Targets Min             -52.2152
trainer/Log Pis Mean                1.70243
trainer/Log Pis Std                 1.52607
trainer/Log Pis Max                 4.88712
trainer/Log Pis Min                -3.1741
trainer/Policy mu Mean              0.145883
trainer/Policy mu Std               0.722521
trainer/Policy mu Max               3.39578
trainer/Policy mu Min              -2.20317
trainer/Policy log std Mean        -2.04701
trainer/Policy log std Std          0.487463
trainer/Policy log std Max         -0.457385
trainer/Policy log std Min         -2.35026
trainer/Alpha                       0.052422
trainer/Alpha Loss                 -0.877336
exploration/num steps total     23800
exploration/num paths total       238
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.151754
exploration/Rewards Std             0.11525
exploration/Rewards Max            -0.00884388
exploration/Rewards Min            -1.40101
exploration/Returns Mean          -15.1754
exploration/Returns Std             1.16674
exploration/Returns Max           -14.0087
exploration/Returns Min           -16.3422
exploration/Actions Mean            0.00590505
exploration/Actions Std             0.169391
exploration/Actions Max             0.978951
exploration/Actions Min            -0.723912
exploration/Num Paths               2
exploration/Average Returns       -15.1754
evaluation/num steps total     118000
evaluation/num paths total       1180
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.226716
evaluation/Rewards Std              0.783363
evaluation/Rewards Max             -0.0453406
evaluation/Rewards Min             -7.79192
evaluation/Returns Mean           -22.6716
evaluation/Returns Std              8.60002
evaluation/Returns Max             -8.66041
evaluation/Returns Min            -40.5771
evaluation/Actions Mean             0.0179411
evaluation/Actions Std              0.181873
evaluation/Actions Max              0.998174
evaluation/Actions Min             -0.995839
evaluation/Num Paths               10
evaluation/Average Returns        -22.6716
time/data storing (s)               0.00124546
time/evaluation sampling (s)        0.286993
time/exploration sampling (s)       0.0827769
time/logging (s)                    0.00586273
time/saving (s)                     0.00292446
time/training (s)                   1.14167
time/epoch (s)                      1.52147
time/total (s)                    172.457
Epoch                             117
-----------------------------  ---------------
2019-04-21 12:19:18.777461 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 118 finished
-----------------------------  ---------------
replay_buffer/size              24000
trainer/QF1 Loss                    0.102201
trainer/QF2 Loss                    0.133972
trainer/Policy Loss                12.7177
trainer/Q1 Predictions Mean       -11.0547
trainer/Q1 Predictions Std          6.78869
trainer/Q1 Predictions Max         -9.27801
trainer/Q1 Predictions Min        -65.819
trainer/Q2 Predictions Mean       -10.994
trainer/Q2 Predictions Std          6.77735
trainer/Q2 Predictions Max         -9.23277
trainer/Q2 Predictions Min        -65.2944
trainer/Q Targets Mean            -11.1369
trainer/Q Targets Std               6.89748
trainer/Q Targets Max              -9.29977
trainer/Q Targets Min             -67.9362
trainer/Log Pis Mean                2.0021
trainer/Log Pis Std                 1.13446
trainer/Log Pis Max                 6.39558
trainer/Log Pis Min                -1.4827
trainer/Policy mu Mean              0.147981
trainer/Policy mu Std               0.742623
trainer/Policy mu Max               3.43633
trainer/Policy mu Min              -3.15208
trainer/Policy log std Mean        -2.0803
trainer/Policy log std Std          0.494439
trainer/Policy log std Max         -0.431449
trainer/Policy log std Min         -2.42943
trainer/Alpha                       0.0528919
trainer/Alpha Loss                  0.00616489
exploration/num steps total     24000
exploration/num paths total       240
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.256113
exploration/Rewards Std             0.722271
exploration/Rewards Max            -0.00846229
exploration/Rewards Min            -6.534
exploration/Returns Mean          -25.6113
exploration/Returns Std             6.25484
exploration/Returns Max           -19.3564
exploration/Returns Min           -31.8661
exploration/Actions Mean            0.0144946
exploration/Actions Std             0.225551
exploration/Actions Max             0.998824
exploration/Actions Min            -0.978508
exploration/Num Paths               2
exploration/Average Returns       -25.6113
evaluation/num steps total     119000
evaluation/num paths total       1190
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.174319
evaluation/Rewards Std              0.759825
evaluation/Rewards Max             -0.0406695
evaluation/Rewards Min            -10.1337
evaluation/Returns Mean           -17.4319
evaluation/Returns Std             15.03
evaluation/Returns Max             -7.60872
evaluation/Returns Min            -59.928
evaluation/Actions Mean             0.0215214
evaluation/Actions Std              0.170796
evaluation/Actions Max              0.996976
evaluation/Actions Min             -0.986694
evaluation/Num Paths               10
evaluation/Average Returns        -17.4319
time/data storing (s)               0.00119354
time/evaluation sampling (s)        0.32318
time/exploration sampling (s)       0.0743802
time/logging (s)                    0.00338786
time/saving (s)                     0.00235449
time/training (s)                   1.27285
time/epoch (s)                      1.67735
time/total (s)                    174.14
Epoch                             118
-----------------------------  ---------------
2019-04-21 12:19:20.127407 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 119 finished
-----------------------------  ---------------
replay_buffer/size              24200
trainer/QF1 Loss                    1.70358
trainer/QF2 Loss                    1.72429
trainer/Policy Loss                11.6224
trainer/Q1 Predictions Mean        -9.91754
trainer/Q1 Predictions Std          2.95939
trainer/Q1 Predictions Max         -9.10052
trainer/Q1 Predictions Min        -32.7222
trainer/Q2 Predictions Mean        -9.9003
trainer/Q2 Predictions Std          3.00138
trainer/Q2 Predictions Max         -9.09892
trainer/Q2 Predictions Min        -33.0874
trainer/Q Targets Mean             -9.96837
trainer/Q Targets Std               3.24914
trainer/Q Targets Max              -0.114602
trainer/Q Targets Min             -32.4261
trainer/Log Pis Mean                1.90504
trainer/Log Pis Std                 1.30673
trainer/Log Pis Max                 7.29812
trainer/Log Pis Min                -2.28258
trainer/Policy mu Mean              0.0856937
trainer/Policy mu Std               0.594716
trainer/Policy mu Max               3.32806
trainer/Policy mu Min              -2.0225
trainer/Policy log std Mean        -2.12612
trainer/Policy log std Std          0.380871
trainer/Policy log std Max         -0.421587
trainer/Policy log std Min         -2.338
trainer/Alpha                       0.0517083
trainer/Alpha Loss                 -0.281283
exploration/num steps total     24200
exploration/num paths total       242
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.149119
exploration/Rewards Std             0.194766
exploration/Rewards Max            -0.00739887
exploration/Rewards Min            -2.01168
exploration/Returns Mean          -14.9119
exploration/Returns Std             0.668043
exploration/Returns Max           -14.2438
exploration/Returns Min           -15.5799
exploration/Actions Mean            0.00298996
exploration/Actions Std             0.182355
exploration/Actions Max             0.98816
exploration/Actions Min            -0.959097
exploration/Num Paths               2
exploration/Average Returns       -14.9119
evaluation/num steps total     120000
evaluation/num paths total       1200
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.207514
evaluation/Rewards Std              1.06365
evaluation/Rewards Max             -0.0125795
evaluation/Rewards Min            -10.567
evaluation/Returns Mean           -20.7514
evaluation/Returns Std             19.6992
evaluation/Returns Max             -1.64594
evaluation/Returns Min            -55.0674
evaluation/Actions Mean             0.0247806
evaluation/Actions Std              0.182913
evaluation/Actions Max              0.997881
evaluation/Actions Min             -0.991702
evaluation/Num Paths               10
evaluation/Average Returns        -20.7514
time/data storing (s)               0.00114286
time/evaluation sampling (s)        0.269454
time/exploration sampling (s)       0.0663677
time/logging (s)                    0.00375691
time/saving (s)                     0.00243885
time/training (s)                   1.00061
time/epoch (s)                      1.34377
time/total (s)                    175.488
Epoch                             119
-----------------------------  ---------------
2019-04-21 12:19:21.534163 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 120 finished
-----------------------------  ---------------
replay_buffer/size              24400
trainer/QF1 Loss                    0.884952
trainer/QF2 Loss                    0.900198
trainer/Policy Loss                12.6038
trainer/Q1 Predictions Mean       -11.1225
trainer/Q1 Predictions Std          7.3434
trainer/Q1 Predictions Max         -9.22162
trainer/Q1 Predictions Min        -76.1079
trainer/Q2 Predictions Mean       -11.108
trainer/Q2 Predictions Std          7.35625
trainer/Q2 Predictions Max         -9.2271
trainer/Q2 Predictions Min        -76.4869
trainer/Q Targets Mean            -11.0596
trainer/Q Targets Std               7.36115
trainer/Q Targets Max              -0.0895981
trainer/Q Targets Min             -75.627
trainer/Log Pis Mean                1.94722
trainer/Log Pis Std                 1.51923
trainer/Log Pis Max                 5.62186
trainer/Log Pis Min                -3.12961
trainer/Policy mu Mean              0.10331
trainer/Policy mu Std               0.722049
trainer/Policy mu Max               3.17009
trainer/Policy mu Min              -2.54232
trainer/Policy log std Mean        -2.09836
trainer/Policy log std Std          0.483557
trainer/Policy log std Max         -0.491375
trainer/Policy log std Min         -2.38605
trainer/Alpha                       0.0512083
trainer/Alpha Loss                 -0.156862
exploration/num steps total     24400
exploration/num paths total       244
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.271828
exploration/Rewards Std             0.739382
exploration/Rewards Max            -0.0115329
exploration/Rewards Min            -5.96082
exploration/Returns Mean          -27.1828
exploration/Returns Std             3.00468
exploration/Returns Max           -24.1781
exploration/Returns Min           -30.1875
exploration/Actions Mean            0.0111655
exploration/Actions Std             0.232635
exploration/Actions Max             0.997445
exploration/Actions Min            -0.998081
exploration/Num Paths               2
exploration/Average Returns       -27.1828
evaluation/num steps total     121000
evaluation/num paths total       1210
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.233215
evaluation/Rewards Std              1.07894
evaluation/Rewards Max             -0.0110946
evaluation/Rewards Min            -11.104
evaluation/Returns Mean           -23.3215
evaluation/Returns Std             18.2553
evaluation/Returns Max             -2.08997
evaluation/Returns Min            -60.532
evaluation/Actions Mean             0.0211437
evaluation/Actions Std              0.190978
evaluation/Actions Max              0.997862
evaluation/Actions Min             -0.997032
evaluation/Num Paths               10
evaluation/Average Returns        -23.3215
time/data storing (s)               0.00119754
time/evaluation sampling (s)        0.267871
time/exploration sampling (s)       0.0768984
time/logging (s)                    0.00345088
time/saving (s)                     0.00239229
time/training (s)                   1.04774
time/epoch (s)                      1.39955
time/total (s)                    176.892
Epoch                             120
-----------------------------  ---------------
2019-04-21 12:19:22.874556 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 121 finished
-----------------------------  ---------------
replay_buffer/size              24600
trainer/QF1 Loss                    1.71128
trainer/QF2 Loss                    1.72072
trainer/Policy Loss                13.1106
trainer/Q1 Predictions Mean       -11.2995
trainer/Q1 Predictions Std          8.23945
trainer/Q1 Predictions Max         -9.15259
trainer/Q1 Predictions Min        -70.5582
trainer/Q2 Predictions Mean       -11.2536
trainer/Q2 Predictions Std          8.13003
trainer/Q2 Predictions Max         -9.15619
trainer/Q2 Predictions Min        -69.118
trainer/Q Targets Mean            -11.175
trainer/Q Targets Std               8.39882
trainer/Q Targets Max              -0.272354
trainer/Q Targets Min             -71.5495
trainer/Log Pis Mean                2.02408
trainer/Log Pis Std                 1.09435
trainer/Log Pis Max                 5.01824
trainer/Log Pis Min                -1.70853
trainer/Policy mu Mean              0.113061
trainer/Policy mu Std               0.725212
trainer/Policy mu Max               3.19873
trainer/Policy mu Min              -3.13351
trainer/Policy log std Mean        -2.07155
trainer/Policy log std Std          0.450097
trainer/Policy log std Max         -0.495394
trainer/Policy log std Min         -2.38429
trainer/Alpha                       0.0507378
trainer/Alpha Loss                  0.0717903
exploration/num steps total     24600
exploration/num paths total       246
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.166471
exploration/Rewards Std             0.270237
exploration/Rewards Max            -0.00253895
exploration/Rewards Min            -2.80769
exploration/Returns Mean          -16.6471
exploration/Returns Std             0.660567
exploration/Returns Max           -15.9866
exploration/Returns Min           -17.3077
exploration/Actions Mean            0.00617559
exploration/Actions Std             0.197316
exploration/Actions Max             0.985456
exploration/Actions Min            -0.991669
exploration/Num Paths               2
exploration/Average Returns       -16.6471
evaluation/num steps total     122000
evaluation/num paths total       1220
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.287438
evaluation/Rewards Std              1.20067
evaluation/Rewards Max             -0.0226198
evaluation/Rewards Min            -10.3493
evaluation/Returns Mean           -28.7438
evaluation/Returns Std             20.6977
evaluation/Returns Max             -4.62088
evaluation/Returns Min            -61.1288
evaluation/Actions Mean             0.0302228
evaluation/Actions Std              0.197462
evaluation/Actions Max              0.996677
evaluation/Actions Min             -0.991622
evaluation/Num Paths               10
evaluation/Average Returns        -28.7438
time/data storing (s)               0.00116857
time/evaluation sampling (s)        0.258428
time/exploration sampling (s)       0.0738257
time/logging (s)                    0.00379036
time/saving (s)                     0.00235223
time/training (s)                   0.994228
time/epoch (s)                      1.33379
time/total (s)                    178.23
Epoch                             121
-----------------------------  ---------------
2019-04-21 12:19:24.369383 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 122 finished
-----------------------------  ---------------
replay_buffer/size              24800
trainer/QF1 Loss                    0.0757996
trainer/QF2 Loss                    0.114065
trainer/Policy Loss                11.927
trainer/Q1 Predictions Mean       -10.45
trainer/Q1 Predictions Std          5.05628
trainer/Q1 Predictions Max         -8.95782
trainer/Q1 Predictions Min        -48.377
trainer/Q2 Predictions Mean       -10.3831
trainer/Q2 Predictions Std          5.05054
trainer/Q2 Predictions Max         -8.89779
trainer/Q2 Predictions Min        -48.0017
trainer/Q Targets Mean            -10.6659
trainer/Q Targets Std               4.99274
trainer/Q Targets Max              -9.14134
trainer/Q Targets Min             -47.5102
trainer/Log Pis Mean                1.64723
trainer/Log Pis Std                 1.23571
trainer/Log Pis Max                 4.70762
trainer/Log Pis Min                -2.90548
trainer/Policy mu Mean              0.0952766
trainer/Policy mu Std               0.697373
trainer/Policy mu Max               3.14779
trainer/Policy mu Min              -2.01479
trainer/Policy log std Mean        -2.03339
trainer/Policy log std Std          0.454725
trainer/Policy log std Max         -0.444423
trainer/Policy log std Min         -2.33627
trainer/Alpha                       0.050021
trainer/Alpha Loss                 -1.05659
exploration/num steps total     24800
exploration/num paths total       248
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.316879
exploration/Rewards Std             0.819592
exploration/Rewards Max            -0.0249482
exploration/Rewards Min            -7.00322
exploration/Returns Mean          -31.6879
exploration/Returns Std             7.3223
exploration/Returns Max           -24.3656
exploration/Returns Min           -39.0102
exploration/Actions Mean            0.0398446
exploration/Actions Std             0.240113
exploration/Actions Max             0.997958
exploration/Actions Min            -0.455825
exploration/Num Paths               2
exploration/Average Returns       -31.6879
evaluation/num steps total     123000
evaluation/num paths total       1230
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.247103
evaluation/Rewards Std              0.970353
evaluation/Rewards Max             -0.0098719
evaluation/Rewards Min            -10.3076
evaluation/Returns Mean           -24.7103
evaluation/Returns Std             17.5658
evaluation/Returns Max             -7.60202
evaluation/Returns Min            -60.2815
evaluation/Actions Mean             0.0243593
evaluation/Actions Std              0.193246
evaluation/Actions Max              0.997311
evaluation/Actions Min             -0.99591
evaluation/Num Paths               10
evaluation/Average Returns        -24.7103
time/data storing (s)               0.00117087
time/evaluation sampling (s)        0.25961
time/exploration sampling (s)       0.0677422
time/logging (s)                    0.00382671
time/saving (s)                     0.0024178
time/training (s)                   1.15312
time/epoch (s)                      1.48789
time/total (s)                    179.723
Epoch                             122
-----------------------------  ---------------
2019-04-21 12:19:25.954158 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 123 finished
-----------------------------  ---------------
replay_buffer/size              25000
trainer/QF1 Loss                    0.849937
trainer/QF2 Loss                    0.854971
trainer/Policy Loss                12.1932
trainer/Q1 Predictions Mean       -10.3898
trainer/Q1 Predictions Std          5.31563
trainer/Q1 Predictions Max         -8.97618
trainer/Q1 Predictions Min        -44.2441
trainer/Q2 Predictions Mean       -10.4334
trainer/Q2 Predictions Std          5.29016
trainer/Q2 Predictions Max         -9.0476
trainer/Q2 Predictions Min        -44.6023
trainer/Q Targets Mean            -10.3805
trainer/Q Targets Std               5.34512
trainer/Q Targets Max              -0.18129
trainer/Q Targets Min             -43.3801
trainer/Log Pis Mean                2.11598
trainer/Log Pis Std                 1.29389
trainer/Log Pis Max                 8.16704
trainer/Log Pis Min                -1.8241
trainer/Policy mu Mean              0.127304
trainer/Policy mu Std               0.669844
trainer/Policy mu Max               3.27887
trainer/Policy mu Min              -1.31811
trainer/Policy log std Mean        -2.18749
trainer/Policy log std Std          0.408489
trainer/Policy log std Max         -0.66456
trainer/Policy log std Min         -2.43196
trainer/Alpha                       0.0508207
trainer/Alpha Loss                  0.345597
exploration/num steps total     25000
exploration/num paths total       250
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.405863
exploration/Rewards Std             1.2816
exploration/Rewards Max            -0.00367648
exploration/Rewards Min           -10.0749
exploration/Returns Mean          -40.5863
exploration/Returns Std            16.9736
exploration/Returns Max           -23.6127
exploration/Returns Min           -57.5599
exploration/Actions Mean            0.0603121
exploration/Actions Std             0.257245
exploration/Actions Max             0.99885
exploration/Actions Min            -0.360388
exploration/Num Paths               2
exploration/Average Returns       -40.5863
evaluation/num steps total     124000
evaluation/num paths total       1240
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.224433
evaluation/Rewards Std              0.905413
evaluation/Rewards Max             -0.0202943
evaluation/Rewards Min             -8.92362
evaluation/Returns Mean           -22.4433
evaluation/Returns Std             13.8381
evaluation/Returns Max             -5.87101
evaluation/Returns Min            -49.2418
evaluation/Actions Mean             0.0270251
evaluation/Actions Std              0.178019
evaluation/Actions Max              0.998467
evaluation/Actions Min             -0.993484
evaluation/Num Paths               10
evaluation/Average Returns        -22.4433
time/data storing (s)               0.00182709
time/evaluation sampling (s)        0.287739
time/exploration sampling (s)       0.103838
time/logging (s)                    0.00347241
time/saving (s)                     0.002389
time/training (s)                   1.17804
time/epoch (s)                      1.5773
time/total (s)                    181.305
Epoch                             123
-----------------------------  ---------------
2019-04-21 12:19:27.405162 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 124 finished
-----------------------------  ---------------
replay_buffer/size              25200
trainer/QF1 Loss                    1.63604
trainer/QF2 Loss                    1.63881
trainer/Policy Loss                12.2252
trainer/Q1 Predictions Mean       -10.3082
trainer/Q1 Predictions Std          4.7382
trainer/Q1 Predictions Max         -9.03915
trainer/Q1 Predictions Min        -50.5887
trainer/Q2 Predictions Mean       -10.3212
trainer/Q2 Predictions Std          4.75377
trainer/Q2 Predictions Max         -9.0392
trainer/Q2 Predictions Min        -50.86
trainer/Q Targets Mean            -10.168
trainer/Q Targets Std               4.96076
trainer/Q Targets Max              -0.0769964
trainer/Q Targets Min             -50.9342
trainer/Log Pis Mean                2.05176
trainer/Log Pis Std                 1.21119
trainer/Log Pis Max                 5.65743
trainer/Log Pis Min                -2.44105
trainer/Policy mu Mean              0.10812
trainer/Policy mu Std               0.694627
trainer/Policy mu Max               3.03809
trainer/Policy mu Min              -2.48456
trainer/Policy log std Mean        -2.104
trainer/Policy log std Std          0.472099
trainer/Policy log std Max         -0.578587
trainer/Policy log std Min         -2.39295
trainer/Alpha                       0.0509092
trainer/Alpha Loss                  0.154117
exploration/num steps total     25200
exploration/num paths total       252
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.495395
exploration/Rewards Std             1.42932
exploration/Rewards Max            -0.00440358
exploration/Rewards Min            -9.30711
exploration/Returns Mean          -49.5395
exploration/Returns Std             1.9856
exploration/Returns Max           -47.5539
exploration/Returns Min           -51.5251
exploration/Actions Mean            0.0289084
exploration/Actions Std             0.263283
exploration/Actions Max             0.999829
exploration/Actions Min            -0.998119
exploration/Num Paths               2
exploration/Average Returns       -49.5395
evaluation/num steps total     125000
evaluation/num paths total       1250
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.209529
evaluation/Rewards Std              0.810149
evaluation/Rewards Max             -0.0241286
evaluation/Rewards Min             -7.93437
evaluation/Returns Mean           -20.9529
evaluation/Returns Std             11.5195
evaluation/Returns Max             -6.85071
evaluation/Returns Min            -35.7064
evaluation/Actions Mean             0.0244807
evaluation/Actions Std              0.175484
evaluation/Actions Max              0.995243
evaluation/Actions Min             -0.992365
evaluation/Num Paths               10
evaluation/Average Returns        -20.9529
time/data storing (s)               0.00117176
time/evaluation sampling (s)        0.288922
time/exploration sampling (s)       0.0686599
time/logging (s)                    0.00411827
time/saving (s)                     0.00240041
time/training (s)                   1.07961
time/epoch (s)                      1.44488
time/total (s)                    182.754
Epoch                             124
-----------------------------  ---------------
2019-04-21 12:19:28.956619 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 125 finished
-----------------------------  ---------------
replay_buffer/size              25400
trainer/QF1 Loss                    2.46405
trainer/QF2 Loss                    2.43306
trainer/Policy Loss                11.9017
trainer/Q1 Predictions Mean       -10.5841
trainer/Q1 Predictions Std          6.97174
trainer/Q1 Predictions Max         -9.02043
trainer/Q1 Predictions Min        -54.3685
trainer/Q2 Predictions Mean       -10.5661
trainer/Q2 Predictions Std          6.95347
trainer/Q2 Predictions Max         -8.99194
trainer/Q2 Predictions Min        -54.8446
trainer/Q Targets Mean            -10.3512
trainer/Q Targets Std               7.2192
trainer/Q Targets Max              -0.0621367
trainer/Q Targets Min             -54.9941
trainer/Log Pis Mean                1.76747
trainer/Log Pis Std                 1.11347
trainer/Log Pis Max                 6.33726
trainer/Log Pis Min                -1.17773
trainer/Policy mu Mean              0.0887753
trainer/Policy mu Std               0.578222
trainer/Policy mu Max               3.05606
trainer/Policy mu Min              -1.24765
trainer/Policy log std Mean        -2.07476
trainer/Policy log std Std          0.353095
trainer/Policy log std Max         -0.66734
trainer/Policy log std Min         -2.30768
trainer/Alpha                       0.0500247
trainer/Alpha Loss                 -0.696466
exploration/num steps total     25400
exploration/num paths total       254
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.268174
exploration/Rewards Std             0.67446
exploration/Rewards Max            -0.00846655
exploration/Rewards Min            -6.3845
exploration/Returns Mean          -26.8174
exploration/Returns Std             8.42161
exploration/Returns Max           -18.3958
exploration/Returns Min           -35.239
exploration/Actions Mean            0.0131749
exploration/Actions Std             0.227747
exploration/Actions Max             0.99832
exploration/Actions Min            -0.890292
exploration/Num Paths               2
exploration/Average Returns       -26.8174
evaluation/num steps total     126000
evaluation/num paths total       1260
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.237467
evaluation/Rewards Std              0.805972
evaluation/Rewards Max             -0.013586
evaluation/Rewards Min             -7.58756
evaluation/Returns Mean           -23.7467
evaluation/Returns Std              6.69589
evaluation/Returns Max            -12.4106
evaluation/Returns Min            -33.2466
evaluation/Actions Mean             0.0234057
evaluation/Actions Std              0.198744
evaluation/Actions Max              0.995706
evaluation/Actions Min             -0.992823
evaluation/Num Paths               10
evaluation/Average Returns        -23.7467
time/data storing (s)               0.00117573
time/evaluation sampling (s)        0.269145
time/exploration sampling (s)       0.0697128
time/logging (s)                    0.00605269
time/saving (s)                     0.00336008
time/training (s)                   1.19693
time/epoch (s)                      1.54637
time/total (s)                    184.305
Epoch                             125
-----------------------------  ---------------
2019-04-21 12:19:30.382770 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 126 finished
-----------------------------  ---------------
replay_buffer/size              25600
trainer/QF1 Loss                    1.69718
trainer/QF2 Loss                    1.6405
trainer/Policy Loss                12.0391
trainer/Q1 Predictions Mean       -10.286
trainer/Q1 Predictions Std          5.26311
trainer/Q1 Predictions Max         -8.9314
trainer/Q1 Predictions Min        -51.4609
trainer/Q2 Predictions Mean       -10.2552
trainer/Q2 Predictions Std          5.2313
trainer/Q2 Predictions Max         -8.89895
trainer/Q2 Predictions Min        -51.0509
trainer/Q Targets Mean            -10.1668
trainer/Q Targets Std               5.44913
trainer/Q Targets Max              -0.118303
trainer/Q Targets Min             -50.8632
trainer/Log Pis Mean                2.05919
trainer/Log Pis Std                 1.15991
trainer/Log Pis Max                 7.97496
trainer/Log Pis Min                -1.21863
trainer/Policy mu Mean              0.0857169
trainer/Policy mu Std               0.685602
trainer/Policy mu Max               3.38186
trainer/Policy mu Min              -2.77581
trainer/Policy log std Mean        -2.07428
trainer/Policy log std Std          0.421701
trainer/Policy log std Max         -0.564669
trainer/Policy log std Min         -2.2967
trainer/Alpha                       0.0502262
trainer/Alpha Loss                  0.177038
exploration/num steps total     25600
exploration/num paths total       256
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.331733
exploration/Rewards Std             0.973972
exploration/Rewards Max            -0.011153
exploration/Rewards Min            -7.73351
exploration/Returns Mean          -33.1733
exploration/Returns Std             5.5629
exploration/Returns Max           -27.6104
exploration/Returns Min           -38.7362
exploration/Actions Mean            0.0253119
exploration/Actions Std             0.257078
exploration/Actions Max             0.996091
exploration/Actions Min            -0.997716
exploration/Num Paths               2
exploration/Average Returns       -33.1733
evaluation/num steps total     127000
evaluation/num paths total       1270
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.262755
evaluation/Rewards Std              1.14464
evaluation/Rewards Max             -0.0112002
evaluation/Rewards Min            -10.6672
evaluation/Returns Mean           -26.2755
evaluation/Returns Std             19.5536
evaluation/Returns Max             -3.70175
evaluation/Returns Min            -61.6656
evaluation/Actions Mean             0.029491
evaluation/Actions Std              0.193038
evaluation/Actions Max              0.997327
evaluation/Actions Min             -0.991804
evaluation/Num Paths               10
evaluation/Average Returns        -26.2755
time/data storing (s)               0.0011655
time/evaluation sampling (s)        0.267069
time/exploration sampling (s)       0.0728478
time/logging (s)                    0.00342185
time/saving (s)                     0.00238136
time/training (s)                   1.06814
time/epoch (s)                      1.41502
time/total (s)                    185.726
Epoch                             126
-----------------------------  ---------------
2019-04-21 12:19:31.690936 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 127 finished
-----------------------------  ---------------
replay_buffer/size              25800
trainer/QF1 Loss                    0.301588
trainer/QF2 Loss                    0.350016
trainer/Policy Loss                12.0717
trainer/Q1 Predictions Mean       -10.4204
trainer/Q1 Predictions Std          5.37829
trainer/Q1 Predictions Max         -8.7888
trainer/Q1 Predictions Min        -48.7095
trainer/Q2 Predictions Mean       -10.3801
trainer/Q2 Predictions Std          5.39468
trainer/Q2 Predictions Max         -8.76757
trainer/Q2 Predictions Min        -49.0793
trainer/Q Targets Mean            -10.4944
trainer/Q Targets Std               4.95824
trainer/Q Targets Max              -8.8665
trainer/Q Targets Min             -43.5376
trainer/Log Pis Mean                2.0834
trainer/Log Pis Std                 1.1954
trainer/Log Pis Max                 6.84075
trainer/Log Pis Min                -5.94376
trainer/Policy mu Mean              0.102637
trainer/Policy mu Std               0.679238
trainer/Policy mu Max               3.11128
trainer/Policy mu Min              -2.17051
trainer/Policy log std Mean        -2.08752
trainer/Policy log std Std          0.408281
trainer/Policy log std Max         -0.499555
trainer/Policy log std Min         -2.32946
trainer/Alpha                       0.0511375
trainer/Alpha Loss                  0.247956
exploration/num steps total     25800
exploration/num paths total       258
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.243918
exploration/Rewards Std             0.667365
exploration/Rewards Max            -0.00783396
exploration/Rewards Min            -6.20507
exploration/Returns Mean          -24.3918
exploration/Returns Std             4.60907
exploration/Returns Max           -19.7827
exploration/Returns Min           -29.0009
exploration/Actions Mean            0.0178861
exploration/Actions Std             0.245117
exploration/Actions Max             0.99186
exploration/Actions Min            -0.987884
exploration/Num Paths               2
exploration/Average Returns       -24.3918
evaluation/num steps total     128000
evaluation/num paths total       1280
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.204685
evaluation/Rewards Std              0.916974
evaluation/Rewards Max             -0.00446801
evaluation/Rewards Min             -8.89656
evaluation/Returns Mean           -20.4685
evaluation/Returns Std             11.5876
evaluation/Returns Max             -2.63667
evaluation/Returns Min            -39.4313
evaluation/Actions Mean             0.0295379
evaluation/Actions Std              0.186855
evaluation/Actions Max              0.995371
evaluation/Actions Min             -0.986705
evaluation/Num Paths               10
evaluation/Average Returns        -20.4685
time/data storing (s)               0.00123597
time/evaluation sampling (s)        0.249706
time/exploration sampling (s)       0.0668163
time/logging (s)                    0.0033805
time/saving (s)                     0.00235458
time/training (s)                   0.977331
time/epoch (s)                      1.30082
time/total (s)                    187.031
Epoch                             127
-----------------------------  ---------------
2019-04-21 12:19:33.102019 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 128 finished
-----------------------------  ---------------
replay_buffer/size              26000
trainer/QF1 Loss                    1.82171
trainer/QF2 Loss                    1.76994
trainer/Policy Loss                12.3827
trainer/Q1 Predictions Mean       -10.6324
trainer/Q1 Predictions Std          6.32595
trainer/Q1 Predictions Max         -9.0307
trainer/Q1 Predictions Min        -55.5985
trainer/Q2 Predictions Mean       -10.5991
trainer/Q2 Predictions Std          6.35206
trainer/Q2 Predictions Max         -9.01032
trainer/Q2 Predictions Min        -55.6809
trainer/Q Targets Mean            -10.4211
trainer/Q Targets Std               6.8463
trainer/Q Targets Max              -0.107673
trainer/Q Targets Min             -58.1459
trainer/Log Pis Mean                1.91853
trainer/Log Pis Std                 1.25709
trainer/Log Pis Max                 7.28087
trainer/Log Pis Min                -2.99549
trainer/Policy mu Mean              0.0935264
trainer/Policy mu Std               0.672682
trainer/Policy mu Max               3.55415
trainer/Policy mu Min              -2.69414
trainer/Policy log std Mean        -2.07639
trainer/Policy log std Std          0.397804
trainer/Policy log std Max         -0.556063
trainer/Policy log std Min         -2.29186
trainer/Alpha                       0.0519066
trainer/Alpha Loss                 -0.240994
exploration/num steps total     26000
exploration/num paths total       260
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.262292
exploration/Rewards Std             0.578822
exploration/Rewards Max            -0.0138678
exploration/Rewards Min            -5.21825
exploration/Returns Mean          -26.2292
exploration/Returns Std             4.45638
exploration/Returns Max           -21.7728
exploration/Returns Min           -30.6856
exploration/Actions Mean            0.0190303
exploration/Actions Std             0.219078
exploration/Actions Max             0.998761
exploration/Actions Min            -0.9832
exploration/Num Paths               2
exploration/Average Returns       -26.2292
evaluation/num steps total     129000
evaluation/num paths total       1290
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.222911
evaluation/Rewards Std              0.63769
evaluation/Rewards Max             -0.0263036
evaluation/Rewards Min             -6.46886
evaluation/Returns Mean           -22.2911
evaluation/Returns Std              3.28494
evaluation/Returns Max            -16.2128
evaluation/Returns Min            -28.8986
evaluation/Actions Mean             0.00909911
evaluation/Actions Std              0.179073
evaluation/Actions Max              0.997285
evaluation/Actions Min             -0.996434
evaluation/Num Paths               10
evaluation/Average Returns        -22.2911
time/data storing (s)               0.00127896
time/evaluation sampling (s)        0.259554
time/exploration sampling (s)       0.0675434
time/logging (s)                    0.00348529
time/saving (s)                     0.00298427
time/training (s)                   1.06968
time/epoch (s)                      1.40453
time/total (s)                    188.44
Epoch                             128
-----------------------------  ---------------
2019-04-21 12:19:34.507880 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 129 finished
-----------------------------  ---------------
replay_buffer/size              26200
trainer/QF1 Loss                    0.867488
trainer/QF2 Loss                    0.887503
trainer/Policy Loss                11.4963
trainer/Q1 Predictions Mean        -9.91374
trainer/Q1 Predictions Std          3.74085
trainer/Q1 Predictions Max         -8.78881
trainer/Q1 Predictions Min        -34.7865
trainer/Q2 Predictions Mean        -9.91545
trainer/Q2 Predictions Std          3.73992
trainer/Q2 Predictions Max         -8.80571
trainer/Q2 Predictions Min        -34.9078
trainer/Q Targets Mean             -9.83745
trainer/Q Targets Std               3.75813
trainer/Q Targets Max              -0.0659945
trainer/Q Targets Min             -35.4699
trainer/Log Pis Mean                1.83944
trainer/Log Pis Std                 1.50682
trainer/Log Pis Max                 7.25088
trainer/Log Pis Min                -2.99906
trainer/Policy mu Mean              0.0455613
trainer/Policy mu Std               0.61772
trainer/Policy mu Max               2.95127
trainer/Policy mu Min              -2.96014
trainer/Policy log std Mean        -2.15526
trainer/Policy log std Std          0.41042
trainer/Policy log std Max         -0.602164
trainer/Policy log std Min         -2.38695
trainer/Alpha                       0.0519722
trainer/Alpha Loss                 -0.474783
exploration/num steps total     26200
exploration/num paths total       262
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.147282
exploration/Rewards Std             0.229571
exploration/Rewards Max            -0.00992301
exploration/Rewards Min            -2.91217
exploration/Returns Mean          -14.7282
exploration/Returns Std             1.239
exploration/Returns Max           -13.4892
exploration/Returns Min           -15.9672
exploration/Actions Mean            0.0046805
exploration/Actions Std             0.18294
exploration/Actions Max             0.98188
exploration/Actions Min            -0.993339
exploration/Num Paths               2
exploration/Average Returns       -14.7282
evaluation/num steps total     130000
evaluation/num paths total       1300
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.156127
evaluation/Rewards Std              0.669834
evaluation/Rewards Max             -0.0334823
evaluation/Rewards Min             -7.73667
evaluation/Returns Mean           -15.6127
evaluation/Returns Std              7.09581
evaluation/Returns Max             -6.77036
evaluation/Returns Min            -29.3711
evaluation/Actions Mean             0.0240142
evaluation/Actions Std              0.175909
evaluation/Actions Max              0.997068
evaluation/Actions Min             -0.992772
evaluation/Num Paths               10
evaluation/Average Returns        -15.6127
time/data storing (s)               0.00135553
time/evaluation sampling (s)        0.262349
time/exploration sampling (s)       0.0656181
time/logging (s)                    0.00418447
time/saving (s)                     0.00258519
time/training (s)                   1.06334
time/epoch (s)                      1.39944
time/total (s)                    189.845
Epoch                             129
-----------------------------  ---------------
2019-04-21 12:19:36.074946 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 130 finished
-----------------------------  ---------------
replay_buffer/size              26400
trainer/QF1 Loss                    0.932019
trainer/QF2 Loss                    0.992528
trainer/Policy Loss                12.481
trainer/Q1 Predictions Mean       -10.8073
trainer/Q1 Predictions Std          8.4641
trainer/Q1 Predictions Max         -8.75543
trainer/Q1 Predictions Min        -79.1303
trainer/Q2 Predictions Mean       -10.8927
trainer/Q2 Predictions Std          8.50658
trainer/Q2 Predictions Max         -8.85032
trainer/Q2 Predictions Min        -79.7347
trainer/Q Targets Mean            -10.7287
trainer/Q Targets Std               8.24631
trainer/Q Targets Max              -0.0621367
trainer/Q Targets Min             -75.4665
trainer/Log Pis Mean                2.01512
trainer/Log Pis Std                 1.20029
trainer/Log Pis Max                 6.586
trainer/Log Pis Min                -2.13163
trainer/Policy mu Mean              0.118629
trainer/Policy mu Std               0.650356
trainer/Policy mu Max               3.24836
trainer/Policy mu Min              -1.69764
trainer/Policy log std Mean        -2.09606
trainer/Policy log std Std          0.39468
trainer/Policy log std Max         -0.453093
trainer/Policy log std Min         -2.30924
trainer/Alpha                       0.0519568
trainer/Alpha Loss                  0.0446972
exploration/num steps total     26400
exploration/num paths total       264
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.382897
exploration/Rewards Std             1.12373
exploration/Rewards Max            -0.00372195
exploration/Rewards Min            -8.63668
exploration/Returns Mean          -38.2897
exploration/Returns Std            16.2282
exploration/Returns Max           -22.0616
exploration/Returns Min           -54.5179
exploration/Actions Mean            0.0377593
exploration/Actions Std             0.232666
exploration/Actions Max             0.998682
exploration/Actions Min            -0.468831
exploration/Num Paths               2
exploration/Average Returns       -38.2897
evaluation/num steps total     131000
evaluation/num paths total       1310
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.30445
evaluation/Rewards Std              1.12162
evaluation/Rewards Max             -0.00733412
evaluation/Rewards Min             -9.64082
evaluation/Returns Mean           -30.445
evaluation/Returns Std             16.8596
evaluation/Returns Max            -10.307
evaluation/Returns Min            -55.8477
evaluation/Actions Mean             0.0272133
evaluation/Actions Std              0.207723
evaluation/Actions Max              0.997128
evaluation/Actions Min             -0.995654
evaluation/Num Paths               10
evaluation/Average Returns        -30.445
time/data storing (s)               0.00117427
time/evaluation sampling (s)        0.333979
time/exploration sampling (s)       0.0698281
time/logging (s)                    0.00351529
time/saving (s)                     0.00307064
time/training (s)                   1.14623
time/epoch (s)                      1.5578
time/total (s)                    191.407
Epoch                             130
-----------------------------  ---------------
2019-04-21 12:19:37.594627 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 131 finished
-----------------------------  ---------------
replay_buffer/size              26600
trainer/QF1 Loss                    0.791978
trainer/QF2 Loss                    0.842168
trainer/Policy Loss                12.6863
trainer/Q1 Predictions Mean       -10.9651
trainer/Q1 Predictions Std          7.68876
trainer/Q1 Predictions Max         -8.75724
trainer/Q1 Predictions Min        -66.0155
trainer/Q2 Predictions Mean       -10.9698
trainer/Q2 Predictions Std          7.61162
trainer/Q2 Predictions Max         -8.75468
trainer/Q2 Predictions Min        -64.5797
trainer/Q Targets Mean            -10.8963
trainer/Q Targets Std               7.86983
trainer/Q Targets Max              -0.309456
trainer/Q Targets Min             -67.2213
trainer/Log Pis Mean                1.92224
trainer/Log Pis Std                 1.44146
trainer/Log Pis Max                 6.93927
trainer/Log Pis Min                -2.66287
trainer/Policy mu Mean              0.0541344
trainer/Policy mu Std               0.777138
trainer/Policy mu Max               3.36696
trainer/Policy mu Min              -2.40562
trainer/Policy log std Mean        -2.02452
trainer/Policy log std Std          0.494808
trainer/Policy log std Max         -0.519464
trainer/Policy log std Min         -2.32692
trainer/Alpha                       0.0527659
trainer/Alpha Loss                 -0.228765
exploration/num steps total     26600
exploration/num paths total       266
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.250226
exploration/Rewards Std             0.582094
exploration/Rewards Max            -0.00968885
exploration/Rewards Min            -5.07913
exploration/Returns Mean          -25.0226
exploration/Returns Std             3.49656
exploration/Returns Max           -21.526
exploration/Returns Min           -28.5191
exploration/Actions Mean            0.0320672
exploration/Actions Std             0.217087
exploration/Actions Max             0.998858
exploration/Actions Min            -0.529921
exploration/Num Paths               2
exploration/Average Returns       -25.0226
evaluation/num steps total     132000
evaluation/num paths total       1320
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.307068
evaluation/Rewards Std              1.09791
evaluation/Rewards Max             -0.0751897
evaluation/Rewards Min             -9.90436
evaluation/Returns Mean           -30.7068
evaluation/Returns Std             16.6664
evaluation/Returns Max            -11.7523
evaluation/Returns Min            -57.41
evaluation/Actions Mean             0.0250539
evaluation/Actions Std              0.198834
evaluation/Actions Max              0.997101
evaluation/Actions Min             -0.994464
evaluation/Num Paths               10
evaluation/Average Returns        -30.7068
time/data storing (s)               0.00130133
time/evaluation sampling (s)        0.330066
time/exploration sampling (s)       0.0728806
time/logging (s)                    0.00347968
time/saving (s)                     0.00234777
time/training (s)                   1.10181
time/epoch (s)                      1.51188
time/total (s)                    192.924
Epoch                             131
-----------------------------  ---------------
2019-04-21 12:19:38.992898 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 132 finished
-----------------------------  ---------------
replay_buffer/size              26800
trainer/QF1 Loss                    0.741639
trainer/QF2 Loss                    0.729016
trainer/Policy Loss                11.3254
trainer/Q1 Predictions Mean        -9.51852
trainer/Q1 Predictions Std          3.845
trainer/Q1 Predictions Max         -8.63298
trainer/Q1 Predictions Min        -36.5673
trainer/Q2 Predictions Mean        -9.52545
trainer/Q2 Predictions Std          3.88359
trainer/Q2 Predictions Max         -8.62365
trainer/Q2 Predictions Min        -37.0079
trainer/Q Targets Mean             -9.50568
trainer/Q Targets Std               3.99432
trainer/Q Targets Max              -0.453406
trainer/Q Targets Min             -37.0581
trainer/Log Pis Mean                1.91051
trainer/Log Pis Std                 1.11256
trainer/Log Pis Max                 6.51556
trainer/Log Pis Min                -1.33534
trainer/Policy mu Mean              0.0967606
trainer/Policy mu Std               0.504557
trainer/Policy mu Max               3.02401
trainer/Policy mu Min              -1.57131
trainer/Policy log std Mean        -2.18631
trainer/Policy log std Std          0.343725
trainer/Policy log std Max         -0.601808
trainer/Policy log std Min         -2.36707
trainer/Alpha                       0.0532672
trainer/Alpha Loss                 -0.262407
exploration/num steps total     26800
exploration/num paths total       268
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.351511
exploration/Rewards Std             1.04496
exploration/Rewards Max            -0.0183878
exploration/Rewards Min            -7.66221
exploration/Returns Mean          -35.1511
exploration/Returns Std             9.06114
exploration/Returns Max           -26.09
exploration/Returns Min           -44.2123
exploration/Actions Mean            0.023991
exploration/Actions Std             0.239769
exploration/Actions Max             0.997541
exploration/Actions Min            -0.978813
exploration/Num Paths               2
exploration/Average Returns       -35.1511
evaluation/num steps total     133000
evaluation/num paths total       1330
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.240703
evaluation/Rewards Std              1.07639
evaluation/Rewards Max             -0.0209131
evaluation/Rewards Min            -10.5482
evaluation/Returns Mean           -24.0703
evaluation/Returns Std             18.5265
evaluation/Returns Max             -7.30694
evaluation/Returns Min            -57.5046
evaluation/Actions Mean             0.0255349
evaluation/Actions Std              0.195873
evaluation/Actions Max              0.997357
evaluation/Actions Min             -0.991988
evaluation/Num Paths               10
evaluation/Average Returns        -24.0703
time/data storing (s)               0.00126179
time/evaluation sampling (s)        0.253801
time/exploration sampling (s)       0.0719528
time/logging (s)                    0.00353527
time/saving (s)                     0.0085793
time/training (s)                   1.05259
time/epoch (s)                      1.39172
time/total (s)                    194.32
Epoch                             132
-----------------------------  ---------------
2019-04-21 12:19:40.622981 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 133 finished
-----------------------------  ---------------
replay_buffer/size              27000
trainer/QF1 Loss                    0.786135
trainer/QF2 Loss                    0.771617
trainer/Policy Loss                11.5162
trainer/Q1 Predictions Mean        -9.81276
trainer/Q1 Predictions Std          3.31
trainer/Q1 Predictions Max         -8.69124
trainer/Q1 Predictions Min        -28.1173
trainer/Q2 Predictions Mean        -9.71638
trainer/Q2 Predictions Std          3.29227
trainer/Q2 Predictions Max         -8.6157
trainer/Q2 Predictions Min        -28.0107
trainer/Q Targets Mean             -9.72163
trainer/Q Targets Std               3.46536
trainer/Q Targets Max              -0.0912171
trainer/Q Targets Min             -28.3138
trainer/Log Pis Mean                1.94798
trainer/Log Pis Std                 1.07801
trainer/Log Pis Max                 5.53926
trainer/Log Pis Min                -1.45007
trainer/Policy mu Mean              0.130392
trainer/Policy mu Std               0.642679
trainer/Policy mu Max               2.98597
trainer/Policy mu Min              -2.91266
trainer/Policy log std Mean        -2.03339
trainer/Policy log std Std          0.385486
trainer/Policy log std Max         -0.525155
trainer/Policy log std Min         -2.25546
trainer/Alpha                       0.0511843
trainer/Alpha Loss                 -0.154597
exploration/num steps total     27000
exploration/num paths total       270
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.48749
exploration/Rewards Std             1.36192
exploration/Rewards Max            -0.00179971
exploration/Rewards Min            -8.22623
exploration/Returns Mean          -48.749
exploration/Returns Std             0.749327
exploration/Returns Max           -47.9997
exploration/Returns Min           -49.4983
exploration/Actions Mean            0.0366846
exploration/Actions Std             0.266497
exploration/Actions Max             0.998814
exploration/Actions Min            -0.813213
exploration/Num Paths               2
exploration/Average Returns       -48.749
evaluation/num steps total     134000
evaluation/num paths total       1340
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.176962
evaluation/Rewards Std              0.842892
evaluation/Rewards Max             -0.0325574
evaluation/Rewards Min            -10.0445
evaluation/Returns Mean           -17.6962
evaluation/Returns Std             14.8608
evaluation/Returns Max             -3.90987
evaluation/Returns Min            -50.796
evaluation/Actions Mean             0.0202811
evaluation/Actions Std              0.172625
evaluation/Actions Max              0.997095
evaluation/Actions Min             -0.993043
evaluation/Num Paths               10
evaluation/Average Returns        -17.6962
time/data storing (s)               0.00176252
time/evaluation sampling (s)        0.316267
time/exploration sampling (s)       0.117438
time/logging (s)                    0.00366993
time/saving (s)                     0.00236968
time/training (s)                   1.18165
time/epoch (s)                      1.62316
time/total (s)                    195.948
Epoch                             133
-----------------------------  ---------------
2019-04-21 12:19:42.034144 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 134 finished
-----------------------------  ---------------
replay_buffer/size              27200
trainer/QF1 Loss                    0.807752
trainer/QF2 Loss                    0.810954
trainer/Policy Loss                12.1952
trainer/Q1 Predictions Mean       -10.6858
trainer/Q1 Predictions Std          7.06538
trainer/Q1 Predictions Max         -8.71992
trainer/Q1 Predictions Min        -60.2241
trainer/Q2 Predictions Mean       -10.632
trainer/Q2 Predictions Std          7.06146
trainer/Q2 Predictions Max         -8.67005
trainer/Q2 Predictions Min        -60.7392
trainer/Q Targets Mean            -10.5186
trainer/Q Targets Std               7.26991
trainer/Q Targets Max              -0.0560581
trainer/Q Targets Min             -60.8936
trainer/Log Pis Mean                2.0684
trainer/Log Pis Std                 1.00029
trainer/Log Pis Max                 5.36911
trainer/Log Pis Min                -0.959778
trainer/Policy mu Mean              0.126944
trainer/Policy mu Std               0.71289
trainer/Policy mu Max               3.0181
trainer/Policy mu Min              -1.78959
trainer/Policy log std Mean        -2.10856
trainer/Policy log std Std          0.459489
trainer/Policy log std Max         -0.573519
trainer/Policy log std Min         -2.36595
trainer/Alpha                       0.0501867
trainer/Alpha Loss                  0.204657
exploration/num steps total     27200
exploration/num paths total       272
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.312485
exploration/Rewards Std             0.862619
exploration/Rewards Max            -0.011804
exploration/Rewards Min            -6.32865
exploration/Returns Mean          -31.2485
exploration/Returns Std             3.50638
exploration/Returns Max           -27.7421
exploration/Returns Min           -34.7549
exploration/Actions Mean            0.0412557
exploration/Actions Std             0.226099
exploration/Actions Max             0.998904
exploration/Actions Min            -0.407029
exploration/Num Paths               2
exploration/Average Returns       -31.2485
evaluation/num steps total     135000
evaluation/num paths total       1350
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.23223
evaluation/Rewards Std              1.10814
evaluation/Rewards Max             -0.010569
evaluation/Rewards Min            -10.2084
evaluation/Returns Mean           -23.223
evaluation/Returns Std             18.6553
evaluation/Returns Max             -1.38664
evaluation/Returns Min            -52.8662
evaluation/Actions Mean             0.0264921
evaluation/Actions Std              0.193703
evaluation/Actions Max              0.996979
evaluation/Actions Min             -0.995609
evaluation/Num Paths               10
evaluation/Average Returns        -23.223
time/data storing (s)               0.00117105
time/evaluation sampling (s)        0.279881
time/exploration sampling (s)       0.0723053
time/logging (s)                    0.00346
time/saving (s)                     0.00257353
time/training (s)                   1.04483
time/epoch (s)                      1.40422
time/total (s)                    197.356
Epoch                             134
-----------------------------  ---------------
2019-04-21 12:19:43.529326 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 135 finished
-----------------------------  ---------------
replay_buffer/size              27400
trainer/QF1 Loss                    0.736832
trainer/QF2 Loss                    0.728214
trainer/Policy Loss                11.0473
trainer/Q1 Predictions Mean        -9.26812
trainer/Q1 Predictions Std          2.21749
trainer/Q1 Predictions Max         -8.50257
trainer/Q1 Predictions Min        -26.301
trainer/Q2 Predictions Mean        -9.19219
trainer/Q2 Predictions Std          2.17819
trainer/Q2 Predictions Max         -8.42773
trainer/Q2 Predictions Min        -26.3458
trainer/Q Targets Mean             -9.22267
trainer/Q Targets Std               2.36976
trainer/Q Targets Max              -0.194062
trainer/Q Targets Min             -26.5552
trainer/Log Pis Mean                2.04952
trainer/Log Pis Std                 1.05327
trainer/Log Pis Max                 3.86072
trainer/Log Pis Min                -2.70247
trainer/Policy mu Mean              0.0731396
trainer/Policy mu Std               0.624182
trainer/Policy mu Max               3.40537
trainer/Policy mu Min              -2.45442
trainer/Policy log std Mean        -2.17897
trainer/Policy log std Std          0.450009
trainer/Policy log std Max         -0.568885
trainer/Policy log std Min         -2.43935
trainer/Alpha                       0.0507904
trainer/Alpha Loss                  0.14758
exploration/num steps total     27400
exploration/num paths total       274
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.426486
exploration/Rewards Std             1.32679
exploration/Rewards Max            -0.00190328
exploration/Rewards Min           -10.1625
exploration/Returns Mean          -42.6486
exploration/Returns Std            18.5005
exploration/Returns Max           -24.1482
exploration/Returns Min           -61.1491
exploration/Actions Mean            0.0511406
exploration/Actions Std             0.251437
exploration/Actions Max             0.998326
exploration/Actions Min            -0.635539
exploration/Num Paths               2
exploration/Average Returns       -42.6486
evaluation/num steps total     136000
evaluation/num paths total       1360
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.212624
evaluation/Rewards Std              0.842568
evaluation/Rewards Max             -0.0541238
evaluation/Rewards Min             -9.48505
evaluation/Returns Mean           -21.2624
evaluation/Returns Std             12.8457
evaluation/Returns Max            -10.82
evaluation/Returns Min            -52.4172
evaluation/Actions Mean             0.0155508
evaluation/Actions Std              0.183758
evaluation/Actions Max              0.995758
evaluation/Actions Min             -0.992565
evaluation/Num Paths               10
evaluation/Average Returns        -21.2624
time/data storing (s)               0.00140896
time/evaluation sampling (s)        0.306787
time/exploration sampling (s)       0.0669516
time/logging (s)                    0.00431196
time/saving (s)                     0.00893757
time/training (s)                   1.1013
time/epoch (s)                      1.4897
time/total (s)                    198.85
Epoch                             135
-----------------------------  ---------------
2019-04-21 12:19:45.078873 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 136 finished
-----------------------------  ---------------
replay_buffer/size              27600
trainer/QF1 Loss                    0.756084
trainer/QF2 Loss                    0.7482
trainer/Policy Loss                11.6504
trainer/Q1 Predictions Mean        -9.93128
trainer/Q1 Predictions Std          5.71676
trainer/Q1 Predictions Max         -8.4253
trainer/Q1 Predictions Min        -58.4603
trainer/Q2 Predictions Mean        -9.96284
trainer/Q2 Predictions Std          5.67142
trainer/Q2 Predictions Max         -8.48956
trainer/Q2 Predictions Min        -58.3424
trainer/Q Targets Mean             -9.95596
trainer/Q Targets Std               5.81022
trainer/Q Targets Max              -0.0845813
trainer/Q Targets Min             -59.0488
trainer/Log Pis Mean                1.93029
trainer/Log Pis Std                 1.11963
trainer/Log Pis Max                 5.23416
trainer/Log Pis Min                -2.40102
trainer/Policy mu Mean              0.116892
trainer/Policy mu Std               0.680362
trainer/Policy mu Max               3.2606
trainer/Policy mu Min              -2.78358
trainer/Policy log std Mean        -2.0493
trainer/Policy log std Std          0.444724
trainer/Policy log std Max         -0.459454
trainer/Policy log std Min         -2.34916
trainer/Alpha                       0.0515309
trainer/Alpha Loss                 -0.206731
exploration/num steps total     27600
exploration/num paths total       276
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.187432
exploration/Rewards Std             0.270214
exploration/Rewards Max            -0.0088563
exploration/Rewards Min            -2.49426
exploration/Returns Mean          -18.7432
exploration/Returns Std             0.216168
exploration/Returns Max           -18.5271
exploration/Returns Min           -18.9594
exploration/Actions Mean            0.0250503
exploration/Actions Std             0.193815
exploration/Actions Max             0.995361
exploration/Actions Min            -0.429184
exploration/Num Paths               2
exploration/Average Returns       -18.7432
evaluation/num steps total     137000
evaluation/num paths total       1370
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.278634
evaluation/Rewards Std              0.912363
evaluation/Rewards Max             -0.040625
evaluation/Rewards Min             -8.92922
evaluation/Returns Mean           -27.8634
evaluation/Returns Std              8.75747
evaluation/Returns Max            -17.5456
evaluation/Returns Min            -45.7716
evaluation/Actions Mean             0.0233567
evaluation/Actions Std              0.201627
evaluation/Actions Max              0.995724
evaluation/Actions Min             -0.995846
evaluation/Num Paths               10
evaluation/Average Returns        -27.8634
time/data storing (s)               0.00119181
time/evaluation sampling (s)        0.278309
time/exploration sampling (s)       0.0686448
time/logging (s)                    0.00474848
time/saving (s)                     0.00257477
time/training (s)                   1.18688
time/epoch (s)                      1.54235
time/total (s)                    200.398
Epoch                             136
-----------------------------  ---------------
2019-04-21 12:19:46.498771 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 137 finished
-----------------------------  ---------------
replay_buffer/size              27800
trainer/QF1 Loss                    1.45961
trainer/QF2 Loss                    1.47332
trainer/Policy Loss                10.8313
trainer/Q1 Predictions Mean        -9.23515
trainer/Q1 Predictions Std          4.22304
trainer/Q1 Predictions Max         -8.23072
trainer/Q1 Predictions Min        -37.0311
trainer/Q2 Predictions Mean        -9.24097
trainer/Q2 Predictions Std          4.16542
trainer/Q2 Predictions Max         -8.26066
trainer/Q2 Predictions Min        -36.7396
trainer/Q Targets Mean             -9.3514
trainer/Q Targets Std               4.50891
trainer/Q Targets Max              -0.116397
trainer/Q Targets Min             -38.847
trainer/Log Pis Mean                1.90706
trainer/Log Pis Std                 1.0928
trainer/Log Pis Max                 5.85895
trainer/Log Pis Min                -2.55274
trainer/Policy mu Mean              0.0369955
trainer/Policy mu Std               0.56268
trainer/Policy mu Max               3.01952
trainer/Policy mu Min              -1.93116
trainer/Policy log std Mean        -2.12851
trainer/Policy log std Std          0.364814
trainer/Policy log std Max         -0.491382
trainer/Policy log std Min         -2.31715
trainer/Alpha                       0.051402
trainer/Alpha Loss                 -0.275859
exploration/num steps total     27800
exploration/num paths total       278
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.185613
exploration/Rewards Std             0.333357
exploration/Rewards Max            -0.0067599
exploration/Rewards Min            -3.01846
exploration/Returns Mean          -18.5613
exploration/Returns Std             0.964214
exploration/Returns Max           -17.597
exploration/Returns Min           -19.5255
exploration/Actions Mean           -0.00527789
exploration/Actions Std             0.194926
exploration/Actions Max             0.995926
exploration/Actions Min            -0.994986
exploration/Num Paths               2
exploration/Average Returns       -18.5613
evaluation/num steps total     138000
evaluation/num paths total       1380
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.191502
evaluation/Rewards Std              0.829041
evaluation/Rewards Max             -0.0325763
evaluation/Rewards Min             -8.09942
evaluation/Returns Mean           -19.1502
evaluation/Returns Std             10.5006
evaluation/Returns Max             -5.56526
evaluation/Returns Min            -36.4577
evaluation/Actions Mean             0.0271275
evaluation/Actions Std              0.182241
evaluation/Actions Max              0.996349
evaluation/Actions Min             -0.996833
evaluation/Num Paths               10
evaluation/Average Returns        -19.1502
time/data storing (s)               0.00121787
time/evaluation sampling (s)        0.268517
time/exploration sampling (s)       0.0728582
time/logging (s)                    0.00378988
time/saving (s)                     0.00236839
time/training (s)                   1.06323
time/epoch (s)                      1.41199
time/total (s)                    201.814
Epoch                             137
-----------------------------  ---------------
2019-04-21 12:19:47.933788 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 138 finished
-----------------------------  ---------------
replay_buffer/size              28000
trainer/QF1 Loss                    0.0194495
trainer/QF2 Loss                    0.0250932
trainer/Policy Loss                11.7168
trainer/Q1 Predictions Mean        -9.845
trainer/Q1 Predictions Std          5.33074
trainer/Q1 Predictions Max         -8.44435
trainer/Q1 Predictions Min        -46.3818
trainer/Q2 Predictions Mean        -9.88814
trainer/Q2 Predictions Std          5.33069
trainer/Q2 Predictions Max         -8.50114
trainer/Q2 Predictions Min        -46.3873
trainer/Q Targets Mean             -9.87409
trainer/Q Targets Std               5.35593
trainer/Q Targets Max              -8.40877
trainer/Q Targets Min             -46.1314
trainer/Log Pis Mean                2.00089
trainer/Log Pis Std                 1.47025
trainer/Log Pis Max                 7.38902
trainer/Log Pis Min                -3.45416
trainer/Policy mu Mean              0.147466
trainer/Policy mu Std               0.676798
trainer/Policy mu Max               3.06695
trainer/Policy mu Min              -2.38478
trainer/Policy log std Mean        -2.13025
trainer/Policy log std Std          0.412232
trainer/Policy log std Max         -0.65834
trainer/Policy log std Min         -2.35188
trainer/Alpha                       0.0494646
trainer/Alpha Loss                  0.00266636
exploration/num steps total     28000
exploration/num paths total       280
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.192796
exploration/Rewards Std             0.427943
exploration/Rewards Max            -0.0172813
exploration/Rewards Min            -3.92536
exploration/Returns Mean          -19.2796
exploration/Returns Std             2.39101
exploration/Returns Max           -16.8886
exploration/Returns Min           -21.6707
exploration/Actions Mean           -0.0123983
exploration/Actions Std             0.205049
exploration/Actions Max             0.970874
exploration/Actions Min            -0.994453
exploration/Num Paths               2
exploration/Average Returns       -19.2796
evaluation/num steps total     139000
evaluation/num paths total       1390
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.213321
evaluation/Rewards Std              0.966899
evaluation/Rewards Max             -0.0119089
evaluation/Rewards Min             -8.86077
evaluation/Returns Mean           -21.3321
evaluation/Returns Std             11.4851
evaluation/Returns Max             -8.96984
evaluation/Returns Min            -42.1193
evaluation/Actions Mean             0.0221828
evaluation/Actions Std              0.198184
evaluation/Actions Max              0.99676
evaluation/Actions Min             -0.996195
evaluation/Num Paths               10
evaluation/Average Returns        -21.3321
time/data storing (s)               0.00162687
time/evaluation sampling (s)        0.263849
time/exploration sampling (s)       0.0726491
time/logging (s)                    0.00380158
time/saving (s)                     0.0023695
time/training (s)                   1.08328
time/epoch (s)                      1.42758
time/total (s)                    203.246
Epoch                             138
-----------------------------  ---------------
2019-04-21 12:19:49.380584 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 139 finished
-----------------------------  ---------------
replay_buffer/size              28200
trainer/QF1 Loss                    0.0475169
trainer/QF2 Loss                    0.0541742
trainer/Policy Loss                11.424
trainer/Q1 Predictions Mean        -9.56438
trainer/Q1 Predictions Std          4.36495
trainer/Q1 Predictions Max         -8.28458
trainer/Q1 Predictions Min        -41.4269
trainer/Q2 Predictions Mean        -9.48201
trainer/Q2 Predictions Std          4.29433
trainer/Q2 Predictions Max         -8.23253
trainer/Q2 Predictions Min        -41.1972
trainer/Q Targets Mean             -9.68878
trainer/Q Targets Std               4.26887
trainer/Q Targets Max              -8.38396
trainer/Q Targets Min             -41.2072
trainer/Log Pis Mean                1.98567
trainer/Log Pis Std                 1.18284
trainer/Log Pis Max                 6.58168
trainer/Log Pis Min                -1.71107
trainer/Policy mu Mean              0.0760307
trainer/Policy mu Std               0.698892
trainer/Policy mu Max               3.43518
trainer/Policy mu Min              -2.43591
trainer/Policy log std Mean        -2.10483
trainer/Policy log std Std          0.46201
trainer/Policy log std Max         -0.525829
trainer/Policy log std Min         -2.35881
trainer/Alpha                       0.0487128
trainer/Alpha Loss                 -0.0432919
exploration/num steps total     28200
exploration/num paths total       282
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.209678
exploration/Rewards Std             0.493303
exploration/Rewards Max            -0.0108914
exploration/Rewards Min            -5.14652
exploration/Returns Mean          -20.9678
exploration/Returns Std             6.72367
exploration/Returns Max           -14.2442
exploration/Returns Min           -27.6915
exploration/Actions Mean           -0.0126906
exploration/Actions Std             0.194585
exploration/Actions Max             0.965996
exploration/Actions Min            -0.997921
exploration/Num Paths               2
exploration/Average Returns       -20.9678
evaluation/num steps total     140000
evaluation/num paths total       1400
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.256988
evaluation/Rewards Std              0.900192
evaluation/Rewards Max             -0.0445655
evaluation/Rewards Min             -9.24245
evaluation/Returns Mean           -25.6988
evaluation/Returns Std             10.6469
evaluation/Returns Max            -12.661
evaluation/Returns Min            -46.3422
evaluation/Actions Mean             0.0355228
evaluation/Actions Std              0.191004
evaluation/Actions Max              0.996915
evaluation/Actions Min             -0.986374
evaluation/Num Paths               10
evaluation/Average Returns        -25.6988
time/data storing (s)               0.00116829
time/evaluation sampling (s)        0.268111
time/exploration sampling (s)       0.0695517
time/logging (s)                    0.00411551
time/saving (s)                     0.00286943
time/training (s)                   1.09359
time/epoch (s)                      1.43941
time/total (s)                    204.69
Epoch                             139
-----------------------------  ---------------
2019-04-21 12:19:50.944974 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 140 finished
-----------------------------  ---------------
replay_buffer/size              28400
trainer/QF1 Loss                    0.0183215
trainer/QF2 Loss                    0.0123132
trainer/Policy Loss                10.8668
trainer/Q1 Predictions Mean        -9.03102
trainer/Q1 Predictions Std          1.8102
trainer/Q1 Predictions Max         -8.49847
trainer/Q1 Predictions Min        -26.1337
trainer/Q2 Predictions Mean        -9.01257
trainer/Q2 Predictions Std          1.78391
trainer/Q2 Predictions Max         -8.47498
trainer/Q2 Predictions Min        -25.8891
trainer/Q Targets Mean             -8.95173
trainer/Q Targets Std               1.77682
trainer/Q Targets Max              -8.29709
trainer/Q Targets Min             -25.7644
trainer/Log Pis Mean                2.05225
trainer/Log Pis Std                 0.974741
trainer/Log Pis Max                 4.91414
trainer/Log Pis Min                -4.15552
trainer/Policy mu Mean             -0.040011
trainer/Policy mu Std               0.517837
trainer/Policy mu Max               2.89326
trainer/Policy mu Min              -2.32217
trainer/Policy log std Mean        -2.14467
trainer/Policy log std Std          0.356849
trainer/Policy log std Max         -0.678469
trainer/Policy log std Min         -2.34275
trainer/Alpha                       0.0500442
trainer/Alpha Loss                  0.156475
exploration/num steps total     28400
exploration/num paths total       284
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.29209
exploration/Rewards Std             0.767395
exploration/Rewards Max            -0.0108872
exploration/Rewards Min            -6.17721
exploration/Returns Mean          -29.209
exploration/Returns Std             4.61381
exploration/Returns Max           -24.5952
exploration/Returns Min           -33.8228
exploration/Actions Mean            0.0445236
exploration/Actions Std             0.234192
exploration/Actions Max             0.998164
exploration/Actions Min            -0.384142
exploration/Num Paths               2
exploration/Average Returns       -29.209
evaluation/num steps total     141000
evaluation/num paths total       1410
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.342953
evaluation/Rewards Std              1.29579
evaluation/Rewards Max             -0.0646402
evaluation/Rewards Min            -10.6414
evaluation/Returns Mean           -34.2953
evaluation/Returns Std             21.6991
evaluation/Returns Max             -7.22566
evaluation/Returns Min            -63.3321
evaluation/Actions Mean             0.0296386
evaluation/Actions Std              0.208286
evaluation/Actions Max              0.998284
evaluation/Actions Min             -0.991288
evaluation/Num Paths               10
evaluation/Average Returns        -34.2953
time/data storing (s)               0.00123126
time/evaluation sampling (s)        0.264658
time/exploration sampling (s)       0.0746131
time/logging (s)                    0.00361413
time/saving (s)                     0.00231808
time/training (s)                   1.20928
time/epoch (s)                      1.55571
time/total (s)                    206.251
Epoch                             140
-----------------------------  ---------------
2019-04-21 12:19:52.364948 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 141 finished
-----------------------------  ---------------
replay_buffer/size              28600
trainer/QF1 Loss                    0.72188
trainer/QF2 Loss                    0.70947
trainer/Policy Loss                11.0476
trainer/Q1 Predictions Mean        -9.41186
trainer/Q1 Predictions Std          4.31672
trainer/Q1 Predictions Max         -8.42291
trainer/Q1 Predictions Min        -47.0274
trainer/Q2 Predictions Mean        -9.37336
trainer/Q2 Predictions Std          4.31917
trainer/Q2 Predictions Max         -8.38219
trainer/Q2 Predictions Min        -46.9513
trainer/Q Targets Mean             -9.27762
trainer/Q Targets Std               4.35182
trainer/Q Targets Max              -0.103753
trainer/Q Targets Min             -46.2978
trainer/Log Pis Mean                1.79015
trainer/Log Pis Std                 1.42187
trainer/Log Pis Max                 6.33058
trainer/Log Pis Min                -4.89539
trainer/Policy mu Mean              0.0920844
trainer/Policy mu Std               0.589435
trainer/Policy mu Max               3.21019
trainer/Policy mu Min              -1.28951
trainer/Policy log std Mean        -2.15525
trainer/Policy log std Std          0.385067
trainer/Policy log std Max         -0.649855
trainer/Policy log std Min         -2.38379
trainer/Alpha                       0.0502443
trainer/Alpha Loss                 -0.627604
exploration/num steps total     28600
exploration/num paths total       286
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.423516
exploration/Rewards Std             1.28059
exploration/Rewards Max            -0.0113115
exploration/Rewards Min            -9.45415
exploration/Returns Mean          -42.3516
exploration/Returns Std            15.9603
exploration/Returns Max           -26.3913
exploration/Returns Min           -58.3119
exploration/Actions Mean            0.0178068
exploration/Actions Std             0.250997
exploration/Actions Max             0.99961
exploration/Actions Min            -0.998569
exploration/Num Paths               2
exploration/Average Returns       -42.3516
evaluation/num steps total     142000
evaluation/num paths total       1420
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.244594
evaluation/Rewards Std              1.03003
evaluation/Rewards Max             -0.0245649
evaluation/Rewards Min            -10.8723
evaluation/Returns Mean           -24.4594
evaluation/Returns Std             16.2777
evaluation/Returns Max             -5.33212
evaluation/Returns Min            -58.5528
evaluation/Actions Mean             0.0127626
evaluation/Actions Std              0.19253
evaluation/Actions Max              0.998032
evaluation/Actions Min             -0.997004
evaluation/Num Paths               10
evaluation/Average Returns        -24.4594
time/data storing (s)               0.00125903
time/evaluation sampling (s)        0.26382
time/exploration sampling (s)       0.0703141
time/logging (s)                    0.00416228
time/saving (s)                     0.00269706
time/training (s)                   1.07144
time/epoch (s)                      1.41369
time/total (s)                    207.67
Epoch                             141
-----------------------------  ---------------
2019-04-21 12:19:53.824014 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 142 finished
-----------------------------  ---------------
replay_buffer/size              28800
trainer/QF1 Loss                    0.696953
trainer/QF2 Loss                    0.681812
trainer/Policy Loss                11.1319
trainer/Q1 Predictions Mean        -9.09039
trainer/Q1 Predictions Std          2.77278
trainer/Q1 Predictions Max         -8.2446
trainer/Q1 Predictions Min        -27.7699
trainer/Q2 Predictions Mean        -9.13294
trainer/Q2 Predictions Std          2.79163
trainer/Q2 Predictions Max         -8.29575
trainer/Q2 Predictions Min        -28.2978
trainer/Q Targets Mean             -9.03899
trainer/Q Targets Std               2.89485
trainer/Q Targets Max              -0.502552
trainer/Q Targets Min             -28.4511
trainer/Log Pis Mean                2.20099
trainer/Log Pis Std                 1.02251
trainer/Log Pis Max                 6.0081
trainer/Log Pis Min                -2.1136
trainer/Policy mu Mean              0.0493772
trainer/Policy mu Std               0.624939
trainer/Policy mu Max               3.02617
trainer/Policy mu Min              -3.349
trainer/Policy log std Mean        -2.19329
trainer/Policy log std Std          0.420581
trainer/Policy log std Max         -0.522479
trainer/Policy log std Min         -2.41464
trainer/Alpha                       0.0512706
trainer/Alpha Loss                  0.597117
exploration/num steps total     28800
exploration/num paths total       288
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.45574
exploration/Rewards Std             1.3274
exploration/Rewards Max            -0.00497302
exploration/Rewards Min            -8.03687
exploration/Returns Mean          -45.574
exploration/Returns Std             0.386004
exploration/Returns Max           -45.188
exploration/Returns Min           -45.96
exploration/Actions Mean            0.0341585
exploration/Actions Std             0.247711
exploration/Actions Max             0.997815
exploration/Actions Min            -0.846769
exploration/Num Paths               2
exploration/Average Returns       -45.574
evaluation/num steps total     143000
evaluation/num paths total       1430
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.199601
evaluation/Rewards Std              0.943811
evaluation/Rewards Max             -0.0115024
evaluation/Rewards Min             -9.98303
evaluation/Returns Mean           -19.9601
evaluation/Returns Std             16.508
evaluation/Returns Max             -2.614
evaluation/Returns Min            -56.4214
evaluation/Actions Mean             0.0171873
evaluation/Actions Std              0.179802
evaluation/Actions Max              0.997078
evaluation/Actions Min             -0.997159
evaluation/Num Paths               10
evaluation/Average Returns        -19.9601
time/data storing (s)               0.00142126
time/evaluation sampling (s)        0.266284
time/exploration sampling (s)       0.0662184
time/logging (s)                    0.00449335
time/saving (s)                     0.00258866
time/training (s)                   1.11091
time/epoch (s)                      1.45191
time/total (s)                    209.126
Epoch                             142
-----------------------------  ---------------
2019-04-21 12:19:55.536389 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 143 finished
-----------------------------  ---------------
replay_buffer/size              29000
trainer/QF1 Loss                    0.713118
trainer/QF2 Loss                    0.732295
trainer/Policy Loss                11.0292
trainer/Q1 Predictions Mean        -9.28571
trainer/Q1 Predictions Std          3.28537
trainer/Q1 Predictions Max         -8.2795
trainer/Q1 Predictions Min        -29.3182
trainer/Q2 Predictions Mean        -9.32627
trainer/Q2 Predictions Std          3.26883
trainer/Q2 Predictions Max         -8.36319
trainer/Q2 Predictions Min        -29.1783
trainer/Q Targets Mean             -9.20154
trainer/Q Targets Std               3.52657
trainer/Q Targets Max              -0.776671
trainer/Q Targets Min             -30.6386
trainer/Log Pis Mean                1.92048
trainer/Log Pis Std                 1.03041
trainer/Log Pis Max                 5.51149
trainer/Log Pis Min                -1.37663
trainer/Policy mu Mean              0.101282
trainer/Policy mu Std               0.597065
trainer/Policy mu Max               3.2427
trainer/Policy mu Min              -1.78855
trainer/Policy log std Mean        -2.18775
trainer/Policy log std Std          0.40524
trainer/Policy log std Max         -0.385443
trainer/Policy log std Min         -2.41575
trainer/Alpha                       0.0530156
trainer/Alpha Loss                 -0.233576
exploration/num steps total     29000
exploration/num paths total       290
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.148775
exploration/Rewards Std             0.286161
exploration/Rewards Max            -0.00670163
exploration/Rewards Min            -3.20871
exploration/Returns Mean          -14.8775
exploration/Returns Std             3.41462
exploration/Returns Max           -11.4629
exploration/Returns Min           -18.2921
exploration/Actions Mean           -0.0139889
exploration/Actions Std             0.175465
exploration/Actions Max             0.666869
exploration/Actions Min            -0.998362
exploration/Num Paths               2
exploration/Average Returns       -14.8775
evaluation/num steps total     144000
evaluation/num paths total       1440
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.285467
evaluation/Rewards Std              1.16999
evaluation/Rewards Max             -0.0160791
evaluation/Rewards Min            -10.3563
evaluation/Returns Mean           -28.5467
evaluation/Returns Std             16.013
evaluation/Returns Max             -3.35225
evaluation/Returns Min            -56.2654
evaluation/Actions Mean             0.0300465
evaluation/Actions Std              0.199904
evaluation/Actions Max              0.996316
evaluation/Actions Min             -0.988303
evaluation/Num Paths               10
evaluation/Average Returns        -28.5467
time/data storing (s)               0.00122256
time/evaluation sampling (s)        0.275004
time/exploration sampling (s)       0.0723976
time/logging (s)                    0.00412926
time/saving (s)                     0.00283432
time/training (s)                   1.34908
time/epoch (s)                      1.70466
time/total (s)                    210.835
Epoch                             143
-----------------------------  ---------------
2019-04-21 12:19:57.507972 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 144 finished
-----------------------------  ---------------
replay_buffer/size              29200
trainer/QF1 Loss                    1.9831
trainer/QF2 Loss                    1.99618
trainer/Policy Loss                11.5972
trainer/Q1 Predictions Mean        -9.85309
trainer/Q1 Predictions Std          6.90169
trainer/Q1 Predictions Max         -8.1197
trainer/Q1 Predictions Min        -54.0562
trainer/Q2 Predictions Mean        -9.88445
trainer/Q2 Predictions Std          6.91618
trainer/Q2 Predictions Max         -8.13004
trainer/Q2 Predictions Min        -54.3637
trainer/Q Targets Mean             -9.7018
trainer/Q Targets Std               7.03313
trainer/Q Targets Max              -0.0424102
trainer/Q Targets Min             -53.7401
trainer/Log Pis Mean                2.04937
trainer/Log Pis Std                 1.16512
trainer/Log Pis Max                 5.04171
trainer/Log Pis Min                -4.23309
trainer/Policy mu Mean              0.184723
trainer/Policy mu Std               0.62265
trainer/Policy mu Max               3.03457
trainer/Policy mu Min              -0.947512
trainer/Policy log std Mean        -2.16522
trainer/Policy log std Std          0.426306
trainer/Policy log std Max         -0.510187
trainer/Policy log std Min         -2.40552
trainer/Alpha                       0.0528064
trainer/Alpha Loss                  0.145206
exploration/num steps total     29200
exploration/num paths total       292
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.396404
exploration/Rewards Std             1.12367
exploration/Rewards Max            -0.00895023
exploration/Rewards Min            -7.51144
exploration/Returns Mean          -39.6404
exploration/Returns Std             1.64609
exploration/Returns Max           -37.9943
exploration/Returns Min           -41.2865
exploration/Actions Mean            0.0321517
exploration/Actions Std             0.246306
exploration/Actions Max             0.99784
exploration/Actions Min            -0.963542
exploration/Num Paths               2
exploration/Average Returns       -39.6404
evaluation/num steps total     145000
evaluation/num paths total       1450
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.175297
evaluation/Rewards Std              0.787942
evaluation/Rewards Max             -0.00733913
evaluation/Rewards Min             -8.02055
evaluation/Returns Mean           -17.5297
evaluation/Returns Std             11.1672
evaluation/Returns Max             -3.90121
evaluation/Returns Min            -38.3392
evaluation/Actions Mean             0.0169801
evaluation/Actions Std              0.176634
evaluation/Actions Max              0.995953
evaluation/Actions Min             -0.995013
evaluation/Num Paths               10
evaluation/Average Returns        -17.5297
time/data storing (s)               0.00135355
time/evaluation sampling (s)        0.307358
time/exploration sampling (s)       0.11889
time/logging (s)                    0.00402048
time/saving (s)                     0.00288673
time/training (s)                   1.52896
time/epoch (s)                      1.96347
time/total (s)                    212.804
Epoch                             144
-----------------------------  ---------------
2019-04-21 12:19:59.668385 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 145 finished
-----------------------------  ---------------
replay_buffer/size              29400
trainer/QF1 Loss                    0.0456926
trainer/QF2 Loss                    0.0315978
trainer/Policy Loss                11.9211
trainer/Q1 Predictions Mean       -10.2749
trainer/Q1 Predictions Std          6.74028
trainer/Q1 Predictions Max         -8.09799
trainer/Q1 Predictions Min        -44.6431
trainer/Q2 Predictions Mean       -10.3475
trainer/Q2 Predictions Std          6.77911
trainer/Q2 Predictions Max         -8.21007
trainer/Q2 Predictions Min        -44.5542
trainer/Q Targets Mean            -10.3362
trainer/Q Targets Std               6.71187
trainer/Q Targets Max              -8.12798
trainer/Q Targets Min             -44.3314
trainer/Log Pis Mean                1.8678
trainer/Log Pis Std                 1.62687
trainer/Log Pis Max                 7.75387
trainer/Log Pis Min                -3.23953
trainer/Policy mu Mean              0.0785899
trainer/Policy mu Std               0.79159
trainer/Policy mu Max               3.58652
trainer/Policy mu Min              -3.11911
trainer/Policy log std Mean        -2.06595
trainer/Policy log std Std          0.425223
trainer/Policy log std Max         -0.555282
trainer/Policy log std Min         -2.33915
trainer/Alpha                       0.052977
trainer/Alpha Loss                 -0.388356
exploration/num steps total     29400
exploration/num paths total       294
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.243847
exploration/Rewards Std             0.591699
exploration/Rewards Max            -0.00474613
exploration/Rewards Min            -5.57852
exploration/Returns Mean          -24.3847
exploration/Returns Std             5.40593
exploration/Returns Max           -18.9788
exploration/Returns Min           -29.7907
exploration/Actions Mean            0.0158537
exploration/Actions Std             0.22615
exploration/Actions Max             0.997905
exploration/Actions Min            -0.971072
exploration/Num Paths               2
exploration/Average Returns       -24.3847
evaluation/num steps total     146000
evaluation/num paths total       1460
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.207741
evaluation/Rewards Std              0.985453
evaluation/Rewards Max             -0.0103045
evaluation/Rewards Min            -10.6041
evaluation/Returns Mean           -20.7741
evaluation/Returns Std             18.8793
evaluation/Returns Max             -3.97259
evaluation/Returns Min            -57.605
evaluation/Actions Mean             0.0298622
evaluation/Actions Std              0.185055
evaluation/Actions Max              0.99831
evaluation/Actions Min             -0.996265
evaluation/Num Paths               10
evaluation/Average Returns        -20.7741
time/data storing (s)               0.00154395
time/evaluation sampling (s)        0.358753
time/exploration sampling (s)       0.150709
time/logging (s)                    0.00353007
time/saving (s)                     0.00258449
time/training (s)                   1.63474
time/epoch (s)                      2.15186
time/total (s)                    214.961
Epoch                             145
-----------------------------  ---------------
2019-04-21 12:20:01.342104 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 146 finished
-----------------------------  ---------------
replay_buffer/size              29600
trainer/QF1 Loss                    0.0457143
trainer/QF2 Loss                    0.0289892
trainer/Policy Loss                10.8121
trainer/Q1 Predictions Mean        -9.13084
trainer/Q1 Predictions Std          4.38791
trainer/Q1 Predictions Max         -7.9861
trainer/Q1 Predictions Min        -42.3926
trainer/Q2 Predictions Mean        -9.22892
trainer/Q2 Predictions Std          4.40906
trainer/Q2 Predictions Max         -8.10602
trainer/Q2 Predictions Min        -42.7846
trainer/Q Targets Mean             -9.28378
trainer/Q Targets Std               4.29906
trainer/Q Targets Max              -8.05652
trainer/Q Targets Min             -41.7893
trainer/Log Pis Mean                1.86074
trainer/Log Pis Std                 1.22061
trainer/Log Pis Max                 4.54885
trainer/Log Pis Min                -2.88123
trainer/Policy mu Mean              0.150351
trainer/Policy mu Std               0.637218
trainer/Policy mu Max               2.90853
trainer/Policy mu Min              -1.75319
trainer/Policy log std Mean        -2.14208
trainer/Policy log std Std          0.455037
trainer/Policy log std Max         -0.561725
trainer/Policy log std Min         -2.422
trainer/Alpha                       0.0540457
trainer/Alpha Loss                 -0.406331
exploration/num steps total     29600
exploration/num paths total       296
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.174912
exploration/Rewards Std             0.338152
exploration/Rewards Max            -0.00222913
exploration/Rewards Min            -3.1605
exploration/Returns Mean          -17.4912
exploration/Returns Std             1.15847
exploration/Returns Max           -16.3327
exploration/Returns Min           -18.6497
exploration/Actions Mean            0.0245657
exploration/Actions Std             0.187106
exploration/Actions Max             0.996033
exploration/Actions Min            -0.340826
exploration/Num Paths               2
exploration/Average Returns       -17.4912
evaluation/num steps total     147000
evaluation/num paths total       1470
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.210719
evaluation/Rewards Std              0.926721
evaluation/Rewards Max             -0.0203511
evaluation/Rewards Min            -10.1555
evaluation/Returns Mean           -21.0719
evaluation/Returns Std             17.0346
evaluation/Returns Max             -4.58868
evaluation/Returns Min            -60.8148
evaluation/Actions Mean             0.0200323
evaluation/Actions Std              0.170864
evaluation/Actions Max              0.995888
evaluation/Actions Min             -0.993539
evaluation/Num Paths               10
evaluation/Average Returns        -21.0719
time/data storing (s)               0.00154212
time/evaluation sampling (s)        0.327933
time/exploration sampling (s)       0.0967665
time/logging (s)                    0.0033194
time/saving (s)                     0.00300624
time/training (s)                   1.23315
time/epoch (s)                      1.66571
time/total (s)                    216.632
Epoch                             146
-----------------------------  ---------------
2019-04-21 12:20:03.122453 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 147 finished
-----------------------------  ---------------
replay_buffer/size              29800
trainer/QF1 Loss                    0.0125754
trainer/QF2 Loss                    0.0176171
trainer/Policy Loss                10.9421
trainer/Q1 Predictions Mean        -8.87373
trainer/Q1 Predictions Std          3.03349
trainer/Q1 Predictions Max         -8.1808
trainer/Q1 Predictions Min        -33.9229
trainer/Q2 Predictions Mean        -8.92443
trainer/Q2 Predictions Std          3.08925
trainer/Q2 Predictions Max         -8.21954
trainer/Q2 Predictions Min        -34.3564
trainer/Q Targets Mean             -8.8301
trainer/Q Targets Std               3.06959
trainer/Q Targets Max              -8.03542
trainer/Q Targets Min             -34.3244
trainer/Log Pis Mean                2.10378
trainer/Log Pis Std                 0.999581
trainer/Log Pis Max                 4.69872
trainer/Log Pis Min                -1.9905
trainer/Policy mu Mean              0.0607413
trainer/Policy mu Std               0.537138
trainer/Policy mu Max               3.00502
trainer/Policy mu Min              -1.78836
trainer/Policy log std Mean        -2.23759
trainer/Policy log std Std          0.375681
trainer/Policy log std Max         -0.657571
trainer/Policy log std Min         -2.44655
trainer/Alpha                       0.0528817
trainer/Alpha Loss                  0.30508
exploration/num steps total     29800
exploration/num paths total       298
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.427062
exploration/Rewards Std             1.30282
exploration/Rewards Max            -0.0171095
exploration/Rewards Min            -9.21232
exploration/Returns Mean          -42.7062
exploration/Returns Std            12.7202
exploration/Returns Max           -29.986
exploration/Returns Min           -55.4264
exploration/Actions Mean            0.0419711
exploration/Actions Std             0.250097
exploration/Actions Max             0.998059
exploration/Actions Min            -0.774053
exploration/Num Paths               2
exploration/Average Returns       -42.7062
evaluation/num steps total     148000
evaluation/num paths total       1480
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.128991
evaluation/Rewards Std              0.67401
evaluation/Rewards Max             -0.00581034
evaluation/Rewards Min             -7.85281
evaluation/Returns Mean           -12.8991
evaluation/Returns Std              8.69786
evaluation/Returns Max             -3.88723
evaluation/Returns Min            -34.9593
evaluation/Actions Mean             0.00186723
evaluation/Actions Std              0.173484
evaluation/Actions Max              0.995156
evaluation/Actions Min             -0.996466
evaluation/Num Paths               10
evaluation/Average Returns        -12.8991
time/data storing (s)               0.00148821
time/evaluation sampling (s)        0.320653
time/exploration sampling (s)       0.112781
time/logging (s)                    0.005089
time/saving (s)                     0.00320883
time/training (s)                   1.33107
time/epoch (s)                      1.77429
time/total (s)                    218.411
Epoch                             147
-----------------------------  ---------------
2019-04-21 12:20:04.826987 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 148 finished
-----------------------------  ---------------
replay_buffer/size              30000
trainer/QF1 Loss                    1.29153
trainer/QF2 Loss                    1.28487
trainer/Policy Loss                11.2567
trainer/Q1 Predictions Mean        -9.12713
trainer/Q1 Predictions Std          4.02304
trainer/Q1 Predictions Max         -8.00754
trainer/Q1 Predictions Min        -36.1774
trainer/Q2 Predictions Mean        -9.13377
trainer/Q2 Predictions Std          4.04882
trainer/Q2 Predictions Max         -8.0333
trainer/Q2 Predictions Min        -35.9713
trainer/Q Targets Mean             -9.01812
trainer/Q Targets Std               4.22453
trainer/Q Targets Max              -0.0841152
trainer/Q Targets Min             -36.0102
trainer/Log Pis Mean                2.4134
trainer/Log Pis Std                 1.01938
trainer/Log Pis Max                 6.53287
trainer/Log Pis Min                -0.40153
trainer/Policy mu Mean              0.00654198
trainer/Policy mu Std               0.639246
trainer/Policy mu Max               2.72295
trainer/Policy mu Min              -3.52605
trainer/Policy log std Mean        -2.26232
trainer/Policy log std Std          0.444435
trainer/Policy log std Max         -0.5736
trainer/Policy log std Min         -2.51493
trainer/Alpha                       0.05309
trainer/Alpha Loss                  1.21379
exploration/num steps total     30000
exploration/num paths total       300
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.397566
exploration/Rewards Std             1.32631
exploration/Rewards Max            -0.010244
exploration/Rewards Min           -10.3102
exploration/Returns Mean          -39.7566
exploration/Returns Std            24.9283
exploration/Returns Max           -14.8283
exploration/Returns Min           -64.6849
exploration/Actions Mean            0.0474481
exploration/Actions Std             0.239056
exploration/Actions Max             0.999444
exploration/Actions Min            -0.364474
exploration/Num Paths               2
exploration/Average Returns       -39.7566
evaluation/num steps total     149000
evaluation/num paths total       1490
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.199544
evaluation/Rewards Std              0.865407
evaluation/Rewards Max             -0.0136057
evaluation/Rewards Min             -9.46266
evaluation/Returns Mean           -19.9544
evaluation/Returns Std             14.0059
evaluation/Returns Max             -6.42088
evaluation/Returns Min            -53.2967
evaluation/Actions Mean             0.0177847
evaluation/Actions Std              0.181925
evaluation/Actions Max              0.996164
evaluation/Actions Min             -0.996631
evaluation/Num Paths               10
evaluation/Average Returns        -19.9544
time/data storing (s)               0.00159488
time/evaluation sampling (s)        0.307936
time/exploration sampling (s)       0.0857576
time/logging (s)                    0.00354232
time/saving (s)                     0.00239486
time/training (s)                   1.2913
time/epoch (s)                      1.69253
time/total (s)                    220.11
Epoch                             148
-----------------------------  ---------------
2019-04-21 12:20:06.443019 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 149 finished
-----------------------------  ---------------
replay_buffer/size              30200
trainer/QF1 Loss                    0.0667809
trainer/QF2 Loss                    0.0644296
trainer/Policy Loss                11.016
trainer/Q1 Predictions Mean        -9.19344
trainer/Q1 Predictions Std          4.11472
trainer/Q1 Predictions Max         -7.88661
trainer/Q1 Predictions Min        -33.8999
trainer/Q2 Predictions Mean        -9.20233
trainer/Q2 Predictions Std          4.10344
trainer/Q2 Predictions Max         -7.92764
trainer/Q2 Predictions Min        -34.2396
trainer/Q Targets Mean             -9.39245
trainer/Q Targets Std               4.10612
trainer/Q Targets Max              -8.00202
trainer/Q Targets Min             -34.3864
trainer/Log Pis Mean                2.06289
trainer/Log Pis Std                 1.29585
trainer/Log Pis Max                 6.47006
trainer/Log Pis Min                -3.22671
trainer/Policy mu Mean              0.110636
trainer/Policy mu Std               0.690494
trainer/Policy mu Max               2.92196
trainer/Policy mu Min              -2.82191
trainer/Policy log std Mean        -2.11229
trainer/Policy log std Std          0.467396
trainer/Policy log std Max         -0.621037
trainer/Policy log std Min         -2.38952
trainer/Alpha                       0.053392
trainer/Alpha Loss                  0.18427
exploration/num steps total     30200
exploration/num paths total       302
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.125018
exploration/Rewards Std             0.127921
exploration/Rewards Max            -0.00943201
exploration/Rewards Min            -1.60206
exploration/Returns Mean          -12.5018
exploration/Returns Std             1.3488
exploration/Returns Max           -11.153
exploration/Returns Min           -13.8506
exploration/Actions Mean            0.00737138
exploration/Actions Std             0.164028
exploration/Actions Max             0.994923
exploration/Actions Min            -0.869692
exploration/Num Paths               2
exploration/Average Returns       -12.5018
evaluation/num steps total     150000
evaluation/num paths total       1500
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.260132
evaluation/Rewards Std              1.15381
evaluation/Rewards Max             -0.0161269
evaluation/Rewards Min            -10.199
evaluation/Returns Mean           -26.0132
evaluation/Returns Std             18.7196
evaluation/Returns Max             -3.53068
evaluation/Returns Min            -56.6914
evaluation/Actions Mean             0.0280872
evaluation/Actions Std              0.192586
evaluation/Actions Max              0.997618
evaluation/Actions Min             -0.997475
evaluation/Num Paths               10
evaluation/Average Returns        -26.0132
time/data storing (s)               0.00125024
time/evaluation sampling (s)        0.271593
time/exploration sampling (s)       0.0776972
time/logging (s)                    0.00380254
time/saving (s)                     0.00275592
time/training (s)                   1.25287
time/epoch (s)                      1.60997
time/total (s)                    221.724
Epoch                             149
-----------------------------  ---------------
2019-04-21 12:20:08.245387 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 150 finished
-----------------------------  ---------------
replay_buffer/size              30400
trainer/QF1 Loss                    0.862258
trainer/QF2 Loss                    0.968152
trainer/Policy Loss                11.5702
trainer/Q1 Predictions Mean        -9.8629
trainer/Q1 Predictions Std          7.85965
trainer/Q1 Predictions Max         -7.9719
trainer/Q1 Predictions Min        -69.292
trainer/Q2 Predictions Mean        -9.95336
trainer/Q2 Predictions Std          7.73998
trainer/Q2 Predictions Max         -8.1045
trainer/Q2 Predictions Min        -68.2221
trainer/Q Targets Mean             -9.90002
trainer/Q Targets Std               8.24487
trainer/Q Targets Max              -0.10439
trainer/Q Targets Min             -73.2874
trainer/Log Pis Mean                1.96276
trainer/Log Pis Std                 1.0568
trainer/Log Pis Max                 5.17304
trainer/Log Pis Min                -2.26517
trainer/Policy mu Mean              0.0709093
trainer/Policy mu Std               0.65684
trainer/Policy mu Max               3.35757
trainer/Policy mu Min              -2.74781
trainer/Policy log std Mean        -2.08887
trainer/Policy log std Std          0.438935
trainer/Policy log std Max         -0.308787
trainer/Policy log std Min         -2.33015
trainer/Alpha                       0.0530569
trainer/Alpha Loss                 -0.109358
exploration/num steps total     30400
exploration/num paths total       304
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.420668
exploration/Rewards Std             1.24273
exploration/Rewards Max            -0.002253
exploration/Rewards Min            -8.47015
exploration/Returns Mean          -42.0668
exploration/Returns Std             4.56017
exploration/Returns Max           -37.5066
exploration/Returns Min           -46.627
exploration/Actions Mean            0.0402442
exploration/Actions Std             0.267307
exploration/Actions Max             0.998931
exploration/Actions Min            -0.942794
exploration/Num Paths               2
exploration/Average Returns       -42.0668
evaluation/num steps total     151000
evaluation/num paths total       1510
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.261795
evaluation/Rewards Std              1.16662
evaluation/Rewards Max             -0.0125823
evaluation/Rewards Min            -10.1624
evaluation/Returns Mean           -26.1795
evaluation/Returns Std             17.802
evaluation/Returns Max             -3.60568
evaluation/Returns Min            -58.0019
evaluation/Actions Mean             0.0293518
evaluation/Actions Std              0.208013
evaluation/Actions Max              0.997157
evaluation/Actions Min             -0.995822
evaluation/Num Paths               10
evaluation/Average Returns        -26.1795
time/data storing (s)               0.00158217
time/evaluation sampling (s)        0.295846
time/exploration sampling (s)       0.133391
time/logging (s)                    0.00461087
time/saving (s)                     0.00268618
time/training (s)                   1.35834
time/epoch (s)                      1.79646
time/total (s)                    223.524
Epoch                             150
-----------------------------  ---------------
2019-04-21 12:20:09.687963 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 151 finished
-----------------------------  ---------------
replay_buffer/size              30600
trainer/QF1 Loss                    0.0282499
trainer/QF2 Loss                    0.0162731
trainer/Policy Loss                10.9343
trainer/Q1 Predictions Mean        -9.32706
trainer/Q1 Predictions Std          4.66767
trainer/Q1 Predictions Max         -7.94919
trainer/Q1 Predictions Min        -38.9324
trainer/Q2 Predictions Mean        -9.32967
trainer/Q2 Predictions Std          4.5915
trainer/Q2 Predictions Max         -7.97046
trainer/Q2 Predictions Min        -38.7105
trainer/Q Targets Mean             -9.39268
trainer/Q Targets Std               4.64356
trainer/Q Targets Max              -7.96661
trainer/Q Targets Min             -38.9285
trainer/Log Pis Mean                2.06696
trainer/Log Pis Std                 1.37237
trainer/Log Pis Max                 7.68771
trainer/Log Pis Min                -1.8226
trainer/Policy mu Mean              0.130216
trainer/Policy mu Std               0.729269
trainer/Policy mu Max               3.18344
trainer/Policy mu Min              -2.72244
trainer/Policy log std Mean        -2.0738
trainer/Policy log std Std          0.488742
trainer/Policy log std Max         -0.466248
trainer/Policy log std Min         -2.3462
trainer/Alpha                       0.0518037
trainer/Alpha Loss                  0.198225
exploration/num steps total     30600
exploration/num paths total       306
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.176783
exploration/Rewards Std             0.271961
exploration/Rewards Max            -0.0144694
exploration/Rewards Min            -2.75397
exploration/Returns Mean          -17.6783
exploration/Returns Std             1.41743
exploration/Returns Max           -16.2609
exploration/Returns Min           -19.0957
exploration/Actions Mean           -0.00559084
exploration/Actions Std             0.196474
exploration/Actions Max             0.938856
exploration/Actions Min            -0.993349
exploration/Num Paths               2
exploration/Average Returns       -17.6783
evaluation/num steps total     152000
evaluation/num paths total       1520
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.190524
evaluation/Rewards Std              0.746734
evaluation/Rewards Max             -0.0458111
evaluation/Rewards Min             -9.80104
evaluation/Returns Mean           -19.0524
evaluation/Returns Std             14.8239
evaluation/Returns Max             -7.5347
evaluation/Returns Min            -59.6638
evaluation/Actions Mean             0.0128821
evaluation/Actions Std              0.163018
evaluation/Actions Max              0.996105
evaluation/Actions Min             -0.99742
evaluation/Num Paths               10
evaluation/Average Returns        -19.0524
time/data storing (s)               0.00117676
time/evaluation sampling (s)        0.283788
time/exploration sampling (s)       0.0723568
time/logging (s)                    0.00395688
time/saving (s)                     0.00184557
time/training (s)                   1.07156
time/epoch (s)                      1.43468
time/total (s)                    224.963
Epoch                             151
-----------------------------  ---------------
2019-04-21 12:20:11.164743 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 152 finished
-----------------------------  ---------------
replay_buffer/size              30800
trainer/QF1 Loss                    0.144901
trainer/QF2 Loss                    0.127605
trainer/Policy Loss                10.5588
trainer/Q1 Predictions Mean        -8.94093
trainer/Q1 Predictions Std          5.18801
trainer/Q1 Predictions Max         -7.73616
trainer/Q1 Predictions Min        -51.3335
trainer/Q2 Predictions Mean        -8.98217
trainer/Q2 Predictions Std          5.2881
trainer/Q2 Predictions Max         -7.76675
trainer/Q2 Predictions Min        -52.228
trainer/Q Targets Mean             -9.21898
trainer/Q Targets Std               5.25507
trainer/Q Targets Max              -7.89521
trainer/Q Targets Min             -51.9599
trainer/Log Pis Mean                1.85951
trainer/Log Pis Std                 1.0614
trainer/Log Pis Max                 5.24261
trainer/Log Pis Min                -1.2848
trainer/Policy mu Mean              0.0162155
trainer/Policy mu Std               0.566499
trainer/Policy mu Max               3.14167
trainer/Policy mu Min              -1.05276
trainer/Policy log std Mean        -2.15335
trainer/Policy log std Std          0.368314
trainer/Policy log std Max         -0.546158
trainer/Policy log std Min         -2.34377
trainer/Alpha                       0.0532819
trainer/Alpha Loss                 -0.411941
exploration/num steps total     30800
exploration/num paths total       308
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.423912
exploration/Rewards Std             1.15316
exploration/Rewards Max            -0.0127248
exploration/Rewards Min            -7.8133
exploration/Returns Mean          -42.3912
exploration/Returns Std             1.5261
exploration/Returns Max           -40.8651
exploration/Returns Min           -43.9173
exploration/Actions Mean            0.0369791
exploration/Actions Std             0.260589
exploration/Actions Max             0.998807
exploration/Actions Min            -0.971429
exploration/Num Paths               2
exploration/Average Returns       -42.3912
evaluation/num steps total     153000
evaluation/num paths total       1530
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.260429
evaluation/Rewards Std              0.880621
evaluation/Rewards Max             -0.0175025
evaluation/Rewards Min             -8.86749
evaluation/Returns Mean           -26.0429
evaluation/Returns Std             12.9735
evaluation/Returns Max             -9.83838
evaluation/Returns Min            -52.4255
evaluation/Actions Mean             0.0345993
evaluation/Actions Std              0.177475
evaluation/Actions Max              0.997584
evaluation/Actions Min             -0.464343
evaluation/Num Paths               10
evaluation/Average Returns        -26.0429
time/data storing (s)               0.00131826
time/evaluation sampling (s)        0.265131
time/exploration sampling (s)       0.0701877
time/logging (s)                    0.00363503
time/saving (s)                     0.00282997
time/training (s)                   1.12678
time/epoch (s)                      1.46988
time/total (s)                    226.437
Epoch                             152
-----------------------------  ---------------
2019-04-21 12:20:12.642196 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 153 finished
-----------------------------  ---------------
replay_buffer/size              31000
trainer/QF1 Loss                    1.26516
trainer/QF2 Loss                    1.24614
trainer/Policy Loss                11.582
trainer/Q1 Predictions Mean        -9.96474
trainer/Q1 Predictions Std          8.64778
trainer/Q1 Predictions Max         -7.78743
trainer/Q1 Predictions Min        -70.5064
trainer/Q2 Predictions Mean        -9.996
trainer/Q2 Predictions Std          8.6454
trainer/Q2 Predictions Max         -7.82742
trainer/Q2 Predictions Min        -70.9719
trainer/Q Targets Mean             -9.95777
trainer/Q Targets Std               8.77379
trainer/Q Targets Max              -0.122671
trainer/Q Targets Min             -71.8835
trainer/Log Pis Mean                2.02512
trainer/Log Pis Std                 1.25661
trainer/Log Pis Max                 7.69159
trainer/Log Pis Min                -1.34126
trainer/Policy mu Mean              0.0856424
trainer/Policy mu Std               0.697367
trainer/Policy mu Max               3.37184
trainer/Policy mu Min              -1.90563
trainer/Policy log std Mean        -2.0977
trainer/Policy log std Std          0.464078
trainer/Policy log std Max         -0.514471
trainer/Policy log std Min         -2.34781
trainer/Alpha                       0.0536416
trainer/Alpha Loss                  0.0734726
exploration/num steps total     31000
exploration/num paths total       310
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.290669
exploration/Rewards Std             0.731105
exploration/Rewards Max            -0.0124446
exploration/Rewards Min            -5.30099
exploration/Returns Mean          -29.0669
exploration/Returns Std             0.917196
exploration/Returns Max           -28.1497
exploration/Returns Min           -29.9841
exploration/Actions Mean            0.00121025
exploration/Actions Std             0.225778
exploration/Actions Max             0.994539
exploration/Actions Min            -0.999324
exploration/Num Paths               2
exploration/Average Returns       -29.0669
evaluation/num steps total     154000
evaluation/num paths total       1540
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.224515
evaluation/Rewards Std              0.800353
evaluation/Rewards Max             -0.0763385
evaluation/Rewards Min             -9.14784
evaluation/Returns Mean           -22.4515
evaluation/Returns Std             10.8044
evaluation/Returns Max            -10.4871
evaluation/Returns Min            -44.8516
evaluation/Actions Mean             0.0222127
evaluation/Actions Std              0.180888
evaluation/Actions Max              0.994845
evaluation/Actions Min             -0.997306
evaluation/Num Paths               10
evaluation/Average Returns        -22.4515
time/data storing (s)               0.00121353
time/evaluation sampling (s)        0.275618
time/exploration sampling (s)       0.0699995
time/logging (s)                    0.00369203
time/saving (s)                     0.00237069
time/training (s)                   1.11661
time/epoch (s)                      1.4695
time/total (s)                    227.912
Epoch                             153
-----------------------------  ---------------
2019-04-21 12:20:14.165451 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 154 finished
-----------------------------  ---------------
replay_buffer/size              31200
trainer/QF1 Loss                    0.646166
trainer/QF2 Loss                    0.645815
trainer/Policy Loss                11.3761
trainer/Q1 Predictions Mean        -9.44148
trainer/Q1 Predictions Std          5.8924
trainer/Q1 Predictions Max         -7.76818
trainer/Q1 Predictions Min        -47.9577
trainer/Q2 Predictions Mean        -9.47304
trainer/Q2 Predictions Std          5.84284
trainer/Q2 Predictions Max         -7.80837
trainer/Q2 Predictions Min        -47.8409
trainer/Q Targets Mean             -9.47163
trainer/Q Targets Std               5.89062
trainer/Q Targets Max              -0.0829586
trainer/Q Targets Min             -47.91
trainer/Log Pis Mean                2.10164
trainer/Log Pis Std                 1.32424
trainer/Log Pis Max                 8.93612
trainer/Log Pis Min                -1.43142
trainer/Policy mu Mean              0.0357081
trainer/Policy mu Std               0.693608
trainer/Policy mu Max               3.09378
trainer/Policy mu Min              -2.74389
trainer/Policy log std Mean        -2.11757
trainer/Policy log std Std          0.433556
trainer/Policy log std Max         -0.571168
trainer/Policy log std Min         -2.36418
trainer/Alpha                       0.0528235
trainer/Alpha Loss                  0.298904
exploration/num steps total     31200
exploration/num paths total       312
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.307998
exploration/Rewards Std             0.952912
exploration/Rewards Max            -0.0020102
exploration/Rewards Min            -7.71252
exploration/Returns Mean          -30.7998
exploration/Returns Std            14.1783
exploration/Returns Max           -16.6215
exploration/Returns Min           -44.9781
exploration/Actions Mean            0.0100429
exploration/Actions Std             0.217807
exploration/Actions Max             0.997805
exploration/Actions Min            -0.996967
exploration/Num Paths               2
exploration/Average Returns       -30.7998
evaluation/num steps total     155000
evaluation/num paths total       1550
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.217263
evaluation/Rewards Std              0.921633
evaluation/Rewards Max             -0.0410864
evaluation/Rewards Min             -9.90336
evaluation/Returns Mean           -21.7263
evaluation/Returns Std             14.9745
evaluation/Returns Max             -4.23458
evaluation/Returns Min            -57.3607
evaluation/Actions Mean             0.0227626
evaluation/Actions Std              0.181436
evaluation/Actions Max              0.996869
evaluation/Actions Min             -0.997468
evaluation/Num Paths               10
evaluation/Average Returns        -21.7263
time/data storing (s)               0.00174193
time/evaluation sampling (s)        0.272616
time/exploration sampling (s)       0.0835957
time/logging (s)                    0.00362692
time/saving (s)                     0.00238099
time/training (s)                   1.1519
time/epoch (s)                      1.51586
time/total (s)                    229.432
Epoch                             154
-----------------------------  ---------------
2019-04-21 12:20:15.819194 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 155 finished
-----------------------------  ---------------
replay_buffer/size              31400
trainer/QF1 Loss                    0.131113
trainer/QF2 Loss                    0.102702
trainer/Policy Loss                10.5648
trainer/Q1 Predictions Mean        -8.7995
trainer/Q1 Predictions Std          4.39146
trainer/Q1 Predictions Max         -7.68464
trainer/Q1 Predictions Min        -44.3014
trainer/Q2 Predictions Mean        -8.81344
trainer/Q2 Predictions Std          4.34852
trainer/Q2 Predictions Max         -7.72066
trainer/Q2 Predictions Min        -44.2505
trainer/Q Targets Mean             -9.0146
trainer/Q Targets Std               4.43697
trainer/Q Targets Max              -7.7981
trainer/Q Targets Min             -45.1744
trainer/Log Pis Mean                1.93689
trainer/Log Pis Std                 1.06867
trainer/Log Pis Max                 5.34335
trainer/Log Pis Min                -0.547786
trainer/Policy mu Mean             -0.0180358
trainer/Policy mu Std               0.583076
trainer/Policy mu Max               2.96297
trainer/Policy mu Min              -2.81157
trainer/Policy log std Mean        -2.15451
trainer/Policy log std Std          0.393038
trainer/Policy log std Max         -0.612292
trainer/Policy log std Min         -2.35733
trainer/Alpha                       0.0515799
trainer/Alpha Loss                 -0.187087
exploration/num steps total     31400
exploration/num paths total       314
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.182499
exploration/Rewards Std             0.41371
exploration/Rewards Max            -0.00365577
exploration/Rewards Min            -4.35692
exploration/Returns Mean          -18.2499
exploration/Returns Std             3.99698
exploration/Returns Max           -14.2529
exploration/Returns Min           -22.2468
exploration/Actions Mean            0.010657
exploration/Actions Std             0.208161
exploration/Actions Max             0.987455
exploration/Actions Min            -0.896376
exploration/Num Paths               2
exploration/Average Returns       -18.2499
evaluation/num steps total     156000
evaluation/num paths total       1560
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.288166
evaluation/Rewards Std              1.11313
evaluation/Rewards Max             -0.0389619
evaluation/Rewards Min             -8.42559
evaluation/Returns Mean           -28.8166
evaluation/Returns Std             12.2088
evaluation/Returns Max             -8.21878
evaluation/Returns Min            -43.7145
evaluation/Actions Mean             0.0272592
evaluation/Actions Std              0.201496
evaluation/Actions Max              0.995682
evaluation/Actions Min             -0.996556
evaluation/Num Paths               10
evaluation/Average Returns        -28.8166
time/data storing (s)               0.00146386
time/evaluation sampling (s)        0.286262
time/exploration sampling (s)       0.0739041
time/logging (s)                    0.00348559
time/saving (s)                     0.00252525
time/training (s)                   1.279
time/epoch (s)                      1.64664
time/total (s)                    231.083
Epoch                             155
-----------------------------  ---------------
2019-04-21 12:20:17.404566 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 156 finished
-----------------------------  ---------------
replay_buffer/size              31600
trainer/QF1 Loss                    1.287
trainer/QF2 Loss                    1.29518
trainer/Policy Loss                11.9796
trainer/Q1 Predictions Mean       -10.1814
trainer/Q1 Predictions Std          7.01005
trainer/Q1 Predictions Max         -7.81507
trainer/Q1 Predictions Min        -46.3187
trainer/Q2 Predictions Mean       -10.1684
trainer/Q2 Predictions Std          6.96997
trainer/Q2 Predictions Max         -7.80823
trainer/Q2 Predictions Min        -45.8663
trainer/Q Targets Mean            -10.0947
trainer/Q Targets Std               7.23667
trainer/Q Targets Max              -0.0426127
trainer/Q Targets Min             -45.8697
trainer/Log Pis Mean                2.25544
trainer/Log Pis Std                 1.29999
trainer/Log Pis Max                 7.80096
trainer/Log Pis Min                -2.17821
trainer/Policy mu Mean              0.122608
trainer/Policy mu Std               0.799757
trainer/Policy mu Max               3.15262
trainer/Policy mu Min              -3.09928
trainer/Policy log std Mean        -2.12916
trainer/Policy log std Std          0.485447
trainer/Policy log std Max         -0.515747
trainer/Policy log std Min         -2.39973
trainer/Alpha                       0.0510323
trainer/Alpha Loss                  0.760033
exploration/num steps total     31600
exploration/num paths total       316
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.427786
exploration/Rewards Std             1.37163
exploration/Rewards Max            -0.00756552
exploration/Rewards Min           -10.0207
exploration/Returns Mean          -42.7786
exploration/Returns Std            23.1979
exploration/Returns Max           -19.5807
exploration/Returns Min           -65.9764
exploration/Actions Mean            0.0404904
exploration/Actions Std             0.244968
exploration/Actions Max             0.998102
exploration/Actions Min            -0.825768
exploration/Num Paths               2
exploration/Average Returns       -42.7786
evaluation/num steps total     157000
evaluation/num paths total       1570
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.183637
evaluation/Rewards Std              0.827692
evaluation/Rewards Max             -0.0200464
evaluation/Rewards Min             -8.31882
evaluation/Returns Mean           -18.3637
evaluation/Returns Std             12.7703
evaluation/Returns Max             -3.40378
evaluation/Returns Min            -40.9575
evaluation/Actions Mean             0.0230462
evaluation/Actions Std              0.174034
evaluation/Actions Max              0.995366
evaluation/Actions Min             -0.974982
evaluation/Num Paths               10
evaluation/Average Returns        -18.3637
time/data storing (s)               0.00131229
time/evaluation sampling (s)        0.287542
time/exploration sampling (s)       0.0768736
time/logging (s)                    0.00340754
time/saving (s)                     0.00197635
time/training (s)                   1.2065
time/epoch (s)                      1.57761
time/total (s)                    232.665
Epoch                             156
-----------------------------  ---------------
2019-04-21 12:20:19.049361 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 157 finished
-----------------------------  ---------------
replay_buffer/size              31800
trainer/QF1 Loss                    0.642668
trainer/QF2 Loss                    0.633734
trainer/Policy Loss                10.1624
trainer/Q1 Predictions Mean        -8.40584
trainer/Q1 Predictions Std          1.79733
trainer/Q1 Predictions Max         -7.80582
trainer/Q1 Predictions Min        -24.5172
trainer/Q2 Predictions Mean        -8.3844
trainer/Q2 Predictions Std          1.76568
trainer/Q2 Predictions Max         -7.80305
trainer/Q2 Predictions Min        -24.2536
trainer/Q Targets Mean             -8.30816
trainer/Q Targets Std               1.88303
trainer/Q Targets Max              -0.0180781
trainer/Q Targets Min             -23.3867
trainer/Log Pis Mean                1.9829
trainer/Log Pis Std                 0.991742
trainer/Log Pis Max                 4.35352
trainer/Log Pis Min                -1.94163
trainer/Policy mu Mean             -0.0502472
trainer/Policy mu Std               0.576423
trainer/Policy mu Max               2.41646
trainer/Policy mu Min              -3.03771
trainer/Policy log std Mean        -2.1489
trainer/Policy log std Std          0.446305
trainer/Policy log std Max         -0.410994
trainer/Policy log std Min         -2.44566
trainer/Alpha                       0.0517506
trainer/Alpha Loss                 -0.0506251
exploration/num steps total     31800
exploration/num paths total       318
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.414609
exploration/Rewards Std             1.29194
exploration/Rewards Max            -0.00554792
exploration/Rewards Min            -9.46455
exploration/Returns Mean          -41.4609
exploration/Returns Std            18.0306
exploration/Returns Max           -23.4303
exploration/Returns Min           -59.4915
exploration/Actions Mean            0.0422187
exploration/Actions Std             0.239601
exploration/Actions Max             0.998331
exploration/Actions Min            -0.598076
exploration/Num Paths               2
exploration/Average Returns       -41.4609
evaluation/num steps total     158000
evaluation/num paths total       1580
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.268741
evaluation/Rewards Std              1.15966
evaluation/Rewards Max             -0.0187274
evaluation/Rewards Min            -10.2338
evaluation/Returns Mean           -26.8741
evaluation/Returns Std             18.2428
evaluation/Returns Max             -6.90265
evaluation/Returns Min            -55.68
evaluation/Actions Mean             0.0290393
evaluation/Actions Std              0.202229
evaluation/Actions Max              0.99661
evaluation/Actions Min             -0.984132
evaluation/Num Paths               10
evaluation/Average Returns        -26.8741
time/data storing (s)               0.00146313
time/evaluation sampling (s)        0.308872
time/exploration sampling (s)       0.0804766
time/logging (s)                    0.00356413
time/saving (s)                     0.00291929
time/training (s)                   1.23943
time/epoch (s)                      1.63673
time/total (s)                    234.307
Epoch                             157
-----------------------------  ---------------
2019-04-21 12:20:20.693909 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 158 finished
-----------------------------  ---------------
replay_buffer/size              32000
trainer/QF1 Loss                    0.0464725
trainer/QF2 Loss                    0.0326005
trainer/Policy Loss                 9.84579
trainer/Q1 Predictions Mean        -8.36893
trainer/Q1 Predictions Std          1.16969
trainer/Q1 Predictions Max         -7.8499
trainer/Q1 Predictions Min        -13.9015
trainer/Q2 Predictions Mean        -8.2681
trainer/Q2 Predictions Std          1.1591
trainer/Q2 Predictions Max         -7.75192
trainer/Q2 Predictions Min        -13.8176
trainer/Q Targets Mean             -8.3132
trainer/Q Targets Std               1.06685
trainer/Q Targets Max              -7.72567
trainer/Q Targets Min             -13.598
trainer/Log Pis Mean                1.66906
trainer/Log Pis Std                 1.36883
trainer/Log Pis Max                 4.24803
trainer/Log Pis Min                -4.70727
trainer/Policy mu Mean              0.00432428
trainer/Policy mu Std               0.56222
trainer/Policy mu Max               2.51318
trainer/Policy mu Min              -1.64348
trainer/Policy log std Mean        -2.16263
trainer/Policy log std Std          0.407779
trainer/Policy log std Max         -0.608638
trainer/Policy log std Min         -2.36386
trainer/Alpha                       0.0526357
trainer/Alpha Loss                 -0.974344
exploration/num steps total     32000
exploration/num paths total       320
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.161203
exploration/Rewards Std             0.207923
exploration/Rewards Max            -0.0112657
exploration/Rewards Min            -2.15951
exploration/Returns Mean          -16.1203
exploration/Returns Std             0.701591
exploration/Returns Max           -15.4187
exploration/Returns Min           -16.8219
exploration/Actions Mean           -0.00414094
exploration/Actions Std             0.182207
exploration/Actions Max             0.989989
exploration/Actions Min            -0.989199
exploration/Num Paths               2
exploration/Average Returns       -16.1203
evaluation/num steps total     159000
evaluation/num paths total       1590
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.343669
evaluation/Rewards Std              1.13497
evaluation/Rewards Max             -0.0625575
evaluation/Rewards Min            -10.9423
evaluation/Returns Mean           -34.3669
evaluation/Returns Std             13.417
evaluation/Returns Max            -18.9403
evaluation/Returns Min            -63.5909
evaluation/Actions Mean             0.0397701
evaluation/Actions Std              0.214517
evaluation/Actions Max              0.998087
evaluation/Actions Min             -0.992696
evaluation/Num Paths               10
evaluation/Average Returns        -34.3669
time/data storing (s)               0.00247497
time/evaluation sampling (s)        0.303743
time/exploration sampling (s)       0.0762222
time/logging (s)                    0.00369317
time/saving (s)                     0.00279761
time/training (s)                   1.24791
time/epoch (s)                      1.63684
time/total (s)                    235.949
Epoch                             158
-----------------------------  ---------------
2019-04-21 12:20:22.272966 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 159 finished
-----------------------------  ---------------
replay_buffer/size              32200
trainer/QF1 Loss                    0.0387502
trainer/QF2 Loss                    0.0327107
trainer/Policy Loss                10.7667
trainer/Q1 Predictions Mean        -9.10846
trainer/Q1 Predictions Std          3.49068
trainer/Q1 Predictions Max         -7.81677
trainer/Q1 Predictions Min        -29.8525
trainer/Q2 Predictions Mean        -9.02885
trainer/Q2 Predictions Std          3.54939
trainer/Q2 Predictions Max         -7.72855
trainer/Q2 Predictions Min        -30.5248
trainer/Q Targets Mean             -9.06193
trainer/Q Targets Std               3.48283
trainer/Q Targets Max              -7.6973
trainer/Q Targets Min             -30.3792
trainer/Log Pis Mean                1.92127
trainer/Log Pis Std                 1.36254
trainer/Log Pis Max                 5.0293
trainer/Log Pis Min                -4.13833
trainer/Policy mu Mean              0.0119215
trainer/Policy mu Std               0.765116
trainer/Policy mu Max               2.78574
trainer/Policy mu Min              -3.39054
trainer/Policy log std Mean        -2.08103
trainer/Policy log std Std          0.51724
trainer/Policy log std Max         -0.488788
trainer/Policy log std Min         -2.42417
trainer/Alpha                       0.052002
trainer/Alpha Loss                 -0.232769
exploration/num steps total     32200
exploration/num paths total       322
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.155284
exploration/Rewards Std             0.257345
exploration/Rewards Max            -0.00738819
exploration/Rewards Min            -2.4798
exploration/Returns Mean          -15.5284
exploration/Returns Std             0.00975746
exploration/Returns Max           -15.5186
exploration/Returns Min           -15.5381
exploration/Actions Mean           -0.013451
exploration/Actions Std             0.189612
exploration/Actions Max             0.949432
exploration/Actions Min            -0.994333
exploration/Num Paths               2
exploration/Average Returns       -15.5284
evaluation/num steps total     160000
evaluation/num paths total       1600
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.259411
evaluation/Rewards Std              1.08205
evaluation/Rewards Max             -0.0400702
evaluation/Rewards Min            -10.2973
evaluation/Returns Mean           -25.9411
evaluation/Returns Std             18.7897
evaluation/Returns Max             -5.73696
evaluation/Returns Min            -62.1256
evaluation/Actions Mean             0.0305148
evaluation/Actions Std              0.190924
evaluation/Actions Max              0.998176
evaluation/Actions Min             -0.987834
evaluation/Num Paths               10
evaluation/Average Returns        -25.9411
time/data storing (s)               0.0018207
time/evaluation sampling (s)        0.292424
time/exploration sampling (s)       0.0813455
time/logging (s)                    0.00350246
time/saving (s)                     0.00238421
time/training (s)                   1.19055
time/epoch (s)                      1.57203
time/total (s)                    237.525
Epoch                             159
-----------------------------  ---------------
2019-04-21 12:20:23.764544 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 160 finished
-----------------------------  ---------------
replay_buffer/size              32400
trainer/QF1 Loss                    0.605507
trainer/QF2 Loss                    0.627883
trainer/Policy Loss                10.4075
trainer/Q1 Predictions Mean        -8.8679
trainer/Q1 Predictions Std          5.00474
trainer/Q1 Predictions Max         -7.73536
trainer/Q1 Predictions Min        -43.7286
trainer/Q2 Predictions Mean        -8.98076
trainer/Q2 Predictions Std          5.06932
trainer/Q2 Predictions Max         -7.83513
trainer/Q2 Predictions Min        -44.6836
trainer/Q Targets Mean             -8.8755
trainer/Q Targets Std               5.08452
trainer/Q Targets Max              -1.10251
trainer/Q Targets Min             -44.4374
trainer/Log Pis Mean                1.72247
trainer/Log Pis Std                 1.05824
trainer/Log Pis Max                 5.31429
trainer/Log Pis Min                -2.03538
trainer/Policy mu Mean              0.0726358
trainer/Policy mu Std               0.559794
trainer/Policy mu Max               3.03085
trainer/Policy mu Min              -2.3805
trainer/Policy log std Mean        -2.06754
trainer/Policy log std Std          0.365265
trainer/Policy log std Max         -0.652083
trainer/Policy log std Min         -2.27076
trainer/Alpha                       0.0508975
trainer/Alpha Loss                 -0.826372
exploration/num steps total     32400
exploration/num paths total       324
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.265235
exploration/Rewards Std             0.616892
exploration/Rewards Max            -0.0187754
exploration/Rewards Min            -5.06197
exploration/Returns Mean          -26.5235
exploration/Returns Std             3.80392
exploration/Returns Max           -22.7196
exploration/Returns Min           -30.3275
exploration/Actions Mean           -0.011507
exploration/Actions Std             0.23152
exploration/Actions Max             0.989607
exploration/Actions Min            -0.998862
exploration/Num Paths               2
exploration/Average Returns       -26.5235
evaluation/num steps total     161000
evaluation/num paths total       1610
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.27327
evaluation/Rewards Std              1.00503
evaluation/Rewards Max             -0.0250035
evaluation/Rewards Min             -8.87935
evaluation/Returns Mean           -27.327
evaluation/Returns Std             11.4748
evaluation/Returns Max             -8.83123
evaluation/Returns Min            -43.312
evaluation/Actions Mean             0.0280021
evaluation/Actions Std              0.20684
evaluation/Actions Max              0.996613
evaluation/Actions Min             -0.980019
evaluation/Num Paths               10
evaluation/Average Returns        -27.327
time/data storing (s)               0.00152147
time/evaluation sampling (s)        0.270209
time/exploration sampling (s)       0.0694379
time/logging (s)                    0.00348809
time/saving (s)                     0.00244012
time/training (s)                   1.13728
time/epoch (s)                      1.48438
time/total (s)                    239.014
Epoch                             160
-----------------------------  ---------------
2019-04-21 12:20:25.386025 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 161 finished
-----------------------------  ---------------
replay_buffer/size              32600
trainer/QF1 Loss                    1.18709
trainer/QF2 Loss                    1.18204
trainer/Policy Loss                11.1078
trainer/Q1 Predictions Mean        -9.13686
trainer/Q1 Predictions Std          6.22794
trainer/Q1 Predictions Max         -7.53127
trainer/Q1 Predictions Min        -48.737
trainer/Q2 Predictions Mean        -9.25658
trainer/Q2 Predictions Std          6.19917
trainer/Q2 Predictions Max         -7.66837
trainer/Q2 Predictions Min        -48.6156
trainer/Q Targets Mean             -9.19293
trainer/Q Targets Std               6.26371
trainer/Q Targets Max              -0.0147347
trainer/Q Targets Min             -48.2502
trainer/Log Pis Mean                2.06642
trainer/Log Pis Std                 1.19652
trainer/Log Pis Max                 6.37515
trainer/Log Pis Min                -3.09841
trainer/Policy mu Mean              0.126349
trainer/Policy mu Std               0.659263
trainer/Policy mu Max               3.24466
trainer/Policy mu Min              -1.6567
trainer/Policy log std Mean        -2.1299
trainer/Policy log std Std          0.418399
trainer/Policy log std Max         -0.547572
trainer/Policy log std Min         -2.34935
trainer/Alpha                       0.0492681
trainer/Alpha Loss                  0.199971
exploration/num steps total     32600
exploration/num paths total       326
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.255811
exploration/Rewards Std             0.648863
exploration/Rewards Max            -0.00510037
exploration/Rewards Min            -5.64261
exploration/Returns Mean          -25.5811
exploration/Returns Std             3.76683
exploration/Returns Max           -21.8143
exploration/Returns Min           -29.348
exploration/Actions Mean            0.00765916
exploration/Actions Std             0.227894
exploration/Actions Max             0.997639
exploration/Actions Min            -0.992297
exploration/Num Paths               2
exploration/Average Returns       -25.5811
evaluation/num steps total     162000
evaluation/num paths total       1620
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.204343
evaluation/Rewards Std              0.880394
evaluation/Rewards Max             -0.0247994
evaluation/Rewards Min            -10.0382
evaluation/Returns Mean           -20.4343
evaluation/Returns Std             16.7105
evaluation/Returns Max             -6.38316
evaluation/Returns Min            -59.0307
evaluation/Actions Mean             0.0297246
evaluation/Actions Std              0.171764
evaluation/Actions Max              0.997512
evaluation/Actions Min             -0.986258
evaluation/Num Paths               10
evaluation/Average Returns        -20.4343
time/data storing (s)               0.001571
time/evaluation sampling (s)        0.283155
time/exploration sampling (s)       0.0810006
time/logging (s)                    0.00261552
time/saving (s)                     0.00187156
time/training (s)                   1.24294
time/epoch (s)                      1.61315
time/total (s)                    240.632
Epoch                             161
-----------------------------  ---------------
2019-04-21 12:20:26.903455 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 162 finished
-----------------------------  ---------------
replay_buffer/size              32800
trainer/QF1 Loss                    1.75432
trainer/QF2 Loss                    1.74177
trainer/Policy Loss                10.758
trainer/Q1 Predictions Mean        -8.84179
trainer/Q1 Predictions Std          5.71989
trainer/Q1 Predictions Max         -7.62242
trainer/Q1 Predictions Min        -57.1812
trainer/Q2 Predictions Mean        -8.7301
trainer/Q2 Predictions Std          5.69922
trainer/Q2 Predictions Max         -7.53141
trainer/Q2 Predictions Min        -56.6915
trainer/Q Targets Mean             -8.68455
trainer/Q Targets Std               5.88788
trainer/Q Targets Max              -0.0587148
trainer/Q Targets Min             -56.9525
trainer/Log Pis Mean                2.07811
trainer/Log Pis Std                 1.25234
trainer/Log Pis Max                 7.14706
trainer/Log Pis Min                -1.97638
trainer/Policy mu Mean              0.0135559
trainer/Policy mu Std               0.557364
trainer/Policy mu Max               3.2374
trainer/Policy mu Min              -2.35043
trainer/Policy log std Mean        -2.2333
trainer/Policy log std Std          0.373511
trainer/Policy log std Max         -0.562613
trainer/Policy log std Min         -2.43677
trainer/Alpha                       0.0512252
trainer/Alpha Loss                  0.232125
exploration/num steps total     32800
exploration/num paths total       328
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.208599
exploration/Rewards Std             0.568483
exploration/Rewards Max            -0.0092821
exploration/Rewards Min            -5.86368
exploration/Returns Mean          -20.8599
exploration/Returns Std             7.94437
exploration/Returns Max           -12.9155
exploration/Returns Min           -28.8042
exploration/Actions Mean            0.00542374
exploration/Actions Std             0.210591
exploration/Actions Max             0.999042
exploration/Actions Min            -0.98068
exploration/Num Paths               2
exploration/Average Returns       -20.8599
evaluation/num steps total     163000
evaluation/num paths total       1630
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.241894
evaluation/Rewards Std              0.956653
evaluation/Rewards Max             -0.0322151
evaluation/Rewards Min             -9.27986
evaluation/Returns Mean           -24.1894
evaluation/Returns Std             11.7191
evaluation/Returns Max             -7.12912
evaluation/Returns Min            -48.5376
evaluation/Actions Mean             0.0309204
evaluation/Actions Std              0.20366
evaluation/Actions Max              0.996694
evaluation/Actions Min             -0.992707
evaluation/Num Paths               10
evaluation/Average Returns        -24.1894
time/data storing (s)               0.00128864
time/evaluation sampling (s)        0.283221
time/exploration sampling (s)       0.0797765
time/logging (s)                    0.00404122
time/saving (s)                     0.00234336
time/training (s)                   1.14108
time/epoch (s)                      1.51175
time/total (s)                    242.148
Epoch                             162
-----------------------------  ---------------
2019-04-21 12:20:28.442687 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 163 finished
-----------------------------  ---------------
replay_buffer/size              33000
trainer/QF1 Loss                    1.74034
trainer/QF2 Loss                    1.75823
trainer/Policy Loss                10.4523
trainer/Q1 Predictions Mean        -8.4256
trainer/Q1 Predictions Std          3.01942
trainer/Q1 Predictions Max         -7.72974
trainer/Q1 Predictions Min        -33.1058
trainer/Q2 Predictions Mean        -8.4464
trainer/Q2 Predictions Std          2.93509
trainer/Q2 Predictions Max         -7.76508
trainer/Q2 Predictions Min        -32.4464
trainer/Q Targets Mean             -8.15144
trainer/Q Targets Std               3.2281
trainer/Q Targets Max              -0.11174
trainer/Q Targets Min             -32.3218
trainer/Log Pis Mean                2.12327
trainer/Log Pis Std                 0.971768
trainer/Log Pis Max                 5.43718
trainer/Log Pis Min                -0.905414
trainer/Policy mu Mean             -0.00301749
trainer/Policy mu Std               0.464555
trainer/Policy mu Max               2.88224
trainer/Policy mu Min              -1.3575
trainer/Policy log std Mean        -2.31334
trainer/Policy log std Std          0.321575
trainer/Policy log std Max         -0.681836
trainer/Policy log std Min         -2.50155
trainer/Alpha                       0.0513474
trainer/Alpha Loss                  0.366012
exploration/num steps total     33000
exploration/num paths total       330
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.382502
exploration/Rewards Std             1.18972
exploration/Rewards Max            -0.0176683
exploration/Rewards Min            -9.06958
exploration/Returns Mean          -38.2502
exploration/Returns Std            13.603
exploration/Returns Max           -24.6472
exploration/Returns Min           -51.8532
exploration/Actions Mean            0.057249
exploration/Actions Std             0.249843
exploration/Actions Max             0.997703
exploration/Actions Min            -0.344477
exploration/Num Paths               2
exploration/Average Returns       -38.2502
evaluation/num steps total     164000
evaluation/num paths total       1640
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.321935
evaluation/Rewards Std              1.18799
evaluation/Rewards Max             -0.0658315
evaluation/Rewards Min            -11.2921
evaluation/Returns Mean           -32.1935
evaluation/Returns Std             16.8754
evaluation/Returns Max            -11.3644
evaluation/Returns Min            -66.721
evaluation/Actions Mean             0.027522
evaluation/Actions Std              0.213045
evaluation/Actions Max              0.997291
evaluation/Actions Min             -0.997429
evaluation/Num Paths               10
evaluation/Average Returns        -32.1935
time/data storing (s)               0.00194192
time/evaluation sampling (s)        0.272451
time/exploration sampling (s)       0.0690412
time/logging (s)                    0.00350521
time/saving (s)                     0.00242486
time/training (s)                   1.18199
time/epoch (s)                      1.53136
time/total (s)                    243.683
Epoch                             163
-----------------------------  ---------------
2019-04-21 12:20:29.905716 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 164 finished
-----------------------------  ---------------
replay_buffer/size              33200
trainer/QF1 Loss                    0.604184
trainer/QF2 Loss                    0.586462
trainer/Policy Loss                10.8567
trainer/Q1 Predictions Mean        -8.81808
trainer/Q1 Predictions Std          4.63499
trainer/Q1 Predictions Max         -7.49403
trainer/Q1 Predictions Min        -37.0923
trainer/Q2 Predictions Mean        -8.84324
trainer/Q2 Predictions Std          4.5959
trainer/Q2 Predictions Max         -7.54685
trainer/Q2 Predictions Min        -37.0795
trainer/Q Targets Mean             -8.91215
trainer/Q Targets Std               4.71998
trainer/Q Targets Max              -0.436759
trainer/Q Targets Min             -36.9716
trainer/Log Pis Mean                2.23917
trainer/Log Pis Std                 1.00857
trainer/Log Pis Max                 6.29
trainer/Log Pis Min                -0.814933
trainer/Policy mu Mean              0.0646117
trainer/Policy mu Std               0.643708
trainer/Policy mu Max               3.11028
trainer/Policy mu Min              -1.83573
trainer/Policy log std Mean        -2.18493
trainer/Policy log std Std          0.425367
trainer/Policy log std Max         -0.60469
trainer/Policy log std Min         -2.40598
trainer/Alpha                       0.0520721
trainer/Alpha Loss                  0.706818
exploration/num steps total     33200
exploration/num paths total       332
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.160754
exploration/Rewards Std             0.345739
exploration/Rewards Max            -0.00789299
exploration/Rewards Min            -4.01746
exploration/Returns Mean          -16.0754
exploration/Returns Std             3.83525
exploration/Returns Max           -12.2402
exploration/Returns Min           -19.9107
exploration/Actions Mean           -0.00265193
exploration/Actions Std             0.191298
exploration/Actions Max             0.99664
exploration/Actions Min            -0.983723
exploration/Num Paths               2
exploration/Average Returns       -16.0754
evaluation/num steps total     165000
evaluation/num paths total       1650
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.257251
evaluation/Rewards Std              1.06697
evaluation/Rewards Max             -0.0303688
evaluation/Rewards Min             -9.85314
evaluation/Returns Mean           -25.7251
evaluation/Returns Std             15.5562
evaluation/Returns Max             -4.79874
evaluation/Returns Min            -56.7151
evaluation/Actions Mean             0.0275835
evaluation/Actions Std              0.186424
evaluation/Actions Max              0.996705
evaluation/Actions Min             -0.996956
evaluation/Num Paths               10
evaluation/Average Returns        -25.7251
time/data storing (s)               0.00121774
time/evaluation sampling (s)        0.277278
time/exploration sampling (s)       0.0695647
time/logging (s)                    0.00417917
time/saving (s)                     0.00240774
time/training (s)                   1.10229
time/epoch (s)                      1.45694
time/total (s)                    245.144
Epoch                             164
-----------------------------  ---------------
2019-04-21 12:20:31.593354 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 165 finished
-----------------------------  ---------------
replay_buffer/size              33400
trainer/QF1 Loss                    0.0522773
trainer/QF2 Loss                    0.0418176
trainer/Policy Loss                 9.99849
trainer/Q1 Predictions Mean        -8.30073
trainer/Q1 Predictions Std          2.50126
trainer/Q1 Predictions Max         -7.57922
trainer/Q1 Predictions Min        -28.5124
trainer/Q2 Predictions Mean        -8.27567
trainer/Q2 Predictions Std          2.52045
trainer/Q2 Predictions Max         -7.55398
trainer/Q2 Predictions Min        -28.5652
trainer/Q Targets Mean             -8.39545
trainer/Q Targets Std               2.59058
trainer/Q Targets Max              -7.54974
trainer/Q Targets Min             -28.8008
trainer/Log Pis Mean                1.90695
trainer/Log Pis Std                 1.23249
trainer/Log Pis Max                 5.36324
trainer/Log Pis Min                -2.01806
trainer/Policy mu Mean              0.0352962
trainer/Policy mu Std               0.544691
trainer/Policy mu Max               2.87576
trainer/Policy mu Min              -2.11262
trainer/Policy log std Mean        -2.16449
trainer/Policy log std Std          0.357721
trainer/Policy log std Max         -0.69269
trainer/Policy log std Min         -2.38063
trainer/Alpha                       0.0524269
trainer/Alpha Loss                 -0.274353
exploration/num steps total     33400
exploration/num paths total       334
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.279657
exploration/Rewards Std             0.770531
exploration/Rewards Max            -0.00273927
exploration/Rewards Min            -5.59451
exploration/Returns Mean          -27.9657
exploration/Returns Std             0.548744
exploration/Returns Max           -27.4169
exploration/Returns Min           -28.5144
exploration/Actions Mean            0.0216603
exploration/Actions Std             0.236794
exploration/Actions Max             0.998975
exploration/Actions Min            -0.991929
exploration/Num Paths               2
exploration/Average Returns       -27.9657
evaluation/num steps total     166000
evaluation/num paths total       1660
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.289487
evaluation/Rewards Std              1.13285
evaluation/Rewards Max             -0.0344953
evaluation/Rewards Min            -10.0269
evaluation/Returns Mean           -28.9487
evaluation/Returns Std             13.7844
evaluation/Returns Max            -10.4789
evaluation/Returns Min            -56.1803
evaluation/Actions Mean             0.0430076
evaluation/Actions Std              0.207794
evaluation/Actions Max              0.997027
evaluation/Actions Min             -0.989414
evaluation/Num Paths               10
evaluation/Average Returns        -28.9487
time/data storing (s)               0.00146172
time/evaluation sampling (s)        0.285811
time/exploration sampling (s)       0.0767265
time/logging (s)                    0.00444226
time/saving (s)                     0.00252651
time/training (s)                   1.30901
time/epoch (s)                      1.67997
time/total (s)                    246.829
Epoch                             165
-----------------------------  ---------------
2019-04-21 12:20:32.995761 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 166 finished
-----------------------------  ---------------
replay_buffer/size              33600
trainer/QF1 Loss                    1.15863
trainer/QF2 Loss                    1.15757
trainer/Policy Loss                10.3649
trainer/Q1 Predictions Mean        -8.67933
trainer/Q1 Predictions Std          5.43297
trainer/Q1 Predictions Max         -7.48837
trainer/Q1 Predictions Min        -59.0726
trainer/Q2 Predictions Mean        -8.702
trainer/Q2 Predictions Std          5.4183
trainer/Q2 Predictions Max         -7.53826
trainer/Q2 Predictions Min        -58.8833
trainer/Q Targets Mean             -8.63356
trainer/Q Targets Std               5.57585
trainer/Q Targets Max              -0.0130858
trainer/Q Targets Min             -59.6354
trainer/Log Pis Mean                1.81705
trainer/Log Pis Std                 1.23132
trainer/Log Pis Max                 6.6264
trainer/Log Pis Min                -2.33275
trainer/Policy mu Mean              0.0598824
trainer/Policy mu Std               0.599056
trainer/Policy mu Max               3.31962
trainer/Policy mu Min              -2.28386
trainer/Policy log std Mean        -2.16738
trainer/Policy log std Std          0.366633
trainer/Policy log std Max         -0.692418
trainer/Policy log std Min         -2.40617
trainer/Alpha                       0.0516641
trainer/Alpha Loss                 -0.542058
exploration/num steps total     33600
exploration/num paths total       336
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.574471
exploration/Rewards Std             1.62974
exploration/Rewards Max            -0.00531342
exploration/Rewards Min            -9.91655
exploration/Returns Mean          -57.4471
exploration/Returns Std             7.14305
exploration/Returns Max           -50.304
exploration/Returns Min           -64.5901
exploration/Actions Mean            0.0435145
exploration/Actions Std             0.256706
exploration/Actions Max             0.999487
exploration/Actions Min            -0.860012
exploration/Num Paths               2
exploration/Average Returns       -57.4471
evaluation/num steps total     167000
evaluation/num paths total       1670
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.163704
evaluation/Rewards Std              0.779724
evaluation/Rewards Max             -0.0291024
evaluation/Rewards Min             -9.98398
evaluation/Returns Mean           -16.3704
evaluation/Returns Std             16.6873
evaluation/Returns Max             -4.63396
evaluation/Returns Min            -59.0685
evaluation/Actions Mean             0.0212139
evaluation/Actions Std              0.147412
evaluation/Actions Max              0.996879
evaluation/Actions Min             -0.908454
evaluation/Num Paths               10
evaluation/Average Returns        -16.3704
time/data storing (s)               0.00122362
time/evaluation sampling (s)        0.283341
time/exploration sampling (s)       0.072417
time/logging (s)                    0.00355617
time/saving (s)                     0.00238249
time/training (s)                   1.03101
time/epoch (s)                      1.39393
time/total (s)                    248.228
Epoch                             166
-----------------------------  ---------------
2019-04-21 12:20:34.481812 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 167 finished
-----------------------------  ---------------
replay_buffer/size              33800
trainer/QF1 Loss                    2.21756
trainer/QF2 Loss                    2.19668
trainer/Policy Loss                 9.64715
trainer/Q1 Predictions Mean        -7.81547
trainer/Q1 Predictions Std          0.960523
trainer/Q1 Predictions Max         -7.44465
trainer/Q1 Predictions Min        -13.74
trainer/Q2 Predictions Mean        -7.81374
trainer/Q2 Predictions Std          0.917527
trainer/Q2 Predictions Max         -7.46736
trainer/Q2 Predictions Min        -13.577
trainer/Q Targets Mean             -7.63609
trainer/Q Targets Std               1.76663
trainer/Q Targets Max              -0.0426127
trainer/Q Targets Min             -13.2999
trainer/Log Pis Mean                1.92388
trainer/Log Pis Std                 1.05627
trainer/Log Pis Max                 5.17071
trainer/Log Pis Min                -1.05854
trainer/Policy mu Mean              0.0438519
trainer/Policy mu Std               0.469982
trainer/Policy mu Max               2.59438
trainer/Policy mu Min              -2.65288
trainer/Policy log std Mean        -2.19952
trainer/Policy log std Std          0.326992
trainer/Policy log std Max         -0.687799
trainer/Policy log std Min         -2.36371
trainer/Alpha                       0.0512455
trainer/Alpha Loss                 -0.226163
exploration/num steps total     33800
exploration/num paths total       338
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.322818
exploration/Rewards Std             0.907049
exploration/Rewards Max            -0.0114889
exploration/Rewards Min            -7.6101
exploration/Returns Mean          -32.2818
exploration/Returns Std             8.65808
exploration/Returns Max           -23.6237
exploration/Returns Min           -40.9399
exploration/Actions Mean            0.0347371
exploration/Actions Std             0.249942
exploration/Actions Max             0.993823
exploration/Actions Min            -0.964908
exploration/Num Paths               2
exploration/Average Returns       -32.2818
evaluation/num steps total     168000
evaluation/num paths total       1680
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.31338
evaluation/Rewards Std              1.22497
evaluation/Rewards Max             -0.0269388
evaluation/Rewards Min            -10.792
evaluation/Returns Mean           -31.338
evaluation/Returns Std             22.6465
evaluation/Returns Max             -7.81684
evaluation/Returns Min            -64.42
evaluation/Actions Mean             0.0200377
evaluation/Actions Std              0.196665
evaluation/Actions Max              0.99783
evaluation/Actions Min             -0.992932
evaluation/Num Paths               10
evaluation/Average Returns        -31.338
time/data storing (s)               0.00121107
time/evaluation sampling (s)        0.27075
time/exploration sampling (s)       0.0820374
time/logging (s)                    0.00344854
time/saving (s)                     0.00247137
time/training (s)                   1.11873
time/epoch (s)                      1.47865
time/total (s)                    249.711
Epoch                             167
-----------------------------  ---------------
2019-04-21 12:20:35.953649 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 168 finished
-----------------------------  ---------------
replay_buffer/size              34000
trainer/QF1 Loss                    2.16303
trainer/QF2 Loss                    2.16455
trainer/Policy Loss                 9.99806
trainer/Q1 Predictions Mean        -8.07468
trainer/Q1 Predictions Std          2.55787
trainer/Q1 Predictions Max         -7.32197
trainer/Q1 Predictions Min        -25.8633
trainer/Q2 Predictions Mean        -8.06593
trainer/Q2 Predictions Std          2.55049
trainer/Q2 Predictions Max         -7.34176
trainer/Q2 Predictions Min        -25.9157
trainer/Q Targets Mean             -7.96182
trainer/Q Targets Std               2.97071
trainer/Q Targets Max              -0.0830755
trainer/Q Targets Min             -26.1465
trainer/Log Pis Mean                2.05147
trainer/Log Pis Std                 1.11233
trainer/Log Pis Max                 5.45241
trainer/Log Pis Min                -1.49905
trainer/Policy mu Mean              0.092154
trainer/Policy mu Std               0.502339
trainer/Policy mu Max               2.86508
trainer/Policy mu Min              -1.49915
trainer/Policy log std Mean        -2.29768
trainer/Policy log std Std          0.351337
trainer/Policy log std Max         -0.585456
trainer/Policy log std Min         -2.48502
trainer/Alpha                       0.0531819
trainer/Alpha Loss                  0.151022
exploration/num steps total     34000
exploration/num paths total       340
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.525349
exploration/Rewards Std             1.58608
exploration/Rewards Max            -0.0101275
exploration/Rewards Min           -10.6544
exploration/Returns Mean          -52.5349
exploration/Returns Std            13.9134
exploration/Returns Max           -38.6216
exploration/Returns Min           -66.4483
exploration/Actions Mean            0.0381208
exploration/Actions Std             0.260516
exploration/Actions Max             0.998544
exploration/Actions Min            -0.938851
exploration/Num Paths               2
exploration/Average Returns       -52.5349
evaluation/num steps total     169000
evaluation/num paths total       1690
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.206514
evaluation/Rewards Std              0.920613
evaluation/Rewards Max             -0.0110153
evaluation/Rewards Min             -7.70258
evaluation/Returns Mean           -20.6514
evaluation/Returns Std              6.85594
evaluation/Returns Max             -9.367
evaluation/Returns Min            -30.195
evaluation/Actions Mean             0.0449189
evaluation/Actions Std              0.199823
evaluation/Actions Max              0.996205
evaluation/Actions Min             -0.906227
evaluation/Num Paths               10
evaluation/Average Returns        -20.6514
time/data storing (s)               0.0012098
time/evaluation sampling (s)        0.276551
time/exploration sampling (s)       0.0726377
time/logging (s)                    0.00376168
time/saving (s)                     0.00236534
time/training (s)                   1.10828
time/epoch (s)                      1.46481
time/total (s)                    251.18
Epoch                             168
-----------------------------  ---------------
2019-04-21 12:20:37.417865 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 169 finished
-----------------------------  ---------------
replay_buffer/size              34200
trainer/QF1 Loss                    2.40226
trainer/QF2 Loss                    2.32829
trainer/Policy Loss                 9.85787
trainer/Q1 Predictions Mean        -8.24577
trainer/Q1 Predictions Std          2.54425
trainer/Q1 Predictions Max         -7.56204
trainer/Q1 Predictions Min        -25.2176
trainer/Q2 Predictions Mean        -8.1704
trainer/Q2 Predictions Std          2.53191
trainer/Q2 Predictions Max         -7.5
trainer/Q2 Predictions Min        -25.019
trainer/Q Targets Mean             -7.93913
trainer/Q Targets Std               3.02466
trainer/Q Targets Max              -0.119626
trainer/Q Targets Min             -24.6481
trainer/Log Pis Mean                1.74378
trainer/Log Pis Std                 1.31955
trainer/Log Pis Max                 5.30468
trainer/Log Pis Min                -3.72396
trainer/Policy mu Mean              0.0216443
trainer/Policy mu Std               0.498431
trainer/Policy mu Max               2.87488
trainer/Policy mu Min              -2.65534
trainer/Policy log std Mean        -2.13417
trainer/Policy log std Std          0.351181
trainer/Policy log std Max         -0.644006
trainer/Policy log std Min         -2.29373
trainer/Alpha                       0.0551569
trainer/Alpha Loss                 -0.742385
exploration/num steps total     34200
exploration/num paths total       342
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.479999
exploration/Rewards Std             1.38739
exploration/Rewards Max            -0.00630653
exploration/Rewards Min            -8.7168
exploration/Returns Mean          -47.9999
exploration/Returns Std             4.39893
exploration/Returns Max           -43.6009
exploration/Returns Min           -52.3988
exploration/Actions Mean            0.0301229
exploration/Actions Std             0.25919
exploration/Actions Max             0.996852
exploration/Actions Min            -0.931454
exploration/Num Paths               2
exploration/Average Returns       -47.9999
evaluation/num steps total     170000
evaluation/num paths total       1700
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.185167
evaluation/Rewards Std              0.873092
evaluation/Rewards Max             -0.00333188
evaluation/Rewards Min             -8.4093
evaluation/Returns Mean           -18.5167
evaluation/Returns Std              8.54935
evaluation/Returns Max             -6.78644
evaluation/Returns Min            -33.2447
evaluation/Actions Mean             0.0229475
evaluation/Actions Std              0.200772
evaluation/Actions Max              0.995751
evaluation/Actions Min             -0.994472
evaluation/Num Paths               10
evaluation/Average Returns        -18.5167
time/data storing (s)               0.00121353
time/evaluation sampling (s)        0.270957
time/exploration sampling (s)       0.0686589
time/logging (s)                    0.00424983
time/saving (s)                     0.00260769
time/training (s)                   1.11067
time/epoch (s)                      1.45836
time/total (s)                    252.643
Epoch                             169
-----------------------------  ---------------
2019-04-21 12:20:38.873779 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 170 finished
-----------------------------  ---------------
replay_buffer/size              34400
trainer/QF1 Loss                    0.589087
trainer/QF2 Loss                    0.579927
trainer/Policy Loss                10.4414
trainer/Q1 Predictions Mean        -8.72584
trainer/Q1 Predictions Std          4.72472
trainer/Q1 Predictions Max         -7.41499
trainer/Q1 Predictions Min        -38.5502
trainer/Q2 Predictions Mean        -8.64673
trainer/Q2 Predictions Std          4.68171
trainer/Q2 Predictions Max         -7.36859
trainer/Q2 Predictions Min        -38.4292
trainer/Q Targets Mean             -8.69527
trainer/Q Targets Std               4.64974
trainer/Q Targets Max              -0.153786
trainer/Q Targets Min             -37.4686
trainer/Log Pis Mean                1.88688
trainer/Log Pis Std                 1.50068
trainer/Log Pis Max                 7.23119
trainer/Log Pis Min                -3.55449
trainer/Policy mu Mean              0.0507577
trainer/Policy mu Std               0.670866
trainer/Policy mu Max               3.00573
trainer/Policy mu Min              -2.54835
trainer/Policy log std Mean        -2.13995
trainer/Policy log std Std          0.439947
trainer/Policy log std Max         -0.546354
trainer/Policy log std Min         -2.36543
trainer/Alpha                       0.0544148
trainer/Alpha Loss                 -0.329307
exploration/num steps total     34400
exploration/num paths total       344
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.513778
exploration/Rewards Std             1.46714
exploration/Rewards Max            -0.00271983
exploration/Rewards Min            -9.15723
exploration/Returns Mean          -51.3778
exploration/Returns Std             6.55205
exploration/Returns Max           -44.8258
exploration/Returns Min           -57.9299
exploration/Actions Mean            0.0382648
exploration/Actions Std             0.262583
exploration/Actions Max             0.999188
exploration/Actions Min            -0.949683
exploration/Num Paths               2
exploration/Average Returns       -51.3778
evaluation/num steps total     171000
evaluation/num paths total       1710
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.221172
evaluation/Rewards Std              1.00908
evaluation/Rewards Max             -0.0168824
evaluation/Rewards Min             -9.46633
evaluation/Returns Mean           -22.1172
evaluation/Returns Std             16.4028
evaluation/Returns Max             -3.6315
evaluation/Returns Min            -51.8184
evaluation/Actions Mean             0.0206932
evaluation/Actions Std              0.187393
evaluation/Actions Max              0.996363
evaluation/Actions Min             -0.996622
evaluation/Num Paths               10
evaluation/Average Returns        -22.1172
time/data storing (s)               0.00128562
time/evaluation sampling (s)        0.269774
time/exploration sampling (s)       0.0630203
time/logging (s)                    0.00413314
time/saving (s)                     0.00242657
time/training (s)                   1.10731
time/epoch (s)                      1.44795
time/total (s)                    254.095
Epoch                             170
-----------------------------  ---------------
2019-04-21 12:20:40.214458 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 171 finished
-----------------------------  ---------------
replay_buffer/size              34600
trainer/QF1 Loss                    0.0155358
trainer/QF2 Loss                    0.0299848
trainer/Policy Loss                 9.69605
trainer/Q1 Predictions Mean        -8.2076
trainer/Q1 Predictions Std          2.8546
trainer/Q1 Predictions Max         -7.43446
trainer/Q1 Predictions Min        -28.6066
trainer/Q2 Predictions Mean        -8.1655
trainer/Q2 Predictions Std          2.83825
trainer/Q2 Predictions Max         -7.42421
trainer/Q2 Predictions Min        -28.0876
trainer/Q Targets Mean             -8.25775
trainer/Q Targets Std               2.83206
trainer/Q Targets Max              -7.37981
trainer/Q Targets Min             -28.8058
trainer/Log Pis Mean                1.81047
trainer/Log Pis Std                 1.10529
trainer/Log Pis Max                 3.81703
trainer/Log Pis Min                -2.57538
trainer/Policy mu Mean              0.00299654
trainer/Policy mu Std               0.537894
trainer/Policy mu Max               2.59463
trainer/Policy mu Min              -3.10217
trainer/Policy log std Mean        -2.14302
trainer/Policy log std Std          0.388711
trainer/Policy log std Max         -0.604606
trainer/Policy log std Min         -2.3611
trainer/Alpha                       0.0550428
trainer/Alpha Loss                 -0.549552
exploration/num steps total     34600
exploration/num paths total       346
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.309993
exploration/Rewards Std             0.780794
exploration/Rewards Max            -0.0114937
exploration/Rewards Min            -6.17819
exploration/Returns Mean          -30.9993
exploration/Returns Std             5.49132
exploration/Returns Max           -25.508
exploration/Returns Min           -36.4907
exploration/Actions Mean            0.0357603
exploration/Actions Std             0.226733
exploration/Actions Max             0.99951
exploration/Actions Min            -0.41896
exploration/Num Paths               2
exploration/Average Returns       -30.9993
evaluation/num steps total     172000
evaluation/num paths total       1720
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.324629
evaluation/Rewards Std              1.05162
evaluation/Rewards Max             -0.08915
evaluation/Rewards Min             -9.64187
evaluation/Returns Mean           -32.4629
evaluation/Returns Std             13.6569
evaluation/Returns Max            -13.9178
evaluation/Returns Min            -56.5161
evaluation/Actions Mean             0.0293868
evaluation/Actions Std              0.192442
evaluation/Actions Max              0.997664
evaluation/Actions Min             -0.997935
evaluation/Num Paths               10
evaluation/Average Returns        -32.4629
time/data storing (s)               0.00115637
time/evaluation sampling (s)        0.265424
time/exploration sampling (s)       0.0627853
time/logging (s)                    0.00355666
time/saving (s)                     0.00233954
time/training (s)                   0.997826
time/epoch (s)                      1.33309
time/total (s)                    255.432
Epoch                             171
-----------------------------  ---------------
2019-04-21 12:20:41.674396 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 172 finished
-----------------------------  ---------------
replay_buffer/size              34800
trainer/QF1 Loss                    1.69942
trainer/QF2 Loss                    1.67634
trainer/Policy Loss                 9.88868
trainer/Q1 Predictions Mean        -8.08376
trainer/Q1 Predictions Std          2.34191
trainer/Q1 Predictions Max         -7.47642
trainer/Q1 Predictions Min        -28.2085
trainer/Q2 Predictions Mean        -8.04385
trainer/Q2 Predictions Std          2.33787
trainer/Q2 Predictions Max         -7.45123
trainer/Q2 Predictions Min        -28.274
trainer/Q Targets Mean             -7.80671
trainer/Q Targets Std               2.69544
trainer/Q Targets Max              -0.0226528
trainer/Q Targets Min             -28.05
trainer/Log Pis Mean                1.9957
trainer/Log Pis Std                 1.28484
trainer/Log Pis Max                 7.77571
trainer/Log Pis Min                -2.1501
trainer/Policy mu Mean              0.0503398
trainer/Policy mu Std               0.492153
trainer/Policy mu Max               2.59528
trainer/Policy mu Min              -2.55393
trainer/Policy log std Mean        -2.21655
trainer/Policy log std Std          0.358875
trainer/Policy log std Max         -0.585192
trainer/Policy log std Min         -2.37197
trainer/Alpha                       0.0535936
trainer/Alpha Loss                 -0.0125907
exploration/num steps total     34800
exploration/num paths total       348
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.424417
exploration/Rewards Std             1.27782
exploration/Rewards Max            -0.0102835
exploration/Rewards Min            -9.17765
exploration/Returns Mean          -42.4417
exploration/Returns Std            15.8988
exploration/Returns Max           -26.5428
exploration/Returns Min           -58.3405
exploration/Actions Mean            0.0359364
exploration/Actions Std             0.244964
exploration/Actions Max             0.998858
exploration/Actions Min            -0.810613
exploration/Num Paths               2
exploration/Average Returns       -42.4417
evaluation/num steps total     173000
evaluation/num paths total       1730
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.30133
evaluation/Rewards Std              1.19358
evaluation/Rewards Max             -0.0253387
evaluation/Rewards Min            -10.0494
evaluation/Returns Mean           -30.133
evaluation/Returns Std             17.8322
evaluation/Returns Max             -8.38854
evaluation/Returns Min            -57.3444
evaluation/Actions Mean             0.0397391
evaluation/Actions Std              0.199076
evaluation/Actions Max              0.998423
evaluation/Actions Min             -0.846822
evaluation/Num Paths               10
evaluation/Average Returns        -30.133
time/data storing (s)               0.00114674
time/evaluation sampling (s)        0.251335
time/exploration sampling (s)       0.0641961
time/logging (s)                    0.00392415
time/saving (s)                     0.00262233
time/training (s)                   1.13002
time/epoch (s)                      1.45325
time/total (s)                    256.89
Epoch                             172
-----------------------------  ---------------
2019-04-21 12:20:43.061261 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 173 finished
-----------------------------  ---------------
replay_buffer/size              35000
trainer/QF1 Loss                    0.586859
trainer/QF2 Loss                    0.57571
trainer/Policy Loss                11.0704
trainer/Q1 Predictions Mean        -9.45911
trainer/Q1 Predictions Std          8.63904
trainer/Q1 Predictions Max         -7.37065
trainer/Q1 Predictions Min        -71.4054
trainer/Q2 Predictions Mean        -9.46232
trainer/Q2 Predictions Std          8.70589
trainer/Q2 Predictions Max         -7.34736
trainer/Q2 Predictions Min        -71.632
trainer/Q Targets Mean             -9.4959
trainer/Q Targets Std               8.81028
trainer/Q Targets Max              -0.409941
trainer/Q Targets Min             -73.0199
trainer/Log Pis Mean                2.07217
trainer/Log Pis Std                 1.01265
trainer/Log Pis Max                 5.76421
trainer/Log Pis Min                -2.39316
trainer/Policy mu Mean              0.0882016
trainer/Policy mu Std               0.64307
trainer/Policy mu Max               3.1952
trainer/Policy mu Min              -3.2276
trainer/Policy log std Mean        -2.13864
trainer/Policy log std Std          0.423208
trainer/Policy log std Max         -0.530543
trainer/Policy log std Min         -2.35887
trainer/Alpha                       0.0534101
trainer/Alpha Loss                  0.211439
exploration/num steps total     35000
exploration/num paths total       350
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.256113
exploration/Rewards Std             0.669464
exploration/Rewards Max            -0.00982419
exploration/Rewards Min            -5.36046
exploration/Returns Mean          -25.6113
exploration/Returns Std             1.41474
exploration/Returns Max           -24.1965
exploration/Returns Min           -27.026
exploration/Actions Mean            0.0142459
exploration/Actions Std             0.238433
exploration/Actions Max             0.994871
exploration/Actions Min            -0.999286
exploration/Num Paths               2
exploration/Average Returns       -25.6113
evaluation/num steps total     174000
evaluation/num paths total       1740
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.30494
evaluation/Rewards Std              1.16467
evaluation/Rewards Max             -0.0486602
evaluation/Rewards Min            -10.6303
evaluation/Returns Mean           -30.494
evaluation/Returns Std             14.6796
evaluation/Returns Max             -9.35327
evaluation/Returns Min            -57.1551
evaluation/Actions Mean             0.0293208
evaluation/Actions Std              0.212198
evaluation/Actions Max              0.998182
evaluation/Actions Min             -0.995168
evaluation/Num Paths               10
evaluation/Average Returns        -30.494
time/data storing (s)               0.0012676
time/evaluation sampling (s)        0.264418
time/exploration sampling (s)       0.0643942
time/logging (s)                    0.00345239
time/saving (s)                     0.00242759
time/training (s)                   1.04139
time/epoch (s)                      1.37735
time/total (s)                    258.273
Epoch                             173
-----------------------------  ---------------
2019-04-21 12:20:44.406771 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 174 finished
-----------------------------  ---------------
replay_buffer/size              35200
trainer/QF1 Loss                    1.66258
trainer/QF2 Loss                    1.63888
trainer/Policy Loss                10.2916
trainer/Q1 Predictions Mean        -8.48651
trainer/Q1 Predictions Std          5.69147
trainer/Q1 Predictions Max         -7.39937
trainer/Q1 Predictions Min        -53.4791
trainer/Q2 Predictions Mean        -8.49685
trainer/Q2 Predictions Std          5.73679
trainer/Q2 Predictions Max         -7.41011
trainer/Q2 Predictions Min        -53.7863
trainer/Q Targets Mean             -8.28047
trainer/Q Targets Std               5.90321
trainer/Q Targets Max              -0.244168
trainer/Q Targets Min             -54.2799
trainer/Log Pis Mean                1.92511
trainer/Log Pis Std                 1.28555
trainer/Log Pis Max                 5.59116
trainer/Log Pis Min                -5.92305
trainer/Policy mu Mean              0.0557395
trainer/Policy mu Std               0.548627
trainer/Policy mu Max               3.09305
trainer/Policy mu Min              -1.99131
trainer/Policy log std Mean        -2.1711
trainer/Policy log std Std          0.393255
trainer/Policy log std Max         -0.63638
trainer/Policy log std Min         -2.38861
trainer/Alpha                       0.0527067
trainer/Alpha Loss                 -0.22039
exploration/num steps total     35200
exploration/num paths total       352
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.493577
exploration/Rewards Std             1.46584
exploration/Rewards Max            -0.00552073
exploration/Rewards Min            -9.6386
exploration/Returns Mean          -49.3577
exploration/Returns Std            13.5164
exploration/Returns Max           -35.8413
exploration/Returns Min           -62.874
exploration/Actions Mean            0.0368311
exploration/Actions Std             0.253341
exploration/Actions Max             0.999225
exploration/Actions Min            -0.821333
exploration/Num Paths               2
exploration/Average Returns       -49.3577
evaluation/num steps total     175000
evaluation/num paths total       1750
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.15119
evaluation/Rewards Std              0.781593
evaluation/Rewards Max             -0.00902756
evaluation/Rewards Min            -10.2521
evaluation/Returns Mean           -15.119
evaluation/Returns Std             15.9842
evaluation/Returns Max             -2.65132
evaluation/Returns Min            -60.3452
evaluation/Actions Mean             0.0203202
evaluation/Actions Std              0.156619
evaluation/Actions Max              0.996929
evaluation/Actions Min             -0.975956
evaluation/Num Paths               10
evaluation/Average Returns        -15.119
time/data storing (s)               0.00114666
time/evaluation sampling (s)        0.270967
time/exploration sampling (s)       0.0688618
time/logging (s)                    0.00277972
time/saving (s)                     0.00203093
time/training (s)                   0.991191
time/epoch (s)                      1.33698
time/total (s)                    259.614
Epoch                             174
-----------------------------  ---------------
2019-04-21 12:20:45.959086 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 175 finished
-----------------------------  ---------------
replay_buffer/size              35400
trainer/QF1 Loss                    0.568543
trainer/QF2 Loss                    0.548158
trainer/Policy Loss                10.0171
trainer/Q1 Predictions Mean        -8.00693
trainer/Q1 Predictions Std          2.92743
trainer/Q1 Predictions Max         -7.21296
trainer/Q1 Predictions Min        -32.3296
trainer/Q2 Predictions Mean        -8.02786
trainer/Q2 Predictions Std          2.94677
trainer/Q2 Predictions Max         -7.23752
trainer/Q2 Predictions Min        -32.7658
trainer/Q Targets Mean             -8.11703
trainer/Q Targets Std               3.0412
trainer/Q Targets Max              -0.512884
trainer/Q Targets Min             -32.8898
trainer/Log Pis Mean                2.08489
trainer/Log Pis Std                 1.13682
trainer/Log Pis Max                 6.30967
trainer/Log Pis Min                -1.72462
trainer/Policy mu Mean              0.0215194
trainer/Policy mu Std               0.615787
trainer/Policy mu Max               2.972
trainer/Policy mu Min              -2.9606
trainer/Policy log std Mean        -2.18275
trainer/Policy log std Std          0.440963
trainer/Policy log std Max         -0.630125
trainer/Policy log std Min         -2.41187
trainer/Alpha                       0.053854
trainer/Alpha Loss                  0.247993
exploration/num steps total     35400
exploration/num paths total       354
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.446327
exploration/Rewards Std             1.41928
exploration/Rewards Max            -0.00425921
exploration/Rewards Min           -10.3505
exploration/Returns Mean          -44.6327
exploration/Returns Std            24.5996
exploration/Returns Max           -20.0331
exploration/Returns Min           -69.2323
exploration/Actions Mean            0.0446444
exploration/Actions Std             0.244137
exploration/Actions Max             0.99989
exploration/Actions Min            -0.506391
exploration/Num Paths               2
exploration/Average Returns       -44.6327
evaluation/num steps total     176000
evaluation/num paths total       1760
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.270981
evaluation/Rewards Std              1.12824
evaluation/Rewards Max             -0.00408154
evaluation/Rewards Min            -10.1718
evaluation/Returns Mean           -27.0981
evaluation/Returns Std             18.2988
evaluation/Returns Max             -4.91447
evaluation/Returns Min            -55.8957
evaluation/Actions Mean             0.0240974
evaluation/Actions Std              0.195875
evaluation/Actions Max              0.998104
evaluation/Actions Min             -0.997447
evaluation/Num Paths               10
evaluation/Average Returns        -27.0981
time/data storing (s)               0.00124608
time/evaluation sampling (s)        0.261964
time/exploration sampling (s)       0.0815716
time/logging (s)                    0.0034733
time/saving (s)                     0.00306723
time/training (s)                   1.19519
time/epoch (s)                      1.54651
time/total (s)                    261.166
Epoch                             175
-----------------------------  ---------------
2019-04-21 12:20:47.538883 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 176 finished
-----------------------------  ---------------
replay_buffer/size              35600
trainer/QF1 Loss                    0.600206
trainer/QF2 Loss                    0.584501
trainer/Policy Loss                 9.84424
trainer/Q1 Predictions Mean        -8.14232
trainer/Q1 Predictions Std          2.59803
trainer/Q1 Predictions Max         -7.4347
trainer/Q1 Predictions Min        -27.8126
trainer/Q2 Predictions Mean        -8.05649
trainer/Q2 Predictions Std          2.58684
trainer/Q2 Predictions Max         -7.35759
trainer/Q2 Predictions Min        -27.8573
trainer/Q Targets Mean             -8.05814
trainer/Q Targets Std               2.86677
trainer/Q Targets Max              -0.0956272
trainer/Q Targets Min             -29.2627
trainer/Log Pis Mean                1.8518
trainer/Log Pis Std                 1.00814
trainer/Log Pis Max                 4.59001
trainer/Log Pis Min                -1.90352
trainer/Policy mu Mean              0.195132
trainer/Policy mu Std               0.609672
trainer/Policy mu Max               3.1821
trainer/Policy mu Min              -2.35604
trainer/Policy log std Mean        -2.05298
trainer/Policy log std Std          0.437709
trainer/Policy log std Max         -0.48618
trainer/Policy log std Min         -2.29115
trainer/Alpha                       0.0531994
trainer/Alpha Loss                 -0.434769
exploration/num steps total     35600
exploration/num paths total       356
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.253856
exploration/Rewards Std             0.476381
exploration/Rewards Max            -0.00390333
exploration/Rewards Min            -4.46854
exploration/Returns Mean          -25.3856
exploration/Returns Std             1.16571
exploration/Returns Max           -24.2199
exploration/Returns Min           -26.5513
exploration/Actions Mean            0.0205064
exploration/Actions Std             0.230533
exploration/Actions Max             0.986674
exploration/Actions Min            -0.987406
exploration/Num Paths               2
exploration/Average Returns       -25.3856
evaluation/num steps total     177000
evaluation/num paths total       1770
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.263107
evaluation/Rewards Std              0.758983
evaluation/Rewards Max             -0.052348
evaluation/Rewards Min             -8.70461
evaluation/Returns Mean           -26.3107
evaluation/Returns Std             11.8385
evaluation/Returns Max            -13.2548
evaluation/Returns Min            -53.0232
evaluation/Actions Mean             0.0133859
evaluation/Actions Std              0.17136
evaluation/Actions Max              0.997901
evaluation/Actions Min             -0.996562
evaluation/Num Paths               10
evaluation/Average Returns        -26.3107
time/data storing (s)               0.00151078
time/evaluation sampling (s)        0.283295
time/exploration sampling (s)       0.0942792
time/logging (s)                    0.0035796
time/saving (s)                     0.00264138
time/training (s)                   1.18673
time/epoch (s)                      1.57203
time/total (s)                    262.742
Epoch                             176
-----------------------------  ---------------
2019-04-21 12:20:49.104508 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 177 finished
-----------------------------  ----------------
replay_buffer/size              35800
trainer/QF1 Loss                    0.573632
trainer/QF2 Loss                    0.543142
trainer/Policy Loss                10.3963
trainer/Q1 Predictions Mean        -8.52897
trainer/Q1 Predictions Std          3.97155
trainer/Q1 Predictions Max         -7.34222
trainer/Q1 Predictions Min        -35.8324
trainer/Q2 Predictions Mean        -8.51037
trainer/Q2 Predictions Std          3.90526
trainer/Q2 Predictions Max         -7.3429
trainer/Q2 Predictions Min        -35.2111
trainer/Q Targets Mean             -8.4525
trainer/Q Targets Std               3.92613
trainer/Q Targets Max              -0.306191
trainer/Q Targets Min             -34.2383
trainer/Log Pis Mean                2.18348
trainer/Log Pis Std                 1.08028
trainer/Log Pis Max                 6.53737
trainer/Log Pis Min                -1.18101
trainer/Policy mu Mean              0.0774253
trainer/Policy mu Std               0.673231
trainer/Policy mu Max               2.87999
trainer/Policy mu Min              -1.90427
trainer/Policy log std Mean        -2.13739
trainer/Policy log std Std          0.452581
trainer/Policy log std Max         -0.508305
trainer/Policy log std Min         -2.38762
trainer/Alpha                       0.0519225
trainer/Alpha Loss                  0.542762
exploration/num steps total     35800
exploration/num paths total       358
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.318074
exploration/Rewards Std             0.973965
exploration/Rewards Max            -0.00292412
exploration/Rewards Min            -8.16321
exploration/Returns Mean          -31.8074
exploration/Returns Std             9.4705
exploration/Returns Max           -22.3369
exploration/Returns Min           -41.2779
exploration/Actions Mean           -0.000395977
exploration/Actions Std             0.254111
exploration/Actions Max             0.995483
exploration/Actions Min            -0.994195
exploration/Num Paths               2
exploration/Average Returns       -31.8074
evaluation/num steps total     178000
evaluation/num paths total       1780
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.243634
evaluation/Rewards Std              0.960929
evaluation/Rewards Max             -0.015407
evaluation/Rewards Min             -9.19315
evaluation/Returns Mean           -24.3634
evaluation/Returns Std             13.4393
evaluation/Returns Max             -6.33143
evaluation/Returns Min            -51.5332
evaluation/Actions Mean             0.0312004
evaluation/Actions Std              0.187073
evaluation/Actions Max              0.996453
evaluation/Actions Min             -0.974331
evaluation/Num Paths               10
evaluation/Average Returns        -24.3634
time/data storing (s)               0.00108054
time/evaluation sampling (s)        0.257119
time/exploration sampling (s)       0.0631077
time/logging (s)                    0.0042781
time/saving (s)                     0.00245573
time/training (s)                   1.23036
time/epoch (s)                      1.5584
time/total (s)                    264.305
Epoch                             177
-----------------------------  ----------------
2019-04-21 12:20:50.617761 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 178 finished
-----------------------------  ---------------
replay_buffer/size              36000
trainer/QF1 Loss                    0.0209273
trainer/QF2 Loss                    0.0251893
trainer/Policy Loss                10.5895
trainer/Q1 Predictions Mean        -8.69825
trainer/Q1 Predictions Std          5.40284
trainer/Q1 Predictions Max         -7.26089
trainer/Q1 Predictions Min        -42.902
trainer/Q2 Predictions Mean        -8.77529
trainer/Q2 Predictions Std          5.46761
trainer/Q2 Predictions Max         -7.35368
trainer/Q2 Predictions Min        -43.4961
trainer/Q Targets Mean             -8.75958
trainer/Q Targets Std               5.39314
trainer/Q Targets Max              -7.2871
trainer/Q Targets Min             -42.9019
trainer/Log Pis Mean                1.96339
trainer/Log Pis Std                 1.23501
trainer/Log Pis Max                 7.75891
trainer/Log Pis Min                -1.66504
trainer/Policy mu Mean              0.0817882
trainer/Policy mu Std               0.644398
trainer/Policy mu Max               3.10445
trainer/Policy mu Min              -1.96585
trainer/Policy log std Mean        -2.1313
trainer/Policy log std Std          0.418251
trainer/Policy log std Max         -0.596866
trainer/Policy log std Min         -2.3974
trainer/Alpha                       0.0517888
trainer/Alpha Loss                 -0.108373
exploration/num steps total     36000
exploration/num paths total       360
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.422079
exploration/Rewards Std             1.21221
exploration/Rewards Max            -0.0075055
exploration/Rewards Min            -8.96825
exploration/Returns Mean          -42.2079
exploration/Returns Std            16.8593
exploration/Returns Max           -25.3485
exploration/Returns Min           -59.0672
exploration/Actions Mean            0.0452444
exploration/Actions Std             0.242951
exploration/Actions Max             0.999707
exploration/Actions Min            -0.513018
exploration/Num Paths               2
exploration/Average Returns       -42.2079
evaluation/num steps total     179000
evaluation/num paths total       1790
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.217488
evaluation/Rewards Std              0.762132
evaluation/Rewards Max             -0.0478657
evaluation/Rewards Min             -7.37538
evaluation/Returns Mean           -21.7488
evaluation/Returns Std              8.20564
evaluation/Returns Max            -11.8461
evaluation/Returns Min            -36.7829
evaluation/Actions Mean             0.0218085
evaluation/Actions Std              0.182749
evaluation/Actions Max              0.995822
evaluation/Actions Min             -0.991787
evaluation/Num Paths               10
evaluation/Average Returns        -21.7488
time/data storing (s)               0.00137973
time/evaluation sampling (s)        0.317365
time/exploration sampling (s)       0.0875715
time/logging (s)                    0.0034319
time/saving (s)                     0.0023474
time/training (s)                   1.09256
time/epoch (s)                      1.50465
time/total (s)                    265.815
Epoch                             178
-----------------------------  ---------------
2019-04-21 12:20:52.127092 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 179 finished
-----------------------------  ---------------
replay_buffer/size              36200
trainer/QF1 Loss                    0.0483297
trainer/QF2 Loss                    0.0359831
trainer/Policy Loss                 9.9789
trainer/Q1 Predictions Mean        -8.26506
trainer/Q1 Predictions Std          4.18669
trainer/Q1 Predictions Max         -7.35669
trainer/Q1 Predictions Min        -43.5539
trainer/Q2 Predictions Mean        -8.26889
trainer/Q2 Predictions Std          4.17894
trainer/Q2 Predictions Max         -7.37105
trainer/Q2 Predictions Min        -43.6187
trainer/Q Targets Mean             -8.20139
trainer/Q Targets Std               4.03713
trainer/Q Targets Max              -7.26556
trainer/Q Targets Min             -42.5484
trainer/Log Pis Mean                1.82931
trainer/Log Pis Std                 1.41825
trainer/Log Pis Max                 5.02293
trainer/Log Pis Min                -4.22858
trainer/Policy mu Mean              0.0918257
trainer/Policy mu Std               0.597282
trainer/Policy mu Max               3.09845
trainer/Policy mu Min              -2.21006
trainer/Policy log std Mean        -2.20866
trainer/Policy log std Std          0.420345
trainer/Policy log std Max         -0.462566
trainer/Policy log std Min         -2.42185
trainer/Alpha                       0.0512771
trainer/Alpha Loss                 -0.507062
exploration/num steps total     36200
exploration/num paths total       362
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.189385
exploration/Rewards Std             0.435734
exploration/Rewards Max            -0.00377885
exploration/Rewards Min            -4.10171
exploration/Returns Mean          -18.9385
exploration/Returns Std             3.259
exploration/Returns Max           -15.6795
exploration/Returns Min           -22.1975
exploration/Actions Mean            0.021947
exploration/Actions Std             0.190154
exploration/Actions Max             0.995802
exploration/Actions Min            -0.420728
exploration/Num Paths               2
exploration/Average Returns       -18.9385
evaluation/num steps total     180000
evaluation/num paths total       1800
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.303849
evaluation/Rewards Std              1.2335
evaluation/Rewards Max             -0.0250564
evaluation/Rewards Min             -9.78743
evaluation/Returns Mean           -30.3849
evaluation/Returns Std             13.7958
evaluation/Returns Max            -13.3855
evaluation/Returns Min            -52.9853
evaluation/Actions Mean             0.0493255
evaluation/Actions Std              0.222927
evaluation/Actions Max              0.996768
evaluation/Actions Min             -0.988478
evaluation/Num Paths               10
evaluation/Average Returns        -30.3849
time/data storing (s)               0.00116769
time/evaluation sampling (s)        0.279001
time/exploration sampling (s)       0.0726647
time/logging (s)                    0.00396168
time/saving (s)                     0.00263816
time/training (s)                   1.14228
time/epoch (s)                      1.50171
time/total (s)                    267.321
Epoch                             179
-----------------------------  ---------------
2019-04-21 12:20:53.557146 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 180 finished
-----------------------------  ---------------
replay_buffer/size              36400
trainer/QF1 Loss                    0.0647534
trainer/QF2 Loss                    0.0924702
trainer/Policy Loss                 9.0974
trainer/Q1 Predictions Mean        -7.72193
trainer/Q1 Predictions Std          2.75816
trainer/Q1 Predictions Max         -7.06438
trainer/Q1 Predictions Min        -26.6399
trainer/Q2 Predictions Mean        -7.66341
trainer/Q2 Predictions Std          2.70482
trainer/Q2 Predictions Max         -7.03845
trainer/Q2 Predictions Min        -26.1679
trainer/Q Targets Mean             -7.93659
trainer/Q Targets Std               2.76985
trainer/Q Targets Max              -7.22567
trainer/Q Targets Min             -27.3751
trainer/Log Pis Mean                1.44284
trainer/Log Pis Std                 1.26442
trainer/Log Pis Max                 5.72582
trainer/Log Pis Min                -2.82277
trainer/Policy mu Mean              0.0161779
trainer/Policy mu Std               0.418252
trainer/Policy mu Max               2.91284
trainer/Policy mu Min              -1.31422
trainer/Policy log std Mean        -2.12665
trainer/Policy log std Std          0.242135
trainer/Policy log std Max         -0.746757
trainer/Policy log std Min         -2.22362
trainer/Alpha                       0.0529936
trainer/Alpha Loss                 -1.63653
exploration/num steps total     36400
exploration/num paths total       364
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.210203
exploration/Rewards Std             0.475515
exploration/Rewards Max            -0.00534624
exploration/Rewards Min            -4.72899
exploration/Returns Mean          -21.0203
exploration/Returns Std             7.43834
exploration/Returns Max           -13.5819
exploration/Returns Min           -28.4586
exploration/Actions Mean            0.0122355
exploration/Actions Std             0.192969
exploration/Actions Max             0.986759
exploration/Actions Min            -0.573546
exploration/Num Paths               2
exploration/Average Returns       -21.0203
evaluation/num steps total     181000
evaluation/num paths total       1810
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.24326
evaluation/Rewards Std              1.01228
evaluation/Rewards Max             -0.0283976
evaluation/Rewards Min            -10.5953
evaluation/Returns Mean           -24.326
evaluation/Returns Std             16.0897
evaluation/Returns Max             -4.80457
evaluation/Returns Min            -57.1886
evaluation/Actions Mean             0.0139875
evaluation/Actions Std              0.197234
evaluation/Actions Max              0.997842
evaluation/Actions Min             -0.996917
evaluation/Num Paths               10
evaluation/Average Returns        -24.326
time/data storing (s)               0.001162
time/evaluation sampling (s)        0.273997
time/exploration sampling (s)       0.0659407
time/logging (s)                    0.00291493
time/saving (s)                     0.00185273
time/training (s)                   1.07642
time/epoch (s)                      1.42229
time/total (s)                    268.748
Epoch                             180
-----------------------------  ---------------
2019-04-21 12:20:55.417526 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 181 finished
-----------------------------  ---------------
replay_buffer/size              36600
trainer/QF1 Loss                    1.04559
trainer/QF2 Loss                    1.03966
trainer/Policy Loss                 9.78408
trainer/Q1 Predictions Mean        -7.7683
trainer/Q1 Predictions Std          2.09491
trainer/Q1 Predictions Max         -7.16958
trainer/Q1 Predictions Min        -24.6191
trainer/Q2 Predictions Mean        -7.77217
trainer/Q2 Predictions Std          2.12686
trainer/Q2 Predictions Max         -7.17929
trainer/Q2 Predictions Min        -24.7444
trainer/Q Targets Mean             -7.73352
trainer/Q Targets Std               2.44763
trainer/Q Targets Max              -0.130196
trainer/Q Targets Min             -25.6648
trainer/Log Pis Mean                2.21541
trainer/Log Pis Std                 1.07275
trainer/Log Pis Max                 6.05962
trainer/Log Pis Min                -0.977913
trainer/Policy mu Mean              0.0687221
trainer/Policy mu Std               0.50161
trainer/Policy mu Max               3.11613
trainer/Policy mu Min              -1.18131
trainer/Policy log std Mean        -2.27031
trainer/Policy log std Std          0.365506
trainer/Policy log std Max         -0.546037
trainer/Policy log std Min         -2.44783
trainer/Alpha                       0.0522748
trainer/Alpha Loss                  0.635781
exploration/num steps total     36600
exploration/num paths total       366
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.124357
exploration/Rewards Std             0.121487
exploration/Rewards Max            -0.00154775
exploration/Rewards Min            -1.50251
exploration/Returns Mean          -12.4357
exploration/Returns Std             1.51203
exploration/Returns Max           -10.9236
exploration/Returns Min           -13.9477
exploration/Actions Mean            0.00470566
exploration/Actions Std             0.149713
exploration/Actions Max             0.990262
exploration/Actions Min            -0.453729
exploration/Num Paths               2
exploration/Average Returns       -12.4357
evaluation/num steps total     182000
evaluation/num paths total       1820
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.112823
evaluation/Rewards Std              0.681198
evaluation/Rewards Max             -0.00164004
evaluation/Rewards Min             -7.7889
evaluation/Returns Mean           -11.2823
evaluation/Returns Std             11.0738
evaluation/Returns Max             -0.259339
evaluation/Returns Min            -32.57
evaluation/Actions Mean             0.0197267
evaluation/Actions Std              0.160828
evaluation/Actions Max              0.995549
evaluation/Actions Min             -0.990596
evaluation/Num Paths               10
evaluation/Average Returns        -11.2823
time/data storing (s)               0.0013473
time/evaluation sampling (s)        0.259089
time/exploration sampling (s)       0.0719103
time/logging (s)                    0.00415345
time/saving (s)                     0.0039057
time/training (s)                   1.51361
time/epoch (s)                      1.85401
time/total (s)                    270.607
Epoch                             181
-----------------------------  ---------------
2019-04-21 12:20:56.868766 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 182 finished
-----------------------------  ---------------
replay_buffer/size              36800
trainer/QF1 Loss                    0.638353
trainer/QF2 Loss                    0.611613
trainer/Policy Loss                 9.68088
trainer/Q1 Predictions Mean        -7.96394
trainer/Q1 Predictions Std          3.82674
trainer/Q1 Predictions Max         -6.96174
trainer/Q1 Predictions Min        -28.3777
trainer/Q2 Predictions Mean        -8.03369
trainer/Q2 Predictions Std          3.79942
trainer/Q2 Predictions Max         -7.04052
trainer/Q2 Predictions Min        -28.0498
trainer/Q Targets Mean             -8.24201
trainer/Q Targets Std               4.01718
trainer/Q Targets Max              -0.0180781
trainer/Q Targets Min             -28.1985
trainer/Log Pis Mean                1.82853
trainer/Log Pis Std                 1.20193
trainer/Log Pis Max                 7.32732
trainer/Log Pis Min                -2.55947
trainer/Policy mu Mean              0.0288703
trainer/Policy mu Std               0.60451
trainer/Policy mu Max               2.85459
trainer/Policy mu Min              -3.47565
trainer/Policy log std Mean        -2.11486
trainer/Policy log std Std          0.407785
trainer/Policy log std Max         -0.550133
trainer/Policy log std Min         -2.32156
trainer/Alpha                       0.0543906
trainer/Alpha Loss                 -0.499232
exploration/num steps total     36800
exploration/num paths total       368
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.261462
exploration/Rewards Std             0.63988
exploration/Rewards Max            -0.0162652
exploration/Rewards Min            -4.90307
exploration/Returns Mean          -26.1462
exploration/Returns Std             0.196589
exploration/Returns Max           -25.9496
exploration/Returns Min           -26.3428
exploration/Actions Mean            0.0202679
exploration/Actions Std             0.237461
exploration/Actions Max             0.99675
exploration/Actions Min            -0.993523
exploration/Num Paths               2
exploration/Average Returns       -26.1462
evaluation/num steps total     183000
evaluation/num paths total       1830
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.11023
evaluation/Rewards Std              0.455225
evaluation/Rewards Max             -0.0188026
evaluation/Rewards Min             -6.07749
evaluation/Returns Mean           -11.023
evaluation/Returns Std              5.41854
evaluation/Returns Max             -4.47172
evaluation/Returns Min            -22.2948
evaluation/Actions Mean             0.0154156
evaluation/Actions Std              0.151736
evaluation/Actions Max              0.996845
evaluation/Actions Min             -0.985559
evaluation/Num Paths               10
evaluation/Average Returns        -11.023
time/data storing (s)               0.00118938
time/evaluation sampling (s)        0.294339
time/exploration sampling (s)       0.0737206
time/logging (s)                    0.00354519
time/saving (s)                     0.00241828
time/training (s)                   1.06662
time/epoch (s)                      1.44183
time/total (s)                    272.053
Epoch                             182
-----------------------------  ---------------
2019-04-21 12:20:58.326931 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 183 finished
-----------------------------  ----------------
replay_buffer/size              37000
trainer/QF1 Loss                    1.0854
trainer/QF2 Loss                    1.06346
trainer/Policy Loss                 9.48702
trainer/Q1 Predictions Mean        -7.68695
trainer/Q1 Predictions Std          0.808743
trainer/Q1 Predictions Max         -7.30958
trainer/Q1 Predictions Min        -14.0223
trainer/Q2 Predictions Mean        -7.64349
trainer/Q2 Predictions Std          0.835449
trainer/Q2 Predictions Max         -7.26898
trainer/Q2 Predictions Min        -14.1875
trainer/Q Targets Mean             -7.4788
trainer/Q Targets Std               1.35009
trainer/Q Targets Max              -0.070668
trainer/Q Targets Min             -14.6207
trainer/Log Pis Mean                1.97771
trainer/Log Pis Std                 1.03016
trainer/Log Pis Max                 5.97817
trainer/Log Pis Min                -1.24439
trainer/Policy mu Mean             -0.0310841
trainer/Policy mu Std               0.479204
trainer/Policy mu Max               2.32572
trainer/Policy mu Min              -1.76915
trainer/Policy log std Mean        -2.21204
trainer/Policy log std Std          0.373399
trainer/Policy log std Max         -0.592609
trainer/Policy log std Min         -2.44716
trainer/Alpha                       0.0545693
trainer/Alpha Loss                 -0.0648394
exploration/num steps total     37000
exploration/num paths total       370
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.423199
exploration/Rewards Std             1.22649
exploration/Rewards Max            -0.000667119
exploration/Rewards Min            -7.75027
exploration/Returns Mean          -42.3199
exploration/Returns Std             1.38792
exploration/Returns Max           -40.9319
exploration/Returns Min           -43.7078
exploration/Actions Mean            0.045868
exploration/Actions Std             0.237786
exploration/Actions Max             0.999201
exploration/Actions Min            -0.401106
exploration/Num Paths               2
exploration/Average Returns       -42.3199
evaluation/num steps total     184000
evaluation/num paths total       1840
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.321401
evaluation/Rewards Std              1.18024
evaluation/Rewards Max             -0.0529869
evaluation/Rewards Min             -9.23807
evaluation/Returns Mean           -32.1401
evaluation/Returns Std             12.9732
evaluation/Returns Max            -13.1621
evaluation/Returns Min            -50.2583
evaluation/Actions Mean             0.0417343
evaluation/Actions Std              0.211355
evaluation/Actions Max              0.996462
evaluation/Actions Min             -0.99681
evaluation/Num Paths               10
evaluation/Average Returns        -32.1401
time/data storing (s)               0.00119232
time/evaluation sampling (s)        0.267947
time/exploration sampling (s)       0.0700425
time/logging (s)                    0.00346307
time/saving (s)                     0.00230511
time/training (s)                   1.10504
time/epoch (s)                      1.44999
time/total (s)                    273.508
Epoch                             183
-----------------------------  ----------------
2019-04-21 12:20:59.768469 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 184 finished
-----------------------------  ---------------
replay_buffer/size              37200
trainer/QF1 Loss                    1.59806
trainer/QF2 Loss                    1.56009
trainer/Policy Loss                 9.76001
trainer/Q1 Predictions Mean        -8.1514
trainer/Q1 Predictions Std          3.98645
trainer/Q1 Predictions Max         -7.2527
trainer/Q1 Predictions Min        -44.5362
trainer/Q2 Predictions Mean        -8.07004
trainer/Q2 Predictions Std          3.99058
trainer/Q2 Predictions Max         -7.19319
trainer/Q2 Predictions Min        -44.5523
trainer/Q Targets Mean             -7.89303
trainer/Q Targets Std               4.14046
trainer/Q Targets Max              -0.00756552
trainer/Q Targets Min             -43.7499
trainer/Log Pis Mean                1.73311
trainer/Log Pis Std                 1.24894
trainer/Log Pis Max                 6.59654
trainer/Log Pis Min                -3.62443
trainer/Policy mu Mean              0.0617179
trainer/Policy mu Std               0.576139
trainer/Policy mu Max               3.04765
trainer/Policy mu Min              -2.25831
trainer/Policy log std Mean        -2.10491
trainer/Policy log std Std          0.390685
trainer/Policy log std Max         -0.480764
trainer/Policy log std Min         -2.35669
trainer/Alpha                       0.0544634
trainer/Alpha Loss                 -0.776623
exploration/num steps total     37200
exploration/num paths total       372
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.205192
exploration/Rewards Std             0.504539
exploration/Rewards Max            -0.00652637
exploration/Rewards Min            -4.92406
exploration/Returns Mean          -20.5192
exploration/Returns Std             7.01113
exploration/Returns Max           -13.5081
exploration/Returns Min           -27.5303
exploration/Actions Mean           -0.00694628
exploration/Actions Std             0.202382
exploration/Actions Max             0.980446
exploration/Actions Min            -0.996615
exploration/Num Paths               2
exploration/Average Returns       -20.5192
evaluation/num steps total     185000
evaluation/num paths total       1850
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.152342
evaluation/Rewards Std              0.647711
evaluation/Rewards Max             -0.0246221
evaluation/Rewards Min             -7.11711
evaluation/Returns Mean           -15.2342
evaluation/Returns Std              9.37044
evaluation/Returns Max             -4.82502
evaluation/Returns Min            -31.3397
evaluation/Actions Mean             0.0134097
evaluation/Actions Std              0.163178
evaluation/Actions Max              0.995147
evaluation/Actions Min             -0.994469
evaluation/Num Paths               10
evaluation/Average Returns        -15.2342
time/data storing (s)               0.00116532
time/evaluation sampling (s)        0.247241
time/exploration sampling (s)       0.0647798
time/logging (s)                    0.00345798
time/saving (s)                     0.00258548
time/training (s)                   1.11482
time/epoch (s)                      1.43405
time/total (s)                    274.946
Epoch                             184
-----------------------------  ---------------
2019-04-21 12:21:01.147564 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 185 finished
-----------------------------  ---------------
replay_buffer/size              37400
trainer/QF1 Loss                    1.03204
trainer/QF2 Loss                    1.03348
trainer/Policy Loss                11.6365
trainer/Q1 Predictions Mean        -9.54738
trainer/Q1 Predictions Std          9.47291
trainer/Q1 Predictions Max         -7.06126
trainer/Q1 Predictions Min        -69.8021
trainer/Q2 Predictions Mean        -9.56729
trainer/Q2 Predictions Std          9.56151
trainer/Q2 Predictions Max         -7.09271
trainer/Q2 Predictions Min        -70.266
trainer/Q Targets Mean             -9.50777
trainer/Q Targets Std               9.57007
trainer/Q Targets Max              -0.177918
trainer/Q Targets Min             -70.9694
trainer/Log Pis Mean                2.41862
trainer/Log Pis Std                 1.19333
trainer/Log Pis Max                 7.7254
trainer/Log Pis Min                -0.268168
trainer/Policy mu Mean              0.0918573
trainer/Policy mu Std               0.720288
trainer/Policy mu Max               3.16813
trainer/Policy mu Min              -2.58973
trainer/Policy log std Mean        -2.18058
trainer/Policy log std Std          0.485482
trainer/Policy log std Max         -0.575219
trainer/Policy log std Min         -2.46684
trainer/Alpha                       0.0546795
trainer/Alpha Loss                  1.21673
exploration/num steps total     37400
exploration/num paths total       374
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.367563
exploration/Rewards Std             1.1698
exploration/Rewards Max            -0.00608475
exploration/Rewards Min            -9.02987
exploration/Returns Mean          -36.7563
exploration/Returns Std            18.4193
exploration/Returns Max           -18.337
exploration/Returns Min           -55.1755
exploration/Actions Mean            0.0286732
exploration/Actions Std             0.231422
exploration/Actions Max             0.999373
exploration/Actions Min            -0.80961
exploration/Num Paths               2
exploration/Average Returns       -36.7563
evaluation/num steps total     186000
evaluation/num paths total       1860
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.204241
evaluation/Rewards Std              1.03718
evaluation/Rewards Max             -0.00302161
evaluation/Rewards Min            -10.7522
evaluation/Returns Mean           -20.4241
evaluation/Returns Std             18.4102
evaluation/Returns Max             -1.48238
evaluation/Returns Min            -54.7536
evaluation/Actions Mean             0.0199075
evaluation/Actions Std              0.193907
evaluation/Actions Max              0.997667
evaluation/Actions Min             -0.997867
evaluation/Num Paths               10
evaluation/Average Returns        -20.4241
time/data storing (s)               0.00121347
time/evaluation sampling (s)        0.286496
time/exploration sampling (s)       0.0683466
time/logging (s)                    0.00344863
time/saving (s)                     0.00303661
time/training (s)                   1.00811
time/epoch (s)                      1.37065
time/total (s)                    276.322
Epoch                             185
-----------------------------  ---------------
2019-04-21 12:21:02.589297 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 186 finished
-----------------------------  ---------------
replay_buffer/size              37600
trainer/QF1 Loss                    1.08126
trainer/QF2 Loss                    1.14256
trainer/Policy Loss                10.4488
trainer/Q1 Predictions Mean        -8.57331
trainer/Q1 Predictions Std          7.27436
trainer/Q1 Predictions Max         -7.02983
trainer/Q1 Predictions Min        -65.6468
trainer/Q2 Predictions Mean        -8.58692
trainer/Q2 Predictions Std          7.10262
trainer/Q2 Predictions Max         -7.06662
trainer/Q2 Predictions Min        -64.0164
trainer/Q Targets Mean             -8.61108
trainer/Q Targets Std               7.50294
trainer/Q Targets Max              -0.0629705
trainer/Q Targets Min             -65.6741
trainer/Log Pis Mean                2.00707
trainer/Log Pis Std                 1.15269
trainer/Log Pis Max                 7.85287
trainer/Log Pis Min                -1.46508
trainer/Policy mu Mean              0.0641502
trainer/Policy mu Std               0.624649
trainer/Policy mu Max               3.32124
trainer/Policy mu Min              -2.21824
trainer/Policy log std Mean        -2.11824
trainer/Policy log std Std          0.410821
trainer/Policy log std Max         -0.561332
trainer/Policy log std Min         -2.38665
trainer/Alpha                       0.0548615
trainer/Alpha Loss                  0.0205352
exploration/num steps total     37600
exploration/num paths total       376
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.560856
exploration/Rewards Std             1.6583
exploration/Rewards Max            -0.00918054
exploration/Rewards Min           -10.64
exploration/Returns Mean          -56.0856
exploration/Returns Std            13.081
exploration/Returns Max           -43.0045
exploration/Returns Min           -69.1666
exploration/Actions Mean            0.0510866
exploration/Actions Std             0.282726
exploration/Actions Max             0.998613
exploration/Actions Min            -0.93669
exploration/Num Paths               2
exploration/Average Returns       -56.0856
evaluation/num steps total     187000
evaluation/num paths total       1870
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.198655
evaluation/Rewards Std              0.837277
evaluation/Rewards Max             -0.0172035
evaluation/Rewards Min             -7.8546
evaluation/Returns Mean           -19.8655
evaluation/Returns Std             10.8932
evaluation/Returns Max             -4.17046
evaluation/Returns Min            -38.6345
evaluation/Actions Mean             0.0175078
evaluation/Actions Std              0.17924
evaluation/Actions Max              0.995186
evaluation/Actions Min             -0.996468
evaluation/Num Paths               10
evaluation/Average Returns        -19.8655
time/data storing (s)               0.00119571
time/evaluation sampling (s)        0.25803
time/exploration sampling (s)       0.0655974
time/logging (s)                    0.00348289
time/saving (s)                     0.00249821
time/training (s)                   1.10351
time/epoch (s)                      1.43432
time/total (s)                    277.761
Epoch                             186
-----------------------------  ---------------
2019-04-21 12:21:04.074304 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 187 finished
-----------------------------  ---------------
replay_buffer/size              37800
trainer/QF1 Loss                    1.52378
trainer/QF2 Loss                    1.50327
trainer/Policy Loss                 9.81798
trainer/Q1 Predictions Mean        -7.97083
trainer/Q1 Predictions Std          4.86006
trainer/Q1 Predictions Max         -6.82349
trainer/Q1 Predictions Min        -53.8757
trainer/Q2 Predictions Mean        -8.05148
trainer/Q2 Predictions Std          4.72559
trainer/Q2 Predictions Max         -6.93508
trainer/Q2 Predictions Min        -52.7096
trainer/Q Targets Mean             -8.02896
trainer/Q Targets Std               4.87916
trainer/Q Targets Max              -0.169375
trainer/Q Targets Min             -52.8023
trainer/Log Pis Mean                1.89769
trainer/Log Pis Std                 1.43737
trainer/Log Pis Max                 4.82111
trainer/Log Pis Min                -5.09752
trainer/Policy mu Mean              0.102999
trainer/Policy mu Std               0.699742
trainer/Policy mu Max               2.96506
trainer/Policy mu Min              -2.69036
trainer/Policy log std Mean        -2.11816
trainer/Policy log std Std          0.491101
trainer/Policy log std Max         -0.674628
trainer/Policy log std Min         -2.4225
trainer/Alpha                       0.0553729
trainer/Alpha Loss                 -0.296063
exploration/num steps total     37800
exploration/num paths total       378
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.162732
exploration/Rewards Std             0.290032
exploration/Rewards Max            -0.00545313
exploration/Rewards Min            -2.80995
exploration/Returns Mean          -16.2732
exploration/Returns Std             0.23278
exploration/Returns Max           -16.0404
exploration/Returns Min           -16.506
exploration/Actions Mean            0.0265809
exploration/Actions Std             0.20219
exploration/Actions Max             0.996273
exploration/Actions Min            -0.348188
exploration/Num Paths               2
exploration/Average Returns       -16.2732
evaluation/num steps total     188000
evaluation/num paths total       1880
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.194199
evaluation/Rewards Std              0.886038
evaluation/Rewards Max             -0.0104151
evaluation/Rewards Min            -10.9201
evaluation/Returns Mean           -19.4199
evaluation/Returns Std             15.0767
evaluation/Returns Max             -3.37943
evaluation/Returns Min            -60.6587
evaluation/Actions Mean             0.0174895
evaluation/Actions Std              0.18135
evaluation/Actions Max              0.996934
evaluation/Actions Min             -0.99692
evaluation/Num Paths               10
evaluation/Average Returns        -19.4199
time/data storing (s)               0.00113572
time/evaluation sampling (s)        0.323265
time/exploration sampling (s)       0.101335
time/logging (s)                    0.00343198
time/saving (s)                     0.00243573
time/training (s)                   1.04594
time/epoch (s)                      1.47755
time/total (s)                    279.243
Epoch                             187
-----------------------------  ---------------
2019-04-21 12:21:05.454856 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 188 finished
-----------------------------  ---------------
replay_buffer/size              38000
trainer/QF1 Loss                    0.443059
trainer/QF2 Loss                    0.46728
trainer/Policy Loss                11.055
trainer/Q1 Predictions Mean        -9.3499
trainer/Q1 Predictions Std          8.74927
trainer/Q1 Predictions Max         -7.16044
trainer/Q1 Predictions Min        -61.0401
trainer/Q2 Predictions Mean        -9.29397
trainer/Q2 Predictions Std          8.66781
trainer/Q2 Predictions Max         -7.15049
trainer/Q2 Predictions Min        -60.016
trainer/Q Targets Mean             -9.20756
trainer/Q Targets Std               8.37744
trainer/Q Targets Max              -7.0547
trainer/Q Targets Min             -61.3637
trainer/Log Pis Mean                1.96289
trainer/Log Pis Std                 1.16057
trainer/Log Pis Max                 5.94027
trainer/Log Pis Min                -2.49786
trainer/Policy mu Mean              0.133204
trainer/Policy mu Std               0.665951
trainer/Policy mu Max               3.18897
trainer/Policy mu Min              -1.25919
trainer/Policy log std Mean        -2.14418
trainer/Policy log std Std          0.426322
trainer/Policy log std Max         -0.532431
trainer/Policy log std Min         -2.36629
trainer/Alpha                       0.0558873
trainer/Alpha Loss                 -0.107039
exploration/num steps total     38000
exploration/num paths total       380
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.309405
exploration/Rewards Std             0.930321
exploration/Rewards Max            -0.00394533
exploration/Rewards Min            -7.91697
exploration/Returns Mean          -30.9405
exploration/Returns Std            13.6972
exploration/Returns Max           -17.2433
exploration/Returns Min           -44.6377
exploration/Actions Mean            0.0394866
exploration/Actions Std             0.232728
exploration/Actions Max             0.996234
exploration/Actions Min            -0.38678
exploration/Num Paths               2
exploration/Average Returns       -30.9405
evaluation/num steps total     189000
evaluation/num paths total       1890
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.246206
evaluation/Rewards Std              1.05694
evaluation/Rewards Max             -0.0316746
evaluation/Rewards Min            -10.4433
evaluation/Returns Mean           -24.6206
evaluation/Returns Std             20.6291
evaluation/Returns Max             -6.15636
evaluation/Returns Min            -62.5281
evaluation/Actions Mean             0.0162261
evaluation/Actions Std              0.183174
evaluation/Actions Max              0.996665
evaluation/Actions Min             -0.992957
evaluation/Num Paths               10
evaluation/Average Returns        -24.6206
time/data storing (s)               0.00146157
time/evaluation sampling (s)        0.256828
time/exploration sampling (s)       0.0692219
time/logging (s)                    0.0034336
time/saving (s)                     0.00235928
time/training (s)                   1.03993
time/epoch (s)                      1.37323
time/total (s)                    280.62
Epoch                             188
-----------------------------  ---------------
2019-04-21 12:21:06.895289 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 189 finished
-----------------------------  ---------------
replay_buffer/size              38200
trainer/QF1 Loss                    0.0592964
trainer/QF2 Loss                    0.021527
trainer/Policy Loss                10.3105
trainer/Q1 Predictions Mean        -8.39976
trainer/Q1 Predictions Std          5.83324
trainer/Q1 Predictions Max         -7.044
trainer/Q1 Predictions Min        -50.6619
trainer/Q2 Predictions Mean        -8.44775
trainer/Q2 Predictions Std          5.92477
trainer/Q2 Predictions Max         -7.08147
trainer/Q2 Predictions Min        -51.8382
trainer/Q Targets Mean             -8.49655
trainer/Q Targets Std               5.95917
trainer/Q Targets Max              -7.06738
trainer/Q Targets Min             -52.6099
trainer/Log Pis Mean                2.03678
trainer/Log Pis Std                 1.3553
trainer/Log Pis Max                 8.49282
trainer/Log Pis Min                -1.97317
trainer/Policy mu Mean              0.128896
trainer/Policy mu Std               0.624682
trainer/Policy mu Max               3.50441
trainer/Policy mu Min              -2.39666
trainer/Policy log std Mean        -2.1159
trainer/Policy log std Std          0.397761
trainer/Policy log std Max         -0.594061
trainer/Policy log std Min         -2.35687
trainer/Alpha                       0.0549642
trainer/Alpha Loss                  0.106694
exploration/num steps total     38200
exploration/num paths total       382
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.212781
exploration/Rewards Std             0.51664
exploration/Rewards Max            -0.00220153
exploration/Rewards Min            -4.56753
exploration/Returns Mean          -21.2781
exploration/Returns Std             0.819172
exploration/Returns Max           -20.4589
exploration/Returns Min           -22.0973
exploration/Actions Mean            0.0365601
exploration/Actions Std             0.219623
exploration/Actions Max             0.998301
exploration/Actions Min            -0.480727
exploration/Num Paths               2
exploration/Average Returns       -21.2781
evaluation/num steps total     190000
evaluation/num paths total       1900
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.233097
evaluation/Rewards Std              1.01206
evaluation/Rewards Max             -0.00508831
evaluation/Rewards Min             -9.032
evaluation/Returns Mean           -23.3097
evaluation/Returns Std             10.1171
evaluation/Returns Max             -5.98479
evaluation/Returns Min            -43.5652
evaluation/Actions Mean             0.0225061
evaluation/Actions Std              0.208361
evaluation/Actions Max              0.997716
evaluation/Actions Min             -0.993403
evaluation/Num Paths               10
evaluation/Average Returns        -23.3097
time/data storing (s)               0.00145497
time/evaluation sampling (s)        0.24714
time/exploration sampling (s)       0.0661086
time/logging (s)                    0.00351542
time/saving (s)                     0.00256828
time/training (s)                   1.11426
time/epoch (s)                      1.43505
time/total (s)                    282.058
Epoch                             189
-----------------------------  ---------------
2019-04-21 12:21:08.885539 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 190 finished
-----------------------------  ---------------
replay_buffer/size              38400
trainer/QF1 Loss                    0.0761749
trainer/QF2 Loss                    0.0953153
trainer/Policy Loss                10.2635
trainer/Q1 Predictions Mean        -8.41524
trainer/Q1 Predictions Std          7.26006
trainer/Q1 Predictions Max         -7.03064
trainer/Q1 Predictions Min        -76.7301
trainer/Q2 Predictions Mean        -8.40772
trainer/Q2 Predictions Std          7.28702
trainer/Q2 Predictions Max         -6.98571
trainer/Q2 Predictions Min        -77.0322
trainer/Q Targets Mean             -8.45379
trainer/Q Targets Std               7.00649
trainer/Q Targets Max              -7.03187
trainer/Q Targets Min             -74.1938
trainer/Log Pis Mean                2.11466
trainer/Log Pis Std                 0.784781
trainer/Log Pis Max                 3.7856
trainer/Log Pis Min                -0.0443773
trainer/Policy mu Mean              0.0157221
trainer/Policy mu Std               0.609766
trainer/Policy mu Max               3.11036
trainer/Policy mu Min              -2.88253
trainer/Policy log std Mean        -2.22845
trainer/Policy log std Std          0.429378
trainer/Policy log std Max         -0.466778
trainer/Policy log std Min         -2.49175
trainer/Alpha                       0.0545049
trainer/Alpha Loss                  0.333617
exploration/num steps total     38400
exploration/num paths total       384
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.213143
exploration/Rewards Std             0.593522
exploration/Rewards Max            -0.0091272
exploration/Rewards Min            -5.8997
exploration/Returns Mean          -21.3143
exploration/Returns Std             6.83273
exploration/Returns Max           -14.4816
exploration/Returns Min           -28.147
exploration/Actions Mean            0.00812134
exploration/Actions Std             0.214629
exploration/Actions Max             0.995172
exploration/Actions Min            -0.985963
exploration/Num Paths               2
exploration/Average Returns       -21.3143
evaluation/num steps total     191000
evaluation/num paths total       1910
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.275511
evaluation/Rewards Std              1.14914
evaluation/Rewards Max             -0.035269
evaluation/Rewards Min            -10.8144
evaluation/Returns Mean           -27.5511
evaluation/Returns Std             19.1092
evaluation/Returns Max             -4.08608
evaluation/Returns Min            -60.0588
evaluation/Actions Mean             0.0280645
evaluation/Actions Std              0.19527
evaluation/Actions Max              0.997293
evaluation/Actions Min             -0.994297
evaluation/Num Paths               10
evaluation/Average Returns        -27.5511
time/data storing (s)               0.00189812
time/evaluation sampling (s)        0.301501
time/exploration sampling (s)       0.102931
time/logging (s)                    0.0035691
time/saving (s)                     0.00250958
time/training (s)                   1.56961
time/epoch (s)                      1.98202
time/total (s)                    284.044
Epoch                             190
-----------------------------  ---------------
2019-04-21 12:21:10.378504 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 191 finished
-----------------------------  ---------------
replay_buffer/size              38600
trainer/QF1 Loss                    1.19793
trainer/QF2 Loss                    1.20978
trainer/Policy Loss                 9.93704
trainer/Q1 Predictions Mean        -8.62443
trainer/Q1 Predictions Std          6.30136
trainer/Q1 Predictions Max         -7.07983
trainer/Q1 Predictions Min        -55.7104
trainer/Q2 Predictions Mean        -8.65392
trainer/Q2 Predictions Std          6.2806
trainer/Q2 Predictions Max         -7.08394
trainer/Q2 Predictions Min        -55.4015
trainer/Q Targets Mean             -8.56388
trainer/Q Targets Std               6.75852
trainer/Q Targets Max              -0.132749
trainer/Q Targets Min             -59.1858
trainer/Log Pis Mean                1.66619
trainer/Log Pis Std                 1.30863
trainer/Log Pis Max                 5.57734
trainer/Log Pis Min                -2.23543
trainer/Policy mu Mean              0.113078
trainer/Policy mu Std               0.636009
trainer/Policy mu Max               3.25409
trainer/Policy mu Min              -1.88858
trainer/Policy log std Mean        -2.12694
trainer/Policy log std Std          0.423414
trainer/Policy log std Max         -0.455321
trainer/Policy log std Min         -2.36857
trainer/Alpha                       0.0550087
trainer/Alpha Loss                 -0.968116
exploration/num steps total     38600
exploration/num paths total       386
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.402888
exploration/Rewards Std             1.15346
exploration/Rewards Max            -0.0104774
exploration/Rewards Min            -8.126
exploration/Returns Mean          -40.2888
exploration/Returns Std             8.84864
exploration/Returns Max           -31.4402
exploration/Returns Min           -49.1375
exploration/Actions Mean            0.0377051
exploration/Actions Std             0.239143
exploration/Actions Max             0.999175
exploration/Actions Min            -0.668963
exploration/Num Paths               2
exploration/Average Returns       -40.2888
evaluation/num steps total     192000
evaluation/num paths total       1920
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.159435
evaluation/Rewards Std              0.649205
evaluation/Rewards Max             -0.0273354
evaluation/Rewards Min             -7.93334
evaluation/Returns Mean           -15.9435
evaluation/Returns Std              9.8419
evaluation/Returns Max             -6.18432
evaluation/Returns Min            -33.4318
evaluation/Actions Mean             0.019239
evaluation/Actions Std              0.163814
evaluation/Actions Max              0.994048
evaluation/Actions Min             -0.99686
evaluation/Num Paths               10
evaluation/Average Returns        -15.9435
time/data storing (s)               0.00123678
time/evaluation sampling (s)        0.296672
time/exploration sampling (s)       0.0697762
time/logging (s)                    0.00345767
time/saving (s)                     0.00243909
time/training (s)                   1.1123
time/epoch (s)                      1.48588
time/total (s)                    285.535
Epoch                             191
-----------------------------  ---------------
2019-04-21 12:21:11.818420 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 192 finished
-----------------------------  ---------------
replay_buffer/size              38800
trainer/QF1 Loss                    0.0226617
trainer/QF2 Loss                    0.0231178
trainer/Policy Loss                 9.49201
trainer/Q1 Predictions Mean        -7.54873
trainer/Q1 Predictions Std          3.0161
trainer/Q1 Predictions Max         -7.00693
trainer/Q1 Predictions Min        -37.4152
trainer/Q2 Predictions Mean        -7.58463
trainer/Q2 Predictions Std          2.99571
trainer/Q2 Predictions Max         -7.05227
trainer/Q2 Predictions Min        -37.2338
trainer/Q Targets Mean             -7.62188
trainer/Q Targets Std               3.10747
trainer/Q Targets Max              -6.97796
trainer/Q Targets Min             -38.3883
trainer/Log Pis Mean                2.11565
trainer/Log Pis Std                 1.05517
trainer/Log Pis Max                 7.10755
trainer/Log Pis Min                -2.3799
trainer/Policy mu Mean              0.0411689
trainer/Policy mu Std               0.443048
trainer/Policy mu Max               3.19593
trainer/Policy mu Min              -2.12871
trainer/Policy log std Mean        -2.30243
trainer/Policy log std Std          0.333658
trainer/Policy log std Max         -0.394684
trainer/Policy log std Min         -2.47679
trainer/Alpha                       0.0542082
trainer/Alpha Loss                  0.337145
exploration/num steps total     38800
exploration/num paths total       388
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.16771
exploration/Rewards Std             0.343679
exploration/Rewards Max            -0.0160372
exploration/Rewards Min            -3.27381
exploration/Returns Mean          -16.771
exploration/Returns Std             1.80181
exploration/Returns Max           -14.9692
exploration/Returns Min           -18.5728
exploration/Actions Mean            0.0245927
exploration/Actions Std             0.188229
exploration/Actions Max             0.997905
exploration/Actions Min            -0.383493
exploration/Num Paths               2
exploration/Average Returns       -16.771
evaluation/num steps total     193000
evaluation/num paths total       1930
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0975232
evaluation/Rewards Std              0.494009
evaluation/Rewards Max             -0.00888017
evaluation/Rewards Min             -6.55154
evaluation/Returns Mean            -9.75232
evaluation/Returns Std              7.40626
evaluation/Returns Max             -2.86956
evaluation/Returns Min            -24.7379
evaluation/Actions Mean             0.0147893
evaluation/Actions Std              0.145664
evaluation/Actions Max              0.991581
evaluation/Actions Min             -0.992791
evaluation/Num Paths               10
evaluation/Average Returns         -9.75232
time/data storing (s)               0.00125355
time/evaluation sampling (s)        0.275703
time/exploration sampling (s)       0.0726957
time/logging (s)                    0.00342081
time/saving (s)                     0.00267122
time/training (s)                   1.07652
time/epoch (s)                      1.43227
time/total (s)                    286.971
Epoch                             192
-----------------------------  ---------------
2019-04-21 12:21:13.617150 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 193 finished
-----------------------------  ---------------
replay_buffer/size              39000
trainer/QF1 Loss                    0.0368324
trainer/QF2 Loss                    0.0101687
trainer/Policy Loss                10.2912
trainer/Q1 Predictions Mean        -8.32804
trainer/Q1 Predictions Std          6.59003
trainer/Q1 Predictions Max         -6.84565
trainer/Q1 Predictions Min        -59.2899
trainer/Q2 Predictions Mean        -8.4308
trainer/Q2 Predictions Std          6.60845
trainer/Q2 Predictions Max         -6.95336
trainer/Q2 Predictions Min        -59.3274
trainer/Q Targets Mean             -8.499
trainer/Q Targets Std               6.58177
trainer/Q Targets Max              -6.92465
trainer/Q Targets Min             -59.2816
trainer/Log Pis Mean                1.97117
trainer/Log Pis Std                 1.3773
trainer/Log Pis Max                 6.07408
trainer/Log Pis Min                -4.43355
trainer/Policy mu Mean              0.0901115
trainer/Policy mu Std               0.568067
trainer/Policy mu Max               3.15548
trainer/Policy mu Min              -1.43731
trainer/Policy log std Mean        -2.24271
trainer/Policy log std Std          0.391308
trainer/Policy log std Max         -0.336319
trainer/Policy log std Min         -2.44139
trainer/Alpha                       0.0550758
trainer/Alpha Loss                 -0.0835927
exploration/num steps total     39000
exploration/num paths total       390
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.401354
exploration/Rewards Std             1.22106
exploration/Rewards Max            -0.00678889
exploration/Rewards Min            -8.36752
exploration/Returns Mean          -40.1354
exploration/Returns Std             1.91126
exploration/Returns Max           -38.2242
exploration/Returns Min           -42.0467
exploration/Actions Mean            0.0227071
exploration/Actions Std             0.255302
exploration/Actions Max             0.99732
exploration/Actions Min            -0.996327
exploration/Num Paths               2
exploration/Average Returns       -40.1354
evaluation/num steps total     194000
evaluation/num paths total       1940
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.236921
evaluation/Rewards Std              0.9921
evaluation/Rewards Max             -0.0225195
evaluation/Rewards Min             -8.99305
evaluation/Returns Mean           -23.6921
evaluation/Returns Std             10.2109
evaluation/Returns Max            -12.9931
evaluation/Returns Min            -41.8793
evaluation/Actions Mean             0.042332
evaluation/Actions Std              0.200152
evaluation/Actions Max              0.997053
evaluation/Actions Min             -0.921803
evaluation/Num Paths               10
evaluation/Average Returns        -23.6921
time/data storing (s)               0.00121819
time/evaluation sampling (s)        0.292414
time/exploration sampling (s)       0.0782959
time/logging (s)                    0.00322686
time/saving (s)                     0.0019337
time/training (s)                   1.41397
time/epoch (s)                      1.79106
time/total (s)                    288.766
Epoch                             193
-----------------------------  ---------------
2019-04-21 12:21:15.210848 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 194 finished
-----------------------------  ---------------
replay_buffer/size              39200
trainer/QF1 Loss                    0.507119
trainer/QF2 Loss                    0.514102
trainer/Policy Loss                 9.62014
trainer/Q1 Predictions Mean        -7.76853
trainer/Q1 Predictions Std          3.41
trainer/Q1 Predictions Max         -7.02589
trainer/Q1 Predictions Min        -35.9545
trainer/Q2 Predictions Mean        -7.76347
trainer/Q2 Predictions Std          3.47973
trainer/Q2 Predictions Max         -7.00976
trainer/Q2 Predictions Min        -36.4433
trainer/Q Targets Mean             -7.70453
trainer/Q Targets Std               3.44579
trainer/Q Targets Max              -0.409941
trainer/Q Targets Min             -35.4336
trainer/Log Pis Mean                1.93886
trainer/Log Pis Std                 1.13031
trainer/Log Pis Max                 5.71898
trainer/Log Pis Min                -1.33665
trainer/Policy mu Mean              0.0319699
trainer/Policy mu Std               0.513254
trainer/Policy mu Max               2.96721
trainer/Policy mu Min              -3.50305
trainer/Policy log std Mean        -2.20049
trainer/Policy log std Std          0.350859
trainer/Policy log std Max         -0.544509
trainer/Policy log std Min         -2.34328
trainer/Alpha                       0.0558884
trainer/Alpha Loss                 -0.176341
exploration/num steps total     39200
exploration/num paths total       392
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.308536
exploration/Rewards Std             0.930623
exploration/Rewards Max            -0.0113721
exploration/Rewards Min            -7.69843
exploration/Returns Mean          -30.8536
exploration/Returns Std            15.2982
exploration/Returns Max           -15.5554
exploration/Returns Min           -46.1519
exploration/Actions Mean            0.0173975
exploration/Actions Std             0.218157
exploration/Actions Max             0.998956
exploration/Actions Min            -0.985188
exploration/Num Paths               2
exploration/Average Returns       -30.8536
evaluation/num steps total     195000
evaluation/num paths total       1950
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.18255
evaluation/Rewards Std              0.758187
evaluation/Rewards Max             -0.0401858
evaluation/Rewards Min             -7.93205
evaluation/Returns Mean           -18.255
evaluation/Returns Std             10.6973
evaluation/Returns Max             -4.87466
evaluation/Returns Min            -40.2691
evaluation/Actions Mean             0.0173747
evaluation/Actions Std              0.178608
evaluation/Actions Max              0.995479
evaluation/Actions Min             -0.989729
evaluation/Num Paths               10
evaluation/Average Returns        -18.255
time/data storing (s)               0.0014777
time/evaluation sampling (s)        0.313317
time/exploration sampling (s)       0.0787319
time/logging (s)                    0.00342576
time/saving (s)                     0.00234706
time/training (s)                   1.18845
time/epoch (s)                      1.58775
time/total (s)                    290.358
Epoch                             194
-----------------------------  ---------------
2019-04-21 12:21:16.531043 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 195 finished
-----------------------------  ---------------
replay_buffer/size              39400
trainer/QF1 Loss                    0.985553
trainer/QF2 Loss                    0.994104
trainer/Policy Loss                10.0778
trainer/Q1 Predictions Mean        -8.18742
trainer/Q1 Predictions Std          3.98841
trainer/Q1 Predictions Max         -6.90951
trainer/Q1 Predictions Min        -36.1655
trainer/Q2 Predictions Mean        -8.13053
trainer/Q2 Predictions Std          3.95814
trainer/Q2 Predictions Max         -6.87147
trainer/Q2 Predictions Min        -36.1352
trainer/Q Targets Mean             -8.14646
trainer/Q Targets Std               4.22518
trainer/Q Targets Max              -0.0488255
trainer/Q Targets Min             -36.8285
trainer/Log Pis Mean                2.09936
trainer/Log Pis Std                 1.33881
trainer/Log Pis Max                 7.26567
trainer/Log Pis Min                -2.8443
trainer/Policy mu Mean              0.0951806
trainer/Policy mu Std               0.654562
trainer/Policy mu Max               3.24458
trainer/Policy mu Min              -1.64924
trainer/Policy log std Mean        -2.14503
trainer/Policy log std Std          0.484161
trainer/Policy log std Max         -0.41481
trainer/Policy log std Min         -2.41979
trainer/Alpha                       0.0562198
trainer/Alpha Loss                  0.286017
exploration/num steps total     39400
exploration/num paths total       394
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.361766
exploration/Rewards Std             1.12311
exploration/Rewards Max            -0.0169466
exploration/Rewards Min            -8.62404
exploration/Returns Mean          -36.1766
exploration/Returns Std            16.7405
exploration/Returns Max           -19.4361
exploration/Returns Min           -52.9171
exploration/Actions Mean            0.0294798
exploration/Actions Std             0.248238
exploration/Actions Max             0.997207
exploration/Actions Min            -0.998747
exploration/Num Paths               2
exploration/Average Returns       -36.1766
evaluation/num steps total     196000
evaluation/num paths total       1960
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.231486
evaluation/Rewards Std              1.06011
evaluation/Rewards Max             -0.0192319
evaluation/Rewards Min            -10.568
evaluation/Returns Mean           -23.1486
evaluation/Returns Std             18.612
evaluation/Returns Max             -4.59409
evaluation/Returns Min            -60.5327
evaluation/Actions Mean             0.0335866
evaluation/Actions Std              0.198445
evaluation/Actions Max              0.995395
evaluation/Actions Min             -0.982764
evaluation/Num Paths               10
evaluation/Average Returns        -23.1486
time/data storing (s)               0.0014015
time/evaluation sampling (s)        0.264807
time/exploration sampling (s)       0.068956
time/logging (s)                    0.0034523
time/saving (s)                     0.00236804
time/training (s)                   0.971604
time/epoch (s)                      1.31259
time/total (s)                    291.675
Epoch                             195
-----------------------------  ---------------
2019-04-21 12:21:17.901653 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 196 finished
-----------------------------  ----------------
replay_buffer/size              39600
trainer/QF1 Loss                    1.49674
trainer/QF2 Loss                    1.45993
trainer/Policy Loss                 9.99499
trainer/Q1 Predictions Mean        -8.28302
trainer/Q1 Predictions Std          4.60628
trainer/Q1 Predictions Max         -7.02646
trainer/Q1 Predictions Min        -41.4532
trainer/Q2 Predictions Mean        -8.22955
trainer/Q2 Predictions Std          4.65249
trainer/Q2 Predictions Max         -7.00861
trainer/Q2 Predictions Min        -41.8853
trainer/Q Targets Mean             -8.00685
trainer/Q Targets Std               4.77127
trainer/Q Targets Max              -0.112568
trainer/Q Targets Min             -41.6746
trainer/Log Pis Mean                1.85698
trainer/Log Pis Std                 1.29104
trainer/Log Pis Max                 6.01157
trainer/Log Pis Min                -2.88515
trainer/Policy mu Mean              0.0841622
trainer/Policy mu Std               0.679646
trainer/Policy mu Max               2.98348
trainer/Policy mu Min              -3.01871
trainer/Policy log std Mean        -2.0658
trainer/Policy log std Std          0.455347
trainer/Policy log std Max         -0.446273
trainer/Policy log std Min         -2.3447
trainer/Alpha                       0.0567066
trainer/Alpha Loss                 -0.410436
exploration/num steps total     39600
exploration/num paths total       396
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.133812
exploration/Rewards Std             0.119567
exploration/Rewards Max            -0.00921454
exploration/Rewards Min            -1.46012
exploration/Returns Mean          -13.3812
exploration/Returns Std             0.695841
exploration/Returns Max           -12.6853
exploration/Returns Min           -14.077
exploration/Actions Mean           -0.00508528
exploration/Actions Std             0.162597
exploration/Actions Max             0.775643
exploration/Actions Min            -0.99424
exploration/Num Paths               2
exploration/Average Returns       -13.3812
evaluation/num steps total     197000
evaluation/num paths total       1970
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.190813
evaluation/Rewards Std              0.854138
evaluation/Rewards Max             -0.000874421
evaluation/Rewards Min             -9.40818
evaluation/Returns Mean           -19.0813
evaluation/Returns Std             13.1767
evaluation/Returns Max             -4.35197
evaluation/Returns Min            -48.969
evaluation/Actions Mean             0.0233332
evaluation/Actions Std              0.181853
evaluation/Actions Max              0.997187
evaluation/Actions Min             -0.994461
evaluation/Num Paths               10
evaluation/Average Returns        -19.0813
time/data storing (s)               0.00118944
time/evaluation sampling (s)        0.269731
time/exploration sampling (s)       0.0689048
time/logging (s)                    0.00353162
time/saving (s)                     0.00242272
time/training (s)                   1.01706
time/epoch (s)                      1.36284
time/total (s)                    293.042
Epoch                             196
-----------------------------  ----------------
2019-04-21 12:21:19.228238 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 197 finished
-----------------------------  ---------------
replay_buffer/size              39800
trainer/QF1 Loss                    0.0390061
trainer/QF2 Loss                    0.0389481
trainer/Policy Loss                 9.99252
trainer/Q1 Predictions Mean        -8.22495
trainer/Q1 Predictions Std          4.91303
trainer/Q1 Predictions Max         -6.91358
trainer/Q1 Predictions Min        -38.0817
trainer/Q2 Predictions Mean        -8.23834
trainer/Q2 Predictions Std          4.90793
trainer/Q2 Predictions Max         -6.92378
trainer/Q2 Predictions Min        -38.1511
trainer/Q Targets Mean             -8.2366
trainer/Q Targets Std               4.73906
trainer/Q Targets Max              -6.90016
trainer/Q Targets Min             -36.6904
trainer/Log Pis Mean                2.10822
trainer/Log Pis Std                 1.17481
trainer/Log Pis Max                 6.37147
trainer/Log Pis Min                -2.42143
trainer/Policy mu Mean              0.0541016
trainer/Policy mu Std               0.618102
trainer/Policy mu Max               2.76471
trainer/Policy mu Min              -2.32443
trainer/Policy log std Mean        -2.21554
trainer/Policy log std Std          0.417635
trainer/Policy log std Max         -0.617083
trainer/Policy log std Min         -2.43506
trainer/Alpha                       0.0550105
trainer/Alpha Loss                  0.313862
exploration/num steps total     39800
exploration/num paths total       398
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.347225
exploration/Rewards Std             1.00269
exploration/Rewards Max            -0.00994086
exploration/Rewards Min            -7.64879
exploration/Returns Mean          -34.7225
exploration/Returns Std             6.37621
exploration/Returns Max           -28.3463
exploration/Returns Min           -41.0988
exploration/Actions Mean            0.0204631
exploration/Actions Std             0.241636
exploration/Actions Max             0.998528
exploration/Actions Min            -0.968272
exploration/Num Paths               2
exploration/Average Returns       -34.7225
evaluation/num steps total     198000
evaluation/num paths total       1980
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.251773
evaluation/Rewards Std              0.992826
evaluation/Rewards Max             -0.0451886
evaluation/Rewards Min             -9.5347
evaluation/Returns Mean           -25.1773
evaluation/Returns Std             14.4942
evaluation/Returns Max             -6.73231
evaluation/Returns Min            -54.9173
evaluation/Actions Mean             0.0179654
evaluation/Actions Std              0.183196
evaluation/Actions Max              0.994617
evaluation/Actions Min             -0.995508
evaluation/Num Paths               10
evaluation/Average Returns        -25.1773
time/data storing (s)               0.00118038
time/evaluation sampling (s)        0.266777
time/exploration sampling (s)       0.0695369
time/logging (s)                    0.00322613
time/saving (s)                     0.00232884
time/training (s)                   0.975609
time/epoch (s)                      1.31866
time/total (s)                    294.365
Epoch                             197
-----------------------------  ---------------
2019-04-21 12:21:20.519210 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 198 finished
-----------------------------  ---------------
replay_buffer/size              40000
trainer/QF1 Loss                    0.497353
trainer/QF2 Loss                    0.519313
trainer/Policy Loss                10.1273
trainer/Q1 Predictions Mean        -8.57124
trainer/Q1 Predictions Std          5.18974
trainer/Q1 Predictions Max         -6.99112
trainer/Q1 Predictions Min        -35.1029
trainer/Q2 Predictions Mean        -8.5555
trainer/Q2 Predictions Std          5.06182
trainer/Q2 Predictions Max         -6.99064
trainer/Q2 Predictions Min        -34.2462
trainer/Q Targets Mean             -8.4775
trainer/Q Targets Std               5.23142
trainer/Q Targets Max              -0.16751
trainer/Q Targets Min             -34.9736
trainer/Log Pis Mean                1.83846
trainer/Log Pis Std                 1.21932
trainer/Log Pis Max                 5.20049
trainer/Log Pis Min                -1.39136
trainer/Policy mu Mean              0.110933
trainer/Policy mu Std               0.672968
trainer/Policy mu Max               3.33531
trainer/Policy mu Min              -2.29845
trainer/Policy log std Mean        -2.16089
trainer/Policy log std Std          0.45204
trainer/Policy log std Max         -0.468248
trainer/Policy log std Min         -2.44115
trainer/Alpha                       0.0555912
trainer/Alpha Loss                 -0.466818
exploration/num steps total     40000
exploration/num paths total       400
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.440804
exploration/Rewards Std             1.36281
exploration/Rewards Max            -0.011797
exploration/Rewards Min           -10.1868
exploration/Returns Mean          -44.0804
exploration/Returns Std            19.3548
exploration/Returns Max           -24.7256
exploration/Returns Min           -63.4352
exploration/Actions Mean            0.03425
exploration/Actions Std             0.265932
exploration/Actions Max             0.999808
exploration/Actions Min            -0.990999
exploration/Num Paths               2
exploration/Average Returns       -44.0804
evaluation/num steps total     199000
evaluation/num paths total       1990
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.262929
evaluation/Rewards Std              1.1255
evaluation/Rewards Max             -0.00545952
evaluation/Rewards Min            -10.9788
evaluation/Returns Mean           -26.2929
evaluation/Returns Std             17.824
evaluation/Returns Max             -4.32985
evaluation/Returns Min            -62.0635
evaluation/Actions Mean             0.027131
evaluation/Actions Std              0.19941
evaluation/Actions Max              0.997585
evaluation/Actions Min             -0.994185
evaluation/Num Paths               10
evaluation/Average Returns        -26.2929
time/data storing (s)               0.00115344
time/evaluation sampling (s)        0.256401
time/exploration sampling (s)       0.0670564
time/logging (s)                    0.003382
time/saving (s)                     0.00236266
time/training (s)                   0.953177
time/epoch (s)                      1.28353
time/total (s)                    295.653
Epoch                             198
-----------------------------  ---------------
2019-04-21 12:21:21.834503 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 199 finished
-----------------------------  ---------------
replay_buffer/size              40200
trainer/QF1 Loss                    0.0156361
trainer/QF2 Loss                    0.0131839
trainer/Policy Loss                 9.50944
trainer/Q1 Predictions Mean        -7.7915
trainer/Q1 Predictions Std          4.074
trainer/Q1 Predictions Max         -7.03835
trainer/Q1 Predictions Min        -47.3785
trainer/Q2 Predictions Mean        -7.7961
trainer/Q2 Predictions Std          4.10919
trainer/Q2 Predictions Max         -7.03078
trainer/Q2 Predictions Min        -47.7018
trainer/Q Targets Mean             -7.71514
trainer/Q Targets Std               4.10331
trainer/Q Targets Max              -6.90348
trainer/Q Targets Min             -47.5045
trainer/Log Pis Mean                1.88151
trainer/Log Pis Std                 1.05728
trainer/Log Pis Max                 5.07396
trainer/Log Pis Min                -1.16684
trainer/Policy mu Mean              0.0111091
trainer/Policy mu Std               0.471495
trainer/Policy mu Max               3.07762
trainer/Policy mu Min              -1.43109
trainer/Policy log std Mean        -2.20677
trainer/Policy log std Std          0.321209
trainer/Policy log std Max         -0.690255
trainer/Policy log std Min         -2.42096
trainer/Alpha                       0.054673
trainer/Alpha Loss                 -0.344344
exploration/num steps total     40200
exploration/num paths total       402
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.36636
exploration/Rewards Std             1.14883
exploration/Rewards Max            -0.00533052
exploration/Rewards Min            -9.08345
exploration/Returns Mean          -36.636
exploration/Returns Std            17.1356
exploration/Returns Max           -19.5004
exploration/Returns Min           -53.7716
exploration/Actions Mean            0.0462418
exploration/Actions Std             0.23577
exploration/Actions Max             0.997926
exploration/Actions Min            -0.37843
exploration/Num Paths               2
exploration/Average Returns       -36.636
evaluation/num steps total     200000
evaluation/num paths total       2000
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.254647
evaluation/Rewards Std              1.09199
evaluation/Rewards Max             -0.0381793
evaluation/Rewards Min            -10.9134
evaluation/Returns Mean           -25.4647
evaluation/Returns Std             19.383
evaluation/Returns Max             -4.63819
evaluation/Returns Min            -61.028
evaluation/Actions Mean             0.0241948
evaluation/Actions Std              0.188038
evaluation/Actions Max              0.997884
evaluation/Actions Min             -0.997608
evaluation/Num Paths               10
evaluation/Average Returns        -25.4647
time/data storing (s)               0.00113724
time/evaluation sampling (s)        0.263181
time/exploration sampling (s)       0.0674495
time/logging (s)                    0.00342054
time/saving (s)                     0.00220162
time/training (s)                   0.970367
time/epoch (s)                      1.30776
time/total (s)                    296.966
Epoch                             199
-----------------------------  ---------------
2019-04-21 12:21:23.200804 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 200 finished
-----------------------------  ---------------
replay_buffer/size              40400
trainer/QF1 Loss                    0.481968
trainer/QF2 Loss                    0.484544
trainer/Policy Loss                 8.99533
trainer/Q1 Predictions Mean        -7.26701
trainer/Q1 Predictions Std          0.876354
trainer/Q1 Predictions Max         -6.94336
trainer/Q1 Predictions Min        -14.6239
trainer/Q2 Predictions Mean        -7.22807
trainer/Q2 Predictions Std          0.888915
trainer/Q2 Predictions Max         -6.93003
trainer/Q2 Predictions Min        -14.8372
trainer/Q Targets Mean             -7.23429
trainer/Q Targets Std               1.15589
trainer/Q Targets Max              -0.126444
trainer/Q Targets Min             -14.9141
trainer/Log Pis Mean                1.8335
trainer/Log Pis Std                 1.08965
trainer/Log Pis Max                 4.98591
trainer/Log Pis Min                -3.85679
trainer/Policy mu Mean              0.0663951
trainer/Policy mu Std               0.4084
trainer/Policy mu Max               2.76864
trainer/Policy mu Min              -1.53754
trainer/Policy log std Mean        -2.19445
trainer/Policy log std Std          0.299873
trainer/Policy log std Max         -0.675061
trainer/Policy log std Min         -2.32791
trainer/Alpha                       0.0535012
trainer/Alpha Loss                 -0.487484
exploration/num steps total     40400
exploration/num paths total       404
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.230647
exploration/Rewards Std             0.579738
exploration/Rewards Max            -0.0128149
exploration/Rewards Min            -4.63205
exploration/Returns Mean          -23.0647
exploration/Returns Std             0.807539
exploration/Returns Max           -22.2571
exploration/Returns Min           -23.8722
exploration/Actions Mean            0.0174113
exploration/Actions Std             0.227252
exploration/Actions Max             0.994493
exploration/Actions Min            -0.997065
exploration/Num Paths               2
exploration/Average Returns       -23.0647
evaluation/num steps total     201000
evaluation/num paths total       2010
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.208243
evaluation/Rewards Std              0.938178
evaluation/Rewards Max             -0.00964669
evaluation/Rewards Min             -8.68752
evaluation/Returns Mean           -20.8243
evaluation/Returns Std             13.5549
evaluation/Returns Max             -4.01494
evaluation/Returns Min            -39.0682
evaluation/Actions Mean             0.0287057
evaluation/Actions Std              0.177242
evaluation/Actions Max              0.996487
evaluation/Actions Min             -0.971951
evaluation/Num Paths               10
evaluation/Average Returns        -20.8243
time/data storing (s)               0.00113412
time/evaluation sampling (s)        0.271608
time/exploration sampling (s)       0.0664838
time/logging (s)                    0.00367835
time/saving (s)                     0.00266735
time/training (s)                   1.01368
time/epoch (s)                      1.35925
time/total (s)                    298.329
Epoch                             200
-----------------------------  ---------------
2019-04-21 12:21:24.521525 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 201 finished
-----------------------------  ---------------
replay_buffer/size              40600
trainer/QF1 Loss                    0.57657
trainer/QF2 Loss                    0.632391
trainer/Policy Loss                 9.81526
trainer/Q1 Predictions Mean        -8.01113
trainer/Q1 Predictions Std          4.17773
trainer/Q1 Predictions Max         -6.83771
trainer/Q1 Predictions Min        -39.9239
trainer/Q2 Predictions Mean        -8.07469
trainer/Q2 Predictions Std          4.22506
trainer/Q2 Predictions Max         -6.89717
trainer/Q2 Predictions Min        -40.4375
trainer/Q Targets Mean             -8.00634
trainer/Q Targets Std               4.09638
trainer/Q Targets Max              -0.096589
trainer/Q Targets Min             -39.4361
trainer/Log Pis Mean                2.07128
trainer/Log Pis Std                 1.30533
trainer/Log Pis Max                 6.13118
trainer/Log Pis Min                -2.11593
trainer/Policy mu Mean              0.0515192
trainer/Policy mu Std               0.604974
trainer/Policy mu Max               3.30513
trainer/Policy mu Min              -1.75545
trainer/Policy log std Mean        -2.2253
trainer/Policy log std Std          0.385354
trainer/Policy log std Max         -0.595823
trainer/Policy log std Min         -2.43379
trainer/Alpha                       0.0519927
trainer/Alpha Loss                  0.210746
exploration/num steps total     40600
exploration/num paths total       406
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.289941
exploration/Rewards Std             0.904261
exploration/Rewards Max            -0.00379726
exploration/Rewards Min            -7.54851
exploration/Returns Mean          -28.9941
exploration/Returns Std            16.022
exploration/Returns Max           -12.972
exploration/Returns Min           -45.0161
exploration/Actions Mean            0.0199738
exploration/Actions Std             0.203654
exploration/Actions Max             0.995713
exploration/Actions Min            -0.72809
exploration/Num Paths               2
exploration/Average Returns       -28.9941
evaluation/num steps total     202000
evaluation/num paths total       2020
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.26185
evaluation/Rewards Std              1.00102
evaluation/Rewards Max             -0.0347176
evaluation/Rewards Min            -10.0287
evaluation/Returns Mean           -26.185
evaluation/Returns Std             17.0356
evaluation/Returns Max             -9.57081
evaluation/Returns Min            -61.7155
evaluation/Actions Mean             0.0227285
evaluation/Actions Std              0.186851
evaluation/Actions Max              0.997331
evaluation/Actions Min             -0.991628
evaluation/Num Paths               10
evaluation/Average Returns        -26.185
time/data storing (s)               0.00118283
time/evaluation sampling (s)        0.260174
time/exploration sampling (s)       0.0699892
time/logging (s)                    0.00339211
time/saving (s)                     0.00231311
time/training (s)                   0.975577
time/epoch (s)                      1.31263
time/total (s)                    299.646
Epoch                             201
-----------------------------  ---------------
2019-04-21 12:21:25.906852 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 202 finished
-----------------------------  ---------------
replay_buffer/size              40800
trainer/QF1 Loss                    0.958433
trainer/QF2 Loss                    1.03319
trainer/Policy Loss                 9.96694
trainer/Q1 Predictions Mean        -8.31996
trainer/Q1 Predictions Std          8.57892
trainer/Q1 Predictions Max         -6.89682
trainer/Q1 Predictions Min        -71.9054
trainer/Q2 Predictions Mean        -8.36351
trainer/Q2 Predictions Std          8.42951
trainer/Q2 Predictions Max         -6.95221
trainer/Q2 Predictions Min        -70.3638
trainer/Q Targets Mean             -8.25971
trainer/Q Targets Std               8.7649
trainer/Q Targets Max              -0.0301986
trainer/Q Targets Min             -72.7772
trainer/Log Pis Mean                1.82957
trainer/Log Pis Std                 1.17
trainer/Log Pis Max                 6.41753
trainer/Log Pis Min                -1.55798
trainer/Policy mu Mean              0.0687267
trainer/Policy mu Std               0.474664
trainer/Policy mu Max               3.4983
trainer/Policy mu Min              -1.54445
trainer/Policy log std Mean        -2.26247
trainer/Policy log std Std          0.305482
trainer/Policy log std Max         -0.680379
trainer/Policy log std Min         -2.41919
trainer/Alpha                       0.0514303
trainer/Alpha Loss                 -0.505757
exploration/num steps total     40800
exploration/num paths total       408
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.128901
exploration/Rewards Std             0.0685501
exploration/Rewards Max            -0.00269934
exploration/Rewards Min            -0.417849
exploration/Returns Mean          -12.8901
exploration/Returns Std             0.104546
exploration/Returns Max           -12.7855
exploration/Returns Min           -12.9946
exploration/Actions Mean           -0.00661047
exploration/Actions Std             0.153975
exploration/Actions Max             0.449037
exploration/Actions Min            -0.983873
exploration/Num Paths               2
exploration/Average Returns       -12.8901
evaluation/num steps total     203000
evaluation/num paths total       2030
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.181009
evaluation/Rewards Std              0.811526
evaluation/Rewards Max             -0.0237014
evaluation/Rewards Min            -10.1482
evaluation/Returns Mean           -18.1009
evaluation/Returns Std             15.3107
evaluation/Returns Max             -4.84955
evaluation/Returns Min            -60.7611
evaluation/Actions Mean             0.0153029
evaluation/Actions Std              0.171946
evaluation/Actions Max              0.99755
evaluation/Actions Min             -0.993664
evaluation/Num Paths               10
evaluation/Average Returns        -18.1009
time/data storing (s)               0.0012289
time/evaluation sampling (s)        0.259128
time/exploration sampling (s)       0.068003
time/logging (s)                    0.00275778
time/saving (s)                     0.00209662
time/training (s)                   1.04382
time/epoch (s)                      1.37704
time/total (s)                    301.027
Epoch                             202
-----------------------------  ---------------
2019-04-21 12:21:27.403835 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 203 finished
-----------------------------  ---------------
replay_buffer/size              41000
trainer/QF1 Loss                    0.0397259
trainer/QF2 Loss                    0.0227342
trainer/Policy Loss                 9.25126
trainer/Q1 Predictions Mean        -7.44822
trainer/Q1 Predictions Std          2.8266
trainer/Q1 Predictions Max         -6.74085
trainer/Q1 Predictions Min        -28.8015
trainer/Q2 Predictions Mean        -7.50412
trainer/Q2 Predictions Std          2.83641
trainer/Q2 Predictions Max         -6.82216
trainer/Q2 Predictions Min        -28.8325
trainer/Q Targets Mean             -7.62616
trainer/Q Targets Std               2.82824
trainer/Q Targets Max              -6.85779
trainer/Q Targets Min             -29.1084
trainer/Log Pis Mean                1.85579
trainer/Log Pis Std                 1.1453
trainer/Log Pis Max                 5.82132
trainer/Log Pis Min                -1.77397
trainer/Policy mu Mean              0.104519
trainer/Policy mu Std               0.530733
trainer/Policy mu Max               3.2123
trainer/Policy mu Min              -1.25822
trainer/Policy log std Mean        -2.21733
trainer/Policy log std Std          0.391694
trainer/Policy log std Max         -0.306925
trainer/Policy log std Min         -2.4226
trainer/Alpha                       0.0525951
trainer/Alpha Loss                 -0.42475
exploration/num steps total     41000
exploration/num paths total       410
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.488203
exploration/Rewards Std             1.49276
exploration/Rewards Max            -0.00914509
exploration/Rewards Min           -10.5414
exploration/Returns Mean          -48.8203
exploration/Returns Std            19.7847
exploration/Returns Max           -29.0356
exploration/Returns Min           -68.6051
exploration/Actions Mean            0.0424374
exploration/Actions Std             0.268356
exploration/Actions Max             0.998537
exploration/Actions Min            -0.962086
exploration/Num Paths               2
exploration/Average Returns       -48.8203
evaluation/num steps total     204000
evaluation/num paths total       2040
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.209255
evaluation/Rewards Std              0.996096
evaluation/Rewards Max             -0.00766051
evaluation/Rewards Min            -10.1916
evaluation/Returns Mean           -20.9255
evaluation/Returns Std             14.1693
evaluation/Returns Max             -3.23831
evaluation/Returns Min            -49.7673
evaluation/Actions Mean             0.0307463
evaluation/Actions Std              0.192117
evaluation/Actions Max              0.998061
evaluation/Actions Min             -0.985174
evaluation/Num Paths               10
evaluation/Average Returns        -20.9255
time/data storing (s)               0.00113955
time/evaluation sampling (s)        0.281058
time/exploration sampling (s)       0.0727131
time/logging (s)                    0.00345692
time/saving (s)                     0.00242506
time/training (s)                   1.12909
time/epoch (s)                      1.48989
time/total (s)                    302.521
Epoch                             203
-----------------------------  ---------------
2019-04-21 12:21:28.836030 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 204 finished
-----------------------------  ---------------
replay_buffer/size              41200
trainer/QF1 Loss                    0.943688
trainer/QF2 Loss                    0.964919
trainer/Policy Loss                10.0021
trainer/Q1 Predictions Mean        -8.19153
trainer/Q1 Predictions Std          5.19224
trainer/Q1 Predictions Max         -6.79255
trainer/Q1 Predictions Min        -43.7524
trainer/Q2 Predictions Mean        -8.27666
trainer/Q2 Predictions Std          5.1483
trainer/Q2 Predictions Max         -6.90818
trainer/Q2 Predictions Min        -42.6594
trainer/Q Targets Mean             -8.13583
trainer/Q Targets Std               5.2579
trainer/Q Targets Max              -0.145427
trainer/Q Targets Min             -43.0892
trainer/Log Pis Mean                1.95541
trainer/Log Pis Std                 1.1239
trainer/Log Pis Max                 5.00567
trainer/Log Pis Min                -3.527
trainer/Policy mu Mean              0.101122
trainer/Policy mu Std               0.595158
trainer/Policy mu Max               3.2123
trainer/Policy mu Min              -1.60988
trainer/Policy log std Mean        -2.1756
trainer/Policy log std Std          0.411223
trainer/Policy log std Max         -0.540543
trainer/Policy log std Min         -2.38664
trainer/Alpha                       0.0541124
trainer/Alpha Loss                 -0.130046
exploration/num steps total     41200
exploration/num paths total       412
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.172194
exploration/Rewards Std             0.320223
exploration/Rewards Max            -0.00970427
exploration/Rewards Min            -3.15347
exploration/Returns Mean          -17.2194
exploration/Returns Std             1.83965
exploration/Returns Max           -15.3798
exploration/Returns Min           -19.0591
exploration/Actions Mean            0.0187717
exploration/Actions Std             0.186376
exploration/Actions Max             0.988275
exploration/Actions Min            -0.426783
exploration/Num Paths               2
exploration/Average Returns       -17.2194
evaluation/num steps total     205000
evaluation/num paths total       2050
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.225379
evaluation/Rewards Std              0.958215
evaluation/Rewards Max             -0.0166135
evaluation/Rewards Min             -9.78744
evaluation/Returns Mean           -22.5379
evaluation/Returns Std             11.7375
evaluation/Returns Max             -8.42376
evaluation/Returns Min            -48.342
evaluation/Actions Mean             0.0339958
evaluation/Actions Std              0.195662
evaluation/Actions Max              0.998195
evaluation/Actions Min             -0.991619
evaluation/Num Paths               10
evaluation/Average Returns        -22.5379
time/data storing (s)               0.00117428
time/evaluation sampling (s)        0.287216
time/exploration sampling (s)       0.0701598
time/logging (s)                    0.00359808
time/saving (s)                     0.00250398
time/training (s)                   1.06004
time/epoch (s)                      1.4247
time/total (s)                    303.951
Epoch                             204
-----------------------------  ---------------
2019-04-21 12:21:30.318389 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 205 finished
-----------------------------  ---------------
replay_buffer/size              41400
trainer/QF1 Loss                    0.0424469
trainer/QF2 Loss                    0.0470199
trainer/Policy Loss                 9.8681
trainer/Q1 Predictions Mean        -8.07555
trainer/Q1 Predictions Std          5.55574
trainer/Q1 Predictions Max         -6.75196
trainer/Q1 Predictions Min        -45.9246
trainer/Q2 Predictions Mean        -8.13425
trainer/Q2 Predictions Std          5.61272
trainer/Q2 Predictions Max         -6.83596
trainer/Q2 Predictions Min        -46.1416
trainer/Q Targets Mean             -8.2125
trainer/Q Targets Std               5.43077
trainer/Q Targets Max              -6.84136
trainer/Q Targets Min             -44.8595
trainer/Log Pis Mean                1.85124
trainer/Log Pis Std                 1.2083
trainer/Log Pis Max                 5.94271
trainer/Log Pis Min                -2.76717
trainer/Policy mu Mean              0.118198
trainer/Policy mu Std               0.575908
trainer/Policy mu Max               3.12257
trainer/Policy mu Min              -1.94387
trainer/Policy log std Mean        -2.15887
trainer/Policy log std Std          0.372777
trainer/Policy log std Max         -0.614675
trainer/Policy log std Min         -2.41525
trainer/Alpha                       0.0533749
trainer/Alpha Loss                 -0.435899
exploration/num steps total     41400
exploration/num paths total       414
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.265661
exploration/Rewards Std             0.807842
exploration/Rewards Max            -0.004453
exploration/Rewards Min            -7.563
exploration/Returns Mean          -26.5661
exploration/Returns Std            11.6769
exploration/Returns Max           -14.8892
exploration/Returns Min           -38.243
exploration/Actions Mean            0.00873762
exploration/Actions Std             0.238786
exploration/Actions Max             0.991394
exploration/Actions Min            -0.992789
exploration/Num Paths               2
exploration/Average Returns       -26.5661
evaluation/num steps total     206000
evaluation/num paths total       2060
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.268755
evaluation/Rewards Std              1.15801
evaluation/Rewards Max             -0.0188274
evaluation/Rewards Min            -10.1404
evaluation/Returns Mean           -26.8755
evaluation/Returns Std             20.307
evaluation/Returns Max             -4.29871
evaluation/Returns Min            -58.7706
evaluation/Actions Mean             0.0278537
evaluation/Actions Std              0.190525
evaluation/Actions Max              0.997151
evaluation/Actions Min             -0.995884
evaluation/Num Paths               10
evaluation/Average Returns        -26.8755
time/data storing (s)               0.00123112
time/evaluation sampling (s)        0.259258
time/exploration sampling (s)       0.0689934
time/logging (s)                    0.00366908
time/saving (s)                     0.00292833
time/training (s)                   1.13847
time/epoch (s)                      1.47455
time/total (s)                    305.429
Epoch                             205
-----------------------------  ---------------
2019-04-21 12:21:31.803596 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 206 finished
-----------------------------  ---------------
replay_buffer/size              41600
trainer/QF1 Loss                    0.594962
trainer/QF2 Loss                    0.580702
trainer/Policy Loss                 9.60521
trainer/Q1 Predictions Mean        -7.67796
trainer/Q1 Predictions Std          2.65584
trainer/Q1 Predictions Max         -6.97402
trainer/Q1 Predictions Min        -29.2712
trainer/Q2 Predictions Mean        -7.70674
trainer/Q2 Predictions Std          2.67786
trainer/Q2 Predictions Max         -7.01093
trainer/Q2 Predictions Min        -29.5477
trainer/Q Targets Mean             -7.5792
trainer/Q Targets Std               3.04042
trainer/Q Targets Max              -0.0774291
trainer/Q Targets Min             -32.0001
trainer/Log Pis Mean                2.03487
trainer/Log Pis Std                 0.853367
trainer/Log Pis Max                 4.72213
trainer/Log Pis Min                -0.585681
trainer/Policy mu Mean              0.0565222
trainer/Policy mu Std               0.517147
trainer/Policy mu Max               2.9014
trainer/Policy mu Min              -2.57421
trainer/Policy log std Mean        -2.19474
trainer/Policy log std Std          0.38478
trainer/Policy log std Max         -0.515803
trainer/Policy log std Min         -2.44497
trainer/Alpha                       0.0537317
trainer/Alpha Loss                  0.101944
exploration/num steps total     41600
exploration/num paths total       416
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.633527
exploration/Rewards Std             1.77475
exploration/Rewards Max            -0.00706909
exploration/Rewards Min           -10.3209
exploration/Returns Mean          -63.3527
exploration/Returns Std             3.95718
exploration/Returns Max           -59.3955
exploration/Returns Min           -67.3099
exploration/Actions Mean            0.0733695
exploration/Actions Std             0.276839
exploration/Actions Max             0.998879
exploration/Actions Min            -0.323548
exploration/Num Paths               2
exploration/Average Returns       -63.3527
evaluation/num steps total     207000
evaluation/num paths total       2070
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.172861
evaluation/Rewards Std              0.747201
evaluation/Rewards Max             -0.0157578
evaluation/Rewards Min             -8.03275
evaluation/Returns Mean           -17.2861
evaluation/Returns Std             12.5887
evaluation/Returns Max             -5.4753
evaluation/Returns Min            -39.1897
evaluation/Actions Mean             0.0194158
evaluation/Actions Std              0.171223
evaluation/Actions Max              0.995073
evaluation/Actions Min             -0.993381
evaluation/Num Paths               10
evaluation/Average Returns        -17.2861
time/data storing (s)               0.00119529
time/evaluation sampling (s)        0.253493
time/exploration sampling (s)       0.0695711
time/logging (s)                    0.00377726
time/saving (s)                     0.00235643
time/training (s)                   1.14788
time/epoch (s)                      1.47827
time/total (s)                    306.911
Epoch                             206
-----------------------------  ---------------
2019-04-21 12:21:33.429957 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 207 finished
-----------------------------  ----------------
replay_buffer/size              41800
trainer/QF1 Loss                    0.991533
trainer/QF2 Loss                    0.988614
trainer/Policy Loss                11.6496
trainer/Q1 Predictions Mean        -9.82464
trainer/Q1 Predictions Std         10.3073
trainer/Q1 Predictions Max         -6.86501
trainer/Q1 Predictions Min        -74.4417
trainer/Q2 Predictions Mean        -9.82809
trainer/Q2 Predictions Std         10.1534
trainer/Q2 Predictions Max         -6.92947
trainer/Q2 Predictions Min        -73.5251
trainer/Q Targets Mean             -9.6912
trainer/Q Targets Std              10.2722
trainer/Q Targets Max              -0.0892301
trainer/Q Targets Min             -74.1927
trainer/Log Pis Mean                2.21294
trainer/Log Pis Std                 1.50322
trainer/Log Pis Max                 7.06463
trainer/Log Pis Min                -1.7208
trainer/Policy mu Mean              0.15705
trainer/Policy mu Std               0.802837
trainer/Policy mu Max               3.04366
trainer/Policy mu Min              -2.37129
trainer/Policy log std Mean        -2.05708
trainer/Policy log std Std          0.540058
trainer/Policy log std Max         -0.592514
trainer/Policy log std Min         -2.40418
trainer/Alpha                       0.052817
trainer/Alpha Loss                  0.626236
exploration/num steps total     41800
exploration/num paths total       418
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.218002
exploration/Rewards Std             0.509186
exploration/Rewards Max            -0.00871893
exploration/Rewards Min            -4.40627
exploration/Returns Mean          -21.8002
exploration/Returns Std             3.06149
exploration/Returns Max           -18.7387
exploration/Returns Min           -24.8617
exploration/Actions Mean           -0.000447319
exploration/Actions Std             0.206348
exploration/Actions Max             0.996985
exploration/Actions Min            -0.995653
exploration/Num Paths               2
exploration/Average Returns       -21.8002
evaluation/num steps total     208000
evaluation/num paths total       2080
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.321612
evaluation/Rewards Std              1.21832
evaluation/Rewards Max             -0.0575797
evaluation/Rewards Min            -10.3635
evaluation/Returns Mean           -32.1612
evaluation/Returns Std             20.7875
evaluation/Returns Max             -9.32331
evaluation/Returns Min            -63.9603
evaluation/Actions Mean             0.0304433
evaluation/Actions Std              0.202906
evaluation/Actions Max              0.99633
evaluation/Actions Min             -0.994787
evaluation/Num Paths               10
evaluation/Average Returns        -32.1612
time/data storing (s)               0.00127088
time/evaluation sampling (s)        0.269194
time/exploration sampling (s)       0.0825758
time/logging (s)                    0.00362966
time/saving (s)                     0.00270975
time/training (s)                   1.25888
time/epoch (s)                      1.61826
time/total (s)                    308.534
Epoch                             207
-----------------------------  ----------------
2019-04-21 12:21:35.094044 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 208 finished
-----------------------------  ---------------
replay_buffer/size              42000
trainer/QF1 Loss                    0.471797
trainer/QF2 Loss                    0.480682
trainer/Policy Loss                 8.73521
trainer/Q1 Predictions Mean        -7.13217
trainer/Q1 Predictions Std          1.23367
trainer/Q1 Predictions Max         -6.8199
trainer/Q1 Predictions Min        -19.0073
trainer/Q2 Predictions Mean        -7.08048
trainer/Q2 Predictions Std          1.24092
trainer/Q2 Predictions Max         -6.76713
trainer/Q2 Predictions Min        -18.9216
trainer/Q Targets Mean             -7.1402
trainer/Q Targets Std               1.38872
trainer/Q Targets Max              -0.127742
trainer/Q Targets Min             -18.743
trainer/Log Pis Mean                1.6759
trainer/Log Pis Std                 1.41687
trainer/Log Pis Max                 5.13485
trainer/Log Pis Min                -6.42134
trainer/Policy mu Mean              0.0362833
trainer/Policy mu Std               0.443894
trainer/Policy mu Max               2.15785
trainer/Policy mu Min              -2.80485
trainer/Policy log std Mean        -2.1901
trainer/Policy log std Std          0.351934
trainer/Policy log std Max         -0.541136
trainer/Policy log std Min         -2.38485
trainer/Alpha                       0.0528345
trainer/Alpha Loss                 -0.953018
exploration/num steps total     42000
exploration/num paths total       420
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.181287
exploration/Rewards Std             0.421701
exploration/Rewards Max            -0.0104884
exploration/Rewards Min            -4.32309
exploration/Returns Mean          -18.1287
exploration/Returns Std             6.16899
exploration/Returns Max           -11.9597
exploration/Returns Min           -24.2977
exploration/Actions Mean           -0.0116523
exploration/Actions Std             0.188943
exploration/Actions Max             0.768241
exploration/Actions Min            -0.996259
exploration/Num Paths               2
exploration/Average Returns       -18.1287
evaluation/num steps total     209000
evaluation/num paths total       2090
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.266359
evaluation/Rewards Std              1.1966
evaluation/Rewards Max             -0.00549881
evaluation/Rewards Min            -10.2399
evaluation/Returns Mean           -26.6359
evaluation/Returns Std             15.7993
evaluation/Returns Max             -2.28081
evaluation/Returns Min            -49.9973
evaluation/Actions Mean             0.0225619
evaluation/Actions Std              0.214113
evaluation/Actions Max              0.99709
evaluation/Actions Min             -0.996293
evaluation/Num Paths               10
evaluation/Average Returns        -26.6359
time/data storing (s)               0.00172303
time/evaluation sampling (s)        0.348562
time/exploration sampling (s)       0.0879989
time/logging (s)                    0.00426027
time/saving (s)                     0.00341512
time/training (s)                   1.21027
time/epoch (s)                      1.65623
time/total (s)                    310.195
Epoch                             208
-----------------------------  ---------------
2019-04-21 12:21:36.597558 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 209 finished
-----------------------------  ----------------
replay_buffer/size              42200
trainer/QF1 Loss                    0.00949505
trainer/QF2 Loss                    0.00950733
trainer/Policy Loss                 9.43242
trainer/Q1 Predictions Mean        -7.33983
trainer/Q1 Predictions Std          1.61967
trainer/Q1 Predictions Max         -6.80498
trainer/Q1 Predictions Min        -19.6204
trainer/Q2 Predictions Mean        -7.44614
trainer/Q2 Predictions Std          1.62158
trainer/Q2 Predictions Max         -6.93146
trainer/Q2 Predictions Min        -19.7802
trainer/Q Targets Mean             -7.38805
trainer/Q Targets Std               1.63506
trainer/Q Targets Max              -6.79001
trainer/Q Targets Min             -20.0161
trainer/Log Pis Mean                2.12209
trainer/Log Pis Std                 1.04785
trainer/Log Pis Max                 5.21669
trainer/Log Pis Min                -1.07271
trainer/Policy mu Mean              0.0664742
trainer/Policy mu Std               0.495585
trainer/Policy mu Max               2.72674
trainer/Policy mu Min              -1.55745
trainer/Policy log std Mean        -2.25703
trainer/Policy log std Std          0.366998
trainer/Policy log std Max         -0.679631
trainer/Policy log std Min         -2.47882
trainer/Alpha                       0.0547975
trainer/Alpha Loss                  0.3546
exploration/num steps total     42200
exploration/num paths total       422
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.15504
exploration/Rewards Std             0.325653
exploration/Rewards Max            -0.000248694
exploration/Rewards Min            -3.35508
exploration/Returns Mean          -15.504
exploration/Returns Std             1.09995
exploration/Returns Max           -14.404
exploration/Returns Min           -16.6039
exploration/Actions Mean            0.00736768
exploration/Actions Std             0.189516
exploration/Actions Max             0.995048
exploration/Actions Min            -0.98871
exploration/Num Paths               2
exploration/Average Returns       -15.504
evaluation/num steps total     210000
evaluation/num paths total       2100
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.171317
evaluation/Rewards Std              0.899164
evaluation/Rewards Max             -0.0107896
evaluation/Rewards Min             -9.78337
evaluation/Returns Mean           -17.1317
evaluation/Returns Std             16.8636
evaluation/Returns Max             -1.24306
evaluation/Returns Min            -54.3807
evaluation/Actions Mean             0.0131127
evaluation/Actions Std              0.176914
evaluation/Actions Max              0.995584
evaluation/Actions Min             -0.994001
evaluation/Num Paths               10
evaluation/Average Returns        -17.1317
time/data storing (s)               0.00143467
time/evaluation sampling (s)        0.298126
time/exploration sampling (s)       0.0842989
time/logging (s)                    0.00340235
time/saving (s)                     0.00241042
time/training (s)                   1.10465
time/epoch (s)                      1.49432
time/total (s)                    311.694
Epoch                             209
-----------------------------  ----------------
2019-04-21 12:21:38.282729 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 210 finished
-----------------------------  ---------------
replay_buffer/size              42400
trainer/QF1 Loss                    0.082727
trainer/QF2 Loss                    0.0755694
trainer/Policy Loss                 9.39072
trainer/Q1 Predictions Mean        -7.53021
trainer/Q1 Predictions Std          3.21204
trainer/Q1 Predictions Max         -6.67543
trainer/Q1 Predictions Min        -29.8554
trainer/Q2 Predictions Mean        -7.57597
trainer/Q2 Predictions Std          3.16854
trainer/Q2 Predictions Max         -6.75831
trainer/Q2 Predictions Min        -29.6902
trainer/Q Targets Mean             -7.71799
trainer/Q Targets Std               3.32317
trainer/Q Targets Max              -6.78247
trainer/Q Targets Min             -31.9681
trainer/Log Pis Mean                1.97916
trainer/Log Pis Std                 1.1424
trainer/Log Pis Max                 6.10644
trainer/Log Pis Min                -2.16191
trainer/Policy mu Mean              0.0491336
trainer/Policy mu Std               0.558577
trainer/Policy mu Max               2.96925
trainer/Policy mu Min              -1.94642
trainer/Policy log std Mean        -2.18727
trainer/Policy log std Std          0.407216
trainer/Policy log std Max         -0.25321
trainer/Policy log std Min         -2.38637
trainer/Alpha                       0.0557107
trainer/Alpha Loss                 -0.0601909
exploration/num steps total     42400
exploration/num paths total       424
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.376138
exploration/Rewards Std             1.16786
exploration/Rewards Max            -0.01291
exploration/Rewards Min            -8.96114
exploration/Returns Mean          -37.6138
exploration/Returns Std            16.9061
exploration/Returns Max           -20.7076
exploration/Returns Min           -54.5199
exploration/Actions Mean            0.036671
exploration/Actions Std             0.238732
exploration/Actions Max             0.999303
exploration/Actions Min            -0.658801
exploration/Num Paths               2
exploration/Average Returns       -37.6138
evaluation/num steps total     211000
evaluation/num paths total       2110
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.144933
evaluation/Rewards Std              0.73009
evaluation/Rewards Max             -0.0210325
evaluation/Rewards Min             -8.77268
evaluation/Returns Mean           -14.4933
evaluation/Returns Std             11.2986
evaluation/Returns Max             -2.96485
evaluation/Returns Min            -37.4766
evaluation/Actions Mean             0.0223047
evaluation/Actions Std              0.169954
evaluation/Actions Max              0.994763
evaluation/Actions Min             -0.981933
evaluation/Num Paths               10
evaluation/Average Returns        -14.4933
time/data storing (s)               0.00139106
time/evaluation sampling (s)        0.340839
time/exploration sampling (s)       0.0691376
time/logging (s)                    0.0037237
time/saving (s)                     0.00256497
time/training (s)                   1.26056
time/epoch (s)                      1.67822
time/total (s)                    313.376
Epoch                             210
-----------------------------  ---------------
2019-04-21 12:21:39.786879 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 211 finished
-----------------------------  ---------------
replay_buffer/size              42600
trainer/QF1 Loss                    0.103426
trainer/QF2 Loss                    0.158109
trainer/Policy Loss                10.4303
trainer/Q1 Predictions Mean        -8.5538
trainer/Q1 Predictions Std          8.01859
trainer/Q1 Predictions Max         -6.76522
trainer/Q1 Predictions Min        -76.8739
trainer/Q2 Predictions Mean        -8.51196
trainer/Q2 Predictions Std          8.11022
trainer/Q2 Predictions Max         -6.70858
trainer/Q2 Predictions Min        -77.6372
trainer/Q Targets Mean             -8.60104
trainer/Q Targets Std               7.82278
trainer/Q Targets Max              -6.75109
trainer/Q Targets Min             -74.0194
trainer/Log Pis Mean                2.1314
trainer/Log Pis Std                 1.3329
trainer/Log Pis Max                 6.71373
trainer/Log Pis Min                -2.53902
trainer/Policy mu Mean              0.115698
trainer/Policy mu Std               0.628632
trainer/Policy mu Max               3.2822
trainer/Policy mu Min              -1.64553
trainer/Policy log std Mean        -2.22111
trainer/Policy log std Std          0.406408
trainer/Policy log std Max         -0.481681
trainer/Policy log std Min         -2.45142
trainer/Alpha                       0.0568182
trainer/Alpha Loss                  0.376844
exploration/num steps total     42600
exploration/num paths total       426
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.436035
exploration/Rewards Std             1.32851
exploration/Rewards Max            -0.0129579
exploration/Rewards Min            -9.73392
exploration/Returns Mean          -43.6035
exploration/Returns Std            18.3721
exploration/Returns Max           -25.2314
exploration/Returns Min           -61.9756
exploration/Actions Mean            0.0225743
exploration/Actions Std             0.257255
exploration/Actions Max             0.998549
exploration/Actions Min            -0.938287
exploration/Num Paths               2
exploration/Average Returns       -43.6035
evaluation/num steps total     212000
evaluation/num paths total       2120
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.261769
evaluation/Rewards Std              1.16475
evaluation/Rewards Max             -0.0127964
evaluation/Rewards Min            -10.7621
evaluation/Returns Mean           -26.1769
evaluation/Returns Std             18.0279
evaluation/Returns Max             -1.85608
evaluation/Returns Min            -59.8552
evaluation/Actions Mean             0.0354926
evaluation/Actions Std              0.202501
evaluation/Actions Max              0.997589
evaluation/Actions Min             -0.959604
evaluation/Num Paths               10
evaluation/Average Returns        -26.1769
time/data storing (s)               0.00134702
time/evaluation sampling (s)        0.301451
time/exploration sampling (s)       0.0764961
time/logging (s)                    0.0036644
time/saving (s)                     0.00389368
time/training (s)                   1.10932
time/epoch (s)                      1.49617
time/total (s)                    314.876
Epoch                             211
-----------------------------  ---------------
2019-04-21 12:21:41.267620 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 212 finished
-----------------------------  ---------------
replay_buffer/size              42800
trainer/QF1 Loss                    0.647749
trainer/QF2 Loss                    0.679508
trainer/Policy Loss                10.12
trainer/Q1 Predictions Mean        -8.27401
trainer/Q1 Predictions Std          7.34312
trainer/Q1 Predictions Max         -6.70221
trainer/Q1 Predictions Min        -52.1852
trainer/Q2 Predictions Mean        -8.30446
trainer/Q2 Predictions Std          7.39411
trainer/Q2 Predictions Max         -6.72862
trainer/Q2 Predictions Min        -52.7092
trainer/Q Targets Mean             -8.26311
trainer/Q Targets Std               7.21416
trainer/Q Targets Max              -0.21688
trainer/Q Targets Min             -52.744
trainer/Log Pis Mean                2.01687
trainer/Log Pis Std                 1.15949
trainer/Log Pis Max                 7.33296
trainer/Log Pis Min                -3.84856
trainer/Policy mu Mean              0.110787
trainer/Policy mu Std               0.570666
trainer/Policy mu Max               3.23559
trainer/Policy mu Min              -1.00422
trainer/Policy log std Mean        -2.17396
trainer/Policy log std Std          0.380411
trainer/Policy log std Max         -0.506489
trainer/Policy log std Min         -2.37019
trainer/Alpha                       0.0570799
trainer/Alpha Loss                  0.0482894
exploration/num steps total     42800
exploration/num paths total       428
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.32987
exploration/Rewards Std             1.03091
exploration/Rewards Max            -0.0164736
exploration/Rewards Min            -8.3586
exploration/Returns Mean          -32.987
exploration/Returns Std            16.7896
exploration/Returns Max           -16.1973
exploration/Returns Min           -49.7766
exploration/Actions Mean            0.0337409
exploration/Actions Std             0.229755
exploration/Actions Max             0.998344
exploration/Actions Min            -0.719448
exploration/Num Paths               2
exploration/Average Returns       -32.987
evaluation/num steps total     213000
evaluation/num paths total       2130
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.246858
evaluation/Rewards Std              1.07053
evaluation/Rewards Max             -0.0074869
evaluation/Rewards Min             -9.85396
evaluation/Returns Mean           -24.6858
evaluation/Returns Std             14.5714
evaluation/Returns Max             -2.59836
evaluation/Returns Min            -54.074
evaluation/Actions Mean             0.0246741
evaluation/Actions Std              0.195158
evaluation/Actions Max              0.996356
evaluation/Actions Min             -0.981933
evaluation/Num Paths               10
evaluation/Average Returns        -24.6858
time/data storing (s)               0.00117662
time/evaluation sampling (s)        0.258103
time/exploration sampling (s)       0.0670862
time/logging (s)                    0.00349741
time/saving (s)                     0.00300565
time/training (s)                   1.14007
time/epoch (s)                      1.47293
time/total (s)                    316.354
Epoch                             212
-----------------------------  ---------------
2019-04-21 12:21:42.690792 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 213 finished
-----------------------------  ---------------
replay_buffer/size              43000
trainer/QF1 Loss                    0.028701
trainer/QF2 Loss                    0.0295698
trainer/Policy Loss                10.4834
trainer/Q1 Predictions Mean        -8.51955
trainer/Q1 Predictions Std          5.94407
trainer/Q1 Predictions Max         -6.82687
trainer/Q1 Predictions Min        -48.0061
trainer/Q2 Predictions Mean        -8.56138
trainer/Q2 Predictions Std          5.91093
trainer/Q2 Predictions Max         -6.87375
trainer/Q2 Predictions Min        -47.3135
trainer/Q Targets Mean             -8.53589
trainer/Q Targets Std               5.98163
trainer/Q Targets Max              -6.7199
trainer/Q Targets Min             -47.9629
trainer/Log Pis Mean                2.104
trainer/Log Pis Std                 1.11112
trainer/Log Pis Max                 7.95542
trainer/Log Pis Min                -0.746901
trainer/Policy mu Mean              0.204568
trainer/Policy mu Std               0.692437
trainer/Policy mu Max               3.21524
trainer/Policy mu Min              -2.21481
trainer/Policy log std Mean        -2.08446
trainer/Policy log std Std          0.448134
trainer/Policy log std Max         -0.607139
trainer/Policy log std Min         -2.38438
trainer/Alpha                       0.0557792
trainer/Alpha Loss                  0.300156
exploration/num steps total     43000
exploration/num paths total       430
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.244464
exploration/Rewards Std             0.590924
exploration/Rewards Max            -0.00619403
exploration/Rewards Min            -5.61946
exploration/Returns Mean          -24.4464
exploration/Returns Std             3.66014
exploration/Returns Max           -20.7863
exploration/Returns Min           -28.1066
exploration/Actions Mean            0.0350658
exploration/Actions Std             0.229053
exploration/Actions Max             0.997508
exploration/Actions Min            -0.459227
exploration/Num Paths               2
exploration/Average Returns       -24.4464
evaluation/num steps total     214000
evaluation/num paths total       2140
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.156417
evaluation/Rewards Std              0.666557
evaluation/Rewards Max             -0.0427434
evaluation/Rewards Min             -8.42376
evaluation/Returns Mean           -15.6417
evaluation/Returns Std             10.9304
evaluation/Returns Max             -5.85785
evaluation/Returns Min            -38.4119
evaluation/Actions Mean             0.0141478
evaluation/Actions Std              0.158273
evaluation/Actions Max              0.995854
evaluation/Actions Min             -0.994349
evaluation/Num Paths               10
evaluation/Average Returns        -15.6417
time/data storing (s)               0.00112142
time/evaluation sampling (s)        0.261015
time/exploration sampling (s)       0.0666098
time/logging (s)                    0.00369007
time/saving (s)                     0.00193173
time/training (s)                   1.08185
time/epoch (s)                      1.41622
time/total (s)                    317.774
Epoch                             213
-----------------------------  ---------------
2019-04-21 12:21:44.071424 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 214 finished
-----------------------------  ---------------
replay_buffer/size              43200
trainer/QF1 Loss                    0.46832
trainer/QF2 Loss                    0.465168
trainer/Policy Loss                 8.99522
trainer/Q1 Predictions Mean        -7.23536
trainer/Q1 Predictions Std          2.50858
trainer/Q1 Predictions Max         -6.59392
trainer/Q1 Predictions Min        -29.1966
trainer/Q2 Predictions Mean        -7.2468
trainer/Q2 Predictions Std          2.50668
trainer/Q2 Predictions Max         -6.62939
trainer/Q2 Predictions Min        -29.1985
trainer/Q Targets Mean             -7.32697
trainer/Q Targets Std               2.61785
trainer/Q Targets Max              -0.101069
trainer/Q Targets Min             -29.4588
trainer/Log Pis Mean                1.86179
trainer/Log Pis Std                 1.17198
trainer/Log Pis Max                 5.01512
trainer/Log Pis Min                -2.71834
trainer/Policy mu Mean              0.0600993
trainer/Policy mu Std               0.512232
trainer/Policy mu Max               2.95921
trainer/Policy mu Min              -1.25269
trainer/Policy log std Mean        -2.17922
trainer/Policy log std Std          0.362602
trainer/Policy log std Max         -0.663476
trainer/Policy log std Min         -2.4085
trainer/Alpha                       0.0552327
trainer/Alpha Loss                 -0.400287
exploration/num steps total     43200
exploration/num paths total       432
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.287512
exploration/Rewards Std             0.914871
exploration/Rewards Max            -0.0111801
exploration/Rewards Min            -7.66278
exploration/Returns Mean          -28.7512
exploration/Returns Std            17.1166
exploration/Returns Max           -11.6346
exploration/Returns Min           -45.8678
exploration/Actions Mean            0.0178468
exploration/Actions Std             0.206709
exploration/Actions Max             0.997961
exploration/Actions Min            -0.631647
exploration/Num Paths               2
exploration/Average Returns       -28.7512
evaluation/num steps total     215000
evaluation/num paths total       2150
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.177299
evaluation/Rewards Std              0.847262
evaluation/Rewards Max             -0.00695821
evaluation/Rewards Min             -9.53389
evaluation/Returns Mean           -17.7299
evaluation/Returns Std             14.6602
evaluation/Returns Max             -3.45414
evaluation/Returns Min            -52.3532
evaluation/Actions Mean             0.0246471
evaluation/Actions Std              0.178462
evaluation/Actions Max              0.997121
evaluation/Actions Min             -0.996742
evaluation/Num Paths               10
evaluation/Average Returns        -17.7299
time/data storing (s)               0.00134529
time/evaluation sampling (s)        0.244392
time/exploration sampling (s)       0.0673649
time/logging (s)                    0.00354691
time/saving (s)                     0.00270257
time/training (s)                   1.05368
time/epoch (s)                      1.37304
time/total (s)                    319.151
Epoch                             214
-----------------------------  ---------------
2019-04-21 12:21:45.515955 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 215 finished
-----------------------------  ---------------
replay_buffer/size              43400
trainer/QF1 Loss                    0.0229891
trainer/QF2 Loss                    0.0239789
trainer/Policy Loss                 8.88149
trainer/Q1 Predictions Mean        -7.25887
trainer/Q1 Predictions Std          1.74935
trainer/Q1 Predictions Max         -6.711
trainer/Q1 Predictions Min        -19.3165
trainer/Q2 Predictions Mean        -7.24105
trainer/Q2 Predictions Std          1.73115
trainer/Q2 Predictions Max         -6.72429
trainer/Q2 Predictions Min        -19.0973
trainer/Q Targets Mean             -7.30848
trainer/Q Targets Std               1.67232
trainer/Q Targets Max              -6.66848
trainer/Q Targets Min             -18.4397
trainer/Log Pis Mean                1.73761
trainer/Log Pis Std                 1.13541
trainer/Log Pis Max                 5.38983
trainer/Log Pis Min                -2.12365
trainer/Policy mu Mean              0.0866497
trainer/Policy mu Std               0.48869
trainer/Policy mu Max               3.11259
trainer/Policy mu Min              -1.15474
trainer/Policy log std Mean        -2.20279
trainer/Policy log std Std          0.345977
trainer/Policy log std Max         -0.694471
trainer/Policy log std Min         -2.37873
trainer/Alpha                       0.0544682
trainer/Alpha Loss                 -0.763565
exploration/num steps total     43400
exploration/num paths total       434
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.436677
exploration/Rewards Std             1.303
exploration/Rewards Max            -0.00238457
exploration/Rewards Min            -9.3579
exploration/Returns Mean          -43.6677
exploration/Returns Std            16.332
exploration/Returns Max           -27.3357
exploration/Returns Min           -59.9997
exploration/Actions Mean            0.0409814
exploration/Actions Std             0.238994
exploration/Actions Max             0.998036
exploration/Actions Min            -0.432936
exploration/Num Paths               2
exploration/Average Returns       -43.6677
evaluation/num steps total     216000
evaluation/num paths total       2160
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.211323
evaluation/Rewards Std              0.80556
evaluation/Rewards Max             -0.0213091
evaluation/Rewards Min             -7.91845
evaluation/Returns Mean           -21.1323
evaluation/Returns Std              9.10434
evaluation/Returns Max             -6.11498
evaluation/Returns Min            -37.5925
evaluation/Actions Mean             0.0180517
evaluation/Actions Std              0.185948
evaluation/Actions Max              0.995391
evaluation/Actions Min             -0.997019
evaluation/Num Paths               10
evaluation/Average Returns        -21.1323
time/data storing (s)               0.00117252
time/evaluation sampling (s)        0.247674
time/exploration sampling (s)       0.0650227
time/logging (s)                    0.00342071
time/saving (s)                     0.0023607
time/training (s)                   1.11752
time/epoch (s)                      1.43717
time/total (s)                    320.592
Epoch                             215
-----------------------------  ---------------
2019-04-21 12:21:46.899073 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 216 finished
-----------------------------  ---------------
replay_buffer/size              43600
trainer/QF1 Loss                    0.933653
trainer/QF2 Loss                    0.928145
trainer/Policy Loss                 9.74089
trainer/Q1 Predictions Mean        -8.15549
trainer/Q1 Predictions Std          6.31333
trainer/Q1 Predictions Max         -6.78893
trainer/Q1 Predictions Min        -57.6129
trainer/Q2 Predictions Mean        -8.16808
trainer/Q2 Predictions Std          6.36268
trainer/Q2 Predictions Max         -6.78368
trainer/Q2 Predictions Min        -58.3316
trainer/Q Targets Mean             -7.94673
trainer/Q Targets Std               6.35548
trainer/Q Targets Max              -0.0932097
trainer/Q Targets Min             -57.5806
trainer/Log Pis Mean                1.89831
trainer/Log Pis Std                 1.46869
trainer/Log Pis Max                 7.46669
trainer/Log Pis Min                -3.26805
trainer/Policy mu Mean              0.0472808
trainer/Policy mu Std               0.534628
trainer/Policy mu Max               2.99353
trainer/Policy mu Min              -2.16497
trainer/Policy log std Mean        -2.30613
trainer/Policy log std Std          0.374838
trainer/Policy log std Max         -0.630484
trainer/Policy log std Min         -2.50153
trainer/Alpha                       0.0533359
trainer/Alpha Loss                 -0.29808
exploration/num steps total     43600
exploration/num paths total       436
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.176548
exploration/Rewards Std             0.438414
exploration/Rewards Max            -0.00211869
exploration/Rewards Min            -4.1883
exploration/Returns Mean          -17.6548
exploration/Returns Std             1.86903
exploration/Returns Max           -15.7857
exploration/Returns Min           -19.5238
exploration/Actions Mean            0.0176554
exploration/Actions Std             0.200936
exploration/Actions Max             0.997092
exploration/Actions Min            -0.976635
exploration/Num Paths               2
exploration/Average Returns       -17.6548
evaluation/num steps total     217000
evaluation/num paths total       2170
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.25713
evaluation/Rewards Std              1.06609
evaluation/Rewards Max             -0.0265815
evaluation/Rewards Min            -10.1004
evaluation/Returns Mean           -25.713
evaluation/Returns Std             16.5042
evaluation/Returns Max             -7.92223
evaluation/Returns Min            -52.8603
evaluation/Actions Mean             0.0275378
evaluation/Actions Std              0.201018
evaluation/Actions Max              0.997327
evaluation/Actions Min             -0.988982
evaluation/Num Paths               10
evaluation/Average Returns        -25.713
time/data storing (s)               0.00118039
time/evaluation sampling (s)        0.262893
time/exploration sampling (s)       0.0645382
time/logging (s)                    0.0035029
time/saving (s)                     0.00234912
time/training (s)                   1.0409
time/epoch (s)                      1.37536
time/total (s)                    321.972
Epoch                             216
-----------------------------  ---------------
2019-04-21 12:21:48.226273 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 217 finished
-----------------------------  ---------------
replay_buffer/size              43800
trainer/QF1 Loss                    0.0243092
trainer/QF2 Loss                    0.0234128
trainer/Policy Loss                 9.17735
trainer/Q1 Predictions Mean        -7.3548
trainer/Q1 Predictions Std          2.58229
trainer/Q1 Predictions Max         -6.6639
trainer/Q1 Predictions Min        -28.3492
trainer/Q2 Predictions Mean        -7.309
trainer/Q2 Predictions Std          2.61049
trainer/Q2 Predictions Max         -6.62154
trainer/Q2 Predictions Min        -28.0472
trainer/Q Targets Mean             -7.43813
trainer/Q Targets Std               2.60158
trainer/Q Targets Max              -6.64078
trainer/Q Targets Min             -28.0863
trainer/Log Pis Mean                2.00572
trainer/Log Pis Std                 1.07235
trainer/Log Pis Max                 5.08127
trainer/Log Pis Min                -2.06449
trainer/Policy mu Mean              0.0377232
trainer/Policy mu Std               0.516097
trainer/Policy mu Max               2.86539
trainer/Policy mu Min              -1.43721
trainer/Policy log std Mean        -2.22833
trainer/Policy log std Std          0.344886
trainer/Policy log std Max         -0.6963
trainer/Policy log std Min         -2.3988
trainer/Alpha                       0.0527831
trainer/Alpha Loss                  0.0168115
exploration/num steps total     43800
exploration/num paths total       438
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.396616
exploration/Rewards Std             1.36094
exploration/Rewards Max            -0.00326044
exploration/Rewards Min           -10.7692
exploration/Returns Mean          -39.6616
exploration/Returns Std            26.3012
exploration/Returns Max           -13.3604
exploration/Returns Min           -65.9629
exploration/Actions Mean            0.0423612
exploration/Actions Std             0.241585
exploration/Actions Max             0.997418
exploration/Actions Min            -0.632023
exploration/Num Paths               2
exploration/Average Returns       -39.6616
evaluation/num steps total     218000
evaluation/num paths total       2180
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.150294
evaluation/Rewards Std              0.714454
evaluation/Rewards Max             -0.0211863
evaluation/Rewards Min             -9.33062
evaluation/Returns Mean           -15.0294
evaluation/Returns Std             12.6877
evaluation/Returns Max             -4.23641
evaluation/Returns Min            -45.7831
evaluation/Actions Mean             0.0199978
evaluation/Actions Std              0.166189
evaluation/Actions Max              0.996828
evaluation/Actions Min             -0.99336
evaluation/Num Paths               10
evaluation/Average Returns        -15.0294
time/data storing (s)               0.00112668
time/evaluation sampling (s)        0.263997
time/exploration sampling (s)       0.0609665
time/logging (s)                    0.00343492
time/saving (s)                     0.00234058
time/training (s)                   0.987353
time/epoch (s)                      1.31922
time/total (s)                    323.296
Epoch                             217
-----------------------------  ---------------
2019-04-21 12:21:49.563365 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 218 finished
-----------------------------  ---------------
replay_buffer/size              44000
trainer/QF1 Loss                    0.0158462
trainer/QF2 Loss                    0.0195071
trainer/Policy Loss                10.0136
trainer/Q1 Predictions Mean        -8.05708
trainer/Q1 Predictions Std          5.37634
trainer/Q1 Predictions Max         -6.74718
trainer/Q1 Predictions Min        -48.8884
trainer/Q2 Predictions Mean        -8.04719
trainer/Q2 Predictions Std          5.36334
trainer/Q2 Predictions Max         -6.71729
trainer/Q2 Predictions Min        -48.4806
trainer/Q Targets Mean             -8.05466
trainer/Q Targets Std               5.40661
trainer/Q Targets Max              -6.6508
trainer/Q Targets Min             -48.6171
trainer/Log Pis Mean                2.11753
trainer/Log Pis Std                 1.27392
trainer/Log Pis Max                 7.32187
trainer/Log Pis Min                -3.1063
trainer/Policy mu Mean              0.0473201
trainer/Policy mu Std               0.640863
trainer/Policy mu Max               3.05228
trainer/Policy mu Min              -3.54299
trainer/Policy log std Mean        -2.19146
trainer/Policy log std Std          0.430232
trainer/Policy log std Max         -0.42028
trainer/Policy log std Min         -2.45174
trainer/Alpha                       0.0532396
trainer/Alpha Loss                  0.344716
exploration/num steps total     44000
exploration/num paths total       440
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.295632
exploration/Rewards Std             0.872025
exploration/Rewards Max            -0.00310862
exploration/Rewards Min            -6.68421
exploration/Returns Mean          -29.5632
exploration/Returns Std             0.920338
exploration/Returns Max           -28.6428
exploration/Returns Min           -30.4835
exploration/Actions Mean            0.049491
exploration/Actions Std             0.236173
exploration/Actions Max             0.997238
exploration/Actions Min            -0.483135
exploration/Num Paths               2
exploration/Average Returns       -29.5632
evaluation/num steps total     219000
evaluation/num paths total       2190
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.193954
evaluation/Rewards Std              0.966776
evaluation/Rewards Max             -0.00981745
evaluation/Rewards Min             -9.87652
evaluation/Returns Mean           -19.3954
evaluation/Returns Std             15.8353
evaluation/Returns Max             -1.38496
evaluation/Returns Min            -47.7008
evaluation/Actions Mean             0.0259405
evaluation/Actions Std              0.183084
evaluation/Actions Max              0.997774
evaluation/Actions Min             -0.979056
evaluation/Num Paths               10
evaluation/Average Returns        -19.3954
time/data storing (s)               0.00120635
time/evaluation sampling (s)        0.257669
time/exploration sampling (s)       0.0716223
time/logging (s)                    0.00343199
time/saving (s)                     0.00195551
time/training (s)                   0.993253
time/epoch (s)                      1.32914
time/total (s)                    324.63
Epoch                             218
-----------------------------  ---------------
2019-04-21 12:21:50.960159 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 219 finished
-----------------------------  ---------------
replay_buffer/size              44200
trainer/QF1 Loss                    0.0423412
trainer/QF2 Loss                    0.0294941
trainer/Policy Loss                 9.57157
trainer/Q1 Predictions Mean        -7.84388
trainer/Q1 Predictions Std          5.69606
trainer/Q1 Predictions Max         -6.73012
trainer/Q1 Predictions Min        -58.2507
trainer/Q2 Predictions Mean        -7.80041
trainer/Q2 Predictions Std          5.69225
trainer/Q2 Predictions Max         -6.70118
trainer/Q2 Predictions Min        -58.3514
trainer/Q Targets Mean             -7.76653
trainer/Q Targets Std               5.53827
trainer/Q Targets Max              -6.61965
trainer/Q Targets Min             -57.0542
trainer/Log Pis Mean                1.93725
trainer/Log Pis Std                 1.22815
trainer/Log Pis Max                 5.80611
trainer/Log Pis Min                -2.47044
trainer/Policy mu Mean              0.0351792
trainer/Policy mu Std               0.523569
trainer/Policy mu Max               3.0812
trainer/Policy mu Min              -1.60479
trainer/Policy log std Mean        -2.22252
trainer/Policy log std Std          0.357255
trainer/Policy log std Max         -0.462373
trainer/Policy log std Min         -2.39175
trainer/Alpha                       0.0543777
trainer/Alpha Loss                 -0.18272
exploration/num steps total     44200
exploration/num paths total       442
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.194351
exploration/Rewards Std             0.531354
exploration/Rewards Max            -0.00686857
exploration/Rewards Min            -5.12223
exploration/Returns Mean          -19.4351
exploration/Returns Std             7.11406
exploration/Returns Max           -12.321
exploration/Returns Min           -26.5492
exploration/Actions Mean           -0.00106954
exploration/Actions Std             0.199097
exploration/Actions Max             0.980366
exploration/Actions Min            -0.998979
exploration/Num Paths               2
exploration/Average Returns       -19.4351
evaluation/num steps total     220000
evaluation/num paths total       2200
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.273925
evaluation/Rewards Std              1.20618
evaluation/Rewards Max             -0.0250962
evaluation/Rewards Min             -9.55298
evaluation/Returns Mean           -27.3925
evaluation/Returns Std             21.5985
evaluation/Returns Max             -2.92361
evaluation/Returns Min            -53.4186
evaluation/Actions Mean             0.028701
evaluation/Actions Std              0.182488
evaluation/Actions Max              0.996643
evaluation/Actions Min             -0.989801
evaluation/Num Paths               10
evaluation/Average Returns        -27.3925
time/data storing (s)               0.00117969
time/evaluation sampling (s)        0.265003
time/exploration sampling (s)       0.0652546
time/logging (s)                    0.00351356
time/saving (s)                     0.00235801
time/training (s)                   1.05133
time/epoch (s)                      1.38863
time/total (s)                    326.023
Epoch                             219
-----------------------------  ---------------
2019-04-21 12:21:52.260339 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 220 finished
-----------------------------  ---------------
replay_buffer/size              44400
trainer/QF1 Loss                    0.885454
trainer/QF2 Loss                    0.893962
trainer/Policy Loss                10.457
trainer/Q1 Predictions Mean        -8.28476
trainer/Q1 Predictions Std          5.67464
trainer/Q1 Predictions Max         -6.49342
trainer/Q1 Predictions Min        -51.3023
trainer/Q2 Predictions Mean        -8.31294
trainer/Q2 Predictions Std          5.67022
trainer/Q2 Predictions Max         -6.53083
trainer/Q2 Predictions Min        -51.4466
trainer/Q Targets Mean             -8.29082
trainer/Q Targets Std               5.75394
trainer/Q Targets Max              -0.255865
trainer/Q Targets Min             -51.3195
trainer/Log Pis Mean                2.31644
trainer/Log Pis Std                 1.22786
trainer/Log Pis Max                 6.46836
trainer/Log Pis Min                -1.37187
trainer/Policy mu Mean              0.0379142
trainer/Policy mu Std               0.802805
trainer/Policy mu Max               3.49608
trainer/Policy mu Min              -3.01051
trainer/Policy log std Mean        -2.14648
trainer/Policy log std Std          0.553531
trainer/Policy log std Max         -0.473392
trainer/Policy log std Min         -2.49609
trainer/Alpha                       0.0554314
trainer/Alpha Loss                  0.915373
exploration/num steps total     44400
exploration/num paths total       444
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.16693
exploration/Rewards Std             0.376202
exploration/Rewards Max            -0.0162087
exploration/Rewards Min            -3.72738
exploration/Returns Mean          -16.693
exploration/Returns Std             2.24422
exploration/Returns Max           -14.4488
exploration/Returns Min           -18.9372
exploration/Actions Mean            0.0251661
exploration/Actions Std             0.192197
exploration/Actions Max             0.995078
exploration/Actions Min            -0.409087
exploration/Num Paths               2
exploration/Average Returns       -16.693
evaluation/num steps total     221000
evaluation/num paths total       2210
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.243393
evaluation/Rewards Std              1.01562
evaluation/Rewards Max             -0.0250872
evaluation/Rewards Min             -8.73501
evaluation/Returns Mean           -24.3393
evaluation/Returns Std             13.0851
evaluation/Returns Max             -3.10554
evaluation/Returns Min            -45.3391
evaluation/Actions Mean             0.0284923
evaluation/Actions Std              0.197699
evaluation/Actions Max              0.997944
evaluation/Actions Min             -0.990028
evaluation/Num Paths               10
evaluation/Average Returns        -24.3393
time/data storing (s)               0.00115225
time/evaluation sampling (s)        0.244425
time/exploration sampling (s)       0.0614768
time/logging (s)                    0.00350953
time/saving (s)                     0.00230305
time/training (s)                   0.97923
time/epoch (s)                      1.2921
time/total (s)                    327.319
Epoch                             220
-----------------------------  ---------------
2019-04-21 12:21:53.657694 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 221 finished
-----------------------------  ---------------
replay_buffer/size              44600
trainer/QF1 Loss                    1.85921
trainer/QF2 Loss                    1.77174
trainer/Policy Loss                 9.89068
trainer/Q1 Predictions Mean        -8.01394
trainer/Q1 Predictions Std          6.04471
trainer/Q1 Predictions Max         -6.53694
trainer/Q1 Predictions Min        -52.918
trainer/Q2 Predictions Mean        -7.97807
trainer/Q2 Predictions Std          6.2
trainer/Q2 Predictions Max         -6.48451
trainer/Q2 Predictions Min        -54.7101
trainer/Q Targets Mean             -7.85422
trainer/Q Targets Std               6.30197
trainer/Q Targets Max              -0.115991
trainer/Q Targets Min             -55.4123
trainer/Log Pis Mean                2.10907
trainer/Log Pis Std                 1.26076
trainer/Log Pis Max                 7.30523
trainer/Log Pis Min                -1.20717
trainer/Policy mu Mean              0.0747434
trainer/Policy mu Std               0.652576
trainer/Policy mu Max               3.50583
trainer/Policy mu Min              -1.81842
trainer/Policy log std Mean        -2.23488
trainer/Policy log std Std          0.408276
trainer/Policy log std Max         -0.415864
trainer/Policy log std Min         -2.43061
trainer/Alpha                       0.055823
trainer/Alpha Loss                  0.314741
exploration/num steps total     44600
exploration/num paths total       446
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.4928
exploration/Rewards Std             1.45079
exploration/Rewards Max            -0.0153212
exploration/Rewards Min            -9.20595
exploration/Returns Mean          -49.28
exploration/Returns Std             8.72958
exploration/Returns Max           -40.5504
exploration/Returns Min           -58.0096
exploration/Actions Mean            0.0623468
exploration/Actions Std             0.26829
exploration/Actions Max             0.998859
exploration/Actions Min            -0.396615
exploration/Num Paths               2
exploration/Average Returns       -49.28
evaluation/num steps total     222000
evaluation/num paths total       2220
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.211594
evaluation/Rewards Std              0.833425
evaluation/Rewards Max             -0.0439127
evaluation/Rewards Min             -8.39931
evaluation/Returns Mean           -21.1594
evaluation/Returns Std             12.3531
evaluation/Returns Max             -6.64011
evaluation/Returns Min            -39.508
evaluation/Actions Mean             0.0209321
evaluation/Actions Std              0.180234
evaluation/Actions Max              0.996002
evaluation/Actions Min             -0.992532
evaluation/Num Paths               10
evaluation/Average Returns        -21.1594
time/data storing (s)               0.00157522
time/evaluation sampling (s)        0.269626
time/exploration sampling (s)       0.0770665
time/logging (s)                    0.00351643
time/saving (s)                     0.0028906
time/training (s)                   1.03487
time/epoch (s)                      1.38954
time/total (s)                    328.713
Epoch                             221
-----------------------------  ---------------
2019-04-21 12:21:55.173085 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 222 finished
-----------------------------  ---------------
replay_buffer/size              44800
trainer/QF1 Loss                    0.447076
trainer/QF2 Loss                    0.438059
trainer/Policy Loss                 8.74741
trainer/Q1 Predictions Mean        -6.86446
trainer/Q1 Predictions Std          1.7405
trainer/Q1 Predictions Max         -6.47371
trainer/Q1 Predictions Min        -23.6751
trainer/Q2 Predictions Mean        -6.97041
trainer/Q2 Predictions Std          1.71632
trainer/Q2 Predictions Max         -6.6058
trainer/Q2 Predictions Min        -23.5476
trainer/Q Targets Mean             -6.94005
trainer/Q Targets Std               1.83131
trainer/Q Targets Max              -0.113508
trainer/Q Targets Min             -23.4022
trainer/Log Pis Mean                1.8735
trainer/Log Pis Std                 1.05522
trainer/Log Pis Max                 3.06302
trainer/Log Pis Min                -2.41049
trainer/Policy mu Mean              0.0303541
trainer/Policy mu Std               0.436531
trainer/Policy mu Max               3.04121
trainer/Policy mu Min              -2.08287
trainer/Policy log std Mean        -2.24042
trainer/Policy log std Std          0.342098
trainer/Policy log std Max         -0.34683
trainer/Policy log std Min         -2.4092
trainer/Alpha                       0.055142
trainer/Alpha Loss                 -0.366573
exploration/num steps total     44800
exploration/num paths total       448
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.279261
exploration/Rewards Std             0.771246
exploration/Rewards Max            -0.00697311
exploration/Rewards Min            -5.482
exploration/Returns Mean          -27.9261
exploration/Returns Std             1.04763
exploration/Returns Max           -26.8785
exploration/Returns Min           -28.9738
exploration/Actions Mean            0.0433855
exploration/Actions Std             0.231623
exploration/Actions Max             0.996363
exploration/Actions Min            -0.346491
exploration/Num Paths               2
exploration/Average Returns       -27.9261
evaluation/num steps total     223000
evaluation/num paths total       2230
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.241719
evaluation/Rewards Std              1.13658
evaluation/Rewards Max             -0.0063167
evaluation/Rewards Min            -10.3274
evaluation/Returns Mean           -24.1719
evaluation/Returns Std             17.6183
evaluation/Returns Max             -3.42536
evaluation/Returns Min            -56.334
evaluation/Actions Mean             0.0226165
evaluation/Actions Std              0.203722
evaluation/Actions Max              0.996835
evaluation/Actions Min             -0.997672
evaluation/Num Paths               10
evaluation/Average Returns        -24.1719
time/data storing (s)               0.00169736
time/evaluation sampling (s)        0.269982
time/exploration sampling (s)       0.0644244
time/logging (s)                    0.00343494
time/saving (s)                     0.00269761
time/training (s)                   1.16595
time/epoch (s)                      1.50819
time/total (s)                    330.225
Epoch                             222
-----------------------------  ---------------
2019-04-21 12:21:56.646237 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 223 finished
-----------------------------  ---------------
replay_buffer/size              45000
trainer/QF1 Loss                    0.865347
trainer/QF2 Loss                    0.866768
trainer/Policy Loss                 9.13049
trainer/Q1 Predictions Mean        -7.35368
trainer/Q1 Predictions Std          2.63311
trainer/Q1 Predictions Max         -6.4922
trainer/Q1 Predictions Min        -24.6232
trainer/Q2 Predictions Mean        -7.40451
trainer/Q2 Predictions Std          2.61345
trainer/Q2 Predictions Max         -6.5445
trainer/Q2 Predictions Min        -24.3396
trainer/Q Targets Mean             -7.35496
trainer/Q Targets Std               2.84378
trainer/Q Targets Max              -0.121943
trainer/Q Targets Min             -24.9627
trainer/Log Pis Mean                1.90123
trainer/Log Pis Std                 1.43518
trainer/Log Pis Max                 6.58618
trainer/Log Pis Min                -4.06899
trainer/Policy mu Mean              0.0537908
trainer/Policy mu Std               0.62715
trainer/Policy mu Max               3.03685
trainer/Policy mu Min              -2.21845
trainer/Policy log std Mean        -2.17193
trainer/Policy log std Std          0.438954
trainer/Policy log std Max         -0.415962
trainer/Policy log std Min         -2.40869
trainer/Alpha                       0.0567946
trainer/Alpha Loss                 -0.283327
exploration/num steps total     45000
exploration/num paths total       450
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.529625
exploration/Rewards Std             1.52286
exploration/Rewards Max            -0.0134275
exploration/Rewards Min            -9.23414
exploration/Returns Mean          -52.9625
exploration/Returns Std             2.01882
exploration/Returns Max           -50.9437
exploration/Returns Min           -54.9813
exploration/Actions Mean            0.0330275
exploration/Actions Std             0.270787
exploration/Actions Max             0.998855
exploration/Actions Min            -0.991646
exploration/Num Paths               2
exploration/Average Returns       -52.9625
evaluation/num steps total     224000
evaluation/num paths total       2240
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.263954
evaluation/Rewards Std              1.10124
evaluation/Rewards Max             -0.0444536
evaluation/Rewards Min            -11.113
evaluation/Returns Mean           -26.3954
evaluation/Returns Std             18.9822
evaluation/Returns Max             -4.51205
evaluation/Returns Min            -64.1532
evaluation/Actions Mean             0.0232604
evaluation/Actions Std              0.194193
evaluation/Actions Max              0.997773
evaluation/Actions Min             -0.997749
evaluation/Num Paths               10
evaluation/Average Returns        -26.3954
time/data storing (s)               0.0014566
time/evaluation sampling (s)        0.302283
time/exploration sampling (s)       0.109581
time/logging (s)                    0.00338293
time/saving (s)                     0.00184527
time/training (s)                   1.04669
time/epoch (s)                      1.46524
time/total (s)                    331.695
Epoch                             223
-----------------------------  ---------------
2019-04-21 12:21:58.037300 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 224 finished
-----------------------------  ---------------
replay_buffer/size              45200
trainer/QF1 Loss                    0.881232
trainer/QF2 Loss                    0.89814
trainer/Policy Loss                 9.23704
trainer/Q1 Predictions Mean        -7.50985
trainer/Q1 Predictions Std          3.3803
trainer/Q1 Predictions Max         -6.64691
trainer/Q1 Predictions Min        -31.5194
trainer/Q2 Predictions Mean        -7.52689
trainer/Q2 Predictions Std          3.36578
trainer/Q2 Predictions Max         -6.67506
trainer/Q2 Predictions Min        -31.883
trainer/Q Targets Mean             -7.38026
trainer/Q Targets Std               3.5673
trainer/Q Targets Max              -0.17174
trainer/Q Targets Min             -31.9081
trainer/Log Pis Mean                1.92414
trainer/Log Pis Std                 1.02016
trainer/Log Pis Max                 4.7562
trainer/Log Pis Min                -1.23419
trainer/Policy mu Mean              0.101386
trainer/Policy mu Std               0.503929
trainer/Policy mu Max               2.99044
trainer/Policy mu Min              -2.20309
trainer/Policy log std Mean        -2.22831
trainer/Policy log std Std          0.369217
trainer/Policy log std Max         -0.655461
trainer/Policy log std Min         -2.41533
trainer/Alpha                       0.0553366
trainer/Alpha Loss                 -0.219551
exploration/num steps total     45200
exploration/num paths total       452
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.232083
exploration/Rewards Std             0.585137
exploration/Rewards Max            -0.011267
exploration/Rewards Min            -5.86168
exploration/Returns Mean          -23.2083
exploration/Returns Std             6.80091
exploration/Returns Max           -16.4074
exploration/Returns Min           -30.0092
exploration/Actions Mean            0.0353664
exploration/Actions Std             0.218598
exploration/Actions Max             0.996267
exploration/Actions Min            -0.382206
exploration/Num Paths               2
exploration/Average Returns       -23.2083
evaluation/num steps total     225000
evaluation/num paths total       2250
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.315828
evaluation/Rewards Std              1.16804
evaluation/Rewards Max             -0.0107224
evaluation/Rewards Min            -10.907
evaluation/Returns Mean           -31.5828
evaluation/Returns Std             16.453
evaluation/Returns Max             -9.92252
evaluation/Returns Min            -61.2934
evaluation/Actions Mean             0.0219231
evaluation/Actions Std              0.21336
evaluation/Actions Max              0.998462
evaluation/Actions Min             -0.992007
evaluation/Num Paths               10
evaluation/Average Returns        -31.5828
time/data storing (s)               0.00116738
time/evaluation sampling (s)        0.269044
time/exploration sampling (s)       0.0662314
time/logging (s)                    0.00374251
time/saving (s)                     0.00302878
time/training (s)                   1.04054
time/epoch (s)                      1.38375
time/total (s)                    333.083
Epoch                             224
-----------------------------  ---------------
2019-04-21 12:21:59.747129 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 225 finished
-----------------------------  ---------------
replay_buffer/size              45400
trainer/QF1 Loss                    0.453755
trainer/QF2 Loss                    0.466671
trainer/Policy Loss                 9.97714
trainer/Q1 Predictions Mean        -8.04648
trainer/Q1 Predictions Std          6.56177
trainer/Q1 Predictions Max         -6.51097
trainer/Q1 Predictions Min        -57.7684
trainer/Q2 Predictions Mean        -8.02779
trainer/Q2 Predictions Std          6.56299
trainer/Q2 Predictions Max         -6.50974
trainer/Q2 Predictions Min        -57.6268
trainer/Q Targets Mean             -8.1216
trainer/Q Targets Std               6.66854
trainer/Q Targets Max              -0.307097
trainer/Q Targets Min             -58.9809
trainer/Log Pis Mean                2.03865
trainer/Log Pis Std                 1.25245
trainer/Log Pis Max                 7.50616
trainer/Log Pis Min                -0.332156
trainer/Policy mu Mean              0.0809532
trainer/Policy mu Std               0.676168
trainer/Policy mu Max               3.24666
trainer/Policy mu Min              -2.81609
trainer/Policy log std Mean        -2.1043
trainer/Policy log std Std          0.418224
trainer/Policy log std Max         -0.475574
trainer/Policy log std Min         -2.34581
trainer/Alpha                       0.054109
trainer/Alpha Loss                  0.112722
exploration/num steps total     45400
exploration/num paths total       454
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.221051
exploration/Rewards Std             0.45502
exploration/Rewards Max            -0.0144167
exploration/Rewards Min            -4.25568
exploration/Returns Mean          -22.1051
exploration/Returns Std             3.35023
exploration/Returns Max           -18.7549
exploration/Returns Min           -25.4553
exploration/Actions Mean           -0.00408858
exploration/Actions Std             0.210643
exploration/Actions Max             0.98713
exploration/Actions Min            -0.997179
exploration/Num Paths               2
exploration/Average Returns       -22.1051
evaluation/num steps total     226000
evaluation/num paths total       2260
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.213476
evaluation/Rewards Std              0.899343
evaluation/Rewards Max             -0.0354807
evaluation/Rewards Min             -9.81123
evaluation/Returns Mean           -21.3476
evaluation/Returns Std             15.649
evaluation/Returns Max             -5.19353
evaluation/Returns Min            -51.2307
evaluation/Actions Mean             0.0190991
evaluation/Actions Std              0.179634
evaluation/Actions Max              0.996108
evaluation/Actions Min             -0.997412
evaluation/Num Paths               10
evaluation/Average Returns        -21.3476
time/data storing (s)               0.00120148
time/evaluation sampling (s)        0.257023
time/exploration sampling (s)       0.0685156
time/logging (s)                    0.00441113
time/saving (s)                     0.00305798
time/training (s)                   1.36833
time/epoch (s)                      1.70254
time/total (s)                    334.79
Epoch                             225
-----------------------------  ---------------
2019-04-21 12:22:01.620468 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 226 finished
-----------------------------  ---------------
replay_buffer/size              45600
trainer/QF1 Loss                    0.472833
trainer/QF2 Loss                    0.476529
trainer/Policy Loss                 9.40101
trainer/Q1 Predictions Mean        -7.58989
trainer/Q1 Predictions Std          3.84042
trainer/Q1 Predictions Max         -6.64547
trainer/Q1 Predictions Min        -37.8186
trainer/Q2 Predictions Mean        -7.61009
trainer/Q2 Predictions Std          3.83422
trainer/Q2 Predictions Max         -6.6795
trainer/Q2 Predictions Min        -37.7562
trainer/Q Targets Mean             -7.47827
trainer/Q Targets Std               3.80928
trainer/Q Targets Max              -0.127392
trainer/Q Targets Min             -36.3107
trainer/Log Pis Mean                1.92874
trainer/Log Pis Std                 1.29219
trainer/Log Pis Max                 8.32424
trainer/Log Pis Min                -3.85327
trainer/Policy mu Mean              0.0719941
trainer/Policy mu Std               0.575315
trainer/Policy mu Max               3.48209
trainer/Policy mu Min              -2.22179
trainer/Policy log std Mean        -2.13629
trainer/Policy log std Std          0.388946
trainer/Policy log std Max         -0.645224
trainer/Policy log std Min         -2.33274
trainer/Alpha                       0.0544942
trainer/Alpha Loss                 -0.207317
exploration/num steps total     45600
exploration/num paths total       456
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.402832
exploration/Rewards Std             1.22828
exploration/Rewards Max            -0.00808358
exploration/Rewards Min            -9.55592
exploration/Returns Mean          -40.2832
exploration/Returns Std            16.4584
exploration/Returns Max           -23.8247
exploration/Returns Min           -56.7416
exploration/Actions Mean            0.0574594
exploration/Actions Std             0.262036
exploration/Actions Max             0.998019
exploration/Actions Min            -0.378758
exploration/Num Paths               2
exploration/Average Returns       -40.2832
evaluation/num steps total     227000
evaluation/num paths total       2270
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.213816
evaluation/Rewards Std              0.938361
evaluation/Rewards Max             -0.0299591
evaluation/Rewards Min             -9.71557
evaluation/Returns Mean           -21.3816
evaluation/Returns Std             13.7609
evaluation/Returns Max             -7.37332
evaluation/Returns Min            -55.31
evaluation/Actions Mean             0.0179523
evaluation/Actions Std              0.193553
evaluation/Actions Max              0.996848
evaluation/Actions Min             -0.995462
evaluation/Num Paths               10
evaluation/Average Returns        -21.3816
time/data storing (s)               0.00192196
time/evaluation sampling (s)        0.431942
time/exploration sampling (s)       0.128007
time/logging (s)                    0.00330054
time/saving (s)                     0.00236586
time/training (s)                   1.29499
time/epoch (s)                      1.86253
time/total (s)                    336.657
Epoch                             226
-----------------------------  ---------------
2019-04-21 12:22:03.013763 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 227 finished
-----------------------------  ---------------
replay_buffer/size              45800
trainer/QF1 Loss                    0.0277691
trainer/QF2 Loss                    0.0185484
trainer/Policy Loss                10.4101
trainer/Q1 Predictions Mean        -8.50388
trainer/Q1 Predictions Std          6.99052
trainer/Q1 Predictions Max         -6.58647
trainer/Q1 Predictions Min        -56.6838
trainer/Q2 Predictions Mean        -8.49024
trainer/Q2 Predictions Std          7.00472
trainer/Q2 Predictions Max         -6.56625
trainer/Q2 Predictions Min        -56.905
trainer/Q Targets Mean             -8.55041
trainer/Q Targets Std               7.0622
trainer/Q Targets Max              -6.50432
trainer/Q Targets Min             -57.3668
trainer/Log Pis Mean                2.10644
trainer/Log Pis Std                 1.08659
trainer/Log Pis Max                 8.14605
trainer/Log Pis Min                -0.70434
trainer/Policy mu Mean              0.178379
trainer/Policy mu Std               0.718321
trainer/Policy mu Max               3.34171
trainer/Policy mu Min              -2.85638
trainer/Policy log std Mean        -2.10925
trainer/Policy log std Std          0.517551
trainer/Policy log std Max         -0.451366
trainer/Policy log std Min         -2.44339
trainer/Alpha                       0.0543089
trainer/Alpha Loss                  0.310056
exploration/num steps total     45800
exploration/num paths total       458
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.38566
exploration/Rewards Std             1.18722
exploration/Rewards Max            -0.00783991
exploration/Rewards Min            -9.2455
exploration/Returns Mean          -38.566
exploration/Returns Std            12.6692
exploration/Returns Max           -25.8968
exploration/Returns Min           -51.2352
exploration/Actions Mean            0.0046936
exploration/Actions Std             0.264495
exploration/Actions Max             0.995192
exploration/Actions Min            -0.998843
exploration/Num Paths               2
exploration/Average Returns       -38.566
evaluation/num steps total     228000
evaluation/num paths total       2280
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.236895
evaluation/Rewards Std              1.04472
evaluation/Rewards Max             -0.0282708
evaluation/Rewards Min             -9.98495
evaluation/Returns Mean           -23.6895
evaluation/Returns Std             17.2103
evaluation/Returns Max             -5.26191
evaluation/Returns Min            -57.7673
evaluation/Actions Mean             0.0321432
evaluation/Actions Std              0.201667
evaluation/Actions Max              0.996895
evaluation/Actions Min             -0.989736
evaluation/Num Paths               10
evaluation/Average Returns        -23.6895
time/data storing (s)               0.0011501
time/evaluation sampling (s)        0.294647
time/exploration sampling (s)       0.0678708
time/logging (s)                    0.00370283
time/saving (s)                     0.00310869
time/training (s)                   1.01525
time/epoch (s)                      1.38573
time/total (s)                    338.047
Epoch                             227
-----------------------------  ---------------
2019-04-21 12:22:04.373225 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 228 finished
-----------------------------  ---------------
replay_buffer/size              46000
trainer/QF1 Loss                    0.0215648
trainer/QF2 Loss                    0.0138048
trainer/Policy Loss                10.2905
trainer/Q1 Predictions Mean        -8.4048
trainer/Q1 Predictions Std          7.06435
trainer/Q1 Predictions Max         -6.65621
trainer/Q1 Predictions Min        -59.3467
trainer/Q2 Predictions Mean        -8.35758
trainer/Q2 Predictions Std          7.08694
trainer/Q2 Predictions Max         -6.61104
trainer/Q2 Predictions Min        -59.3648
trainer/Q Targets Mean             -8.34074
trainer/Q Targets Std               7.11464
trainer/Q Targets Max              -6.52692
trainer/Q Targets Min             -60.1268
trainer/Log Pis Mean                2.10464
trainer/Log Pis Std                 1.39529
trainer/Log Pis Max                 7.3726
trainer/Log Pis Min                -4.41174
trainer/Policy mu Mean              0.00138448
trainer/Policy mu Std               0.697535
trainer/Policy mu Max               3.08301
trainer/Policy mu Min              -2.63337
trainer/Policy log std Mean        -2.11819
trainer/Policy log std Std          0.47135
trainer/Policy log std Max         -0.644659
trainer/Policy log std Min         -2.43246
trainer/Alpha                       0.0548557
trainer/Alpha Loss                  0.303778
exploration/num steps total     46000
exploration/num paths total       460
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.332194
exploration/Rewards Std             0.97002
exploration/Rewards Max            -0.00208725
exploration/Rewards Min            -6.93582
exploration/Returns Mean          -33.2194
exploration/Returns Std             1.72211
exploration/Returns Max           -31.4973
exploration/Returns Min           -34.9415
exploration/Actions Mean            0.0350239
exploration/Actions Std             0.260705
exploration/Actions Max             0.997468
exploration/Actions Min            -0.998337
exploration/Num Paths               2
exploration/Average Returns       -33.2194
evaluation/num steps total     229000
evaluation/num paths total       2290
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.224257
evaluation/Rewards Std              0.957704
evaluation/Rewards Max             -0.0201102
evaluation/Rewards Min            -10.3637
evaluation/Returns Mean           -22.4257
evaluation/Returns Std             15.0675
evaluation/Returns Max             -5.91302
evaluation/Returns Min            -55.5079
evaluation/Actions Mean             0.0256734
evaluation/Actions Std              0.193
evaluation/Actions Max              0.997073
evaluation/Actions Min             -0.996123
evaluation/Num Paths               10
evaluation/Average Returns        -22.4257
time/data storing (s)               0.00115199
time/evaluation sampling (s)        0.261749
time/exploration sampling (s)       0.0653076
time/logging (s)                    0.00303667
time/saving (s)                     0.00233804
time/training (s)                   1.0171
time/epoch (s)                      1.35068
time/total (s)                    339.402
Epoch                             228
-----------------------------  ---------------
2019-04-21 12:22:05.709918 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 229 finished
-----------------------------  ---------------
replay_buffer/size              46200
trainer/QF1 Loss                    0.446811
trainer/QF2 Loss                    0.448146
trainer/Policy Loss                 9.08724
trainer/Q1 Predictions Mean        -7.2706
trainer/Q1 Predictions Std          2.83912
trainer/Q1 Predictions Max         -6.50506
trainer/Q1 Predictions Min        -26.111
trainer/Q2 Predictions Mean        -7.29176
trainer/Q2 Predictions Std          2.80515
trainer/Q2 Predictions Max         -6.52611
trainer/Q2 Predictions Min        -25.7948
trainer/Q Targets Mean             -7.31063
trainer/Q Targets Std               2.865
trainer/Q Targets Max              -0.518954
trainer/Q Targets Min             -25.8128
trainer/Log Pis Mean                2.00379
trainer/Log Pis Std                 1.02552
trainer/Log Pis Max                 6.40346
trainer/Log Pis Min                -0.78
trainer/Policy mu Mean              0.0165822
trainer/Policy mu Std               0.556093
trainer/Policy mu Max               2.98435
trainer/Policy mu Min              -2.7089
trainer/Policy log std Mean        -2.12705
trainer/Policy log std Std          0.380084
trainer/Policy log std Max         -0.461741
trainer/Policy log std Min         -2.34213
trainer/Alpha                       0.0548988
trainer/Alpha Loss                  0.0109837
exploration/num steps total     46200
exploration/num paths total       462
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.219788
exploration/Rewards Std             0.557599
exploration/Rewards Max            -0.0196011
exploration/Rewards Min            -5.38783
exploration/Returns Mean          -21.9788
exploration/Returns Std             7.61703
exploration/Returns Max           -14.3617
exploration/Returns Min           -29.5958
exploration/Actions Mean            0.00971052
exploration/Actions Std             0.212503
exploration/Actions Max             0.996329
exploration/Actions Min            -0.983154
exploration/Num Paths               2
exploration/Average Returns       -21.9788
evaluation/num steps total     230000
evaluation/num paths total       2300
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.291543
evaluation/Rewards Std              1.18017
evaluation/Rewards Max             -0.00895388
evaluation/Rewards Min            -10.8692
evaluation/Returns Mean           -29.1543
evaluation/Returns Std             15.0158
evaluation/Returns Max             -5.84654
evaluation/Returns Min            -58.5552
evaluation/Actions Mean             0.0296454
evaluation/Actions Std              0.210902
evaluation/Actions Max              0.998332
evaluation/Actions Min             -0.99743
evaluation/Num Paths               10
evaluation/Average Returns        -29.1543
time/data storing (s)               0.0012097
time/evaluation sampling (s)        0.249982
time/exploration sampling (s)       0.069701
time/logging (s)                    0.00385343
time/saving (s)                     0.00216224
time/training (s)                   1.00278
time/epoch (s)                      1.32969
time/total (s)                    340.736
Epoch                             229
-----------------------------  ---------------
2019-04-21 12:22:07.091869 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 230 finished
-----------------------------  ---------------
replay_buffer/size              46400
trainer/QF1 Loss                    1.28334
trainer/QF2 Loss                    1.2925
trainer/Policy Loss                 9.09411
trainer/Q1 Predictions Mean        -7.16691
trainer/Q1 Predictions Std          2.16731
trainer/Q1 Predictions Max         -6.53616
trainer/Q1 Predictions Min        -18.8605
trainer/Q2 Predictions Mean        -7.19796
trainer/Q2 Predictions Std          2.14301
trainer/Q2 Predictions Max         -6.58592
trainer/Q2 Predictions Min        -18.8492
trainer/Q Targets Mean             -7.01457
trainer/Q Targets Std               2.40422
trainer/Q Targets Max              -0.0755429
trainer/Q Targets Min             -18.0702
trainer/Log Pis Mean                1.97925
trainer/Log Pis Std                 0.944724
trainer/Log Pis Max                 5.65679
trainer/Log Pis Min                -0.717238
trainer/Policy mu Mean              0.0221897
trainer/Policy mu Std               0.513722
trainer/Policy mu Max               2.78521
trainer/Policy mu Min              -2.96783
trainer/Policy log std Mean        -2.19291
trainer/Policy log std Std          0.383972
trainer/Policy log std Max         -0.464163
trainer/Policy log std Min         -2.36909
trainer/Alpha                       0.054723
trainer/Alpha Loss                 -0.0602965
exploration/num steps total     46400
exploration/num paths total       464
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.458497
exploration/Rewards Std             1.42176
exploration/Rewards Max            -0.00567638
exploration/Rewards Min           -10.3124
exploration/Returns Mean          -45.8497
exploration/Returns Std            24.65
exploration/Returns Max           -21.1996
exploration/Returns Min           -70.4997
exploration/Actions Mean            0.0217765
exploration/Actions Std             0.246401
exploration/Actions Max             0.996573
exploration/Actions Min            -0.996263
exploration/Num Paths               2
exploration/Average Returns       -45.8497
evaluation/num steps total     231000
evaluation/num paths total       2310
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.193809
evaluation/Rewards Std              0.912031
evaluation/Rewards Max             -0.0113583
evaluation/Rewards Min             -8.6366
evaluation/Returns Mean           -19.3809
evaluation/Returns Std             12.1009
evaluation/Returns Max             -1.60791
evaluation/Returns Min            -42.8275
evaluation/Actions Mean             0.0226356
evaluation/Actions Std              0.192154
evaluation/Actions Max              0.995898
evaluation/Actions Min             -0.995
evaluation/Num Paths               10
evaluation/Average Returns        -19.3809
time/data storing (s)               0.00114582
time/evaluation sampling (s)        0.26396
time/exploration sampling (s)       0.0681612
time/logging (s)                    0.00343869
time/saving (s)                     0.00232153
time/training (s)                   1.03449
time/epoch (s)                      1.37352
time/total (s)                    342.114
Epoch                             230
-----------------------------  ---------------
2019-04-21 12:22:08.515017 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 231 finished
-----------------------------  ----------------
replay_buffer/size              46600
trainer/QF1 Loss                    0.459574
trainer/QF2 Loss                    0.443975
trainer/Policy Loss                 9.61127
trainer/Q1 Predictions Mean        -7.58417
trainer/Q1 Predictions Std          4.47876
trainer/Q1 Predictions Max         -6.53864
trainer/Q1 Predictions Min        -48.5853
trainer/Q2 Predictions Mean        -7.66382
trainer/Q2 Predictions Std          4.58511
trainer/Q2 Predictions Max         -6.60802
trainer/Q2 Predictions Min        -49.8356
trainer/Q Targets Mean             -7.58266
trainer/Q Targets Std               4.67261
trainer/Q Targets Max              -0.0561629
trainer/Q Targets Min             -50.0625
trainer/Log Pis Mean                2.03314
trainer/Log Pis Std                 1.33854
trainer/Log Pis Max                 7.60167
trainer/Log Pis Min                -3.08979
trainer/Policy mu Mean              0.11468
trainer/Policy mu Std               0.656717
trainer/Policy mu Max               3.24715
trainer/Policy mu Min              -1.97433
trainer/Policy log std Mean        -2.1151
trainer/Policy log std Std          0.449581
trainer/Policy log std Max         -0.601999
trainer/Policy log std Min         -2.37704
trainer/Alpha                       0.0543915
trainer/Alpha Loss                  0.0964963
exploration/num steps total     46600
exploration/num paths total       466
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.192831
exploration/Rewards Std             0.478931
exploration/Rewards Max            -0.00887126
exploration/Rewards Min            -5.09632
exploration/Returns Mean          -19.2831
exploration/Returns Std             6.26864
exploration/Returns Max           -13.0145
exploration/Returns Min           -25.5518
exploration/Actions Mean            0.000522199
exploration/Actions Std             0.19972
exploration/Actions Max             0.993212
exploration/Actions Min            -0.997321
exploration/Num Paths               2
exploration/Average Returns       -19.2831
evaluation/num steps total     232000
evaluation/num paths total       2320
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.16637
evaluation/Rewards Std              0.840444
evaluation/Rewards Max             -0.0114717
evaluation/Rewards Min             -8.67183
evaluation/Returns Mean           -16.637
evaluation/Returns Std             12.5557
evaluation/Returns Max             -1.61559
evaluation/Returns Min            -43.3866
evaluation/Actions Mean             0.0271137
evaluation/Actions Std              0.182132
evaluation/Actions Max              0.997917
evaluation/Actions Min             -0.9733
evaluation/Num Paths               10
evaluation/Average Returns        -16.637
time/data storing (s)               0.00121995
time/evaluation sampling (s)        0.243041
time/exploration sampling (s)       0.069323
time/logging (s)                    0.00374242
time/saving (s)                     0.00240869
time/training (s)                   1.096
time/epoch (s)                      1.41574
time/total (s)                    343.534
Epoch                             231
-----------------------------  ----------------
2019-04-21 12:22:09.950652 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 232 finished
-----------------------------  ---------------
replay_buffer/size              46800
trainer/QF1 Loss                    0.459269
trainer/QF2 Loss                    0.42383
trainer/Policy Loss                 9.37492
trainer/Q1 Predictions Mean        -7.52888
trainer/Q1 Predictions Std          4.84722
trainer/Q1 Predictions Max         -6.56682
trainer/Q1 Predictions Min        -50.4188
trainer/Q2 Predictions Mean        -7.50903
trainer/Q2 Predictions Std          4.93206
trainer/Q2 Predictions Max         -6.53576
trainer/Q2 Predictions Min        -51.3839
trainer/Q Targets Mean             -7.51029
trainer/Q Targets Std               5.0239
trainer/Q Targets Max              -0.560083
trainer/Q Targets Min             -51.9257
trainer/Log Pis Mean                1.99287
trainer/Log Pis Std                 1.15032
trainer/Log Pis Max                 8.35837
trainer/Log Pis Min                -1.45574
trainer/Policy mu Mean             -0.0478953
trainer/Policy mu Std               0.527782
trainer/Policy mu Max               3.29471
trainer/Policy mu Min              -2.90452
trainer/Policy log std Mean        -2.17267
trainer/Policy log std Std          0.380423
trainer/Policy log std Max         -0.482964
trainer/Policy log std Min         -2.34926
trainer/Alpha                       0.0540335
trainer/Alpha Loss                 -0.0208042
exploration/num steps total     46800
exploration/num paths total       468
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.377465
exploration/Rewards Std             1.26033
exploration/Rewards Max            -0.00849668
exploration/Rewards Min            -9.52853
exploration/Returns Mean          -37.7465
exploration/Returns Std            23.2692
exploration/Returns Max           -14.4773
exploration/Returns Min           -61.0157
exploration/Actions Mean            0.0355266
exploration/Actions Std             0.231248
exploration/Actions Max             0.998517
exploration/Actions Min            -0.719423
exploration/Num Paths               2
exploration/Average Returns       -37.7465
evaluation/num steps total     233000
evaluation/num paths total       2330
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.132487
evaluation/Rewards Std              0.685208
evaluation/Rewards Max             -0.0115584
evaluation/Rewards Min             -7.01542
evaluation/Returns Mean           -13.2487
evaluation/Returns Std              9.21625
evaluation/Returns Max             -1.57972
evaluation/Returns Min            -27.3846
evaluation/Actions Mean             0.0142699
evaluation/Actions Std              0.170014
evaluation/Actions Max              0.995168
evaluation/Actions Min             -0.994785
evaluation/Num Paths               10
evaluation/Average Returns        -13.2487
time/data storing (s)               0.00112528
time/evaluation sampling (s)        0.2541
time/exploration sampling (s)       0.0610678
time/logging (s)                    0.00371357
time/saving (s)                     0.00272279
time/training (s)                   1.10498
time/epoch (s)                      1.42771
time/total (s)                    344.966
Epoch                             232
-----------------------------  ---------------
2019-04-21 12:22:11.318821 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 233 finished
-----------------------------  ---------------
replay_buffer/size              47000
trainer/QF1 Loss                    0.0446922
trainer/QF2 Loss                    0.0157494
trainer/Policy Loss                10.2528
trainer/Q1 Predictions Mean        -8.06913
trainer/Q1 Predictions Std          7.15364
trainer/Q1 Predictions Max         -6.36742
trainer/Q1 Predictions Min        -64.4986
trainer/Q2 Predictions Mean        -8.15092
trainer/Q2 Predictions Std          7.21201
trainer/Q2 Predictions Max         -6.47435
trainer/Q2 Predictions Min        -65.3701
trainer/Q Targets Mean             -8.24456
trainer/Q Targets Std               7.21879
trainer/Q Targets Max              -6.49036
trainer/Q Targets Min             -65.5803
trainer/Log Pis Mean                2.26948
trainer/Log Pis Std                 1.29684
trainer/Log Pis Max                 7.02462
trainer/Log Pis Min                -2.36868
trainer/Policy mu Mean              0.0501445
trainer/Policy mu Std               0.631027
trainer/Policy mu Max               3.25514
trainer/Policy mu Min              -3.6351
trainer/Policy log std Mean        -2.27767
trainer/Policy log std Std          0.418292
trainer/Policy log std Max         -0.454448
trainer/Policy log std Min         -2.49104
trainer/Alpha                       0.0552904
trainer/Alpha Loss                  0.780249
exploration/num steps total     47000
exploration/num paths total       470
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.19857
exploration/Rewards Std             0.487804
exploration/Rewards Max            -0.00280698
exploration/Rewards Min            -4.27322
exploration/Returns Mean          -19.857
exploration/Returns Std             1.57118
exploration/Returns Max           -18.2858
exploration/Returns Min           -21.4282
exploration/Actions Mean            0.0227144
exploration/Actions Std             0.215362
exploration/Actions Max             0.993448
exploration/Actions Min            -0.979224
exploration/Num Paths               2
exploration/Average Returns       -19.857
evaluation/num steps total     234000
evaluation/num paths total       2340
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.204241
evaluation/Rewards Std              0.832542
evaluation/Rewards Max             -0.0121722
evaluation/Rewards Min             -9.6282
evaluation/Returns Mean           -20.4241
evaluation/Returns Std             12.2686
evaluation/Returns Max             -7.2012
evaluation/Returns Min            -46.7874
evaluation/Actions Mean             0.0201559
evaluation/Actions Std              0.183507
evaluation/Actions Max              0.997212
evaluation/Actions Min             -0.997642
evaluation/Num Paths               10
evaluation/Average Returns        -20.4241
time/data storing (s)               0.00110915
time/evaluation sampling (s)        0.261674
time/exploration sampling (s)       0.0632753
time/logging (s)                    0.00346965
time/saving (s)                     0.00234073
time/training (s)                   1.02736
time/epoch (s)                      1.35923
time/total (s)                    346.329
Epoch                             233
-----------------------------  ---------------
2019-04-21 12:22:12.635955 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 234 finished
-----------------------------  ----------------
replay_buffer/size              47200
trainer/QF1 Loss                    0.455829
trainer/QF2 Loss                    0.471512
trainer/Policy Loss                 9.89017
trainer/Q1 Predictions Mean        -7.70423
trainer/Q1 Predictions Std          4.16075
trainer/Q1 Predictions Max         -6.51782
trainer/Q1 Predictions Min        -30.5206
trainer/Q2 Predictions Mean        -7.70238
trainer/Q2 Predictions Std          4.18734
trainer/Q2 Predictions Max         -6.52131
trainer/Q2 Predictions Min        -30.5286
trainer/Q Targets Mean             -7.65869
trainer/Q Targets Std               4.15709
trainer/Q Targets Max              -0.0396466
trainer/Q Targets Min             -30.2458
trainer/Log Pis Mean                2.29477
trainer/Log Pis Std                 1.07347
trainer/Log Pis Max                 6.929
trainer/Log Pis Min                -2.36181
trainer/Policy mu Mean              0.100475
trainer/Policy mu Std               0.628226
trainer/Policy mu Max               3.03828
trainer/Policy mu Min              -2.09417
trainer/Policy log std Mean        -2.17898
trainer/Policy log std Std          0.435214
trainer/Policy log std Max         -0.342881
trainer/Policy log std Min         -2.4257
trainer/Alpha                       0.0557081
trainer/Alpha Loss                  0.851205
exploration/num steps total     47200
exploration/num paths total       472
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.335877
exploration/Rewards Std             1.00108
exploration/Rewards Max            -0.00856494
exploration/Rewards Min            -7.61489
exploration/Returns Mean          -33.5877
exploration/Returns Std            10.061
exploration/Returns Max           -23.5267
exploration/Returns Min           -43.6487
exploration/Actions Mean            0.0139715
exploration/Actions Std             0.231238
exploration/Actions Max             0.998901
exploration/Actions Min            -0.99621
exploration/Num Paths               2
exploration/Average Returns       -33.5877
evaluation/num steps total     235000
evaluation/num paths total       2350
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.192583
evaluation/Rewards Std              0.926155
evaluation/Rewards Max             -0.000565738
evaluation/Rewards Min             -9.26933
evaluation/Returns Mean           -19.2583
evaluation/Returns Std             13.6526
evaluation/Returns Max             -2.26438
evaluation/Returns Min            -49.2219
evaluation/Actions Mean             0.0317998
evaluation/Actions Std              0.185317
evaluation/Actions Max              0.996251
evaluation/Actions Min             -0.994763
evaluation/Num Paths               10
evaluation/Average Returns        -19.2583
time/data storing (s)               0.00106854
time/evaluation sampling (s)        0.246908
time/exploration sampling (s)       0.0587206
time/logging (s)                    0.00354094
time/saving (s)                     0.00235503
time/training (s)                   0.99742
time/epoch (s)                      1.31001
time/total (s)                    347.643
Epoch                             234
-----------------------------  ----------------
2019-04-21 12:22:13.973622 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 235 finished
-----------------------------  ---------------
replay_buffer/size              47400
trainer/QF1 Loss                    0.858021
trainer/QF2 Loss                    0.86505
trainer/Policy Loss                 9.57929
trainer/Q1 Predictions Mean        -7.77854
trainer/Q1 Predictions Std          5.1668
trainer/Q1 Predictions Max         -6.38693
trainer/Q1 Predictions Min        -42.5389
trainer/Q2 Predictions Mean        -7.80071
trainer/Q2 Predictions Std          5.19004
trainer/Q2 Predictions Max         -6.41904
trainer/Q2 Predictions Min        -42.86
trainer/Q Targets Mean             -7.85098
trainer/Q Targets Std               5.3444
trainer/Q Targets Max              -0.081052
trainer/Q Targets Min             -42.7945
trainer/Log Pis Mean                2.01056
trainer/Log Pis Std                 1.08901
trainer/Log Pis Max                 6.38172
trainer/Log Pis Min                -0.480163
trainer/Policy mu Mean              0.0676649
trainer/Policy mu Std               0.674077
trainer/Policy mu Max               3.63057
trainer/Policy mu Min              -2.64921
trainer/Policy log std Mean        -2.11429
trainer/Policy log std Std          0.435736
trainer/Policy log std Max         -0.549246
trainer/Policy log std Min         -2.3847
trainer/Alpha                       0.053923
trainer/Alpha Loss                  0.0308329
exploration/num steps total     47400
exploration/num paths total       474
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.505919
exploration/Rewards Std             1.51308
exploration/Rewards Max            -0.0111007
exploration/Rewards Min           -10.2869
exploration/Returns Mean          -50.5919
exploration/Returns Std            18.6092
exploration/Returns Max           -31.9827
exploration/Returns Min           -69.201
exploration/Actions Mean            0.0407475
exploration/Actions Std             0.258712
exploration/Actions Max             0.99946
exploration/Actions Min            -0.912373
exploration/Num Paths               2
exploration/Average Returns       -50.5919
evaluation/num steps total     236000
evaluation/num paths total       2360
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.226284
evaluation/Rewards Std              1.07121
evaluation/Rewards Max             -0.00599935
evaluation/Rewards Min            -10.0261
evaluation/Returns Mean           -22.6284
evaluation/Returns Std             16.732
evaluation/Returns Max             -1.55195
evaluation/Returns Min            -56.5304
evaluation/Actions Mean             0.0246356
evaluation/Actions Std              0.194937
evaluation/Actions Max              0.997164
evaluation/Actions Min             -0.993966
evaluation/Num Paths               10
evaluation/Average Returns        -22.6284
time/data storing (s)               0.00117116
time/evaluation sampling (s)        0.23928
time/exploration sampling (s)       0.0643397
time/logging (s)                    0.00361844
time/saving (s)                     0.00267369
time/training (s)                   1.01882
time/epoch (s)                      1.3299
time/total (s)                    348.977
Epoch                             235
-----------------------------  ---------------
2019-04-21 12:22:15.266909 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 236 finished
-----------------------------  ---------------
replay_buffer/size              47600
trainer/QF1 Loss                    0.438814
trainer/QF2 Loss                    0.439868
trainer/Policy Loss                 8.7915
trainer/Q1 Predictions Mean        -6.95925
trainer/Q1 Predictions Std          2.05004
trainer/Q1 Predictions Max         -6.50689
trainer/Q1 Predictions Min        -26.778
trainer/Q2 Predictions Mean        -6.96587
trainer/Q2 Predictions Std          2.07988
trainer/Q2 Predictions Max         -6.49678
trainer/Q2 Predictions Min        -27.0364
trainer/Q Targets Mean             -6.93273
trainer/Q Targets Std               2.21982
trainer/Q Targets Max              -0.110761
trainer/Q Targets Min             -27.4978
trainer/Log Pis Mean                1.99107
trainer/Log Pis Std                 1.1113
trainer/Log Pis Max                 4.42523
trainer/Log Pis Min                -1.81221
trainer/Policy mu Mean              0.0733857
trainer/Policy mu Std               0.421953
trainer/Policy mu Max               3.43267
trainer/Policy mu Min              -2.23492
trainer/Policy log std Mean        -2.26794
trainer/Policy log std Std          0.29814
trainer/Policy log std Max         -0.558862
trainer/Policy log std Min         -2.4473
trainer/Alpha                       0.0534853
trainer/Alpha Loss                 -0.026152
exploration/num steps total     47600
exploration/num paths total       476
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.291931
exploration/Rewards Std             0.752765
exploration/Rewards Max            -0.0124609
exploration/Rewards Min            -5.86103
exploration/Returns Mean          -29.1931
exploration/Returns Std             4.80127
exploration/Returns Max           -24.3918
exploration/Returns Min           -33.9943
exploration/Actions Mean            0.0323055
exploration/Actions Std             0.224293
exploration/Actions Max             0.998821
exploration/Actions Min            -0.766891
exploration/Num Paths               2
exploration/Average Returns       -29.1931
evaluation/num steps total     237000
evaluation/num paths total       2370
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.230867
evaluation/Rewards Std              0.872487
evaluation/Rewards Max             -0.0668894
evaluation/Rewards Min            -10.2517
evaluation/Returns Mean           -23.0867
evaluation/Returns Std             15.5157
evaluation/Returns Max             -7.65614
evaluation/Returns Min            -61.6666
evaluation/Actions Mean             0.0187975
evaluation/Actions Std              0.175449
evaluation/Actions Max              0.99785
evaluation/Actions Min             -0.987495
evaluation/Num Paths               10
evaluation/Average Returns        -23.0867
time/data storing (s)               0.00112918
time/evaluation sampling (s)        0.247936
time/exploration sampling (s)       0.0619752
time/logging (s)                    0.00368696
time/saving (s)                     0.00233344
time/training (s)                   0.968062
time/epoch (s)                      1.28512
time/total (s)                    350.267
Epoch                             236
-----------------------------  ---------------
2019-04-21 12:22:16.543607 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 237 finished
-----------------------------  ---------------
replay_buffer/size              47800
trainer/QF1 Loss                    0.441765
trainer/QF2 Loss                    0.435125
trainer/Policy Loss                 8.90919
trainer/Q1 Predictions Mean        -7.12487
trainer/Q1 Predictions Std          2.30106
trainer/Q1 Predictions Max         -6.55322
trainer/Q1 Predictions Min        -24.5785
trainer/Q2 Predictions Mean        -7.10603
trainer/Q2 Predictions Std          2.31111
trainer/Q2 Predictions Max         -6.51629
trainer/Q2 Predictions Min        -24.3174
trainer/Q Targets Mean             -7.04126
trainer/Q Targets Std               2.41798
trainer/Q Targets Max              -0.0741007
trainer/Q Targets Min             -24.3246
trainer/Log Pis Mean                1.95533
trainer/Log Pis Std                 1.00212
trainer/Log Pis Max                 4.75853
trainer/Log Pis Min                -2.2355
trainer/Policy mu Mean              0.049631
trainer/Policy mu Std               0.452793
trainer/Policy mu Max               2.82193
trainer/Policy mu Min              -1.40396
trainer/Policy log std Mean        -2.25781
trainer/Policy log std Std          0.317433
trainer/Policy log std Max         -0.658801
trainer/Policy log std Min         -2.4581
trainer/Alpha                       0.0538113
trainer/Alpha Loss                 -0.130547
exploration/num steps total     47800
exploration/num paths total       478
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.154857
exploration/Rewards Std             0.301971
exploration/Rewards Max            -0.00653717
exploration/Rewards Min            -3.25216
exploration/Returns Mean          -15.4857
exploration/Returns Std             2.0922
exploration/Returns Max           -13.3935
exploration/Returns Min           -17.5779
exploration/Actions Mean           -0.001208
exploration/Actions Std             0.191378
exploration/Actions Max             0.989689
exploration/Actions Min            -0.992674
exploration/Num Paths               2
exploration/Average Returns       -15.4857
evaluation/num steps total     238000
evaluation/num paths total       2380
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.272348
evaluation/Rewards Std              1.2355
evaluation/Rewards Max             -0.00123374
evaluation/Rewards Min            -10.998
evaluation/Returns Mean           -27.2348
evaluation/Returns Std             18.8919
evaluation/Returns Max             -5.09996
evaluation/Returns Min            -56.9914
evaluation/Actions Mean             0.0388076
evaluation/Actions Std              0.204777
evaluation/Actions Max              0.99743
evaluation/Actions Min             -0.941802
evaluation/Num Paths               10
evaluation/Average Returns        -27.2348
time/data storing (s)               0.0011214
time/evaluation sampling (s)        0.236629
time/exploration sampling (s)       0.0583793
time/logging (s)                    0.00346025
time/saving (s)                     0.00254333
time/training (s)                   0.966775
time/epoch (s)                      1.26891
time/total (s)                    351.539
Epoch                             237
-----------------------------  ---------------
2019-04-21 12:22:17.868138 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 238 finished
-----------------------------  ---------------
replay_buffer/size              48000
trainer/QF1 Loss                    0.584654
trainer/QF2 Loss                    0.47516
trainer/Policy Loss                10.978
trainer/Q1 Predictions Mean        -8.86269
trainer/Q1 Predictions Std          7.96268
trainer/Q1 Predictions Max         -6.34667
trainer/Q1 Predictions Min        -49.1145
trainer/Q2 Predictions Mean        -8.8964
trainer/Q2 Predictions Std          8.06461
trainer/Q2 Predictions Max         -6.36618
trainer/Q2 Predictions Min        -50.3602
trainer/Q Targets Mean             -8.96535
trainer/Q Targets Std               8.04617
trainer/Q Targets Max              -0.0890191
trainer/Q Targets Min             -51.7319
trainer/Log Pis Mean                2.35947
trainer/Log Pis Std                 1.38925
trainer/Log Pis Max                 8.7065
trainer/Log Pis Min                -2.02964
trainer/Policy mu Mean              0.167627
trainer/Policy mu Std               0.725516
trainer/Policy mu Max               3.227
trainer/Policy mu Min              -1.85601
trainer/Policy log std Mean        -2.18585
trainer/Policy log std Std          0.449087
trainer/Policy log std Max         -0.680896
trainer/Policy log std Min         -2.45209
trainer/Alpha                       0.052988
trainer/Alpha Loss                  1.05604
exploration/num steps total     48000
exploration/num paths total       480
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.487703
exploration/Rewards Std             1.51754
exploration/Rewards Max            -0.00349253
exploration/Rewards Min           -10.6549
exploration/Returns Mean          -48.7703
exploration/Returns Std            13.7833
exploration/Returns Max           -34.987
exploration/Returns Min           -62.5536
exploration/Actions Mean            0.0402083
exploration/Actions Std             0.276466
exploration/Actions Max             0.999138
exploration/Actions Min            -0.983249
exploration/Num Paths               2
exploration/Average Returns       -48.7703
evaluation/num steps total     239000
evaluation/num paths total       2390
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.195337
evaluation/Rewards Std              0.892547
evaluation/Rewards Max             -0.0145919
evaluation/Rewards Min             -9.12814
evaluation/Returns Mean           -19.5337
evaluation/Returns Std             11.199
evaluation/Returns Max             -5.30394
evaluation/Returns Min            -42.5926
evaluation/Actions Mean             0.0154694
evaluation/Actions Std              0.194758
evaluation/Actions Max              0.997107
evaluation/Actions Min             -0.995154
evaluation/Num Paths               10
evaluation/Average Returns        -19.5337
time/data storing (s)               0.00107781
time/evaluation sampling (s)        0.253406
time/exploration sampling (s)       0.0634577
time/logging (s)                    0.00259412
time/saving (s)                     0.00188192
time/training (s)                   0.993074
time/epoch (s)                      1.31549
time/total (s)                    352.86
Epoch                             238
-----------------------------  ---------------
2019-04-21 12:22:19.239733 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 239 finished
-----------------------------  ---------------
replay_buffer/size              48200
trainer/QF1 Loss                    0.42427
trainer/QF2 Loss                    0.43048
trainer/Policy Loss                10.5083
trainer/Q1 Predictions Mean        -8.37544
trainer/Q1 Predictions Std          7.77989
trainer/Q1 Predictions Max         -6.44094
trainer/Q1 Predictions Min        -67.1038
trainer/Q2 Predictions Mean        -8.39434
trainer/Q2 Predictions Std          7.75651
trainer/Q2 Predictions Max         -6.47272
trainer/Q2 Predictions Min        -66.5579
trainer/Q Targets Mean             -8.37213
trainer/Q Targets Std               7.84436
trainer/Q Targets Max              -0.119126
trainer/Q Targets Min             -67.6108
trainer/Log Pis Mean                2.33967
trainer/Log Pis Std                 0.9888
trainer/Log Pis Max                 6.18102
trainer/Log Pis Min                -0.0969596
trainer/Policy mu Mean              0.0944479
trainer/Policy mu Std               0.698671
trainer/Policy mu Max               2.9347
trainer/Policy mu Min              -2.15031
trainer/Policy log std Mean        -2.21385
trainer/Policy log std Std          0.50191
trainer/Policy log std Max         -0.585207
trainer/Policy log std Min         -2.50574
trainer/Alpha                       0.0535154
trainer/Alpha Loss                  0.99456
exploration/num steps total     48200
exploration/num paths total       482
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.401737
exploration/Rewards Std             1.25441
exploration/Rewards Max            -0.00692594
exploration/Rewards Min            -9.41136
exploration/Returns Mean          -40.1737
exploration/Returns Std            15.8518
exploration/Returns Max           -24.3219
exploration/Returns Min           -56.0255
exploration/Actions Mean            0.0577069
exploration/Actions Std             0.255235
exploration/Actions Max             0.999348
exploration/Actions Min            -0.428527
exploration/Num Paths               2
exploration/Average Returns       -40.1737
evaluation/num steps total     240000
evaluation/num paths total       2400
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.2286
evaluation/Rewards Std              1.00231
evaluation/Rewards Max             -0.0343152
evaluation/Rewards Min            -10.5111
evaluation/Returns Mean           -22.86
evaluation/Returns Std             17.5588
evaluation/Returns Max             -3.92115
evaluation/Returns Min            -61.6375
evaluation/Actions Mean             0.0255374
evaluation/Actions Std              0.184138
evaluation/Actions Max              0.995996
evaluation/Actions Min             -0.987256
evaluation/Num Paths               10
evaluation/Average Returns        -22.86
time/data storing (s)               0.00113234
time/evaluation sampling (s)        0.248316
time/exploration sampling (s)       0.0588492
time/logging (s)                    0.00344535
time/saving (s)                     0.00233427
time/training (s)                   1.05036
time/epoch (s)                      1.36444
time/total (s)                    354.228
Epoch                             239
-----------------------------  ---------------
2019-04-21 12:22:20.582270 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 240 finished
-----------------------------  ----------------
replay_buffer/size              48400
trainer/QF1 Loss                    1.30695
trainer/QF2 Loss                    1.33493
trainer/Policy Loss                 9.81974
trainer/Q1 Predictions Mean        -8.0222
trainer/Q1 Predictions Std          6.01693
trainer/Q1 Predictions Max         -6.48404
trainer/Q1 Predictions Min        -46.3947
trainer/Q2 Predictions Mean        -8.05917
trainer/Q2 Predictions Std          6.07738
trainer/Q2 Predictions Max         -6.5259
trainer/Q2 Predictions Min        -46.6551
trainer/Q Targets Mean             -7.832
trainer/Q Targets Std               6.07806
trainer/Q Targets Max              -0.0226528
trainer/Q Targets Min             -45.4563
trainer/Log Pis Mean                2.06763
trainer/Log Pis Std                 1.14388
trainer/Log Pis Max                 6.8498
trainer/Log Pis Min                -2.46748
trainer/Policy mu Mean              0.0460344
trainer/Policy mu Std               0.603565
trainer/Policy mu Max               3.03646
trainer/Policy mu Min              -2.66928
trainer/Policy log std Mean        -2.16033
trainer/Policy log std Std          0.398465
trainer/Policy log std Max         -0.566434
trainer/Policy log std Min         -2.35834
trainer/Alpha                       0.0550713
trainer/Alpha Loss                  0.196066
exploration/num steps total     48400
exploration/num paths total       484
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.146301
exploration/Rewards Std             0.089032
exploration/Rewards Max            -0.00478581
exploration/Rewards Min            -0.679727
exploration/Returns Mean          -14.6301
exploration/Returns Std             0.18462
exploration/Returns Max           -14.4455
exploration/Returns Min           -14.8148
exploration/Actions Mean            0.000389318
exploration/Actions Std             0.156738
exploration/Actions Max             0.9656
exploration/Actions Min            -0.979474
exploration/Num Paths               2
exploration/Average Returns       -14.6301
evaluation/num steps total     241000
evaluation/num paths total       2410
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.230905
evaluation/Rewards Std              0.842135
evaluation/Rewards Max             -0.0114132
evaluation/Rewards Min             -9.73059
evaluation/Returns Mean           -23.0905
evaluation/Returns Std             15.4048
evaluation/Returns Max             -9.04031
evaluation/Returns Min            -59.5516
evaluation/Actions Mean             0.0218145
evaluation/Actions Std              0.170705
evaluation/Actions Max              0.9971
evaluation/Actions Min             -0.995818
evaluation/Num Paths               10
evaluation/Average Returns        -23.0905
time/data storing (s)               0.00117506
time/evaluation sampling (s)        0.251827
time/exploration sampling (s)       0.0645125
time/logging (s)                    0.00347402
time/saving (s)                     0.00186714
time/training (s)                   1.01154
time/epoch (s)                      1.3344
time/total (s)                    355.567
Epoch                             240
-----------------------------  ----------------
2019-04-21 12:22:21.953750 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 241 finished
-----------------------------  ---------------
replay_buffer/size              48600
trainer/QF1 Loss                    0.0376622
trainer/QF2 Loss                    0.0483902
trainer/Policy Loss                 8.92868
trainer/Q1 Predictions Mean        -7.03423
trainer/Q1 Predictions Std          2.17
trainer/Q1 Predictions Max         -6.33198
trainer/Q1 Predictions Min        -18.8651
trainer/Q2 Predictions Mean        -7.02543
trainer/Q2 Predictions Std          2.12773
trainer/Q2 Predictions Max         -6.3397
trainer/Q2 Predictions Min        -18.7128
trainer/Q Targets Mean             -7.19388
trainer/Q Targets Std               2.14222
trainer/Q Targets Max              -6.41019
trainer/Q Targets Min             -18.7854
trainer/Log Pis Mean                2.00607
trainer/Log Pis Std                 1.09523
trainer/Log Pis Max                 6.89551
trainer/Log Pis Min                -1.45438
trainer/Policy mu Mean              0.0263243
trainer/Policy mu Std               0.545772
trainer/Policy mu Max               2.71425
trainer/Policy mu Min              -2.36479
trainer/Policy log std Mean        -2.20704
trainer/Policy log std Std          0.4189
trainer/Policy log std Max         -0.496645
trainer/Policy log std Min         -2.43682
trainer/Alpha                       0.0551561
trainer/Alpha Loss                  0.0175843
exploration/num steps total     48600
exploration/num paths total       486
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.400277
exploration/Rewards Std             1.32467
exploration/Rewards Max            -0.00811665
exploration/Rewards Min            -9.78222
exploration/Returns Mean          -40.0277
exploration/Returns Std            22.7435
exploration/Returns Max           -17.2842
exploration/Returns Min           -62.7713
exploration/Actions Mean            0.0265135
exploration/Actions Std             0.232796
exploration/Actions Max             0.998018
exploration/Actions Min            -0.995869
exploration/Num Paths               2
exploration/Average Returns       -40.0277
evaluation/num steps total     242000
evaluation/num paths total       2420
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.148261
evaluation/Rewards Std              0.754824
evaluation/Rewards Max             -0.0137356
evaluation/Rewards Min             -8.64768
evaluation/Returns Mean           -14.8261
evaluation/Returns Std             10.1758
evaluation/Returns Max             -2.33708
evaluation/Returns Min            -40.4875
evaluation/Actions Mean             0.022793
evaluation/Actions Std              0.183179
evaluation/Actions Max              0.996308
evaluation/Actions Min             -0.995606
evaluation/Num Paths               10
evaluation/Average Returns        -14.8261
time/data storing (s)               0.00118064
time/evaluation sampling (s)        0.259667
time/exploration sampling (s)       0.0639661
time/logging (s)                    0.0034773
time/saving (s)                     0.00197541
time/training (s)                   1.0333
time/epoch (s)                      1.36357
time/total (s)                    356.935
Epoch                             241
-----------------------------  ---------------
2019-04-21 12:22:23.313180 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 242 finished
-----------------------------  ---------------
replay_buffer/size              48800
trainer/QF1 Loss                    1.02887
trainer/QF2 Loss                    1.03455
trainer/Policy Loss                10.9966
trainer/Q1 Predictions Mean        -9.22354
trainer/Q1 Predictions Std          7.29665
trainer/Q1 Predictions Max         -6.34145
trainer/Q1 Predictions Min        -41.4118
trainer/Q2 Predictions Mean        -9.28063
trainer/Q2 Predictions Std          7.26498
trainer/Q2 Predictions Max         -6.44115
trainer/Q2 Predictions Min        -41.374
trainer/Q Targets Mean             -9.23502
trainer/Q Targets Std               7.39392
trainer/Q Targets Max              -0.108633
trainer/Q Targets Min             -40.9153
trainer/Log Pis Mean                2.31606
trainer/Log Pis Std                 1.44286
trainer/Log Pis Max                 7.48689
trainer/Log Pis Min                -1.94581
trainer/Policy mu Mean              0.206454
trainer/Policy mu Std               0.914627
trainer/Policy mu Max               3.29763
trainer/Policy mu Min              -3.43201
trainer/Policy log std Mean        -2.0013
trainer/Policy log std Std          0.542254
trainer/Policy log std Max         -0.42106
trainer/Policy log std Min         -2.35786
trainer/Alpha                       0.0563303
trainer/Alpha Loss                  0.909145
exploration/num steps total     48800
exploration/num paths total       488
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.286558
exploration/Rewards Std             0.775178
exploration/Rewards Max            -0.00841683
exploration/Rewards Min            -6.58569
exploration/Returns Mean          -28.6558
exploration/Returns Std             6.26725
exploration/Returns Max           -22.3886
exploration/Returns Min           -34.9231
exploration/Actions Mean           -0.00572903
exploration/Actions Std             0.240633
exploration/Actions Max             0.992871
exploration/Actions Min            -0.995536
exploration/Num Paths               2
exploration/Average Returns       -28.6558
evaluation/num steps total     243000
evaluation/num paths total       2430
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.233961
evaluation/Rewards Std              1.02642
evaluation/Rewards Max             -0.0163947
evaluation/Rewards Min             -9.50429
evaluation/Returns Mean           -23.3961
evaluation/Returns Std             17.041
evaluation/Returns Max             -4.59853
evaluation/Returns Min            -50.5212
evaluation/Actions Mean             0.0346457
evaluation/Actions Std              0.190866
evaluation/Actions Max              0.996632
evaluation/Actions Min             -0.983834
evaluation/Num Paths               10
evaluation/Average Returns        -23.3961
time/data storing (s)               0.00122906
time/evaluation sampling (s)        0.256795
time/exploration sampling (s)       0.0653686
time/logging (s)                    0.00340494
time/saving (s)                     0.00229893
time/training (s)                   1.02275
time/epoch (s)                      1.35185
time/total (s)                    358.29
Epoch                             242
-----------------------------  ---------------
2019-04-21 12:22:24.670317 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 243 finished
-----------------------------  ---------------
replay_buffer/size              49000
trainer/QF1 Loss                    0.0575169
trainer/QF2 Loss                    0.0624022
trainer/Policy Loss                 9.73902
trainer/Q1 Predictions Mean        -7.57684
trainer/Q1 Predictions Std          5.9422
trainer/Q1 Predictions Max         -6.36138
trainer/Q1 Predictions Min        -59.6407
trainer/Q2 Predictions Mean        -7.56526
trainer/Q2 Predictions Std          5.93019
trainer/Q2 Predictions Max         -6.35538
trainer/Q2 Predictions Min        -59.6198
trainer/Q Targets Mean             -7.70549
trainer/Q Targets Std               6.08792
trainer/Q Targets Max              -6.39583
trainer/Q Targets Min             -61.5488
trainer/Log Pis Mean                2.24454
trainer/Log Pis Std                 0.994981
trainer/Log Pis Max                 7.16101
trainer/Log Pis Min                -1.06577
trainer/Policy mu Mean              0.0794872
trainer/Policy mu Std               0.560907
trainer/Policy mu Max               3.39882
trainer/Policy mu Min              -2.13088
trainer/Policy log std Mean        -2.26299
trainer/Policy log std Std          0.385066
trainer/Policy log std Max         -0.606545
trainer/Policy log std Min         -2.44826
trainer/Alpha                       0.0560354
trainer/Alpha Loss                  0.704751
exploration/num steps total     49000
exploration/num paths total       490
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.28247
exploration/Rewards Std             0.836143
exploration/Rewards Max            -0.0103942
exploration/Rewards Min            -6.9064
exploration/Returns Mean          -28.247
exploration/Returns Std             9.88534
exploration/Returns Max           -18.3617
exploration/Returns Min           -38.1324
exploration/Actions Mean            0.031213
exploration/Actions Std             0.215329
exploration/Actions Max             0.997864
exploration/Actions Min            -0.712079
exploration/Num Paths               2
exploration/Average Returns       -28.247
evaluation/num steps total     244000
evaluation/num paths total       2440
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.158736
evaluation/Rewards Std              0.72455
evaluation/Rewards Max             -0.0138555
evaluation/Rewards Min             -8.62485
evaluation/Returns Mean           -15.8736
evaluation/Returns Std             11.4288
evaluation/Returns Max             -4.32455
evaluation/Returns Min            -44.1918
evaluation/Actions Mean             0.0192702
evaluation/Actions Std              0.172435
evaluation/Actions Max              0.995316
evaluation/Actions Min             -0.993608
evaluation/Num Paths               10
evaluation/Average Returns        -15.8736
time/data storing (s)               0.00157676
time/evaluation sampling (s)        0.258128
time/exploration sampling (s)       0.0652802
time/logging (s)                    0.00438551
time/saving (s)                     0.00212892
time/training (s)                   1.01893
time/epoch (s)                      1.35043
time/total (s)                    359.645
Epoch                             243
-----------------------------  ---------------
2019-04-21 12:22:26.045479 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 244 finished
-----------------------------  ---------------
replay_buffer/size              49200
trainer/QF1 Loss                    1.25718
trainer/QF2 Loss                    1.27176
trainer/Policy Loss                 9.99305
trainer/Q1 Predictions Mean        -8.05308
trainer/Q1 Predictions Std          6.29657
trainer/Q1 Predictions Max         -6.32735
trainer/Q1 Predictions Min        -42.9658
trainer/Q2 Predictions Mean        -8.12893
trainer/Q2 Predictions Std          6.32618
trainer/Q2 Predictions Max         -6.40311
trainer/Q2 Predictions Min        -43.1131
trainer/Q Targets Mean             -7.98395
trainer/Q Targets Std               6.49139
trainer/Q Targets Max              -0.0661729
trainer/Q Targets Min             -42.7452
trainer/Log Pis Mean                2.06852
trainer/Log Pis Std                 1.10986
trainer/Log Pis Max                 5.09053
trainer/Log Pis Min                -1.94865
trainer/Policy mu Mean              0.120936
trainer/Policy mu Std               0.632247
trainer/Policy mu Max               3.18972
trainer/Policy mu Min              -2.13645
trainer/Policy log std Mean        -2.22148
trainer/Policy log std Std          0.445366
trainer/Policy log std Max         -0.350968
trainer/Policy log std Min         -2.47375
trainer/Alpha                       0.0577617
trainer/Alpha Loss                  0.195369
exploration/num steps total     49200
exploration/num paths total       492
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.30014
exploration/Rewards Std             0.986512
exploration/Rewards Max            -0.0106751
exploration/Rewards Min            -8.15341
exploration/Returns Mean          -30.014
exploration/Returns Std            17.7327
exploration/Returns Max           -12.2813
exploration/Returns Min           -47.7467
exploration/Actions Mean            0.0275488
exploration/Actions Std             0.213941
exploration/Actions Max             0.99687
exploration/Actions Min            -0.896417
exploration/Num Paths               2
exploration/Average Returns       -30.014
evaluation/num steps total     245000
evaluation/num paths total       2450
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.161854
evaluation/Rewards Std              0.75282
evaluation/Rewards Max             -0.0223647
evaluation/Rewards Min             -8.64306
evaluation/Returns Mean           -16.1854
evaluation/Returns Std             11.5207
evaluation/Returns Max             -3.41717
evaluation/Returns Min            -44.5148
evaluation/Actions Mean             0.0183848
evaluation/Actions Std              0.173196
evaluation/Actions Max              0.997763
evaluation/Actions Min             -0.996166
evaluation/Num Paths               10
evaluation/Average Returns        -16.1854
time/data storing (s)               0.00117711
time/evaluation sampling (s)        0.269695
time/exploration sampling (s)       0.0669172
time/logging (s)                    0.00343937
time/saving (s)                     0.00238995
time/training (s)                   1.02254
time/epoch (s)                      1.36616
time/total (s)                    361.015
Epoch                             244
-----------------------------  ---------------
2019-04-21 12:22:27.448019 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 245 finished
-----------------------------  ---------------
replay_buffer/size              49400
trainer/QF1 Loss                    0.424096
trainer/QF2 Loss                    0.422386
trainer/Policy Loss                 9.82473
trainer/Q1 Predictions Mean        -7.7546
trainer/Q1 Predictions Std          5.00626
trainer/Q1 Predictions Max         -6.34954
trainer/Q1 Predictions Min        -47.8124
trainer/Q2 Predictions Mean        -7.81192
trainer/Q2 Predictions Std          4.97842
trainer/Q2 Predictions Max         -6.39603
trainer/Q2 Predictions Min        -47.875
trainer/Q Targets Mean             -7.8143
trainer/Q Targets Std               5.06083
trainer/Q Targets Max              -0.114953
trainer/Q Targets Min             -48.0024
trainer/Log Pis Mean                2.16684
trainer/Log Pis Std                 1.27222
trainer/Log Pis Max                 7.36621
trainer/Log Pis Min                -2.9659
trainer/Policy mu Mean              0.162301
trainer/Policy mu Std               0.710237
trainer/Policy mu Max               3.0575
trainer/Policy mu Min              -2.67849
trainer/Policy log std Mean        -2.1257
trainer/Policy log std Std          0.532347
trainer/Policy log std Max         -0.532242
trainer/Policy log std Min         -2.42544
trainer/Alpha                       0.0569156
trainer/Alpha Loss                  0.478207
exploration/num steps total     49400
exploration/num paths total       494
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.388442
exploration/Rewards Std             1.27671
exploration/Rewards Max            -0.0107251
exploration/Rewards Min           -10.2886
exploration/Returns Mean          -38.8442
exploration/Returns Std            21.8097
exploration/Returns Max           -17.0346
exploration/Returns Min           -60.6539
exploration/Actions Mean            0.039669
exploration/Actions Std             0.25286
exploration/Actions Max             0.998418
exploration/Actions Min            -0.941473
exploration/Num Paths               2
exploration/Average Returns       -38.8442
evaluation/num steps total     246000
evaluation/num paths total       2460
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.277313
evaluation/Rewards Std              1.06357
evaluation/Rewards Max             -0.0267248
evaluation/Rewards Min             -9.66039
evaluation/Returns Mean           -27.7313
evaluation/Returns Std             16.6292
evaluation/Returns Max            -10.1017
evaluation/Returns Min            -57.2657
evaluation/Actions Mean             0.0174415
evaluation/Actions Std              0.195515
evaluation/Actions Max              0.996167
evaluation/Actions Min             -0.992399
evaluation/Num Paths               10
evaluation/Average Returns        -27.7313
time/data storing (s)               0.00115382
time/evaluation sampling (s)        0.268687
time/exploration sampling (s)       0.0616243
time/logging (s)                    0.00346798
time/saving (s)                     0.00235497
time/training (s)                   1.05646
time/epoch (s)                      1.39374
time/total (s)                    362.414
Epoch                             245
-----------------------------  ---------------
2019-04-21 12:22:28.839896 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 246 finished
-----------------------------  ---------------
replay_buffer/size              49600
trainer/QF1 Loss                    0.832886
trainer/QF2 Loss                    0.836381
trainer/Policy Loss                10.5361
trainer/Q1 Predictions Mean        -8.53285
trainer/Q1 Predictions Std          7.58671
trainer/Q1 Predictions Max         -6.35665
trainer/Q1 Predictions Min        -53.6234
trainer/Q2 Predictions Mean        -8.58409
trainer/Q2 Predictions Std          7.59788
trainer/Q2 Predictions Max         -6.39147
trainer/Q2 Predictions Min        -53.3381
trainer/Q Targets Mean             -8.47883
trainer/Q Targets Std               7.59809
trainer/Q Targets Max              -0.0799859
trainer/Q Targets Min             -53.1006
trainer/Log Pis Mean                2.01603
trainer/Log Pis Std                 1.53792
trainer/Log Pis Max                 8.57036
trainer/Log Pis Min                -3.40454
trainer/Policy mu Mean              0.168861
trainer/Policy mu Std               0.683073
trainer/Policy mu Max               3.181
trainer/Policy mu Min              -2.5968
trainer/Policy log std Mean        -2.15822
trainer/Policy log std Std          0.43719
trainer/Policy log std Max         -0.52525
trainer/Policy log std Min         -2.38499
trainer/Alpha                       0.0570553
trainer/Alpha Loss                  0.0459003
exploration/num steps total     49600
exploration/num paths total       496
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.198452
exploration/Rewards Std             0.415733
exploration/Rewards Max            -0.0176002
exploration/Rewards Min            -4.53069
exploration/Returns Mean          -19.8452
exploration/Returns Std             5.09765
exploration/Returns Max           -14.7476
exploration/Returns Min           -24.9428
exploration/Actions Mean            0.00629165
exploration/Actions Std             0.187189
exploration/Actions Max             0.997618
exploration/Actions Min            -0.914964
exploration/Num Paths               2
exploration/Average Returns       -19.8452
evaluation/num steps total     247000
evaluation/num paths total       2470
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.203512
evaluation/Rewards Std              0.822864
evaluation/Rewards Max             -0.0498583
evaluation/Rewards Min             -9.893
evaluation/Returns Mean           -20.3512
evaluation/Returns Std             15.3971
evaluation/Returns Max             -6.5204
evaluation/Returns Min            -57.5224
evaluation/Actions Mean             0.028958
evaluation/Actions Std              0.171102
evaluation/Actions Max              0.996423
evaluation/Actions Min             -0.982847
evaluation/Num Paths               10
evaluation/Average Returns        -20.3512
time/data storing (s)               0.00131432
time/evaluation sampling (s)        0.261831
time/exploration sampling (s)       0.0751322
time/logging (s)                    0.00361125
time/saving (s)                     0.00232982
time/training (s)                   1.03986
time/epoch (s)                      1.38408
time/total (s)                    363.802
Epoch                             246
-----------------------------  ---------------
2019-04-21 12:22:30.197837 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 247 finished
-----------------------------  ---------------
replay_buffer/size              49800
trainer/QF1 Loss                    0.0936587
trainer/QF2 Loss                    0.0366331
trainer/Policy Loss                 9.49036
trainer/Q1 Predictions Mean        -7.61792
trainer/Q1 Predictions Std          4.48396
trainer/Q1 Predictions Max         -6.48827
trainer/Q1 Predictions Min        -45.5964
trainer/Q2 Predictions Mean        -7.66865
trainer/Q2 Predictions Std          4.59436
trainer/Q2 Predictions Max         -6.52613
trainer/Q2 Predictions Min        -46.8809
trainer/Q Targets Mean             -7.62759
trainer/Q Targets Std               4.70111
trainer/Q Targets Max              -6.35898
trainer/Q Targets Min             -48.2408
trainer/Log Pis Mean                1.99466
trainer/Log Pis Std                 1.19005
trainer/Log Pis Max                 6.84728
trainer/Log Pis Min                -1.04533
trainer/Policy mu Mean              0.107506
trainer/Policy mu Std               0.656244
trainer/Policy mu Max               3.24158
trainer/Policy mu Min              -2.37391
trainer/Policy log std Mean        -2.09799
trainer/Policy log std Std          0.439075
trainer/Policy log std Max         -0.58746
trainer/Policy log std Min         -2.37468
trainer/Alpha                       0.0555451
trainer/Alpha Loss                 -0.015424
exploration/num steps total     49800
exploration/num paths total       498
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.325497
exploration/Rewards Std             0.996039
exploration/Rewards Max            -0.00473717
exploration/Rewards Min            -8.53172
exploration/Returns Mean          -32.5497
exploration/Returns Std            16.465
exploration/Returns Max           -16.0847
exploration/Returns Min           -49.0147
exploration/Actions Mean            0.0199873
exploration/Actions Std             0.236857
exploration/Actions Max             0.996585
exploration/Actions Min            -0.969503
exploration/Num Paths               2
exploration/Average Returns       -32.5497
evaluation/num steps total     248000
evaluation/num paths total       2480
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.193282
evaluation/Rewards Std              0.89491
evaluation/Rewards Max             -0.0312677
evaluation/Rewards Min            -10.3463
evaluation/Returns Mean           -19.3282
evaluation/Returns Std             16.3834
evaluation/Returns Max             -4.34137
evaluation/Returns Min            -57.8658
evaluation/Actions Mean             0.0219971
evaluation/Actions Std              0.17687
evaluation/Actions Max              0.99757
evaluation/Actions Min             -0.985396
evaluation/Num Paths               10
evaluation/Average Returns        -19.3282
time/data storing (s)               0.00116034
time/evaluation sampling (s)        0.261073
time/exploration sampling (s)       0.0702287
time/logging (s)                    0.00343209
time/saving (s)                     0.00244278
time/training (s)                   1.0113
time/epoch (s)                      1.34964
time/total (s)                    365.156
Epoch                             247
-----------------------------  ---------------
2019-04-21 12:22:31.554768 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 248 finished
-----------------------------  ---------------
replay_buffer/size              50000
trainer/QF1 Loss                    0.512197
trainer/QF2 Loss                    0.521576
trainer/Policy Loss                 8.923
trainer/Q1 Predictions Mean        -7.01477
trainer/Q1 Predictions Std          2.38978
trainer/Q1 Predictions Max         -6.41848
trainer/Q1 Predictions Min        -28.5892
trainer/Q2 Predictions Mean        -7.07595
trainer/Q2 Predictions Std          2.43706
trainer/Q2 Predictions Max         -6.48674
trainer/Q2 Predictions Min        -29.0956
trainer/Q Targets Mean             -7.01403
trainer/Q Targets Std               2.61342
trainer/Q Targets Max              -0.159506
trainer/Q Targets Min             -28.8497
trainer/Log Pis Mean                1.94309
trainer/Log Pis Std                 1.00129
trainer/Log Pis Max                 4.98127
trainer/Log Pis Min                -1.77351
trainer/Policy mu Mean              0.0580983
trainer/Policy mu Std               0.477465
trainer/Policy mu Max               2.75886
trainer/Policy mu Min              -1.7102
trainer/Policy log std Mean        -2.2122
trainer/Policy log std Std          0.34574
trainer/Policy log std Max         -0.603856
trainer/Policy log std Min         -2.41061
trainer/Alpha                       0.0541807
trainer/Alpha Loss                 -0.165929
exploration/num steps total     50000
exploration/num paths total       500
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.392132
exploration/Rewards Std             1.27655
exploration/Rewards Max            -0.0122406
exploration/Rewards Min            -9.84213
exploration/Returns Mean          -39.2132
exploration/Returns Std            25.3359
exploration/Returns Max           -13.8773
exploration/Returns Min           -64.5491
exploration/Actions Mean            0.0411048
exploration/Actions Std             0.231164
exploration/Actions Max             0.99832
exploration/Actions Min            -0.430573
exploration/Num Paths               2
exploration/Average Returns       -39.2132
evaluation/num steps total     249000
evaluation/num paths total       2490
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.337026
evaluation/Rewards Std              1.30198
evaluation/Rewards Max             -0.0389431
evaluation/Rewards Min            -10.538
evaluation/Returns Mean           -33.7026
evaluation/Returns Std             18.7786
evaluation/Returns Max             -6.87002
evaluation/Returns Min            -59.4889
evaluation/Actions Mean             0.0336869
evaluation/Actions Std              0.213761
evaluation/Actions Max              0.997435
evaluation/Actions Min             -0.997403
evaluation/Num Paths               10
evaluation/Average Returns        -33.7026
time/data storing (s)               0.00118506
time/evaluation sampling (s)        0.26829
time/exploration sampling (s)       0.0650456
time/logging (s)                    0.0035264
time/saving (s)                     0.00229101
time/training (s)                   1.00917
time/epoch (s)                      1.34951
time/total (s)                    366.509
Epoch                             248
-----------------------------  ---------------
2019-04-21 12:22:32.857100 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 249 finished
-----------------------------  ---------------
replay_buffer/size              50200
trainer/QF1 Loss                    0.733468
trainer/QF2 Loss                    0.655633
trainer/Policy Loss                 9.36714
trainer/Q1 Predictions Mean        -7.44984
trainer/Q1 Predictions Std          5.26948
trainer/Q1 Predictions Max         -6.29911
trainer/Q1 Predictions Min        -46.1093
trainer/Q2 Predictions Mean        -7.37068
trainer/Q2 Predictions Std          5.36154
trainer/Q2 Predictions Max         -6.19729
trainer/Q2 Predictions Min        -47.2971
trainer/Q Targets Mean             -7.59935
trainer/Q Targets Std               5.82516
trainer/Q Targets Max              -0.0361637
trainer/Q Targets Min             -51.1145
trainer/Log Pis Mean                1.96659
trainer/Log Pis Std                 1.2799
trainer/Log Pis Max                 8.13398
trainer/Log Pis Min                -0.67786
trainer/Policy mu Mean              0.0608185
trainer/Policy mu Std               0.612288
trainer/Policy mu Max               3.28152
trainer/Policy mu Min              -2.25044
trainer/Policy log std Mean        -2.20615
trainer/Policy log std Std          0.426425
trainer/Policy log std Max         -0.618466
trainer/Policy log std Min         -2.4426
trainer/Alpha                       0.0546509
trainer/Alpha Loss                 -0.0971202
exploration/num steps total     50200
exploration/num paths total       502
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.351413
exploration/Rewards Std             1.0745
exploration/Rewards Max            -0.00917212
exploration/Rewards Min            -8.34629
exploration/Returns Mean          -35.1413
exploration/Returns Std            15.1758
exploration/Returns Max           -19.9655
exploration/Returns Min           -50.3171
exploration/Actions Mean            0.0187034
exploration/Actions Std             0.226381
exploration/Actions Max             0.999571
exploration/Actions Min            -0.995341
exploration/Num Paths               2
exploration/Average Returns       -35.1413
evaluation/num steps total     250000
evaluation/num paths total       2500
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.227872
evaluation/Rewards Std              0.882135
evaluation/Rewards Max             -0.0236826
evaluation/Rewards Min             -8.80815
evaluation/Returns Mean           -22.7872
evaluation/Returns Std              6.91421
evaluation/Returns Max            -12.1116
evaluation/Returns Min            -39.5329
evaluation/Actions Mean             0.0224039
evaluation/Actions Std              0.204025
evaluation/Actions Max              0.99595
evaluation/Actions Min             -0.989886
evaluation/Num Paths               10
evaluation/Average Returns        -22.7872
time/data storing (s)               0.00112226
time/evaluation sampling (s)        0.248904
time/exploration sampling (s)       0.0600666
time/logging (s)                    0.00344949
time/saving (s)                     0.00236484
time/training (s)                   0.978976
time/epoch (s)                      1.29488
time/total (s)                    367.808
Epoch                             249
-----------------------------  ---------------
2019-04-21 12:22:34.151327 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 250 finished
-----------------------------  ---------------
replay_buffer/size              50400
trainer/QF1 Loss                    0.0110652
trainer/QF2 Loss                    0.0191215
trainer/Policy Loss                 9.96145
trainer/Q1 Predictions Mean        -8.15441
trainer/Q1 Predictions Std          5.346
trainer/Q1 Predictions Max         -6.45017
trainer/Q1 Predictions Min        -32.0596
trainer/Q2 Predictions Mean        -8.10856
trainer/Q2 Predictions Std          5.31987
trainer/Q2 Predictions Max         -6.4343
trainer/Q2 Predictions Min        -32.2559
trainer/Q Targets Mean             -8.11919
trainer/Q Targets Std               5.30975
trainer/Q Targets Max              -6.34962
trainer/Q Targets Min             -31.8811
trainer/Log Pis Mean                2.09707
trainer/Log Pis Std                 1.09135
trainer/Log Pis Max                 6.16042
trainer/Log Pis Min                -1.80672
trainer/Policy mu Mean              0.156754
trainer/Policy mu Std               0.696284
trainer/Policy mu Max               3.00445
trainer/Policy mu Min              -1.54364
trainer/Policy log std Mean        -2.11906
trainer/Policy log std Std          0.484976
trainer/Policy log std Max         -0.540689
trainer/Policy log std Min         -2.41124
trainer/Alpha                       0.0548803
trainer/Alpha Loss                  0.281749
exploration/num steps total     50400
exploration/num paths total       504
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.431334
exploration/Rewards Std             1.28131
exploration/Rewards Max            -0.0187816
exploration/Rewards Min            -9.08128
exploration/Returns Mean          -43.1334
exploration/Returns Std             8.02359
exploration/Returns Max           -35.1098
exploration/Returns Min           -51.157
exploration/Actions Mean            0.0410674
exploration/Actions Std             0.269884
exploration/Actions Max             0.999603
exploration/Actions Min            -0.973378
exploration/Num Paths               2
exploration/Average Returns       -43.1334
evaluation/num steps total     251000
evaluation/num paths total       2510
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.237655
evaluation/Rewards Std              1.00235
evaluation/Rewards Max             -0.039757
evaluation/Rewards Min            -11.0144
evaluation/Returns Mean           -23.7655
evaluation/Returns Std             18.097
evaluation/Returns Max             -5.52741
evaluation/Returns Min            -61.8851
evaluation/Actions Mean             0.0265575
evaluation/Actions Std              0.180442
evaluation/Actions Max              0.998262
evaluation/Actions Min             -0.979119
evaluation/Num Paths               10
evaluation/Average Returns        -23.7655
time/data storing (s)               0.00109697
time/evaluation sampling (s)        0.246089
time/exploration sampling (s)       0.0599661
time/logging (s)                    0.00287321
time/saving (s)                     0.00232012
time/training (s)                   0.974192
time/epoch (s)                      1.28654
time/total (s)                    369.097
Epoch                             250
-----------------------------  ---------------
2019-04-21 12:22:35.447322 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 251 finished
-----------------------------  ---------------
replay_buffer/size              50600
trainer/QF1 Loss                    0.819747
trainer/QF2 Loss                    0.811119
trainer/Policy Loss                 8.72148
trainer/Q1 Predictions Mean        -6.94574
trainer/Q1 Predictions Std          4.17434
trainer/Q1 Predictions Max         -6.21736
trainer/Q1 Predictions Min        -47.2556
trainer/Q2 Predictions Mean        -7.00301
trainer/Q2 Predictions Std          4.20114
trainer/Q2 Predictions Max         -6.26958
trainer/Q2 Predictions Min        -47.531
trainer/Q Targets Mean             -7.01196
trainer/Q Targets Std               4.24166
trainer/Q Targets Max              -0.156778
trainer/Q Targets Min             -46.9671
trainer/Log Pis Mean                1.81415
trainer/Log Pis Std                 1.1282
trainer/Log Pis Max                 4.72254
trainer/Log Pis Min                -1.75718
trainer/Policy mu Mean              0.0456761
trainer/Policy mu Std               0.400108
trainer/Policy mu Max               2.98551
trainer/Policy mu Min              -1.39181
trainer/Policy log std Mean        -2.22724
trainer/Policy log std Std          0.282366
trainer/Policy log std Max         -0.656561
trainer/Policy log std Min         -2.3625
trainer/Alpha                       0.0557365
trainer/Alpha Loss                 -0.536542
exploration/num steps total     50600
exploration/num paths total       506
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.449232
exploration/Rewards Std             1.28777
exploration/Rewards Max            -0.0126497
exploration/Rewards Min            -8.21488
exploration/Returns Mean          -44.9232
exploration/Returns Std             5.76881
exploration/Returns Max           -39.1544
exploration/Returns Min           -50.692
exploration/Actions Mean            0.0309465
exploration/Actions Std             0.257913
exploration/Actions Max             0.99937
exploration/Actions Min            -0.932797
exploration/Num Paths               2
exploration/Average Returns       -44.9232
evaluation/num steps total     252000
evaluation/num paths total       2520
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.21819
evaluation/Rewards Std              0.970629
evaluation/Rewards Max             -0.0277672
evaluation/Rewards Min            -11.1914
evaluation/Returns Mean           -21.819
evaluation/Returns Std             15.4215
evaluation/Returns Max             -3.21788
evaluation/Returns Min            -62.0607
evaluation/Actions Mean             0.0233709
evaluation/Actions Std              0.197844
evaluation/Actions Max              0.997652
evaluation/Actions Min             -0.995633
evaluation/Num Paths               10
evaluation/Average Returns        -21.819
time/data storing (s)               0.00106253
time/evaluation sampling (s)        0.243241
time/exploration sampling (s)       0.05908
time/logging (s)                    0.00347566
time/saving (s)                     0.00234915
time/training (s)                   0.980214
time/epoch (s)                      1.28942
time/total (s)                    370.391
Epoch                             251
-----------------------------  ---------------
2019-04-21 12:22:36.849277 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 252 finished
-----------------------------  ---------------
replay_buffer/size              50800
trainer/QF1 Loss                    0.0353819
trainer/QF2 Loss                    0.0480571
trainer/Policy Loss                 9.15315
trainer/Q1 Predictions Mean        -7.34865
trainer/Q1 Predictions Std          4.26862
trainer/Q1 Predictions Max         -6.38419
trainer/Q1 Predictions Min        -37.2617
trainer/Q2 Predictions Mean        -7.32968
trainer/Q2 Predictions Std          4.32609
trainer/Q2 Predictions Max         -6.36157
trainer/Q2 Predictions Min        -37.5226
trainer/Q Targets Mean             -7.34633
trainer/Q Targets Std               4.15895
trainer/Q Targets Max              -6.33439
trainer/Q Targets Min             -35.9258
trainer/Log Pis Mean                2.00672
trainer/Log Pis Std                 1.076
trainer/Log Pis Max                 5.84319
trainer/Log Pis Min                -2.28539
trainer/Policy mu Mean              0.0825566
trainer/Policy mu Std               0.585813
trainer/Policy mu Max               3.07525
trainer/Policy mu Min              -1.43818
trainer/Policy log std Mean        -2.20753
trainer/Policy log std Std          0.424369
trainer/Policy log std Max         -0.426196
trainer/Policy log std Min         -2.45556
trainer/Alpha                       0.0555731
trainer/Alpha Loss                  0.0194073
exploration/num steps total     50800
exploration/num paths total       508
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.416777
exploration/Rewards Std             1.19249
exploration/Rewards Max            -0.00655733
exploration/Rewards Min            -8.54109
exploration/Returns Mean          -41.6777
exploration/Returns Std             7.18259
exploration/Returns Max           -34.4951
exploration/Returns Min           -48.8603
exploration/Actions Mean            0.0239063
exploration/Actions Std             0.254672
exploration/Actions Max             0.999437
exploration/Actions Min            -0.974047
exploration/Num Paths               2
exploration/Average Returns       -41.6777
evaluation/num steps total     253000
evaluation/num paths total       2530
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.214223
evaluation/Rewards Std              0.909883
evaluation/Rewards Max             -0.03058
evaluation/Rewards Min             -9.72112
evaluation/Returns Mean           -21.4223
evaluation/Returns Std             15.8591
evaluation/Returns Max             -5.24704
evaluation/Returns Min            -55.4667
evaluation/Actions Mean             0.0255957
evaluation/Actions Std              0.180524
evaluation/Actions Max              0.99635
evaluation/Actions Min             -0.98315
evaluation/Num Paths               10
evaluation/Average Returns        -21.4223
time/data storing (s)               0.00132195
time/evaluation sampling (s)        0.26099
time/exploration sampling (s)       0.069634
time/logging (s)                    0.00342129
time/saving (s)                     0.00230497
time/training (s)                   1.05628
time/epoch (s)                      1.39395
time/total (s)                    371.789
Epoch                             252
-----------------------------  ---------------
2019-04-21 12:22:38.225588 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 253 finished
-----------------------------  ----------------
replay_buffer/size              51000
trainer/QF1 Loss                    0.0111249
trainer/QF2 Loss                    0.0139141
trainer/Policy Loss                 9.02767
trainer/Q1 Predictions Mean        -7.3114
trainer/Q1 Predictions Std          3.90376
trainer/Q1 Predictions Max         -6.39674
trainer/Q1 Predictions Min        -35.5257
trainer/Q2 Predictions Mean        -7.38333
trainer/Q2 Predictions Std          3.99662
trainer/Q2 Predictions Max         -6.42624
trainer/Q2 Predictions Min        -36.4541
trainer/Q Targets Mean             -7.35409
trainer/Q Targets Std               3.93006
trainer/Q Targets Max              -6.30511
trainer/Q Targets Min             -35.723
trainer/Log Pis Mean                1.87884
trainer/Log Pis Std                 1.17948
trainer/Log Pis Max                 6.78651
trainer/Log Pis Min                -1.55303
trainer/Policy mu Mean             -0.0370446
trainer/Policy mu Std               0.563818
trainer/Policy mu Max               2.99833
trainer/Policy mu Min              -3.40066
trainer/Policy log std Mean        -2.17918
trainer/Policy log std Std          0.386492
trainer/Policy log std Max         -0.455076
trainer/Policy log std Min         -2.39182
trainer/Alpha                       0.0543542
trainer/Alpha Loss                 -0.352831
exploration/num steps total     51000
exploration/num paths total       510
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.287255
exploration/Rewards Std             0.744067
exploration/Rewards Max            -0.000720665
exploration/Rewards Min            -5.88785
exploration/Returns Mean          -28.7255
exploration/Returns Std             3.92654
exploration/Returns Max           -24.799
exploration/Returns Min           -32.6521
exploration/Actions Mean           -0.000513878
exploration/Actions Std             0.234318
exploration/Actions Max             0.996464
exploration/Actions Min            -0.996886
exploration/Num Paths               2
exploration/Average Returns       -28.7255
evaluation/num steps total     254000
evaluation/num paths total       2540
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.189856
evaluation/Rewards Std              0.762812
evaluation/Rewards Max             -0.0434911
evaluation/Rewards Min             -9.87253
evaluation/Returns Mean           -18.9856
evaluation/Returns Std             14.3642
evaluation/Returns Max             -9.20088
evaluation/Returns Min            -51.8426
evaluation/Actions Mean             0.0188371
evaluation/Actions Std              0.172048
evaluation/Actions Max              0.996685
evaluation/Actions Min             -0.991808
evaluation/Num Paths               10
evaluation/Average Returns        -18.9856
time/data storing (s)               0.00120389
time/evaluation sampling (s)        0.244734
time/exploration sampling (s)       0.0630282
time/logging (s)                    0.00340417
time/saving (s)                     0.00250119
time/training (s)                   1.05342
time/epoch (s)                      1.36829
time/total (s)                    373.162
Epoch                             253
-----------------------------  ----------------
2019-04-21 12:22:39.590698 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 254 finished
-----------------------------  ---------------
replay_buffer/size              51200
trainer/QF1 Loss                    0.910532
trainer/QF2 Loss                    0.905066
trainer/Policy Loss                 9.92328
trainer/Q1 Predictions Mean        -8.0153
trainer/Q1 Predictions Std          6.50571
trainer/Q1 Predictions Max         -6.35262
trainer/Q1 Predictions Min        -52.0873
trainer/Q2 Predictions Mean        -7.95918
trainer/Q2 Predictions Std          6.48076
trainer/Q2 Predictions Max         -6.30357
trainer/Q2 Predictions Min        -51.0024
trainer/Q Targets Mean             -7.9487
trainer/Q Targets Std               6.61688
trainer/Q Targets Max              -0.112925
trainer/Q Targets Min             -51.4147
trainer/Log Pis Mean                2.16256
trainer/Log Pis Std                 1.33353
trainer/Log Pis Max                 7.89072
trainer/Log Pis Min                -2.70394
trainer/Policy mu Mean              0.0987353
trainer/Policy mu Std               0.69619
trainer/Policy mu Max               3.35869
trainer/Policy mu Min              -2.02735
trainer/Policy log std Mean        -2.17134
trainer/Policy log std Std          0.478059
trainer/Policy log std Max         -0.58709
trainer/Policy log std Min         -2.43946
trainer/Alpha                       0.0533793
trainer/Alpha Loss                  0.47638
exploration/num steps total     51200
exploration/num paths total       512
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.320686
exploration/Rewards Std             1.01473
exploration/Rewards Max            -0.00680769
exploration/Rewards Min            -8.34115
exploration/Returns Mean          -32.0686
exploration/Returns Std            16.4319
exploration/Returns Max           -15.6367
exploration/Returns Min           -48.5006
exploration/Actions Mean            0.0367573
exploration/Actions Std             0.228993
exploration/Actions Max             0.997855
exploration/Actions Min            -0.594278
exploration/Num Paths               2
exploration/Average Returns       -32.0686
evaluation/num steps total     255000
evaluation/num paths total       2550
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.269471
evaluation/Rewards Std              1.0864
evaluation/Rewards Max             -0.0154621
evaluation/Rewards Min            -10.1651
evaluation/Returns Mean           -26.9471
evaluation/Returns Std             17.257
evaluation/Returns Max             -8.53376
evaluation/Returns Min            -60.5656
evaluation/Actions Mean             0.0249545
evaluation/Actions Std              0.194004
evaluation/Actions Max              0.998481
evaluation/Actions Min             -0.99868
evaluation/Num Paths               10
evaluation/Average Returns        -26.9471
time/data storing (s)               0.0011725
time/evaluation sampling (s)        0.256189
time/exploration sampling (s)       0.0702568
time/logging (s)                    0.00340193
time/saving (s)                     0.00228394
time/training (s)                   1.02425
time/epoch (s)                      1.35755
time/total (s)                    374.523
Epoch                             254
-----------------------------  ---------------
2019-04-21 12:22:40.965830 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 255 finished
-----------------------------  ---------------
replay_buffer/size              51400
trainer/QF1 Loss                    0.428127
trainer/QF2 Loss                    0.420037
trainer/Policy Loss                 9.55401
trainer/Q1 Predictions Mean        -7.71155
trainer/Q1 Predictions Std          6.46575
trainer/Q1 Predictions Max         -6.48837
trainer/Q1 Predictions Min        -63.6848
trainer/Q2 Predictions Mean        -7.63299
trainer/Q2 Predictions Std          6.4147
trainer/Q2 Predictions Max         -6.4082
trainer/Q2 Predictions Min        -62.8777
trainer/Q Targets Mean             -7.57406
trainer/Q Targets Std               6.54705
trainer/Q Targets Max              -0.194459
trainer/Q Targets Min             -64.1372
trainer/Log Pis Mean                1.94802
trainer/Log Pis Std                 1.2014
trainer/Log Pis Max                 6.40932
trainer/Log Pis Min                -2.86142
trainer/Policy mu Mean              0.0604429
trainer/Policy mu Std               0.563492
trainer/Policy mu Max               3.29324
trainer/Policy mu Min              -1.5955
trainer/Policy log std Mean        -2.17991
trainer/Policy log std Std          0.381229
trainer/Policy log std Max         -0.560538
trainer/Policy log std Min         -2.40893
trainer/Alpha                       0.0536383
trainer/Alpha Loss                 -0.152053
exploration/num steps total     51400
exploration/num paths total       514
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.605592
exploration/Rewards Std             1.69139
exploration/Rewards Max            -0.00942075
exploration/Rewards Min            -9.87724
exploration/Returns Mean          -60.5592
exploration/Returns Std             5.46894
exploration/Returns Max           -55.0903
exploration/Returns Min           -66.0282
exploration/Actions Mean            0.054438
exploration/Actions Std             0.266376
exploration/Actions Max             0.99971
exploration/Actions Min            -0.664586
exploration/Num Paths               2
exploration/Average Returns       -60.5592
evaluation/num steps total     256000
evaluation/num paths total       2560
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.238401
evaluation/Rewards Std              1.06425
evaluation/Rewards Max             -0.00858062
evaluation/Rewards Min             -9.17847
evaluation/Returns Mean           -23.8401
evaluation/Returns Std             16.7432
evaluation/Returns Max             -2.72049
evaluation/Returns Min            -48.5208
evaluation/Actions Mean             0.0303849
evaluation/Actions Std              0.190617
evaluation/Actions Max              0.997359
evaluation/Actions Min             -0.961882
evaluation/Num Paths               10
evaluation/Average Returns        -23.8401
time/data storing (s)               0.00119942
time/evaluation sampling (s)        0.250905
time/exploration sampling (s)       0.0661093
time/logging (s)                    0.00372302
time/saving (s)                     0.00233256
time/training (s)                   1.04313
time/epoch (s)                      1.3674
time/total (s)                    375.895
Epoch                             255
-----------------------------  ---------------
2019-04-21 12:22:42.291945 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 256 finished
-----------------------------  ---------------
replay_buffer/size              51600
trainer/QF1 Loss                    0.417997
trainer/QF2 Loss                    0.42457
trainer/Policy Loss                 8.32686
trainer/Q1 Predictions Mean        -6.50049
trainer/Q1 Predictions Std          0.489956
trainer/Q1 Predictions Max         -6.26106
trainer/Q1 Predictions Min        -10.6214
trainer/Q2 Predictions Mean        -6.51541
trainer/Q2 Predictions Std          0.510329
trainer/Q2 Predictions Max         -6.26569
trainer/Q2 Predictions Min        -10.8451
trainer/Q Targets Mean             -6.56494
trainer/Q Targets Std               0.814581
trainer/Q Targets Max              -0.0823483
trainer/Q Targets Min             -10.6879
trainer/Log Pis Mean                1.89018
trainer/Log Pis Std                 1.06177
trainer/Log Pis Max                 3.77035
trainer/Log Pis Min                -2.96538
trainer/Policy mu Mean              0.0450792
trainer/Policy mu Std               0.413174
trainer/Policy mu Max               2.61709
trainer/Policy mu Min              -1.41953
trainer/Policy log std Mean        -2.24633
trainer/Policy log std Std          0.328564
trainer/Policy log std Max         -0.761488
trainer/Policy log std Min         -2.42276
trainer/Alpha                       0.0538711
trainer/Alpha Loss                 -0.320808
exploration/num steps total     51600
exploration/num paths total       516
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.297692
exploration/Rewards Std             0.947598
exploration/Rewards Max            -0.00950995
exploration/Rewards Min            -8.30606
exploration/Returns Mean          -29.7692
exploration/Returns Std            13.8874
exploration/Returns Max           -15.8819
exploration/Returns Min           -43.6566
exploration/Actions Mean            0.0453527
exploration/Actions Std             0.240713
exploration/Actions Max             0.998809
exploration/Actions Min            -0.504569
exploration/Num Paths               2
exploration/Average Returns       -29.7692
evaluation/num steps total     257000
evaluation/num paths total       2570
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.162462
evaluation/Rewards Std              0.767001
evaluation/Rewards Max             -0.0152818
evaluation/Rewards Min             -7.96495
evaluation/Returns Mean           -16.2462
evaluation/Returns Std              7.80307
evaluation/Returns Max             -2.59701
evaluation/Returns Min            -30.0498
evaluation/Actions Mean             0.00539729
evaluation/Actions Std              0.189697
evaluation/Actions Max              0.997848
evaluation/Actions Min             -0.996936
evaluation/Num Paths               10
evaluation/Average Returns        -16.2462
time/data storing (s)               0.00109732
time/evaluation sampling (s)        0.248739
time/exploration sampling (s)       0.0606941
time/logging (s)                    0.00340629
time/saving (s)                     0.00232022
time/training (s)                   1.00136
time/epoch (s)                      1.31762
time/total (s)                    377.217
Epoch                             256
-----------------------------  ---------------
2019-04-21 12:22:43.680754 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 257 finished
-----------------------------  ---------------
replay_buffer/size              51800
trainer/QF1 Loss                    0.412649
trainer/QF2 Loss                    0.399307
trainer/Policy Loss                 9.26264
trainer/Q1 Predictions Mean        -7.28169
trainer/Q1 Predictions Std          5.17136
trainer/Q1 Predictions Max         -6.26556
trainer/Q1 Predictions Min        -52.4937
trainer/Q2 Predictions Mean        -7.3178
trainer/Q2 Predictions Std          5.16226
trainer/Q2 Predictions Max         -6.2967
trainer/Q2 Predictions Min        -52.5028
trainer/Q Targets Mean             -7.35215
trainer/Q Targets Std               5.17167
trainer/Q Targets Max              -0.122639
trainer/Q Targets Min             -52.2234
trainer/Log Pis Mean                2.07984
trainer/Log Pis Std                 0.911019
trainer/Log Pis Max                 4.6131
trainer/Log Pis Min                -1.67743
trainer/Policy mu Mean              0.121517
trainer/Policy mu Std               0.531695
trainer/Policy mu Max               3.25017
trainer/Policy mu Min              -1.35808
trainer/Policy log std Mean        -2.22113
trainer/Policy log std Std          0.368451
trainer/Policy log std Max         -0.534555
trainer/Policy log std Min         -2.42029
trainer/Alpha                       0.0535216
trainer/Alpha Loss                  0.233731
exploration/num steps total     51800
exploration/num paths total       518
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.559581
exploration/Rewards Std             1.62001
exploration/Rewards Max            -0.00704818
exploration/Rewards Min           -10.0425
exploration/Returns Mean          -55.9581
exploration/Returns Std             4.33915
exploration/Returns Max           -51.619
exploration/Returns Min           -60.2973
exploration/Actions Mean            0.0670672
exploration/Actions Std             0.270644
exploration/Actions Max             0.999377
exploration/Actions Min            -0.427689
exploration/Num Paths               2
exploration/Average Returns       -55.9581
evaluation/num steps total     258000
evaluation/num paths total       2580
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.228969
evaluation/Rewards Std              0.918775
evaluation/Rewards Max             -0.0228967
evaluation/Rewards Min             -9.14277
evaluation/Returns Mean           -22.8969
evaluation/Returns Std             14.2088
evaluation/Returns Max             -6.32751
evaluation/Returns Min            -51.8934
evaluation/Actions Mean             0.0265934
evaluation/Actions Std              0.185783
evaluation/Actions Max              0.995646
evaluation/Actions Min             -0.974511
evaluation/Num Paths               10
evaluation/Average Returns        -22.8969
time/data storing (s)               0.00132613
time/evaluation sampling (s)        0.256448
time/exploration sampling (s)       0.0708919
time/logging (s)                    0.00355704
time/saving (s)                     0.0111168
time/training (s)                   1.03759
time/epoch (s)                      1.38093
time/total (s)                    378.601
Epoch                             257
-----------------------------  ---------------
2019-04-21 12:22:44.992802 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 258 finished
-----------------------------  ----------------
replay_buffer/size              52000
trainer/QF1 Loss                    0.428712
trainer/QF2 Loss                    0.452416
trainer/Policy Loss                 9.34926
trainer/Q1 Predictions Mean        -7.58509
trainer/Q1 Predictions Std          6.22535
trainer/Q1 Predictions Max         -6.23609
trainer/Q1 Predictions Min        -62.2307
trainer/Q2 Predictions Mean        -7.56111
trainer/Q2 Predictions Std          6.1723
trainer/Q2 Predictions Max         -6.21354
trainer/Q2 Predictions Min        -61.7297
trainer/Q Targets Mean             -7.66664
trainer/Q Targets Std               6.37316
trainer/Q Targets Max              -0.0932097
trainer/Q Targets Min             -63.4319
trainer/Log Pis Mean                1.81996
trainer/Log Pis Std                 1.21443
trainer/Log Pis Max                 6.66892
trainer/Log Pis Min                -3.42367
trainer/Policy mu Mean              0.0747418
trainer/Policy mu Std               0.577254
trainer/Policy mu Max               3.25162
trainer/Policy mu Min              -2.70665
trainer/Policy log std Mean        -2.14653
trainer/Policy log std Std          0.380686
trainer/Policy log std Max         -0.616115
trainer/Policy log std Min         -2.33114
trainer/Alpha                       0.0537524
trainer/Alpha Loss                 -0.526298
exploration/num steps total     52000
exploration/num paths total       520
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.277927
exploration/Rewards Std             0.675047
exploration/Rewards Max            -0.0158766
exploration/Rewards Min            -5.47638
exploration/Returns Mean          -27.7927
exploration/Returns Std             2.9646
exploration/Returns Max           -24.8281
exploration/Returns Min           -30.7573
exploration/Actions Mean            0.000660179
exploration/Actions Std             0.225106
exploration/Actions Max             0.993472
exploration/Actions Min            -0.995247
exploration/Num Paths               2
exploration/Average Returns       -27.7927
evaluation/num steps total     259000
evaluation/num paths total       2590
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.300897
evaluation/Rewards Std              1.08521
evaluation/Rewards Max             -0.0323178
evaluation/Rewards Min            -10.9786
evaluation/Returns Mean           -30.0897
evaluation/Returns Std             15.5811
evaluation/Returns Max             -8.13782
evaluation/Returns Min            -63.7178
evaluation/Actions Mean             0.0286378
evaluation/Actions Std              0.208599
evaluation/Actions Max              0.997812
evaluation/Actions Min             -0.997724
evaluation/Num Paths               10
evaluation/Average Returns        -30.0897
time/data storing (s)               0.00118797
time/evaluation sampling (s)        0.244384
time/exploration sampling (s)       0.0635511
time/logging (s)                    0.00344125
time/saving (s)                     0.00230862
time/training (s)                   0.989359
time/epoch (s)                      1.30423
time/total (s)                    379.91
Epoch                             258
-----------------------------  ----------------
2019-04-21 12:22:46.290182 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 259 finished
-----------------------------  ---------------
replay_buffer/size              52200
trainer/QF1 Loss                    0.410828
trainer/QF2 Loss                    0.409967
trainer/Policy Loss                 8.93492
trainer/Q1 Predictions Mean        -6.96735
trainer/Q1 Predictions Std          2.90442
trainer/Q1 Predictions Max         -6.36385
trainer/Q1 Predictions Min        -34.7418
trainer/Q2 Predictions Mean        -6.94859
trainer/Q2 Predictions Std          2.92016
trainer/Q2 Predictions Max         -6.35719
trainer/Q2 Predictions Min        -34.8345
trainer/Q Targets Mean             -6.91598
trainer/Q Targets Std               3.01372
trainer/Q Targets Max              -0.0233809
trainer/Q Targets Min             -35.0092
trainer/Log Pis Mean                2.04912
trainer/Log Pis Std                 1.10405
trainer/Log Pis Max                 5.6397
trainer/Log Pis Min                -2.13442
trainer/Policy mu Mean              0.059333
trainer/Policy mu Std               0.506325
trainer/Policy mu Max               2.97204
trainer/Policy mu Min              -1.59118
trainer/Policy log std Mean        -2.23717
trainer/Policy log std Std          0.374818
trainer/Policy log std Max         -0.646984
trainer/Policy log std Min         -2.40042
trainer/Alpha                       0.0540729
trainer/Alpha Loss                  0.143303
exploration/num steps total     52200
exploration/num paths total       522
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.224601
exploration/Rewards Std             0.622146
exploration/Rewards Max            -0.011224
exploration/Rewards Min            -5.91932
exploration/Returns Mean          -22.4601
exploration/Returns Std             4.55396
exploration/Returns Max           -17.9061
exploration/Returns Min           -27.0141
exploration/Actions Mean            0.0154103
exploration/Actions Std             0.224665
exploration/Actions Max             0.997907
exploration/Actions Min            -0.994234
exploration/Num Paths               2
exploration/Average Returns       -22.4601
evaluation/num steps total     260000
evaluation/num paths total       2600
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.288462
evaluation/Rewards Std              1.14119
evaluation/Rewards Max             -0.0251725
evaluation/Rewards Min             -9.50292
evaluation/Returns Mean           -28.8462
evaluation/Returns Std             12.2792
evaluation/Returns Max            -11.4106
evaluation/Returns Min            -52.5644
evaluation/Actions Mean             0.0358278
evaluation/Actions Std              0.211112
evaluation/Actions Max              0.997146
evaluation/Actions Min             -0.992474
evaluation/Num Paths               10
evaluation/Average Returns        -28.8462
time/data storing (s)               0.00114613
time/evaluation sampling (s)        0.244166
time/exploration sampling (s)       0.06105
time/logging (s)                    0.00338308
time/saving (s)                     0.00236021
time/training (s)                   0.977129
time/epoch (s)                      1.28923
time/total (s)                    381.203
Epoch                             259
-----------------------------  ---------------
2019-04-21 12:22:47.638269 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 260 finished
-----------------------------  ---------------
replay_buffer/size              52400
trainer/QF1 Loss                    1.19037
trainer/QF2 Loss                    1.20184
trainer/Policy Loss                 8.57708
trainer/Q1 Predictions Mean        -6.74403
trainer/Q1 Predictions Std          2.53315
trainer/Q1 Predictions Max         -6.12274
trainer/Q1 Predictions Min        -29.8007
trainer/Q2 Predictions Mean        -6.74198
trainer/Q2 Predictions Std          2.50998
trainer/Q2 Predictions Max         -6.11427
trainer/Q2 Predictions Min        -29.622
trainer/Q Targets Mean             -6.81641
trainer/Q Targets Std               2.86469
trainer/Q Targets Max              -0.0488255
trainer/Q Targets Min             -30.922
trainer/Log Pis Mean                1.95162
trainer/Log Pis Std                 1.12173
trainer/Log Pis Max                 6.25376
trainer/Log Pis Min                -1.60212
trainer/Policy mu Mean              0.0322906
trainer/Policy mu Std               0.530713
trainer/Policy mu Max               2.86405
trainer/Policy mu Min              -2.16095
trainer/Policy log std Mean        -2.18225
trainer/Policy log std Std          0.382405
trainer/Policy log std Max         -0.616954
trainer/Policy log std Min         -2.38416
trainer/Alpha                       0.0542943
trainer/Alpha Loss                 -0.140955
exploration/num steps total     52400
exploration/num paths total       524
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.546147
exploration/Rewards Std             1.58779
exploration/Rewards Max            -0.00715041
exploration/Rewards Min            -9.61235
exploration/Returns Mean          -54.6147
exploration/Returns Std             5.38258
exploration/Returns Max           -49.2321
exploration/Returns Min           -59.9973
exploration/Actions Mean            0.0500283
exploration/Actions Std             0.263762
exploration/Actions Max             0.998987
exploration/Actions Min            -0.984559
exploration/Num Paths               2
exploration/Average Returns       -54.6147
evaluation/num steps total     261000
evaluation/num paths total       2610
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.181058
evaluation/Rewards Std              0.920776
evaluation/Rewards Max             -0.00130652
evaluation/Rewards Min             -8.34901
evaluation/Returns Mean           -18.1058
evaluation/Returns Std             12.899
evaluation/Returns Max             -0.428348
evaluation/Returns Min            -37.849
evaluation/Actions Mean             0.0277234
evaluation/Actions Std              0.185069
evaluation/Actions Max              0.995854
evaluation/Actions Min             -0.993304
evaluation/Num Paths               10
evaluation/Average Returns        -18.1058
time/data storing (s)               0.00113563
time/evaluation sampling (s)        0.248118
time/exploration sampling (s)       0.0593912
time/logging (s)                    0.00344383
time/saving (s)                     0.00232062
time/training (s)                   1.02564
time/epoch (s)                      1.34005
time/total (s)                    382.547
Epoch                             260
-----------------------------  ---------------
2019-04-21 12:22:48.953063 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 261 finished
-----------------------------  ---------------
replay_buffer/size              52600
trainer/QF1 Loss                    0.0116518
trainer/QF2 Loss                    0.0210768
trainer/Policy Loss                 8.75584
trainer/Q1 Predictions Mean        -6.8507
trainer/Q1 Predictions Std          1.77415
trainer/Q1 Predictions Max         -6.32953
trainer/Q1 Predictions Min        -17.1696
trainer/Q2 Predictions Mean        -6.82495
trainer/Q2 Predictions Std          1.72504
trainer/Q2 Predictions Max         -6.32497
trainer/Q2 Predictions Min        -16.9478
trainer/Q Targets Mean             -6.87573
trainer/Q Targets Std               1.83602
trainer/Q Targets Max              -6.27075
trainer/Q Targets Min             -17.5105
trainer/Log Pis Mean                1.99605
trainer/Log Pis Std                 0.933251
trainer/Log Pis Max                 5.62431
trainer/Log Pis Min                -0.792518
trainer/Policy mu Mean              0.0020854
trainer/Policy mu Std               0.482949
trainer/Policy mu Max               2.76328
trainer/Policy mu Min              -2.79241
trainer/Policy log std Mean        -2.21256
trainer/Policy log std Std          0.348716
trainer/Policy log std Max         -0.534818
trainer/Policy log std Min         -2.37904
trainer/Alpha                       0.0541674
trainer/Alpha Loss                 -0.0115266
exploration/num steps total     52600
exploration/num paths total       526
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.297758
exploration/Rewards Std             0.838393
exploration/Rewards Max            -0.0163974
exploration/Rewards Min            -6.30034
exploration/Returns Mean          -29.7758
exploration/Returns Std             0.966851
exploration/Returns Max           -28.8089
exploration/Returns Min           -30.7426
exploration/Actions Mean            0.0178064
exploration/Actions Std             0.241222
exploration/Actions Max             0.99872
exploration/Actions Min            -0.998287
exploration/Num Paths               2
exploration/Average Returns       -29.7758
evaluation/num steps total     262000
evaluation/num paths total       2620
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.198856
evaluation/Rewards Std              0.8664
evaluation/Rewards Max             -0.0397952
evaluation/Rewards Min             -9.28664
evaluation/Returns Mean           -19.8856
evaluation/Returns Std             14.4711
evaluation/Returns Max             -6.25412
evaluation/Returns Min            -51.9409
evaluation/Actions Mean             0.0208962
evaluation/Actions Std              0.180656
evaluation/Actions Max              0.997033
evaluation/Actions Min             -0.972788
evaluation/Num Paths               10
evaluation/Average Returns        -19.8856
time/data storing (s)               0.00146994
time/evaluation sampling (s)        0.242512
time/exploration sampling (s)       0.0617993
time/logging (s)                    0.00295966
time/saving (s)                     0.00232978
time/training (s)                   0.995126
time/epoch (s)                      1.3062
time/total (s)                    383.858
Epoch                             261
-----------------------------  ---------------
2019-04-21 12:22:50.307500 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 262 finished
-----------------------------  ---------------
replay_buffer/size              52800
trainer/QF1 Loss                    0.0362158
trainer/QF2 Loss                    0.0328139
trainer/Policy Loss                 8.5976
trainer/Q1 Predictions Mean        -6.71078
trainer/Q1 Predictions Std          1.87536
trainer/Q1 Predictions Max         -6.20503
trainer/Q1 Predictions Min        -20.3663
trainer/Q2 Predictions Mean        -6.71695
trainer/Q2 Predictions Std          1.86667
trainer/Q2 Predictions Max         -6.22948
trainer/Q2 Predictions Min        -20.3067
trainer/Q Targets Mean             -6.843
trainer/Q Targets Std               1.80286
trainer/Q Targets Max              -6.25819
trainer/Q Targets Min             -19.3407
trainer/Log Pis Mean                1.9697
trainer/Log Pis Std                 1.06193
trainer/Log Pis Max                 3.78741
trainer/Log Pis Min                -1.62931
trainer/Policy mu Mean              0.0818225
trainer/Policy mu Std               0.425439
trainer/Policy mu Max               3.35693
trainer/Policy mu Min              -1.35923
trainer/Policy log std Mean        -2.27871
trainer/Policy log std Std          0.297467
trainer/Policy log std Max         -0.38835
trainer/Policy log std Min         -2.42626
trainer/Alpha                       0.05552
trainer/Alpha Loss                 -0.0875915
exploration/num steps total     52800
exploration/num paths total       528
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.235085
exploration/Rewards Std             0.632513
exploration/Rewards Max            -0.00490228
exploration/Rewards Min            -5.20892
exploration/Returns Mean          -23.5085
exploration/Returns Std             4.01738
exploration/Returns Max           -19.4911
exploration/Returns Min           -27.5258
exploration/Actions Mean            0.00492922
exploration/Actions Std             0.209612
exploration/Actions Max             0.998038
exploration/Actions Min            -0.997398
exploration/Num Paths               2
exploration/Average Returns       -23.5085
evaluation/num steps total     263000
evaluation/num paths total       2630
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.16946
evaluation/Rewards Std              0.809462
evaluation/Rewards Max             -0.00619651
evaluation/Rewards Min             -9.41531
evaluation/Returns Mean           -16.946
evaluation/Returns Std              9.3361
evaluation/Returns Max             -4.19555
evaluation/Returns Min            -42.2429
evaluation/Actions Mean             0.021814
evaluation/Actions Std              0.190877
evaluation/Actions Max              0.997818
evaluation/Actions Min             -0.997097
evaluation/Num Paths               10
evaluation/Average Returns        -16.946
time/data storing (s)               0.00135309
time/evaluation sampling (s)        0.243068
time/exploration sampling (s)       0.0625701
time/logging (s)                    0.0035443
time/saving (s)                     0.00255092
time/training (s)                   1.0337
time/epoch (s)                      1.34679
time/total (s)                    385.209
Epoch                             262
-----------------------------  ---------------
2019-04-21 12:22:51.656875 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 263 finished
-----------------------------  ---------------
replay_buffer/size              53000
trainer/QF1 Loss                    0.0407647
trainer/QF2 Loss                    0.0265869
trainer/Policy Loss                 8.30181
trainer/Q1 Predictions Mean        -6.67185
trainer/Q1 Predictions Std          2.21153
trainer/Q1 Predictions Max         -6.17448
trainer/Q1 Predictions Min        -26.9869
trainer/Q2 Predictions Mean        -6.73175
trainer/Q2 Predictions Std          2.2002
trainer/Q2 Predictions Max         -6.24381
trainer/Q2 Predictions Min        -26.8572
trainer/Q Targets Mean             -6.85042
trainer/Q Targets Std               2.24085
trainer/Q Targets Max              -6.28797
trainer/Q Targets Min             -27.5886
trainer/Log Pis Mean                1.80762
trainer/Log Pis Std                 0.966638
trainer/Log Pis Max                 3.78735
trainer/Log Pis Min                -2.26959
trainer/Policy mu Mean             -0.00743806
trainer/Policy mu Std               0.388384
trainer/Policy mu Max               3.07763
trainer/Policy mu Min              -1.45296
trainer/Policy log std Mean        -2.22179
trainer/Policy log std Std          0.293489
trainer/Policy log std Max         -0.300508
trainer/Policy log std Min         -2.36088
trainer/Alpha                       0.0557911
trainer/Alpha Loss                 -0.555212
exploration/num steps total     53000
exploration/num paths total       530
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.363716
exploration/Rewards Std             1.13002
exploration/Rewards Max            -0.0146751
exploration/Rewards Min            -8.86592
exploration/Returns Mean          -36.3716
exploration/Returns Std            10.8489
exploration/Returns Max           -25.5227
exploration/Returns Min           -47.2205
exploration/Actions Mean            0.0593475
exploration/Actions Std             0.25742
exploration/Actions Max             0.998453
exploration/Actions Min            -0.476334
exploration/Num Paths               2
exploration/Average Returns       -36.3716
evaluation/num steps total     264000
evaluation/num paths total       2640
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.158355
evaluation/Rewards Std              0.760313
evaluation/Rewards Max             -0.00571415
evaluation/Rewards Min             -7.60079
evaluation/Returns Mean           -15.8355
evaluation/Returns Std              9.06715
evaluation/Returns Max             -1.68647
evaluation/Returns Min            -32.5553
evaluation/Actions Mean             0.0268469
evaluation/Actions Std              0.181888
evaluation/Actions Max              0.996147
evaluation/Actions Min             -0.993087
evaluation/Num Paths               10
evaluation/Average Returns        -15.8355
time/data storing (s)               0.00143657
time/evaluation sampling (s)        0.256625
time/exploration sampling (s)       0.0663355
time/logging (s)                    0.0034176
time/saving (s)                     0.00187548
time/training (s)                   1.01155
time/epoch (s)                      1.34124
time/total (s)                    386.554
Epoch                             263
-----------------------------  ---------------
2019-04-21 12:22:52.981515 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 264 finished
-----------------------------  ---------------
replay_buffer/size              53200
trainer/QF1 Loss                    1.58313
trainer/QF2 Loss                    1.58409
trainer/Policy Loss                 9.21644
trainer/Q1 Predictions Mean        -7.41943
trainer/Q1 Predictions Std          3.73523
trainer/Q1 Predictions Max         -6.28262
trainer/Q1 Predictions Min        -31.7603
trainer/Q2 Predictions Mean        -7.43382
trainer/Q2 Predictions Std          3.72664
trainer/Q2 Predictions Max         -6.30228
trainer/Q2 Predictions Min        -31.7564
trainer/Q Targets Mean             -7.21473
trainer/Q Targets Std               4.02915
trainer/Q Targets Max              -0.00781419
trainer/Q Targets Min             -32.5639
trainer/Log Pis Mean                2.0128
trainer/Log Pis Std                 1.23523
trainer/Log Pis Max                 6.36094
trainer/Log Pis Min                -3.66915
trainer/Policy mu Mean              0.104774
trainer/Policy mu Std               0.613341
trainer/Policy mu Max               2.78319
trainer/Policy mu Min              -2.0766
trainer/Policy log std Mean        -2.1926
trainer/Policy log std Std          0.437528
trainer/Policy log std Max         -0.642438
trainer/Policy log std Min         -2.42296
trainer/Alpha                       0.0548806
trainer/Alpha Loss                  0.0371565
exploration/num steps total     53200
exploration/num paths total       532
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.144439
exploration/Rewards Std             0.263989
exploration/Rewards Max            -0.00391533
exploration/Rewards Min            -3.26513
exploration/Returns Mean          -14.4439
exploration/Returns Std             2.69044
exploration/Returns Max           -11.7534
exploration/Returns Min           -17.1343
exploration/Actions Mean           -0.0051715
exploration/Actions Std             0.180865
exploration/Actions Max             0.979634
exploration/Actions Min            -0.987388
exploration/Num Paths               2
exploration/Average Returns       -14.4439
evaluation/num steps total     265000
evaluation/num paths total       2650
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.113074
evaluation/Rewards Std              0.681312
evaluation/Rewards Max             -0.00299852
evaluation/Rewards Min             -9.37796
evaluation/Returns Mean           -11.3074
evaluation/Returns Std             12.6019
evaluation/Returns Max             -1.337
evaluation/Returns Min            -45.4278
evaluation/Actions Mean             0.011009
evaluation/Actions Std              0.159458
evaluation/Actions Max              0.997133
evaluation/Actions Min             -0.997605
evaluation/Num Paths               10
evaluation/Average Returns        -11.3074
time/data storing (s)               0.00117508
time/evaluation sampling (s)        0.251812
time/exploration sampling (s)       0.0632623
time/logging (s)                    0.00341198
time/saving (s)                     0.00235575
time/training (s)                   0.994255
time/epoch (s)                      1.31627
time/total (s)                    387.875
Epoch                             264
-----------------------------  ---------------
2019-04-21 12:22:54.319909 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 265 finished
-----------------------------  ---------------
replay_buffer/size              53400
trainer/QF1 Loss                    0.0136123
trainer/QF2 Loss                    0.0240424
trainer/Policy Loss                 9.21848
trainer/Q1 Predictions Mean        -7.50804
trainer/Q1 Predictions Std          5.59006
trainer/Q1 Predictions Max         -6.2676
trainer/Q1 Predictions Min        -52.6876
trainer/Q2 Predictions Mean        -7.46305
trainer/Q2 Predictions Std          5.57876
trainer/Q2 Predictions Max         -6.2209
trainer/Q2 Predictions Min        -52.5338
trainer/Q Targets Mean             -7.58344
trainer/Q Targets Std               5.57277
trainer/Q Targets Max              -6.24454
trainer/Q Targets Min             -52.6848
trainer/Log Pis Mean                1.88307
trainer/Log Pis Std                 1.1461
trainer/Log Pis Max                 5.15358
trainer/Log Pis Min                -2.20956
trainer/Policy mu Mean              0.0379245
trainer/Policy mu Std               0.623435
trainer/Policy mu Max               3.12433
trainer/Policy mu Min              -2.09891
trainer/Policy log std Mean        -2.1558
trainer/Policy log std Std          0.44701
trainer/Policy log std Max         -0.58056
trainer/Policy log std Min         -2.46383
trainer/Alpha                       0.0557438
trainer/Alpha Loss                 -0.337555
exploration/num steps total     53400
exploration/num paths total       534
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.284188
exploration/Rewards Std             0.927484
exploration/Rewards Max            -0.00467744
exploration/Rewards Min            -7.91114
exploration/Returns Mean          -28.4188
exploration/Returns Std            16.3378
exploration/Returns Max           -12.0809
exploration/Returns Min           -44.7566
exploration/Actions Mean            0.0313862
exploration/Actions Std             0.208109
exploration/Actions Max             0.998708
exploration/Actions Min            -0.439268
exploration/Num Paths               2
exploration/Average Returns       -28.4188
evaluation/num steps total     266000
evaluation/num paths total       2660
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.262609
evaluation/Rewards Std              1.0437
evaluation/Rewards Max             -0.0268738
evaluation/Rewards Min            -10.3681
evaluation/Returns Mean           -26.2609
evaluation/Returns Std             16.3449
evaluation/Returns Max             -8.40041
evaluation/Returns Min            -60.1987
evaluation/Actions Mean             0.014777
evaluation/Actions Std              0.200271
evaluation/Actions Max              0.997784
evaluation/Actions Min             -0.997222
evaluation/Num Paths               10
evaluation/Average Returns        -26.2609
time/data storing (s)               0.0013343
time/evaluation sampling (s)        0.253013
time/exploration sampling (s)       0.0648787
time/logging (s)                    0.00351334
time/saving (s)                     0.00232395
time/training (s)                   1.00605
time/epoch (s)                      1.33112
time/total (s)                    389.209
Epoch                             265
-----------------------------  ---------------
2019-04-21 12:22:55.666167 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 266 finished
-----------------------------  ---------------
replay_buffer/size              53600
trainer/QF1 Loss                    0.401372
trainer/QF2 Loss                    0.402787
trainer/Policy Loss                 8.56326
trainer/Q1 Predictions Mean        -6.54982
trainer/Q1 Predictions Std          0.495083
trainer/Q1 Predictions Max         -6.27729
trainer/Q1 Predictions Min         -9.50226
trainer/Q2 Predictions Mean        -6.52495
trainer/Q2 Predictions Std          0.511873
trainer/Q2 Predictions Max         -6.2316
trainer/Q2 Predictions Min         -9.66253
trainer/Q Targets Mean             -6.54665
trainer/Q Targets Std               0.816593
trainer/Q Targets Max              -0.0453797
trainer/Q Targets Min              -9.72424
trainer/Log Pis Mean                2.12084
trainer/Log Pis Std                 0.880779
trainer/Log Pis Max                 4.19051
trainer/Log Pis Min                -0.736304
trainer/Policy mu Mean              0.0106347
trainer/Policy mu Std               0.43639
trainer/Policy mu Max               2.50629
trainer/Policy mu Min              -1.6437
trainer/Policy log std Mean        -2.27183
trainer/Policy log std Std          0.343603
trainer/Policy log std Max         -0.789041
trainer/Policy log std Min         -2.45467
trainer/Alpha                       0.054703
trainer/Alpha Loss                  0.351153
exploration/num steps total     53600
exploration/num paths total       536
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.235633
exploration/Rewards Std             0.643139
exploration/Rewards Max            -0.00498107
exploration/Rewards Min            -5.69627
exploration/Returns Mean          -23.5633
exploration/Returns Std             7.38961
exploration/Returns Max           -16.1737
exploration/Returns Min           -30.9529
exploration/Actions Mean            0.0275231
exploration/Actions Std             0.201352
exploration/Actions Max             0.994751
exploration/Actions Min            -0.552216
exploration/Num Paths               2
exploration/Average Returns       -23.5633
evaluation/num steps total     267000
evaluation/num paths total       2670
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.225774
evaluation/Rewards Std              0.953217
evaluation/Rewards Max             -0.0342895
evaluation/Rewards Min             -9.75648
evaluation/Returns Mean           -22.5774
evaluation/Returns Std             13.0049
evaluation/Returns Max             -3.44729
evaluation/Returns Min            -50.5812
evaluation/Actions Mean             0.0242373
evaluation/Actions Std              0.189413
evaluation/Actions Max              0.997377
evaluation/Actions Min             -0.997734
evaluation/Num Paths               10
evaluation/Average Returns        -22.5774
time/data storing (s)               0.00129873
time/evaluation sampling (s)        0.244222
time/exploration sampling (s)       0.0656955
time/logging (s)                    0.00344412
time/saving (s)                     0.0018747
time/training (s)                   1.02149
time/epoch (s)                      1.33802
time/total (s)                    390.551
Epoch                             266
-----------------------------  ---------------
2019-04-21 12:22:56.995288 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 267 finished
-----------------------------  ---------------
replay_buffer/size              53800
trainer/QF1 Loss                    0.00776916
trainer/QF2 Loss                    0.00619344
trainer/Policy Loss                 8.54391
trainer/Q1 Predictions Mean        -6.70962
trainer/Q1 Predictions Std          1.04496
trainer/Q1 Predictions Max         -6.28274
trainer/Q1 Predictions Min        -12.2147
trainer/Q2 Predictions Mean        -6.76659
trainer/Q2 Predictions Std          1.06062
trainer/Q2 Predictions Max         -6.36737
trainer/Q2 Predictions Min        -12.2443
trainer/Q Targets Mean             -6.756
trainer/Q Targets Std               1.08088
trainer/Q Targets Max              -6.26621
trainer/Q Targets Min             -12.2937
trainer/Log Pis Mean                1.90442
trainer/Log Pis Std                 1.17055
trainer/Log Pis Max                 4.07181
trainer/Log Pis Min                -2.32898
trainer/Policy mu Mean              0.0486059
trainer/Policy mu Std               0.469333
trainer/Policy mu Max               2.7146
trainer/Policy mu Min              -2.32353
trainer/Policy log std Mean        -2.27388
trainer/Policy log std Std          0.353745
trainer/Policy log std Max         -0.79036
trainer/Policy log std Min         -2.48078
trainer/Alpha                       0.0529383
trainer/Alpha Loss                 -0.280874
exploration/num steps total     53800
exploration/num paths total       538
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.216196
exploration/Rewards Std             0.580571
exploration/Rewards Max            -0.0135405
exploration/Rewards Min            -5.33969
exploration/Returns Mean          -21.6196
exploration/Returns Std             4.11965
exploration/Returns Max           -17.5
exploration/Returns Min           -25.7393
exploration/Actions Mean            0.0155268
exploration/Actions Std             0.211808
exploration/Actions Max             0.997254
exploration/Actions Min            -0.971895
exploration/Num Paths               2
exploration/Average Returns       -21.6196
evaluation/num steps total     268000
evaluation/num paths total       2680
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.224529
evaluation/Rewards Std              1.02245
evaluation/Rewards Max             -0.0103974
evaluation/Rewards Min             -9.84955
evaluation/Returns Mean           -22.4529
evaluation/Returns Std             17.3675
evaluation/Returns Max             -4.34537
evaluation/Returns Min            -54.889
evaluation/Actions Mean             0.0249526
evaluation/Actions Std              0.188929
evaluation/Actions Max              0.995962
evaluation/Actions Min             -0.997252
evaluation/Num Paths               10
evaluation/Average Returns        -22.4529
time/data storing (s)               0.00117996
time/evaluation sampling (s)        0.252133
time/exploration sampling (s)       0.071005
time/logging (s)                    0.00345603
time/saving (s)                     0.00233468
time/training (s)                   0.990849
time/epoch (s)                      1.32096
time/total (s)                    391.876
Epoch                             267
-----------------------------  ---------------
2019-04-21 12:22:58.301199 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 268 finished
-----------------------------  ---------------
replay_buffer/size              54000
trainer/QF1 Loss                    0.0139246
trainer/QF2 Loss                    0.0122614
trainer/Policy Loss                 9.08709
trainer/Q1 Predictions Mean        -7.45592
trainer/Q1 Predictions Std          4.40031
trainer/Q1 Predictions Max         -6.28617
trainer/Q1 Predictions Min        -34.9448
trainer/Q2 Predictions Mean        -7.48988
trainer/Q2 Predictions Std          4.4474
trainer/Q2 Predictions Max         -6.31108
trainer/Q2 Predictions Min        -35.3682
trainer/Q Targets Mean             -7.5091
trainer/Q Targets Std               4.42974
trainer/Q Targets Max              -6.26371
trainer/Q Targets Min             -35.5983
trainer/Log Pis Mean                1.80291
trainer/Log Pis Std                 1.55622
trainer/Log Pis Max                 6.68324
trainer/Log Pis Min                -2.67874
trainer/Policy mu Mean              0.0131454
trainer/Policy mu Std               0.63083
trainer/Policy mu Max               2.8306
trainer/Policy mu Min              -3.36085
trainer/Policy log std Mean        -2.13939
trainer/Policy log std Std          0.430578
trainer/Policy log std Max         -0.555029
trainer/Policy log std Min         -2.3924
trainer/Alpha                       0.0539711
trainer/Alpha Loss                 -0.575337
exploration/num steps total     54000
exploration/num paths total       540
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.217553
exploration/Rewards Std             0.618111
exploration/Rewards Max            -0.0100533
exploration/Rewards Min            -6.2541
exploration/Returns Mean          -21.7553
exploration/Returns Std             8.00003
exploration/Returns Max           -13.7553
exploration/Returns Min           -29.7553
exploration/Actions Mean            0.026353
exploration/Actions Std             0.206148
exploration/Actions Max             0.998289
exploration/Actions Min            -0.41859
exploration/Num Paths               2
exploration/Average Returns       -21.7553
evaluation/num steps total     269000
evaluation/num paths total       2690
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.326173
evaluation/Rewards Std              1.2469
evaluation/Rewards Max             -0.0109091
evaluation/Rewards Min             -9.29657
evaluation/Returns Mean           -32.6173
evaluation/Returns Std             14.7294
evaluation/Returns Max             -8.67701
evaluation/Returns Min            -51.2718
evaluation/Actions Mean             0.0302334
evaluation/Actions Std              0.221653
evaluation/Actions Max              0.996418
evaluation/Actions Min             -0.985631
evaluation/Num Paths               10
evaluation/Average Returns        -32.6173
time/data storing (s)               0.0010681
time/evaluation sampling (s)        0.244378
time/exploration sampling (s)       0.0583331
time/logging (s)                    0.00346687
time/saving (s)                     0.00238823
time/training (s)                   0.988105
time/epoch (s)                      1.29774
time/total (s)                    393.178
Epoch                             268
-----------------------------  ---------------
2019-04-21 12:22:59.670518 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 269 finished
-----------------------------  ---------------
replay_buffer/size              54200
trainer/QF1 Loss                    1.16553
trainer/QF2 Loss                    1.14103
trainer/Policy Loss                 9.04091
trainer/Q1 Predictions Mean        -7.2834
trainer/Q1 Predictions Std          5.49389
trainer/Q1 Predictions Max         -6.28047
trainer/Q1 Predictions Min        -56.8661
trainer/Q2 Predictions Mean        -7.22341
trainer/Q2 Predictions Std          5.52399
trainer/Q2 Predictions Max         -6.20164
trainer/Q2 Predictions Min        -57.1096
trainer/Q Targets Mean             -7.1214
trainer/Q Targets Std               5.59477
trainer/Q Targets Max              -0.169682
trainer/Q Targets Min             -56.8681
trainer/Log Pis Mean                1.9675
trainer/Log Pis Std                 0.962721
trainer/Log Pis Max                 4.60679
trainer/Log Pis Min                -0.487613
trainer/Policy mu Mean             -0.011391
trainer/Policy mu Std               0.503973
trainer/Policy mu Max               3.05941
trainer/Policy mu Min              -2.38635
trainer/Policy log std Mean        -2.24121
trainer/Policy log std Std          0.354162
trainer/Policy log std Max         -0.785879
trainer/Policy log std Min         -2.43314
trainer/Alpha                       0.055948
trainer/Alpha Loss                 -0.0937134
exploration/num steps total     54200
exploration/num paths total       542
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.421218
exploration/Rewards Std             1.32199
exploration/Rewards Max            -0.00445631
exploration/Rewards Min           -10.0028
exploration/Returns Mean          -42.1218
exploration/Returns Std            20.9189
exploration/Returns Max           -21.2029
exploration/Returns Min           -63.0407
exploration/Actions Mean            0.0476327
exploration/Actions Std             0.243957
exploration/Actions Max             0.998663
exploration/Actions Min            -0.669185
exploration/Num Paths               2
exploration/Average Returns       -42.1218
evaluation/num steps total     270000
evaluation/num paths total       2700
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.234148
evaluation/Rewards Std              0.921396
evaluation/Rewards Max             -0.0569191
evaluation/Rewards Min             -9.69358
evaluation/Returns Mean           -23.4148
evaluation/Returns Std             13.3758
evaluation/Returns Max             -6.73206
evaluation/Returns Min            -54.1596
evaluation/Actions Mean             0.0257952
evaluation/Actions Std              0.196686
evaluation/Actions Max              0.997149
evaluation/Actions Min             -0.994186
evaluation/Num Paths               10
evaluation/Average Returns        -23.4148
time/data storing (s)               0.00118891
time/evaluation sampling (s)        0.273254
time/exploration sampling (s)       0.0674039
time/logging (s)                    0.00343391
time/saving (s)                     0.00208279
time/training (s)                   1.0144
time/epoch (s)                      1.36176
time/total (s)                    394.544
Epoch                             269
-----------------------------  ---------------
2019-04-21 12:23:01.052334 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 270 finished
-----------------------------  ---------------
replay_buffer/size              54400
trainer/QF1 Loss                    0.529585
trainer/QF2 Loss                    0.456252
trainer/Policy Loss                11.1381
trainer/Q1 Predictions Mean        -8.97985
trainer/Q1 Predictions Std          7.92797
trainer/Q1 Predictions Max         -6.17428
trainer/Q1 Predictions Min        -53.4848
trainer/Q2 Predictions Mean        -9.03846
trainer/Q2 Predictions Std          7.99728
trainer/Q2 Predictions Max         -6.21633
trainer/Q2 Predictions Min        -55.0122
trainer/Q Targets Mean             -9.0711
trainer/Q Targets Std               8.16991
trainer/Q Targets Max              -0.103447
trainer/Q Targets Min             -56.4775
trainer/Log Pis Mean                2.39918
trainer/Log Pis Std                 1.43488
trainer/Log Pis Max                 7.4986
trainer/Log Pis Min                -2.43901
trainer/Policy mu Mean              0.185326
trainer/Policy mu Std               0.886465
trainer/Policy mu Max               3.434
trainer/Policy mu Min              -3.25623
trainer/Policy log std Mean        -2.08089
trainer/Policy log std Std          0.581496
trainer/Policy log std Max         -0.404259
trainer/Policy log std Min         -2.46269
trainer/Alpha                       0.0557406
trainer/Alpha Loss                  1.15252
exploration/num steps total     54400
exploration/num paths total       544
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.417491
exploration/Rewards Std             1.22481
exploration/Rewards Max            -0.00307721
exploration/Rewards Min            -8.14401
exploration/Returns Mean          -41.7491
exploration/Returns Std             5.65493
exploration/Returns Max           -36.0941
exploration/Returns Min           -47.404
exploration/Actions Mean            0.0555971
exploration/Actions Std             0.248511
exploration/Actions Max             0.999199
exploration/Actions Min            -0.368981
exploration/Num Paths               2
exploration/Average Returns       -41.7491
evaluation/num steps total     271000
evaluation/num paths total       2710
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.216485
evaluation/Rewards Std              1.06074
evaluation/Rewards Max             -0.00384987
evaluation/Rewards Min             -9.95758
evaluation/Returns Mean           -21.6485
evaluation/Returns Std             15.7858
evaluation/Returns Max             -4.7594
evaluation/Returns Min            -47.4477
evaluation/Actions Mean             0.0241029
evaluation/Actions Std              0.204453
evaluation/Actions Max              0.997064
evaluation/Actions Min             -0.994326
evaluation/Num Paths               10
evaluation/Average Returns        -21.6485
time/data storing (s)               0.00124281
time/evaluation sampling (s)        0.25076
time/exploration sampling (s)       0.0633676
time/logging (s)                    0.00340588
time/saving (s)                     0.00230236
time/training (s)                   1.05246
time/epoch (s)                      1.37354
time/total (s)                    395.922
Epoch                             270
-----------------------------  ---------------
2019-04-21 12:23:02.387955 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 271 finished
-----------------------------  ---------------
replay_buffer/size              54600
trainer/QF1 Loss                    0.00748635
trainer/QF2 Loss                    0.0179747
trainer/Policy Loss                 8.7404
trainer/Q1 Predictions Mean        -6.88405
trainer/Q1 Predictions Std          2.07453
trainer/Q1 Predictions Max         -6.25042
trainer/Q1 Predictions Min        -19.0158
trainer/Q2 Predictions Mean        -6.86956
trainer/Q2 Predictions Std          2.11533
trainer/Q2 Predictions Max         -6.22799
trainer/Q2 Predictions Min        -19.5287
trainer/Q Targets Mean             -6.90228
trainer/Q Targets Std               2.04067
trainer/Q Targets Max              -6.17428
trainer/Q Targets Min             -18.5466
trainer/Log Pis Mean                1.93003
trainer/Log Pis Std                 1.14928
trainer/Log Pis Max                 4.87448
trainer/Log Pis Min                -4.36898
trainer/Policy mu Mean              0.0522317
trainer/Policy mu Std               0.498033
trainer/Policy mu Max               2.7237
trainer/Policy mu Min              -3.00205
trainer/Policy log std Mean        -2.18643
trainer/Policy log std Std          0.379294
trainer/Policy log std Max         -0.457189
trainer/Policy log std Min         -2.43017
trainer/Alpha                       0.0572775
trainer/Alpha Loss                 -0.200103
exploration/num steps total     54600
exploration/num paths total       546
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.270928
exploration/Rewards Std             0.758242
exploration/Rewards Max            -0.0108135
exploration/Rewards Min            -6.32781
exploration/Returns Mean          -27.0928
exploration/Returns Std             2.9213
exploration/Returns Max           -24.1715
exploration/Returns Min           -30.0141
exploration/Actions Mean            0.0360267
exploration/Actions Std             0.231521
exploration/Actions Max             0.997947
exploration/Actions Min            -0.557714
exploration/Num Paths               2
exploration/Average Returns       -27.0928
evaluation/num steps total     272000
evaluation/num paths total       2720
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.313605
evaluation/Rewards Std              1.30884
evaluation/Rewards Max             -0.0198896
evaluation/Rewards Min             -9.9694
evaluation/Returns Mean           -31.3605
evaluation/Returns Std             20.2058
evaluation/Returns Max             -2.25616
evaluation/Returns Min            -57.0968
evaluation/Actions Mean             0.0363619
evaluation/Actions Std              0.20481
evaluation/Actions Max              0.996867
evaluation/Actions Min             -0.971087
evaluation/Num Paths               10
evaluation/Average Returns        -31.3605
time/data storing (s)               0.00114032
time/evaluation sampling (s)        0.25167
time/exploration sampling (s)       0.0633649
time/logging (s)                    0.00344855
time/saving (s)                     0.0024178
time/training (s)                   1.00541
time/epoch (s)                      1.32745
time/total (s)                    397.253
Epoch                             271
-----------------------------  ---------------
2019-04-21 12:23:03.805583 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 272 finished
-----------------------------  ---------------
replay_buffer/size              54800
trainer/QF1 Loss                    0.024959
trainer/QF2 Loss                    0.0196226
trainer/Policy Loss                 9.08886
trainer/Q1 Predictions Mean        -7.30939
trainer/Q1 Predictions Std          3.39195
trainer/Q1 Predictions Max         -6.34337
trainer/Q1 Predictions Min        -31.0695
trainer/Q2 Predictions Mean        -7.2105
trainer/Q2 Predictions Std          3.40472
trainer/Q2 Predictions Max         -6.23804
trainer/Q2 Predictions Min        -31.0695
trainer/Q Targets Mean             -7.25425
trainer/Q Targets Std               3.39936
trainer/Q Targets Max              -6.22498
trainer/Q Targets Min             -31.4767
trainer/Log Pis Mean                1.85188
trainer/Log Pis Std                 1.15157
trainer/Log Pis Max                 5.3223
trainer/Log Pis Min                -1.5081
trainer/Policy mu Mean              0.091825
trainer/Policy mu Std               0.601132
trainer/Policy mu Max               3.15984
trainer/Policy mu Min              -1.84677
trainer/Policy log std Mean        -2.16005
trainer/Policy log std Std          0.420978
trainer/Policy log std Max         -0.567743
trainer/Policy log std Min         -2.41739
trainer/Alpha                       0.0561501
trainer/Alpha Loss                 -0.426556
exploration/num steps total     54800
exploration/num paths total       548
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.378791
exploration/Rewards Std             1.14865
exploration/Rewards Max            -0.0114879
exploration/Rewards Min            -8.76454
exploration/Returns Mean          -37.8791
exploration/Returns Std            14.6102
exploration/Returns Max           -23.2689
exploration/Returns Min           -52.4892
exploration/Actions Mean            0.053381
exploration/Actions Std             0.253859
exploration/Actions Max             0.999386
exploration/Actions Min            -0.378959
exploration/Num Paths               2
exploration/Average Returns       -37.8791
evaluation/num steps total     273000
evaluation/num paths total       2730
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.244194
evaluation/Rewards Std              1.11581
evaluation/Rewards Max             -0.0208205
evaluation/Rewards Min            -10.7972
evaluation/Returns Mean           -24.4194
evaluation/Returns Std             19.4022
evaluation/Returns Max             -4.40976
evaluation/Returns Min            -59.3905
evaluation/Actions Mean             0.0287001
evaluation/Actions Std              0.202245
evaluation/Actions Max              0.997049
evaluation/Actions Min             -0.99006
evaluation/Num Paths               10
evaluation/Average Returns        -24.4194
time/data storing (s)               0.0016914
time/evaluation sampling (s)        0.260531
time/exploration sampling (s)       0.0778469
time/logging (s)                    0.00328538
time/saving (s)                     0.00230399
time/training (s)                   1.06349
time/epoch (s)                      1.40915
time/total (s)                    398.666
Epoch                             272
-----------------------------  ---------------
2019-04-21 12:23:05.214777 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 273 finished
-----------------------------  ---------------
replay_buffer/size              55000
trainer/QF1 Loss                    1.17211
trainer/QF2 Loss                    1.17651
trainer/Policy Loss                 8.66783
trainer/Q1 Predictions Mean        -6.89093
trainer/Q1 Predictions Std          3.42261
trainer/Q1 Predictions Max         -6.29351
trainer/Q1 Predictions Min        -40.526
trainer/Q2 Predictions Mean        -6.89347
trainer/Q2 Predictions Std          3.44265
trainer/Q2 Predictions Max         -6.2945
trainer/Q2 Predictions Min        -40.7371
trainer/Q Targets Mean             -6.68274
trainer/Q Targets Std               3.58552
trainer/Q Targets Max              -0.0993137
trainer/Q Targets Min             -40.2438
trainer/Log Pis Mean                1.95669
trainer/Log Pis Std                 0.971953
trainer/Log Pis Max                 4.7301
trainer/Log Pis Min                -1.24183
trainer/Policy mu Mean              0.0637288
trainer/Policy mu Std               0.454986
trainer/Policy mu Max               2.9273
trainer/Policy mu Min              -1.59234
trainer/Policy log std Mean        -2.27951
trainer/Policy log std Std          0.352016
trainer/Policy log std Max         -0.666299
trainer/Policy log std Min         -2.49977
trainer/Alpha                       0.0555468
trainer/Alpha Loss                 -0.125194
exploration/num steps total     55000
exploration/num paths total       550
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.169518
exploration/Rewards Std             0.429977
exploration/Rewards Max            -0.0150805
exploration/Rewards Min            -4.43182
exploration/Returns Mean          -16.9518
exploration/Returns Std             4.11675
exploration/Returns Max           -12.835
exploration/Returns Min           -21.0685
exploration/Actions Mean            0.0291325
exploration/Actions Std             0.185499
exploration/Actions Max             0.984298
exploration/Actions Min            -0.288495
exploration/Num Paths               2
exploration/Average Returns       -16.9518
evaluation/num steps total     274000
evaluation/num paths total       2740
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.263326
evaluation/Rewards Std              1.10154
evaluation/Rewards Max             -0.0144073
evaluation/Rewards Min             -9.37306
evaluation/Returns Mean           -26.3326
evaluation/Returns Std             16.255
evaluation/Returns Max             -3.77201
evaluation/Returns Min            -47.514
evaluation/Actions Mean             0.0350155
evaluation/Actions Std              0.200962
evaluation/Actions Max              0.99711
evaluation/Actions Min             -0.980369
evaluation/Num Paths               10
evaluation/Average Returns        -26.3326
time/data storing (s)               0.00117719
time/evaluation sampling (s)        0.251076
time/exploration sampling (s)       0.0677296
time/logging (s)                    0.00256846
time/saving (s)                     0.00254982
time/training (s)                   1.07582
time/epoch (s)                      1.40092
time/total (s)                    400.072
Epoch                             273
-----------------------------  ---------------
2019-04-21 12:23:06.601201 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 274 finished
-----------------------------  ---------------
replay_buffer/size              55200
trainer/QF1 Loss                    0.402587
trainer/QF2 Loss                    0.409302
trainer/Policy Loss                 8.74325
trainer/Q1 Predictions Mean        -6.80412
trainer/Q1 Predictions Std          3.00046
trainer/Q1 Predictions Max         -6.2336
trainer/Q1 Predictions Min        -35.6756
trainer/Q2 Predictions Mean        -6.82073
trainer/Q2 Predictions Std          2.9976
trainer/Q2 Predictions Max         -6.23989
trainer/Q2 Predictions Min        -35.6936
trainer/Q Targets Mean             -6.78695
trainer/Q Targets Std               3.10534
trainer/Q Targets Max              -0.188163
trainer/Q Targets Min             -35.8759
trainer/Log Pis Mean                2.06843
trainer/Log Pis Std                 0.872497
trainer/Log Pis Max                 4.67673
trainer/Log Pis Min                -0.773103
trainer/Policy mu Mean              0.0715744
trainer/Policy mu Std               0.395014
trainer/Policy mu Max               2.83605
trainer/Policy mu Min              -0.827839
trainer/Policy log std Mean        -2.28937
trainer/Policy log std Std          0.315533
trainer/Policy log std Max         -0.62311
trainer/Policy log std Min         -2.4603
trainer/Alpha                       0.0569869
trainer/Alpha Loss                  0.19606
exploration/num steps total     55200
exploration/num paths total       552
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.257459
exploration/Rewards Std             0.685813
exploration/Rewards Max            -0.00883568
exploration/Rewards Min            -5.49629
exploration/Returns Mean          -25.7459
exploration/Returns Std             1.42344
exploration/Returns Max           -24.3225
exploration/Returns Min           -27.1693
exploration/Actions Mean            0.0368276
exploration/Actions Std             0.223099
exploration/Actions Max             0.998776
exploration/Actions Min            -0.537556
exploration/Num Paths               2
exploration/Average Returns       -25.7459
evaluation/num steps total     275000
evaluation/num paths total       2750
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.230093
evaluation/Rewards Std              1.05847
evaluation/Rewards Max             -0.00869975
evaluation/Rewards Min             -9.48491
evaluation/Returns Mean           -23.0093
evaluation/Returns Std             14.0782
evaluation/Returns Max             -1.5222
evaluation/Returns Min            -42.0797
evaluation/Actions Mean             0.025108
evaluation/Actions Std              0.20447
evaluation/Actions Max              0.996236
evaluation/Actions Min             -0.993871
evaluation/Num Paths               10
evaluation/Average Returns        -23.0093
time/data storing (s)               0.0011698
time/evaluation sampling (s)        0.293794
time/exploration sampling (s)       0.0645384
time/logging (s)                    0.00261433
time/saving (s)                     0.00234464
time/training (s)                   1.01337
time/epoch (s)                      1.37783
time/total (s)                    401.454
Epoch                             274
-----------------------------  ---------------
2019-04-21 12:23:07.932628 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 275 finished
-----------------------------  ---------------
replay_buffer/size              55400
trainer/QF1 Loss                    0.390919
trainer/QF2 Loss                    0.393489
trainer/Policy Loss                 9.28296
trainer/Q1 Predictions Mean        -7.35128
trainer/Q1 Predictions Std          3.93963
trainer/Q1 Predictions Max         -6.23258
trainer/Q1 Predictions Min        -32.9776
trainer/Q2 Predictions Mean        -7.37924
trainer/Q2 Predictions Std          3.92438
trainer/Q2 Predictions Max         -6.28086
trainer/Q2 Predictions Min        -32.9355
trainer/Q Targets Mean             -7.32329
trainer/Q Targets Std               4.01991
trainer/Q Targets Max              -0.0666771
trainer/Q Targets Min             -32.9609
trainer/Log Pis Mean                1.94794
trainer/Log Pis Std                 1.14836
trainer/Log Pis Max                 5.66484
trainer/Log Pis Min                -1.86814
trainer/Policy mu Mean              0.101603
trainer/Policy mu Std               0.571399
trainer/Policy mu Max               2.84839
trainer/Policy mu Min              -1.94562
trainer/Policy log std Mean        -2.21921
trainer/Policy log std Std          0.398359
trainer/Policy log std Max         -0.66178
trainer/Policy log std Min         -2.39094
trainer/Alpha                       0.0562149
trainer/Alpha Loss                 -0.149848
exploration/num steps total     55400
exploration/num paths total       554
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.291037
exploration/Rewards Std             0.815059
exploration/Rewards Max            -0.0085823
exploration/Rewards Min            -6.39757
exploration/Returns Mean          -29.1037
exploration/Returns Std             5.77657
exploration/Returns Max           -23.3271
exploration/Returns Min           -34.8803
exploration/Actions Mean            0.0261606
exploration/Actions Std             0.222422
exploration/Actions Max             0.998365
exploration/Actions Min            -0.744323
exploration/Num Paths               2
exploration/Average Returns       -29.1037
evaluation/num steps total     276000
evaluation/num paths total       2760
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.189924
evaluation/Rewards Std              0.85058
evaluation/Rewards Max             -0.0177867
evaluation/Rewards Min             -8.43993
evaluation/Returns Mean           -18.9924
evaluation/Returns Std             10.6088
evaluation/Returns Max             -3.05724
evaluation/Returns Min            -36.2939
evaluation/Actions Mean             0.0246166
evaluation/Actions Std              0.189059
evaluation/Actions Max              0.996122
evaluation/Actions Min             -0.996728
evaluation/Num Paths               10
evaluation/Average Returns        -18.9924
time/data storing (s)               0.00117284
time/evaluation sampling (s)        0.2521
time/exploration sampling (s)       0.0649335
time/logging (s)                    0.00343045
time/saving (s)                     0.00229325
time/training (s)                   0.999553
time/epoch (s)                      1.32348
time/total (s)                    402.782
Epoch                             275
-----------------------------  ---------------
2019-04-21 12:23:09.283088 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 276 finished
-----------------------------  ---------------
replay_buffer/size              55600
trainer/QF1 Loss                    0.420345
trainer/QF2 Loss                    0.404365
trainer/Policy Loss                 9.03464
trainer/Q1 Predictions Mean        -7.35853
trainer/Q1 Predictions Std          5.48755
trainer/Q1 Predictions Max         -6.19071
trainer/Q1 Predictions Min        -49.8299
trainer/Q2 Predictions Mean        -7.35061
trainer/Q2 Predictions Std          5.57482
trainer/Q2 Predictions Max         -6.18611
trainer/Q2 Predictions Min        -50.7949
trainer/Q Targets Mean             -7.3975
trainer/Q Targets Std               5.66156
trainer/Q Targets Max              -0.15761
trainer/Q Targets Min             -51.5125
trainer/Log Pis Mean                1.71583
trainer/Log Pis Std                 1.30154
trainer/Log Pis Max                 7.1121
trainer/Log Pis Min                -2.9241
trainer/Policy mu Mean              0.04513
trainer/Policy mu Std               0.541664
trainer/Policy mu Max               3.31909
trainer/Policy mu Min              -2.61974
trainer/Policy log std Mean        -2.17878
trainer/Policy log std Std          0.370834
trainer/Policy log std Max         -0.563843
trainer/Policy log std Min         -2.34326
trainer/Alpha                       0.0556854
trainer/Alpha Loss                 -0.82059
exploration/num steps total     55600
exploration/num paths total       556
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.335147
exploration/Rewards Std             1.09332
exploration/Rewards Max            -0.00808503
exploration/Rewards Min            -9.08832
exploration/Returns Mean          -33.5147
exploration/Returns Std            19.7754
exploration/Returns Max           -13.7393
exploration/Returns Min           -53.2901
exploration/Actions Mean            0.0171782
exploration/Actions Std             0.235435
exploration/Actions Max             0.999464
exploration/Actions Min            -0.987068
exploration/Num Paths               2
exploration/Average Returns       -33.5147
evaluation/num steps total     277000
evaluation/num paths total       2770
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.258985
evaluation/Rewards Std              1.15833
evaluation/Rewards Max             -0.0114665
evaluation/Rewards Min            -10.1001
evaluation/Returns Mean           -25.8985
evaluation/Returns Std             18.3815
evaluation/Returns Max             -2.79846
evaluation/Returns Min            -52.2757
evaluation/Actions Mean             0.0364825
evaluation/Actions Std              0.202579
evaluation/Actions Max              0.997464
evaluation/Actions Min             -0.988331
evaluation/Num Paths               10
evaluation/Average Returns        -25.8985
time/data storing (s)               0.00116585
time/evaluation sampling (s)        0.248484
time/exploration sampling (s)       0.064058
time/logging (s)                    0.00339964
time/saving (s)                     0.00238203
time/training (s)                   1.02263
time/epoch (s)                      1.34212
time/total (s)                    404.128
Epoch                             276
-----------------------------  ---------------
2019-04-21 12:23:10.632345 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 277 finished
-----------------------------  ---------------
replay_buffer/size              55800
trainer/QF1 Loss                    0.828302
trainer/QF2 Loss                    0.84478
trainer/Policy Loss                 9.4313
trainer/Q1 Predictions Mean        -7.34461
trainer/Q1 Predictions Std          6.61857
trainer/Q1 Predictions Max         -6.16605
trainer/Q1 Predictions Min        -69.7554
trainer/Q2 Predictions Mean        -7.36862
trainer/Q2 Predictions Std          6.58793
trainer/Q2 Predictions Max         -6.19699
trainer/Q2 Predictions Min        -69.4329
trainer/Q Targets Mean             -7.33373
trainer/Q Targets Std               6.92201
trainer/Q Targets Max              -0.0530902
trainer/Q Targets Min             -72.0236
trainer/Log Pis Mean                2.22664
trainer/Log Pis Std                 1.00384
trainer/Log Pis Max                 7.19266
trainer/Log Pis Min                -0.54039
trainer/Policy mu Mean              0.0999206
trainer/Policy mu Std               0.530102
trainer/Policy mu Max               3.10653
trainer/Policy mu Min              -1.86425
trainer/Policy log std Mean        -2.3086
trainer/Policy log std Std          0.382977
trainer/Policy log std Max         -0.623464
trainer/Policy log std Min         -2.48082
trainer/Alpha                       0.0549149
trainer/Alpha Loss                  0.657737
exploration/num steps total     55800
exploration/num paths total       558
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.249226
exploration/Rewards Std             0.66691
exploration/Rewards Max            -0.00682225
exploration/Rewards Min            -5.55764
exploration/Returns Mean          -24.9226
exploration/Returns Std             2.48765
exploration/Returns Max           -22.4349
exploration/Returns Min           -27.4102
exploration/Actions Mean            0.0182933
exploration/Actions Std             0.22986
exploration/Actions Max             0.999206
exploration/Actions Min            -0.979969
exploration/Num Paths               2
exploration/Average Returns       -24.9226
evaluation/num steps total     278000
evaluation/num paths total       2780
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.263303
evaluation/Rewards Std              1.03584
evaluation/Rewards Max             -0.00875902
evaluation/Rewards Min             -9.2558
evaluation/Returns Mean           -26.3303
evaluation/Returns Std             14.2311
evaluation/Returns Max             -5.33236
evaluation/Returns Min            -51.1513
evaluation/Actions Mean             0.0285237
evaluation/Actions Std              0.194464
evaluation/Actions Max              0.995289
evaluation/Actions Min             -0.989234
evaluation/Num Paths               10
evaluation/Average Returns        -26.3303
time/data storing (s)               0.00117488
time/evaluation sampling (s)        0.252922
time/exploration sampling (s)       0.0654054
time/logging (s)                    0.00341538
time/saving (s)                     0.00231311
time/training (s)                   1.01578
time/epoch (s)                      1.34101
time/total (s)                    405.473
Epoch                             277
-----------------------------  ---------------
2019-04-21 12:23:12.173921 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 278 finished
-----------------------------  ---------------
replay_buffer/size              56000
trainer/QF1 Loss                    0.786636
trainer/QF2 Loss                    0.780514
trainer/Policy Loss                 9.26494
trainer/Q1 Predictions Mean        -7.29678
trainer/Q1 Predictions Std          4.19772
trainer/Q1 Predictions Max         -6.03696
trainer/Q1 Predictions Min        -31.002
trainer/Q2 Predictions Mean        -7.33122
trainer/Q2 Predictions Std          4.19725
trainer/Q2 Predictions Max         -6.10762
trainer/Q2 Predictions Min        -30.6558
trainer/Q Targets Mean             -7.38462
trainer/Q Targets Std               4.33091
trainer/Q Targets Max              -0.0887528
trainer/Q Targets Min             -30.8269
trainer/Log Pis Mean                2.14087
trainer/Log Pis Std                 1.04085
trainer/Log Pis Max                 5.39856
trainer/Log Pis Min                -1.55062
trainer/Policy mu Mean              0.0633519
trainer/Policy mu Std               0.616958
trainer/Policy mu Max               3.52426
trainer/Policy mu Min              -2.61445
trainer/Policy log std Mean        -2.18035
trainer/Policy log std Std          0.416673
trainer/Policy log std Max         -0.498718
trainer/Policy log std Min         -2.40177
trainer/Alpha                       0.0549712
trainer/Alpha Loss                  0.408659
exploration/num steps total     56000
exploration/num paths total       560
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.182199
exploration/Rewards Std             0.35696
exploration/Rewards Max            -0.0079098
exploration/Rewards Min            -3.6008
exploration/Returns Mean          -18.2199
exploration/Returns Std             1.95833
exploration/Returns Max           -16.2615
exploration/Returns Min           -20.1782
exploration/Actions Mean            0.0262629
exploration/Actions Std             0.202912
exploration/Actions Max             0.984932
exploration/Actions Min            -0.403263
exploration/Num Paths               2
exploration/Average Returns       -18.2199
evaluation/num steps total     279000
evaluation/num paths total       2790
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.237122
evaluation/Rewards Std              1.05173
evaluation/Rewards Max             -0.0265709
evaluation/Rewards Min             -9.85198
evaluation/Returns Mean           -23.7122
evaluation/Returns Std             16.4693
evaluation/Returns Max             -4.52315
evaluation/Returns Min            -51.049
evaluation/Actions Mean             0.0146976
evaluation/Actions Std              0.198255
evaluation/Actions Max              0.996702
evaluation/Actions Min             -0.994903
evaluation/Num Paths               10
evaluation/Average Returns        -23.7122
time/data storing (s)               0.0011532
time/evaluation sampling (s)        0.257258
time/exploration sampling (s)       0.0646085
time/logging (s)                    0.00343723
time/saving (s)                     0.00235055
time/training (s)                   1.20428
time/epoch (s)                      1.53309
time/total (s)                    407.011
Epoch                             278
-----------------------------  ---------------
2019-04-21 12:23:13.701493 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 279 finished
-----------------------------  ---------------
replay_buffer/size              56200
trainer/QF1 Loss                    0.44481
trainer/QF2 Loss                    0.42455
trainer/Policy Loss                 9.66271
trainer/Q1 Predictions Mean        -7.54785
trainer/Q1 Predictions Std          5.94569
trainer/Q1 Predictions Max         -6.30904
trainer/Q1 Predictions Min        -60.1327
trainer/Q2 Predictions Mean        -7.5507
trainer/Q2 Predictions Std          5.99775
trainer/Q2 Predictions Max         -6.32694
trainer/Q2 Predictions Min        -60.5841
trainer/Q Targets Mean             -7.44551
trainer/Q Targets Std               6.16327
trainer/Q Targets Max              -0.125588
trainer/Q Targets Min             -61.534
trainer/Log Pis Mean                2.2325
trainer/Log Pis Std                 1.26132
trainer/Log Pis Max                 8.85077
trainer/Log Pis Min                -1.99116
trainer/Policy mu Mean              0.139317
trainer/Policy mu Std               0.608599
trainer/Policy mu Max               3.3957
trainer/Policy mu Min              -2.2532
trainer/Policy log std Mean        -2.19284
trainer/Policy log std Std          0.419946
trainer/Policy log std Max         -0.506297
trainer/Policy log std Min         -2.38839
trainer/Alpha                       0.0561794
trainer/Alpha Loss                  0.669448
exploration/num steps total     56200
exploration/num paths total       562
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.471997
exploration/Rewards Std             1.43914
exploration/Rewards Max            -0.00468623
exploration/Rewards Min           -10.1609
exploration/Returns Mean          -47.1997
exploration/Returns Std            20.9754
exploration/Returns Max           -26.2243
exploration/Returns Min           -68.1751
exploration/Actions Mean            0.0210969
exploration/Actions Std             0.248103
exploration/Actions Max             0.998867
exploration/Actions Min            -0.998923
exploration/Num Paths               2
exploration/Average Returns       -47.1997
evaluation/num steps total     280000
evaluation/num paths total       2800
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.273342
evaluation/Rewards Std              1.10833
evaluation/Rewards Max             -0.0164313
evaluation/Rewards Min             -9.83203
evaluation/Returns Mean           -27.3342
evaluation/Returns Std             18.8043
evaluation/Returns Max             -5.96374
evaluation/Returns Min            -58.3446
evaluation/Actions Mean             0.0234419
evaluation/Actions Std              0.193306
evaluation/Actions Max              0.997409
evaluation/Actions Min             -0.988048
evaluation/Num Paths               10
evaluation/Average Returns        -27.3342
time/data storing (s)               0.00121991
time/evaluation sampling (s)        0.315268
time/exploration sampling (s)       0.0812175
time/logging (s)                    0.0034259
time/saving (s)                     0.0106723
time/training (s)                   1.10609
time/epoch (s)                      1.5179
time/total (s)                    408.534
Epoch                             279
-----------------------------  ---------------
2019-04-21 12:23:15.084145 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 280 finished
-----------------------------  ---------------
replay_buffer/size              56400
trainer/QF1 Loss                    0.906686
trainer/QF2 Loss                    0.925081
trainer/Policy Loss                 9.73353
trainer/Q1 Predictions Mean        -7.96729
trainer/Q1 Predictions Std          7.95125
trainer/Q1 Predictions Max         -6.1174
trainer/Q1 Predictions Min        -76.5348
trainer/Q2 Predictions Mean        -7.96029
trainer/Q2 Predictions Std          7.98094
trainer/Q2 Predictions Max         -6.13122
trainer/Q2 Predictions Min        -76.796
trainer/Q Targets Mean             -7.90306
trainer/Q Targets Std               7.66647
trainer/Q Targets Max              -0.0646219
trainer/Q Targets Min             -72.8182
trainer/Log Pis Mean                2.00052
trainer/Log Pis Std                 1.09458
trainer/Log Pis Max                 5.65171
trainer/Log Pis Min                -0.727237
trainer/Policy mu Mean              0.103874
trainer/Policy mu Std               0.655233
trainer/Policy mu Max               3.01833
trainer/Policy mu Min              -1.52205
trainer/Policy log std Mean        -2.16277
trainer/Policy log std Std          0.460148
trainer/Policy log std Max         -0.528713
trainer/Policy log std Min         -2.46465
trainer/Alpha                       0.0546873
trainer/Alpha Loss                  0.00151542
exploration/num steps total     56400
exploration/num paths total       564
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.403679
exploration/Rewards Std             1.1636
exploration/Rewards Max            -0.00977373
exploration/Rewards Min            -8.13507
exploration/Returns Mean          -40.3679
exploration/Returns Std             7.02976
exploration/Returns Max           -33.3382
exploration/Returns Min           -47.3977
exploration/Actions Mean            0.0480819
exploration/Actions Std             0.247665
exploration/Actions Max             0.998278
exploration/Actions Min            -0.503524
exploration/Num Paths               2
exploration/Average Returns       -40.3679
evaluation/num steps total     281000
evaluation/num paths total       2810
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.215943
evaluation/Rewards Std              1.01831
evaluation/Rewards Max             -0.0158098
evaluation/Rewards Min             -9.76605
evaluation/Returns Mean           -21.5943
evaluation/Returns Std             16.8422
evaluation/Returns Max             -2.79
evaluation/Returns Min            -49.9999
evaluation/Actions Mean             0.0324954
evaluation/Actions Std              0.189357
evaluation/Actions Max              0.996454
evaluation/Actions Min             -0.981695
evaluation/Num Paths               10
evaluation/Average Returns        -21.5943
time/data storing (s)               0.0011636
time/evaluation sampling (s)        0.258245
time/exploration sampling (s)       0.064182
time/logging (s)                    0.00339765
time/saving (s)                     0.00238421
time/training (s)                   1.04526
time/epoch (s)                      1.37463
time/total (s)                    409.912
Epoch                             280
-----------------------------  ---------------
2019-04-21 12:23:16.680597 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 281 finished
-----------------------------  ---------------
replay_buffer/size              56600
trainer/QF1 Loss                    0.0590889
trainer/QF2 Loss                    0.0560085
trainer/Policy Loss                 8.8968
trainer/Q1 Predictions Mean        -7.14837
trainer/Q1 Predictions Std          3.62252
trainer/Q1 Predictions Max         -6.23888
trainer/Q1 Predictions Min        -30.8859
trainer/Q2 Predictions Mean        -7.13861
trainer/Q2 Predictions Std          3.62813
trainer/Q2 Predictions Max         -6.24237
trainer/Q2 Predictions Min        -30.797
trainer/Q Targets Mean             -7.16915
trainer/Q Targets Std               3.76239
trainer/Q Targets Max              -6.14383
trainer/Q Targets Min             -31.9083
trainer/Log Pis Mean                1.88839
trainer/Log Pis Std                 1.18392
trainer/Log Pis Max                 5.98925
trainer/Log Pis Min                -1.47462
trainer/Policy mu Mean              0.067512
trainer/Policy mu Std               0.584632
trainer/Policy mu Max               3.53753
trainer/Policy mu Min              -2.38946
trainer/Policy log std Mean        -2.20335
trainer/Policy log std Std          0.377108
trainer/Policy log std Max         -0.657922
trainer/Policy log std Min         -2.46385
trainer/Alpha                       0.0554275
trainer/Alpha Loss                 -0.322847
exploration/num steps total     56600
exploration/num paths total       566
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.123986
exploration/Rewards Std             0.114669
exploration/Rewards Max            -0.0112337
exploration/Rewards Min            -1.39247
exploration/Returns Mean          -12.3986
exploration/Returns Std             1.06028
exploration/Returns Max           -11.3383
exploration/Returns Min           -13.4589
exploration/Actions Mean            0.00742493
exploration/Actions Std             0.171068
exploration/Actions Max             0.972373
exploration/Actions Min            -0.907191
exploration/Num Paths               2
exploration/Average Returns       -12.3986
evaluation/num steps total     282000
evaluation/num paths total       2820
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.21815
evaluation/Rewards Std              0.969402
evaluation/Rewards Max             -0.0236816
evaluation/Rewards Min             -8.99931
evaluation/Returns Mean           -21.815
evaluation/Returns Std             13.5602
evaluation/Returns Max             -6.87292
evaluation/Returns Min            -47.0741
evaluation/Actions Mean             0.0314116
evaluation/Actions Std              0.196325
evaluation/Actions Max              0.997373
evaluation/Actions Min             -0.987962
evaluation/Num Paths               10
evaluation/Average Returns        -21.815
time/data storing (s)               0.00121753
time/evaluation sampling (s)        0.257777
time/exploration sampling (s)       0.0709773
time/logging (s)                    0.00340525
time/saving (s)                     0.00235476
time/training (s)                   1.25175
time/epoch (s)                      1.58748
time/total (s)                    411.504
Epoch                             281
-----------------------------  ---------------
2019-04-21 12:23:18.139726 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 282 finished
-----------------------------  ---------------
replay_buffer/size              56800
trainer/QF1 Loss                    0.0253309
trainer/QF2 Loss                    0.0249732
trainer/Policy Loss                 9.44389
trainer/Q1 Predictions Mean        -7.51959
trainer/Q1 Predictions Std          6.08805
trainer/Q1 Predictions Max         -6.2071
trainer/Q1 Predictions Min        -52.4917
trainer/Q2 Predictions Mean        -7.54843
trainer/Q2 Predictions Std          6.06392
trainer/Q2 Predictions Max         -6.23262
trainer/Q2 Predictions Min        -52.1815
trainer/Q Targets Mean             -7.58374
trainer/Q Targets Std               6.18879
trainer/Q Targets Max              -6.19323
trainer/Q Targets Min             -53.3062
trainer/Log Pis Mean                1.92587
trainer/Log Pis Std                 1.31118
trainer/Log Pis Max                 5.44068
trainer/Log Pis Min                -4.48976
trainer/Policy mu Mean              0.0990732
trainer/Policy mu Std               0.597088
trainer/Policy mu Max               3.06864
trainer/Policy mu Min              -1.50879
trainer/Policy log std Mean        -2.17741
trainer/Policy log std Std          0.433615
trainer/Policy log std Max         -0.57611
trainer/Policy log std Min         -2.46876
trainer/Alpha                       0.0539194
trainer/Alpha Loss                 -0.21647
exploration/num steps total     56800
exploration/num paths total       568
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.332837
exploration/Rewards Std             1.0366
exploration/Rewards Max            -0.0132097
exploration/Rewards Min            -8.50415
exploration/Returns Mean          -33.2837
exploration/Returns Std            16.0357
exploration/Returns Max           -17.248
exploration/Returns Min           -49.3194
exploration/Actions Mean            0.0400337
exploration/Actions Std             0.228568
exploration/Actions Max             0.998339
exploration/Actions Min            -0.394002
exploration/Num Paths               2
exploration/Average Returns       -33.2837
evaluation/num steps total     283000
evaluation/num paths total       2830
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.318879
evaluation/Rewards Std              1.20166
evaluation/Rewards Max             -0.0450272
evaluation/Rewards Min            -10.4177
evaluation/Returns Mean           -31.8879
evaluation/Returns Std             15.7744
evaluation/Returns Max             -5.97751
evaluation/Returns Min            -63.2637
evaluation/Actions Mean             0.0324554
evaluation/Actions Std              0.212312
evaluation/Actions Max              0.997168
evaluation/Actions Min             -0.98124
evaluation/Num Paths               10
evaluation/Average Returns        -31.8879
time/data storing (s)               0.00136132
time/evaluation sampling (s)        0.317653
time/exploration sampling (s)       0.0929935
time/logging (s)                    0.00340846
time/saving (s)                     0.00186577
time/training (s)                   1.03363
time/epoch (s)                      1.45091
time/total (s)                    412.959
Epoch                             282
-----------------------------  ---------------
2019-04-21 12:23:19.527292 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 283 finished
-----------------------------  ---------------
replay_buffer/size              57000
trainer/QF1 Loss                    0.38514
trainer/QF2 Loss                    0.384624
trainer/Policy Loss                 8.54754
trainer/Q1 Predictions Mean        -6.71076
trainer/Q1 Predictions Std          2.12207
trainer/Q1 Predictions Max         -6.17039
trainer/Q1 Predictions Min        -20.7655
trainer/Q2 Predictions Mean        -6.71003
trainer/Q2 Predictions Std          2.15752
trainer/Q2 Predictions Max         -6.15258
trainer/Q2 Predictions Min        -21.0426
trainer/Q Targets Mean             -6.72021
trainer/Q Targets Std               2.2131
trainer/Q Targets Max              -0.194062
trainer/Q Targets Min             -20.8244
trainer/Log Pis Mean                1.91082
trainer/Log Pis Std                 1.12407
trainer/Log Pis Max                 5.92987
trainer/Log Pis Min                -1.7047
trainer/Policy mu Mean              0.0759009
trainer/Policy mu Std               0.459452
trainer/Policy mu Max               2.88315
trainer/Policy mu Min              -1.60094
trainer/Policy log std Mean        -2.27083
trainer/Policy log std Std          0.354621
trainer/Policy log std Max         -0.389218
trainer/Policy log std Min         -2.44395
trainer/Alpha                       0.0554337
trainer/Alpha Loss                 -0.257974
exploration/num steps total     57000
exploration/num paths total       570
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.144136
exploration/Rewards Std             0.212856
exploration/Rewards Max            -0.0140288
exploration/Rewards Min            -2.55704
exploration/Returns Mean          -14.4136
exploration/Returns Std             2.48211
exploration/Returns Max           -11.9315
exploration/Returns Min           -16.8957
exploration/Actions Mean           -0.0162867
exploration/Actions Std             0.168918
exploration/Actions Max             0.33819
exploration/Actions Min            -0.993588
exploration/Num Paths               2
exploration/Average Returns       -14.4136
evaluation/num steps total     284000
evaluation/num paths total       2840
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.228839
evaluation/Rewards Std              0.971767
evaluation/Rewards Max             -0.0145344
evaluation/Rewards Min             -9.36324
evaluation/Returns Mean           -22.8839
evaluation/Returns Std             12.4297
evaluation/Returns Max             -4.04623
evaluation/Returns Min            -43.8923
evaluation/Actions Mean             0.017596
evaluation/Actions Std              0.197934
evaluation/Actions Max              0.99736
evaluation/Actions Min             -0.997981
evaluation/Num Paths               10
evaluation/Average Returns        -22.8839
time/data storing (s)               0.00122732
time/evaluation sampling (s)        0.266411
time/exploration sampling (s)       0.0678947
time/logging (s)                    0.00341878
time/saving (s)                     0.00233163
time/training (s)                   1.03755
time/epoch (s)                      1.37883
time/total (s)                    414.342
Epoch                             283
-----------------------------  ---------------
2019-04-21 12:23:21.219793 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 284 finished
-----------------------------  ---------------
replay_buffer/size              57200
trainer/QF1 Loss                    1.17984
trainer/QF2 Loss                    1.17833
trainer/Policy Loss                 8.46309
trainer/Q1 Predictions Mean        -6.60605
trainer/Q1 Predictions Std          1.53023
trainer/Q1 Predictions Max         -6.28715
trainer/Q1 Predictions Min        -21.6247
trainer/Q2 Predictions Mean        -6.59774
trainer/Q2 Predictions Std          1.53305
trainer/Q2 Predictions Max         -6.27089
trainer/Q2 Predictions Min        -21.5976
trainer/Q Targets Mean             -6.35984
trainer/Q Targets Std               1.87085
trainer/Q Targets Max              -0.0819209
trainer/Q Targets Min             -21.4262
trainer/Log Pis Mean                1.9237
trainer/Log Pis Std                 0.896887
trainer/Log Pis Max                 6.80003
trainer/Log Pis Min                -1.18619
trainer/Policy mu Mean             -0.00287973
trainer/Policy mu Std               0.35081
trainer/Policy mu Max               2.70795
trainer/Policy mu Min              -2.27428
trainer/Policy log std Mean        -2.23416
trainer/Policy log std Std          0.259073
trainer/Policy log std Max         -0.601016
trainer/Policy log std Min         -2.36515
trainer/Alpha                       0.0558687
trainer/Alpha Loss                 -0.220083
exploration/num steps total     57200
exploration/num paths total       572
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.459248
exploration/Rewards Std             1.46665
exploration/Rewards Max            -0.00813031
exploration/Rewards Min           -11.102
exploration/Returns Mean          -45.9248
exploration/Returns Std            25.0691
exploration/Returns Max           -20.8557
exploration/Returns Min           -70.9939
exploration/Actions Mean            0.0142788
exploration/Actions Std             0.276617
exploration/Actions Max             0.998809
exploration/Actions Min            -0.985934
exploration/Num Paths               2
exploration/Average Returns       -45.9248
evaluation/num steps total     285000
evaluation/num paths total       2850
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.162028
evaluation/Rewards Std              0.697175
evaluation/Rewards Max             -0.0174104
evaluation/Rewards Min             -6.83419
evaluation/Returns Mean           -16.2028
evaluation/Returns Std              9.17423
evaluation/Returns Max             -4.19244
evaluation/Returns Min            -30.891
evaluation/Actions Mean             0.027137
evaluation/Actions Std              0.170244
evaluation/Actions Max              0.994457
evaluation/Actions Min             -0.988615
evaluation/Num Paths               10
evaluation/Average Returns        -16.2028
time/data storing (s)               0.00185517
time/evaluation sampling (s)        0.245691
time/exploration sampling (s)       0.0977867
time/logging (s)                    0.00352751
time/saving (s)                     0.00236901
time/training (s)                   1.33326
time/epoch (s)                      1.68449
time/total (s)                    416.031
Epoch                             284
-----------------------------  ---------------
2019-04-21 12:23:22.842759 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 285 finished
-----------------------------  ---------------
replay_buffer/size              57400
trainer/QF1 Loss                    0.0150927
trainer/QF2 Loss                    0.0106851
trainer/Policy Loss                 9.62189
trainer/Q1 Predictions Mean        -7.82271
trainer/Q1 Predictions Std          6.36321
trainer/Q1 Predictions Max         -6.28416
trainer/Q1 Predictions Min        -47.5593
trainer/Q2 Predictions Mean        -7.78416
trainer/Q2 Predictions Std          6.33275
trainer/Q2 Predictions Max         -6.2381
trainer/Q2 Predictions Min        -47.0802
trainer/Q Targets Mean             -7.81234
trainer/Q Targets Std               6.32719
trainer/Q Targets Max              -6.16582
trainer/Q Targets Min             -47.1689
trainer/Log Pis Mean                1.86859
trainer/Log Pis Std                 1.5851
trainer/Log Pis Max                 6.47649
trainer/Log Pis Min                -5.52717
trainer/Policy mu Mean              0.137315
trainer/Policy mu Std               0.627057
trainer/Policy mu Max               3.05443
trainer/Policy mu Min              -1.63029
trainer/Policy log std Mean        -2.16453
trainer/Policy log std Std          0.392336
trainer/Policy log std Max         -0.708742
trainer/Policy log std Min         -2.40099
trainer/Alpha                       0.056431
trainer/Alpha Loss                 -0.377754
exploration/num steps total     57400
exploration/num paths total       574
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.279115
exploration/Rewards Std             0.862969
exploration/Rewards Max            -0.0106415
exploration/Rewards Min            -7.51793
exploration/Returns Mean          -27.9115
exploration/Returns Std            14.4152
exploration/Returns Max           -13.4963
exploration/Returns Min           -42.3267
exploration/Actions Mean            0.0118531
exploration/Actions Std             0.20525
exploration/Actions Max             0.999119
exploration/Actions Min            -0.990877
exploration/Num Paths               2
exploration/Average Returns       -27.9115
evaluation/num steps total     286000
evaluation/num paths total       2860
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.259966
evaluation/Rewards Std              0.990147
evaluation/Rewards Max             -0.0263141
evaluation/Rewards Min             -9.99225
evaluation/Returns Mean           -25.9966
evaluation/Returns Std             16.3773
evaluation/Returns Max             -9.15688
evaluation/Returns Min            -53.9461
evaluation/Actions Mean             0.0273483
evaluation/Actions Std              0.189974
evaluation/Actions Max              0.997486
evaluation/Actions Min             -0.98554
evaluation/Num Paths               10
evaluation/Average Returns        -25.9966
time/data storing (s)               0.00108079
time/evaluation sampling (s)        0.347842
time/exploration sampling (s)       0.0633996
time/logging (s)                    0.00347757
time/saving (s)                     0.00293739
time/training (s)                   1.1954
time/epoch (s)                      1.61413
time/total (s)                    417.649
Epoch                             285
-----------------------------  ---------------
2019-04-21 12:23:24.318469 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 286 finished
-----------------------------  ---------------
replay_buffer/size              57600
trainer/QF1 Loss                    0.405815
trainer/QF2 Loss                    0.408753
trainer/Policy Loss                 8.87473
trainer/Q1 Predictions Mean        -7.19155
trainer/Q1 Predictions Std          4.95527
trainer/Q1 Predictions Max         -6.00608
trainer/Q1 Predictions Min        -36.9551
trainer/Q2 Predictions Mean        -7.20535
trainer/Q2 Predictions Std          4.99644
trainer/Q2 Predictions Max         -6.01113
trainer/Q2 Predictions Min        -37.4933
trainer/Q Targets Mean             -7.34019
trainer/Q Targets Std               4.9892
trainer/Q Targets Max              -0.201789
trainer/Q Targets Min             -37.0698
trainer/Log Pis Mean                1.71741
trainer/Log Pis Std                 1.50477
trainer/Log Pis Max                 6.85826
trainer/Log Pis Min                -3.40586
trainer/Policy mu Mean              0.0514482
trainer/Policy mu Std               0.529404
trainer/Policy mu Max               2.93245
trainer/Policy mu Min              -3.01582
trainer/Policy log std Mean        -2.21103
trainer/Policy log std Std          0.361283
trainer/Policy log std Max         -0.499897
trainer/Policy log std Min         -2.45715
trainer/Alpha                       0.0559351
trainer/Alpha Loss                 -0.814875
exploration/num steps total     57600
exploration/num paths total       576
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.50119
exploration/Rewards Std             1.45869
exploration/Rewards Max            -0.00500093
exploration/Rewards Min            -9.13196
exploration/Returns Mean          -50.119
exploration/Returns Std             7.20734
exploration/Returns Max           -42.9117
exploration/Returns Min           -57.3264
exploration/Actions Mean            0.0525599
exploration/Actions Std             0.254441
exploration/Actions Max             0.997598
exploration/Actions Min            -0.558949
exploration/Num Paths               2
exploration/Average Returns       -50.119
evaluation/num steps total     287000
evaluation/num paths total       2870
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.201822
evaluation/Rewards Std              0.98404
evaluation/Rewards Max             -0.0064055
evaluation/Rewards Min             -9.97218
evaluation/Returns Mean           -20.1822
evaluation/Returns Std             15.6685
evaluation/Returns Max             -1.21298
evaluation/Returns Min            -54.0645
evaluation/Actions Mean             0.0310392
evaluation/Actions Std              0.193613
evaluation/Actions Max              0.996224
evaluation/Actions Min             -0.989689
evaluation/Num Paths               10
evaluation/Average Returns        -20.1822
time/data storing (s)               0.00127191
time/evaluation sampling (s)        0.252238
time/exploration sampling (s)       0.0607152
time/logging (s)                    0.0025818
time/saving (s)                     0.00217723
time/training (s)                   1.14738
time/epoch (s)                      1.46637
time/total (s)                    419.12
Epoch                             286
-----------------------------  ---------------
2019-04-21 12:23:25.640022 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 287 finished
-----------------------------  ---------------
replay_buffer/size              57800
trainer/QF1 Loss                    0.420069
trainer/QF2 Loss                    0.402927
trainer/Policy Loss                 9.23856
trainer/Q1 Predictions Mean        -7.27273
trainer/Q1 Predictions Std          4.35762
trainer/Q1 Predictions Max         -6.29621
trainer/Q1 Predictions Min        -40.919
trainer/Q2 Predictions Mean        -7.23696
trainer/Q2 Predictions Std          4.37967
trainer/Q2 Predictions Max         -6.24587
trainer/Q2 Predictions Min        -41.1269
trainer/Q Targets Mean             -7.10479
trainer/Q Targets Std               4.35402
trainer/Q Targets Max              -0.221025
trainer/Q Targets Min             -40.5398
trainer/Log Pis Mean                2.05551
trainer/Log Pis Std                 1.32168
trainer/Log Pis Max                 6.98446
trainer/Log Pis Min                -2.549
trainer/Policy mu Mean              0.0218895
trainer/Policy mu Std               0.53672
trainer/Policy mu Max               2.9223
trainer/Policy mu Min              -2.56568
trainer/Policy log std Mean        -2.27616
trainer/Policy log std Std          0.389874
trainer/Policy log std Max         -0.604226
trainer/Policy log std Min         -2.47616
trainer/Alpha                       0.0568041
trainer/Alpha Loss                  0.159215
exploration/num steps total     57800
exploration/num paths total       578
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.405136
exploration/Rewards Std             1.32329
exploration/Rewards Max            -0.0095744
exploration/Rewards Min           -10.0147
exploration/Returns Mean          -40.5136
exploration/Returns Std            22.7232
exploration/Returns Max           -17.7904
exploration/Returns Min           -63.2368
exploration/Actions Mean            0.0255674
exploration/Actions Std             0.23753
exploration/Actions Max             0.998088
exploration/Actions Min            -0.990876
exploration/Num Paths               2
exploration/Average Returns       -40.5136
evaluation/num steps total     288000
evaluation/num paths total       2880
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.169604
evaluation/Rewards Std              0.803705
evaluation/Rewards Max             -0.0193794
evaluation/Rewards Min             -9.76794
evaluation/Returns Mean           -16.9604
evaluation/Returns Std             14.394
evaluation/Returns Max             -6.79591
evaluation/Returns Min            -55.6
evaluation/Actions Mean             0.0229883
evaluation/Actions Std              0.171368
evaluation/Actions Max              0.995733
evaluation/Actions Min             -0.993298
evaluation/Num Paths               10
evaluation/Average Returns        -16.9604
time/data storing (s)               0.00142273
time/evaluation sampling (s)        0.264232
time/exploration sampling (s)       0.0661552
time/logging (s)                    0.00347658
time/saving (s)                     0.00234599
time/training (s)                   0.975405
time/epoch (s)                      1.31304
time/total (s)                    420.438
Epoch                             287
-----------------------------  ---------------
2019-04-21 12:23:26.939983 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 288 finished
-----------------------------  ---------------
replay_buffer/size              58000
trainer/QF1 Loss                    0.389929
trainer/QF2 Loss                    0.396343
trainer/Policy Loss                 9.17089
trainer/Q1 Predictions Mean        -7.12648
trainer/Q1 Predictions Std          4.64334
trainer/Q1 Predictions Max         -6.16221
trainer/Q1 Predictions Min        -43.4737
trainer/Q2 Predictions Mean        -7.13419
trainer/Q2 Predictions Std          4.66313
trainer/Q2 Predictions Max         -6.17361
trainer/Q2 Predictions Min        -43.8182
trainer/Q Targets Mean             -7.15745
trainer/Q Targets Std               4.73778
trainer/Q Targets Max              -0.112369
trainer/Q Targets Min             -43.6792
trainer/Log Pis Mean                2.18995
trainer/Log Pis Std                 0.920157
trainer/Log Pis Max                 7.19338
trainer/Log Pis Min                -0.324018
trainer/Policy mu Mean              0.0871411
trainer/Policy mu Std               0.529352
trainer/Policy mu Max               3.10695
trainer/Policy mu Min              -1.94411
trainer/Policy log std Mean        -2.20773
trainer/Policy log std Std          0.382785
trainer/Policy log std Max         -0.669893
trainer/Policy log std Min         -2.42242
trainer/Alpha                       0.0555167
trainer/Alpha Loss                  0.549163
exploration/num steps total     58000
exploration/num paths total       580
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.239398
exploration/Rewards Std             0.523451
exploration/Rewards Max            -0.0137978
exploration/Rewards Min            -5.4305
exploration/Returns Mean          -23.9398
exploration/Returns Std             5.35825
exploration/Returns Max           -18.5816
exploration/Returns Min           -29.2981
exploration/Actions Mean           -0.00122243
exploration/Actions Std             0.208695
exploration/Actions Max             0.971985
exploration/Actions Min            -0.972861
exploration/Num Paths               2
exploration/Average Returns       -23.9398
evaluation/num steps total     289000
evaluation/num paths total       2890
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.298626
evaluation/Rewards Std              0.969319
evaluation/Rewards Max             -0.0709872
evaluation/Rewards Min             -9.8837
evaluation/Returns Mean           -29.8626
evaluation/Returns Std             17.9327
evaluation/Returns Max            -14.4033
evaluation/Returns Min            -64.7439
evaluation/Actions Mean             0.0287829
evaluation/Actions Std              0.188586
evaluation/Actions Max              0.996769
evaluation/Actions Min             -0.99
evaluation/Num Paths               10
evaluation/Average Returns        -29.8626
time/data storing (s)               0.00108312
time/evaluation sampling (s)        0.243432
time/exploration sampling (s)       0.0601281
time/logging (s)                    0.00344724
time/saving (s)                     0.00232961
time/training (s)                   0.980725
time/epoch (s)                      1.29114
time/total (s)                    421.734
Epoch                             288
-----------------------------  ---------------
2019-04-21 12:23:28.530828 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 289 finished
-----------------------------  ---------------
replay_buffer/size              58200
trainer/QF1 Loss                    0.00965567
trainer/QF2 Loss                    0.00711166
trainer/Policy Loss                 8.8885
trainer/Q1 Predictions Mean        -6.86569
trainer/Q1 Predictions Std          2.93422
trainer/Q1 Predictions Max         -6.18909
trainer/Q1 Predictions Min        -33.8964
trainer/Q2 Predictions Mean        -6.85677
trainer/Q2 Predictions Std          2.92159
trainer/Q2 Predictions Max         -6.19926
trainer/Q2 Predictions Min        -33.9832
trainer/Q Targets Mean             -6.84945
trainer/Q Targets Std               2.93208
trainer/Q Targets Max              -6.12469
trainer/Q Targets Min             -33.9872
trainer/Log Pis Mean                2.10243
trainer/Log Pis Std                 0.950746
trainer/Log Pis Max                 4.70095
trainer/Log Pis Min                -2.30815
trainer/Policy mu Mean              0.0495221
trainer/Policy mu Std               0.511714
trainer/Policy mu Max               2.83416
trainer/Policy mu Min              -2.65426
trainer/Policy log std Mean        -2.2229
trainer/Policy log std Std          0.394586
trainer/Policy log std Max         -0.557646
trainer/Policy log std Min         -2.47277
trainer/Alpha                       0.0561735
trainer/Alpha Loss                  0.294936
exploration/num steps total     58200
exploration/num paths total       582
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.144242
exploration/Rewards Std             0.209604
exploration/Rewards Max            -0.004053
exploration/Rewards Min            -2.042
exploration/Returns Mean          -14.4242
exploration/Returns Std             0.245752
exploration/Returns Max           -14.1785
exploration/Returns Min           -14.67
exploration/Actions Mean            0.0123142
exploration/Actions Std             0.174054
exploration/Actions Max             0.986572
exploration/Actions Min            -0.836202
exploration/Num Paths               2
exploration/Average Returns       -14.4242
evaluation/num steps total     290000
evaluation/num paths total       2900
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.289505
evaluation/Rewards Std              1.19936
evaluation/Rewards Max             -0.0160329
evaluation/Rewards Min            -11.1272
evaluation/Returns Mean           -28.9505
evaluation/Returns Std             19.3211
evaluation/Returns Max             -4.95265
evaluation/Returns Min            -61.2975
evaluation/Actions Mean             0.0397984
evaluation/Actions Std              0.208966
evaluation/Actions Max              0.996305
evaluation/Actions Min             -0.978018
evaluation/Num Paths               10
evaluation/Average Returns        -28.9505
time/data storing (s)               0.00154973
time/evaluation sampling (s)        0.269136
time/exploration sampling (s)       0.0855055
time/logging (s)                    0.00379711
time/saving (s)                     0.00283992
time/training (s)                   1.21944
time/epoch (s)                      1.58227
time/total (s)                    423.32
Epoch                             289
-----------------------------  ---------------
2019-04-21 12:23:29.870615 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 290 finished
-----------------------------  ---------------
replay_buffer/size              58400
trainer/QF1 Loss                    0.76813
trainer/QF2 Loss                    0.754128
trainer/Policy Loss                10.0047
trainer/Q1 Predictions Mean        -7.93193
trainer/Q1 Predictions Std          5.67455
trainer/Q1 Predictions Max         -6.16866
trainer/Q1 Predictions Min        -49.1694
trainer/Q2 Predictions Mean        -7.92839
trainer/Q2 Predictions Std          5.75164
trainer/Q2 Predictions Max         -6.15002
trainer/Q2 Predictions Min        -49.7056
trainer/Q Targets Mean             -7.83236
trainer/Q Targets Std               5.82709
trainer/Q Targets Max              -0.0980717
trainer/Q Targets Min             -49.4778
trainer/Log Pis Mean                2.42184
trainer/Log Pis Std                 1.04983
trainer/Log Pis Max                 6.38169
trainer/Log Pis Min                 0.00289202
trainer/Policy mu Mean              0.157005
trainer/Policy mu Std               0.707368
trainer/Policy mu Max               3.49347
trainer/Policy mu Min              -2.53868
trainer/Policy log std Mean        -2.25722
trainer/Policy log std Std          0.496426
trainer/Policy log std Max         -0.418787
trainer/Policy log std Min         -2.54376
trainer/Alpha                       0.0575295
trainer/Alpha Loss                  1.20472
exploration/num steps total     58400
exploration/num paths total       584
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.302632
exploration/Rewards Std             0.895842
exploration/Rewards Max            -0.0115168
exploration/Rewards Min            -6.49184
exploration/Returns Mean          -30.2632
exploration/Returns Std             4.73103
exploration/Returns Max           -25.5321
exploration/Returns Min           -34.9942
exploration/Actions Mean            0.017742
exploration/Actions Std             0.234592
exploration/Actions Max             0.997017
exploration/Actions Min            -0.976125
exploration/Num Paths               2
exploration/Average Returns       -30.2632
evaluation/num steps total     291000
evaluation/num paths total       2910
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.223624
evaluation/Rewards Std              1.00993
evaluation/Rewards Max             -0.0142717
evaluation/Rewards Min            -10.143
evaluation/Returns Mean           -22.3624
evaluation/Returns Std             14.2866
evaluation/Returns Max             -5.62165
evaluation/Returns Min            -53.6958
evaluation/Actions Mean             0.028544
evaluation/Actions Std              0.195384
evaluation/Actions Max              0.998666
evaluation/Actions Min             -0.990968
evaluation/Num Paths               10
evaluation/Average Returns        -22.3624
time/data storing (s)               0.00120589
time/evaluation sampling (s)        0.265096
time/exploration sampling (s)       0.0717267
time/logging (s)                    0.00341854
time/saving (s)                     0.00240995
time/training (s)                   0.985692
time/epoch (s)                      1.32955
time/total (s)                    424.655
Epoch                             290
-----------------------------  ---------------
2019-04-21 12:23:31.194543 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 291 finished
-----------------------------  ---------------
replay_buffer/size              58600
trainer/QF1 Loss                    0.420978
trainer/QF2 Loss                    0.405511
trainer/Policy Loss                 9.3317
trainer/Q1 Predictions Mean        -7.46324
trainer/Q1 Predictions Std          5.7376
trainer/Q1 Predictions Max         -6.06768
trainer/Q1 Predictions Min        -51.9136
trainer/Q2 Predictions Mean        -7.49331
trainer/Q2 Predictions Std          5.77274
trainer/Q2 Predictions Max         -6.10104
trainer/Q2 Predictions Min        -52.1104
trainer/Q Targets Mean             -7.51091
trainer/Q Targets Std               5.83913
trainer/Q Targets Max              -0.00756552
trainer/Q Targets Min             -51.958
trainer/Log Pis Mean                2.02623
trainer/Log Pis Std                 1.08468
trainer/Log Pis Max                 5.47863
trainer/Log Pis Min                -1.22834
trainer/Policy mu Mean              0.111652
trainer/Policy mu Std               0.603646
trainer/Policy mu Max               3.39824
trainer/Policy mu Min              -1.7523
trainer/Policy log std Mean        -2.22834
trainer/Policy log std Std          0.408309
trainer/Policy log std Max         -0.601837
trainer/Policy log std Min         -2.44677
trainer/Alpha                       0.058518
trainer/Alpha Loss                  0.07444
exploration/num steps total     58600
exploration/num paths total       586
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.211728
exploration/Rewards Std             0.592797
exploration/Rewards Max            -0.014648
exploration/Rewards Min            -5.83102
exploration/Returns Mean          -21.1728
exploration/Returns Std             7.07629
exploration/Returns Max           -14.0965
exploration/Returns Min           -28.2491
exploration/Actions Mean            0.0314018
exploration/Actions Std             0.200194
exploration/Actions Max             0.999235
exploration/Actions Min            -0.3342
exploration/Num Paths               2
exploration/Average Returns       -21.1728
evaluation/num steps total     292000
evaluation/num paths total       2920
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.220689
evaluation/Rewards Std              0.997011
evaluation/Rewards Max             -0.0114959
evaluation/Rewards Min            -10.552
evaluation/Returns Mean           -22.0689
evaluation/Returns Std             16.975
evaluation/Returns Max             -3.44728
evaluation/Returns Min            -54.0524
evaluation/Actions Mean             0.0244305
evaluation/Actions Std              0.187065
evaluation/Actions Max              0.997608
evaluation/Actions Min             -0.991907
evaluation/Num Paths               10
evaluation/Average Returns        -22.0689
time/data storing (s)               0.00118612
time/evaluation sampling (s)        0.255495
time/exploration sampling (s)       0.0688094
time/logging (s)                    0.00342595
time/saving (s)                     0.00187159
time/training (s)                   0.983583
time/epoch (s)                      1.31437
time/total (s)                    425.974
Epoch                             291
-----------------------------  ---------------
2019-04-21 12:23:32.529990 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 292 finished
-----------------------------  ---------------
replay_buffer/size              58800
trainer/QF1 Loss                    0.403565
trainer/QF2 Loss                    0.402119
trainer/Policy Loss                 9.43544
trainer/Q1 Predictions Mean        -7.50281
trainer/Q1 Predictions Std          5.80602
trainer/Q1 Predictions Max         -6.1395
trainer/Q1 Predictions Min        -46.5582
trainer/Q2 Predictions Mean        -7.56446
trainer/Q2 Predictions Std          5.84143
trainer/Q2 Predictions Max         -6.17934
trainer/Q2 Predictions Min        -46.6655
trainer/Q Targets Mean             -7.50648
trainer/Q Targets Std               5.97453
trainer/Q Targets Max              -0.0408738
trainer/Q Targets Min             -47.0575
trainer/Log Pis Mean                1.99038
trainer/Log Pis Std                 1.2666
trainer/Log Pis Max                 5.5721
trainer/Log Pis Min                -4.04665
trainer/Policy mu Mean              0.0793024
trainer/Policy mu Std               0.603695
trainer/Policy mu Max               2.95434
trainer/Policy mu Min              -2.73599
trainer/Policy log std Mean        -2.16713
trainer/Policy log std Std          0.442704
trainer/Policy log std Max         -0.587291
trainer/Policy log std Min         -2.42011
trainer/Alpha                       0.0587843
trainer/Alpha Loss                 -0.0272553
exploration/num steps total     58800
exploration/num paths total       588
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.156111
exploration/Rewards Std             0.26014
exploration/Rewards Max            -0.0125558
exploration/Rewards Min            -2.99882
exploration/Returns Mean          -15.6111
exploration/Returns Std             2.23841
exploration/Returns Max           -13.3727
exploration/Returns Min           -17.8495
exploration/Actions Mean           -0.00491734
exploration/Actions Std             0.171608
exploration/Actions Max             0.883618
exploration/Actions Min            -0.988686
exploration/Num Paths               2
exploration/Average Returns       -15.6111
evaluation/num steps total     293000
evaluation/num paths total       2930
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.298381
evaluation/Rewards Std              1.21438
evaluation/Rewards Max             -0.0153157
evaluation/Rewards Min            -10.7847
evaluation/Returns Mean           -29.8381
evaluation/Returns Std             20.7741
evaluation/Returns Max             -4.62069
evaluation/Returns Min            -63.2424
evaluation/Actions Mean             0.0342353
evaluation/Actions Std              0.200944
evaluation/Actions Max              0.996151
evaluation/Actions Min             -0.996137
evaluation/Num Paths               10
evaluation/Average Returns        -29.8381
time/data storing (s)               0.00140118
time/evaluation sampling (s)        0.259296
time/exploration sampling (s)       0.0682862
time/logging (s)                    0.00359281
time/saving (s)                     0.00235315
time/training (s)                   0.991759
time/epoch (s)                      1.32669
time/total (s)                    427.305
Epoch                             292
-----------------------------  ---------------
2019-04-21 12:23:33.858648 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 293 finished
-----------------------------  ---------------
replay_buffer/size              59000
trainer/QF1 Loss                    0.388841
trainer/QF2 Loss                    0.386407
trainer/Policy Loss                 9.7561
trainer/Q1 Predictions Mean        -8.05842
trainer/Q1 Predictions Std          7.70125
trainer/Q1 Predictions Max         -6.17358
trainer/Q1 Predictions Min        -57.9009
trainer/Q2 Predictions Mean        -8.06782
trainer/Q2 Predictions Std          7.70728
trainer/Q2 Predictions Max         -6.19959
trainer/Q2 Predictions Min        -58.3267
trainer/Q Targets Mean             -7.97432
trainer/Q Targets Std               7.72177
trainer/Q Targets Max              -0.184489
trainer/Q Targets Min             -58.0587
trainer/Log Pis Mean                1.92385
trainer/Log Pis Std                 1.17285
trainer/Log Pis Max                 4.64024
trainer/Log Pis Min                -3.09231
trainer/Policy mu Mean              0.131798
trainer/Policy mu Std               0.623703
trainer/Policy mu Max               3.28729
trainer/Policy mu Min              -1.34907
trainer/Policy log std Mean        -2.19932
trainer/Policy log std Std          0.441979
trainer/Policy log std Max         -0.612594
trainer/Policy log std Min         -2.45989
trainer/Alpha                       0.0575352
trainer/Alpha Loss                 -0.217429
exploration/num steps total     59000
exploration/num paths total       590
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.195644
exploration/Rewards Std             0.443249
exploration/Rewards Max            -0.00374041
exploration/Rewards Min            -3.79677
exploration/Returns Mean          -19.5644
exploration/Returns Std             0.649733
exploration/Returns Max           -18.9147
exploration/Returns Min           -20.2142
exploration/Actions Mean            0.025446
exploration/Actions Std             0.203856
exploration/Actions Max             0.996666
exploration/Actions Min            -0.551667
exploration/Num Paths               2
exploration/Average Returns       -19.5644
evaluation/num steps total     294000
evaluation/num paths total       2940
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.229706
evaluation/Rewards Std              0.946173
evaluation/Rewards Max             -0.00219038
evaluation/Rewards Min             -9.00049
evaluation/Returns Mean           -22.9706
evaluation/Returns Std             10.6263
evaluation/Returns Max             -4.78658
evaluation/Returns Min            -40.2358
evaluation/Actions Mean             0.0220366
evaluation/Actions Std              0.196439
evaluation/Actions Max              0.997661
evaluation/Actions Min             -0.998191
evaluation/Num Paths               10
evaluation/Average Returns        -22.9706
time/data storing (s)               0.00112804
time/evaluation sampling (s)        0.252957
time/exploration sampling (s)       0.0726347
time/logging (s)                    0.00373842
time/saving (s)                     0.00276795
time/training (s)                   0.986714
time/epoch (s)                      1.31994
time/total (s)                    428.63
Epoch                             293
-----------------------------  ---------------
2019-04-21 12:23:35.190013 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 294 finished
-----------------------------  ---------------
replay_buffer/size              59200
trainer/QF1 Loss                    0.763601
trainer/QF2 Loss                    0.756529
trainer/Policy Loss                 8.91026
trainer/Q1 Predictions Mean        -7.14293
trainer/Q1 Predictions Std          3.92693
trainer/Q1 Predictions Max         -6.09494
trainer/Q1 Predictions Min        -35.9172
trainer/Q2 Predictions Mean        -7.09801
trainer/Q2 Predictions Std          3.88623
trainer/Q2 Predictions Max         -6.07763
trainer/Q2 Predictions Min        -35.6261
trainer/Q Targets Mean             -7.09288
trainer/Q Targets Std               3.99282
trainer/Q Targets Max              -0.097949
trainer/Q Targets Min             -35.6104
trainer/Log Pis Mean                2.02584
trainer/Log Pis Std                 1.14577
trainer/Log Pis Max                 7.41915
trainer/Log Pis Min                -0.952473
trainer/Policy mu Mean              0.0815844
trainer/Policy mu Std               0.581346
trainer/Policy mu Max               2.84066
trainer/Policy mu Min              -1.52902
trainer/Policy log std Mean        -2.1345
trainer/Policy log std Std          0.398882
trainer/Policy log std Max         -0.618672
trainer/Policy log std Min         -2.36954
trainer/Alpha                       0.0562679
trainer/Alpha Loss                  0.0743523
exploration/num steps total     59200
exploration/num paths total       592
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.479349
exploration/Rewards Std             1.43029
exploration/Rewards Max            -0.0023008
exploration/Rewards Min           -10.2513
exploration/Returns Mean          -47.9349
exploration/Returns Std            23.1196
exploration/Returns Max           -24.8153
exploration/Returns Min           -71.0545
exploration/Actions Mean            0.0403681
exploration/Actions Std             0.246079
exploration/Actions Max             0.998184
exploration/Actions Min            -0.559141
exploration/Num Paths               2
exploration/Average Returns       -47.9349
evaluation/num steps total     295000
evaluation/num paths total       2950
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.238578
evaluation/Rewards Std              0.955478
evaluation/Rewards Max             -0.0297566
evaluation/Rewards Min             -9.79576
evaluation/Returns Mean           -23.8578
evaluation/Returns Std             15.0099
evaluation/Returns Max             -9.85659
evaluation/Returns Min            -53.1832
evaluation/Actions Mean             0.028055
evaluation/Actions Std              0.188898
evaluation/Actions Max              0.995943
evaluation/Actions Min             -0.99251
evaluation/Num Paths               10
evaluation/Average Returns        -23.8578
time/data storing (s)               0.00118626
time/evaluation sampling (s)        0.255502
time/exploration sampling (s)       0.0685903
time/logging (s)                    0.0034166
time/saving (s)                     0.0023902
time/training (s)                   0.990963
time/epoch (s)                      1.32205
time/total (s)                    429.956
Epoch                             294
-----------------------------  ---------------
2019-04-21 12:23:36.537510 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 295 finished
-----------------------------  ---------------
replay_buffer/size              59400
trainer/QF1 Loss                    0.404336
trainer/QF2 Loss                    0.419861
trainer/Policy Loss                 8.82244
trainer/Q1 Predictions Mean        -6.78241
trainer/Q1 Predictions Std          3.09224
trainer/Q1 Predictions Max         -6.11608
trainer/Q1 Predictions Min        -31.6483
trainer/Q2 Predictions Mean        -6.7905
trainer/Q2 Predictions Std          3.13047
trainer/Q2 Predictions Max         -6.11091
trainer/Q2 Predictions Min        -32.049
trainer/Q Targets Mean             -6.74843
trainer/Q Targets Std               3.04913
trainer/Q Targets Max              -0.0661729
trainer/Q Targets Min             -30.0703
trainer/Log Pis Mean                2.15557
trainer/Log Pis Std                 1.09497
trainer/Log Pis Max                 7.98806
trainer/Log Pis Min                -1.47818
trainer/Policy mu Mean              0.0820978
trainer/Policy mu Std               0.444369
trainer/Policy mu Max               3.46708
trainer/Policy mu Min              -0.965869
trainer/Policy log std Mean        -2.3364
trainer/Policy log std Std          0.290419
trainer/Policy log std Max         -0.490247
trainer/Policy log std Min         -2.47824
trainer/Alpha                       0.056422
trainer/Alpha Loss                  0.44726
exploration/num steps total     59400
exploration/num paths total       594
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.224734
exploration/Rewards Std             0.654215
exploration/Rewards Max            -0.00412795
exploration/Rewards Min            -6.10308
exploration/Returns Mean          -22.4734
exploration/Returns Std             6.85158
exploration/Returns Max           -15.6219
exploration/Returns Min           -29.325
exploration/Actions Mean            0.0289806
exploration/Actions Std             0.213958
exploration/Actions Max             0.998635
exploration/Actions Min            -0.970237
exploration/Num Paths               2
exploration/Average Returns       -22.4734
evaluation/num steps total     296000
evaluation/num paths total       2960
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.261907
evaluation/Rewards Std              1.07107
evaluation/Rewards Max             -0.016905
evaluation/Rewards Min            -11.0732
evaluation/Returns Mean           -26.1907
evaluation/Returns Std             16.0805
evaluation/Returns Max             -5.27181
evaluation/Returns Min            -61.4726
evaluation/Actions Mean             0.0320227
evaluation/Actions Std              0.198787
evaluation/Actions Max              0.997221
evaluation/Actions Min             -0.993748
evaluation/Num Paths               10
evaluation/Average Returns        -26.1907
time/data storing (s)               0.00121814
time/evaluation sampling (s)        0.250306
time/exploration sampling (s)       0.0703252
time/logging (s)                    0.00371651
time/saving (s)                     0.00288671
time/training (s)                   1.01066
time/epoch (s)                      1.33911
time/total (s)                    431.3
Epoch                             295
-----------------------------  ---------------
2019-04-21 12:23:37.876338 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 296 finished
-----------------------------  ---------------
replay_buffer/size              59600
trainer/QF1 Loss                    0.428195
trainer/QF2 Loss                    0.395994
trainer/Policy Loss                 9.00196
trainer/Q1 Predictions Mean        -7.25204
trainer/Q1 Predictions Std          5.98326
trainer/Q1 Predictions Max         -6.06918
trainer/Q1 Predictions Min        -56.114
trainer/Q2 Predictions Mean        -7.25404
trainer/Q2 Predictions Std          6.09474
trainer/Q2 Predictions Max         -6.08608
trainer/Q2 Predictions Min        -57.4086
trainer/Q Targets Mean             -7.30868
trainer/Q Targets Std               6.17837
trainer/Q Targets Max              -0.0361637
trainer/Q Targets Min             -58.2042
trainer/Log Pis Mean                1.92297
trainer/Log Pis Std                 1.2312
trainer/Log Pis Max                 7.41949
trainer/Log Pis Min                -2.30594
trainer/Policy mu Mean              0.0388354
trainer/Policy mu Std               0.558177
trainer/Policy mu Max               3.1487
trainer/Policy mu Min              -2.00797
trainer/Policy log std Mean        -2.14642
trainer/Policy log std Std          0.397826
trainer/Policy log std Max         -0.673164
trainer/Policy log std Min         -2.36004
trainer/Alpha                       0.057118
trainer/Alpha Loss                 -0.22049
exploration/num steps total     59600
exploration/num paths total       596
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.306547
exploration/Rewards Std             0.837557
exploration/Rewards Max            -0.00703606
exploration/Rewards Min            -5.9181
exploration/Returns Mean          -30.6547
exploration/Returns Std             1.7602
exploration/Returns Max           -28.8945
exploration/Returns Min           -32.4149
exploration/Actions Mean            0.0230989
exploration/Actions Std             0.238414
exploration/Actions Max             0.997569
exploration/Actions Min            -0.984266
exploration/Num Paths               2
exploration/Average Returns       -30.6547
evaluation/num steps total     297000
evaluation/num paths total       2970
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.352602
evaluation/Rewards Std              1.35901
evaluation/Rewards Max             -0.0352938
evaluation/Rewards Min            -10.3711
evaluation/Returns Mean           -35.2602
evaluation/Returns Std             18.3638
evaluation/Returns Max             -6.69411
evaluation/Returns Min            -60.4265
evaluation/Actions Mean             0.0267275
evaluation/Actions Std              0.216996
evaluation/Actions Max              0.996718
evaluation/Actions Min             -0.996815
evaluation/Num Paths               10
evaluation/Average Returns        -35.2602
time/data storing (s)               0.00114293
time/evaluation sampling (s)        0.257495
time/exploration sampling (s)       0.067248
time/logging (s)                    0.00376045
time/saving (s)                     0.00259135
time/training (s)                   0.996199
time/epoch (s)                      1.32844
time/total (s)                    432.633
Epoch                             296
-----------------------------  ---------------
2019-04-21 12:23:39.199627 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 297 finished
-----------------------------  ---------------
replay_buffer/size              59800
trainer/QF1 Loss                    1.08625
trainer/QF2 Loss                    1.12179
trainer/Policy Loss                 9.07146
trainer/Q1 Predictions Mean        -7.3683
trainer/Q1 Predictions Std          5.91605
trainer/Q1 Predictions Max         -6.05577
trainer/Q1 Predictions Min        -58.6764
trainer/Q2 Predictions Mean        -7.43615
trainer/Q2 Predictions Std          6.00423
trainer/Q2 Predictions Max         -6.0924
trainer/Q2 Predictions Min        -59.2271
trainer/Q Targets Mean             -7.42069
trainer/Q Targets Std               6.21718
trainer/Q Targets Max              -0.168755
trainer/Q Targets Min             -60.9125
trainer/Log Pis Mean                1.87946
trainer/Log Pis Std                 1.31596
trainer/Log Pis Max                 8.16104
trainer/Log Pis Min                -1.28954
trainer/Policy mu Mean              0.0288758
trainer/Policy mu Std               0.627875
trainer/Policy mu Max               3.37988
trainer/Policy mu Min              -2.89646
trainer/Policy log std Mean        -2.15664
trainer/Policy log std Std          0.426804
trainer/Policy log std Max         -0.514841
trainer/Policy log std Min         -2.37933
trainer/Alpha                       0.0578493
trainer/Alpha Loss                 -0.343549
exploration/num steps total     59800
exploration/num paths total       598
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.577943
exploration/Rewards Std             1.63349
exploration/Rewards Max            -0.0132653
exploration/Rewards Min            -9.37337
exploration/Returns Mean          -57.7943
exploration/Returns Std             1.18178
exploration/Returns Max           -56.6125
exploration/Returns Min           -58.976
exploration/Actions Mean            0.0617014
exploration/Actions Std             0.269862
exploration/Actions Max             0.999436
exploration/Actions Min            -0.559485
exploration/Num Paths               2
exploration/Average Returns       -57.7943
evaluation/num steps total     298000
evaluation/num paths total       2980
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.190015
evaluation/Rewards Std              0.871315
evaluation/Rewards Max             -0.0275943
evaluation/Rewards Min             -8.6096
evaluation/Returns Mean           -19.0015
evaluation/Returns Std             14.0541
evaluation/Returns Max             -4.02398
evaluation/Returns Min            -43.5276
evaluation/Actions Mean             0.0228226
evaluation/Actions Std              0.177376
evaluation/Actions Max              0.996408
evaluation/Actions Min             -0.995625
evaluation/Num Paths               10
evaluation/Average Returns        -19.0015
time/data storing (s)               0.00121906
time/evaluation sampling (s)        0.256943
time/exploration sampling (s)       0.0694862
time/logging (s)                    0.0034256
time/saving (s)                     0.00229296
time/training (s)                   0.980693
time/epoch (s)                      1.31406
time/total (s)                    433.951
Epoch                             297
-----------------------------  ---------------
2019-04-21 12:23:40.519375 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 298 finished
-----------------------------  ---------------
replay_buffer/size              60000
trainer/QF1 Loss                    1.12152
trainer/QF2 Loss                    1.12595
trainer/Policy Loss                 8.88604
trainer/Q1 Predictions Mean        -6.81919
trainer/Q1 Predictions Std          3.88048
trainer/Q1 Predictions Max         -6.05528
trainer/Q1 Predictions Min        -43.5428
trainer/Q2 Predictions Mean        -6.85906
trainer/Q2 Predictions Std          3.88272
trainer/Q2 Predictions Max         -6.11259
trainer/Q2 Predictions Min        -43.6104
trainer/Q Targets Mean             -6.71742
trainer/Q Targets Std               3.95924
trainer/Q Targets Max              -0.20092
trainer/Q Targets Min             -43.0018
trainer/Log Pis Mean                2.08299
trainer/Log Pis Std                 1.10983
trainer/Log Pis Max                 5.74908
trainer/Log Pis Min                -2.80757
trainer/Policy mu Mean              0.0444141
trainer/Policy mu Std               0.505609
trainer/Policy mu Max               3.04524
trainer/Policy mu Min              -2.8981
trainer/Policy log std Mean        -2.27495
trainer/Policy log std Std          0.375087
trainer/Policy log std Max         -0.366126
trainer/Policy log std Min         -2.49124
trainer/Alpha                       0.0574821
trainer/Alpha Loss                  0.237064
exploration/num steps total     60000
exploration/num paths total       600
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.188667
exploration/Rewards Std             0.452248
exploration/Rewards Max            -0.00336464
exploration/Rewards Min            -3.65158
exploration/Returns Mean          -18.8667
exploration/Returns Std             0.188316
exploration/Returns Max           -18.6784
exploration/Returns Min           -19.055
exploration/Actions Mean            0.00244717
exploration/Actions Std             0.195274
exploration/Actions Max             0.996095
exploration/Actions Min            -0.997897
exploration/Num Paths               2
exploration/Average Returns       -18.8667
evaluation/num steps total     299000
evaluation/num paths total       2990
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.229752
evaluation/Rewards Std              1.10084
evaluation/Rewards Max             -0.0119845
evaluation/Rewards Min            -11.0712
evaluation/Returns Mean           -22.9752
evaluation/Returns Std             20.4573
evaluation/Returns Max             -2.08046
evaluation/Returns Min            -60.4333
evaluation/Actions Mean             0.0236623
evaluation/Actions Std              0.189508
evaluation/Actions Max              0.99721
evaluation/Actions Min             -0.992583
evaluation/Num Paths               10
evaluation/Average Returns        -22.9752
time/data storing (s)               0.00120047
time/evaluation sampling (s)        0.25862
time/exploration sampling (s)       0.06866
time/logging (s)                    0.00337607
time/saving (s)                     0.00230792
time/training (s)                   0.977715
time/epoch (s)                      1.31188
time/total (s)                    435.267
Epoch                             298
-----------------------------  ---------------
2019-04-21 12:23:41.838730 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 299 finished
-----------------------------  ---------------
replay_buffer/size              60200
trainer/QF1 Loss                    0.0580894
trainer/QF2 Loss                    0.19359
trainer/Policy Loss                 9.72405
trainer/Q1 Predictions Mean        -7.80145
trainer/Q1 Predictions Std          6.42974
trainer/Q1 Predictions Max         -6.21046
trainer/Q1 Predictions Min        -62.7079
trainer/Q2 Predictions Mean        -7.67763
trainer/Q2 Predictions Std          6.18432
trainer/Q2 Predictions Max         -6.12721
trainer/Q2 Predictions Min        -60.0943
trainer/Q Targets Mean             -7.73811
trainer/Q Targets Std               6.55104
trainer/Q Targets Max              -6.08636
trainer/Q Targets Min             -64.1822
trainer/Log Pis Mean                2.20158
trainer/Log Pis Std                 1.10873
trainer/Log Pis Max                 6.00673
trainer/Log Pis Min                -4.49525
trainer/Policy mu Mean              0.0877659
trainer/Policy mu Std               0.615998
trainer/Policy mu Max               2.96908
trainer/Policy mu Min              -2.74522
trainer/Policy log std Mean        -2.16973
trainer/Policy log std Std          0.421563
trainer/Policy log std Max         -0.557917
trainer/Policy log std Min         -2.38442
trainer/Alpha                       0.0578272
trainer/Alpha Loss                  0.574566
exploration/num steps total     60200
exploration/num paths total       602
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.451167
exploration/Rewards Std             1.33508
exploration/Rewards Max            -0.00854626
exploration/Rewards Min            -9.52464
exploration/Returns Mean          -45.1167
exploration/Returns Std            17.1774
exploration/Returns Max           -27.9393
exploration/Returns Min           -62.2941
exploration/Actions Mean            0.0224339
exploration/Actions Std             0.253227
exploration/Actions Max             0.997014
exploration/Actions Min            -0.998729
exploration/Num Paths               2
exploration/Average Returns       -45.1167
evaluation/num steps total     300000
evaluation/num paths total       3000
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.195503
evaluation/Rewards Std              0.948499
evaluation/Rewards Max             -0.0135759
evaluation/Rewards Min             -9.15983
evaluation/Returns Mean           -19.5503
evaluation/Returns Std             14.3681
evaluation/Returns Max             -1.37371
evaluation/Returns Min            -48.3086
evaluation/Actions Mean             0.0271966
evaluation/Actions Std              0.186766
evaluation/Actions Max              0.995169
evaluation/Actions Min             -0.98472
evaluation/Num Paths               10
evaluation/Average Returns        -19.5503
time/data storing (s)               0.00136082
time/evaluation sampling (s)        0.260707
time/exploration sampling (s)       0.0679674
time/logging (s)                    0.00344312
time/saving (s)                     0.00188014
time/training (s)                   0.975413
time/epoch (s)                      1.31077
time/total (s)                    436.582
Epoch                             299
-----------------------------  ---------------
2019-04-21 12:23:43.187673 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 300 finished
-----------------------------  ---------------
replay_buffer/size              60400
trainer/QF1 Loss                    0.066843
trainer/QF2 Loss                    0.074637
trainer/Policy Loss                 9.25171
trainer/Q1 Predictions Mean        -7.50538
trainer/Q1 Predictions Std          5.96504
trainer/Q1 Predictions Max         -6.15935
trainer/Q1 Predictions Min        -57.015
trainer/Q2 Predictions Mean        -7.52125
trainer/Q2 Predictions Std          5.9024
trainer/Q2 Predictions Max         -6.20119
trainer/Q2 Predictions Min        -56.2639
trainer/Q Targets Mean             -7.51461
trainer/Q Targets Std               5.85757
trainer/Q Targets Max              -6.07435
trainer/Q Targets Min             -56.8618
trainer/Log Pis Mean                1.8823
trainer/Log Pis Std                 0.86278
trainer/Log Pis Max                 4.14954
trainer/Log Pis Min                -0.936979
trainer/Policy mu Mean              0.116035
trainer/Policy mu Std               0.548922
trainer/Policy mu Max               3.34805
trainer/Policy mu Min              -1.05635
trainer/Policy log std Mean        -2.15711
trainer/Policy log std Std          0.364216
trainer/Policy log std Max         -0.408668
trainer/Policy log std Min         -2.31865
trainer/Alpha                       0.0564262
trainer/Alpha Loss                 -0.338353
exploration/num steps total     60400
exploration/num paths total       604
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.309446
exploration/Rewards Std             0.893195
exploration/Rewards Max            -0.00886405
exploration/Rewards Min            -7.65243
exploration/Returns Mean          -30.9446
exploration/Returns Std            11.4812
exploration/Returns Max           -19.4634
exploration/Returns Min           -42.4258
exploration/Actions Mean            0.0411313
exploration/Actions Std             0.235316
exploration/Actions Max             0.999337
exploration/Actions Min            -0.489521
exploration/Num Paths               2
exploration/Average Returns       -30.9446
evaluation/num steps total     301000
evaluation/num paths total       3010
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.234567
evaluation/Rewards Std              0.926111
evaluation/Rewards Max             -0.0112222
evaluation/Rewards Min            -10.6786
evaluation/Returns Mean           -23.4567
evaluation/Returns Std             14.0722
evaluation/Returns Max             -6.55692
evaluation/Returns Min            -57.7014
evaluation/Actions Mean             0.0209492
evaluation/Actions Std              0.190862
evaluation/Actions Max              0.997787
evaluation/Actions Min             -0.995829
evaluation/Num Paths               10
evaluation/Average Returns        -23.4567
time/data storing (s)               0.00118305
time/evaluation sampling (s)        0.260862
time/exploration sampling (s)       0.0675444
time/logging (s)                    0.00353746
time/saving (s)                     0.00807873
time/training (s)                   0.999023
time/epoch (s)                      1.34023
time/total (s)                    437.927
Epoch                             300
-----------------------------  ---------------
2019-04-21 12:23:44.502977 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 301 finished
-----------------------------  ---------------
replay_buffer/size              60600
trainer/QF1 Loss                    0.768218
trainer/QF2 Loss                    0.749189
trainer/Policy Loss                 8.7609
trainer/Q1 Predictions Mean        -6.77414
trainer/Q1 Predictions Std          2.93466
trainer/Q1 Predictions Max         -5.97315
trainer/Q1 Predictions Min        -27.7761
trainer/Q2 Predictions Mean        -6.82737
trainer/Q2 Predictions Std          2.90846
trainer/Q2 Predictions Max         -6.04061
trainer/Q2 Predictions Min        -27.4955
trainer/Q Targets Mean             -6.83862
trainer/Q Targets Std               3.02821
trainer/Q Targets Max              -0.156778
trainer/Q Targets Min             -27.8072
trainer/Log Pis Mean                2.02528
trainer/Log Pis Std                 1.35325
trainer/Log Pis Max                 8.16912
trainer/Log Pis Min                -1.4242
trainer/Policy mu Mean              0.121685
trainer/Policy mu Std               0.656729
trainer/Policy mu Max               2.95169
trainer/Policy mu Min              -3.77669
trainer/Policy log std Mean        -2.1666
trainer/Policy log std Std          0.459914
trainer/Policy log std Max         -0.359478
trainer/Policy log std Min         -2.41257
trainer/Alpha                       0.0540926
trainer/Alpha Loss                  0.0737423
exploration/num steps total     60600
exploration/num paths total       606
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.433718
exploration/Rewards Std             1.29336
exploration/Rewards Max            -0.00431572
exploration/Rewards Min            -9.25548
exploration/Returns Mean          -43.3718
exploration/Returns Std            15.3614
exploration/Returns Max           -28.0104
exploration/Returns Min           -58.7333
exploration/Actions Mean            0.0156191
exploration/Actions Std             0.251208
exploration/Actions Max             0.995021
exploration/Actions Min            -0.999201
exploration/Num Paths               2
exploration/Average Returns       -43.3718
evaluation/num steps total     302000
evaluation/num paths total       3020
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.163051
evaluation/Rewards Std              0.757009
evaluation/Rewards Max             -0.00555104
evaluation/Rewards Min            -10.4726
evaluation/Returns Mean           -16.3051
evaluation/Returns Std             14.0631
evaluation/Returns Max             -5.92801
evaluation/Returns Min            -54.8433
evaluation/Actions Mean             0.0275737
evaluation/Actions Std              0.172113
evaluation/Actions Max              0.997776
evaluation/Actions Min             -0.971207
evaluation/Num Paths               10
evaluation/Average Returns        -16.3051
time/data storing (s)               0.00117035
time/evaluation sampling (s)        0.258265
time/exploration sampling (s)       0.0670728
time/logging (s)                    0.00316414
time/saving (s)                     0.00233419
time/training (s)                   0.97392
time/epoch (s)                      1.30593
time/total (s)                    439.237
Epoch                             301
-----------------------------  ---------------
2019-04-21 12:23:45.837812 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 302 finished
-----------------------------  ---------------
replay_buffer/size              60800
trainer/QF1 Loss                    0.410764
trainer/QF2 Loss                    0.406543
trainer/Policy Loss                 9.25923
trainer/Q1 Predictions Mean        -7.29511
trainer/Q1 Predictions Std          5.54746
trainer/Q1 Predictions Max         -5.99263
trainer/Q1 Predictions Min        -50.8292
trainer/Q2 Predictions Mean        -7.31165
trainer/Q2 Predictions Std          5.55445
trainer/Q2 Predictions Max         -6.02192
trainer/Q2 Predictions Min        -50.9737
trainer/Q Targets Mean             -7.44086
trainer/Q Targets Std               5.68818
trainer/Q Targets Max              -0.153857
trainer/Q Targets Min             -51.8011
trainer/Log Pis Mean                2.06244
trainer/Log Pis Std                 1.14318
trainer/Log Pis Max                 5.68377
trainer/Log Pis Min                -1.51154
trainer/Policy mu Mean              0.0541563
trainer/Policy mu Std               0.604463
trainer/Policy mu Max               3.12609
trainer/Policy mu Min              -2.5831
trainer/Policy log std Mean        -2.19729
trainer/Policy log std Std          0.422825
trainer/Policy log std Max         -0.57198
trainer/Policy log std Min         -2.41579
trainer/Alpha                       0.053371
trainer/Alpha Loss                  0.183002
exploration/num steps total     60800
exploration/num paths total       608
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.348098
exploration/Rewards Std             0.964138
exploration/Rewards Max            -0.00785316
exploration/Rewards Min            -7.21493
exploration/Returns Mean          -34.8098
exploration/Returns Std             7.44919
exploration/Returns Max           -27.3606
exploration/Returns Min           -42.259
exploration/Actions Mean            0.0395297
exploration/Actions Std             0.235334
exploration/Actions Max             0.99873
exploration/Actions Min            -0.825205
exploration/Num Paths               2
exploration/Average Returns       -34.8098
evaluation/num steps total     303000
evaluation/num paths total       3030
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.165282
evaluation/Rewards Std              0.728967
evaluation/Rewards Max             -0.0297425
evaluation/Rewards Min             -7.81404
evaluation/Returns Mean           -16.5282
evaluation/Returns Std              7.34362
evaluation/Returns Max             -6.45804
evaluation/Returns Min            -29.47
evaluation/Actions Mean             0.0239664
evaluation/Actions Std              0.188415
evaluation/Actions Max              0.995736
evaluation/Actions Min             -0.991606
evaluation/Num Paths               10
evaluation/Average Returns        -16.5282
time/data storing (s)               0.00123156
time/evaluation sampling (s)        0.261752
time/exploration sampling (s)       0.0676956
time/logging (s)                    0.00338335
time/saving (s)                     0.00236778
time/training (s)                   0.989587
time/epoch (s)                      1.32602
time/total (s)                    440.567
Epoch                             302
-----------------------------  ---------------
2019-04-21 12:23:47.161881 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 303 finished
-----------------------------  ---------------
replay_buffer/size              61000
trainer/QF1 Loss                    0.506755
trainer/QF2 Loss                    0.47313
trainer/Policy Loss                10.0663
trainer/Q1 Predictions Mean        -7.99861
trainer/Q1 Predictions Std          7.83765
trainer/Q1 Predictions Max         -6.03714
trainer/Q1 Predictions Min        -62.624
trainer/Q2 Predictions Mean        -8.13865
trainer/Q2 Predictions Std          7.90247
trainer/Q2 Predictions Max         -6.15504
trainer/Q2 Predictions Min        -62.5469
trainer/Q Targets Mean             -8.10753
trainer/Q Targets Std               8.07565
trainer/Q Targets Max              -0.185588
trainer/Q Targets Min             -63.9539
trainer/Log Pis Mean                2.20056
trainer/Log Pis Std                 1.32912
trainer/Log Pis Max                 8.45253
trainer/Log Pis Min                -1.82105
trainer/Policy mu Mean              0.0868788
trainer/Policy mu Std               0.648024
trainer/Policy mu Max               3.18986
trainer/Policy mu Min              -3.24703
trainer/Policy log std Mean        -2.19388
trainer/Policy log std Std          0.438547
trainer/Policy log std Max         -0.521076
trainer/Policy log std Min         -2.46177
trainer/Alpha                       0.0551751
trainer/Alpha Loss                  0.581048
exploration/num steps total     61000
exploration/num paths total       610
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.476198
exploration/Rewards Std             1.46345
exploration/Rewards Max            -0.014817
exploration/Rewards Min           -10.2699
exploration/Returns Mean          -47.6198
exploration/Returns Std            22.3117
exploration/Returns Max           -25.3081
exploration/Returns Min           -69.9315
exploration/Actions Mean            0.0179621
exploration/Actions Std             0.251801
exploration/Actions Max             0.999434
exploration/Actions Min            -0.991215
exploration/Num Paths               2
exploration/Average Returns       -47.6198
evaluation/num steps total     304000
evaluation/num paths total       3040
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.225824
evaluation/Rewards Std              1.00316
evaluation/Rewards Max             -0.0130633
evaluation/Rewards Min             -9.88133
evaluation/Returns Mean           -22.5824
evaluation/Returns Std             17.4511
evaluation/Returns Max             -4.66161
evaluation/Returns Min            -57.2984
evaluation/Actions Mean             0.0230088
evaluation/Actions Std              0.186824
evaluation/Actions Max              0.996224
evaluation/Actions Min             -0.996649
evaluation/Num Paths               10
evaluation/Average Returns        -22.5824
time/data storing (s)               0.001169
time/evaluation sampling (s)        0.256311
time/exploration sampling (s)       0.0698737
time/logging (s)                    0.00344256
time/saving (s)                     0.00232508
time/training (s)                   0.982408
time/epoch (s)                      1.31553
time/total (s)                    441.887
Epoch                             303
-----------------------------  ---------------
2019-04-21 12:23:48.488897 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 304 finished
-----------------------------  ---------------
replay_buffer/size              61200
trainer/QF1 Loss                    0.383472
trainer/QF2 Loss                    0.383974
trainer/Policy Loss                 9.39203
trainer/Q1 Predictions Mean        -7.27839
trainer/Q1 Predictions Std          5.63214
trainer/Q1 Predictions Max         -6.09707
trainer/Q1 Predictions Min        -53.1379
trainer/Q2 Predictions Mean        -7.30466
trainer/Q2 Predictions Std          5.61782
trainer/Q2 Predictions Max         -6.13803
trainer/Q2 Predictions Min        -52.7919
trainer/Q Targets Mean             -7.2785
trainer/Q Targets Std               5.60915
trainer/Q Targets Max              -0.0882428
trainer/Q Targets Min             -52.4485
trainer/Log Pis Mean                2.14445
trainer/Log Pis Std                 1.1746
trainer/Log Pis Max                 7.29473
trainer/Log Pis Min                -0.755926
trainer/Policy mu Mean              0.122553
trainer/Policy mu Std               0.532354
trainer/Policy mu Max               3.16257
trainer/Policy mu Min              -2.80574
trainer/Policy log std Mean        -2.25399
trainer/Policy log std Std          0.360717
trainer/Policy log std Max         -0.681137
trainer/Policy log std Min         -2.4242
trainer/Alpha                       0.0550584
trainer/Alpha Loss                  0.418816
exploration/num steps total     61200
exploration/num paths total       612
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.391106
exploration/Rewards Std             1.3076
exploration/Rewards Max            -0.00998445
exploration/Rewards Min            -9.81483
exploration/Returns Mean          -39.1106
exploration/Returns Std            26.1268
exploration/Returns Max           -12.9838
exploration/Returns Min           -65.2374
exploration/Actions Mean            0.0335785
exploration/Actions Std             0.209458
exploration/Actions Max             0.998659
exploration/Actions Min            -0.318227
exploration/Num Paths               2
exploration/Average Returns       -39.1106
evaluation/num steps total     305000
evaluation/num paths total       3050
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.348219
evaluation/Rewards Std              1.23447
evaluation/Rewards Max             -0.0216399
evaluation/Rewards Min             -9.49316
evaluation/Returns Mean           -34.8219
evaluation/Returns Std             14.4409
evaluation/Returns Max             -9.16753
evaluation/Returns Min            -55.5273
evaluation/Actions Mean             0.0250801
evaluation/Actions Std              0.202389
evaluation/Actions Max              0.996537
evaluation/Actions Min             -0.997572
evaluation/Num Paths               10
evaluation/Average Returns        -34.8219
time/data storing (s)               0.00125019
time/evaluation sampling (s)        0.262308
time/exploration sampling (s)       0.0686443
time/logging (s)                    0.00343679
time/saving (s)                     0.00234625
time/training (s)                   0.980667
time/epoch (s)                      1.31865
time/total (s)                    443.21
Epoch                             304
-----------------------------  ---------------
2019-04-21 12:23:49.816239 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 305 finished
-----------------------------  ---------------
replay_buffer/size              61400
trainer/QF1 Loss                    0.416572
trainer/QF2 Loss                    0.425919
trainer/Policy Loss                 9.06592
trainer/Q1 Predictions Mean        -7.21579
trainer/Q1 Predictions Std          4.47934
trainer/Q1 Predictions Max         -6.09421
trainer/Q1 Predictions Min        -36.5417
trainer/Q2 Predictions Mean        -7.19278
trainer/Q2 Predictions Std          4.49932
trainer/Q2 Predictions Max         -6.08538
trainer/Q2 Predictions Min        -36.6883
trainer/Q Targets Mean             -7.18647
trainer/Q Targets Std               4.41715
trainer/Q Targets Max              -0.0769506
trainer/Q Targets Min             -36.3719
trainer/Log Pis Mean                1.98843
trainer/Log Pis Std                 1.47354
trainer/Log Pis Max                 8.15119
trainer/Log Pis Min                -4.95596
trainer/Policy mu Mean              0.0224946
trainer/Policy mu Std               0.606178
trainer/Policy mu Max               3.16473
trainer/Policy mu Min              -2.23044
trainer/Policy log std Mean        -2.17989
trainer/Policy log std Std          0.437769
trainer/Policy log std Max         -0.455865
trainer/Policy log std Min         -2.4017
trainer/Alpha                       0.0560589
trainer/Alpha Loss                 -0.0333447
exploration/num steps total     61400
exploration/num paths total       614
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.297842
exploration/Rewards Std             0.825045
exploration/Rewards Max            -0.0154992
exploration/Rewards Min            -6.55695
exploration/Returns Mean          -29.7842
exploration/Returns Std             7.25893
exploration/Returns Max           -22.5253
exploration/Returns Min           -37.0431
exploration/Actions Mean            0.0388966
exploration/Actions Std             0.225703
exploration/Actions Max             0.996835
exploration/Actions Min            -0.561032
exploration/Num Paths               2
exploration/Average Returns       -29.7842
evaluation/num steps total     306000
evaluation/num paths total       3060
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.195986
evaluation/Rewards Std              0.852415
evaluation/Rewards Max             -0.0427482
evaluation/Rewards Min             -8.63282
evaluation/Returns Mean           -19.5986
evaluation/Returns Std             14.2697
evaluation/Returns Max             -6.30015
evaluation/Returns Min            -45.2801
evaluation/Actions Mean             0.0257328
evaluation/Actions Std              0.178335
evaluation/Actions Max              0.995382
evaluation/Actions Min             -0.988181
evaluation/Num Paths               10
evaluation/Average Returns        -19.5986
time/data storing (s)               0.00113258
time/evaluation sampling (s)        0.26229
time/exploration sampling (s)       0.0695743
time/logging (s)                    0.00344567
time/saving (s)                     0.00226407
time/training (s)                   0.979573
time/epoch (s)                      1.31828
time/total (s)                    444.533
Epoch                             305
-----------------------------  ---------------
2019-04-21 12:23:51.143628 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 306 finished
-----------------------------  ---------------
replay_buffer/size              61600
trainer/QF1 Loss                    0.396155
trainer/QF2 Loss                    0.389974
trainer/Policy Loss                 9.26075
trainer/Q1 Predictions Mean        -7.41713
trainer/Q1 Predictions Std          4.69808
trainer/Q1 Predictions Max         -6.19959
trainer/Q1 Predictions Min        -41.4691
trainer/Q2 Predictions Mean        -7.40249
trainer/Q2 Predictions Std          4.656
trainer/Q2 Predictions Max         -6.1942
trainer/Q2 Predictions Min        -41.3747
trainer/Q Targets Mean             -7.31122
trainer/Q Targets Std               4.66494
trainer/Q Targets Max              -0.337786
trainer/Q Targets Min             -40.8023
trainer/Log Pis Mean                1.93108
trainer/Log Pis Std                 1.51248
trainer/Log Pis Max                 8.56853
trainer/Log Pis Min                -3.30121
trainer/Policy mu Mean              0.156774
trainer/Policy mu Std               0.646427
trainer/Policy mu Max               3.52611
trainer/Policy mu Min              -0.640656
trainer/Policy log std Mean        -2.20134
trainer/Policy log std Std          0.418116
trainer/Policy log std Max         -0.661082
trainer/Policy log std Min         -2.49726
trainer/Alpha                       0.0536709
trainer/Alpha Loss                 -0.201564
exploration/num steps total     61600
exploration/num paths total       616
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.46069
exploration/Rewards Std             1.41433
exploration/Rewards Max            -0.00309722
exploration/Rewards Min            -9.96469
exploration/Returns Mean          -46.069
exploration/Returns Std            15.0458
exploration/Returns Max           -31.0232
exploration/Returns Min           -61.1148
exploration/Actions Mean            0.0143745
exploration/Actions Std             0.269804
exploration/Actions Max             0.998706
exploration/Actions Min            -0.998568
exploration/Num Paths               2
exploration/Average Returns       -46.069
evaluation/num steps total     307000
evaluation/num paths total       3070
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.182923
evaluation/Rewards Std              0.825405
evaluation/Rewards Max             -0.0103016
evaluation/Rewards Min             -8.90163
evaluation/Returns Mean           -18.2923
evaluation/Returns Std             13.361
evaluation/Returns Max             -3.92067
evaluation/Returns Min            -47.4965
evaluation/Actions Mean             0.0187212
evaluation/Actions Std              0.172747
evaluation/Actions Max              0.997757
evaluation/Actions Min             -0.995406
evaluation/Num Paths               10
evaluation/Average Returns        -18.2923
time/data storing (s)               0.00135726
time/evaluation sampling (s)        0.258645
time/exploration sampling (s)       0.0683761
time/logging (s)                    0.00341773
time/saving (s)                     0.00243542
time/training (s)                   0.984105
time/epoch (s)                      1.31834
time/total (s)                    445.856
Epoch                             306
-----------------------------  ---------------
2019-04-21 12:23:52.467985 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 307 finished
-----------------------------  ---------------
replay_buffer/size              61800
trainer/QF1 Loss                    0.0211645
trainer/QF2 Loss                    0.0222035
trainer/Policy Loss                 8.55569
trainer/Q1 Predictions Mean        -6.66571
trainer/Q1 Predictions Std          3.19562
trainer/Q1 Predictions Max         -6.04486
trainer/Q1 Predictions Min        -35.9666
trainer/Q2 Predictions Mean        -6.69143
trainer/Q2 Predictions Std          3.25557
trainer/Q2 Predictions Max         -6.08267
trainer/Q2 Predictions Min        -36.5121
trainer/Q Targets Mean             -6.78441
trainer/Q Targets Std               3.19735
trainer/Q Targets Max              -6.09318
trainer/Q Targets Min             -36.1404
trainer/Log Pis Mean                2.03808
trainer/Log Pis Std                 1.22458
trainer/Log Pis Max                 6.61607
trainer/Log Pis Min                -2.16828
trainer/Policy mu Mean              0.0113945
trainer/Policy mu Std               0.439207
trainer/Policy mu Max               3.04029
trainer/Policy mu Min              -2.96821
trainer/Policy log std Mean        -2.30412
trainer/Policy log std Std          0.359733
trainer/Policy log std Max         -0.37211
trainer/Policy log std Min         -2.51031
trainer/Alpha                       0.0538731
trainer/Alpha Loss                  0.111235
exploration/num steps total     61800
exploration/num paths total       618
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.223305
exploration/Rewards Std             0.587037
exploration/Rewards Max            -0.00459048
exploration/Rewards Min            -4.95396
exploration/Returns Mean          -22.3305
exploration/Returns Std             2.87393
exploration/Returns Max           -19.4566
exploration/Returns Min           -25.2045
exploration/Actions Mean           -0.0188111
exploration/Actions Std             0.206737
exploration/Actions Max             0.854723
exploration/Actions Min            -0.999003
exploration/Num Paths               2
exploration/Average Returns       -22.3305
evaluation/num steps total     308000
evaluation/num paths total       3080
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.143147
evaluation/Rewards Std              0.762923
evaluation/Rewards Max             -0.0150931
evaluation/Rewards Min             -9.12286
evaluation/Returns Mean           -14.3147
evaluation/Returns Std             14.3403
evaluation/Returns Max             -2.53483
evaluation/Returns Min            -47.9538
evaluation/Actions Mean             0.0211038
evaluation/Actions Std              0.163598
evaluation/Actions Max              0.995892
evaluation/Actions Min             -0.978625
evaluation/Num Paths               10
evaluation/Average Returns        -14.3147
time/data storing (s)               0.00113766
time/evaluation sampling (s)        0.262997
time/exploration sampling (s)       0.0677246
time/logging (s)                    0.00340966
time/saving (s)                     0.00239301
time/training (s)                   0.978435
time/epoch (s)                      1.3161
time/total (s)                    447.175
Epoch                             307
-----------------------------  ---------------
2019-04-21 12:23:53.795350 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 308 finished
-----------------------------  ---------------
replay_buffer/size              62000
trainer/QF1 Loss                    0.0109892
trainer/QF2 Loss                    0.0127193
trainer/Policy Loss                 8.2903
trainer/Q1 Predictions Mean        -6.63336
trainer/Q1 Predictions Std          1.79422
trainer/Q1 Predictions Max         -6.16303
trainer/Q1 Predictions Min        -22.1331
trainer/Q2 Predictions Mean        -6.6327
trainer/Q2 Predictions Std          1.77741
trainer/Q2 Predictions Max         -6.17377
trainer/Q2 Predictions Min        -21.9642
trainer/Q Targets Mean             -6.65373
trainer/Q Targets Std               1.80602
trainer/Q Targets Max              -6.0975
trainer/Q Targets Min             -22.1886
trainer/Log Pis Mean                1.73379
trainer/Log Pis Std                 1.37666
trainer/Log Pis Max                 5.73308
trainer/Log Pis Min                -5.72024
trainer/Policy mu Mean              0.0748577
trainer/Policy mu Std               0.476677
trainer/Policy mu Max               2.93054
trainer/Policy mu Min              -2.56096
trainer/Policy log std Mean        -2.21818
trainer/Policy log std Std          0.361483
trainer/Policy log std Max         -0.593015
trainer/Policy log std Min         -2.4256
trainer/Alpha                       0.0545151
trainer/Alpha Loss                 -0.77444
exploration/num steps total     62000
exploration/num paths total       620
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.209366
exploration/Rewards Std             0.447556
exploration/Rewards Max            -0.0180255
exploration/Rewards Min            -4.30424
exploration/Returns Mean          -20.9366
exploration/Returns Std             3.55378
exploration/Returns Max           -17.3828
exploration/Returns Min           -24.4904
exploration/Actions Mean            0.0264033
exploration/Actions Std             0.186599
exploration/Actions Max             0.990996
exploration/Actions Min            -0.370724
exploration/Num Paths               2
exploration/Average Returns       -20.9366
evaluation/num steps total     309000
evaluation/num paths total       3090
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.260424
evaluation/Rewards Std              1.04923
evaluation/Rewards Max             -0.0154901
evaluation/Rewards Min            -11.3018
evaluation/Returns Mean           -26.0424
evaluation/Returns Std             20.5175
evaluation/Returns Max             -7.10911
evaluation/Returns Min            -66.9562
evaluation/Actions Mean             0.0288667
evaluation/Actions Std              0.197057
evaluation/Actions Max              0.997849
evaluation/Actions Min             -0.994799
evaluation/Num Paths               10
evaluation/Average Returns        -26.0424
time/data storing (s)               0.00117072
time/evaluation sampling (s)        0.255811
time/exploration sampling (s)       0.0681261
time/logging (s)                    0.00338393
time/saving (s)                     0.00183954
time/training (s)                   0.987856
time/epoch (s)                      1.31819
time/total (s)                    448.498
Epoch                             308
-----------------------------  ---------------
2019-04-21 12:23:55.112027 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 309 finished
-----------------------------  ---------------
replay_buffer/size              62200
trainer/QF1 Loss                    0.385849
trainer/QF2 Loss                    0.39144
trainer/Policy Loss                 9.75775
trainer/Q1 Predictions Mean        -7.77728
trainer/Q1 Predictions Std          7.11953
trainer/Q1 Predictions Max         -6.09517
trainer/Q1 Predictions Min        -53.615
trainer/Q2 Predictions Mean        -7.76223
trainer/Q2 Predictions Std          7.12368
trainer/Q2 Predictions Max         -6.09841
trainer/Q2 Predictions Min        -53.3498
trainer/Q Targets Mean             -7.74492
trainer/Q Targets Std               7.0861
trainer/Q Targets Max              -0.0563318
trainer/Q Targets Min             -53.3426
trainer/Log Pis Mean                2.14719
trainer/Log Pis Std                 1.22727
trainer/Log Pis Max                 6.74281
trainer/Log Pis Min                -2.4482
trainer/Policy mu Mean              0.0821439
trainer/Policy mu Std               0.597213
trainer/Policy mu Max               3.16017
trainer/Policy mu Min              -1.42632
trainer/Policy log std Mean        -2.22361
trainer/Policy log std Std          0.401924
trainer/Policy log std Max         -0.460454
trainer/Policy log std Min         -2.45061
trainer/Alpha                       0.0555045
trainer/Alpha Loss                  0.425585
exploration/num steps total     62200
exploration/num paths total       622
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.269124
exploration/Rewards Std             0.756971
exploration/Rewards Max            -0.00626303
exploration/Rewards Min            -5.65603
exploration/Returns Mean          -26.9124
exploration/Returns Std             2.24561
exploration/Returns Max           -24.6668
exploration/Returns Min           -29.158
exploration/Actions Mean            0.0404498
exploration/Actions Std             0.218636
exploration/Actions Max             0.996786
exploration/Actions Min            -0.316724
exploration/Num Paths               2
exploration/Average Returns       -26.9124
evaluation/num steps total     310000
evaluation/num paths total       3100
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.250369
evaluation/Rewards Std              1.07732
evaluation/Rewards Max             -0.0208962
evaluation/Rewards Min             -9.2058
evaluation/Returns Mean           -25.0369
evaluation/Returns Std             15.1637
evaluation/Returns Max             -3.83056
evaluation/Returns Min            -43.2257
evaluation/Actions Mean             0.028517
evaluation/Actions Std              0.199501
evaluation/Actions Max              0.996792
evaluation/Actions Min             -0.988678
evaluation/Num Paths               10
evaluation/Average Returns        -25.0369
time/data storing (s)               0.00121941
time/evaluation sampling (s)        0.251826
time/exploration sampling (s)       0.0678953
time/logging (s)                    0.00341831
time/saving (s)                     0.00229981
time/training (s)                   0.981714
time/epoch (s)                      1.30837
time/total (s)                    449.811
Epoch                             309
-----------------------------  ---------------
2019-04-21 12:23:56.443248 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 310 finished
-----------------------------  ---------------
replay_buffer/size              62400
trainer/QF1 Loss                    0.400881
trainer/QF2 Loss                    0.399983
trainer/Policy Loss                 8.34571
trainer/Q1 Predictions Mean        -6.76129
trainer/Q1 Predictions Std          2.25606
trainer/Q1 Predictions Max         -6.22855
trainer/Q1 Predictions Min        -24.7271
trainer/Q2 Predictions Mean        -6.71021
trainer/Q2 Predictions Std          2.27314
trainer/Q2 Predictions Max         -6.20382
trainer/Q2 Predictions Min        -24.6403
trainer/Q Targets Mean             -6.66565
trainer/Q Targets Std               2.33633
trainer/Q Targets Max              -0.665978
trainer/Q Targets Min             -24.6928
trainer/Log Pis Mean                1.62906
trainer/Log Pis Std                 1.16997
trainer/Log Pis Max                 4.70933
trainer/Log Pis Min                -2.57442
trainer/Policy mu Mean              0.0350693
trainer/Policy mu Std               0.459691
trainer/Policy mu Max               2.82477
trainer/Policy mu Min              -1.12737
trainer/Policy log std Mean        -2.13815
trainer/Policy log std Std          0.314296
trainer/Policy log std Max         -0.643159
trainer/Policy log std Min         -2.37441
trainer/Alpha                       0.0534934
trainer/Alpha Loss                 -1.0861
exploration/num steps total     62400
exploration/num paths total       624
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.249755
exploration/Rewards Std             0.624566
exploration/Rewards Max            -0.00704717
exploration/Rewards Min            -5.78411
exploration/Returns Mean          -24.9755
exploration/Returns Std             8.67452
exploration/Returns Max           -16.301
exploration/Returns Min           -33.6501
exploration/Actions Mean            0.00912548
exploration/Actions Std             0.204997
exploration/Actions Max             0.993792
exploration/Actions Min            -0.983263
exploration/Num Paths               2
exploration/Average Returns       -24.9755
evaluation/num steps total     311000
evaluation/num paths total       3110
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.26804
evaluation/Rewards Std              0.91407
evaluation/Rewards Max             -0.0864194
evaluation/Rewards Min             -9.51778
evaluation/Returns Mean           -26.804
evaluation/Returns Std             14.1995
evaluation/Returns Max             -9.68397
evaluation/Returns Min            -58.8913
evaluation/Actions Mean             0.0266313
evaluation/Actions Std              0.183857
evaluation/Actions Max              0.99746
evaluation/Actions Min             -0.994741
evaluation/Num Paths               10
evaluation/Average Returns        -26.804
time/data storing (s)               0.00116261
time/evaluation sampling (s)        0.260005
time/exploration sampling (s)       0.0726484
time/logging (s)                    0.00346268
time/saving (s)                     0.00258881
time/training (s)                   0.982298
time/epoch (s)                      1.32217
time/total (s)                    451.138
Epoch                             310
-----------------------------  ---------------
2019-04-21 12:23:57.772265 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 311 finished
-----------------------------  ---------------
replay_buffer/size              62600
trainer/QF1 Loss                    1.14014
trainer/QF2 Loss                    1.14898
trainer/Policy Loss                 9.49029
trainer/Q1 Predictions Mean        -7.27562
trainer/Q1 Predictions Std          3.94224
trainer/Q1 Predictions Max         -6.15705
trainer/Q1 Predictions Min        -31.6321
trainer/Q2 Predictions Mean        -7.29493
trainer/Q2 Predictions Std          3.93721
trainer/Q2 Predictions Max         -6.19144
trainer/Q2 Predictions Min        -31.6918
trainer/Q Targets Mean             -7.08829
trainer/Q Targets Std               4.09928
trainer/Q Targets Max              -0.081052
trainer/Q Targets Min             -31.5954
trainer/Log Pis Mean                2.25202
trainer/Log Pis Std                 1.07685
trainer/Log Pis Max                 5.15389
trainer/Log Pis Min                -1.58125
trainer/Policy mu Mean              0.0694758
trainer/Policy mu Std               0.583373
trainer/Policy mu Max               2.79537
trainer/Policy mu Min              -2.741
trainer/Policy log std Mean        -2.292
trainer/Policy log std Std          0.433326
trainer/Policy log std Max         -0.605884
trainer/Policy log std Min         -2.52594
trainer/Alpha                       0.0540274
trainer/Alpha Loss                  0.735545
exploration/num steps total     62600
exploration/num paths total       626
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.343129
exploration/Rewards Std             1.05198
exploration/Rewards Max            -0.00404814
exploration/Rewards Min            -8.07861
exploration/Returns Mean          -34.3129
exploration/Returns Std            11.3202
exploration/Returns Max           -22.9927
exploration/Returns Min           -45.6331
exploration/Actions Mean            0.0489208
exploration/Actions Std             0.234994
exploration/Actions Max             0.998073
exploration/Actions Min            -0.400624
exploration/Num Paths               2
exploration/Average Returns       -34.3129
evaluation/num steps total     312000
evaluation/num paths total       3120
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.237945
evaluation/Rewards Std              1.07112
evaluation/Rewards Max             -0.00309004
evaluation/Rewards Min            -10.434
evaluation/Returns Mean           -23.7945
evaluation/Returns Std             16.7593
evaluation/Returns Max             -5.2303
evaluation/Returns Min            -56.5906
evaluation/Actions Mean             0.0283207
evaluation/Actions Std              0.201507
evaluation/Actions Max              0.996054
evaluation/Actions Min             -0.99423
evaluation/Num Paths               10
evaluation/Average Returns        -23.7945
time/data storing (s)               0.00118779
time/evaluation sampling (s)        0.257687
time/exploration sampling (s)       0.0686705
time/logging (s)                    0.00342204
time/saving (s)                     0.00229818
time/training (s)                   0.986603
time/epoch (s)                      1.31987
time/total (s)                    452.461
Epoch                             311
-----------------------------  ---------------
2019-04-21 12:23:59.091228 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 312 finished
-----------------------------  ---------------
replay_buffer/size              62800
trainer/QF1 Loss                    0.392722
trainer/QF2 Loss                    0.394495
trainer/Policy Loss                 8.96286
trainer/Q1 Predictions Mean        -6.9954
trainer/Q1 Predictions Std          2.80203
trainer/Q1 Predictions Max         -6.09354
trainer/Q1 Predictions Min        -27.0744
trainer/Q2 Predictions Mean        -6.95097
trainer/Q2 Predictions Std          2.79781
trainer/Q2 Predictions Max         -6.05281
trainer/Q2 Predictions Min        -27.2513
trainer/Q Targets Mean             -6.98688
trainer/Q Targets Std               2.91763
trainer/Q Targets Max              -0.014309
trainer/Q Targets Min             -27.6703
trainer/Log Pis Mean                2.21802
trainer/Log Pis Std                 1.11391
trainer/Log Pis Max                 5.67911
trainer/Log Pis Min                -1.5747
trainer/Policy mu Mean              0.0211244
trainer/Policy mu Std               0.609554
trainer/Policy mu Max               2.63176
trainer/Policy mu Min              -3.58071
trainer/Policy log std Mean        -2.27562
trainer/Policy log std Std          0.443354
trainer/Policy log std Max         -0.405236
trainer/Policy log std Min         -2.53054
trainer/Alpha                       0.0569501
trainer/Alpha Loss                  0.624802
exploration/num steps total     62800
exploration/num paths total       628
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.156054
exploration/Rewards Std             0.255745
exploration/Rewards Max            -0.00349057
exploration/Rewards Min            -2.71307
exploration/Returns Mean          -15.6054
exploration/Returns Std             1.86265
exploration/Returns Max           -13.7428
exploration/Returns Min           -17.4681
exploration/Actions Mean           -0.0011664
exploration/Actions Std             0.188627
exploration/Actions Max             0.978835
exploration/Actions Min            -0.988148
exploration/Num Paths               2
exploration/Average Returns       -15.6054
evaluation/num steps total     313000
evaluation/num paths total       3130
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.242999
evaluation/Rewards Std              0.972512
evaluation/Rewards Max             -0.0554054
evaluation/Rewards Min             -9.27835
evaluation/Returns Mean           -24.2999
evaluation/Returns Std             16.032
evaluation/Returns Max             -5.81798
evaluation/Returns Min            -53.454
evaluation/Actions Mean             0.0160266
evaluation/Actions Std              0.183501
evaluation/Actions Max              0.99647
evaluation/Actions Min             -0.998209
evaluation/Num Paths               10
evaluation/Average Returns        -24.2999
time/data storing (s)               0.00118264
time/evaluation sampling (s)        0.262725
time/exploration sampling (s)       0.0703632
time/logging (s)                    0.0034393
time/saving (s)                     0.00187491
time/training (s)                   0.970884
time/epoch (s)                      1.31047
time/total (s)                    453.777
Epoch                             312
-----------------------------  ---------------
2019-04-21 12:24:00.416401 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 313 finished
-----------------------------  ---------------
replay_buffer/size              63000
trainer/QF1 Loss                    0.410643
trainer/QF2 Loss                    0.438388
trainer/Policy Loss                 9.60013
trainer/Q1 Predictions Mean        -7.63739
trainer/Q1 Predictions Std          4.46985
trainer/Q1 Predictions Max         -6.08481
trainer/Q1 Predictions Min        -32.1796
trainer/Q2 Predictions Mean        -7.64425
trainer/Q2 Predictions Std          4.48141
trainer/Q2 Predictions Max         -6.06014
trainer/Q2 Predictions Min        -31.9616
trainer/Q Targets Mean             -7.6263
trainer/Q Targets Std               4.45945
trainer/Q Targets Max              -0.0397104
trainer/Q Targets Min             -31.7865
trainer/Log Pis Mean                2.19006
trainer/Log Pis Std                 1.3156
trainer/Log Pis Max                 6.22135
trainer/Log Pis Min                -1.80633
trainer/Policy mu Mean              0.0533875
trainer/Policy mu Std               0.709831
trainer/Policy mu Max               2.7977
trainer/Policy mu Min              -3.0792
trainer/Policy log std Mean        -2.20451
trainer/Policy log std Std          0.529563
trainer/Policy log std Max         -0.452645
trainer/Policy log std Min         -2.51833
trainer/Alpha                       0.0581116
trainer/Alpha Loss                  0.540807
exploration/num steps total     63000
exploration/num paths total       630
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.402373
exploration/Rewards Std             1.38635
exploration/Rewards Max            -0.00701995
exploration/Rewards Min           -10.1759
exploration/Returns Mean          -40.2373
exploration/Returns Std            28.5298
exploration/Returns Max           -11.7075
exploration/Returns Min           -68.7671
exploration/Actions Mean            0.0276465
exploration/Actions Std             0.204542
exploration/Actions Max             0.997141
exploration/Actions Min            -0.805989
exploration/Num Paths               2
exploration/Average Returns       -40.2373
evaluation/num steps total     314000
evaluation/num paths total       3140
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.209254
evaluation/Rewards Std              0.863926
evaluation/Rewards Max             -0.0335438
evaluation/Rewards Min             -9.05201
evaluation/Returns Mean           -20.9254
evaluation/Returns Std             12.5388
evaluation/Returns Max             -5.13578
evaluation/Returns Min            -43.9413
evaluation/Actions Mean             0.0304867
evaluation/Actions Std              0.185212
evaluation/Actions Max              0.995924
evaluation/Actions Min             -0.928329
evaluation/Num Paths               10
evaluation/Average Returns        -20.9254
time/data storing (s)               0.00131227
time/evaluation sampling (s)        0.256406
time/exploration sampling (s)       0.0661954
time/logging (s)                    0.00352095
time/saving (s)                     0.00235642
time/training (s)                   0.986354
time/epoch (s)                      1.31614
time/total (s)                    455.097
Epoch                             313
-----------------------------  ---------------
2019-04-21 12:24:01.742353 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 314 finished
-----------------------------  ---------------
replay_buffer/size              63200
trainer/QF1 Loss                    0.0083953
trainer/QF2 Loss                    0.0122775
trainer/Policy Loss                 8.50954
trainer/Q1 Predictions Mean        -6.51011
trainer/Q1 Predictions Std          0.783915
trainer/Q1 Predictions Max         -6.19543
trainer/Q1 Predictions Min        -11.1287
trainer/Q2 Predictions Mean        -6.45231
trainer/Q2 Predictions Std          0.816408
trainer/Q2 Predictions Max         -6.13554
trainer/Q2 Predictions Min        -11.3795
trainer/Q Targets Mean             -6.4576
trainer/Q Targets Std               0.764233
trainer/Q Targets Max              -6.04544
trainer/Q Targets Min             -11.0962
trainer/Log Pis Mean                2.11755
trainer/Log Pis Std                 0.889831
trainer/Log Pis Max                 4.01452
trainer/Log Pis Min                -0.827217
trainer/Policy mu Mean              0.03667
trainer/Policy mu Std               0.37
trainer/Policy mu Max               2.4817
trainer/Policy mu Min              -1.56752
trainer/Policy log std Mean        -2.29398
trainer/Policy log std Std          0.316215
trainer/Policy log std Max         -0.598653
trainer/Policy log std Min         -2.4831
trainer/Alpha                       0.0585523
trainer/Alpha Loss                  0.333584
exploration/num steps total     63200
exploration/num paths total       632
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.229566
exploration/Rewards Std             0.595744
exploration/Rewards Max            -0.00627844
exploration/Rewards Min            -5.21782
exploration/Returns Mean          -22.9566
exploration/Returns Std             2.5513
exploration/Returns Max           -20.4053
exploration/Returns Min           -25.5079
exploration/Actions Mean           -0.00771376
exploration/Actions Std             0.220989
exploration/Actions Max             0.994865
exploration/Actions Min            -0.999038
exploration/Num Paths               2
exploration/Average Returns       -22.9566
evaluation/num steps total     315000
evaluation/num paths total       3150
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.232954
evaluation/Rewards Std              1.07607
evaluation/Rewards Max             -0.0148484
evaluation/Rewards Min            -10.5068
evaluation/Returns Mean           -23.2954
evaluation/Returns Std             17.3798
evaluation/Returns Max             -8.04168
evaluation/Returns Min            -52.8342
evaluation/Actions Mean             0.0271804
evaluation/Actions Std              0.202062
evaluation/Actions Max              0.997466
evaluation/Actions Min             -0.995407
evaluation/Num Paths               10
evaluation/Average Returns        -23.2954
time/data storing (s)               0.00122582
time/evaluation sampling (s)        0.260494
time/exploration sampling (s)       0.067271
time/logging (s)                    0.00345846
time/saving (s)                     0.00233115
time/training (s)                   0.982002
time/epoch (s)                      1.31678
time/total (s)                    456.419
Epoch                             314
-----------------------------  ---------------
2019-04-21 12:24:03.088183 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 315 finished
-----------------------------  ---------------
replay_buffer/size              63400
trainer/QF1 Loss                    0.387657
trainer/QF2 Loss                    0.388647
trainer/Policy Loss                 8.85961
trainer/Q1 Predictions Mean        -7.08067
trainer/Q1 Predictions Std          4.34923
trainer/Q1 Predictions Max         -6.14779
trainer/Q1 Predictions Min        -45.0051
trainer/Q2 Predictions Mean        -7.02707
trainer/Q2 Predictions Std          4.35017
trainer/Q2 Predictions Max         -6.11909
trainer/Q2 Predictions Min        -44.7923
trainer/Q Targets Mean             -7.00852
trainer/Q Targets Std               4.36412
trainer/Q Targets Max              -0.0226528
trainer/Q Targets Min             -44.4575
trainer/Log Pis Mean                1.86568
trainer/Log Pis Std                 1.16619
trainer/Log Pis Max                 4.34802
trainer/Log Pis Min                -4.11406
trainer/Policy mu Mean              0.096742
trainer/Policy mu Std               0.50687
trainer/Policy mu Max               3.02659
trainer/Policy mu Min              -2.84136
trainer/Policy log std Mean        -2.17562
trainer/Policy log std Std          0.382234
trainer/Policy log std Max         -0.458887
trainer/Policy log std Min         -2.40426
trainer/Alpha                       0.057945
trainer/Alpha Loss                 -0.382581
exploration/num steps total     63400
exploration/num paths total       634
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.241413
exploration/Rewards Std             0.604011
exploration/Rewards Max            -0.00357942
exploration/Rewards Min            -5.07598
exploration/Returns Mean          -24.1413
exploration/Returns Std             3.77269
exploration/Returns Max           -20.3686
exploration/Returns Min           -27.914
exploration/Actions Mean            0.0161066
exploration/Actions Std             0.22408
exploration/Actions Max             0.999402
exploration/Actions Min            -0.961221
exploration/Num Paths               2
exploration/Average Returns       -24.1413
evaluation/num steps total     316000
evaluation/num paths total       3160
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.191557
evaluation/Rewards Std              0.893922
evaluation/Rewards Max             -0.00681786
evaluation/Rewards Min             -9.77591
evaluation/Returns Mean           -19.1557
evaluation/Returns Std             15.7826
evaluation/Returns Max             -3.733
evaluation/Returns Min            -55.8217
evaluation/Actions Mean             0.0131051
evaluation/Actions Std              0.183366
evaluation/Actions Max              0.996686
evaluation/Actions Min             -0.997924
evaluation/Num Paths               10
evaluation/Average Returns        -19.1557
time/data storing (s)               0.00119065
time/evaluation sampling (s)        0.262808
time/exploration sampling (s)       0.0688111
time/logging (s)                    0.00342959
time/saving (s)                     0.00235353
time/training (s)                   0.99857
time/epoch (s)                      1.33716
time/total (s)                    457.76
Epoch                             315
-----------------------------  ---------------
2019-04-21 12:24:04.408342 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 316 finished
-----------------------------  ---------------
replay_buffer/size              63600
trainer/QF1 Loss                    0.0246423
trainer/QF2 Loss                    0.0135988
trainer/Policy Loss                 9.00249
trainer/Q1 Predictions Mean        -7.00154
trainer/Q1 Predictions Std          3.26802
trainer/Q1 Predictions Max         -6.04463
trainer/Q1 Predictions Min        -25.9191
trainer/Q2 Predictions Mean        -7.0529
trainer/Q2 Predictions Std          3.25154
trainer/Q2 Predictions Max         -6.09173
trainer/Q2 Predictions Min        -26.1633
trainer/Q Targets Mean             -7.0947
trainer/Q Targets Std               3.25383
trainer/Q Targets Max              -6.09441
trainer/Q Targets Min             -26.7782
trainer/Log Pis Mean                2.09672
trainer/Log Pis Std                 1.26645
trainer/Log Pis Max                 7.32196
trainer/Log Pis Min                -2.54445
trainer/Policy mu Mean              0.11923
trainer/Policy mu Std               0.611786
trainer/Policy mu Max               3.49709
trainer/Policy mu Min              -1.78162
trainer/Policy log std Mean        -2.23117
trainer/Policy log std Std          0.439877
trainer/Policy log std Max         -0.518652
trainer/Policy log std Min         -2.51798
trainer/Alpha                       0.0579849
trainer/Alpha Loss                  0.27542
exploration/num steps total     63600
exploration/num paths total       636
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.171309
exploration/Rewards Std             0.297333
exploration/Rewards Max            -0.00952654
exploration/Rewards Min            -2.77484
exploration/Returns Mean          -17.1309
exploration/Returns Std             0.174347
exploration/Returns Max           -16.9566
exploration/Returns Min           -17.3052
exploration/Actions Mean            0.00894074
exploration/Actions Std             0.198335
exploration/Actions Max             0.989953
exploration/Actions Min            -0.992994
exploration/Num Paths               2
exploration/Average Returns       -17.1309
evaluation/num steps total     317000
evaluation/num paths total       3170
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.245917
evaluation/Rewards Std              1.01663
evaluation/Rewards Max             -0.0327568
evaluation/Rewards Min             -9.58806
evaluation/Returns Mean           -24.5917
evaluation/Returns Std             15.091
evaluation/Returns Max             -6.58736
evaluation/Returns Min            -53.4128
evaluation/Actions Mean             0.0308036
evaluation/Actions Std              0.19864
evaluation/Actions Max              0.997027
evaluation/Actions Min             -0.993107
evaluation/Num Paths               10
evaluation/Average Returns        -24.5917
time/data storing (s)               0.00121431
time/evaluation sampling (s)        0.257593
time/exploration sampling (s)       0.0669574
time/logging (s)                    0.00339653
time/saving (s)                     0.0023608
time/training (s)                   0.979154
time/epoch (s)                      1.31068
time/total (s)                    459.075
Epoch                             316
-----------------------------  ---------------
2019-04-21 12:24:05.730601 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 317 finished
-----------------------------  ---------------
replay_buffer/size              63800
trainer/QF1 Loss                    0.394801
trainer/QF2 Loss                    0.381388
trainer/Policy Loss                 8.99129
trainer/Q1 Predictions Mean        -7.29891
trainer/Q1 Predictions Std          6.21338
trainer/Q1 Predictions Max         -6.06153
trainer/Q1 Predictions Min        -62.4071
trainer/Q2 Predictions Mean        -7.33619
trainer/Q2 Predictions Std          6.26111
trainer/Q2 Predictions Max         -6.07061
trainer/Q2 Predictions Min        -62.942
trainer/Q Targets Mean             -7.35014
trainer/Q Targets Std               6.33861
trainer/Q Targets Max              -0.300826
trainer/Q Targets Min             -63.6395
trainer/Log Pis Mean                1.88142
trainer/Log Pis Std                 1.17173
trainer/Log Pis Max                 5.91176
trainer/Log Pis Min                -2.54083
trainer/Policy mu Mean              0.0668175
trainer/Policy mu Std               0.555222
trainer/Policy mu Max               2.95546
trainer/Policy mu Min              -3.09628
trainer/Policy log std Mean        -2.17011
trainer/Policy log std Std          0.415329
trainer/Policy log std Max         -0.462512
trainer/Policy log std Min         -2.41893
trainer/Alpha                       0.0577885
trainer/Alpha Loss                 -0.338049
exploration/num steps total     63800
exploration/num paths total       638
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.297574
exploration/Rewards Std             0.809693
exploration/Rewards Max            -0.0146856
exploration/Rewards Min            -5.61143
exploration/Returns Mean          -29.7574
exploration/Returns Std             0.675686
exploration/Returns Max           -29.0817
exploration/Returns Min           -30.4331
exploration/Actions Mean            0.0244903
exploration/Actions Std             0.222979
exploration/Actions Max             0.998885
exploration/Actions Min            -0.811996
exploration/Num Paths               2
exploration/Average Returns       -29.7574
evaluation/num steps total     318000
evaluation/num paths total       3180
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.256678
evaluation/Rewards Std              1.02169
evaluation/Rewards Max             -0.0186948
evaluation/Rewards Min             -9.53238
evaluation/Returns Mean           -25.6678
evaluation/Returns Std             17.1552
evaluation/Returns Max             -5.5638
evaluation/Returns Min            -55.3504
evaluation/Actions Mean             0.0282729
evaluation/Actions Std              0.183145
evaluation/Actions Max              0.9973
evaluation/Actions Min             -0.978082
evaluation/Num Paths               10
evaluation/Average Returns        -25.6678
time/data storing (s)               0.00127611
time/evaluation sampling (s)        0.254399
time/exploration sampling (s)       0.0664808
time/logging (s)                    0.00339774
time/saving (s)                     0.00217581
time/training (s)                   0.985418
time/epoch (s)                      1.31315
time/total (s)                    460.393
Epoch                             317
-----------------------------  ---------------
2019-04-21 12:24:07.051321 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 318 finished
-----------------------------  ---------------
replay_buffer/size              64000
trainer/QF1 Loss                    0.774515
trainer/QF2 Loss                    0.788886
trainer/Policy Loss                10.3251
trainer/Q1 Predictions Mean        -8.25689
trainer/Q1 Predictions Std          8.03845
trainer/Q1 Predictions Max         -5.96788
trainer/Q1 Predictions Min        -64.1102
trainer/Q2 Predictions Mean        -8.24839
trainer/Q2 Predictions Std          7.99752
trainer/Q2 Predictions Max         -5.9723
trainer/Q2 Predictions Min        -63.9891
trainer/Q Targets Mean             -8.3391
trainer/Q Targets Std               8.2532
trainer/Q Targets Max              -0.125668
trainer/Q Targets Min             -65.9824
trainer/Log Pis Mean                2.34817
trainer/Log Pis Std                 1.36792
trainer/Log Pis Max                 7.52225
trainer/Log Pis Min                -1.87579
trainer/Policy mu Mean              0.156998
trainer/Policy mu Std               0.700354
trainer/Policy mu Max               3.2175
trainer/Policy mu Min              -2.59687
trainer/Policy log std Mean        -2.20452
trainer/Policy log std Std          0.458739
trainer/Policy log std Max         -0.591423
trainer/Policy log std Min         -2.49613
trainer/Alpha                       0.057555
trainer/Alpha Loss                  0.994112
exploration/num steps total     64000
exploration/num paths total       640
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.426232
exploration/Rewards Std             1.27491
exploration/Rewards Max            -0.00517081
exploration/Rewards Min            -8.86058
exploration/Returns Mean          -42.6232
exploration/Returns Std            12.3272
exploration/Returns Max           -30.296
exploration/Returns Min           -54.9504
exploration/Actions Mean            0.019341
exploration/Actions Std             0.25522
exploration/Actions Max             0.994488
exploration/Actions Min            -0.997716
exploration/Num Paths               2
exploration/Average Returns       -42.6232
evaluation/num steps total     319000
evaluation/num paths total       3190
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.252906
evaluation/Rewards Std              0.994898
evaluation/Rewards Max             -0.0217065
evaluation/Rewards Min             -9.21682
evaluation/Returns Mean           -25.2906
evaluation/Returns Std             11.2956
evaluation/Returns Max             -6.48546
evaluation/Returns Min            -51.31
evaluation/Actions Mean             0.029116
evaluation/Actions Std              0.206764
evaluation/Actions Max              0.996309
evaluation/Actions Min             -0.997718
evaluation/Num Paths               10
evaluation/Average Returns        -25.2906
time/data storing (s)               0.00127748
time/evaluation sampling (s)        0.257151
time/exploration sampling (s)       0.0685819
time/logging (s)                    0.00256045
time/saving (s)                     0.0024423
time/training (s)                   0.978997
time/epoch (s)                      1.31101
time/total (s)                    461.708
Epoch                             318
-----------------------------  ---------------
2019-04-21 12:24:08.433992 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 319 finished
-----------------------------  ---------------
replay_buffer/size              64200
trainer/QF1 Loss                    0.413287
trainer/QF2 Loss                    0.406289
trainer/Policy Loss                 9.01323
trainer/Q1 Predictions Mean        -7.22263
trainer/Q1 Predictions Std          4.56124
trainer/Q1 Predictions Max         -5.99066
trainer/Q1 Predictions Min        -31.9424
trainer/Q2 Predictions Mean        -7.23712
trainer/Q2 Predictions Std          4.58426
trainer/Q2 Predictions Max         -6.01801
trainer/Q2 Predictions Min        -32.1732
trainer/Q Targets Mean             -7.34287
trainer/Q Targets Std               4.68762
trainer/Q Targets Max              -0.266148
trainer/Q Targets Min             -32.2839
trainer/Log Pis Mean                1.92626
trainer/Log Pis Std                 1.23537
trainer/Log Pis Max                 4.3762
trainer/Log Pis Min                -4.96078
trainer/Policy mu Mean              0.146798
trainer/Policy mu Std               0.534339
trainer/Policy mu Max               2.81297
trainer/Policy mu Min              -0.815368
trainer/Policy log std Mean        -2.21687
trainer/Policy log std Std          0.391494
trainer/Policy log std Max         -0.617319
trainer/Policy log std Min         -2.47436
trainer/Alpha                       0.0576167
trainer/Alpha Loss                 -0.210435
exploration/num steps total     64200
exploration/num paths total       642
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.451736
exploration/Rewards Std             1.29869
exploration/Rewards Max            -0.0169266
exploration/Rewards Min            -9.67533
exploration/Returns Mean          -45.1736
exploration/Returns Std            19.6678
exploration/Returns Max           -25.5058
exploration/Returns Min           -64.8414
exploration/Actions Mean            0.0359099
exploration/Actions Std             0.249414
exploration/Actions Max             0.999433
exploration/Actions Min            -0.811891
exploration/Num Paths               2
exploration/Average Returns       -45.1736
evaluation/num steps total     320000
evaluation/num paths total       3200
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.282434
evaluation/Rewards Std              0.985501
evaluation/Rewards Max             -0.0425475
evaluation/Rewards Min             -9.75699
evaluation/Returns Mean           -28.2434
evaluation/Returns Std             16.4035
evaluation/Returns Max            -10.5923
evaluation/Returns Min            -59.9705
evaluation/Actions Mean             0.017542
evaluation/Actions Std              0.188798
evaluation/Actions Max              0.994295
evaluation/Actions Min             -0.995719
evaluation/Num Paths               10
evaluation/Average Returns        -28.2434
time/data storing (s)               0.00127009
time/evaluation sampling (s)        0.272293
time/exploration sampling (s)       0.0756624
time/logging (s)                    0.00362142
time/saving (s)                     0.00257952
time/training (s)                   1.02056
time/epoch (s)                      1.37599
time/total (s)                    463.088
Epoch                             319
-----------------------------  ---------------
2019-04-21 12:24:09.803738 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 320 finished
-----------------------------  ---------------
replay_buffer/size              64400
trainer/QF1 Loss                    0.0234091
trainer/QF2 Loss                    0.0319556
trainer/Policy Loss                 9.31029
trainer/Q1 Predictions Mean        -7.38406
trainer/Q1 Predictions Std          5.03345
trainer/Q1 Predictions Max         -6.15175
trainer/Q1 Predictions Min        -46.601
trainer/Q2 Predictions Mean        -7.40903
trainer/Q2 Predictions Std          5.04676
trainer/Q2 Predictions Max         -6.1789
trainer/Q2 Predictions Min        -47.098
trainer/Q Targets Mean             -7.31885
trainer/Q Targets Std               4.91684
trainer/Q Targets Max              -6.03132
trainer/Q Targets Min             -45.8301
trainer/Log Pis Mean                2.06401
trainer/Log Pis Std                 0.997015
trainer/Log Pis Max                 6.26546
trainer/Log Pis Min                -1.45894
trainer/Policy mu Mean              0.0890331
trainer/Policy mu Std               0.587453
trainer/Policy mu Max               2.99075
trainer/Policy mu Min              -1.96641
trainer/Policy log std Mean        -2.2353
trainer/Policy log std Std          0.441159
trainer/Policy log std Max         -0.574355
trainer/Policy log std Min         -2.49787
trainer/Alpha                       0.0571739
trainer/Alpha Loss                  0.183197
exploration/num steps total     64400
exploration/num paths total       644
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.239885
exploration/Rewards Std             0.728637
exploration/Rewards Max            -0.00714632
exploration/Rewards Min            -6.65654
exploration/Returns Mean          -23.9885
exploration/Returns Std             6.63495
exploration/Returns Max           -17.3535
exploration/Returns Min           -30.6234
exploration/Actions Mean            0.0175241
exploration/Actions Std             0.230642
exploration/Actions Max             0.988797
exploration/Actions Min            -0.981227
exploration/Num Paths               2
exploration/Average Returns       -23.9885
evaluation/num steps total     321000
evaluation/num paths total       3210
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.228897
evaluation/Rewards Std              0.995518
evaluation/Rewards Max             -0.0195458
evaluation/Rewards Min             -9.52487
evaluation/Returns Mean           -22.8897
evaluation/Returns Std             12.1175
evaluation/Returns Max             -3.25837
evaluation/Returns Min            -45.3328
evaluation/Actions Mean             0.0138926
evaluation/Actions Std              0.204968
evaluation/Actions Max              0.995933
evaluation/Actions Min             -0.998817
evaluation/Num Paths               10
evaluation/Average Returns        -22.8897
time/data storing (s)               0.00117111
time/evaluation sampling (s)        0.259262
time/exploration sampling (s)       0.0697917
time/logging (s)                    0.00326524
time/saving (s)                     0.00265755
time/training (s)                   1.02291
time/epoch (s)                      1.35905
time/total (s)                    464.452
Epoch                             320
-----------------------------  ---------------
2019-04-21 12:24:11.166279 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 321 finished
-----------------------------  ---------------
replay_buffer/size              64600
trainer/QF1 Loss                    0.0211341
trainer/QF2 Loss                    0.0329856
trainer/Policy Loss                 9.32581
trainer/Q1 Predictions Mean        -7.33897
trainer/Q1 Predictions Std          5.49567
trainer/Q1 Predictions Max         -6.00418
trainer/Q1 Predictions Min        -51.3108
trainer/Q2 Predictions Mean        -7.29989
trainer/Q2 Predictions Std          5.53964
trainer/Q2 Predictions Max         -5.97439
trainer/Q2 Predictions Min        -51.7573
trainer/Q Targets Mean             -7.44164
trainer/Q Targets Std               5.49415
trainer/Q Targets Max              -6.04272
trainer/Q Targets Min             -51.3333
trainer/Log Pis Mean                2.16793
trainer/Log Pis Std                 1.02995
trainer/Log Pis Max                 5.32849
trainer/Log Pis Min                -0.71822
trainer/Policy mu Mean              0.136161
trainer/Policy mu Std               0.636313
trainer/Policy mu Max               2.98967
trainer/Policy mu Min              -1.75451
trainer/Policy log std Mean        -2.15664
trainer/Policy log std Std          0.463632
trainer/Policy log std Max         -0.50225
trainer/Policy log std Min         -2.40802
trainer/Alpha                       0.0586835
trainer/Alpha Loss                  0.476182
exploration/num steps total     64600
exploration/num paths total       646
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.286247
exploration/Rewards Std             0.790336
exploration/Rewards Max            -0.0137676
exploration/Rewards Min            -5.65732
exploration/Returns Mean          -28.6247
exploration/Returns Std             0.171636
exploration/Returns Max           -28.4531
exploration/Returns Min           -28.7963
exploration/Actions Mean            0.00268181
exploration/Actions Std             0.229844
exploration/Actions Max             0.997146
exploration/Actions Min            -0.998768
exploration/Num Paths               2
exploration/Average Returns       -28.6247
evaluation/num steps total     322000
evaluation/num paths total       3220
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.235976
evaluation/Rewards Std              1.00601
evaluation/Rewards Max             -0.0184314
evaluation/Rewards Min             -9.55899
evaluation/Returns Mean           -23.5976
evaluation/Returns Std             13.7764
evaluation/Returns Max             -6.09884
evaluation/Returns Min            -50.6673
evaluation/Actions Mean             0.0226445
evaluation/Actions Std              0.199797
evaluation/Actions Max              0.996992
evaluation/Actions Min             -0.992421
evaluation/Num Paths               10
evaluation/Average Returns        -23.5976
time/data storing (s)               0.00117436
time/evaluation sampling (s)        0.260078
time/exploration sampling (s)       0.0710769
time/logging (s)                    0.00354806
time/saving (s)                     0.00233285
time/training (s)                   1.01533
time/epoch (s)                      1.35354
time/total (s)                    465.81
Epoch                             321
-----------------------------  ---------------
2019-04-21 12:24:12.530624 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 322 finished
-----------------------------  ---------------
replay_buffer/size              64800
trainer/QF1 Loss                    0.743627
trainer/QF2 Loss                    0.737757
trainer/Policy Loss                 8.19551
trainer/Q1 Predictions Mean        -6.61597
trainer/Q1 Predictions Std          2.37273
trainer/Q1 Predictions Max         -6.10793
trainer/Q1 Predictions Min        -23.1695
trainer/Q2 Predictions Mean        -6.59145
trainer/Q2 Predictions Std          2.32829
trainer/Q2 Predictions Max         -6.09308
trainer/Q2 Predictions Min        -22.8419
trainer/Q Targets Mean             -6.48629
trainer/Q Targets Std               2.47381
trainer/Q Targets Max              -0.0987106
trainer/Q Targets Min             -22.6287
trainer/Log Pis Mean                1.69763
trainer/Log Pis Std                 1.35067
trainer/Log Pis Max                 4.79847
trainer/Log Pis Min                -4.10813
trainer/Policy mu Mean              0.00506766
trainer/Policy mu Std               0.409738
trainer/Policy mu Max               2.77031
trainer/Policy mu Min              -2.65785
trainer/Policy log std Mean        -2.2629
trainer/Policy log std Std          0.303215
trainer/Policy log std Max         -0.670666
trainer/Policy log std Min         -2.42209
trainer/Alpha                       0.0579463
trainer/Alpha Loss                 -0.861193
exploration/num steps total     64800
exploration/num paths total       648
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.337027
exploration/Rewards Std             1.0575
exploration/Rewards Max            -0.0112593
exploration/Rewards Min            -8.58597
exploration/Returns Mean          -33.7027
exploration/Returns Std            18.1388
exploration/Returns Max           -15.5638
exploration/Returns Min           -51.8415
exploration/Actions Mean            0.0439197
exploration/Actions Std             0.229688
exploration/Actions Max             0.995103
exploration/Actions Min            -0.350062
exploration/Num Paths               2
exploration/Average Returns       -33.7027
evaluation/num steps total     323000
evaluation/num paths total       3230
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.189444
evaluation/Rewards Std              0.810966
evaluation/Rewards Max             -0.0163542
evaluation/Rewards Min             -9.68528
evaluation/Returns Mean           -18.9444
evaluation/Returns Std             13.3893
evaluation/Returns Max             -7.16103
evaluation/Returns Min            -55.6818
evaluation/Actions Mean             0.00460577
evaluation/Actions Std              0.176127
evaluation/Actions Max              0.996219
evaluation/Actions Min             -0.998542
evaluation/Num Paths               10
evaluation/Average Returns        -18.9444
time/data storing (s)               0.00125891
time/evaluation sampling (s)        0.256338
time/exploration sampling (s)       0.0692376
time/logging (s)                    0.00387298
time/saving (s)                     0.00270518
time/training (s)                   1.02051
time/epoch (s)                      1.35393
time/total (s)                    467.17
Epoch                             322
-----------------------------  ---------------
2019-04-21 12:24:13.875537 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 323 finished
-----------------------------  ---------------
replay_buffer/size              65000
trainer/QF1 Loss                    0.0220457
trainer/QF2 Loss                    0.0106036
trainer/Policy Loss                 8.63495
trainer/Q1 Predictions Mean        -7.10029
trainer/Q1 Predictions Std          5.26011
trainer/Q1 Predictions Max         -6.03824
trainer/Q1 Predictions Min        -54.9755
trainer/Q2 Predictions Mean        -7.15669
trainer/Q2 Predictions Std          5.28556
trainer/Q2 Predictions Max         -6.09494
trainer/Q2 Predictions Min        -55.2304
trainer/Q Targets Mean             -7.20395
trainer/Q Targets Std               5.26052
trainer/Q Targets Max              -6.05985
trainer/Q Targets Min             -55.0762
trainer/Log Pis Mean                1.69181
trainer/Log Pis Std                 1.1934
trainer/Log Pis Max                 5.09626
trainer/Log Pis Min                -1.71047
trainer/Policy mu Mean              0.0310847
trainer/Policy mu Std               0.576755
trainer/Policy mu Max               2.96713
trainer/Policy mu Min              -2.20304
trainer/Policy log std Mean        -2.11343
trainer/Policy log std Std          0.392604
trainer/Policy log std Max         -0.631754
trainer/Policy log std Min         -2.37502
trainer/Alpha                       0.0570962
trainer/Alpha Loss                 -0.882293
exploration/num steps total     65000
exploration/num paths total       650
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.356164
exploration/Rewards Std             0.989847
exploration/Rewards Max            -0.0126334
exploration/Rewards Min            -7.95293
exploration/Returns Mean          -35.6164
exploration/Returns Std             8.02287
exploration/Returns Max           -27.5935
exploration/Returns Min           -43.6393
exploration/Actions Mean            0.0198483
exploration/Actions Std             0.249056
exploration/Actions Max             0.998908
exploration/Actions Min            -0.974399
exploration/Num Paths               2
exploration/Average Returns       -35.6164
evaluation/num steps total     324000
evaluation/num paths total       3240
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.300766
evaluation/Rewards Std              1.16326
evaluation/Rewards Max             -0.0655045
evaluation/Rewards Min            -11.321
evaluation/Returns Mean           -30.0766
evaluation/Returns Std             20.8602
evaluation/Returns Max             -7.88709
evaluation/Returns Min            -66.2031
evaluation/Actions Mean             0.0418047
evaluation/Actions Std              0.194616
evaluation/Actions Max              0.997107
evaluation/Actions Min             -0.959117
evaluation/Num Paths               10
evaluation/Average Returns        -30.0766
time/data storing (s)               0.00113342
time/evaluation sampling (s)        0.257895
time/exploration sampling (s)       0.0692487
time/logging (s)                    0.00345598
time/saving (s)                     0.0105796
time/training (s)                   0.992576
time/epoch (s)                      1.33489
time/total (s)                    468.509
Epoch                             323
-----------------------------  ---------------
2019-04-21 12:24:15.208349 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 324 finished
-----------------------------  ---------------
replay_buffer/size              65200
trainer/QF1 Loss                    0.0218811
trainer/QF2 Loss                    0.0218147
trainer/Policy Loss                 9.68638
trainer/Q1 Predictions Mean        -7.72963
trainer/Q1 Predictions Std          5.98623
trainer/Q1 Predictions Max         -6.01931
trainer/Q1 Predictions Min        -52.6694
trainer/Q2 Predictions Mean        -7.75331
trainer/Q2 Predictions Std          6.01849
trainer/Q2 Predictions Max         -6.04757
trainer/Q2 Predictions Min        -52.9137
trainer/Q Targets Mean             -7.80267
trainer/Q Targets Std               5.98813
trainer/Q Targets Max              -6.03552
trainer/Q Targets Min             -52.8684
trainer/Log Pis Mean                2.06441
trainer/Log Pis Std                 1.45012
trainer/Log Pis Max                 6.9438
trainer/Log Pis Min                -2.6925
trainer/Policy mu Mean              0.111697
trainer/Policy mu Std               0.715076
trainer/Policy mu Max               3.06472
trainer/Policy mu Min              -2.94525
trainer/Policy log std Mean        -2.1013
trainer/Policy log std Std          0.509524
trainer/Policy log std Max         -0.506382
trainer/Policy log std Min         -2.42273
trainer/Alpha                       0.0564908
trainer/Alpha Loss                  0.185109
exploration/num steps total     65200
exploration/num paths total       652
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.380768
exploration/Rewards Std             1.21611
exploration/Rewards Max            -0.0119372
exploration/Rewards Min            -9.77562
exploration/Returns Mean          -38.0768
exploration/Returns Std            20.4595
exploration/Returns Max           -17.6172
exploration/Returns Min           -58.5363
exploration/Actions Mean            0.00105782
exploration/Actions Std             0.248543
exploration/Actions Max             0.999667
exploration/Actions Min            -0.991274
exploration/Num Paths               2
exploration/Average Returns       -38.0768
evaluation/num steps total     325000
evaluation/num paths total       3250
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.198704
evaluation/Rewards Std              0.766968
evaluation/Rewards Max             -0.0306815
evaluation/Rewards Min             -8.6728
evaluation/Returns Mean           -19.8704
evaluation/Returns Std             13.0228
evaluation/Returns Max             -8.03742
evaluation/Returns Min            -47.8313
evaluation/Actions Mean             0.0121916
evaluation/Actions Std              0.17212
evaluation/Actions Max              0.994222
evaluation/Actions Min             -0.99796
evaluation/Num Paths               10
evaluation/Average Returns        -19.8704
time/data storing (s)               0.00117374
time/evaluation sampling (s)        0.253403
time/exploration sampling (s)       0.066361
time/logging (s)                    0.00378646
time/saving (s)                     0.00234371
time/training (s)                   0.996392
time/epoch (s)                      1.32346
time/total (s)                    469.838
Epoch                             324
-----------------------------  ---------------
2019-04-21 12:24:16.553992 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 325 finished
-----------------------------  ---------------
replay_buffer/size              65400
trainer/QF1 Loss                    0.395344
trainer/QF2 Loss                    0.3967
trainer/Policy Loss                 8.60439
trainer/Q1 Predictions Mean        -6.89501
trainer/Q1 Predictions Std          3.34126
trainer/Q1 Predictions Max         -6.09135
trainer/Q1 Predictions Min        -29.9349
trainer/Q2 Predictions Mean        -6.89859
trainer/Q2 Predictions Std          3.3208
trainer/Q2 Predictions Max         -6.12301
trainer/Q2 Predictions Min        -29.6946
trainer/Q Targets Mean             -6.88336
trainer/Q Targets Std               3.45934
trainer/Q Targets Max              -0.643937
trainer/Q Targets Min             -30.0609
trainer/Log Pis Mean                1.84666
trainer/Log Pis Std                 1.18558
trainer/Log Pis Max                 5.13932
trainer/Log Pis Min                -3.03133
trainer/Policy mu Mean              0.0410295
trainer/Policy mu Std               0.513011
trainer/Policy mu Max               2.72769
trainer/Policy mu Min              -1.70617
trainer/Policy log std Mean        -2.15943
trainer/Policy log std Std          0.372533
trainer/Policy log std Max         -0.619136
trainer/Policy log std Min         -2.38944
trainer/Alpha                       0.0548305
trainer/Alpha Loss                 -0.445195
exploration/num steps total     65400
exploration/num paths total       654
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.416839
exploration/Rewards Std             1.30378
exploration/Rewards Max            -0.0146344
exploration/Rewards Min           -10.196
exploration/Returns Mean          -41.6839
exploration/Returns Std            24.2062
exploration/Returns Max           -17.4777
exploration/Returns Min           -65.89
exploration/Actions Mean            0.0350887
exploration/Actions Std             0.249399
exploration/Actions Max             0.996715
exploration/Actions Min            -0.998648
exploration/Num Paths               2
exploration/Average Returns       -41.6839
evaluation/num steps total     326000
evaluation/num paths total       3260
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.234607
evaluation/Rewards Std              0.905171
evaluation/Rewards Max             -0.0421609
evaluation/Rewards Min             -9.80412
evaluation/Returns Mean           -23.4607
evaluation/Returns Std             12.916
evaluation/Returns Max             -8.41873
evaluation/Returns Min            -51.5852
evaluation/Actions Mean             0.0304111
evaluation/Actions Std              0.192047
evaluation/Actions Max              0.997132
evaluation/Actions Min             -0.987359
evaluation/Num Paths               10
evaluation/Average Returns        -23.4607
time/data storing (s)               0.00121879
time/evaluation sampling (s)        0.260209
time/exploration sampling (s)       0.0700146
time/logging (s)                    0.0034301
time/saving (s)                     0.00231738
time/training (s)                   0.998244
time/epoch (s)                      1.33543
time/total (s)                    471.178
Epoch                             325
-----------------------------  ---------------
2019-04-21 12:24:17.883052 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 326 finished
-----------------------------  ---------------
replay_buffer/size              65600
trainer/QF1 Loss                    0.011624
trainer/QF2 Loss                    0.0193078
trainer/Policy Loss                 9.04209
trainer/Q1 Predictions Mean        -7.14513
trainer/Q1 Predictions Std          4.14288
trainer/Q1 Predictions Max         -6.13926
trainer/Q1 Predictions Min        -36.1581
trainer/Q2 Predictions Mean        -7.18657
trainer/Q2 Predictions Std          4.17596
trainer/Q2 Predictions Max         -6.17192
trainer/Q2 Predictions Min        -36.465
trainer/Q Targets Mean             -7.09016
trainer/Q Targets Std               4.11345
trainer/Q Targets Max              -6.02786
trainer/Q Targets Min             -35.7403
trainer/Log Pis Mean                1.95691
trainer/Log Pis Std                 1.27441
trainer/Log Pis Max                 5.70791
trainer/Log Pis Min                -2.68536
trainer/Policy mu Mean              0.0584511
trainer/Policy mu Std               0.59318
trainer/Policy mu Max               3.09663
trainer/Policy mu Min              -2.32571
trainer/Policy log std Mean        -2.22795
trainer/Policy log std Std          0.418729
trainer/Policy log std Max         -0.628181
trainer/Policy log std Min         -2.42746
trainer/Alpha                       0.0558558
trainer/Alpha Loss                 -0.124328
exploration/num steps total     65600
exploration/num paths total       656
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.388433
exploration/Rewards Std             1.21852
exploration/Rewards Max            -0.0219283
exploration/Rewards Min            -9.44612
exploration/Returns Mean          -38.8433
exploration/Returns Std            13.8921
exploration/Returns Max           -24.9511
exploration/Returns Min           -52.7354
exploration/Actions Mean            0.0199027
exploration/Actions Std             0.24905
exploration/Actions Max             0.997528
exploration/Actions Min            -0.960453
exploration/Num Paths               2
exploration/Average Returns       -38.8433
evaluation/num steps total     327000
evaluation/num paths total       3270
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.202707
evaluation/Rewards Std              0.824429
evaluation/Rewards Max             -0.0238964
evaluation/Rewards Min             -7.95945
evaluation/Returns Mean           -20.2707
evaluation/Returns Std              8.95982
evaluation/Returns Max             -4.40973
evaluation/Returns Min            -36.2639
evaluation/Actions Mean             0.0272052
evaluation/Actions Std              0.185588
evaluation/Actions Max              0.997148
evaluation/Actions Min             -0.995319
evaluation/Num Paths               10
evaluation/Average Returns        -20.2707
time/data storing (s)               0.00132558
time/evaluation sampling (s)        0.26045
time/exploration sampling (s)       0.0663699
time/logging (s)                    0.00349232
time/saving (s)                     0.00268164
time/training (s)                   0.985655
time/epoch (s)                      1.31997
time/total (s)                    472.503
Epoch                             326
-----------------------------  ---------------
2019-04-21 12:24:19.204407 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 327 finished
-----------------------------  ---------------
replay_buffer/size              65800
trainer/QF1 Loss                    1.09744
trainer/QF2 Loss                    1.0971
trainer/Policy Loss                 8.23093
trainer/Q1 Predictions Mean        -6.46297
trainer/Q1 Predictions Std          1.73874
trainer/Q1 Predictions Max         -6.0424
trainer/Q1 Predictions Min        -22.1377
trainer/Q2 Predictions Mean        -6.46328
trainer/Q2 Predictions Std          1.72234
trainer/Q2 Predictions Max         -6.0667
trainer/Q2 Predictions Min        -21.9194
trainer/Q Targets Mean             -6.36066
trainer/Q Targets Std               2.04203
trainer/Q Targets Max              -0.0629705
trainer/Q Targets Min             -21.9826
trainer/Log Pis Mean                1.85105
trainer/Log Pis Std                 1.17361
trainer/Log Pis Max                 6.86055
trainer/Log Pis Min                -2.65264
trainer/Policy mu Mean              0.0498089
trainer/Policy mu Std               0.40596
trainer/Policy mu Max               2.77817
trainer/Policy mu Min              -1.41735
trainer/Policy log std Mean        -2.24418
trainer/Policy log std Std          0.285259
trainer/Policy log std Max         -0.649114
trainer/Policy log std Min         -2.40328
trainer/Alpha                       0.055987
trainer/Alpha Loss                 -0.429338
exploration/num steps total     65800
exploration/num paths total       658
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.120266
exploration/Rewards Std             0.0667507
exploration/Rewards Max            -0.00899194
exploration/Rewards Min            -0.356015
exploration/Returns Mean          -12.0266
exploration/Returns Std             0.475908
exploration/Returns Max           -11.5507
exploration/Returns Min           -12.5026
exploration/Actions Mean           -0.00736196
exploration/Actions Std             0.141562
exploration/Actions Max             0.324812
exploration/Actions Min            -0.905906
exploration/Num Paths               2
exploration/Average Returns       -12.0266
evaluation/num steps total     328000
evaluation/num paths total       3280
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.196222
evaluation/Rewards Std              0.956708
evaluation/Rewards Max             -0.0183385
evaluation/Rewards Min            -10.5266
evaluation/Returns Mean           -19.6222
evaluation/Returns Std             16.8529
evaluation/Returns Max             -2.01216
evaluation/Returns Min            -57.716
evaluation/Actions Mean             0.0194721
evaluation/Actions Std              0.176456
evaluation/Actions Max              0.997259
evaluation/Actions Min             -0.968902
evaluation/Num Paths               10
evaluation/Average Returns        -19.6222
time/data storing (s)               0.00127773
time/evaluation sampling (s)        0.25809
time/exploration sampling (s)       0.0675889
time/logging (s)                    0.00357523
time/saving (s)                     0.00231024
time/training (s)                   0.97948
time/epoch (s)                      1.31232
time/total (s)                    473.819
Epoch                             327
-----------------------------  ---------------
2019-04-21 12:24:20.525534 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 328 finished
-----------------------------  ---------------
replay_buffer/size              66000
trainer/QF1 Loss                    0.00966437
trainer/QF2 Loss                    0.00899123
trainer/Policy Loss                 8.47331
trainer/Q1 Predictions Mean        -6.59927
trainer/Q1 Predictions Std          3.40233
trainer/Q1 Predictions Max         -6.04595
trainer/Q1 Predictions Min        -40.2799
trainer/Q2 Predictions Mean        -6.66039
trainer/Q2 Predictions Std          3.45784
trainer/Q2 Predictions Max         -6.10421
trainer/Q2 Predictions Min        -40.8879
trainer/Q Targets Mean             -6.66499
trainer/Q Targets Std               3.40209
trainer/Q Targets Max              -6.02018
trainer/Q Targets Min             -40.3286
trainer/Log Pis Mean                1.96841
trainer/Log Pis Std                 0.93976
trainer/Log Pis Max                 4.15356
trainer/Log Pis Min                -1.47617
trainer/Policy mu Mean              0.00469964
trainer/Policy mu Std               0.367019
trainer/Policy mu Max               3.11458
trainer/Policy mu Min              -1.3896
trainer/Policy log std Mean        -2.28119
trainer/Policy log std Std          0.245408
trainer/Policy log std Max         -0.723672
trainer/Policy log std Min         -2.42139
trainer/Alpha                       0.0562868
trainer/Alpha Loss                 -0.0908873
exploration/num steps total     66000
exploration/num paths total       660
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.156084
exploration/Rewards Std             0.300323
exploration/Rewards Max            -0.0110156
exploration/Rewards Min            -3.35729
exploration/Returns Mean          -15.6084
exploration/Returns Std             3.38209
exploration/Returns Max           -12.2263
exploration/Returns Min           -18.9905
exploration/Actions Mean           -0.00128249
exploration/Actions Std             0.179164
exploration/Actions Max             0.954585
exploration/Actions Min            -0.998645
exploration/Num Paths               2
exploration/Average Returns       -15.6084
evaluation/num steps total     329000
evaluation/num paths total       3290
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.151955
evaluation/Rewards Std              0.732358
evaluation/Rewards Max             -0.00135127
evaluation/Rewards Min             -7.33832
evaluation/Returns Mean           -15.1955
evaluation/Returns Std              9.80733
evaluation/Returns Max             -2.55831
evaluation/Returns Min            -31.5774
evaluation/Actions Mean             0.0151264
evaluation/Actions Std              0.182846
evaluation/Actions Max              0.995617
evaluation/Actions Min             -0.996156
evaluation/Num Paths               10
evaluation/Average Returns        -15.1955
time/data storing (s)               0.0011562
time/evaluation sampling (s)        0.257153
time/exploration sampling (s)       0.0681155
time/logging (s)                    0.00376731
time/saving (s)                     0.00255055
time/training (s)                   0.979375
time/epoch (s)                      1.31212
time/total (s)                    475.136
Epoch                             328
-----------------------------  ---------------
2019-04-21 12:24:21.861112 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 329 finished
-----------------------------  ---------------
replay_buffer/size              66200
trainer/QF1 Loss                    1.12362
trainer/QF2 Loss                    1.1369
trainer/Policy Loss                 8.56928
trainer/Q1 Predictions Mean        -6.64112
trainer/Q1 Predictions Std          2.16829
trainer/Q1 Predictions Max         -6.1323
trainer/Q1 Predictions Min        -24.1927
trainer/Q2 Predictions Mean        -6.68722
trainer/Q2 Predictions Std          2.18605
trainer/Q2 Predictions Max         -6.16513
trainer/Q2 Predictions Min        -24.3423
trainer/Q Targets Mean             -6.44926
trainer/Q Targets Std               2.40478
trainer/Q Targets Max              -0.249156
trainer/Q Targets Min             -24.0507
trainer/Log Pis Mean                1.95985
trainer/Log Pis Std                 1.11982
trainer/Log Pis Max                 5.83101
trainer/Log Pis Min                -2.77204
trainer/Policy mu Mean              0.033698
trainer/Policy mu Std               0.478922
trainer/Policy mu Max               2.83366
trainer/Policy mu Min              -1.67204
trainer/Policy log std Mean        -2.18608
trainer/Policy log std Std          0.36113
trainer/Policy log std Max         -0.583606
trainer/Policy log std Min         -2.42418
trainer/Alpha                       0.0550153
trainer/Alpha Loss                 -0.116438
exploration/num steps total     66200
exploration/num paths total       662
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.541409
exploration/Rewards Std             1.60465
exploration/Rewards Max            -0.0127739
exploration/Rewards Min           -10.0614
exploration/Returns Mean          -54.1409
exploration/Returns Std             9.47664
exploration/Returns Max           -44.6643
exploration/Returns Min           -63.6176
exploration/Actions Mean            0.0229213
exploration/Actions Std             0.285014
exploration/Actions Max             0.998779
exploration/Actions Min            -0.991879
exploration/Num Paths               2
exploration/Average Returns       -54.1409
evaluation/num steps total     330000
evaluation/num paths total       3300
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.263914
evaluation/Rewards Std              1.13277
evaluation/Rewards Max             -0.0259133
evaluation/Rewards Min             -9.71251
evaluation/Returns Mean           -26.3914
evaluation/Returns Std             16.6509
evaluation/Returns Max             -2.85888
evaluation/Returns Min            -49.9668
evaluation/Actions Mean             0.0205972
evaluation/Actions Std              0.203438
evaluation/Actions Max              0.996405
evaluation/Actions Min             -0.99623
evaluation/Num Paths               10
evaluation/Average Returns        -26.3914
time/data storing (s)               0.00122399
time/evaluation sampling (s)        0.25982
time/exploration sampling (s)       0.0676466
time/logging (s)                    0.00330523
time/saving (s)                     0.00230882
time/training (s)                   0.991119
time/epoch (s)                      1.32542
time/total (s)                    476.466
Epoch                             329
-----------------------------  ---------------
2019-04-21 12:24:23.167520 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 330 finished
-----------------------------  ---------------
replay_buffer/size              66400
trainer/QF1 Loss                    0.0137424
trainer/QF2 Loss                    0.0208237
trainer/Policy Loss                 9.30896
trainer/Q1 Predictions Mean        -7.08738
trainer/Q1 Predictions Std          3.68454
trainer/Q1 Predictions Max         -6.02606
trainer/Q1 Predictions Min        -25.6398
trainer/Q2 Predictions Mean        -7.0623
trainer/Q2 Predictions Std          3.68167
trainer/Q2 Predictions Max         -5.99856
trainer/Q2 Predictions Min        -25.3405
trainer/Q Targets Mean             -7.13765
trainer/Q Targets Std               3.68499
trainer/Q Targets Max              -6.00526
trainer/Q Targets Min             -25.5309
trainer/Log Pis Mean                2.27418
trainer/Log Pis Std                 1.1954
trainer/Log Pis Max                 8.02259
trainer/Log Pis Min                -1.12554
trainer/Policy mu Mean              0.0444976
trainer/Policy mu Std               0.654301
trainer/Policy mu Max               2.9093
trainer/Policy mu Min              -3.20926
trainer/Policy log std Mean        -2.26391
trainer/Policy log std Std          0.442023
trainer/Policy log std Max         -0.531413
trainer/Policy log std Min         -2.49727
trainer/Alpha                       0.0560374
trainer/Alpha Loss                  0.790132
exploration/num steps total     66400
exploration/num paths total       664
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.17702
exploration/Rewards Std             0.424024
exploration/Rewards Max            -0.0069592
exploration/Rewards Min            -4.25189
exploration/Returns Mean          -17.702
exploration/Returns Std             2.07306
exploration/Returns Max           -15.6289
exploration/Returns Min           -19.775
exploration/Actions Mean            0.0124936
exploration/Actions Std             0.20356
exploration/Actions Max             0.993536
exploration/Actions Min            -0.994502
exploration/Num Paths               2
exploration/Average Returns       -17.702
evaluation/num steps total     331000
evaluation/num paths total       3310
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.13252
evaluation/Rewards Std              0.653915
evaluation/Rewards Max             -0.0136414
evaluation/Rewards Min             -8.82498
evaluation/Returns Mean           -13.252
evaluation/Returns Std              8.94076
evaluation/Returns Max             -4.81794
evaluation/Returns Min            -36.4491
evaluation/Actions Mean            -0.00155252
evaluation/Actions Std              0.17734
evaluation/Actions Max              0.997048
evaluation/Actions Min             -0.998624
evaluation/Num Paths               10
evaluation/Average Returns        -13.252
time/data storing (s)               0.00138466
time/evaluation sampling (s)        0.254299
time/exploration sampling (s)       0.0704801
time/logging (s)                    0.00344676
time/saving (s)                     0.00229044
time/training (s)                   0.965532
time/epoch (s)                      1.29743
time/total (s)                    477.768
Epoch                             330
-----------------------------  ---------------
2019-04-21 12:24:24.493974 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 331 finished
-----------------------------  ---------------
replay_buffer/size              66600
trainer/QF1 Loss                    0.411277
trainer/QF2 Loss                    0.408441
trainer/Policy Loss                 9.04044
trainer/Q1 Predictions Mean        -7.03711
trainer/Q1 Predictions Std          3.9277
trainer/Q1 Predictions Max         -6.18445
trainer/Q1 Predictions Min        -40.5017
trainer/Q2 Predictions Mean        -7.01395
trainer/Q2 Predictions Std          3.95069
trainer/Q2 Predictions Max         -6.15296
trainer/Q2 Predictions Min        -40.7873
trainer/Q Targets Mean             -6.88509
trainer/Q Targets Std               3.94533
trainer/Q Targets Max              -0.168143
trainer/Q Targets Min             -39.4509
trainer/Log Pis Mean                2.08882
trainer/Log Pis Std                 1.16046
trainer/Log Pis Max                 6.07561
trainer/Log Pis Min                -1.39221
trainer/Policy mu Mean              0.0785247
trainer/Policy mu Std               0.600613
trainer/Policy mu Max               3.14114
trainer/Policy mu Min              -2.43025
trainer/Policy log std Mean        -2.17347
trainer/Policy log std Std          0.432905
trainer/Policy log std Max         -0.451688
trainer/Policy log std Min         -2.43273
trainer/Alpha                       0.0551796
trainer/Alpha Loss                  0.2573
exploration/num steps total     66600
exploration/num paths total       666
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.349869
exploration/Rewards Std             1.08478
exploration/Rewards Max            -0.00444349
exploration/Rewards Min            -8.09576
exploration/Returns Mean          -34.9869
exploration/Returns Std            11.759
exploration/Returns Max           -23.2279
exploration/Returns Min           -46.7459
exploration/Actions Mean            0.0490914
exploration/Actions Std             0.237044
exploration/Actions Max             0.999393
exploration/Actions Min            -0.383123
exploration/Num Paths               2
exploration/Average Returns       -34.9869
evaluation/num steps total     332000
evaluation/num paths total       3320
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.254904
evaluation/Rewards Std              1.16837
evaluation/Rewards Max             -0.00558175
evaluation/Rewards Min            -10.5307
evaluation/Returns Mean           -25.4904
evaluation/Returns Std             19.2569
evaluation/Returns Max             -1.41674
evaluation/Returns Min            -57.0788
evaluation/Actions Mean             0.0280916
evaluation/Actions Std              0.19727
evaluation/Actions Max              0.997286
evaluation/Actions Min             -0.99661
evaluation/Num Paths               10
evaluation/Average Returns        -25.4904
time/data storing (s)               0.00115956
time/evaluation sampling (s)        0.256638
time/exploration sampling (s)       0.0679617
time/logging (s)                    0.00301114
time/saving (s)                     0.0023092
time/training (s)                   0.985887
time/epoch (s)                      1.31697
time/total (s)                    479.089
Epoch                             331
-----------------------------  ---------------
2019-04-21 12:24:25.842037 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 332 finished
-----------------------------  ---------------
replay_buffer/size              66800
trainer/QF1 Loss                    0.00922108
trainer/QF2 Loss                    0.00725998
trainer/Policy Loss                 8.97598
trainer/Q1 Predictions Mean        -6.77908
trainer/Q1 Predictions Std          3.07884
trainer/Q1 Predictions Max         -6.03733
trainer/Q1 Predictions Min        -31.2243
trainer/Q2 Predictions Mean        -6.79651
trainer/Q2 Predictions Std          3.05368
trainer/Q2 Predictions Max         -6.06583
trainer/Q2 Predictions Min        -31.0594
trainer/Q Targets Mean             -6.81498
trainer/Q Targets Std               3.04904
trainer/Q Targets Max              -5.98668
trainer/Q Targets Min             -31.0125
trainer/Log Pis Mean                2.2459
trainer/Log Pis Std                 0.875745
trainer/Log Pis Max                 5.15936
trainer/Log Pis Min                -0.851846
trainer/Policy mu Mean              0.0352131
trainer/Policy mu Std               0.476046
trainer/Policy mu Max               2.9221
trainer/Policy mu Min              -2.15567
trainer/Policy log std Mean        -2.2852
trainer/Policy log std Std          0.345054
trainer/Policy log std Max         -0.57573
trainer/Policy log std Min         -2.45547
trainer/Alpha                       0.0555012
trainer/Alpha Loss                  0.711024
exploration/num steps total     66800
exploration/num paths total       668
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.25261
exploration/Rewards Std             0.684914
exploration/Rewards Max            -0.00352396
exploration/Rewards Min            -5.59374
exploration/Returns Mean          -25.261
exploration/Returns Std             3.68324
exploration/Returns Max           -21.5778
exploration/Returns Min           -28.9443
exploration/Actions Mean            0.0418101
exploration/Actions Std             0.233021
exploration/Actions Max             0.99881
exploration/Actions Min            -0.550818
exploration/Num Paths               2
exploration/Average Returns       -25.261
evaluation/num steps total     333000
evaluation/num paths total       3330
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.195185
evaluation/Rewards Std              0.845112
evaluation/Rewards Max             -0.0233012
evaluation/Rewards Min            -10.3069
evaluation/Returns Mean           -19.5185
evaluation/Returns Std             15.2473
evaluation/Returns Max             -5.83464
evaluation/Returns Min            -58.5208
evaluation/Actions Mean             0.019641
evaluation/Actions Std              0.181248
evaluation/Actions Max              0.997333
evaluation/Actions Min             -0.992059
evaluation/Num Paths               10
evaluation/Average Returns        -19.5185
time/data storing (s)               0.00128926
time/evaluation sampling (s)        0.253082
time/exploration sampling (s)       0.07012
time/logging (s)                    0.00343186
time/saving (s)                     0.00234302
time/training (s)                   1.00992
time/epoch (s)                      1.34018
time/total (s)                    480.433
Epoch                             332
-----------------------------  ---------------
2019-04-21 12:24:27.153417 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 333 finished
-----------------------------  ---------------
replay_buffer/size              67000
trainer/QF1 Loss                    0.739114
trainer/QF2 Loss                    0.732098
trainer/Policy Loss                 9.65706
trainer/Q1 Predictions Mean        -7.53125
trainer/Q1 Predictions Std          5.78937
trainer/Q1 Predictions Max         -5.99502
trainer/Q1 Predictions Min        -39.9525
trainer/Q2 Predictions Mean        -7.55554
trainer/Q2 Predictions Std          5.81433
trainer/Q2 Predictions Max         -6.00173
trainer/Q2 Predictions Min        -40.3726
trainer/Q Targets Mean             -7.51846
trainer/Q Targets Std               5.99094
trainer/Q Targets Max              -0.0529459
trainer/Q Targets Min             -40.7895
trainer/Log Pis Mean                2.2594
trainer/Log Pis Std                 1.26783
trainer/Log Pis Max                 7.45452
trainer/Log Pis Min                -1.13528
trainer/Policy mu Mean              0.130554
trainer/Policy mu Std               0.666454
trainer/Policy mu Max               3.04307
trainer/Policy mu Min              -2.39195
trainer/Policy log std Mean        -2.2751
trainer/Policy log std Std          0.458262
trainer/Policy log std Max         -0.634491
trainer/Policy log std Min         -2.53273
trainer/Alpha                       0.0561089
trainer/Alpha Loss                  0.747247
exploration/num steps total     67000
exploration/num paths total       670
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.31845
exploration/Rewards Std             1.1157
exploration/Rewards Max            -0.00491421
exploration/Rewards Min            -8.80032
exploration/Returns Mean          -31.845
exploration/Returns Std            21.4029
exploration/Returns Max           -10.4421
exploration/Returns Min           -53.2479
exploration/Actions Mean            0.0200818
exploration/Actions Std             0.206909
exploration/Actions Max             0.997891
exploration/Actions Min            -0.877101
exploration/Num Paths               2
exploration/Average Returns       -31.845
evaluation/num steps total     334000
evaluation/num paths total       3340
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.200444
evaluation/Rewards Std              0.978081
evaluation/Rewards Max             -0.0146184
evaluation/Rewards Min             -9.45673
evaluation/Returns Mean           -20.0444
evaluation/Returns Std             17.6841
evaluation/Returns Max             -3.11113
evaluation/Returns Min            -51.2212
evaluation/Actions Mean             0.0171545
evaluation/Actions Std              0.175945
evaluation/Actions Max              0.996968
evaluation/Actions Min             -0.995766
evaluation/Num Paths               10
evaluation/Average Returns        -20.0444
time/data storing (s)               0.00115639
time/evaluation sampling (s)        0.251435
time/exploration sampling (s)       0.0601037
time/logging (s)                    0.00314456
time/saving (s)                     0.00242723
time/training (s)                   0.983571
time/epoch (s)                      1.30184
time/total (s)                    481.739
Epoch                             333
-----------------------------  ---------------
2019-04-21 12:24:28.542975 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 334 finished
-----------------------------  ---------------
replay_buffer/size              67200
trainer/QF1 Loss                    0.0193326
trainer/QF2 Loss                    0.0256714
trainer/Policy Loss                 8.75955
trainer/Q1 Predictions Mean        -6.83444
trainer/Q1 Predictions Std          4.75392
trainer/Q1 Predictions Max         -6.00956
trainer/Q1 Predictions Min        -52.495
trainer/Q2 Predictions Mean        -6.83133
trainer/Q2 Predictions Std          4.75154
trainer/Q2 Predictions Max         -6.01536
trainer/Q2 Predictions Min        -52.4658
trainer/Q Targets Mean             -6.92752
trainer/Q Targets Std               4.76506
trainer/Q Targets Max              -6.03669
trainer/Q Targets Min             -52.6341
trainer/Log Pis Mean                2.01155
trainer/Log Pis Std                 0.976136
trainer/Log Pis Max                 5.91003
trainer/Log Pis Min                -0.97127
trainer/Policy mu Mean              0.0509748
trainer/Policy mu Std               0.489389
trainer/Policy mu Max               3.40116
trainer/Policy mu Min              -2.26572
trainer/Policy log std Mean        -2.19501
trainer/Policy log std Std          0.318007
trainer/Policy log std Max         -0.6865
trainer/Policy log std Min         -2.37403
trainer/Alpha                       0.0561903
trainer/Alpha Loss                  0.0332481
exploration/num steps total     67200
exploration/num paths total       672
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.398052
exploration/Rewards Std             1.23468
exploration/Rewards Max            -0.0178029
exploration/Rewards Min            -9.28007
exploration/Returns Mean          -39.8052
exploration/Returns Std            19.7501
exploration/Returns Max           -20.0552
exploration/Returns Min           -59.5553
exploration/Actions Mean            0.048574
exploration/Actions Std             0.244437
exploration/Actions Max             0.998961
exploration/Actions Min            -0.471468
exploration/Num Paths               2
exploration/Average Returns       -39.8052
evaluation/num steps total     335000
evaluation/num paths total       3350
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.236756
evaluation/Rewards Std              1.05505
evaluation/Rewards Max             -0.0146501
evaluation/Rewards Min            -11.0413
evaluation/Returns Mean           -23.6756
evaluation/Returns Std             17.8256
evaluation/Returns Max            -10.7183
evaluation/Returns Min            -60.74
evaluation/Actions Mean             0.0247213
evaluation/Actions Std              0.201427
evaluation/Actions Max              0.998332
evaluation/Actions Min             -0.996485
evaluation/Num Paths               10
evaluation/Average Returns        -23.6756
time/data storing (s)               0.00116954
time/evaluation sampling (s)        0.268148
time/exploration sampling (s)       0.0693022
time/logging (s)                    0.00374358
time/saving (s)                     0.00232002
time/training (s)                   1.03607
time/epoch (s)                      1.38076
time/total (s)                    483.125
Epoch                             334
-----------------------------  ---------------
2019-04-21 12:24:30.012626 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 335 finished
-----------------------------  ---------------
replay_buffer/size              67400
trainer/QF1 Loss                    0.767445
trainer/QF2 Loss                    0.752205
trainer/Policy Loss                 9.06513
trainer/Q1 Predictions Mean        -7.37541
trainer/Q1 Predictions Std          4.40119
trainer/Q1 Predictions Max         -6.12372
trainer/Q1 Predictions Min        -35.8488
trainer/Q2 Predictions Mean        -7.34878
trainer/Q2 Predictions Std          4.39658
trainer/Q2 Predictions Max         -6.11287
trainer/Q2 Predictions Min        -35.7265
trainer/Q Targets Mean             -7.23507
trainer/Q Targets Std               4.48894
trainer/Q Targets Max              -0.0661729
trainer/Q Targets Min             -35.7462
trainer/Log Pis Mean                1.7393
trainer/Log Pis Std                 1.13266
trainer/Log Pis Max                 5.39253
trainer/Log Pis Min                -2.60643
trainer/Policy mu Mean              0.148689
trainer/Policy mu Std               0.621363
trainer/Policy mu Max               2.96088
trainer/Policy mu Min              -1.23025
trainer/Policy log std Mean        -2.092
trainer/Policy log std Std          0.429072
trainer/Policy log std Max         -0.615
trainer/Policy log std Min         -2.35198
trainer/Alpha                       0.0559781
trainer/Alpha Loss                 -0.751449
exploration/num steps total     67400
exploration/num paths total       674
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.344593
exploration/Rewards Std             1.0202
exploration/Rewards Max            -0.00414454
exploration/Rewards Min            -8.06786
exploration/Returns Mean          -34.4593
exploration/Returns Std            15.5647
exploration/Returns Max           -18.8946
exploration/Returns Min           -50.024
exploration/Actions Mean            0.0311792
exploration/Actions Std             0.228926
exploration/Actions Max             0.998193
exploration/Actions Min            -0.543683
exploration/Num Paths               2
exploration/Average Returns       -34.4593
evaluation/num steps total     336000
evaluation/num paths total       3360
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.188246
evaluation/Rewards Std              0.868597
evaluation/Rewards Max             -0.0159689
evaluation/Rewards Min             -7.94499
evaluation/Returns Mean           -18.8246
evaluation/Returns Std             12.705
evaluation/Returns Max             -2.96038
evaluation/Returns Min            -35.5243
evaluation/Actions Mean             0.0176717
evaluation/Actions Std              0.181879
evaluation/Actions Max              0.995917
evaluation/Actions Min             -0.995629
evaluation/Num Paths               10
evaluation/Average Returns        -18.8246
time/data storing (s)               0.00145144
time/evaluation sampling (s)        0.255194
time/exploration sampling (s)       0.0895142
time/logging (s)                    0.00347475
time/saving (s)                     0.00241568
time/training (s)                   1.10772
time/epoch (s)                      1.45977
time/total (s)                    484.589
Epoch                             335
-----------------------------  ---------------
2019-04-21 12:24:31.421479 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 336 finished
-----------------------------  ---------------
replay_buffer/size              67600
trainer/QF1 Loss                    0.394859
trainer/QF2 Loss                    0.395316
trainer/Policy Loss                 9.7144
trainer/Q1 Predictions Mean        -8.03853
trainer/Q1 Predictions Std          8.5729
trainer/Q1 Predictions Max         -5.97321
trainer/Q1 Predictions Min        -74.1752
trainer/Q2 Predictions Mean        -8.05713
trainer/Q2 Predictions Std          8.58224
trainer/Q2 Predictions Max         -5.95997
trainer/Q2 Predictions Min        -74.2532
trainer/Q Targets Mean             -8.08745
trainer/Q Targets Std               8.46339
trainer/Q Targets Max              -0.16751
trainer/Q Targets Min             -73.2164
trainer/Log Pis Mean                1.99848
trainer/Log Pis Std                 1.34015
trainer/Log Pis Max                 6.96395
trainer/Log Pis Min                -2.32473
trainer/Policy mu Mean              0.0896798
trainer/Policy mu Std               0.620687
trainer/Policy mu Max               3.28213
trainer/Policy mu Min              -1.68193
trainer/Policy log std Mean        -2.16573
trainer/Policy log std Std          0.387285
trainer/Policy log std Max         -0.666483
trainer/Policy log std Min         -2.38086
trainer/Alpha                       0.0545656
trainer/Alpha Loss                 -0.00442119
exploration/num steps total     67600
exploration/num paths total       676
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.257269
exploration/Rewards Std             0.710489
exploration/Rewards Max            -0.0194186
exploration/Rewards Min            -6.69613
exploration/Returns Mean          -25.7269
exploration/Returns Std             9.30674
exploration/Returns Max           -16.4202
exploration/Returns Min           -35.0336
exploration/Actions Mean            0.0332678
exploration/Actions Std             0.215755
exploration/Actions Max             0.997896
exploration/Actions Min            -0.416056
exploration/Num Paths               2
exploration/Average Returns       -25.7269
evaluation/num steps total     337000
evaluation/num paths total       3370
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.326274
evaluation/Rewards Std              1.20995
evaluation/Rewards Max             -0.0553971
evaluation/Rewards Min             -9.48085
evaluation/Returns Mean           -32.6274
evaluation/Returns Std             14.8749
evaluation/Returns Max            -11.1991
evaluation/Returns Min            -53.0947
evaluation/Actions Mean             0.0332599
evaluation/Actions Std              0.217586
evaluation/Actions Max              0.996275
evaluation/Actions Min             -0.994107
evaluation/Num Paths               10
evaluation/Average Returns        -32.6274
time/data storing (s)               0.0011365
time/evaluation sampling (s)        0.246625
time/exploration sampling (s)       0.0607767
time/logging (s)                    0.00344689
time/saving (s)                     0.00261768
time/training (s)                   1.08496
time/epoch (s)                      1.39956
time/total (s)                    485.993
Epoch                             336
-----------------------------  ---------------
2019-04-21 12:24:32.870504 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 337 finished
-----------------------------  ---------------
replay_buffer/size              67800
trainer/QF1 Loss                    0.40211
trainer/QF2 Loss                    0.391599
trainer/Policy Loss                 8.84336
trainer/Q1 Predictions Mean        -7.36409
trainer/Q1 Predictions Std          5.02637
trainer/Q1 Predictions Max         -6.10799
trainer/Q1 Predictions Min        -37.1613
trainer/Q2 Predictions Mean        -7.2763
trainer/Q2 Predictions Std          5.07775
trainer/Q2 Predictions Max         -6.00132
trainer/Q2 Predictions Min        -37.2397
trainer/Q Targets Mean             -7.28488
trainer/Q Targets Std               5.02208
trainer/Q Targets Max              -0.0702438
trainer/Q Targets Min             -36.3671
trainer/Log Pis Mean                1.65808
trainer/Log Pis Std                 1.10896
trainer/Log Pis Max                 5.67183
trainer/Log Pis Min                -1.86793
trainer/Policy mu Mean              0.0822317
trainer/Policy mu Std               0.568709
trainer/Policy mu Max               2.90736
trainer/Policy mu Min              -2.3384
trainer/Policy log std Mean        -2.10613
trainer/Policy log std Std          0.39991
trainer/Policy log std Max         -0.475053
trainer/Policy log std Min         -2.34116
trainer/Alpha                       0.0530527
trainer/Alpha Loss                 -1.00393
exploration/num steps total     67800
exploration/num paths total       678
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.19908
exploration/Rewards Std             0.378341
exploration/Rewards Max            -0.0166331
exploration/Rewards Min            -3.47023
exploration/Returns Mean          -19.908
exploration/Returns Std             1.3557
exploration/Returns Max           -18.5523
exploration/Returns Min           -21.2637
exploration/Actions Mean            0.026747
exploration/Actions Std             0.207372
exploration/Actions Max             0.994762
exploration/Actions Min            -0.451657
exploration/Num Paths               2
exploration/Average Returns       -19.908
evaluation/num steps total     338000
evaluation/num paths total       3380
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.238133
evaluation/Rewards Std              0.952489
evaluation/Rewards Max             -0.0150235
evaluation/Rewards Min             -9.46487
evaluation/Returns Mean           -23.8133
evaluation/Returns Std             15.4985
evaluation/Returns Max             -8.06715
evaluation/Returns Min            -53.3478
evaluation/Actions Mean             0.0197788
evaluation/Actions Std              0.184328
evaluation/Actions Max              0.995452
evaluation/Actions Min             -0.990708
evaluation/Num Paths               10
evaluation/Average Returns        -23.8133
time/data storing (s)               0.00122744
time/evaluation sampling (s)        0.256481
time/exploration sampling (s)       0.0685347
time/logging (s)                    0.00347607
time/saving (s)                     0.00254175
time/training (s)                   1.10844
time/epoch (s)                      1.4407
time/total (s)                    487.438
Epoch                             337
-----------------------------  ---------------
2019-04-21 12:24:34.205933 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 338 finished
-----------------------------  ---------------
replay_buffer/size              68000
trainer/QF1 Loss                    0.376949
trainer/QF2 Loss                    0.375445
trainer/Policy Loss                 9.33242
trainer/Q1 Predictions Mean        -7.40204
trainer/Q1 Predictions Std          6.16568
trainer/Q1 Predictions Max         -6.10941
trainer/Q1 Predictions Min        -62.184
trainer/Q2 Predictions Mean        -7.36868
trainer/Q2 Predictions Std          6.15036
trainer/Q2 Predictions Max         -6.08025
trainer/Q2 Predictions Min        -62.068
trainer/Q Targets Mean             -7.31283
trainer/Q Targets Std               6.23617
trainer/Q Targets Max              -0.193792
trainer/Q Targets Min             -62.4483
trainer/Log Pis Mean                2.0851
trainer/Log Pis Std                 1.31457
trainer/Log Pis Max                 7.44589
trainer/Log Pis Min                -2.70903
trainer/Policy mu Mean              0.120338
trainer/Policy mu Std               0.679409
trainer/Policy mu Max               3.27505
trainer/Policy mu Min              -3.83173
trainer/Policy log std Mean        -2.16122
trainer/Policy log std Std          0.46899
trainer/Policy log std Max         -0.423745
trainer/Policy log std Min         -2.47606
trainer/Alpha                       0.0540194
trainer/Alpha Loss                  0.248368
exploration/num steps total     68000
exploration/num paths total       680
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.206891
exploration/Rewards Std             0.522823
exploration/Rewards Max            -0.024714
exploration/Rewards Min            -4.95374
exploration/Returns Mean          -20.6891
exploration/Returns Std             2.32646
exploration/Returns Max           -18.3627
exploration/Returns Min           -23.0156
exploration/Actions Mean            0.0282312
exploration/Actions Std             0.212769
exploration/Actions Max             0.997923
exploration/Actions Min            -0.598014
exploration/Num Paths               2
exploration/Average Returns       -20.6891
evaluation/num steps total     339000
evaluation/num paths total       3390
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.149012
evaluation/Rewards Std              0.719998
evaluation/Rewards Max             -0.00347509
evaluation/Rewards Min             -7.11221
evaluation/Returns Mean           -14.9012
evaluation/Returns Std              7.49739
evaluation/Returns Max             -2.23057
evaluation/Returns Min            -28.1151
evaluation/Actions Mean             0.0123783
evaluation/Actions Std              0.183017
evaluation/Actions Max              0.994452
evaluation/Actions Min             -0.995883
evaluation/Num Paths               10
evaluation/Average Returns        -14.9012
time/data storing (s)               0.0011871
time/evaluation sampling (s)        0.253018
time/exploration sampling (s)       0.0648169
time/logging (s)                    0.00357946
time/saving (s)                     0.00238591
time/training (s)                   1.00153
time/epoch (s)                      1.32651
time/total (s)                    488.769
Epoch                             338
-----------------------------  ---------------
2019-04-21 12:24:35.528074 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 339 finished
-----------------------------  ---------------
replay_buffer/size              68200
trainer/QF1 Loss                    0.363558
trainer/QF2 Loss                    0.364409
trainer/Policy Loss                 9.557
trainer/Q1 Predictions Mean        -7.48643
trainer/Q1 Predictions Std          6.18008
trainer/Q1 Predictions Max         -6.00057
trainer/Q1 Predictions Min        -48.6261
trainer/Q2 Predictions Mean        -7.46631
trainer/Q2 Predictions Std          6.17963
trainer/Q2 Predictions Max         -5.9893
trainer/Q2 Predictions Min        -48.5465
trainer/Q Targets Mean             -7.48818
trainer/Q Targets Std               6.19915
trainer/Q Targets Max              -0.0819682
trainer/Q Targets Min             -48.4458
trainer/Log Pis Mean                2.25979
trainer/Log Pis Std                 1.1699
trainer/Log Pis Max                 7.55421
trainer/Log Pis Min                -0.652867
trainer/Policy mu Mean              0.0412672
trainer/Policy mu Std               0.605559
trainer/Policy mu Max               3.10657
trainer/Policy mu Min              -2.06692
trainer/Policy log std Mean        -2.26726
trainer/Policy log std Std          0.397709
trainer/Policy log std Max         -0.761576
trainer/Policy log std Min         -2.50382
trainer/Alpha                       0.0540988
trainer/Alpha Loss                  0.757886
exploration/num steps total     68200
exploration/num paths total       682
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.17914
exploration/Rewards Std             0.376699
exploration/Rewards Max            -0.0187028
exploration/Rewards Min            -3.93126
exploration/Returns Mean          -17.914
exploration/Returns Std             4.03852
exploration/Returns Max           -13.8755
exploration/Returns Min           -21.9526
exploration/Actions Mean            0.00129544
exploration/Actions Std             0.186698
exploration/Actions Max             0.983739
exploration/Actions Min            -0.995636
exploration/Num Paths               2
exploration/Average Returns       -17.914
evaluation/num steps total     340000
evaluation/num paths total       3400
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.237102
evaluation/Rewards Std              0.956226
evaluation/Rewards Max             -0.0393369
evaluation/Rewards Min             -9.14951
evaluation/Returns Mean           -23.7102
evaluation/Returns Std             15.2217
evaluation/Returns Max             -5.67631
evaluation/Returns Min            -51.2882
evaluation/Actions Mean             0.0238323
evaluation/Actions Std              0.182376
evaluation/Actions Max              0.996304
evaluation/Actions Min             -0.99586
evaluation/Num Paths               10
evaluation/Average Returns        -23.7102
time/data storing (s)               0.00113399
time/evaluation sampling (s)        0.2443
time/exploration sampling (s)       0.0615138
time/logging (s)                    0.00345162
time/saving (s)                     0.00231175
time/training (s)                   0.999923
time/epoch (s)                      1.31263
time/total (s)                    490.085
Epoch                             339
-----------------------------  ---------------
2019-04-21 12:24:37.076602 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 340 finished
-----------------------------  ---------------
replay_buffer/size              68400
trainer/QF1 Loss                    0.4135
trainer/QF2 Loss                    0.455839
trainer/Policy Loss                 8.85226
trainer/Q1 Predictions Mean        -7.12487
trainer/Q1 Predictions Std          4.75686
trainer/Q1 Predictions Max         -6.00427
trainer/Q1 Predictions Min        -48.488
trainer/Q2 Predictions Mean        -7.15731
trainer/Q2 Predictions Std          4.7416
trainer/Q2 Predictions Max         -6.02331
trainer/Q2 Predictions Min        -48.2192
trainer/Q Targets Mean             -7.10981
trainer/Q Targets Std               4.69233
trainer/Q Targets Max              -0.0823483
trainer/Q Targets Min             -47.9095
trainer/Log Pis Mean                1.85688
trainer/Log Pis Std                 1.30792
trainer/Log Pis Max                 7.20628
trainer/Log Pis Min                -3.46243
trainer/Policy mu Mean              0.0850403
trainer/Policy mu Std               0.591613
trainer/Policy mu Max               3.15642
trainer/Policy mu Min              -2.21366
trainer/Policy log std Mean        -2.18784
trainer/Policy log std Std          0.385773
trainer/Policy log std Max         -0.656625
trainer/Policy log std Min         -2.37108
trainer/Alpha                       0.0546095
trainer/Alpha Loss                 -0.416141
exploration/num steps total     68400
exploration/num paths total       684
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.382053
exploration/Rewards Std             1.11985
exploration/Rewards Max            -0.00475014
exploration/Rewards Min            -8.80867
exploration/Returns Mean          -38.2053
exploration/Returns Std            10.6518
exploration/Returns Max           -27.5535
exploration/Returns Min           -48.8571
exploration/Actions Mean            0.0252614
exploration/Actions Std             0.258574
exploration/Actions Max             0.997267
exploration/Actions Min            -0.996122
exploration/Num Paths               2
exploration/Average Returns       -38.2053
evaluation/num steps total     341000
evaluation/num paths total       3410
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.24376
evaluation/Rewards Std              0.996006
evaluation/Rewards Max             -0.0384304
evaluation/Rewards Min             -9.93365
evaluation/Returns Mean           -24.376
evaluation/Returns Std             17.5951
evaluation/Returns Max             -6.2761
evaluation/Returns Min            -53.7334
evaluation/Actions Mean             0.0231795
evaluation/Actions Std              0.188081
evaluation/Actions Max              0.997398
evaluation/Actions Min             -0.989307
evaluation/Num Paths               10
evaluation/Average Returns        -24.376
time/data storing (s)               0.00167083
time/evaluation sampling (s)        0.261402
time/exploration sampling (s)       0.0675584
time/logging (s)                    0.00255317
time/saving (s)                     0.00184831
time/training (s)                   1.20377
time/epoch (s)                      1.5388
time/total (s)                    491.629
Epoch                             340
-----------------------------  ---------------
2019-04-21 12:24:38.541364 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 341 finished
-----------------------------  ---------------
replay_buffer/size              68600
trainer/QF1 Loss                    0.00823581
trainer/QF2 Loss                    0.0209343
trainer/Policy Loss                 8.7818
trainer/Q1 Predictions Mean        -6.91226
trainer/Q1 Predictions Std          5.58093
trainer/Q1 Predictions Max         -6.05824
trainer/Q1 Predictions Min        -61.93
trainer/Q2 Predictions Mean        -6.87257
trainer/Q2 Predictions Std          5.54644
trainer/Q2 Predictions Max         -6.01512
trainer/Q2 Predictions Min        -61.4861
trainer/Q Targets Mean             -6.93768
trainer/Q Targets Std               5.63192
trainer/Q Targets Max              -5.99164
trainer/Q Targets Min             -62.4682
trainer/Log Pis Mean                1.91911
trainer/Log Pis Std                 0.998307
trainer/Log Pis Max                 6.04701
trainer/Log Pis Min                -1.84544
trainer/Policy mu Mean              0.0785673
trainer/Policy mu Std               0.54491
trainer/Policy mu Max               3.20818
trainer/Policy mu Min              -1.89707
trainer/Policy log std Mean        -2.13811
trainer/Policy log std Std          0.409912
trainer/Policy log std Max         -0.549354
trainer/Policy log std Min         -2.38622
trainer/Alpha                       0.0538037
trainer/Alpha Loss                 -0.236387
exploration/num steps total     68600
exploration/num paths total       686
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.31628
exploration/Rewards Std             0.866448
exploration/Rewards Max            -0.0206556
exploration/Rewards Min            -6.78612
exploration/Returns Mean          -31.628
exploration/Returns Std             6.9814
exploration/Returns Max           -24.6466
exploration/Returns Min           -38.6093
exploration/Actions Mean            0.00675861
exploration/Actions Std             0.246964
exploration/Actions Max             0.998405
exploration/Actions Min            -0.998558
exploration/Num Paths               2
exploration/Average Returns       -31.628
evaluation/num steps total     342000
evaluation/num paths total       3420
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.176817
evaluation/Rewards Std              0.861307
evaluation/Rewards Max             -0.00995764
evaluation/Rewards Min             -8.64164
evaluation/Returns Mean           -17.6817
evaluation/Returns Std             13.4639
evaluation/Returns Max             -1.71973
evaluation/Returns Min            -43.438
evaluation/Actions Mean             0.0243086
evaluation/Actions Std              0.176695
evaluation/Actions Max              0.995982
evaluation/Actions Min             -0.995354
evaluation/Num Paths               10
evaluation/Average Returns        -17.6817
time/data storing (s)               0.00246348
time/evaluation sampling (s)        0.256417
time/exploration sampling (s)       0.110839
time/logging (s)                    0.00255015
time/saving (s)                     0.00231163
time/training (s)                   1.08208
time/epoch (s)                      1.45667
time/total (s)                    493.089
Epoch                             341
-----------------------------  ---------------
2019-04-21 12:24:39.843016 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 342 finished
-----------------------------  ---------------
replay_buffer/size              68800
trainer/QF1 Loss                    0.367701
trainer/QF2 Loss                    0.366355
trainer/Policy Loss                 8.40983
trainer/Q1 Predictions Mean        -6.44696
trainer/Q1 Predictions Std          1.67613
trainer/Q1 Predictions Max         -6.06081
trainer/Q1 Predictions Min        -22.4182
trainer/Q2 Predictions Mean        -6.42651
trainer/Q2 Predictions Std          1.66486
trainer/Q2 Predictions Max         -6.05873
trainer/Q2 Predictions Min        -22.275
trainer/Q Targets Mean             -6.36818
trainer/Q Targets Std               1.76976
trainer/Q Targets Max              -0.0966028
trainer/Q Targets Min             -22.2117
trainer/Log Pis Mean                2.047
trainer/Log Pis Std                 1.03549
trainer/Log Pis Max                 5.05037
trainer/Log Pis Min                -1.58407
trainer/Policy mu Mean              0.030853
trainer/Policy mu Std               0.396227
trainer/Policy mu Max               2.8125
trainer/Policy mu Min              -2.23775
trainer/Policy log std Mean        -2.33454
trainer/Policy log std Std          0.304099
trainer/Policy log std Max         -0.651983
trainer/Policy log std Min         -2.51509
trainer/Alpha                       0.0527271
trainer/Alpha Loss                  0.1383
exploration/num steps total     68800
exploration/num paths total       688
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.286502
exploration/Rewards Std             0.972554
exploration/Rewards Max            -0.0134624
exploration/Rewards Min            -8.67456
exploration/Returns Mean          -28.6502
exploration/Returns Std            15.9657
exploration/Returns Max           -12.6845
exploration/Returns Min           -44.616
exploration/Actions Mean            0.00747096
exploration/Actions Std             0.229867
exploration/Actions Max             0.998727
exploration/Actions Min            -0.996498
exploration/Num Paths               2
exploration/Average Returns       -28.6502
evaluation/num steps total     343000
evaluation/num paths total       3430
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.260399
evaluation/Rewards Std              1.06819
evaluation/Rewards Max             -0.0152863
evaluation/Rewards Min             -9.71566
evaluation/Returns Mean           -26.0399
evaluation/Returns Std             12.4081
evaluation/Returns Max             -4.19634
evaluation/Returns Min            -49.2797
evaluation/Actions Mean             0.0335412
evaluation/Actions Std              0.214778
evaluation/Actions Max              0.997514
evaluation/Actions Min             -0.996732
evaluation/Num Paths               10
evaluation/Average Returns        -26.0399
time/data storing (s)               0.00118953
time/evaluation sampling (s)        0.243516
time/exploration sampling (s)       0.0621852
time/logging (s)                    0.00342271
time/saving (s)                     0.00235409
time/training (s)                   0.981208
time/epoch (s)                      1.29387
time/total (s)                    494.387
Epoch                             342
-----------------------------  ---------------
2019-04-21 12:24:41.160732 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 343 finished
-----------------------------  ---------------
replay_buffer/size              69000
trainer/QF1 Loss                    0.0384881
trainer/QF2 Loss                    0.036258
trainer/Policy Loss                 8.70297
trainer/Q1 Predictions Mean        -6.82336
trainer/Q1 Predictions Std          4.3419
trainer/Q1 Predictions Max         -6.06758
trainer/Q1 Predictions Min        -47.0785
trainer/Q2 Predictions Mean        -6.81628
trainer/Q2 Predictions Std          4.38895
trainer/Q2 Predictions Max         -6.06572
trainer/Q2 Predictions Min        -47.572
trainer/Q Targets Mean             -6.81435
trainer/Q Targets Std               4.34247
trainer/Q Targets Max              -5.99138
trainer/Q Targets Min             -47.6772
trainer/Log Pis Mean                1.9296
trainer/Log Pis Std                 1.07425
trainer/Log Pis Max                 5.23907
trainer/Log Pis Min                -2.20682
trainer/Policy mu Mean             -0.00528648
trainer/Policy mu Std               0.461328
trainer/Policy mu Max               3.09866
trainer/Policy mu Min              -2.09396
trainer/Policy log std Mean        -2.23418
trainer/Policy log std Std          0.318887
trainer/Policy log std Max         -0.572951
trainer/Policy log std Min         -2.41983
trainer/Alpha                       0.0541608
trainer/Alpha Loss                 -0.205277
exploration/num steps total     69000
exploration/num paths total       690
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.188522
exploration/Rewards Std             0.405887
exploration/Rewards Max            -0.0124434
exploration/Rewards Min            -4.01015
exploration/Returns Mean          -18.8522
exploration/Returns Std             3.26171
exploration/Returns Max           -15.5905
exploration/Returns Min           -22.1139
exploration/Actions Mean            0.0084438
exploration/Actions Std             0.204261
exploration/Actions Max             0.990915
exploration/Actions Min            -0.990347
exploration/Num Paths               2
exploration/Average Returns       -18.8522
evaluation/num steps total     344000
evaluation/num paths total       3440
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.318571
evaluation/Rewards Std              1.27159
evaluation/Rewards Max             -0.0286855
evaluation/Rewards Min            -10.4039
evaluation/Returns Mean           -31.8571
evaluation/Returns Std             21.3001
evaluation/Returns Max             -6.35547
evaluation/Returns Min            -59.0019
evaluation/Actions Mean             0.0316789
evaluation/Actions Std              0.210442
evaluation/Actions Max              0.996369
evaluation/Actions Min             -0.983387
evaluation/Num Paths               10
evaluation/Average Returns        -31.8571
time/data storing (s)               0.0011817
time/evaluation sampling (s)        0.251577
time/exploration sampling (s)       0.0640965
time/logging (s)                    0.00343374
time/saving (s)                     0.00245259
time/training (s)                   0.986406
time/epoch (s)                      1.30915
time/total (s)                    495.701
Epoch                             343
-----------------------------  ---------------
2019-04-21 12:24:42.775479 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 344 finished
-----------------------------  ---------------
replay_buffer/size              69200
trainer/QF1 Loss                    0.369875
trainer/QF2 Loss                    0.370014
trainer/Policy Loss                 8.70905
trainer/Q1 Predictions Mean        -6.94914
trainer/Q1 Predictions Std          4.46864
trainer/Q1 Predictions Max         -5.99746
trainer/Q1 Predictions Min        -44.2374
trainer/Q2 Predictions Mean        -6.93687
trainer/Q2 Predictions Std          4.4252
trainer/Q2 Predictions Max         -5.99988
trainer/Q2 Predictions Min        -43.8524
trainer/Q Targets Mean             -6.92328
trainer/Q Targets Std               4.50509
trainer/Q Targets Max              -0.0545586
trainer/Q Targets Min             -43.7025
trainer/Log Pis Mean                2.057
trainer/Log Pis Std                 1.28174
trainer/Log Pis Max                 5.80018
trainer/Log Pis Min                -3.11477
trainer/Policy mu Mean              0.0924625
trainer/Policy mu Std               0.553315
trainer/Policy mu Max               2.81571
trainer/Policy mu Min              -2.14322
trainer/Policy log std Mean        -2.24768
trainer/Policy log std Std          0.404259
trainer/Policy log std Max         -0.630807
trainer/Policy log std Min         -2.46096
trainer/Alpha                       0.0559385
trainer/Alpha Loss                  0.164353
exploration/num steps total     69200
exploration/num paths total       692
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.202841
exploration/Rewards Std             0.507687
exploration/Rewards Max            -0.0134925
exploration/Rewards Min            -4.42643
exploration/Returns Mean          -20.2841
exploration/Returns Std             1.76631
exploration/Returns Max           -18.5178
exploration/Returns Min           -22.0504
exploration/Actions Mean            0.0163254
exploration/Actions Std             0.201448
exploration/Actions Max             0.997154
exploration/Actions Min            -0.827997
exploration/Num Paths               2
exploration/Average Returns       -20.2841
evaluation/num steps total     345000
evaluation/num paths total       3450
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.243514
evaluation/Rewards Std              1.0353
evaluation/Rewards Max             -0.0138272
evaluation/Rewards Min             -8.92131
evaluation/Returns Mean           -24.3514
evaluation/Returns Std             12.5551
evaluation/Returns Max             -3.73728
evaluation/Returns Min            -44.2492
evaluation/Actions Mean             0.0274962
evaluation/Actions Std              0.20846
evaluation/Actions Max              0.996266
evaluation/Actions Min             -0.993795
evaluation/Num Paths               10
evaluation/Average Returns        -24.3514
time/data storing (s)               0.00243173
time/evaluation sampling (s)        0.287806
time/exploration sampling (s)       0.109931
time/logging (s)                    0.00644212
time/saving (s)                     0.00404149
time/training (s)                   1.19834
time/epoch (s)                      1.609
time/total (s)                    497.314
Epoch                             344
-----------------------------  ---------------
2019-04-21 12:24:44.450951 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 345 finished
-----------------------------  ---------------
replay_buffer/size              69400
trainer/QF1 Loss                    0.0154059
trainer/QF2 Loss                    0.0205213
trainer/Policy Loss                 8.52162
trainer/Q1 Predictions Mean        -6.74295
trainer/Q1 Predictions Std          2.58292
trainer/Q1 Predictions Max         -5.98703
trainer/Q1 Predictions Min        -26.3646
trainer/Q2 Predictions Mean        -6.71218
trainer/Q2 Predictions Std          2.59158
trainer/Q2 Predictions Max         -5.96355
trainer/Q2 Predictions Min        -26.5041
trainer/Q Targets Mean             -6.8186
trainer/Q Targets Std               2.56322
trainer/Q Targets Max              -5.95491
trainer/Q Targets Min             -26.2311
trainer/Log Pis Mean                1.93202
trainer/Log Pis Std                 1.23136
trainer/Log Pis Max                 4.86466
trainer/Log Pis Min                -3.95498
trainer/Policy mu Mean              0.0756083
trainer/Policy mu Std               0.618192
trainer/Policy mu Max               2.85757
trainer/Policy mu Min              -1.8352
trainer/Policy log std Mean        -2.10109
trainer/Policy log std Std          0.452995
trainer/Policy log std Max         -0.54842
trainer/Policy log std Min         -2.35882
trainer/Alpha                       0.0554134
trainer/Alpha Loss                 -0.19667
exploration/num steps total     69400
exploration/num paths total       694
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.278716
exploration/Rewards Std             0.736198
exploration/Rewards Max            -0.0138949
exploration/Rewards Min            -5.73824
exploration/Returns Mean          -27.8716
exploration/Returns Std             4.59319
exploration/Returns Max           -23.2785
exploration/Returns Min           -32.4648
exploration/Actions Mean            0.0190699
exploration/Actions Std             0.235663
exploration/Actions Max             0.997816
exploration/Actions Min            -0.989509
exploration/Num Paths               2
exploration/Average Returns       -27.8716
evaluation/num steps total     346000
evaluation/num paths total       3460
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.234072
evaluation/Rewards Std              0.947532
evaluation/Rewards Max             -0.0360389
evaluation/Rewards Min            -10.3017
evaluation/Returns Mean           -23.4072
evaluation/Returns Std             15.6502
evaluation/Returns Max             -8.32952
evaluation/Returns Min            -55.4961
evaluation/Actions Mean             0.0169952
evaluation/Actions Std              0.191697
evaluation/Actions Max              0.997515
evaluation/Actions Min             -0.993071
evaluation/Num Paths               10
evaluation/Average Returns        -23.4072
time/data storing (s)               0.00114114
time/evaluation sampling (s)        0.279155
time/exploration sampling (s)       0.0701583
time/logging (s)                    0.00361782
time/saving (s)                     0.00244897
time/training (s)                   1.30416
time/epoch (s)                      1.66068
time/total (s)                    498.98
Epoch                             345
-----------------------------  ---------------
2019-04-21 12:24:45.805409 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 346 finished
-----------------------------  ---------------
replay_buffer/size              69600
trainer/QF1 Loss                    0.369063
trainer/QF2 Loss                    0.375605
trainer/Policy Loss                 8.91083
trainer/Q1 Predictions Mean        -7.05441
trainer/Q1 Predictions Std          3.9919
trainer/Q1 Predictions Max         -5.9143
trainer/Q1 Predictions Min        -27.0334
trainer/Q2 Predictions Mean        -7.03659
trainer/Q2 Predictions Std          4.00777
trainer/Q2 Predictions Max         -5.89951
trainer/Q2 Predictions Min        -26.9845
trainer/Q Targets Mean             -7.11421
trainer/Q Targets Std               3.99272
trainer/Q Targets Max              -0.03921
trainer/Q Targets Min             -26.6214
trainer/Log Pis Mean                1.89207
trainer/Log Pis Std                 1.36976
trainer/Log Pis Max                 6.85145
trainer/Log Pis Min                -3.11683
trainer/Policy mu Mean              0.11715
trainer/Policy mu Std               0.588276
trainer/Policy mu Max               3.30132
trainer/Policy mu Min              -0.571928
trainer/Policy log std Mean        -2.18773
trainer/Policy log std Std          0.367428
trainer/Policy log std Max         -0.617208
trainer/Policy log std Min         -2.36571
trainer/Alpha                       0.0549811
trainer/Alpha Loss                 -0.313071
exploration/num steps total     69600
exploration/num paths total       696
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.24624
exploration/Rewards Std             0.686401
exploration/Rewards Max            -0.00500352
exploration/Rewards Min            -6.33877
exploration/Returns Mean          -24.624
exploration/Returns Std             8.29442
exploration/Returns Max           -16.3296
exploration/Returns Min           -32.9184
exploration/Actions Mean            0.0146946
exploration/Actions Std             0.221327
exploration/Actions Max             0.998203
exploration/Actions Min            -0.986446
exploration/Num Paths               2
exploration/Average Returns       -24.624
evaluation/num steps total     347000
evaluation/num paths total       3470
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.275363
evaluation/Rewards Std              1.18232
evaluation/Rewards Max             -0.0274945
evaluation/Rewards Min            -10.9298
evaluation/Returns Mean           -27.5363
evaluation/Returns Std             19.4501
evaluation/Returns Max             -9.72737
evaluation/Returns Min            -60.3399
evaluation/Actions Mean             0.0404776
evaluation/Actions Std              0.204718
evaluation/Actions Max              0.996841
evaluation/Actions Min             -0.988819
evaluation/Num Paths               10
evaluation/Average Returns        -27.5363
time/data storing (s)               0.00106454
time/evaluation sampling (s)        0.26235
time/exploration sampling (s)       0.0621909
time/logging (s)                    0.00329015
time/saving (s)                     0.00235571
time/training (s)                   1.01376
time/epoch (s)                      1.34501
time/total (s)                    500.329
Epoch                             346
-----------------------------  ---------------
2019-04-21 12:24:47.131650 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 347 finished
-----------------------------  ---------------
replay_buffer/size              69800
trainer/QF1 Loss                    0.609896
trainer/QF2 Loss                    0.482254
trainer/Policy Loss                 8.73372
trainer/Q1 Predictions Mean        -6.94115
trainer/Q1 Predictions Std          3.24366
trainer/Q1 Predictions Max         -6.0602
trainer/Q1 Predictions Min        -25.5493
trainer/Q2 Predictions Mean        -6.91605
trainer/Q2 Predictions Std          3.32478
trainer/Q2 Predictions Max         -6.00659
trainer/Q2 Predictions Min        -25.4553
trainer/Q Targets Mean             -6.93599
trainer/Q Targets Std               3.62082
trainer/Q Targets Max              -0.107316
trainer/Q Targets Min             -27.811
trainer/Log Pis Mean                2.01647
trainer/Log Pis Std                 1.15304
trainer/Log Pis Max                 5.13183
trainer/Log Pis Min                -2.16273
trainer/Policy mu Mean              0.0619828
trainer/Policy mu Std               0.591631
trainer/Policy mu Max               3.00126
trainer/Policy mu Min              -3.51527
trainer/Policy log std Mean        -2.21885
trainer/Policy log std Std          0.408489
trainer/Policy log std Max         -0.339557
trainer/Policy log std Min         -2.39539
trainer/Alpha                       0.0539204
trainer/Alpha Loss                  0.0480905
exploration/num steps total     69800
exploration/num paths total       698
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.207929
exploration/Rewards Std             0.575632
exploration/Rewards Max            -0.00960941
exploration/Rewards Min            -5.73594
exploration/Returns Mean          -20.7929
exploration/Returns Std             7.91288
exploration/Returns Max           -12.8801
exploration/Returns Min           -28.7058
exploration/Actions Mean            0.0146909
exploration/Actions Std             0.21438
exploration/Actions Max             0.994491
exploration/Actions Min            -0.971611
exploration/Num Paths               2
exploration/Average Returns       -20.7929
evaluation/num steps total     348000
evaluation/num paths total       3480
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.181014
evaluation/Rewards Std              0.839126
evaluation/Rewards Max             -0.018932
evaluation/Rewards Min             -7.99916
evaluation/Returns Mean           -18.1014
evaluation/Returns Std             10.3019
evaluation/Returns Max             -4.06179
evaluation/Returns Min            -38.1689
evaluation/Actions Mean             0.0250196
evaluation/Actions Std              0.187256
evaluation/Actions Max              0.99408
evaluation/Actions Min             -0.992884
evaluation/Num Paths               10
evaluation/Average Returns        -18.1014
time/data storing (s)               0.00118642
time/evaluation sampling (s)        0.247624
time/exploration sampling (s)       0.0643555
time/logging (s)                    0.00359812
time/saving (s)                     0.00232757
time/training (s)                   0.997579
time/epoch (s)                      1.31667
time/total (s)                    501.65
Epoch                             347
-----------------------------  ---------------
2019-04-21 12:24:48.446071 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 348 finished
-----------------------------  ---------------
replay_buffer/size              70000
trainer/QF1 Loss                    0.719889
trainer/QF2 Loss                    0.723032
trainer/Policy Loss                 9.31448
trainer/Q1 Predictions Mean        -7.48137
trainer/Q1 Predictions Std          6.6442
trainer/Q1 Predictions Max         -5.98686
trainer/Q1 Predictions Min        -47.2709
trainer/Q2 Predictions Mean        -7.49023
trainer/Q2 Predictions Std          6.66962
trainer/Q2 Predictions Max         -5.98696
trainer/Q2 Predictions Min        -47.2574
trainer/Q Targets Mean             -7.40906
trainer/Q Targets Std               6.65563
trainer/Q Targets Max              -0.0565341
trainer/Q Targets Min             -46.8591
trainer/Log Pis Mean                1.97284
trainer/Log Pis Std                 1.25222
trainer/Log Pis Max                 7.3881
trainer/Log Pis Min                -2.6295
trainer/Policy mu Mean              0.0652016
trainer/Policy mu Std               0.482734
trainer/Policy mu Max               3.02201
trainer/Policy mu Min              -1.10993
trainer/Policy log std Mean        -2.25146
trainer/Policy log std Std          0.326692
trainer/Policy log std Max         -0.672497
trainer/Policy log std Min         -2.44072
trainer/Alpha                       0.0542569
trainer/Alpha Loss                 -0.0791571
exploration/num steps total     70000
exploration/num paths total       700
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.24061
exploration/Rewards Std             0.670822
exploration/Rewards Max            -0.00953415
exploration/Rewards Min            -6.03076
exploration/Returns Mean          -24.061
exploration/Returns Std             6.92765
exploration/Returns Max           -17.1333
exploration/Returns Min           -30.9886
exploration/Actions Mean            0.0185701
exploration/Actions Std             0.208726
exploration/Actions Max             0.996366
exploration/Actions Min            -0.624025
exploration/Num Paths               2
exploration/Average Returns       -24.061
evaluation/num steps total     349000
evaluation/num paths total       3490
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.142458
evaluation/Rewards Std              0.721821
evaluation/Rewards Max             -0.00907996
evaluation/Rewards Min             -7.93947
evaluation/Returns Mean           -14.2458
evaluation/Returns Std             10.7
evaluation/Returns Max             -2.26781
evaluation/Returns Min            -37.6332
evaluation/Actions Mean             0.0208116
evaluation/Actions Std              0.173655
evaluation/Actions Max              0.994897
evaluation/Actions Min             -0.987891
evaluation/Num Paths               10
evaluation/Average Returns        -14.2458
time/data storing (s)               0.00124124
time/evaluation sampling (s)        0.254152
time/exploration sampling (s)       0.065454
time/logging (s)                    0.00351288
time/saving (s)                     0.00231537
time/training (s)                   0.978081
time/epoch (s)                      1.30476
time/total (s)                    502.96
Epoch                             348
-----------------------------  ---------------
2019-04-21 12:24:49.766897 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 349 finished
-----------------------------  ---------------
replay_buffer/size              70200
trainer/QF1 Loss                    0.0552804
trainer/QF2 Loss                    0.0418817
trainer/Policy Loss                 9.31706
trainer/Q1 Predictions Mean        -7.35154
trainer/Q1 Predictions Std          5.43795
trainer/Q1 Predictions Max         -5.84586
trainer/Q1 Predictions Min        -43.7217
trainer/Q2 Predictions Mean        -7.39819
trainer/Q2 Predictions Std          5.47701
trainer/Q2 Predictions Max         -5.89887
trainer/Q2 Predictions Min        -43.8579
trainer/Q Targets Mean             -7.55946
trainer/Q Targets Std               5.41869
trainer/Q Targets Max              -6.00245
trainer/Q Targets Min             -43.5119
trainer/Log Pis Mean                2.07461
trainer/Log Pis Std                 1.12654
trainer/Log Pis Max                 6.16394
trainer/Log Pis Min                -1.07706
trainer/Policy mu Mean              0.11051
trainer/Policy mu Std               0.682451
trainer/Policy mu Max               3.15034
trainer/Policy mu Min              -2.99289
trainer/Policy log std Mean        -2.14646
trainer/Policy log std Std          0.454638
trainer/Policy log std Max         -0.526621
trainer/Policy log std Min         -2.39824
trainer/Alpha                       0.054443
trainer/Alpha Loss                  0.217147
exploration/num steps total     70200
exploration/num paths total       702
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.414637
exploration/Rewards Std             1.39466
exploration/Rewards Max            -0.0099968
exploration/Rewards Min           -10.5863
exploration/Returns Mean          -41.4637
exploration/Returns Std            26.4489
exploration/Returns Max           -15.0149
exploration/Returns Min           -67.9126
exploration/Actions Mean            0.0133375
exploration/Actions Std             0.245769
exploration/Actions Max             0.99881
exploration/Actions Min            -0.97355
exploration/Num Paths               2
exploration/Average Returns       -41.4637
evaluation/num steps total     350000
evaluation/num paths total       3500
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.270904
evaluation/Rewards Std              1.16219
evaluation/Rewards Max             -0.0251692
evaluation/Rewards Min            -11.087
evaluation/Returns Mean           -27.0904
evaluation/Returns Std             19.7501
evaluation/Returns Max             -6.63395
evaluation/Returns Min            -62.3702
evaluation/Actions Mean             0.0292133
evaluation/Actions Std              0.200127
evaluation/Actions Max              0.998066
evaluation/Actions Min             -0.987444
evaluation/Num Paths               10
evaluation/Average Returns        -27.0904
time/data storing (s)               0.00131032
time/evaluation sampling (s)        0.251725
time/exploration sampling (s)       0.063673
time/logging (s)                    0.0034885
time/saving (s)                     0.00265448
time/training (s)                   0.988414
time/epoch (s)                      1.31127
time/total (s)                    504.275
Epoch                             349
-----------------------------  ---------------
2019-04-21 12:24:51.148602 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 350 finished
-----------------------------  ---------------
replay_buffer/size              70400
trainer/QF1 Loss                    1.08743
trainer/QF2 Loss                    1.07577
trainer/Policy Loss                 8.84661
trainer/Q1 Predictions Mean        -7.06349
trainer/Q1 Predictions Std          4.22018
trainer/Q1 Predictions Max         -5.98906
trainer/Q1 Predictions Min        -35.3779
trainer/Q2 Predictions Mean        -7.03717
trainer/Q2 Predictions Std          4.28884
trainer/Q2 Predictions Max         -5.96675
trainer/Q2 Predictions Min        -35.4474
trainer/Q Targets Mean             -6.95712
trainer/Q Targets Std               4.42797
trainer/Q Targets Max              -0.0841152
trainer/Q Targets Min             -35.4723
trainer/Log Pis Mean                1.91789
trainer/Log Pis Std                 1.35865
trainer/Log Pis Max                 7.26914
trainer/Log Pis Min                -2.03739
trainer/Policy mu Mean              0.139603
trainer/Policy mu Std               0.637043
trainer/Policy mu Max               2.88794
trainer/Policy mu Min              -2.62734
trainer/Policy log std Mean        -2.15297
trainer/Policy log std Std          0.459366
trainer/Policy log std Max         -0.544244
trainer/Policy log std Min         -2.42276
trainer/Alpha                       0.0528038
trainer/Alpha Loss                 -0.241518
exploration/num steps total     70400
exploration/num paths total       704
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.297997
exploration/Rewards Std             0.867793
exploration/Rewards Max            -0.0112995
exploration/Rewards Min            -7.16634
exploration/Returns Mean          -29.7997
exploration/Returns Std             8.56293
exploration/Returns Max           -21.2368
exploration/Returns Min           -38.3627
exploration/Actions Mean            0.0405476
exploration/Actions Std             0.235904
exploration/Actions Max             0.998348
exploration/Actions Min            -0.62778
exploration/Num Paths               2
exploration/Average Returns       -29.7997
evaluation/num steps total     351000
evaluation/num paths total       3510
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.189448
evaluation/Rewards Std              0.93057
evaluation/Rewards Max             -0.00420759
evaluation/Rewards Min             -8.76994
evaluation/Returns Mean           -18.9448
evaluation/Returns Std             13.346
evaluation/Returns Max             -1.21499
evaluation/Returns Min            -42.0227
evaluation/Actions Mean             0.0244763
evaluation/Actions Std              0.189894
evaluation/Actions Max              0.995838
evaluation/Actions Min             -0.996744
evaluation/Num Paths               10
evaluation/Average Returns        -18.9448
time/data storing (s)               0.00117726
time/evaluation sampling (s)        0.253069
time/exploration sampling (s)       0.0644517
time/logging (s)                    0.00340822
time/saving (s)                     0.00233351
time/training (s)                   1.0476
time/epoch (s)                      1.37204
time/total (s)                    505.652
Epoch                             350
-----------------------------  ---------------
2019-04-21 12:24:52.541727 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 351 finished
-----------------------------  ---------------
replay_buffer/size              70600
trainer/QF1 Loss                    1.13283
trainer/QF2 Loss                    1.11876
trainer/Policy Loss                 8.68917
trainer/Q1 Predictions Mean        -6.90888
trainer/Q1 Predictions Std          3.18392
trainer/Q1 Predictions Max         -6.05221
trainer/Q1 Predictions Min        -28.769
trainer/Q2 Predictions Mean        -6.90311
trainer/Q2 Predictions Std          3.19944
trainer/Q2 Predictions Max         -6.04471
trainer/Q2 Predictions Min        -28.9934
trainer/Q Targets Mean             -6.71172
trainer/Q Targets Std               3.34347
trainer/Q Targets Max              -0.104387
trainer/Q Targets Min             -29.1223
trainer/Log Pis Mean                1.91196
trainer/Log Pis Std                 1.16714
trainer/Log Pis Max                 5.73116
trainer/Log Pis Min                -1.91319
trainer/Policy mu Mean              0.0667281
trainer/Policy mu Std               0.56888
trainer/Policy mu Max               2.97585
trainer/Policy mu Min              -2.54851
trainer/Policy log std Mean        -2.20224
trainer/Policy log std Std          0.37828
trainer/Policy log std Max         -0.758783
trainer/Policy log std Min         -2.41331
trainer/Alpha                       0.0533618
trainer/Alpha Loss                 -0.257984
exploration/num steps total     70600
exploration/num paths total       706
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.343887
exploration/Rewards Std             0.945621
exploration/Rewards Max            -0.00501679
exploration/Rewards Min            -7.46811
exploration/Returns Mean          -34.3887
exploration/Returns Std             6.56303
exploration/Returns Max           -27.8257
exploration/Returns Min           -40.9517
exploration/Actions Mean            0.0473985
exploration/Actions Std             0.247216
exploration/Actions Max             0.996601
exploration/Actions Min            -0.441244
exploration/Num Paths               2
exploration/Average Returns       -34.3887
evaluation/num steps total     352000
evaluation/num paths total       3520
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.243284
evaluation/Rewards Std              0.929556
evaluation/Rewards Max             -0.044584
evaluation/Rewards Min             -8.16418
evaluation/Returns Mean           -24.3284
evaluation/Returns Std             10.4356
evaluation/Returns Max            -10.2897
evaluation/Returns Min            -42.0729
evaluation/Actions Mean             0.0246695
evaluation/Actions Std              0.199118
evaluation/Actions Max              0.996871
evaluation/Actions Min             -0.992452
evaluation/Num Paths               10
evaluation/Average Returns        -24.3284
time/data storing (s)               0.00120679
time/evaluation sampling (s)        0.262665
time/exploration sampling (s)       0.0680528
time/logging (s)                    0.00347034
time/saving (s)                     0.00232952
time/training (s)                   1.04677
time/epoch (s)                      1.3845
time/total (s)                    507.04
Epoch                             351
-----------------------------  ---------------
2019-04-21 12:24:53.852424 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 352 finished
-----------------------------  ---------------
replay_buffer/size              70800
trainer/QF1 Loss                    0.720091
trainer/QF2 Loss                    0.724465
trainer/Policy Loss                 8.86673
trainer/Q1 Predictions Mean        -6.93401
trainer/Q1 Predictions Std          4.50537
trainer/Q1 Predictions Max         -5.99357
trainer/Q1 Predictions Min        -42.953
trainer/Q2 Predictions Mean        -6.93245
trainer/Q2 Predictions Std          4.52157
trainer/Q2 Predictions Max         -6.00868
trainer/Q2 Predictions Min        -43.1424
trainer/Q Targets Mean             -6.88535
trainer/Q Targets Std               4.59475
trainer/Q Targets Max              -0.0595299
trainer/Q Targets Min             -42.7841
trainer/Log Pis Mean                2.08784
trainer/Log Pis Std                 0.853312
trainer/Log Pis Max                 4.8048
trainer/Log Pis Min                -1.04249
trainer/Policy mu Mean              0.066572
trainer/Policy mu Std               0.457151
trainer/Policy mu Max               2.96233
trainer/Policy mu Min              -1.17966
trainer/Policy log std Mean        -2.23593
trainer/Policy log std Std          0.34178
trainer/Policy log std Max         -0.572946
trainer/Policy log std Min         -2.41248
trainer/Alpha                       0.0540648
trainer/Alpha Loss                  0.256305
exploration/num steps total     70800
exploration/num paths total       708
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.180528
exploration/Rewards Std             0.302197
exploration/Rewards Max            -0.0122025
exploration/Rewards Min            -2.8084
exploration/Returns Mean          -18.0528
exploration/Returns Std             1.04561
exploration/Returns Max           -17.0072
exploration/Returns Min           -19.0984
exploration/Actions Mean            0.00481945
exploration/Actions Std             0.182984
exploration/Actions Max             0.982183
exploration/Actions Min            -0.983446
exploration/Num Paths               2
exploration/Average Returns       -18.0528
evaluation/num steps total     353000
evaluation/num paths total       3530
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.255004
evaluation/Rewards Std              1.09785
evaluation/Rewards Max             -0.0161159
evaluation/Rewards Min             -9.7984
evaluation/Returns Mean           -25.5004
evaluation/Returns Std             21.0443
evaluation/Returns Max             -4.94242
evaluation/Returns Min            -57.2174
evaluation/Actions Mean             0.0303285
evaluation/Actions Std              0.181087
evaluation/Actions Max              0.995803
evaluation/Actions Min             -0.993039
evaluation/Num Paths               10
evaluation/Average Returns        -25.5004
time/data storing (s)               0.00114259
time/evaluation sampling (s)        0.254965
time/exploration sampling (s)       0.0639455
time/logging (s)                    0.00329069
time/saving (s)                     0.0023315
time/training (s)                   0.975217
time/epoch (s)                      1.30089
time/total (s)                    508.345
Epoch                             352
-----------------------------  ---------------
2019-04-21 12:24:55.446702 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 353 finished
-----------------------------  ---------------
replay_buffer/size              71000
trainer/QF1 Loss                    0.00842837
trainer/QF2 Loss                    0.00660602
trainer/Policy Loss                 8.38801
trainer/Q1 Predictions Mean        -6.52947
trainer/Q1 Predictions Std          2.54535
trainer/Q1 Predictions Max         -5.99839
trainer/Q1 Predictions Min        -26.4286
trainer/Q2 Predictions Mean        -6.55295
trainer/Q2 Predictions Std          2.53018
trainer/Q2 Predictions Max         -6.01971
trainer/Q2 Predictions Min        -26.2165
trainer/Q Targets Mean             -6.58692
trainer/Q Targets Std               2.50732
trainer/Q Targets Max              -6.00678
trainer/Q Targets Min             -26.1705
trainer/Log Pis Mean                1.88329
trainer/Log Pis Std                 1.28327
trainer/Log Pis Max                 7.80522
trainer/Log Pis Min                -2.3544
trainer/Policy mu Mean              0.0348426
trainer/Policy mu Std               0.43525
trainer/Policy mu Max               2.95131
trainer/Policy mu Min              -3.11589
trainer/Policy log std Mean        -2.27327
trainer/Policy log std Std          0.288932
trainer/Policy log std Max         -0.541729
trainer/Policy log std Min         -2.42451
trainer/Alpha                       0.0536533
trainer/Alpha Loss                 -0.341387
exploration/num steps total     71000
exploration/num paths total       710
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.267281
exploration/Rewards Std             0.783892
exploration/Rewards Max            -0.00373979
exploration/Rewards Min            -6.0109
exploration/Returns Mean          -26.7281
exploration/Returns Std             1.18571
exploration/Returns Max           -25.5424
exploration/Returns Min           -27.9138
exploration/Actions Mean            0.0504664
exploration/Actions Std             0.240174
exploration/Actions Max             0.999132
exploration/Actions Min            -0.377591
exploration/Num Paths               2
exploration/Average Returns       -26.7281
evaluation/num steps total     354000
evaluation/num paths total       3540
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.225513
evaluation/Rewards Std              1.04117
evaluation/Rewards Max             -0.00797481
evaluation/Rewards Min             -9.90169
evaluation/Returns Mean           -22.5513
evaluation/Returns Std             14.4469
evaluation/Returns Max             -5.34582
evaluation/Returns Min            -47.0115
evaluation/Actions Mean             0.0207967
evaluation/Actions Std              0.201935
evaluation/Actions Max              0.997308
evaluation/Actions Min             -0.997486
evaluation/Num Paths               10
evaluation/Average Returns        -22.5513
time/data storing (s)               0.00119639
time/evaluation sampling (s)        0.243672
time/exploration sampling (s)       0.0626113
time/logging (s)                    0.0036033
time/saving (s)                     0.00298215
time/training (s)                   1.27215
time/epoch (s)                      1.58622
time/total (s)                    509.935
Epoch                             353
-----------------------------  ---------------
2019-04-21 12:24:56.966812 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 354 finished
-----------------------------  ---------------
replay_buffer/size              71200
trainer/QF1 Loss                    0.0119162
trainer/QF2 Loss                    0.0151981
trainer/Policy Loss                 9.52233
trainer/Q1 Predictions Mean        -7.54234
trainer/Q1 Predictions Std          6.25825
trainer/Q1 Predictions Max         -6.04143
trainer/Q1 Predictions Min        -56.6125
trainer/Q2 Predictions Mean        -7.55234
trainer/Q2 Predictions Std          6.21709
trainer/Q2 Predictions Max         -6.04902
trainer/Q2 Predictions Min        -56.1484
trainer/Q Targets Mean             -7.56373
trainer/Q Targets Std               6.26385
trainer/Q Targets Max              -5.9758
trainer/Q Targets Min             -56.6248
trainer/Log Pis Mean                2.07955
trainer/Log Pis Std                 1.2193
trainer/Log Pis Max                 5.55013
trainer/Log Pis Min                -2.81975
trainer/Policy mu Mean              0.172757
trainer/Policy mu Std               0.651464
trainer/Policy mu Max               3.16134
trainer/Policy mu Min              -1.45201
trainer/Policy log std Mean        -2.19289
trainer/Policy log std Std          0.470406
trainer/Policy log std Max         -0.571889
trainer/Policy log std Min         -2.46384
trainer/Alpha                       0.0533922
trainer/Alpha Loss                  0.233104
exploration/num steps total     71200
exploration/num paths total       712
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.372573
exploration/Rewards Std             1.17493
exploration/Rewards Max            -0.0158693
exploration/Rewards Min            -9.38286
exploration/Returns Mean          -37.2573
exploration/Returns Std            18.67
exploration/Returns Max           -18.5873
exploration/Returns Min           -55.9274
exploration/Actions Mean            0.0246581
exploration/Actions Std             0.242957
exploration/Actions Max             0.999432
exploration/Actions Min            -0.977385
exploration/Num Paths               2
exploration/Average Returns       -37.2573
evaluation/num steps total     355000
evaluation/num paths total       3550
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.221237
evaluation/Rewards Std              0.955684
evaluation/Rewards Max             -0.00839462
evaluation/Rewards Min             -9.71604
evaluation/Returns Mean           -22.1237
evaluation/Returns Std             16.5603
evaluation/Returns Max             -8.08359
evaluation/Returns Min            -56.2538
evaluation/Actions Mean             0.0225208
evaluation/Actions Std              0.194127
evaluation/Actions Max              0.997532
evaluation/Actions Min             -0.994171
evaluation/Num Paths               10
evaluation/Average Returns        -22.1237
time/data storing (s)               0.00140734
time/evaluation sampling (s)        0.274845
time/exploration sampling (s)       0.0882281
time/logging (s)                    0.00388404
time/saving (s)                     0.00268848
time/training (s)                   1.13957
time/epoch (s)                      1.51062
time/total (s)                    511.451
Epoch                             354
-----------------------------  ---------------
2019-04-21 12:24:58.563597 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 355 finished
-----------------------------  ---------------
replay_buffer/size              71400
trainer/QF1 Loss                    0.0393683
trainer/QF2 Loss                    0.0410002
trainer/Policy Loss                 8.79394
trainer/Q1 Predictions Mean        -6.93828
trainer/Q1 Predictions Std          5.48266
trainer/Q1 Predictions Max         -5.88508
trainer/Q1 Predictions Min        -58.4383
trainer/Q2 Predictions Mean        -6.94357
trainer/Q2 Predictions Std          5.46505
trainer/Q2 Predictions Max         -5.88079
trainer/Q2 Predictions Min        -58.1807
trainer/Q Targets Mean             -7.10643
trainer/Q Targets Std               5.47411
trainer/Q Targets Max              -5.94717
trainer/Q Targets Min             -58.4705
trainer/Log Pis Mean                1.90105
trainer/Log Pis Std                 1.48542
trainer/Log Pis Max                 9.63881
trainer/Log Pis Min                -2.58452
trainer/Policy mu Mean              0.0505377
trainer/Policy mu Std               0.601498
trainer/Policy mu Max               3.4293
trainer/Policy mu Min              -2.3272
trainer/Policy log std Mean        -2.1797
trainer/Policy log std Std          0.40721
trainer/Policy log std Max         -0.608083
trainer/Policy log std Min         -2.41787
trainer/Alpha                       0.0559507
trainer/Alpha Loss                 -0.2853
exploration/num steps total     71400
exploration/num paths total       714
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.175924
exploration/Rewards Std             0.323348
exploration/Rewards Max            -0.0084379
exploration/Rewards Min            -3.44795
exploration/Returns Mean          -17.5924
exploration/Returns Std             4.31644
exploration/Returns Max           -13.276
exploration/Returns Min           -21.9089
exploration/Actions Mean           -0.0147938
exploration/Actions Std             0.192815
exploration/Actions Max             0.901475
exploration/Actions Min            -0.992524
exploration/Num Paths               2
exploration/Average Returns       -17.5924
evaluation/num steps total     356000
evaluation/num paths total       3560
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.3008
evaluation/Rewards Std              1.15772
evaluation/Rewards Max             -0.00222214
evaluation/Rewards Min             -9.95442
evaluation/Returns Mean           -30.08
evaluation/Returns Std             13.6186
evaluation/Returns Max            -11.4441
evaluation/Returns Min            -52.7593
evaluation/Actions Mean             0.0302317
evaluation/Actions Std              0.2183
evaluation/Actions Max              0.997543
evaluation/Actions Min             -0.992415
evaluation/Num Paths               10
evaluation/Average Returns        -30.08
time/data storing (s)               0.00129445
time/evaluation sampling (s)        0.270335
time/exploration sampling (s)       0.0765894
time/logging (s)                    0.00333601
time/saving (s)                     0.00210183
time/training (s)                   1.23113
time/epoch (s)                      1.58479
time/total (s)                    513.04
Epoch                             355
-----------------------------  ---------------
2019-04-21 12:25:00.128718 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 356 finished
-----------------------------  ---------------
replay_buffer/size              71600
trainer/QF1 Loss                    0.384844
trainer/QF2 Loss                    0.379556
trainer/Policy Loss                 8.78686
trainer/Q1 Predictions Mean        -6.7591
trainer/Q1 Predictions Std          3.16745
trainer/Q1 Predictions Max         -6.09306
trainer/Q1 Predictions Min        -31.4983
trainer/Q2 Predictions Mean        -6.72278
trainer/Q2 Predictions Std          3.15483
trainer/Q2 Predictions Max         -6.05372
trainer/Q2 Predictions Min        -31.3883
trainer/Q Targets Mean             -6.64486
trainer/Q Targets Std               3.2778
trainer/Q Targets Max              -0.0291897
trainer/Q Targets Min             -31.2971
trainer/Log Pis Mean                2.1886
trainer/Log Pis Std                 0.894422
trainer/Log Pis Max                 6.33933
trainer/Log Pis Min                -0.483277
trainer/Policy mu Mean              0.0207612
trainer/Policy mu Std               0.476131
trainer/Policy mu Max               2.94212
trainer/Policy mu Min              -1.46338
trainer/Policy log std Mean        -2.23894
trainer/Policy log std Std          0.354541
trainer/Policy log std Max         -0.529896
trainer/Policy log std Min         -2.41696
trainer/Alpha                       0.0570532
trainer/Alpha Loss                  0.540124
exploration/num steps total     71600
exploration/num paths total       716
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.278141
exploration/Rewards Std             0.776847
exploration/Rewards Max            -0.0059294
exploration/Rewards Min            -5.98213
exploration/Returns Mean          -27.8141
exploration/Returns Std             3.80145
exploration/Returns Max           -24.0127
exploration/Returns Min           -31.6156
exploration/Actions Mean            0.0184081
exploration/Actions Std             0.229727
exploration/Actions Max             0.997932
exploration/Actions Min            -0.998325
exploration/Num Paths               2
exploration/Average Returns       -27.8141
evaluation/num steps total     357000
evaluation/num paths total       3570
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.217299
evaluation/Rewards Std              0.916255
evaluation/Rewards Max             -0.0192561
evaluation/Rewards Min             -9.42845
evaluation/Returns Mean           -21.7299
evaluation/Returns Std             12.8255
evaluation/Returns Max             -5.23797
evaluation/Returns Min            -52.8127
evaluation/Actions Mean             0.0289379
evaluation/Actions Std              0.187296
evaluation/Actions Max              0.996109
evaluation/Actions Min             -0.980699
evaluation/Num Paths               10
evaluation/Average Returns        -21.7299
time/data storing (s)               0.0011767
time/evaluation sampling (s)        0.279121
time/exploration sampling (s)       0.0655202
time/logging (s)                    0.00317077
time/saving (s)                     0.00238135
time/training (s)                   1.20365
time/epoch (s)                      1.55502
time/total (s)                    514.6
Epoch                             356
-----------------------------  ---------------
2019-04-21 12:25:01.539493 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 357 finished
-----------------------------  ---------------
replay_buffer/size              71800
trainer/QF1 Loss                    0.378908
trainer/QF2 Loss                    0.379473
trainer/Policy Loss                 8.61132
trainer/Q1 Predictions Mean        -7.01852
trainer/Q1 Predictions Std          4.14032
trainer/Q1 Predictions Max         -6.04806
trainer/Q1 Predictions Min        -37.8683
trainer/Q2 Predictions Mean        -7.00713
trainer/Q2 Predictions Std          4.16373
trainer/Q2 Predictions Max         -6.00414
trainer/Q2 Predictions Min        -37.9258
trainer/Q Targets Mean             -6.93325
trainer/Q Targets Std               4.23601
trainer/Q Targets Max              -0.170201
trainer/Q Targets Min             -38.5381
trainer/Log Pis Mean                1.73891
trainer/Log Pis Std                 1.26502
trainer/Log Pis Max                 5.16336
trainer/Log Pis Min                -2.99489
trainer/Policy mu Mean              0.0386627
trainer/Policy mu Std               0.526422
trainer/Policy mu Max               3.04954
trainer/Policy mu Min              -1.51665
trainer/Policy log std Mean        -2.25468
trainer/Policy log std Std          0.377666
trainer/Policy log std Max         -0.501056
trainer/Policy log std Min         -2.46889
trainer/Alpha                       0.0574105
trainer/Alpha Loss                 -0.746083
exploration/num steps total     71800
exploration/num paths total       718
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.172481
exploration/Rewards Std             0.352973
exploration/Rewards Max            -0.00767358
exploration/Rewards Min            -3.02963
exploration/Returns Mean          -17.2481
exploration/Returns Std             0.24066
exploration/Returns Max           -17.0074
exploration/Returns Min           -17.4887
exploration/Actions Mean           -0.00359829
exploration/Actions Std             0.19341
exploration/Actions Max             0.993135
exploration/Actions Min            -0.989952
exploration/Num Paths               2
exploration/Average Returns       -17.2481
evaluation/num steps total     358000
evaluation/num paths total       3580
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.207674
evaluation/Rewards Std              0.849328
evaluation/Rewards Max             -0.0340918
evaluation/Rewards Min             -8.70638
evaluation/Returns Mean           -20.7674
evaluation/Returns Std             11.5014
evaluation/Returns Max             -7.5107
evaluation/Returns Min            -43.3511
evaluation/Actions Mean             0.0271287
evaluation/Actions Std              0.192054
evaluation/Actions Max              0.995275
evaluation/Actions Min             -0.998663
evaluation/Num Paths               10
evaluation/Average Returns        -20.7674
time/data storing (s)               0.00113993
time/evaluation sampling (s)        0.263314
time/exploration sampling (s)       0.0665666
time/logging (s)                    0.0034987
time/saving (s)                     0.00232473
time/training (s)                   1.06404
time/epoch (s)                      1.40089
time/total (s)                    516.006
Epoch                             357
-----------------------------  ---------------
2019-04-21 12:25:02.938515 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 358 finished
-----------------------------  ---------------
replay_buffer/size              72000
trainer/QF1 Loss                    0.00778846
trainer/QF2 Loss                    0.0136023
trainer/Policy Loss                 8.48128
trainer/Q1 Predictions Mean        -6.65278
trainer/Q1 Predictions Std          2.43783
trainer/Q1 Predictions Max         -6.01978
trainer/Q1 Predictions Min        -23.3517
trainer/Q2 Predictions Mean        -6.59071
trainer/Q2 Predictions Std          2.41397
trainer/Q2 Predictions Max         -5.94947
trainer/Q2 Predictions Min        -23.1331
trainer/Q Targets Mean             -6.66672
trainer/Q Targets Std               2.43027
trainer/Q Targets Max              -5.94243
trainer/Q Targets Min             -23.0387
trainer/Log Pis Mean                1.92365
trainer/Log Pis Std                 1.41459
trainer/Log Pis Max                 7.15897
trainer/Log Pis Min                -3.13024
trainer/Policy mu Mean              0.0911479
trainer/Policy mu Std               0.541544
trainer/Policy mu Max               2.79931
trainer/Policy mu Min              -2.12878
trainer/Policy log std Mean        -2.13804
trainer/Policy log std Std          0.40654
trainer/Policy log std Max         -0.461876
trainer/Policy log std Min         -2.37164
trainer/Alpha                       0.0576941
trainer/Alpha Loss                 -0.217786
exploration/num steps total     72000
exploration/num paths total       720
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.181871
exploration/Rewards Std             0.350531
exploration/Rewards Max            -0.00692328
exploration/Rewards Min            -3.12308
exploration/Returns Mean          -18.1871
exploration/Returns Std             0.265901
exploration/Returns Max           -17.9212
exploration/Returns Min           -18.453
exploration/Actions Mean           -0.0149808
exploration/Actions Std             0.205979
exploration/Actions Max             0.830869
exploration/Actions Min            -0.991094
exploration/Num Paths               2
exploration/Average Returns       -18.1871
evaluation/num steps total     359000
evaluation/num paths total       3590
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.308965
evaluation/Rewards Std              1.29105
evaluation/Rewards Max             -0.0113583
evaluation/Rewards Min            -10.2324
evaluation/Returns Mean           -30.8965
evaluation/Returns Std             15.2177
evaluation/Returns Max             -7.54966
evaluation/Returns Min            -49.7997
evaluation/Actions Mean             0.0329106
evaluation/Actions Std              0.226322
evaluation/Actions Max              0.997285
evaluation/Actions Min             -0.993116
evaluation/Num Paths               10
evaluation/Average Returns        -30.8965
time/data storing (s)               0.0013605
time/evaluation sampling (s)        0.267441
time/exploration sampling (s)       0.0677249
time/logging (s)                    0.00352629
time/saving (s)                     0.00246652
time/training (s)                   1.04638
time/epoch (s)                      1.3889
time/total (s)                    517.4
Epoch                             358
-----------------------------  ---------------
2019-04-21 12:25:04.311529 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 359 finished
-----------------------------  ---------------
replay_buffer/size              72200
trainer/QF1 Loss                    1.39878
trainer/QF2 Loss                    1.38957
trainer/Policy Loss                 9.09942
trainer/Q1 Predictions Mean        -7.12447
trainer/Q1 Predictions Std          4.44348
trainer/Q1 Predictions Max         -5.88462
trainer/Q1 Predictions Min        -32.4362
trainer/Q2 Predictions Mean        -7.08713
trainer/Q2 Predictions Std          4.41872
trainer/Q2 Predictions Max         -5.84921
trainer/Q2 Predictions Min        -32.2861
trainer/Q Targets Mean             -6.99005
trainer/Q Targets Std               4.61893
trainer/Q Targets Max              -0.0370817
trainer/Q Targets Min             -32.2552
trainer/Log Pis Mean                2.12046
trainer/Log Pis Std                 1.02827
trainer/Log Pis Max                 5.23238
trainer/Log Pis Min                -1.53838
trainer/Policy mu Mean              0.0267642
trainer/Policy mu Std               0.575696
trainer/Policy mu Max               2.885
trainer/Policy mu Min              -3.04378
trainer/Policy log std Mean        -2.22422
trainer/Policy log std Std          0.422567
trainer/Policy log std Max         -0.524005
trainer/Policy log std Min         -2.43269
trainer/Alpha                       0.0584797
trainer/Alpha Loss                  0.342006
exploration/num steps total     72200
exploration/num paths total       722
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.180309
exploration/Rewards Std             0.489997
exploration/Rewards Max            -0.00344661
exploration/Rewards Min            -4.88524
exploration/Returns Mean          -18.0309
exploration/Returns Std             6.97687
exploration/Returns Max           -11.0541
exploration/Returns Min           -25.0078
exploration/Actions Mean            0.0166533
exploration/Actions Std             0.182567
exploration/Actions Max             0.996358
exploration/Actions Min            -0.622829
exploration/Num Paths               2
exploration/Average Returns       -18.0309
evaluation/num steps total     360000
evaluation/num paths total       3600
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.203113
evaluation/Rewards Std              0.900573
evaluation/Rewards Max             -0.00975892
evaluation/Rewards Min             -9.99236
evaluation/Returns Mean           -20.3113
evaluation/Returns Std             14.4106
evaluation/Returns Max             -4.48068
evaluation/Returns Min            -50.8551
evaluation/Actions Mean             0.01284
evaluation/Actions Std              0.18885
evaluation/Actions Max              0.996313
evaluation/Actions Min             -0.997232
evaluation/Num Paths               10
evaluation/Average Returns        -20.3113
time/data storing (s)               0.00118192
time/evaluation sampling (s)        0.25584
time/exploration sampling (s)       0.0703243
time/logging (s)                    0.00339785
time/saving (s)                     0.00231136
time/training (s)                   1.03026
time/epoch (s)                      1.36331
time/total (s)                    518.767
Epoch                             359
-----------------------------  ---------------
2019-04-21 12:25:05.717364 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 360 finished
-----------------------------  ---------------
replay_buffer/size              72400
trainer/QF1 Loss                    0.720001
trainer/QF2 Loss                    0.719857
trainer/Policy Loss                 8.28627
trainer/Q1 Predictions Mean        -6.43957
trainer/Q1 Predictions Std          2.38506
trainer/Q1 Predictions Max         -5.91551
trainer/Q1 Predictions Min        -23.3551
trainer/Q2 Predictions Mean        -6.45786
trainer/Q2 Predictions Std          2.34747
trainer/Q2 Predictions Max         -5.94367
trainer/Q2 Predictions Min        -23.1306
trainer/Q Targets Mean             -6.40409
trainer/Q Targets Std               2.49798
trainer/Q Targets Max              -0.178427
trainer/Q Targets Min             -23.1058
trainer/Log Pis Mean                1.88865
trainer/Log Pis Std                 0.90893
trainer/Log Pis Max                 6.35313
trainer/Log Pis Min                -0.893922
trainer/Policy mu Mean              0.0357597
trainer/Policy mu Std               0.382711
trainer/Policy mu Max               2.71328
trainer/Policy mu Min              -1.61688
trainer/Policy log std Mean        -2.24745
trainer/Policy log std Std          0.297015
trainer/Policy log std Max         -0.681158
trainer/Policy log std Min         -2.40627
trainer/Alpha                       0.0598507
trainer/Alpha Loss                 -0.313558
exploration/num steps total     72400
exploration/num paths total       724
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.136874
exploration/Rewards Std             0.101846
exploration/Rewards Max            -0.00343851
exploration/Rewards Min            -1.20862
exploration/Returns Mean          -13.6874
exploration/Returns Std             0.60613
exploration/Returns Max           -13.0813
exploration/Returns Min           -14.2936
exploration/Actions Mean            0.0123336
exploration/Actions Std             0.164969
exploration/Actions Max             0.931217
exploration/Actions Min            -0.340384
exploration/Num Paths               2
exploration/Average Returns       -13.6874
evaluation/num steps total     361000
evaluation/num paths total       3610
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.19642
evaluation/Rewards Std              0.982612
evaluation/Rewards Max             -0.0060322
evaluation/Rewards Min             -9.90369
evaluation/Returns Mean           -19.642
evaluation/Returns Std             17.6117
evaluation/Returns Max             -4.32958
evaluation/Returns Min            -50.5609
evaluation/Actions Mean             0.0207691
evaluation/Actions Std              0.181763
evaluation/Actions Max              0.996352
evaluation/Actions Min             -0.986266
evaluation/Num Paths               10
evaluation/Average Returns        -19.642
time/data storing (s)               0.0011554
time/evaluation sampling (s)        0.265761
time/exploration sampling (s)       0.0667102
time/logging (s)                    0.00455326
time/saving (s)                     0.00308339
time/training (s)                   1.05656
time/epoch (s)                      1.39782
time/total (s)                    520.17
Epoch                             360
-----------------------------  ---------------
2019-04-21 12:25:07.148782 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 361 finished
-----------------------------  ---------------
replay_buffer/size              72600
trainer/QF1 Loss                    0.0217633
trainer/QF2 Loss                    0.0184532
trainer/Policy Loss                 8.43103
trainer/Q1 Predictions Mean        -6.8314
trainer/Q1 Predictions Std          3.16833
trainer/Q1 Predictions Max         -5.99587
trainer/Q1 Predictions Min        -31.032
trainer/Q2 Predictions Mean        -6.82564
trainer/Q2 Predictions Std          3.14836
trainer/Q2 Predictions Max         -5.98945
trainer/Q2 Predictions Min        -30.6315
trainer/Q Targets Mean             -6.86937
trainer/Q Targets Std               3.06627
trainer/Q Targets Max              -5.90968
trainer/Q Targets Min             -30.1008
trainer/Log Pis Mean                1.76468
trainer/Log Pis Std                 1.03187
trainer/Log Pis Max                 5.11186
trainer/Log Pis Min                -1.75309
trainer/Policy mu Mean              0.0381561
trainer/Policy mu Std               0.620482
trainer/Policy mu Max               3.15415
trainer/Policy mu Min              -3.2212
trainer/Policy log std Mean        -2.05868
trainer/Policy log std Std          0.424983
trainer/Policy log std Max         -0.341044
trainer/Policy log std Min         -2.31153
trainer/Alpha                       0.0566281
trainer/Alpha Loss                 -0.675561
exploration/num steps total     72600
exploration/num paths total       726
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.2882
exploration/Rewards Std             0.831046
exploration/Rewards Max            -0.00536551
exploration/Rewards Min            -7.09306
exploration/Returns Mean          -28.82
exploration/Returns Std            13.2326
exploration/Returns Max           -15.5874
exploration/Returns Min           -42.0526
exploration/Actions Mean            0.0344474
exploration/Actions Std             0.220102
exploration/Actions Max             0.997978
exploration/Actions Min            -0.516628
exploration/Num Paths               2
exploration/Average Returns       -28.82
evaluation/num steps total     362000
evaluation/num paths total       3620
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.222786
evaluation/Rewards Std              0.985133
evaluation/Rewards Max             -0.0280792
evaluation/Rewards Min            -10.5601
evaluation/Returns Mean           -22.2786
evaluation/Returns Std             15.0411
evaluation/Returns Max             -5.29458
evaluation/Returns Min            -55.1531
evaluation/Actions Mean             0.0198462
evaluation/Actions Std              0.1965
evaluation/Actions Max              0.996828
evaluation/Actions Min             -0.990714
evaluation/Num Paths               10
evaluation/Average Returns        -22.2786
time/data storing (s)               0.00123961
time/evaluation sampling (s)        0.248448
time/exploration sampling (s)       0.0665923
time/logging (s)                    0.00349312
time/saving (s)                     0.00235924
time/training (s)                   1.09608
time/epoch (s)                      1.41822
time/total (s)                    521.593
Epoch                             361
-----------------------------  ---------------
2019-04-21 12:25:08.597470 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 362 finished
-----------------------------  ---------------
replay_buffer/size              72800
trainer/QF1 Loss                    0.364711
trainer/QF2 Loss                    0.361518
trainer/Policy Loss                 8.50596
trainer/Q1 Predictions Mean        -6.41277
trainer/Q1 Predictions Std          3.40318
trainer/Q1 Predictions Max         -5.8809
trainer/Q1 Predictions Min        -39.9645
trainer/Q2 Predictions Mean        -6.4449
trainer/Q2 Predictions Std          3.39715
trainer/Q2 Predictions Max         -5.90623
trainer/Q2 Predictions Min        -40.0002
trainer/Q Targets Mean             -6.48891
trainer/Q Targets Std               3.45613
trainer/Q Targets Max              -0.134535
trainer/Q Targets Min             -40.0454
trainer/Log Pis Mean                2.11863
trainer/Log Pis Std                 0.851578
trainer/Log Pis Max                 3.79073
trainer/Log Pis Min                -1.44206
trainer/Policy mu Mean              0.0502936
trainer/Policy mu Std               0.358409
trainer/Policy mu Max               2.94841
trainer/Policy mu Min              -0.848376
trainer/Policy log std Mean        -2.30846
trainer/Policy log std Std          0.257347
trainer/Policy log std Max         -0.683255
trainer/Policy log std Min         -2.46452
trainer/Alpha                       0.0552973
trainer/Alpha Loss                  0.343446
exploration/num steps total     72800
exploration/num paths total       728
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.566044
exploration/Rewards Std             1.65814
exploration/Rewards Max            -0.00963856
exploration/Rewards Min           -10.6792
exploration/Returns Mean          -56.6044
exploration/Returns Std             8.37937
exploration/Returns Max           -48.225
exploration/Returns Min           -64.9837
exploration/Actions Mean            0.0653937
exploration/Actions Std             0.273163
exploration/Actions Max             0.997831
exploration/Actions Min            -0.538753
exploration/Num Paths               2
exploration/Average Returns       -56.6044
evaluation/num steps total     363000
evaluation/num paths total       3630
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.175025
evaluation/Rewards Std              0.897117
evaluation/Rewards Max             -0.0112492
evaluation/Rewards Min            -10.2453
evaluation/Returns Mean           -17.5025
evaluation/Returns Std             17.4783
evaluation/Returns Max             -2.47899
evaluation/Returns Min            -54.8981
evaluation/Actions Mean             0.0104258
evaluation/Actions Std              0.169649
evaluation/Actions Max              0.997336
evaluation/Actions Min             -0.989031
evaluation/Num Paths               10
evaluation/Average Returns        -17.5025
time/data storing (s)               0.00122965
time/evaluation sampling (s)        0.264944
time/exploration sampling (s)       0.0675295
time/logging (s)                    0.0039649
time/saving (s)                     0.00320633
time/training (s)                   1.09813
time/epoch (s)                      1.43901
time/total (s)                    523.037
Epoch                             362
-----------------------------  ---------------
2019-04-21 12:25:10.111432 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 363 finished
-----------------------------  ---------------
replay_buffer/size              73000
trainer/QF1 Loss                    0.0183475
trainer/QF2 Loss                    0.0203275
trainer/Policy Loss                 8.55817
trainer/Q1 Predictions Mean        -6.43194
trainer/Q1 Predictions Std          2.07675
trainer/Q1 Predictions Max         -5.96936
trainer/Q1 Predictions Min        -26.0563
trainer/Q2 Predictions Mean        -6.40967
trainer/Q2 Predictions Std          2.08974
trainer/Q2 Predictions Max         -5.94173
trainer/Q2 Predictions Min        -26.1366
trainer/Q Targets Mean             -6.49345
trainer/Q Targets Std               2.16722
trainer/Q Targets Max              -5.91656
trainer/Q Targets Min             -27.077
trainer/Log Pis Mean                2.21201
trainer/Log Pis Std                 0.926765
trainer/Log Pis Max                 6.10396
trainer/Log Pis Min                -1.22955
trainer/Policy mu Mean              0.0662299
trainer/Policy mu Std               0.477175
trainer/Policy mu Max               3.33904
trainer/Policy mu Min              -1.40688
trainer/Policy log std Mean        -2.26803
trainer/Policy log std Std          0.36272
trainer/Policy log std Max         -0.54635
trainer/Policy log std Min         -2.44192
trainer/Alpha                       0.0565187
trainer/Alpha Loss                  0.60917
exploration/num steps total     73000
exploration/num paths total       730
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.401293
exploration/Rewards Std             1.36434
exploration/Rewards Max            -0.00226798
exploration/Rewards Min           -10.0947
exploration/Returns Mean          -40.1293
exploration/Returns Std            27.0887
exploration/Returns Max           -13.0406
exploration/Returns Min           -67.218
exploration/Actions Mean            0.0398699
exploration/Actions Std             0.221718
exploration/Actions Max             0.996878
exploration/Actions Min            -0.478606
exploration/Num Paths               2
exploration/Average Returns       -40.1293
evaluation/num steps total     364000
evaluation/num paths total       3640
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.30607
evaluation/Rewards Std              1.26229
evaluation/Rewards Max             -0.031919
evaluation/Rewards Min            -10.629
evaluation/Returns Mean           -30.607
evaluation/Returns Std             19.453
evaluation/Returns Max             -4.28972
evaluation/Returns Min            -59.3647
evaluation/Actions Mean             0.0356279
evaluation/Actions Std              0.213452
evaluation/Actions Max              0.997831
evaluation/Actions Min             -0.996988
evaluation/Num Paths               10
evaluation/Average Returns        -30.607
time/data storing (s)               0.00121086
time/evaluation sampling (s)        0.266644
time/exploration sampling (s)       0.0724765
time/logging (s)                    0.00344293
time/saving (s)                     0.00184095
time/training (s)                   1.15727
time/epoch (s)                      1.50289
time/total (s)                    524.544
Epoch                             363
-----------------------------  ---------------
2019-04-21 12:25:11.652629 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 364 finished
-----------------------------  ---------------
replay_buffer/size              73200
trainer/QF1 Loss                    0.369199
trainer/QF2 Loss                    0.371413
trainer/Policy Loss                 8.27633
trainer/Q1 Predictions Mean        -6.65103
trainer/Q1 Predictions Std          3.06218
trainer/Q1 Predictions Max         -5.89306
trainer/Q1 Predictions Min        -32.2059
trainer/Q2 Predictions Mean        -6.63381
trainer/Q2 Predictions Std          3.08113
trainer/Q2 Predictions Max         -5.87426
trainer/Q2 Predictions Min        -32.2795
trainer/Q Targets Mean             -6.71506
trainer/Q Targets Std               3.09757
trainer/Q Targets Max              -0.221331
trainer/Q Targets Min             -32.1731
trainer/Log Pis Mean                1.74856
trainer/Log Pis Std                 1.1811
trainer/Log Pis Max                 6.38329
trainer/Log Pis Min                -2.81225
trainer/Policy mu Mean              0.130406
trainer/Policy mu Std               0.57425
trainer/Policy mu Max               2.9541
trainer/Policy mu Min              -1.71069
trainer/Policy log std Mean        -2.159
trainer/Policy log std Std          0.416314
trainer/Policy log std Max         -0.641368
trainer/Policy log std Min         -2.42838
trainer/Alpha                       0.0566951
trainer/Alpha Loss                 -0.721618
exploration/num steps total     73200
exploration/num paths total       732
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.370608
exploration/Rewards Std             1.10182
exploration/Rewards Max            -0.00623939
exploration/Rewards Min            -8.54468
exploration/Returns Mean          -37.0608
exploration/Returns Std            11.6007
exploration/Returns Max           -25.46
exploration/Returns Min           -48.6615
exploration/Actions Mean            0.0266157
exploration/Actions Std             0.252057
exploration/Actions Max             0.996656
exploration/Actions Min            -0.987481
exploration/Num Paths               2
exploration/Average Returns       -37.0608
evaluation/num steps total     365000
evaluation/num paths total       3650
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.222973
evaluation/Rewards Std              1.03343
evaluation/Rewards Max             -0.0150292
evaluation/Rewards Min             -9.73256
evaluation/Returns Mean           -22.2973
evaluation/Returns Std             17.9465
evaluation/Returns Max             -5.48154
evaluation/Returns Min            -54.3766
evaluation/Actions Mean             0.0274976
evaluation/Actions Std              0.194498
evaluation/Actions Max              0.995792
evaluation/Actions Min             -0.988997
evaluation/Num Paths               10
evaluation/Average Returns        -22.2973
time/data storing (s)               0.00140858
time/evaluation sampling (s)        0.254556
time/exploration sampling (s)       0.0685083
time/logging (s)                    0.00349861
time/saving (s)                     0.0025446
time/training (s)                   1.2011
time/epoch (s)                      1.53161
time/total (s)                    526.08
Epoch                             364
-----------------------------  ---------------
2019-04-21 12:25:13.055232 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 365 finished
-----------------------------  ---------------
replay_buffer/size              73400
trainer/QF1 Loss                    0.367309
trainer/QF2 Loss                    0.359948
trainer/Policy Loss                 8.76975
trainer/Q1 Predictions Mean        -6.90595
trainer/Q1 Predictions Std          3.28895
trainer/Q1 Predictions Max         -6.05551
trainer/Q1 Predictions Min        -27.686
trainer/Q2 Predictions Mean        -6.82125
trainer/Q2 Predictions Std          3.27218
trainer/Q2 Predictions Max         -5.97009
trainer/Q2 Predictions Min        -27.6369
trainer/Q Targets Mean             -6.79503
trainer/Q Targets Std               3.35047
trainer/Q Targets Max              -0.122671
trainer/Q Targets Min             -27.5022
trainer/Log Pis Mean                1.97548
trainer/Log Pis Std                 0.9988
trainer/Log Pis Max                 4.63437
trainer/Log Pis Min                -1.95372
trainer/Policy mu Mean              0.0287747
trainer/Policy mu Std               0.524145
trainer/Policy mu Max               2.88507
trainer/Policy mu Min              -1.83145
trainer/Policy log std Mean        -2.2272
trainer/Policy log std Std          0.38817
trainer/Policy log std Max         -0.626819
trainer/Policy log std Min         -2.42373
trainer/Alpha                       0.0576135
trainer/Alpha Loss                 -0.0699778
exploration/num steps total     73400
exploration/num paths total       734
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.189517
exploration/Rewards Std             0.497034
exploration/Rewards Max            -0.0164732
exploration/Rewards Min            -5.20738
exploration/Returns Mean          -18.9517
exploration/Returns Std             5.33435
exploration/Returns Max           -13.6174
exploration/Returns Min           -24.2861
exploration/Actions Mean           -0.00764803
exploration/Actions Std             0.20375
exploration/Actions Max             0.971836
exploration/Actions Min            -0.994163
exploration/Num Paths               2
exploration/Average Returns       -18.9517
evaluation/num steps total     366000
evaluation/num paths total       3660
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.182951
evaluation/Rewards Std              0.804751
evaluation/Rewards Max             -0.0174559
evaluation/Rewards Min             -9.40558
evaluation/Returns Mean           -18.2951
evaluation/Returns Std             12.4805
evaluation/Returns Max             -6.71369
evaluation/Returns Min            -45.5048
evaluation/Actions Mean             0.0235865
evaluation/Actions Std              0.185741
evaluation/Actions Max              0.997229
evaluation/Actions Min             -0.990966
evaluation/Num Paths               10
evaluation/Average Returns        -18.2951
time/data storing (s)               0.00131925
time/evaluation sampling (s)        0.254817
time/exploration sampling (s)       0.0741572
time/logging (s)                    0.00384624
time/saving (s)                     0.0027318
time/training (s)                   1.05643
time/epoch (s)                      1.3933
time/total (s)                    527.478
Epoch                             365
-----------------------------  ---------------
2019-04-21 12:25:14.671313 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 366 finished
-----------------------------  ---------------
replay_buffer/size              73600
trainer/QF1 Loss                    0.720608
trainer/QF2 Loss                    0.717798
trainer/Policy Loss                 8.09741
trainer/Q1 Predictions Mean        -6.43227
trainer/Q1 Predictions Std          1.89686
trainer/Q1 Predictions Max         -5.93566
trainer/Q1 Predictions Min        -21.4361
trainer/Q2 Predictions Mean        -6.41451
trainer/Q2 Predictions Std          1.88436
trainer/Q2 Predictions Max         -5.92263
trainer/Q2 Predictions Min        -21.3879
trainer/Q Targets Mean             -6.39218
trainer/Q Targets Std               2.07793
trainer/Q Targets Max              -0.0568438
trainer/Q Targets Min             -21.4665
trainer/Log Pis Mean                1.78962
trainer/Log Pis Std                 1.33236
trainer/Log Pis Max                 5.89393
trainer/Log Pis Min                -4.98587
trainer/Policy mu Mean              0.0664646
trainer/Policy mu Std               0.416933
trainer/Policy mu Max               2.83082
trainer/Policy mu Min              -1.53814
trainer/Policy log std Mean        -2.25738
trainer/Policy log std Std          0.324136
trainer/Policy log std Max         -0.588057
trainer/Policy log std Min         -2.42016
trainer/Alpha                       0.0572256
trainer/Alpha Loss                 -0.601837
exploration/num steps total     73600
exploration/num paths total       736
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.194927
exploration/Rewards Std             0.446964
exploration/Rewards Max            -0.0121482
exploration/Rewards Min            -4.22106
exploration/Returns Mean          -19.4927
exploration/Returns Std             1.53245
exploration/Returns Max           -17.9602
exploration/Returns Min           -21.0251
exploration/Actions Mean           -0.00902285
exploration/Actions Std             0.213656
exploration/Actions Max             0.963218
exploration/Actions Min            -0.986217
exploration/Num Paths               2
exploration/Average Returns       -19.4927
evaluation/num steps total     367000
evaluation/num paths total       3670
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.332744
evaluation/Rewards Std              1.31048
evaluation/Rewards Max             -0.00267874
evaluation/Rewards Min            -10.0908
evaluation/Returns Mean           -33.2744
evaluation/Returns Std             19.1863
evaluation/Returns Max             -6.39742
evaluation/Returns Min            -58.0966
evaluation/Actions Mean             0.0361809
evaluation/Actions Std              0.212197
evaluation/Actions Max              0.996975
evaluation/Actions Min             -0.997585
evaluation/Num Paths               10
evaluation/Average Returns        -33.2744
time/data storing (s)               0.00142104
time/evaluation sampling (s)        0.258094
time/exploration sampling (s)       0.0816235
time/logging (s)                    0.00346795
time/saving (s)                     0.00211881
time/training (s)                   1.25836
time/epoch (s)                      1.60508
time/total (s)                    529.087
Epoch                             366
-----------------------------  ---------------
2019-04-21 12:25:16.226494 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 367 finished
-----------------------------  ---------------
replay_buffer/size              73800
trainer/QF1 Loss                    0.385109
trainer/QF2 Loss                    0.376996
trainer/Policy Loss                 7.84631
trainer/Q1 Predictions Mean        -6.28053
trainer/Q1 Predictions Std          1.37144
trainer/Q1 Predictions Max         -5.98353
trainer/Q1 Predictions Min        -19.4071
trainer/Q2 Predictions Mean        -6.21029
trainer/Q2 Predictions Std          1.2676
trainer/Q2 Predictions Max         -5.93726
trainer/Q2 Predictions Min        -18.3497
trainer/Q Targets Mean             -6.26849
trainer/Q Targets Std               1.42154
trainer/Q Targets Max              -0.0702438
trainer/Q Targets Min             -18.6545
trainer/Log Pis Mean                1.59759
trainer/Log Pis Std                 0.949464
trainer/Log Pis Max                 4.24569
trainer/Log Pis Min                -3.10659
trainer/Policy mu Mean              0.0128399
trainer/Policy mu Std               0.339407
trainer/Policy mu Max               2.60693
trainer/Policy mu Min              -0.935152
trainer/Policy log std Mean        -2.04554
trainer/Policy log std Std          0.247284
trainer/Policy log std Max         -0.503314
trainer/Policy log std Min         -2.18253
trainer/Alpha                       0.0565418
trainer/Alpha Loss                 -1.15576
exploration/num steps total     73800
exploration/num paths total       738
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.258469
exploration/Rewards Std             0.544808
exploration/Rewards Max            -0.011812
exploration/Rewards Min            -5.06536
exploration/Returns Mean          -25.8469
exploration/Returns Std             7.35684
exploration/Returns Max           -18.49
exploration/Returns Min           -33.2037
exploration/Actions Mean            0.025752
exploration/Actions Std             0.23205
exploration/Actions Max             0.998919
exploration/Actions Min            -0.630581
exploration/Num Paths               2
exploration/Average Returns       -25.8469
evaluation/num steps total     368000
evaluation/num paths total       3680
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.108634
evaluation/Rewards Std              0.461677
evaluation/Rewards Max             -0.0122453
evaluation/Rewards Min             -6.13648
evaluation/Returns Mean           -10.8634
evaluation/Returns Std              6.27098
evaluation/Returns Max             -4.99313
evaluation/Returns Min            -21.5201
evaluation/Actions Mean             0.0146293
evaluation/Actions Std              0.150787
evaluation/Actions Max              0.995869
evaluation/Actions Min             -0.978229
evaluation/Num Paths               10
evaluation/Average Returns        -10.8634
time/data storing (s)               0.00172995
time/evaluation sampling (s)        0.288357
time/exploration sampling (s)       0.0867469
time/logging (s)                    0.0035826
time/saving (s)                     0.00284054
time/training (s)                   1.16231
time/epoch (s)                      1.54557
time/total (s)                    530.638
Epoch                             367
-----------------------------  ---------------
2019-04-21 12:25:17.851645 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 368 finished
-----------------------------  ---------------
replay_buffer/size              74000
trainer/QF1 Loss                    1.0597
trainer/QF2 Loss                    1.05168
trainer/Policy Loss                 9.36664
trainer/Q1 Predictions Mean        -7.09333
trainer/Q1 Predictions Std          5.09795
trainer/Q1 Predictions Max         -5.9353
trainer/Q1 Predictions Min        -51.8965
trainer/Q2 Predictions Mean        -7.09219
trainer/Q2 Predictions Std          5.08254
trainer/Q2 Predictions Max         -5.93693
trainer/Q2 Predictions Min        -51.738
trainer/Q Targets Mean             -6.9669
trainer/Q Targets Std               5.19068
trainer/Q Targets Max              -0.0983733
trainer/Q Targets Min             -51.6888
trainer/Log Pis Mean                2.37433
trainer/Log Pis Std                 0.952673
trainer/Log Pis Max                 6.58811
trainer/Log Pis Min                -0.472323
trainer/Policy mu Mean              0.094116
trainer/Policy mu Std               0.627427
trainer/Policy mu Max               3.14898
trainer/Policy mu Min              -2.49936
trainer/Policy log std Mean        -2.2516
trainer/Policy log std Std          0.463333
trainer/Policy log std Max         -0.506865
trainer/Policy log std Min         -2.48785
trainer/Alpha                       0.055189
trainer/Alpha Loss                  1.08453
exploration/num steps total     74000
exploration/num paths total       740
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.329117
exploration/Rewards Std             0.965766
exploration/Rewards Max            -0.00126359
exploration/Rewards Min            -7.04364
exploration/Returns Mean          -32.9117
exploration/Returns Std             6.58102
exploration/Returns Max           -26.3307
exploration/Returns Min           -39.4927
exploration/Actions Mean            0.011402
exploration/Actions Std             0.230615
exploration/Actions Max             0.997142
exploration/Actions Min            -0.997798
exploration/Num Paths               2
exploration/Average Returns       -32.9117
evaluation/num steps total     369000
evaluation/num paths total       3690
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.235337
evaluation/Rewards Std              0.96635
evaluation/Rewards Max             -0.0229803
evaluation/Rewards Min            -11.2819
evaluation/Returns Mean           -23.5337
evaluation/Returns Std             17.4581
evaluation/Returns Max             -7.51163
evaluation/Returns Min            -65.3068
evaluation/Actions Mean             0.0239322
evaluation/Actions Std              0.192773
evaluation/Actions Max              0.997923
evaluation/Actions Min             -0.993584
evaluation/Num Paths               10
evaluation/Average Returns        -23.5337
time/data storing (s)               0.00123305
time/evaluation sampling (s)        0.3171
time/exploration sampling (s)       0.0770469
time/logging (s)                    0.0034877
time/saving (s)                     0.0023514
time/training (s)                   1.21344
time/epoch (s)                      1.61466
time/total (s)                    532.257
Epoch                             368
-----------------------------  ---------------
2019-04-21 12:25:19.463091 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 369 finished
-----------------------------  ---------------
replay_buffer/size              74200
trainer/QF1 Loss                    0.79709
trainer/QF2 Loss                    0.784516
trainer/Policy Loss                 9.29083
trainer/Q1 Predictions Mean        -7.3854
trainer/Q1 Predictions Std          5.03438
trainer/Q1 Predictions Max         -6.04548
trainer/Q1 Predictions Min        -37.8447
trainer/Q2 Predictions Mean        -7.34603
trainer/Q2 Predictions Std          5.05945
trainer/Q2 Predictions Max         -6.0235
trainer/Q2 Predictions Min        -38.0477
trainer/Q Targets Mean             -7.23193
trainer/Q Targets Std               5.31881
trainer/Q Targets Max              -0.0965151
trainer/Q Targets Min             -38.0211
trainer/Log Pis Mean                2.14907
trainer/Log Pis Std                 1.1695
trainer/Log Pis Max                 5.77031
trainer/Log Pis Min                -3.58299
trainer/Policy mu Mean              0.0952139
trainer/Policy mu Std               0.641118
trainer/Policy mu Max               3.14599
trainer/Policy mu Min              -3.3027
trainer/Policy log std Mean        -2.22033
trainer/Policy log std Std          0.446502
trainer/Policy log std Max         -0.451624
trainer/Policy log std Min         -2.46963
trainer/Alpha                       0.0561476
trainer/Alpha Loss                  0.429296
exploration/num steps total     74200
exploration/num paths total       742
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.322233
exploration/Rewards Std             0.88038
exploration/Rewards Max            -0.00751166
exploration/Rewards Min            -6.52625
exploration/Returns Mean          -32.2233
exploration/Returns Std             0.490595
exploration/Returns Max           -31.7327
exploration/Returns Min           -32.7139
exploration/Actions Mean            0.0385282
exploration/Actions Std             0.252515
exploration/Actions Max             0.999297
exploration/Actions Min            -0.807291
exploration/Num Paths               2
exploration/Average Returns       -32.2233
evaluation/num steps total     370000
evaluation/num paths total       3700
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.312213
evaluation/Rewards Std              1.18576
evaluation/Rewards Max             -0.00841349
evaluation/Rewards Min            -10.16
evaluation/Returns Mean           -31.2213
evaluation/Returns Std             16.8231
evaluation/Returns Max            -10.3519
evaluation/Returns Min            -61.3563
evaluation/Actions Mean             0.0362361
evaluation/Actions Std              0.212021
evaluation/Actions Max              0.998135
evaluation/Actions Min             -0.993838
evaluation/Num Paths               10
evaluation/Average Returns        -31.2213
time/data storing (s)               0.00127341
time/evaluation sampling (s)        0.256386
time/exploration sampling (s)       0.0813643
time/logging (s)                    0.00449439
time/saving (s)                     0.00268109
time/training (s)                   1.25735
time/epoch (s)                      1.60355
time/total (s)                    533.865
Epoch                             369
-----------------------------  ---------------
2019-04-21 12:25:20.998074 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 370 finished
-----------------------------  ---------------
replay_buffer/size              74400
trainer/QF1 Loss                    0.058254
trainer/QF2 Loss                    0.0588079
trainer/Policy Loss                 8.08616
trainer/Q1 Predictions Mean        -6.18478
trainer/Q1 Predictions Std          1.94395
trainer/Q1 Predictions Max         -5.79356
trainer/Q1 Predictions Min        -24.8771
trainer/Q2 Predictions Mean        -6.17601
trainer/Q2 Predictions Std          1.93524
trainer/Q2 Predictions Max         -5.75611
trainer/Q2 Predictions Min        -24.7837
trainer/Q Targets Mean             -6.39294
trainer/Q Targets Std               1.94879
trainer/Q Targets Max              -5.90834
trainer/Q Targets Min             -25.0422
trainer/Log Pis Mean                1.94741
trainer/Log Pis Std                 1.06423
trainer/Log Pis Max                 4.33306
trainer/Log Pis Min                -1.99876
trainer/Policy mu Mean              0.0193517
trainer/Policy mu Std               0.375168
trainer/Policy mu Max               2.80038
trainer/Policy mu Min              -1.89021
trainer/Policy log std Mean        -2.3163
trainer/Policy log std Std          0.29439
trainer/Policy log std Max         -0.604404
trainer/Policy log std Min         -2.46129
trainer/Alpha                       0.057264
trainer/Alpha Loss                 -0.150412
exploration/num steps total     74400
exploration/num paths total       744
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.468748
exploration/Rewards Std             1.44661
exploration/Rewards Max            -0.00783049
exploration/Rewards Min           -10.0046
exploration/Returns Mean          -46.8748
exploration/Returns Std            15.2382
exploration/Returns Max           -31.6367
exploration/Returns Min           -62.113
exploration/Actions Mean            0.0450318
exploration/Actions Std             0.264051
exploration/Actions Max             0.998703
exploration/Actions Min            -0.965796
exploration/Num Paths               2
exploration/Average Returns       -46.8748
evaluation/num steps total     371000
evaluation/num paths total       3710
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.261415
evaluation/Rewards Std              1.151
evaluation/Rewards Max             -0.0180902
evaluation/Rewards Min            -10.5637
evaluation/Returns Mean           -26.1415
evaluation/Returns Std             21.7021
evaluation/Returns Max             -3.75362
evaluation/Returns Min            -61.016
evaluation/Actions Mean             0.0211993
evaluation/Actions Std              0.188037
evaluation/Actions Max              0.996732
evaluation/Actions Min             -0.994377
evaluation/Num Paths               10
evaluation/Average Returns        -26.1415
time/data storing (s)               0.00172535
time/evaluation sampling (s)        0.275346
time/exploration sampling (s)       0.0941868
time/logging (s)                    0.00380862
time/saving (s)                     0.00240268
time/training (s)                   1.14483
time/epoch (s)                      1.5223
time/total (s)                    535.392
Epoch                             370
-----------------------------  ---------------
2019-04-21 12:25:22.461910 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 371 finished
-----------------------------  ---------------
replay_buffer/size              74600
trainer/QF1 Loss                    0.364262
trainer/QF2 Loss                    0.362393
trainer/Policy Loss                 9.34505
trainer/Q1 Predictions Mean        -7.18253
trainer/Q1 Predictions Std          5.0864
trainer/Q1 Predictions Max         -5.94003
trainer/Q1 Predictions Min        -46.8344
trainer/Q2 Predictions Mean        -7.18245
trainer/Q2 Predictions Std          5.07534
trainer/Q2 Predictions Max         -5.95828
trainer/Q2 Predictions Min        -47.3038
trainer/Q Targets Mean             -7.13577
trainer/Q Targets Std               5.08125
trainer/Q Targets Max              -0.176105
trainer/Q Targets Min             -46.6544
trainer/Log Pis Mean                2.31419
trainer/Log Pis Std                 1.28656
trainer/Log Pis Max                 6.86839
trainer/Log Pis Min                -2.51724
trainer/Policy mu Mean              0.161569
trainer/Policy mu Std               0.724783
trainer/Policy mu Max               3.07879
trainer/Policy mu Min              -2.25682
trainer/Policy log std Mean        -2.20097
trainer/Policy log std Std          0.540992
trainer/Policy log std Max         -0.594166
trainer/Policy log std Min         -2.5126
trainer/Alpha                       0.0565391
trainer/Alpha Loss                  0.902698
exploration/num steps total     74600
exploration/num paths total       746
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.184034
exploration/Rewards Std             0.452315
exploration/Rewards Max            -0.0118696
exploration/Rewards Min            -4.78558
exploration/Returns Mean          -18.4034
exploration/Returns Std             5.67835
exploration/Returns Max           -12.7251
exploration/Returns Min           -24.0818
exploration/Actions Mean            0.00907873
exploration/Actions Std             0.189507
exploration/Actions Max             0.994722
exploration/Actions Min            -0.956043
exploration/Num Paths               2
exploration/Average Returns       -18.4034
evaluation/num steps total     372000
evaluation/num paths total       3720
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.231965
evaluation/Rewards Std              0.956794
evaluation/Rewards Max             -0.037909
evaluation/Rewards Min            -10.9583
evaluation/Returns Mean           -23.1965
evaluation/Returns Std             16.7578
evaluation/Returns Max             -6.56923
evaluation/Returns Min            -63.9509
evaluation/Actions Mean             0.0166934
evaluation/Actions Std              0.199532
evaluation/Actions Max              0.997915
evaluation/Actions Min             -0.991941
evaluation/Num Paths               10
evaluation/Average Returns        -23.1965
time/data storing (s)               0.00117721
time/evaluation sampling (s)        0.290878
time/exploration sampling (s)       0.0641579
time/logging (s)                    0.0034388
time/saving (s)                     0.00231988
time/training (s)                   1.09161
time/epoch (s)                      1.45358
time/total (s)                    536.85
Epoch                             371
-----------------------------  ---------------
2019-04-21 12:25:23.915646 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 372 finished
-----------------------------  ---------------
replay_buffer/size              74800
trainer/QF1 Loss                    0.368816
trainer/QF2 Loss                    0.364033
trainer/Policy Loss                 8.42248
trainer/Q1 Predictions Mean        -6.50982
trainer/Q1 Predictions Std          1.78456
trainer/Q1 Predictions Max         -6.00281
trainer/Q1 Predictions Min        -22.5967
trainer/Q2 Predictions Mean        -6.46945
trainer/Q2 Predictions Std          1.79773
trainer/Q2 Predictions Max         -5.94284
trainer/Q2 Predictions Min        -22.5634
trainer/Q Targets Mean             -6.45012
trainer/Q Targets Std               1.96299
trainer/Q Targets Max              -0.096589
trainer/Q Targets Min             -23.3266
trainer/Log Pis Mean                2.02187
trainer/Log Pis Std                 0.807106
trainer/Log Pis Max                 3.65345
trainer/Log Pis Min                -0.829795
trainer/Policy mu Mean              0.0728931
trainer/Policy mu Std               0.53505
trainer/Policy mu Max               2.83086
trainer/Policy mu Min              -1.41872
trainer/Policy log std Mean        -2.17131
trainer/Policy log std Std          0.423935
trainer/Policy log std Max         -0.609726
trainer/Policy log std Min         -2.45174
trainer/Alpha                       0.057493
trainer/Alpha Loss                  0.0624699
exploration/num steps total     74800
exploration/num paths total       748
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.142422
exploration/Rewards Std             0.105269
exploration/Rewards Max            -0.0110843
exploration/Rewards Min            -1.26762
exploration/Returns Mean          -14.2422
exploration/Returns Std             0.916839
exploration/Returns Max           -13.3254
exploration/Returns Min           -15.159
exploration/Actions Mean            0.00472587
exploration/Actions Std             0.159594
exploration/Actions Max             0.960973
exploration/Actions Min            -0.738829
exploration/Num Paths               2
exploration/Average Returns       -14.2422
evaluation/num steps total     373000
evaluation/num paths total       3730
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.309196
evaluation/Rewards Std              1.15874
evaluation/Rewards Max             -0.0143711
evaluation/Rewards Min            -10.1925
evaluation/Returns Mean           -30.9196
evaluation/Returns Std             18.7192
evaluation/Returns Max             -6.98361
evaluation/Returns Min            -62.1987
evaluation/Actions Mean             0.0300935
evaluation/Actions Std              0.199155
evaluation/Actions Max              0.996518
evaluation/Actions Min             -0.997047
evaluation/Num Paths               10
evaluation/Average Returns        -30.9196
time/data storing (s)               0.00116846
time/evaluation sampling (s)        0.248659
time/exploration sampling (s)       0.0645599
time/logging (s)                    0.00344971
time/saving (s)                     0.0020321
time/training (s)                   1.12385
time/epoch (s)                      1.44372
time/total (s)                    538.298
Epoch                             372
-----------------------------  ---------------
2019-04-21 12:25:25.313546 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 373 finished
-----------------------------  ---------------
replay_buffer/size              75000
trainer/QF1 Loss                    0.35719
trainer/QF2 Loss                    0.369349
trainer/Policy Loss                 7.95215
trainer/Q1 Predictions Mean        -6.24893
trainer/Q1 Predictions Std          1.47018
trainer/Q1 Predictions Max         -5.92946
trainer/Q1 Predictions Min        -20.5492
trainer/Q2 Predictions Mean        -6.1872
trainer/Q2 Predictions Std          1.42111
trainer/Q2 Predictions Max         -5.90203
trainer/Q2 Predictions Min        -19.9776
trainer/Q Targets Mean             -6.26914
trainer/Q Targets Std               1.604
trainer/Q Targets Max              -0.20092
trainer/Q Targets Min             -20.7604
trainer/Log Pis Mean                1.79138
trainer/Log Pis Std                 0.925209
trainer/Log Pis Max                 4.27698
trainer/Log Pis Min                -2.17972
trainer/Policy mu Mean              0.0051663
trainer/Policy mu Std               0.386794
trainer/Policy mu Max               2.51674
trainer/Policy mu Min              -1.2476
trainer/Policy log std Mean        -2.19037
trainer/Policy log std Std          0.324571
trainer/Policy log std Max         -0.64701
trainer/Policy log std Min         -2.39766
trainer/Alpha                       0.0569278
trainer/Alpha Loss                 -0.59783
exploration/num steps total     75000
exploration/num paths total       750
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.465945
exploration/Rewards Std             1.29194
exploration/Rewards Max            -0.0111313
exploration/Rewards Min            -8.49419
exploration/Returns Mean          -46.5945
exploration/Returns Std             6.9069
exploration/Returns Max           -39.6876
exploration/Returns Min           -53.5014
exploration/Actions Mean            0.0389489
exploration/Actions Std             0.244844
exploration/Actions Max             0.997488
exploration/Actions Min            -0.523124
exploration/Num Paths               2
exploration/Average Returns       -46.5945
evaluation/num steps total     374000
evaluation/num paths total       3740
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.303457
evaluation/Rewards Std              1.11999
evaluation/Rewards Max             -0.0500863
evaluation/Rewards Min            -11.146
evaluation/Returns Mean           -30.3457
evaluation/Returns Std             18.5537
evaluation/Returns Max             -7.65233
evaluation/Returns Min            -65.714
evaluation/Actions Mean             0.021011
evaluation/Actions Std              0.198262
evaluation/Actions Max              0.99749
evaluation/Actions Min             -0.995523
evaluation/Num Paths               10
evaluation/Average Returns        -30.3457
time/data storing (s)               0.00122364
time/evaluation sampling (s)        0.257766
time/exploration sampling (s)       0.0708857
time/logging (s)                    0.00353287
time/saving (s)                     0.00242667
time/training (s)                   1.05311
time/epoch (s)                      1.38895
time/total (s)                    539.691
Epoch                             373
-----------------------------  ---------------
2019-04-21 12:25:26.774929 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 374 finished
-----------------------------  ---------------
replay_buffer/size              75200
trainer/QF1 Loss                    0.715618
trainer/QF2 Loss                    0.709086
trainer/Policy Loss                 8.69439
trainer/Q1 Predictions Mean        -6.70804
trainer/Q1 Predictions Std          2.9223
trainer/Q1 Predictions Max         -5.98758
trainer/Q1 Predictions Min        -32.0121
trainer/Q2 Predictions Mean        -6.70723
trainer/Q2 Predictions Std          2.89065
trainer/Q2 Predictions Max         -5.99885
trainer/Q2 Predictions Min        -31.4991
trainer/Q Targets Mean             -6.5865
trainer/Q Targets Std               3.04817
trainer/Q Targets Max              -0.157683
trainer/Q Targets Min             -31.8119
trainer/Log Pis Mean                2.07385
trainer/Log Pis Std                 0.942048
trainer/Log Pis Max                 3.42197
trainer/Log Pis Min                -1.07149
trainer/Policy mu Mean              0.0843556
trainer/Policy mu Std               0.561218
trainer/Policy mu Max               2.89304
trainer/Policy mu Min              -2.26199
trainer/Policy log std Mean        -2.21015
trainer/Policy log std Std          0.427237
trainer/Policy log std Max         -0.70961
trainer/Policy log std Min         -2.49805
trainer/Alpha                       0.0570419
trainer/Alpha Loss                  0.211487
exploration/num steps total     75200
exploration/num paths total       752
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.335176
exploration/Rewards Std             1.03926
exploration/Rewards Max            -0.003506
exploration/Rewards Min            -8.43563
exploration/Returns Mean          -33.5176
exploration/Returns Std            10.7294
exploration/Returns Max           -22.7882
exploration/Returns Min           -44.247
exploration/Actions Mean            0.0394691
exploration/Actions Std             0.250378
exploration/Actions Max             0.999542
exploration/Actions Min            -0.876077
exploration/Num Paths               2
exploration/Average Returns       -33.5176
evaluation/num steps total     375000
evaluation/num paths total       3750
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.157157
evaluation/Rewards Std              0.782462
evaluation/Rewards Max             -0.0140894
evaluation/Rewards Min             -8.34499
evaluation/Returns Mean           -15.7157
evaluation/Returns Std             12.0763
evaluation/Returns Max             -2.64489
evaluation/Returns Min            -38.4126
evaluation/Actions Mean             0.0120306
evaluation/Actions Std              0.18256
evaluation/Actions Max              0.996235
evaluation/Actions Min             -0.994345
evaluation/Num Paths               10
evaluation/Average Returns        -15.7157
time/data storing (s)               0.00123393
time/evaluation sampling (s)        0.268169
time/exploration sampling (s)       0.0727085
time/logging (s)                    0.0031061
time/saving (s)                     0.00193734
time/training (s)                   1.10301
time/epoch (s)                      1.45016
time/total (s)                    541.145
Epoch                             374
-----------------------------  ---------------
2019-04-21 12:25:28.234336 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 375 finished
-----------------------------  ---------------
replay_buffer/size              75400
trainer/QF1 Loss                    0.0347731
trainer/QF2 Loss                    0.0207849
trainer/Policy Loss                 8.78947
trainer/Q1 Predictions Mean        -6.79686
trainer/Q1 Predictions Std          3.74312
trainer/Q1 Predictions Max         -5.88897
trainer/Q1 Predictions Min        -37.4396
trainer/Q2 Predictions Mean        -6.81306
trainer/Q2 Predictions Std          3.7656
trainer/Q2 Predictions Max         -5.91588
trainer/Q2 Predictions Min        -37.4873
trainer/Q Targets Mean             -6.89381
trainer/Q Targets Std               3.78475
trainer/Q Targets Max              -5.90221
trainer/Q Targets Min             -37.5751
trainer/Log Pis Mean                2.1558
trainer/Log Pis Std                 1.03718
trainer/Log Pis Max                 5.55195
trainer/Log Pis Min                -1.80288
trainer/Policy mu Mean              0.0604257
trainer/Policy mu Std               0.589076
trainer/Policy mu Max               2.90456
trainer/Policy mu Min              -2.04231
trainer/Policy log std Mean        -2.18868
trainer/Policy log std Std          0.440311
trainer/Policy log std Max         -0.569285
trainer/Policy log std Min         -2.44897
trainer/Alpha                       0.0569892
trainer/Alpha Loss                  0.446354
exploration/num steps total     75400
exploration/num paths total       754
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.253393
exploration/Rewards Std             0.720161
exploration/Rewards Max            -0.00340033
exploration/Rewards Min            -6.39892
exploration/Returns Mean          -25.3393
exploration/Returns Std            11.4792
exploration/Returns Max           -13.8601
exploration/Returns Min           -36.8185
exploration/Actions Mean            0.0319253
exploration/Actions Std             0.214991
exploration/Actions Max             0.998556
exploration/Actions Min            -0.464668
exploration/Num Paths               2
exploration/Average Returns       -25.3393
evaluation/num steps total     376000
evaluation/num paths total       3760
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.210656
evaluation/Rewards Std              0.907324
evaluation/Rewards Max             -0.00498855
evaluation/Rewards Min             -7.98061
evaluation/Returns Mean           -21.0656
evaluation/Returns Std             11.5579
evaluation/Returns Max             -6.13744
evaluation/Returns Min            -38.8873
evaluation/Actions Mean             0.033071
evaluation/Actions Std              0.189663
evaluation/Actions Max              0.994994
evaluation/Actions Min             -0.991454
evaluation/Num Paths               10
evaluation/Average Returns        -21.0656
time/data storing (s)               0.00113721
time/evaluation sampling (s)        0.257948
time/exploration sampling (s)       0.0661565
time/logging (s)                    0.00381172
time/saving (s)                     0.00251988
time/training (s)                   1.11971
time/epoch (s)                      1.45128
time/total (s)                    542.601
Epoch                             375
-----------------------------  ---------------
2019-04-21 12:25:29.625225 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 376 finished
-----------------------------  ---------------
replay_buffer/size              75600
trainer/QF1 Loss                    0.356919
trainer/QF2 Loss                    0.358531
trainer/Policy Loss                 8.13154
trainer/Q1 Predictions Mean        -6.24419
trainer/Q1 Predictions Std          1.17325
trainer/Q1 Predictions Max         -5.91837
trainer/Q1 Predictions Min        -16.7836
trainer/Q2 Predictions Mean        -6.19696
trainer/Q2 Predictions Std          1.20097
trainer/Q2 Predictions Max         -5.86305
trainer/Q2 Predictions Min        -16.9262
trainer/Q Targets Mean             -6.25274
trainer/Q Targets Std               1.35756
trainer/Q Targets Max              -0.124677
trainer/Q Targets Min             -17.1255
trainer/Log Pis Mean                1.93727
trainer/Log Pis Std                 1.14826
trainer/Log Pis Max                 7.37181
trainer/Log Pis Min                -2.37391
trainer/Policy mu Mean              0.0167308
trainer/Policy mu Std               0.415824
trainer/Policy mu Max               2.50465
trainer/Policy mu Min              -2.49677
trainer/Policy log std Mean        -2.30249
trainer/Policy log std Std          0.303195
trainer/Policy log std Max         -0.645033
trainer/Policy log std Min         -2.47964
trainer/Alpha                       0.0578972
trainer/Alpha Loss                 -0.178718
exploration/num steps total     75600
exploration/num paths total       756
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.180227
exploration/Rewards Std             0.411368
exploration/Rewards Max            -0.00845081
exploration/Rewards Min            -4.17419
exploration/Returns Mean          -18.0227
exploration/Returns Std             4.25657
exploration/Returns Max           -13.7662
exploration/Returns Min           -22.2793
exploration/Actions Mean            0.011762
exploration/Actions Std             0.18945
exploration/Actions Max             0.990264
exploration/Actions Min            -0.955263
exploration/Num Paths               2
exploration/Average Returns       -18.0227
evaluation/num steps total     377000
evaluation/num paths total       3770
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.267009
evaluation/Rewards Std              1.1306
evaluation/Rewards Max             -0.0168435
evaluation/Rewards Min            -10.5305
evaluation/Returns Mean           -26.7009
evaluation/Returns Std             17.6337
evaluation/Returns Max             -4.65078
evaluation/Returns Min            -60.2715
evaluation/Actions Mean             0.0351575
evaluation/Actions Std              0.205931
evaluation/Actions Max              0.996739
evaluation/Actions Min             -0.990714
evaluation/Num Paths               10
evaluation/Average Returns        -26.7009
time/data storing (s)               0.00117191
time/evaluation sampling (s)        0.282205
time/exploration sampling (s)       0.0652391
time/logging (s)                    0.00295178
time/saving (s)                     0.00237817
time/training (s)                   1.02521
time/epoch (s)                      1.37915
time/total (s)                    543.985
Epoch                             376
-----------------------------  ---------------
2019-04-21 12:25:31.060230 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 377 finished
-----------------------------  ---------------
replay_buffer/size              75800
trainer/QF1 Loss                    0.707305
trainer/QF2 Loss                    0.705448
trainer/Policy Loss                 8.87774
trainer/Q1 Predictions Mean        -6.78422
trainer/Q1 Predictions Std          3.14766
trainer/Q1 Predictions Max         -5.90098
trainer/Q1 Predictions Min        -23.1861
trainer/Q2 Predictions Mean        -6.78329
trainer/Q2 Predictions Std          3.12732
trainer/Q2 Predictions Max         -5.87178
trainer/Q2 Predictions Min        -23.135
trainer/Q Targets Mean             -6.73984
trainer/Q Targets Std               3.25762
trainer/Q Targets Max              -0.0233809
trainer/Q Targets Min             -23.2744
trainer/Log Pis Mean                2.20689
trainer/Log Pis Std                 1.09158
trainer/Log Pis Max                 5.56528
trainer/Log Pis Min                -2.30761
trainer/Policy mu Mean              0.0707601
trainer/Policy mu Std               0.547065
trainer/Policy mu Max               2.99416
trainer/Policy mu Min              -2.7228
trainer/Policy log std Mean        -2.3308
trainer/Policy log std Std          0.395478
trainer/Policy log std Max         -0.664306
trainer/Policy log std Min         -2.53596
trainer/Alpha                       0.057879
trainer/Alpha Loss                  0.589551
exploration/num steps total     75800
exploration/num paths total       758
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.357121
exploration/Rewards Std             1.12258
exploration/Rewards Max            -0.0199273
exploration/Rewards Min            -8.80491
exploration/Returns Mean          -35.7121
exploration/Returns Std            15.1434
exploration/Returns Max           -20.5687
exploration/Returns Min           -50.8555
exploration/Actions Mean            0.0373375
exploration/Actions Std             0.24323
exploration/Actions Max             0.998489
exploration/Actions Min            -0.944267
exploration/Num Paths               2
exploration/Average Returns       -35.7121
evaluation/num steps total     378000
evaluation/num paths total       3780
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.220554
evaluation/Rewards Std              0.931383
evaluation/Rewards Max             -0.030238
evaluation/Rewards Min             -9.62672
evaluation/Returns Mean           -22.0554
evaluation/Returns Std             11.0393
evaluation/Returns Max             -9.48203
evaluation/Returns Min            -48.9993
evaluation/Actions Mean             0.0346667
evaluation/Actions Std              0.195516
evaluation/Actions Max              0.996182
evaluation/Actions Min             -0.991556
evaluation/Num Paths               10
evaluation/Average Returns        -22.0554
time/data storing (s)               0.0011778
time/evaluation sampling (s)        0.275134
time/exploration sampling (s)       0.0699292
time/logging (s)                    0.00350056
time/saving (s)                     0.00238157
time/training (s)                   1.07389
time/epoch (s)                      1.42601
time/total (s)                    545.416
Epoch                             377
-----------------------------  ---------------
2019-04-21 12:25:32.601553 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 378 finished
-----------------------------  ---------------
replay_buffer/size              76000
trainer/QF1 Loss                    0.444946
trainer/QF2 Loss                    0.448137
trainer/Policy Loss                 9.35825
trainer/Q1 Predictions Mean        -7.566
trainer/Q1 Predictions Std          7.57802
trainer/Q1 Predictions Max         -5.77888
trainer/Q1 Predictions Min        -70.9472
trainer/Q2 Predictions Mean        -7.56142
trainer/Q2 Predictions Std          7.56659
trainer/Q2 Predictions Max         -5.78883
trainer/Q2 Predictions Min        -70.8567
trainer/Q Targets Mean             -7.74635
trainer/Q Targets Std               7.7772
trainer/Q Targets Max              -0.0707486
trainer/Q Targets Min             -73.114
trainer/Log Pis Mean                1.92479
trainer/Log Pis Std                 1.38219
trainer/Log Pis Max                 6.34089
trainer/Log Pis Min                -1.81504
trainer/Policy mu Mean              0.110469
trainer/Policy mu Std               0.665588
trainer/Policy mu Max               3.25306
trainer/Policy mu Min              -2.76182
trainer/Policy log std Mean        -2.13944
trainer/Policy log std Std          0.430946
trainer/Policy log std Max         -0.52765
trainer/Policy log std Min         -2.37548
trainer/Alpha                       0.0589293
trainer/Alpha Loss                 -0.212951
exploration/num steps total     76000
exploration/num paths total       760
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.527013
exploration/Rewards Std             1.55902
exploration/Rewards Max            -0.0155034
exploration/Rewards Min           -10.548
exploration/Returns Mean          -52.7013
exploration/Returns Std            14.1094
exploration/Returns Max           -38.5919
exploration/Returns Min           -66.8108
exploration/Actions Mean            0.0469304
exploration/Actions Std             0.281309
exploration/Actions Max             0.999592
exploration/Actions Min            -0.937395
exploration/Num Paths               2
exploration/Average Returns       -52.7013
evaluation/num steps total     379000
evaluation/num paths total       3790
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.15644
evaluation/Rewards Std              0.730334
evaluation/Rewards Max             -0.00676459
evaluation/Rewards Min             -7.85038
evaluation/Returns Mean           -15.644
evaluation/Returns Std             11.3495
evaluation/Returns Max             -3.52501
evaluation/Returns Min            -38.312
evaluation/Actions Mean             0.0251407
evaluation/Actions Std              0.17109
evaluation/Actions Max              0.995821
evaluation/Actions Min             -0.982883
evaluation/Num Paths               10
evaluation/Average Returns        -15.644
time/data storing (s)               0.00115843
time/evaluation sampling (s)        0.270129
time/exploration sampling (s)       0.066731
time/logging (s)                    0.00411899
time/saving (s)                     0.00200957
time/training (s)                   1.18708
time/epoch (s)                      1.53123
time/total (s)                    546.953
Epoch                             378
-----------------------------  ---------------
2019-04-21 12:25:33.987830 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 379 finished
-----------------------------  ---------------
replay_buffer/size              76200
trainer/QF1 Loss                    0.0361813
trainer/QF2 Loss                    0.0367912
trainer/Policy Loss                 8.73858
trainer/Q1 Predictions Mean        -6.84862
trainer/Q1 Predictions Std          5.02088
trainer/Q1 Predictions Max         -5.79141
trainer/Q1 Predictions Min        -48.317
trainer/Q2 Predictions Mean        -6.85853
trainer/Q2 Predictions Std          5.01363
trainer/Q2 Predictions Max         -5.82664
trainer/Q2 Predictions Min        -48.3846
trainer/Q Targets Mean             -7.00564
trainer/Q Targets Std               4.95254
trainer/Q Targets Max              -5.88666
trainer/Q Targets Min             -47.9433
trainer/Log Pis Mean                1.91772
trainer/Log Pis Std                 0.902115
trainer/Log Pis Max                 5.41131
trainer/Log Pis Min                -1.05453
trainer/Policy mu Mean              0.0681542
trainer/Policy mu Std               0.539312
trainer/Policy mu Max               3.01421
trainer/Policy mu Min              -2.17482
trainer/Policy log std Mean        -2.16768
trainer/Policy log std Std          0.37737
trainer/Policy log std Max         -0.634183
trainer/Policy log std Min         -2.38103
trainer/Alpha                       0.0586461
trainer/Alpha Loss                 -0.233349
exploration/num steps total     76200
exploration/num paths total       762
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.397195
exploration/Rewards Std             1.1445
exploration/Rewards Max            -0.00529831
exploration/Rewards Min            -8.23381
exploration/Returns Mean          -39.7195
exploration/Returns Std             5.70705
exploration/Returns Max           -34.0124
exploration/Returns Min           -45.4265
exploration/Actions Mean            0.0338719
exploration/Actions Std             0.263138
exploration/Actions Max             0.998449
exploration/Actions Min            -0.995985
exploration/Num Paths               2
exploration/Average Returns       -39.7195
evaluation/num steps total     380000
evaluation/num paths total       3800
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.199915
evaluation/Rewards Std              0.978477
evaluation/Rewards Max             -0.0119116
evaluation/Rewards Min             -8.85834
evaluation/Returns Mean           -19.9915
evaluation/Returns Std             15.5294
evaluation/Returns Max             -2.67746
evaluation/Returns Min            -45.3788
evaluation/Actions Mean             0.0201022
evaluation/Actions Std              0.188179
evaluation/Actions Max              0.995967
evaluation/Actions Min             -0.991619
evaluation/Num Paths               10
evaluation/Average Returns        -19.9915
time/data storing (s)               0.00106402
time/evaluation sampling (s)        0.284825
time/exploration sampling (s)       0.0612835
time/logging (s)                    0.00360011
time/saving (s)                     0.00268976
time/training (s)                   1.01998
time/epoch (s)                      1.37344
time/total (s)                    548.331
Epoch                             379
-----------------------------  ---------------
2019-04-21 12:25:35.354854 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 380 finished
-----------------------------  ---------------
replay_buffer/size              76400
trainer/QF1 Loss                    0.034249
trainer/QF2 Loss                    0.0145902
trainer/Policy Loss                 9.30188
trainer/Q1 Predictions Mean        -7.26401
trainer/Q1 Predictions Std          5.46149
trainer/Q1 Predictions Max         -5.87872
trainer/Q1 Predictions Min        -47.0338
trainer/Q2 Predictions Mean        -7.30626
trainer/Q2 Predictions Std          5.54874
trainer/Q2 Predictions Max         -5.89176
trainer/Q2 Predictions Min        -47.898
trainer/Q Targets Mean             -7.36662
trainer/Q Targets Std               5.5758
trainer/Q Targets Max              -5.9018
trainer/Q Targets Min             -48.3323
trainer/Log Pis Mean                2.23905
trainer/Log Pis Std                 1.29329
trainer/Log Pis Max                 7.24323
trainer/Log Pis Min                -2.56643
trainer/Policy mu Mean              0.0936463
trainer/Policy mu Std               0.613067
trainer/Policy mu Max               3.25386
trainer/Policy mu Min              -2.30139
trainer/Policy log std Mean        -2.28441
trainer/Policy log std Std          0.420209
trainer/Policy log std Max         -0.620958
trainer/Policy log std Min         -2.52047
trainer/Alpha                       0.0587722
trainer/Alpha Loss                  0.677527
exploration/num steps total     76400
exploration/num paths total       764
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.269145
exploration/Rewards Std             0.857551
exploration/Rewards Max            -0.00938531
exploration/Rewards Min            -7.42434
exploration/Returns Mean          -26.9145
exploration/Returns Std             7.751
exploration/Returns Max           -19.1635
exploration/Returns Min           -34.6655
exploration/Actions Mean            0.0506364
exploration/Actions Std             0.23903
exploration/Actions Max             0.997906
exploration/Actions Min            -0.367908
exploration/Num Paths               2
exploration/Average Returns       -26.9145
evaluation/num steps total     381000
evaluation/num paths total       3810
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.222161
evaluation/Rewards Std              0.972748
evaluation/Rewards Max             -0.0283999
evaluation/Rewards Min            -10.9144
evaluation/Returns Mean           -22.2161
evaluation/Returns Std             15.2287
evaluation/Returns Max             -4.54819
evaluation/Returns Min            -59.6479
evaluation/Actions Mean             0.0154953
evaluation/Actions Std              0.195763
evaluation/Actions Max              0.998083
evaluation/Actions Min             -0.994753
evaluation/Num Paths               10
evaluation/Average Returns        -22.2161
time/data storing (s)               0.00129514
time/evaluation sampling (s)        0.254307
time/exploration sampling (s)       0.065039
time/logging (s)                    0.00349482
time/saving (s)                     0.00245285
time/training (s)                   1.03027
time/epoch (s)                      1.35686
time/total (s)                    549.692
Epoch                             380
-----------------------------  ---------------
2019-04-21 12:25:36.724334 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 381 finished
-----------------------------  ---------------
replay_buffer/size              76600
trainer/QF1 Loss                    0.363141
trainer/QF2 Loss                    0.363373
trainer/Policy Loss                 8.77547
trainer/Q1 Predictions Mean        -6.81113
trainer/Q1 Predictions Std          3.83344
trainer/Q1 Predictions Max         -5.94064
trainer/Q1 Predictions Min        -33.9522
trainer/Q2 Predictions Mean        -6.83944
trainer/Q2 Predictions Std          3.83566
trainer/Q2 Predictions Max         -5.97331
trainer/Q2 Predictions Min        -33.9952
trainer/Q Targets Mean             -6.77671
trainer/Q Targets Std               3.9001
trainer/Q Targets Max              -0.253865
trainer/Q Targets Min             -34.1348
trainer/Log Pis Mean                2.05566
trainer/Log Pis Std                 1.08579
trainer/Log Pis Max                 5.30577
trainer/Log Pis Min                -1.49034
trainer/Policy mu Mean              0.0826713
trainer/Policy mu Std               0.533657
trainer/Policy mu Max               2.95418
trainer/Policy mu Min              -2.18992
trainer/Policy log std Mean        -2.21453
trainer/Policy log std Std          0.407719
trainer/Policy log std Max         -0.578382
trainer/Policy log std Min         -2.47426
trainer/Alpha                       0.0591145
trainer/Alpha Loss                  0.157419
exploration/num steps total     76600
exploration/num paths total       766
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.35462
exploration/Rewards Std             1.03533
exploration/Rewards Max            -0.0085979
exploration/Rewards Min            -8.15427
exploration/Returns Mean          -35.462
exploration/Returns Std             7.7044
exploration/Returns Max           -27.7576
exploration/Returns Min           -43.1664
exploration/Actions Mean            0.0207738
exploration/Actions Std             0.25363
exploration/Actions Max             0.99835
exploration/Actions Min            -0.995911
exploration/Num Paths               2
exploration/Average Returns       -35.462
evaluation/num steps total     382000
evaluation/num paths total       3820
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.203537
evaluation/Rewards Std              0.884341
evaluation/Rewards Max             -0.0189737
evaluation/Rewards Min             -8.19451
evaluation/Returns Mean           -20.3537
evaluation/Returns Std             10.6269
evaluation/Returns Max             -4.65192
evaluation/Returns Min            -33.9036
evaluation/Actions Mean             0.0306602
evaluation/Actions Std              0.195476
evaluation/Actions Max              0.996775
evaluation/Actions Min             -0.984327
evaluation/Num Paths               10
evaluation/Average Returns        -20.3537
time/data storing (s)               0.00122058
time/evaluation sampling (s)        0.245733
time/exploration sampling (s)       0.0672091
time/logging (s)                    0.00306029
time/saving (s)                     0.00235359
time/training (s)                   1.03949
time/epoch (s)                      1.35906
time/total (s)                    551.055
Epoch                             381
-----------------------------  ---------------
2019-04-21 12:25:38.210383 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 382 finished
-----------------------------  ---------------
replay_buffer/size              76800
trainer/QF1 Loss                    0.36025
trainer/QF2 Loss                    0.361782
trainer/Policy Loss                 9.07118
trainer/Q1 Predictions Mean        -7.08796
trainer/Q1 Predictions Std          5.96337
trainer/Q1 Predictions Max         -5.99693
trainer/Q1 Predictions Min        -61.3283
trainer/Q2 Predictions Mean        -7.06505
trainer/Q2 Predictions Std          5.91805
trainer/Q2 Predictions Max         -5.98765
trainer/Q2 Predictions Min        -60.8984
trainer/Q Targets Mean             -7.04135
trainer/Q Targets Std               6.01548
trainer/Q Targets Max              -0.253027
trainer/Q Targets Min             -61.6755
trainer/Log Pis Mean                2.07475
trainer/Log Pis Std                 1.26398
trainer/Log Pis Max                 8.73936
trainer/Log Pis Min                -2.64197
trainer/Policy mu Mean              0.113668
trainer/Policy mu Std               0.557526
trainer/Policy mu Max               3.45633
trainer/Policy mu Min              -2.34949
trainer/Policy log std Mean        -2.18118
trainer/Policy log std Std          0.39689
trainer/Policy log std Max         -0.556277
trainer/Policy log std Min         -2.43309
trainer/Alpha                       0.0574721
trainer/Alpha Loss                  0.21351
exploration/num steps total     76800
exploration/num paths total       768
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.193407
exploration/Rewards Std             0.512196
exploration/Rewards Max            -0.00384606
exploration/Rewards Min            -5.42798
exploration/Returns Mean          -19.3407
exploration/Returns Std             6.12509
exploration/Returns Max           -13.2156
exploration/Returns Min           -25.4658
exploration/Actions Mean            0.027243
exploration/Actions Std             0.2009
exploration/Actions Max             0.997127
exploration/Actions Min            -0.385512
exploration/Num Paths               2
exploration/Average Returns       -19.3407
evaluation/num steps total     383000
evaluation/num paths total       3830
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.207651
evaluation/Rewards Std              0.841993
evaluation/Rewards Max             -0.00269142
evaluation/Rewards Min            -10.1884
evaluation/Returns Mean           -20.7651
evaluation/Returns Std             14.6068
evaluation/Returns Max             -6.4583
evaluation/Returns Min            -53.3942
evaluation/Actions Mean             0.0201554
evaluation/Actions Std              0.174281
evaluation/Actions Max              0.996318
evaluation/Actions Min             -0.992667
evaluation/Num Paths               10
evaluation/Average Returns        -20.7651
time/data storing (s)               0.00116955
time/evaluation sampling (s)        0.252888
time/exploration sampling (s)       0.0657708
time/logging (s)                    0.00345332
time/saving (s)                     0.00234674
time/training (s)                   1.15053
time/epoch (s)                      1.47616
time/total (s)                    552.536
Epoch                             382
-----------------------------  ---------------
2019-04-21 12:25:39.728570 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 383 finished
-----------------------------  ---------------
replay_buffer/size              77000
trainer/QF1 Loss                    0.712901
trainer/QF2 Loss                    0.712797
trainer/Policy Loss                 9.66019
trainer/Q1 Predictions Mean        -7.74728
trainer/Q1 Predictions Std          7.24268
trainer/Q1 Predictions Max         -5.92885
trainer/Q1 Predictions Min        -56.2792
trainer/Q2 Predictions Mean        -7.71622
trainer/Q2 Predictions Std          7.2459
trainer/Q2 Predictions Max         -5.90444
trainer/Q2 Predictions Min        -56.3196
trainer/Q Targets Mean             -7.68551
trainer/Q Targets Std               7.23307
trainer/Q Targets Max              -0.0918934
trainer/Q Targets Min             -56.0167
trainer/Log Pis Mean                2.08608
trainer/Log Pis Std                 1.2167
trainer/Log Pis Max                 7.73578
trainer/Log Pis Min                -1.42481
trainer/Policy mu Mean              0.16707
trainer/Policy mu Std               0.694067
trainer/Policy mu Max               3.27525
trainer/Policy mu Min              -2.5663
trainer/Policy log std Mean        -2.13862
trainer/Policy log std Std          0.465267
trainer/Policy log std Max         -0.490174
trainer/Policy log std Min         -2.45243
trainer/Alpha                       0.0543492
trainer/Alpha Loss                  0.250702
exploration/num steps total     77000
exploration/num paths total       770
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.591954
exploration/Rewards Std             1.67539
exploration/Rewards Max            -0.00587611
exploration/Rewards Min           -10.2535
exploration/Returns Mean          -59.1954
exploration/Returns Std             7.86534
exploration/Returns Max           -51.33
exploration/Returns Min           -67.0607
exploration/Actions Mean            0.045669
exploration/Actions Std             0.272394
exploration/Actions Max             0.999328
exploration/Actions Min            -0.920654
exploration/Num Paths               2
exploration/Average Returns       -59.1954
evaluation/num steps total     384000
evaluation/num paths total       3840
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.22547
evaluation/Rewards Std              1.07898
evaluation/Rewards Max             -0.00272818
evaluation/Rewards Min            -11.1833
evaluation/Returns Mean           -22.547
evaluation/Returns Std             18.5616
evaluation/Returns Max             -5.31668
evaluation/Returns Min            -60.8716
evaluation/Actions Mean             0.0422188
evaluation/Actions Std              0.195745
evaluation/Actions Max              0.997471
evaluation/Actions Min             -0.881737
evaluation/Num Paths               10
evaluation/Average Returns        -22.547
time/data storing (s)               0.00117437
time/evaluation sampling (s)        0.324589
time/exploration sampling (s)       0.0636874
time/logging (s)                    0.00345562
time/saving (s)                     0.00234582
time/training (s)                   1.1139
time/epoch (s)                      1.50915
time/total (s)                    554.049
Epoch                             383
-----------------------------  ---------------
2019-04-21 12:25:41.241087 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 384 finished
-----------------------------  ---------------
replay_buffer/size              77200
trainer/QF1 Loss                    0.032986
trainer/QF2 Loss                    0.0206246
trainer/Policy Loss                 8.35889
trainer/Q1 Predictions Mean        -6.61115
trainer/Q1 Predictions Std          2.75151
trainer/Q1 Predictions Max         -5.94322
trainer/Q1 Predictions Min        -24.9867
trainer/Q2 Predictions Mean        -6.61239
trainer/Q2 Predictions Std          2.79857
trainer/Q2 Predictions Max         -5.95102
trainer/Q2 Predictions Min        -25.7911
trainer/Q Targets Mean             -6.68083
trainer/Q Targets Std               2.75455
trainer/Q Targets Max              -5.95638
trainer/Q Targets Min             -25.9703
trainer/Log Pis Mean                1.83201
trainer/Log Pis Std                 1.07863
trainer/Log Pis Max                 7.16537
trainer/Log Pis Min                -1.32152
trainer/Policy mu Mean              0.0709982
trainer/Policy mu Std               0.508085
trainer/Policy mu Max               3.09744
trainer/Policy mu Min              -2.64487
trainer/Policy log std Mean        -2.18311
trainer/Policy log std Std          0.349503
trainer/Policy log std Max         -0.57077
trainer/Policy log std Min         -2.42393
trainer/Alpha                       0.0530584
trainer/Alpha Loss                 -0.493238
exploration/num steps total     77200
exploration/num paths total       772
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.212815
exploration/Rewards Std             0.49013
exploration/Rewards Max            -0.00607666
exploration/Rewards Min            -4.66037
exploration/Returns Mean          -21.2815
exploration/Returns Std             5.0185
exploration/Returns Max           -16.263
exploration/Returns Min           -26.3
exploration/Actions Mean           -0.00711088
exploration/Actions Std             0.215237
exploration/Actions Max             0.992328
exploration/Actions Min            -0.993654
exploration/Num Paths               2
exploration/Average Returns       -21.2815
evaluation/num steps total     385000
evaluation/num paths total       3850
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.1627
evaluation/Rewards Std              0.789136
evaluation/Rewards Max             -0.00879132
evaluation/Rewards Min             -8.37642
evaluation/Returns Mean           -16.27
evaluation/Returns Std              8.3619
evaluation/Returns Max             -2.00788
evaluation/Returns Min            -31.8672
evaluation/Actions Mean             0.013831
evaluation/Actions Std              0.187461
evaluation/Actions Max              0.995301
evaluation/Actions Min             -0.99683
evaluation/Num Paths               10
evaluation/Average Returns        -16.27
time/data storing (s)               0.00157758
time/evaluation sampling (s)        0.332915
time/exploration sampling (s)       0.10462
time/logging (s)                    0.00330318
time/saving (s)                     0.00250315
time/training (s)                   1.05818
time/epoch (s)                      1.5031
time/total (s)                    555.555
Epoch                             384
-----------------------------  ---------------
2019-04-21 12:25:42.767499 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 385 finished
-----------------------------  ----------------
replay_buffer/size              77400
trainer/QF1 Loss                    0.355992
trainer/QF2 Loss                    0.367486
trainer/Policy Loss                 8.43897
trainer/Q1 Predictions Mean        -6.49962
trainer/Q1 Predictions Std          2.92334
trainer/Q1 Predictions Max         -5.89053
trainer/Q1 Predictions Min        -31.3924
trainer/Q2 Predictions Mean        -6.43741
trainer/Q2 Predictions Std          2.92495
trainer/Q2 Predictions Max         -5.8152
trainer/Q2 Predictions Min        -31.297
trainer/Q Targets Mean             -6.54023
trainer/Q Targets Std               2.96308
trainer/Q Targets Max              -0.0773003
trainer/Q Targets Min             -31.4261
trainer/Log Pis Mean                1.98046
trainer/Log Pis Std                 1.00344
trainer/Log Pis Max                 6.4971
trainer/Log Pis Min                -0.980666
trainer/Policy mu Mean              0.000844604
trainer/Policy mu Std               0.465175
trainer/Policy mu Max               2.95156
trainer/Policy mu Min              -3.21979
trainer/Policy log std Mean        -2.24418
trainer/Policy log std Std          0.334689
trainer/Policy log std Max         -0.420599
trainer/Policy log std Min         -2.45758
trainer/Alpha                       0.0536084
trainer/Alpha Loss                 -0.0571829
exploration/num steps total     77400
exploration/num paths total       774
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.301695
exploration/Rewards Std             0.958603
exploration/Rewards Max            -0.00640341
exploration/Rewards Min            -7.99609
exploration/Returns Mean          -30.1695
exploration/Returns Std            16.005
exploration/Returns Max           -14.1645
exploration/Returns Min           -46.1745
exploration/Actions Mean            0.0127772
exploration/Actions Std             0.205492
exploration/Actions Max             0.996178
exploration/Actions Min            -0.950805
exploration/Num Paths               2
exploration/Average Returns       -30.1695
evaluation/num steps total     386000
evaluation/num paths total       3860
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.177289
evaluation/Rewards Std              0.766988
evaluation/Rewards Max             -0.0344646
evaluation/Rewards Min             -8.29648
evaluation/Returns Mean           -17.7289
evaluation/Returns Std             11.9308
evaluation/Returns Max             -5.02674
evaluation/Returns Min            -43.0058
evaluation/Actions Mean             0.0272731
evaluation/Actions Std              0.174276
evaluation/Actions Max              0.99632
evaluation/Actions Min             -0.991179
evaluation/Num Paths               10
evaluation/Average Returns        -17.7289
time/data storing (s)               0.001526
time/evaluation sampling (s)        0.26663
time/exploration sampling (s)       0.069995
time/logging (s)                    0.00351527
time/saving (s)                     0.0026139
time/training (s)                   1.1733
time/epoch (s)                      1.51758
time/total (s)                    557.078
Epoch                             385
-----------------------------  ----------------
2019-04-21 12:25:44.176270 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 386 finished
-----------------------------  ---------------
replay_buffer/size              77600
trainer/QF1 Loss                    0.703901
trainer/QF2 Loss                    0.705307
trainer/Policy Loss                 8.23672
trainer/Q1 Predictions Mean        -6.3134
trainer/Q1 Predictions Std          1.84677
trainer/Q1 Predictions Max         -5.83127
trainer/Q1 Predictions Min        -19.1907
trainer/Q2 Predictions Mean        -6.39119
trainer/Q2 Predictions Std          1.85156
trainer/Q2 Predictions Max         -5.90934
trainer/Q2 Predictions Min        -19.2464
trainer/Q Targets Mean             -6.34559
trainer/Q Targets Std               2.03085
trainer/Q Targets Max              -0.0952488
trainer/Q Targets Min             -19.1783
trainer/Log Pis Mean                1.88152
trainer/Log Pis Std                 1.40471
trainer/Log Pis Max                 5.47061
trainer/Log Pis Min                -5.77057
trainer/Policy mu Mean              0.0333715
trainer/Policy mu Std               0.479909
trainer/Policy mu Max               2.8708
trainer/Policy mu Min              -1.78061
trainer/Policy log std Mean        -2.30176
trainer/Policy log std Std          0.365658
trainer/Policy log std Max         -0.604793
trainer/Policy log std Min         -2.47965
trainer/Alpha                       0.0547861
trainer/Alpha Loss                 -0.344128
exploration/num steps total     77600
exploration/num paths total       776
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.308336
exploration/Rewards Std             0.920239
exploration/Rewards Max            -0.0160221
exploration/Rewards Min            -7.81081
exploration/Returns Mean          -30.8336
exploration/Returns Std            11.8755
exploration/Returns Max           -18.9581
exploration/Returns Min           -42.709
exploration/Actions Mean            0.0417124
exploration/Actions Std             0.233115
exploration/Actions Max             0.998141
exploration/Actions Min            -0.417252
exploration/Num Paths               2
exploration/Average Returns       -30.8336
evaluation/num steps total     387000
evaluation/num paths total       3870
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.308541
evaluation/Rewards Std              1.2255
evaluation/Rewards Max             -0.0109089
evaluation/Rewards Min             -9.92407
evaluation/Returns Mean           -30.8541
evaluation/Returns Std             14.2291
evaluation/Returns Max            -10.1915
evaluation/Returns Min            -55.7298
evaluation/Actions Mean             0.0283481
evaluation/Actions Std              0.223023
evaluation/Actions Max              0.996277
evaluation/Actions Min             -0.994892
evaluation/Num Paths               10
evaluation/Average Returns        -30.8541
time/data storing (s)               0.00124361
time/evaluation sampling (s)        0.28377
time/exploration sampling (s)       0.0749099
time/logging (s)                    0.00463862
time/saving (s)                     0.0126054
time/training (s)                   1.0227
time/epoch (s)                      1.39987
time/total (s)                    558.482
Epoch                             386
-----------------------------  ---------------
2019-04-21 12:25:45.698684 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 387 finished
-----------------------------  ---------------
replay_buffer/size              77800
trainer/QF1 Loss                    0.745567
trainer/QF2 Loss                    0.758178
trainer/Policy Loss                 9.28845
trainer/Q1 Predictions Mean        -7.31413
trainer/Q1 Predictions Std          5.90722
trainer/Q1 Predictions Max         -5.76997
trainer/Q1 Predictions Min        -51.109
trainer/Q2 Predictions Mean        -7.29009
trainer/Q2 Predictions Std          5.86674
trainer/Q2 Predictions Max         -5.73088
trainer/Q2 Predictions Min        -50.4564
trainer/Q Targets Mean             -7.41246
trainer/Q Targets Std               5.99239
trainer/Q Targets Max              -0.0657341
trainer/Q Targets Min             -50.8843
trainer/Log Pis Mean                2.03734
trainer/Log Pis Std                 1.23143
trainer/Log Pis Max                 6.40251
trainer/Log Pis Min                -2.67237
trainer/Policy mu Mean              0.0886176
trainer/Policy mu Std               0.688571
trainer/Policy mu Max               3.07842
trainer/Policy mu Min              -2.21492
trainer/Policy log std Mean        -2.17977
trainer/Policy log std Std          0.492097
trainer/Policy log std Max         -0.552407
trainer/Policy log std Min         -2.50913
trainer/Alpha                       0.0575199
trainer/Alpha Loss                  0.10663
exploration/num steps total     77800
exploration/num paths total       778
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.185413
exploration/Rewards Std             0.413736
exploration/Rewards Max            -0.00655067
exploration/Rewards Min            -4.25606
exploration/Returns Mean          -18.5413
exploration/Returns Std             5.1745
exploration/Returns Max           -13.3668
exploration/Returns Min           -23.7158
exploration/Actions Mean            0.00350364
exploration/Actions Std             0.18356
exploration/Actions Max             0.995649
exploration/Actions Min            -0.982759
exploration/Num Paths               2
exploration/Average Returns       -18.5413
evaluation/num steps total     388000
evaluation/num paths total       3880
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.20559
evaluation/Rewards Std              0.930971
evaluation/Rewards Max             -0.0182401
evaluation/Rewards Min             -9.84652
evaluation/Returns Mean           -20.559
evaluation/Returns Std             17.0191
evaluation/Returns Max             -4.19224
evaluation/Returns Min            -56.2721
evaluation/Actions Mean             0.0159991
evaluation/Actions Std              0.182731
evaluation/Actions Max              0.995286
evaluation/Actions Min             -0.991856
evaluation/Num Paths               10
evaluation/Average Returns        -20.559
time/data storing (s)               0.00115502
time/evaluation sampling (s)        0.345107
time/exploration sampling (s)       0.0633726
time/logging (s)                    0.00363133
time/saving (s)                     0.00232424
time/training (s)                   1.09242
time/epoch (s)                      1.50801
time/total (s)                    559.996
Epoch                             387
-----------------------------  ---------------
2019-04-21 12:25:47.343284 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 388 finished
-----------------------------  ---------------
replay_buffer/size              78000
trainer/QF1 Loss                    0.364625
trainer/QF2 Loss                    0.360443
trainer/Policy Loss                 8.62728
trainer/Q1 Predictions Mean        -6.80845
trainer/Q1 Predictions Std          4.80032
trainer/Q1 Predictions Max         -5.90321
trainer/Q1 Predictions Min        -51.1238
trainer/Q2 Predictions Mean        -6.82988
trainer/Q2 Predictions Std          4.76043
trainer/Q2 Predictions Max         -5.93614
trainer/Q2 Predictions Min        -50.7429
trainer/Q Targets Mean             -6.81218
trainer/Q Targets Std               4.80593
trainer/Q Targets Max              -0.00374041
trainer/Q Targets Min             -50.7972
trainer/Log Pis Mean                1.82759
trainer/Log Pis Std                 1.13621
trainer/Log Pis Max                 4.70871
trainer/Log Pis Min                -3.28068
trainer/Policy mu Mean              0.0617522
trainer/Policy mu Std               0.484868
trainer/Policy mu Max               3.05175
trainer/Policy mu Min              -2.05252
trainer/Policy log std Mean        -2.26238
trainer/Policy log std Std          0.354788
trainer/Policy log std Max         -0.616304
trainer/Policy log std Min         -2.43545
trainer/Alpha                       0.0575628
trainer/Alpha Loss                 -0.492216
exploration/num steps total     78000
exploration/num paths total       780
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.250644
exploration/Rewards Std             0.755934
exploration/Rewards Max            -0.0205682
exploration/Rewards Min            -6.69119
exploration/Returns Mean          -25.0644
exploration/Returns Std            12.2334
exploration/Returns Max           -12.8311
exploration/Returns Min           -37.2978
exploration/Actions Mean            0.0106501
exploration/Actions Std             0.204149
exploration/Actions Max             0.998985
exploration/Actions Min            -0.993401
exploration/Num Paths               2
exploration/Average Returns       -25.0644
evaluation/num steps total     389000
evaluation/num paths total       3890
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.270889
evaluation/Rewards Std              1.1174
evaluation/Rewards Max             -0.0281073
evaluation/Rewards Min             -9.67576
evaluation/Returns Mean           -27.0889
evaluation/Returns Std             16.8312
evaluation/Returns Max             -4.36032
evaluation/Returns Min            -56.0956
evaluation/Actions Mean             0.0233729
evaluation/Actions Std              0.205882
evaluation/Actions Max              0.995958
evaluation/Actions Min             -0.99666
evaluation/Num Paths               10
evaluation/Average Returns        -27.0889
time/data storing (s)               0.00121378
time/evaluation sampling (s)        0.258098
time/exploration sampling (s)       0.0698961
time/logging (s)                    0.00366205
time/saving (s)                     0.00253162
time/training (s)                   1.29949
time/epoch (s)                      1.63489
time/total (s)                    561.635
Epoch                             388
-----------------------------  ---------------
2019-04-21 12:25:48.890068 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 389 finished
-----------------------------  ---------------
replay_buffer/size              78200
trainer/QF1 Loss                    0.366134
trainer/QF2 Loss                    0.36527
trainer/Policy Loss                 8.78948
trainer/Q1 Predictions Mean        -6.87886
trainer/Q1 Predictions Std          4.71285
trainer/Q1 Predictions Max         -6.01161
trainer/Q1 Predictions Min        -52.4787
trainer/Q2 Predictions Mean        -6.87294
trainer/Q2 Predictions Std          4.70889
trainer/Q2 Predictions Max         -6.00764
trainer/Q2 Predictions Min        -52.3344
trainer/Q Targets Mean             -6.80143
trainer/Q Targets Std               4.72191
trainer/Q Targets Max              -0.167296
trainer/Q Targets Min             -52.0241
trainer/Log Pis Mean                1.96956
trainer/Log Pis Std                 0.993552
trainer/Log Pis Max                 4.54999
trainer/Log Pis Min                -3.2864
trainer/Policy mu Mean              0.06995
trainer/Policy mu Std               0.505799
trainer/Policy mu Max               3.02242
trainer/Policy mu Min              -2.43497
trainer/Policy log std Mean        -2.22827
trainer/Policy log std Std          0.376829
trainer/Policy log std Max         -0.591529
trainer/Policy log std Min         -2.41702
trainer/Alpha                       0.0572844
trainer/Alpha Loss                 -0.087045
exploration/num steps total     78200
exploration/num paths total       782
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.205881
exploration/Rewards Std             0.626748
exploration/Rewards Max            -0.00644976
exploration/Rewards Min            -6.28799
exploration/Returns Mean          -20.5881
exploration/Returns Std             8.7703
exploration/Returns Max           -11.8178
exploration/Returns Min           -29.3584
exploration/Actions Mean           -0.00267904
exploration/Actions Std             0.198467
exploration/Actions Max             0.997835
exploration/Actions Min            -0.997186
exploration/Num Paths               2
exploration/Average Returns       -20.5881
evaluation/num steps total     390000
evaluation/num paths total       3900
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.197974
evaluation/Rewards Std              0.976811
evaluation/Rewards Max             -0.00941406
evaluation/Rewards Min            -10.9554
evaluation/Returns Mean           -19.7974
evaluation/Returns Std             17.6649
evaluation/Returns Max             -2.998
evaluation/Returns Min            -60.4096
evaluation/Actions Mean             0.0261276
evaluation/Actions Std              0.193435
evaluation/Actions Max              0.996966
evaluation/Actions Min             -0.994296
evaluation/Num Paths               10
evaluation/Average Returns        -19.7974
time/data storing (s)               0.00121675
time/evaluation sampling (s)        0.300113
time/exploration sampling (s)       0.0743019
time/logging (s)                    0.00293706
time/saving (s)                     0.00231199
time/training (s)                   1.1546
time/epoch (s)                      1.53548
time/total (s)                    563.175
Epoch                             389
-----------------------------  ---------------
2019-04-21 12:25:50.638842 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 390 finished
-----------------------------  ---------------
replay_buffer/size              78400
trainer/QF1 Loss                    0.0199897
trainer/QF2 Loss                    0.0120114
trainer/Policy Loss                 8.6706
trainer/Q1 Predictions Mean        -6.6823
trainer/Q1 Predictions Std          2.93671
trainer/Q1 Predictions Max         -5.8808
trainer/Q1 Predictions Min        -26.2079
trainer/Q2 Predictions Mean        -6.7403
trainer/Q2 Predictions Std          2.95073
trainer/Q2 Predictions Max         -5.92632
trainer/Q2 Predictions Min        -26.4436
trainer/Q Targets Mean             -6.79242
trainer/Q Targets Std               2.92956
trainer/Q Targets Max              -5.90942
trainer/Q Targets Min             -26.0282
trainer/Log Pis Mean                2.14391
trainer/Log Pis Std                 1.00654
trainer/Log Pis Max                 5.29127
trainer/Log Pis Min                -0.866149
trainer/Policy mu Mean              0.112283
trainer/Policy mu Std               0.511783
trainer/Policy mu Max               2.79832
trainer/Policy mu Min              -2.05128
trainer/Policy log std Mean        -2.27639
trainer/Policy log std Std          0.39097
trainer/Policy log std Max         -0.626031
trainer/Policy log std Min         -2.50853
trainer/Alpha                       0.0572782
trainer/Alpha Loss                  0.411594
exploration/num steps total     78400
exploration/num paths total       784
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.201273
exploration/Rewards Std             0.529098
exploration/Rewards Max            -0.0059934
exploration/Rewards Min            -5.15061
exploration/Returns Mean          -20.1273
exploration/Returns Std             7.04101
exploration/Returns Max           -13.0863
exploration/Returns Min           -27.1683
exploration/Actions Mean           -0.00652907
exploration/Actions Std             0.185665
exploration/Actions Max             0.981851
exploration/Actions Min            -0.998916
exploration/Num Paths               2
exploration/Average Returns       -20.1273
evaluation/num steps total     391000
evaluation/num paths total       3910
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.20629
evaluation/Rewards Std              0.841938
evaluation/Rewards Max             -0.049121
evaluation/Rewards Min             -9.58986
evaluation/Returns Mean           -20.629
evaluation/Returns Std             12.355
evaluation/Returns Max             -6.21925
evaluation/Returns Min            -49.4193
evaluation/Actions Mean             0.0192702
evaluation/Actions Std              0.187181
evaluation/Actions Max              0.997477
evaluation/Actions Min             -0.988645
evaluation/Num Paths               10
evaluation/Average Returns        -20.629
time/data storing (s)               0.00194758
time/evaluation sampling (s)        0.277467
time/exploration sampling (s)       0.109736
time/logging (s)                    0.00371915
time/saving (s)                     0.00299752
time/training (s)                   1.34366
time/epoch (s)                      1.73953
time/total (s)                    564.919
Epoch                             390
-----------------------------  ---------------
2019-04-21 12:25:52.104707 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 391 finished
-----------------------------  ---------------
replay_buffer/size              78600
trainer/QF1 Loss                    0.710584
trainer/QF2 Loss                    0.711761
trainer/Policy Loss                 8.51083
trainer/Q1 Predictions Mean        -6.67336
trainer/Q1 Predictions Std          3.95126
trainer/Q1 Predictions Max         -5.94708
trainer/Q1 Predictions Min        -42.056
trainer/Q2 Predictions Mean        -6.65951
trainer/Q2 Predictions Std          3.95948
trainer/Q2 Predictions Max         -5.92545
trainer/Q2 Predictions Min        -42.1604
trainer/Q Targets Mean             -6.59185
trainer/Q Targets Std               4.01553
trainer/Q Targets Max              -0.0426127
trainer/Q Targets Min             -41.5965
trainer/Log Pis Mean                1.88686
trainer/Log Pis Std                 1.15105
trainer/Log Pis Max                 6.10176
trainer/Log Pis Min                -1.95549
trainer/Policy mu Mean              0.0565122
trainer/Policy mu Std               0.469548
trainer/Policy mu Max               2.93547
trainer/Policy mu Min              -1.7886
trainer/Policy log std Mean        -2.24963
trainer/Policy log std Std          0.365102
trainer/Policy log std Max         -0.577993
trainer/Policy log std Min         -2.47228
trainer/Alpha                       0.0584899
trainer/Alpha Loss                 -0.321194
exploration/num steps total     78600
exploration/num paths total       786
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.43481
exploration/Rewards Std             1.37582
exploration/Rewards Max            -0.0136344
exploration/Rewards Min            -9.94932
exploration/Returns Mean          -43.481
exploration/Returns Std            23.1356
exploration/Returns Max           -20.3454
exploration/Returns Min           -66.6167
exploration/Actions Mean            0.0470952
exploration/Actions Std             0.242496
exploration/Actions Max             0.995968
exploration/Actions Min            -0.480279
exploration/Num Paths               2
exploration/Average Returns       -43.481
evaluation/num steps total     392000
evaluation/num paths total       3920
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.269656
evaluation/Rewards Std              1.22548
evaluation/Rewards Max             -0.00741363
evaluation/Rewards Min            -10.2618
evaluation/Returns Mean           -26.9656
evaluation/Returns Std             20.3425
evaluation/Returns Max             -2.23272
evaluation/Returns Min            -54.2238
evaluation/Actions Mean             0.0395379
evaluation/Actions Std              0.199728
evaluation/Actions Max              0.995449
evaluation/Actions Min             -0.979823
evaluation/Num Paths               10
evaluation/Average Returns        -26.9656
time/data storing (s)               0.00114763
time/evaluation sampling (s)        0.248939
time/exploration sampling (s)       0.0626891
time/logging (s)                    0.00342528
time/saving (s)                     0.00233743
time/training (s)                   1.13664
time/epoch (s)                      1.45518
time/total (s)                    566.379
Epoch                             391
-----------------------------  ---------------
2019-04-21 12:25:53.640247 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 392 finished
-----------------------------  ---------------
replay_buffer/size              78800
trainer/QF1 Loss                    0.364432
trainer/QF2 Loss                    0.362382
trainer/Policy Loss                 9.21617
trainer/Q1 Predictions Mean        -7.42553
trainer/Q1 Predictions Std          5.65915
trainer/Q1 Predictions Max         -5.93806
trainer/Q1 Predictions Min        -47.0826
trainer/Q2 Predictions Mean        -7.38586
trainer/Q2 Predictions Std          5.63778
trainer/Q2 Predictions Max         -5.88709
trainer/Q2 Predictions Min        -47.147
trainer/Q Targets Mean             -7.41069
trainer/Q Targets Std               5.635
trainer/Q Targets Max              -0.0774291
trainer/Q Targets Min             -46.5657
trainer/Log Pis Mean                1.86891
trainer/Log Pis Std                 1.27027
trainer/Log Pis Max                 6.40998
trainer/Log Pis Min                -1.06459
trainer/Policy mu Mean              0.0500202
trainer/Policy mu Std               0.625982
trainer/Policy mu Max               2.88388
trainer/Policy mu Min              -3.04836
trainer/Policy log std Mean        -2.14692
trainer/Policy log std Std          0.452084
trainer/Policy log std Max         -0.509592
trainer/Policy log std Min         -2.39106
trainer/Alpha                       0.0580733
trainer/Alpha Loss                 -0.373078
exploration/num steps total     78800
exploration/num paths total       788
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.565606
exploration/Rewards Std             1.5887
exploration/Rewards Max            -0.00964092
exploration/Rewards Min            -9.48072
exploration/Returns Mean          -56.5606
exploration/Returns Std             3.90881
exploration/Returns Max           -52.6518
exploration/Returns Min           -60.4694
exploration/Actions Mean            0.0524024
exploration/Actions Std             0.257589
exploration/Actions Max             0.999467
exploration/Actions Min            -0.566565
exploration/Num Paths               2
exploration/Average Returns       -56.5606
evaluation/num steps total     393000
evaluation/num paths total       3930
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.176168
evaluation/Rewards Std              0.961085
evaluation/Rewards Max             -0.00324839
evaluation/Rewards Min            -10.4326
evaluation/Returns Mean           -17.6168
evaluation/Returns Std             19.3923
evaluation/Returns Max             -0.600311
evaluation/Returns Min            -58.7237
evaluation/Actions Mean             0.0228738
evaluation/Actions Std              0.17255
evaluation/Actions Max              0.996185
evaluation/Actions Min             -0.983915
evaluation/Num Paths               10
evaluation/Average Returns        -17.6168
time/data storing (s)               0.00123756
time/evaluation sampling (s)        0.242241
time/exploration sampling (s)       0.063376
time/logging (s)                    0.00255907
time/saving (s)                     0.00230516
time/training (s)                   1.21305
time/epoch (s)                      1.52476
time/total (s)                    567.908
Epoch                             392
-----------------------------  ---------------
2019-04-21 12:25:55.104083 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 393 finished
-----------------------------  ---------------
replay_buffer/size              79000
trainer/QF1 Loss                    1.04898
trainer/QF2 Loss                    1.05586
trainer/Policy Loss                 8.52083
trainer/Q1 Predictions Mean        -6.53592
trainer/Q1 Predictions Std          3.31389
trainer/Q1 Predictions Max         -5.91051
trainer/Q1 Predictions Min        -38.0505
trainer/Q2 Predictions Mean        -6.52513
trainer/Q2 Predictions Std          3.33721
trainer/Q2 Predictions Max         -5.90924
trainer/Q2 Predictions Min        -38.3342
trainer/Q Targets Mean             -6.41264
trainer/Q Targets Std               3.51031
trainer/Q Targets Max              -0.097897
trainer/Q Targets Min             -38.3294
trainer/Log Pis Mean                2.00392
trainer/Log Pis Std                 0.968354
trainer/Log Pis Max                 6.05276
trainer/Log Pis Min                -0.369899
trainer/Policy mu Mean              0.0351081
trainer/Policy mu Std               0.474118
trainer/Policy mu Max               3.01487
trainer/Policy mu Min              -2.35326
trainer/Policy log std Mean        -2.24018
trainer/Policy log std Std          0.351805
trainer/Policy log std Max         -0.549848
trainer/Policy log std Min         -2.42274
trainer/Alpha                       0.0579056
trainer/Alpha Loss                  0.0111799
exploration/num steps total     79000
exploration/num paths total       790
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.220786
exploration/Rewards Std             0.562032
exploration/Rewards Max            -0.0123471
exploration/Rewards Min            -4.46458
exploration/Returns Mean          -22.0786
exploration/Returns Std             2.08984
exploration/Returns Max           -19.9888
exploration/Returns Min           -24.1685
exploration/Actions Mean            0.00434229
exploration/Actions Std             0.225596
exploration/Actions Max             0.99555
exploration/Actions Min            -0.998627
exploration/Num Paths               2
exploration/Average Returns       -22.0786
evaluation/num steps total     394000
evaluation/num paths total       3940
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.127403
evaluation/Rewards Std              0.733399
evaluation/Rewards Max             -0.00202932
evaluation/Rewards Min             -9.45756
evaluation/Returns Mean           -12.7403
evaluation/Returns Std             11.0819
evaluation/Returns Max             -2.54114
evaluation/Returns Min            -40.9398
evaluation/Actions Mean             0.0110878
evaluation/Actions Std              0.179795
evaluation/Actions Max              0.997405
evaluation/Actions Min             -0.99779
evaluation/Num Paths               10
evaluation/Average Returns        -12.7403
time/data storing (s)               0.00120986
time/evaluation sampling (s)        0.265567
time/exploration sampling (s)       0.0664826
time/logging (s)                    0.00276302
time/saving (s)                     0.00232181
time/training (s)                   1.11621
time/epoch (s)                      1.45455
time/total (s)                    569.367
Epoch                             393
-----------------------------  ---------------
2019-04-21 12:25:56.428330 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 394 finished
-----------------------------  ---------------
replay_buffer/size              79200
trainer/QF1 Loss                    0.363451
trainer/QF2 Loss                    0.370036
trainer/Policy Loss                 8.92971
trainer/Q1 Predictions Mean        -7.09518
trainer/Q1 Predictions Std          4.07649
trainer/Q1 Predictions Max         -5.9905
trainer/Q1 Predictions Min        -35.4632
trainer/Q2 Predictions Mean        -7.11586
trainer/Q2 Predictions Std          4.06715
trainer/Q2 Predictions Max         -5.99216
trainer/Q2 Predictions Min        -35.2949
trainer/Q Targets Mean             -7.01873
trainer/Q Targets Std               4.09683
trainer/Q Targets Max              -0.18282
trainer/Q Targets Min             -35.2827
trainer/Log Pis Mean                1.9429
trainer/Log Pis Std                 1.15895
trainer/Log Pis Max                 6.0143
trainer/Log Pis Min                -1.21935
trainer/Policy mu Mean              0.0873853
trainer/Policy mu Std               0.584532
trainer/Policy mu Max               2.83477
trainer/Policy mu Min              -1.64602
trainer/Policy log std Mean        -2.1737
trainer/Policy log std Std          0.453206
trainer/Policy log std Max         -0.513765
trainer/Policy log std Min         -2.43812
trainer/Alpha                       0.0583806
trainer/Alpha Loss                 -0.162214
exploration/num steps total     79200
exploration/num paths total       792
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.268133
exploration/Rewards Std             0.736839
exploration/Rewards Max            -0.00519814
exploration/Rewards Min            -5.88183
exploration/Returns Mean          -26.8133
exploration/Returns Std             2.24928
exploration/Returns Max           -24.564
exploration/Returns Min           -29.0626
exploration/Actions Mean            0.0128
exploration/Actions Std             0.235063
exploration/Actions Max             0.998708
exploration/Actions Min            -0.993365
exploration/Num Paths               2
exploration/Average Returns       -26.8133
evaluation/num steps total     395000
evaluation/num paths total       3950
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.16329
evaluation/Rewards Std              0.787703
evaluation/Rewards Max             -0.0117189
evaluation/Rewards Min             -8.24629
evaluation/Returns Mean           -16.329
evaluation/Returns Std             10.7365
evaluation/Returns Max             -3.62842
evaluation/Returns Min            -37.3432
evaluation/Actions Mean             0.017923
evaluation/Actions Std              0.182561
evaluation/Actions Max              0.99542
evaluation/Actions Min             -0.995734
evaluation/Num Paths               10
evaluation/Average Returns        -16.329
time/data storing (s)               0.00117041
time/evaluation sampling (s)        0.235869
time/exploration sampling (s)       0.0619468
time/logging (s)                    0.00356021
time/saving (s)                     0.00234757
time/training (s)                   1.01075
time/epoch (s)                      1.31564
time/total (s)                    570.687
Epoch                             394
-----------------------------  ---------------
2019-04-21 12:25:57.925212 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 395 finished
-----------------------------  ---------------
replay_buffer/size              79400
trainer/QF1 Loss                    0.784871
trainer/QF2 Loss                    0.740417
trainer/Policy Loss                 8.74118
trainer/Q1 Predictions Mean        -6.96226
trainer/Q1 Predictions Std          5.6463
trainer/Q1 Predictions Max         -5.88248
trainer/Q1 Predictions Min        -59.682
trainer/Q2 Predictions Mean        -6.95789
trainer/Q2 Predictions Std          5.73557
trainer/Q2 Predictions Max         -5.86644
trainer/Q2 Predictions Min        -60.5688
trainer/Q Targets Mean             -6.95459
trainer/Q Targets Std               5.98253
trainer/Q Targets Max              -0.0659945
trainer/Q Targets Min             -62.5534
trainer/Log Pis Mean                1.95896
trainer/Log Pis Std                 0.98062
trainer/Log Pis Max                 4.28699
trainer/Log Pis Min                -1.58209
trainer/Policy mu Mean              0.0905523
trainer/Policy mu Std               0.483655
trainer/Policy mu Max               2.74207
trainer/Policy mu Min              -1.46751
trainer/Policy log std Mean        -2.26499
trainer/Policy log std Std          0.383443
trainer/Policy log std Max         -0.584305
trainer/Policy log std Min         -2.45506
trainer/Alpha                       0.0586485
trainer/Alpha Loss                 -0.116392
exploration/num steps total     79400
exploration/num paths total       794
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.318178
exploration/Rewards Std             1.09944
exploration/Rewards Max            -0.0017527
exploration/Rewards Min            -8.73308
exploration/Returns Mean          -31.8178
exploration/Returns Std            21.0974
exploration/Returns Max           -10.7203
exploration/Returns Min           -52.9152
exploration/Actions Mean            0.0306198
exploration/Actions Std             0.203166
exploration/Actions Max             0.997678
exploration/Actions Min            -0.596359
exploration/Num Paths               2
exploration/Average Returns       -31.8178
evaluation/num steps total     396000
evaluation/num paths total       3960
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.126683
evaluation/Rewards Std              0.63298
evaluation/Rewards Max             -0.0194191
evaluation/Rewards Min             -7.35166
evaluation/Returns Mean           -12.6683
evaluation/Returns Std              8.14839
evaluation/Returns Max             -2.13555
evaluation/Returns Min            -32.6307
evaluation/Actions Mean             0.0178527
evaluation/Actions Std              0.174073
evaluation/Actions Max              0.990766
evaluation/Actions Min             -0.99081
evaluation/Num Paths               10
evaluation/Average Returns        -12.6683
time/data storing (s)               0.00117319
time/evaluation sampling (s)        0.342707
time/exploration sampling (s)       0.0649827
time/logging (s)                    0.00356287
time/saving (s)                     0.00238801
time/training (s)                   1.07225
time/epoch (s)                      1.48707
time/total (s)                    572.179
Epoch                             395
-----------------------------  ---------------
2019-04-21 12:25:59.228520 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 396 finished
-----------------------------  ---------------
replay_buffer/size              79600
trainer/QF1 Loss                    0.0354338
trainer/QF2 Loss                    0.0224177
trainer/Policy Loss                 8.85405
trainer/Q1 Predictions Mean        -6.98704
trainer/Q1 Predictions Std          6.03066
trainer/Q1 Predictions Max         -5.94231
trainer/Q1 Predictions Min        -63.0121
trainer/Q2 Predictions Mean        -6.94491
trainer/Q2 Predictions Std          6.1806
trainer/Q2 Predictions Max         -5.88544
trainer/Q2 Predictions Min        -64.5744
trainer/Q Targets Mean             -7.05031
trainer/Q Targets Std               6.18847
trainer/Q Targets Max              -5.91473
trainer/Q Targets Min             -64.5317
trainer/Log Pis Mean                2.04078
trainer/Log Pis Std                 0.991049
trainer/Log Pis Max                 6.30861
trainer/Log Pis Min                -1.28412
trainer/Policy mu Mean              0.0272533
trainer/Policy mu Std               0.477289
trainer/Policy mu Max               3.19742
trainer/Policy mu Min              -1.1192
trainer/Policy log std Mean        -2.23696
trainer/Policy log std Std          0.31753
trainer/Policy log std Max         -0.694062
trainer/Policy log std Min         -2.43465
trainer/Alpha                       0.0558088
trainer/Alpha Loss                  0.117686
exploration/num steps total     79600
exploration/num paths total       796
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.459511
exploration/Rewards Std             1.41344
exploration/Rewards Max            -0.00934713
exploration/Rewards Min           -10.2779
exploration/Returns Mean          -45.9511
exploration/Returns Std            23.2803
exploration/Returns Max           -22.6708
exploration/Returns Min           -69.2314
exploration/Actions Mean            0.035438
exploration/Actions Std             0.23974
exploration/Actions Max             0.998562
exploration/Actions Min            -0.801533
exploration/Num Paths               2
exploration/Average Returns       -45.9511
evaluation/num steps total     397000
evaluation/num paths total       3970
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.190434
evaluation/Rewards Std              0.737286
evaluation/Rewards Max             -0.0460059
evaluation/Rewards Min             -7.61903
evaluation/Returns Mean           -19.0434
evaluation/Returns Std             10.6422
evaluation/Returns Max             -6.40978
evaluation/Returns Min            -38.8766
evaluation/Actions Mean             0.0232577
evaluation/Actions Std              0.174914
evaluation/Actions Max              0.994925
evaluation/Actions Min             -0.987239
evaluation/Num Paths               10
evaluation/Average Returns        -19.0434
time/data storing (s)               0.00113043
time/evaluation sampling (s)        0.245051
time/exploration sampling (s)       0.0590343
time/logging (s)                    0.00344384
time/saving (s)                     0.00232529
time/training (s)                   0.982161
time/epoch (s)                      1.29315
time/total (s)                    573.476
Epoch                             396
-----------------------------  ---------------
2019-04-21 12:26:00.680963 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 397 finished
-----------------------------  ---------------
replay_buffer/size              79800
trainer/QF1 Loss                    0.0393685
trainer/QF2 Loss                    0.0402876
trainer/Policy Loss                10.8511
trainer/Q1 Predictions Mean        -8.66042
trainer/Q1 Predictions Std          8.22749
trainer/Q1 Predictions Max         -5.97107
trainer/Q1 Predictions Min        -56.3307
trainer/Q2 Predictions Mean        -8.67094
trainer/Q2 Predictions Std          8.16438
trainer/Q2 Predictions Max         -6.001
trainer/Q2 Predictions Min        -55.5727
trainer/Q Targets Mean             -8.64251
trainer/Q Targets Std               8.19851
trainer/Q Targets Max              -5.88336
trainer/Q Targets Min             -56.0813
trainer/Log Pis Mean                2.38621
trainer/Log Pis Std                 1.39763
trainer/Log Pis Max                 8.58847
trainer/Log Pis Min                -1.43766
trainer/Policy mu Mean              0.163136
trainer/Policy mu Std               0.810155
trainer/Policy mu Max               3.23798
trainer/Policy mu Min              -2.28157
trainer/Policy log std Mean        -2.09585
trainer/Policy log std Std          0.549031
trainer/Policy log std Max         -0.47317
trainer/Policy log std Min         -2.46335
trainer/Alpha                       0.0565179
trainer/Alpha Loss                  1.10972
exploration/num steps total     79800
exploration/num paths total       798
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.508269
exploration/Rewards Std             1.49681
exploration/Rewards Max            -0.00600745
exploration/Rewards Min            -9.98143
exploration/Returns Mean          -50.8269
exploration/Returns Std             8.02666
exploration/Returns Max           -42.8002
exploration/Returns Min           -58.8536
exploration/Actions Mean            0.067768
exploration/Actions Std             0.276099
exploration/Actions Max             0.999662
exploration/Actions Min            -0.351098
exploration/Num Paths               2
exploration/Average Returns       -50.8269
evaluation/num steps total     398000
evaluation/num paths total       3980
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.188065
evaluation/Rewards Std              0.903193
evaluation/Rewards Max             -0.00914922
evaluation/Rewards Min             -9.216
evaluation/Returns Mean           -18.8065
evaluation/Returns Std             15.0691
evaluation/Returns Max             -2.09769
evaluation/Returns Min            -48.7566
evaluation/Actions Mean             0.0312795
evaluation/Actions Std              0.176191
evaluation/Actions Max              0.99742
evaluation/Actions Min             -0.931062
evaluation/Num Paths               10
evaluation/Average Returns        -18.8065
time/data storing (s)               0.00107542
time/evaluation sampling (s)        0.241531
time/exploration sampling (s)       0.0595045
time/logging (s)                    0.0045387
time/saving (s)                     0.00416519
time/training (s)                   1.13268
time/epoch (s)                      1.44349
time/total (s)                    574.925
Epoch                             397
-----------------------------  ---------------
2019-04-21 12:26:02.067801 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 398 finished
-----------------------------  ---------------
replay_buffer/size              80000
trainer/QF1 Loss                    0.751652
trainer/QF2 Loss                    0.759911
trainer/Policy Loss                 8.64396
trainer/Q1 Predictions Mean        -6.69636
trainer/Q1 Predictions Std          3.59221
trainer/Q1 Predictions Max         -5.93325
trainer/Q1 Predictions Min        -36.4054
trainer/Q2 Predictions Mean        -6.70073
trainer/Q2 Predictions Std          3.60191
trainer/Q2 Predictions Max         -5.93895
trainer/Q2 Predictions Min        -36.5795
trainer/Q Targets Mean             -6.56325
trainer/Q Targets Std               3.53028
trainer/Q Targets Max              -0.0266738
trainer/Q Targets Min             -34.2199
trainer/Log Pis Mean                2.10325
trainer/Log Pis Std                 1.08143
trainer/Log Pis Max                 5.78369
trainer/Log Pis Min                -2.98646
trainer/Policy mu Mean              0.0676769
trainer/Policy mu Std               0.470257
trainer/Policy mu Max               2.97336
trainer/Policy mu Min              -1.6336
trainer/Policy log std Mean        -2.32579
trainer/Policy log std Std          0.367148
trainer/Policy log std Max         -0.578041
trainer/Policy log std Min         -2.53936
trainer/Alpha                       0.0567246
trainer/Alpha Loss                  0.296299
exploration/num steps total     80000
exploration/num paths total       800
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.237885
exploration/Rewards Std             0.702038
exploration/Rewards Max            -0.0107682
exploration/Rewards Min            -6.34358
exploration/Returns Mean          -23.7885
exploration/Returns Std             9.50414
exploration/Returns Max           -14.2843
exploration/Returns Min           -33.2926
exploration/Actions Mean            0.0277408
exploration/Actions Std             0.203786
exploration/Actions Max             0.995806
exploration/Actions Min            -0.76807
exploration/Num Paths               2
exploration/Average Returns       -23.7885
evaluation/num steps total     399000
evaluation/num paths total       3990
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.143852
evaluation/Rewards Std              0.691704
evaluation/Rewards Max             -0.0031501
evaluation/Rewards Min             -8.36562
evaluation/Returns Mean           -14.3852
evaluation/Returns Std             10.8126
evaluation/Returns Max             -4.47114
evaluation/Returns Min            -40.0941
evaluation/Actions Mean             0.027193
evaluation/Actions Std              0.17417
evaluation/Actions Max              0.996261
evaluation/Actions Min             -0.977839
evaluation/Num Paths               10
evaluation/Average Returns        -14.3852
time/data storing (s)               0.0012178
time/evaluation sampling (s)        0.323547
time/exploration sampling (s)       0.0597952
time/logging (s)                    0.00343811
time/saving (s)                     0.00785867
time/training (s)                   0.976007
time/epoch (s)                      1.37186
time/total (s)                    576.301
Epoch                             398
-----------------------------  ---------------
2019-04-21 12:26:03.386675 PDT | [sac-pointmass-multitask-1_2019_04_21_12_16_24_0000--s-0] Epoch 399 finished
-----------------------------  ---------------
replay_buffer/size              80200
trainer/QF1 Loss                    0.0249826
trainer/QF2 Loss                    0.020791
trainer/Policy Loss                 8.29221
trainer/Q1 Predictions Mean        -6.48352
trainer/Q1 Predictions Std          2.28664
trainer/Q1 Predictions Max         -5.87145
trainer/Q1 Predictions Min        -20.8186
trainer/Q2 Predictions Mean        -6.49249
trainer/Q2 Predictions Std          2.27102
trainer/Q2 Predictions Max         -5.89213
trainer/Q2 Predictions Min        -20.8233
trainer/Q Targets Mean             -6.59326
trainer/Q Targets Std               2.28785
trainer/Q Targets Max              -5.87915
trainer/Q Targets Min             -21.0644
trainer/Log Pis Mean                1.81645
trainer/Log Pis Std                 1.22284
trainer/Log Pis Max                 6.72194
trainer/Log Pis Min                -2.82225
trainer/Policy mu Mean              0.044335
trainer/Policy mu Std               0.504362
trainer/Policy mu Max               2.75184
trainer/Policy mu Min              -2.73861
trainer/Policy log std Mean        -2.23911
trainer/Policy log std Std          0.369391
trainer/Policy log std Max         -0.586992
trainer/Policy log std Min         -2.42231
trainer/Alpha                       0.057766
trainer/Alpha Loss                 -0.523347
exploration/num steps total     80200
exploration/num paths total       802
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.349432
exploration/Rewards Std             1.07285
exploration/Rewards Max            -0.0221285
exploration/Rewards Min            -8.85454
exploration/Returns Mean          -34.9432
exploration/Returns Std            13.28
exploration/Returns Max           -21.6631
exploration/Returns Min           -48.2232
exploration/Actions Mean            0.0197276
exploration/Actions Std             0.262324
exploration/Actions Max             0.997637
exploration/Actions Min            -0.999006
exploration/Num Paths               2
exploration/Average Returns       -34.9432
evaluation/num steps total     400000
evaluation/num paths total       4000
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.268608
evaluation/Rewards Std              1.05938
evaluation/Rewards Max             -0.0214445
evaluation/Rewards Min             -9.86326
evaluation/Returns Mean           -26.8608
evaluation/Returns Std             16.2307
evaluation/Returns Max             -5.46623
evaluation/Returns Min            -58.4791
evaluation/Actions Mean             0.0359163
evaluation/Actions Std              0.194053
evaluation/Actions Max              0.995981
evaluation/Actions Min             -0.988014
evaluation/Num Paths               10
evaluation/Average Returns        -26.8608
time/data storing (s)               0.00114637
time/evaluation sampling (s)        0.242579
time/exploration sampling (s)       0.0602022
time/logging (s)                    0.00340882
time/saving (s)                     0.00236156
time/training (s)                   1.00064
time/epoch (s)                      1.31033
time/total (s)                    577.617
Epoch                             399
-----------------------------  ---------------
