2019-04-22 20:52:37.770954 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 0 finished
-----------------------------  --------------
replay_buffer/size              400
trainer/QF1 Loss                  0.989633
trainer/QF2 Loss                  1.00532
trainer/Policy Loss              -1.31752
trainer/Q1 Predictions Mean      -0.00653524
trainer/Q1 Predictions Std        0.00088782
trainer/Q1 Predictions Max       -0.00490805
trainer/Q1 Predictions Min       -0.00828762
trainer/Q2 Predictions Mean       0.00132401
trainer/Q2 Predictions Std        0.000569081
trainer/Q2 Predictions Max        0.00299376
trainer/Q2 Predictions Min        0.000247193
trainer/Q Targets Mean           -1.00099
trainer/Q Targets Std             0.0261981
trainer/Q Targets Max            -0.740596
trainer/Q Targets Min            -1.00467
trainer/Log Pis Mean             -1.3241
trainer/Log Pis Std               0.340056
trainer/Log Pis Max              -0.58625
trainer/Log Pis Min              -1.83047
trainer/Policy mu Mean           -0.00060162
trainer/Policy mu Std             0.000531165
trainer/Policy mu Max             0.000489407
trainer/Policy mu Min            -0.0014629
trainer/Policy log std Mean       0.000673632
trainer/Policy log std Std        0.000522193
trainer/Policy log std Max        0.00147599
trainer/Policy log std Min       -0.000263753
trainer/Alpha                     0.9997
trainer/Alpha Loss               -0
exploration/num steps total     400
exploration/num paths total       4
exploration/path length Mean    100
exploration/path length Std       0
exploration/path length Max     100
exploration/path length Min     100
exploration/Rewards Mean         -0.994446
exploration/Rewards Std           0.038295
exploration/Rewards Max          -0.59733
exploration/Rewards Min          -1
exploration/Returns Mean        -99.4446
exploration/Returns Std           0.555436
exploration/Returns Max         -98.8891
exploration/Returns Min        -100
exploration/Actions Mean         -0.00654711
exploration/Actions Std           0.648364
exploration/Actions Max           0.995554
exploration/Actions Min          -0.997869
exploration/Num Paths             2
exploration/Average Returns     -99.4446
evaluation/num steps total     1000
evaluation/num paths total       10
evaluation/path length Mean     100
evaluation/path length Std        0
evaluation/path length Max      100
evaluation/path length Min      100
evaluation/Rewards Mean          -1
evaluation/Rewards Std            0
evaluation/Rewards Max           -1
evaluation/Rewards Min           -1
evaluation/Returns Mean        -100
evaluation/Returns Std            0
evaluation/Returns Max         -100
evaluation/Returns Min         -100
evaluation/Actions Mean          -0.000633087
evaluation/Actions Std            0.000704659
evaluation/Actions Max            0.000439668
evaluation/Actions Min           -0.00175094
evaluation/Num Paths             10
evaluation/Average Returns     -100
time/data storing (s)             0.00113037
time/evaluation sampling (s)      0.22413
time/exploration sampling (s)     0.0651808
time/logging (s)                  0.00353916
time/saving (s)                   0.00287431
time/training (s)                 0.993579
time/epoch (s)                    1.29043
time/total (s)                    1.57776
Epoch                             0
-----------------------------  --------------
2019-04-22 20:52:39.091499 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 1 finished
-----------------------------  -------------
replay_buffer/size              600
trainer/QF1 Loss                  0.0537551
trainer/QF2 Loss                  0.0670132
trainer/Policy Loss              -0.105094
trainer/Q1 Predictions Mean      -1.24955
trainer/Q1 Predictions Std        0.0995833
trainer/Q1 Predictions Max       -0.992905
trainer/Q1 Predictions Min       -1.49428
trainer/Q2 Predictions Mean      -1.27172
trainer/Q2 Predictions Std        0.103612
trainer/Q2 Predictions Max       -0.990347
trainer/Q2 Predictions Min       -1.52169
trainer/Q Targets Mean           -1.1745
trainer/Q Targets Std             0.207188
trainer/Q Targets Max            -0.358026
trainer/Q Targets Min            -1.3053
trainer/Log Pis Mean             -1.37814
trainer/Log Pis Std               0.250667
trainer/Log Pis Max              -1.0961
trainer/Log Pis Min              -3.56894
trainer/Policy mu Mean            0.0144593
trainer/Policy mu Std             0.0111219
trainer/Policy mu Max             0.0280584
trainer/Policy mu Min             0.00258792
trainer/Policy log std Mean      -0.148202
trainer/Policy log std Std        0.0153108
trainer/Policy log std Max       -0.120731
trainer/Policy log std Min       -0.185195
trainer/Alpha                     0.941417
trainer/Alpha Loss               -0.202918
exploration/num steps total     600
exploration/num paths total       6
exploration/path length Mean    100
exploration/path length Std       0
exploration/path length Max     100
exploration/path length Min     100
exploration/Rewards Mean         -0.799314
exploration/Rewards Std           0.283477
exploration/Rewards Max          -0.0667784
exploration/Rewards Min          -1
exploration/Returns Mean        -79.9314
exploration/Returns Std           5.5316
exploration/Returns Max         -74.3998
exploration/Returns Min         -85.463
exploration/Actions Mean         -0.0208246
exploration/Actions Std           0.587828
exploration/Actions Max           0.982365
exploration/Actions Min          -0.97975
exploration/Num Paths             2
exploration/Average Returns     -79.9314
evaluation/num steps total     2000
evaluation/num paths total       20
evaluation/path length Mean     100
evaluation/path length Std        0
evaluation/path length Max      100
evaluation/path length Min      100
evaluation/Rewards Mean          -1
evaluation/Rewards Std            0
evaluation/Rewards Max           -1
evaluation/Rewards Min           -1
evaluation/Returns Mean        -100
evaluation/Returns Std            0
evaluation/Returns Max         -100
evaluation/Returns Min         -100
evaluation/Actions Mean           0.0141851
evaluation/Actions Std            0.0111241
evaluation/Actions Max            0.028775
evaluation/Actions Min            0.00265277
evaluation/Num Paths             10
evaluation/Average Returns     -100
time/data storing (s)             0.0012225
time/evaluation sampling (s)      0.266184
time/exploration sampling (s)     0.0684706
time/logging (s)                  0.00253121
time/saving (s)                   0.00245556
time/training (s)                 0.973518
time/epoch (s)                    1.31438
time/total (s)                    2.89641
Epoch                             1
-----------------------------  -------------
2019-04-22 20:52:40.401123 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 2 finished
-----------------------------  -------------
replay_buffer/size              800
trainer/QF1 Loss                  0.0146879
trainer/QF2 Loss                  0.0191956
trainer/Policy Loss               0.38483
trainer/Q1 Predictions Mean      -1.71718
trainer/Q1 Predictions Std        0.222139
trainer/Q1 Predictions Max       -1.25879
trainer/Q1 Predictions Min       -2.13251
trainer/Q2 Predictions Mean      -1.71782
trainer/Q2 Predictions Std        0.214958
trainer/Q2 Predictions Max       -1.31394
trainer/Q2 Predictions Min       -2.14745
trainer/Q Targets Mean           -1.70573
trainer/Q Targets Std             0.273342
trainer/Q Targets Max            -0.873482
trainer/Q Targets Min            -1.98745
trainer/Log Pis Mean             -1.3452
trainer/Log Pis Std               0.126113
trainer/Log Pis Max              -1.07168
trainer/Log Pis Min              -1.84851
trainer/Policy mu Mean            0.00635826
trainer/Policy mu Std             0.00455857
trainer/Policy mu Max             0.0143966
trainer/Policy mu Min            -0.00552681
trainer/Policy log std Mean      -0.144733
trainer/Policy log std Std        0.0124548
trainer/Policy log std Max       -0.119881
trainer/Policy log std Min       -0.175662
trainer/Alpha                     0.886581
trainer/Alpha Loss               -0.4017
exploration/num steps total     800
exploration/num paths total       8
exploration/path length Mean    100
exploration/path length Std       0
exploration/path length Max     100
exploration/path length Min     100
exploration/Rewards Mean         -0.905226
exploration/Rewards Std           0.187852
exploration/Rewards Max          -0.155045
exploration/Rewards Min          -1
exploration/Returns Mean        -90.5226
exploration/Returns Std           9.25989
exploration/Returns Max         -81.2628
exploration/Returns Min         -99.7825
exploration/Actions Mean          0.0541775
exploration/Actions Std           0.564066
exploration/Actions Max           0.987383
exploration/Actions Min          -0.980875
exploration/Num Paths             2
exploration/Average Returns     -90.5226
evaluation/num steps total     3000
evaluation/num paths total       30
evaluation/path length Mean     100
evaluation/path length Std        0
evaluation/path length Max      100
evaluation/path length Min      100
evaluation/Rewards Mean          -0.916391
evaluation/Rewards Std            0.193426
evaluation/Rewards Max           -0.33251
evaluation/Rewards Min           -1
evaluation/Returns Mean         -91.6391
evaluation/Returns Std           19.2408
evaluation/Returns Max          -36.8874
evaluation/Returns Min         -100
evaluation/Actions Mean           0.00597506
evaluation/Actions Std            0.00425702
evaluation/Actions Max            0.0142639
evaluation/Actions Min           -0.00453927
evaluation/Num Paths             10
evaluation/Average Returns      -91.6391
time/data storing (s)             0.00113504
time/evaluation sampling (s)      0.268984
time/exploration sampling (s)     0.0691199
time/logging (s)                  0.00332102
time/saving (s)                   0.00234929
time/training (s)                 0.96135
time/epoch (s)                    1.30626
time/total (s)                    4.20632
Epoch                             2
-----------------------------  -------------
2019-04-22 20:52:41.738755 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 3 finished
-----------------------------  -------------
replay_buffer/size             1000
trainer/QF1 Loss                  0.00723824
trainer/QF2 Loss                  0.0101053
trainer/Policy Loss               1.0765
trainer/Q1 Predictions Mean      -2.42356
trainer/Q1 Predictions Std        0.255992
trainer/Q1 Predictions Max       -1.65002
trainer/Q1 Predictions Min       -2.84661
trainer/Q2 Predictions Mean      -2.42313
trainer/Q2 Predictions Std        0.252475
trainer/Q2 Predictions Max       -1.72327
trainer/Q2 Predictions Min       -2.89428
trainer/Q Targets Mean           -2.4479
trainer/Q Targets Std             0.266625
trainer/Q Targets Max            -1.34362
trainer/Q Targets Min            -2.81824
trainer/Log Pis Mean             -1.36769
trainer/Log Pis Std               0.15086
trainer/Log Pis Max              -0.977128
trainer/Log Pis Min              -2.13329
trainer/Policy mu Mean           -0.00733907
trainer/Policy mu Std             0.0233483
trainer/Policy mu Max             0.0264023
trainer/Policy mu Min            -0.0761287
trainer/Policy log std Mean      -0.142825
trainer/Policy log std Std        0.0128202
trainer/Policy log std Max       -0.118821
trainer/Policy log std Min       -0.178615
trainer/Alpha                     0.834903
trainer/Alpha Loss               -0.606652
exploration/num steps total    1000
exploration/num paths total      10
exploration/path length Mean    100
exploration/path length Std       0
exploration/path length Max     100
exploration/path length Min     100
exploration/Rewards Mean         -1
exploration/Rewards Std           0
exploration/Rewards Max          -1
exploration/Rewards Min          -1
exploration/Returns Mean       -100
exploration/Returns Std           0
exploration/Returns Max        -100
exploration/Returns Min        -100
exploration/Actions Mean         -0.0362672
exploration/Actions Std           0.604714
exploration/Actions Max           0.975626
exploration/Actions Min          -0.993439
exploration/Num Paths             2
exploration/Average Returns    -100
evaluation/num steps total     4000
evaluation/num paths total       40
evaluation/path length Mean     100
evaluation/path length Std        0
evaluation/path length Max      100
evaluation/path length Min      100
evaluation/Rewards Mean          -0.96864
evaluation/Rewards Std            0.0902644
evaluation/Rewards Max           -0.563551
evaluation/Rewards Min           -1
evaluation/Returns Mean         -96.864
evaluation/Returns Std            6.2877
evaluation/Returns Max          -83.33
evaluation/Returns Min         -100
evaluation/Actions Mean          -0.00169633
evaluation/Actions Std            0.0159333
evaluation/Actions Max            0.0260229
evaluation/Actions Min           -0.0697809
evaluation/Num Paths             10
evaluation/Average Returns      -96.864
time/data storing (s)             0.00142023
time/evaluation sampling (s)      0.269124
time/exploration sampling (s)     0.0684375
time/logging (s)                  0.00362293
time/saving (s)                   0.00273685
time/training (s)                 0.987893
time/epoch (s)                    1.33324
time/total (s)                    5.54354
Epoch                             3
-----------------------------  -------------
2019-04-22 20:52:43.089642 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 4 finished
-----------------------------  --------------
replay_buffer/size             1200
trainer/QF1 Loss                  0.0130551
trainer/QF2 Loss                  0.0130283
trainer/Policy Loss               1.74033
trainer/Q1 Predictions Mean      -3.07718
trainer/Q1 Predictions Std        0.41621
trainer/Q1 Predictions Max       -1.88422
trainer/Q1 Predictions Min       -3.59214
trainer/Q2 Predictions Mean      -3.09057
trainer/Q2 Predictions Std        0.402776
trainer/Q2 Predictions Max       -1.94797
trainer/Q2 Predictions Min       -3.62425
trainer/Q Targets Mean           -3.15309
trainer/Q Targets Std             0.424215
trainer/Q Targets Max            -1.79393
trainer/Q Targets Min            -3.66068
trainer/Log Pis Mean             -1.35357
trainer/Log Pis Std               0.148279
trainer/Log Pis Max              -1.00515
trainer/Log Pis Min              -1.92075
trainer/Policy mu Mean            0.0111133
trainer/Policy mu Std             0.0479727
trainer/Policy mu Max             0.111203
trainer/Policy mu Min            -0.112572
trainer/Policy log std Mean      -0.137757
trainer/Policy log std Std        0.0159761
trainer/Policy log std Max       -0.111395
trainer/Policy log std Min       -0.180496
trainer/Alpha                     0.786265
trainer/Alpha Loss               -0.805399
exploration/num steps total    1200
exploration/num paths total      12
exploration/path length Mean    100
exploration/path length Std       0
exploration/path length Max     100
exploration/path length Min     100
exploration/Rewards Mean         -0.791726
exploration/Rewards Std           0.26881
exploration/Rewards Max          -0.0684362
exploration/Rewards Min          -1
exploration/Returns Mean        -79.1726
exploration/Returns Std          13.0997
exploration/Returns Max         -66.0729
exploration/Returns Min         -92.2723
exploration/Actions Mean          0.013911
exploration/Actions Std           0.590926
exploration/Actions Max           0.992803
exploration/Actions Min          -0.989845
exploration/Num Paths             2
exploration/Average Returns     -79.1726
evaluation/num steps total     5000
evaluation/num paths total       50
evaluation/path length Mean     100
evaluation/path length Std        0
evaluation/path length Max      100
evaluation/path length Min      100
evaluation/Rewards Mean          -0.961472
evaluation/Rewards Std            0.109504
evaluation/Rewards Max           -0.472286
evaluation/Rewards Min           -1
evaluation/Returns Mean         -96.1472
evaluation/Returns Std            7.88695
evaluation/Returns Max          -76.9764
evaluation/Returns Min         -100
evaluation/Actions Mean           0.000123671
evaluation/Actions Std            0.0324592
evaluation/Actions Max            0.0395989
evaluation/Actions Min           -0.103657
evaluation/Num Paths             10
evaluation/Average Returns      -96.1472
time/data storing (s)             0.0013187
time/evaluation sampling (s)      0.265939
time/exploration sampling (s)     0.0685398
time/logging (s)                  0.0029427
time/saving (s)                   0.00262674
time/training (s)                 0.99003
time/epoch (s)                    1.3314
time/total (s)                    6.89287
Epoch                             4
-----------------------------  --------------
2019-04-22 20:52:44.423332 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 5 finished
-----------------------------  -------------
replay_buffer/size             1400
trainer/QF1 Loss                  0.122031
trainer/QF2 Loss                  0.1255
trainer/Policy Loss               2.49977
trainer/Q1 Predictions Mean      -3.8362
trainer/Q1 Predictions Std        0.598962
trainer/Q1 Predictions Max       -2.32367
trainer/Q1 Predictions Min       -4.54845
trainer/Q2 Predictions Mean      -3.83068
trainer/Q2 Predictions Std        0.594145
trainer/Q2 Predictions Max       -2.31321
trainer/Q2 Predictions Min       -4.5556
trainer/Q Targets Mean           -3.77637
trainer/Q Targets Std             0.64085
trainer/Q Targets Max            -1
trainer/Q Targets Min            -4.51517
trainer/Log Pis Mean             -1.34237
trainer/Log Pis Std               0.201269
trainer/Log Pis Max              -0.67225
trainer/Log Pis Min              -1.7578
trainer/Policy mu Mean            0.0365114
trainer/Policy mu Std             0.0834297
trainer/Policy mu Max             0.249971
trainer/Policy mu Min            -0.205307
trainer/Policy log std Mean      -0.127904
trainer/Policy log std Std        0.0157546
trainer/Policy log std Max       -0.100143
trainer/Policy log std Min       -0.168013
trainer/Alpha                     0.740557
trainer/Alpha Loss               -1.00289
exploration/num steps total    1400
exploration/num paths total      14
exploration/path length Mean    100
exploration/path length Std       0
exploration/path length Max     100
exploration/path length Min     100
exploration/Rewards Mean         -0.796663
exploration/Rewards Std           0.256531
exploration/Rewards Max          -0.0617583
exploration/Rewards Min          -1
exploration/Returns Mean        -79.6663
exploration/Returns Std          16.4327
exploration/Returns Max         -63.2336
exploration/Returns Min         -96.099
exploration/Actions Mean          0.0247782
exploration/Actions Std           0.574182
exploration/Actions Max           0.972925
exploration/Actions Min          -0.980702
exploration/Num Paths             2
exploration/Average Returns     -79.6663
evaluation/num steps total     6000
evaluation/num paths total       60
evaluation/path length Mean     100
evaluation/path length Std        0
evaluation/path length Max      100
evaluation/path length Min      100
evaluation/Rewards Mean          -0.747729
evaluation/Rewards Std            0.289691
evaluation/Rewards Max           -0.14363
evaluation/Rewards Min           -1
evaluation/Returns Mean         -74.7729
evaluation/Returns Std           17.752
evaluation/Returns Max          -51.808
evaluation/Returns Min         -100
evaluation/Actions Mean           0.0255631
evaluation/Actions Std            0.0449814
evaluation/Actions Max            0.154485
evaluation/Actions Min           -0.158856
evaluation/Num Paths             10
evaluation/Average Returns      -74.7729
time/data storing (s)             0.00126187
time/evaluation sampling (s)      0.273236
time/exploration sampling (s)     0.0697302
time/logging (s)                  0.00344502
time/saving (s)                   0.00251466
time/training (s)                 0.979304
time/epoch (s)                    1.32949
time/total (s)                    8.22652
Epoch                             5
-----------------------------  -------------
2019-04-22 20:52:45.755697 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 6 finished
-----------------------------  -------------
replay_buffer/size             1600
trainer/QF1 Loss                  0.239801
trainer/QF2 Loss                  0.242572
trainer/Policy Loss               3.23172
trainer/Q1 Predictions Mean      -4.57496
trainer/Q1 Predictions Std        0.55438
trainer/Q1 Predictions Max       -2.67902
trainer/Q1 Predictions Min       -5.20314
trainer/Q2 Predictions Mean      -4.58336
trainer/Q2 Predictions Std        0.553802
trainer/Q2 Predictions Max       -2.64823
trainer/Q2 Predictions Min       -5.22333
trainer/Q Targets Mean           -4.60222
trainer/Q Targets Std             0.814354
trainer/Q Targets Max            -0.526607
trainer/Q Targets Min            -5.23098
trainer/Log Pis Mean             -1.38144
trainer/Log Pis Std               0.213378
trainer/Log Pis Max              -0.651121
trainer/Log Pis Min              -2.08072
trainer/Policy mu Mean            0.0479746
trainer/Policy mu Std             0.0975148
trainer/Policy mu Max             0.322638
trainer/Policy mu Min            -0.245996
trainer/Policy log std Mean      -0.148508
trainer/Policy log std Std        0.0216085
trainer/Policy log std Max       -0.121274
trainer/Policy log std Min       -0.204687
trainer/Alpha                     0.697582
trainer/Alpha Loss               -1.21677
exploration/num steps total    1600
exploration/num paths total      16
exploration/path length Mean    100
exploration/path length Std       0
exploration/path length Max     100
exploration/path length Min     100
exploration/Rewards Mean         -1
exploration/Rewards Std           0
exploration/Rewards Max          -1
exploration/Rewards Min          -1
exploration/Returns Mean       -100
exploration/Returns Std           0
exploration/Returns Max        -100
exploration/Returns Min        -100
exploration/Actions Mean         -0.027222
exploration/Actions Std           0.577767
exploration/Actions Max           0.981006
exploration/Actions Min          -0.983285
exploration/Num Paths             2
exploration/Average Returns    -100
evaluation/num steps total     7000
evaluation/num paths total       70
evaluation/path length Mean     100
evaluation/path length Std        0
evaluation/path length Max      100
evaluation/path length Min      100
evaluation/Rewards Mean          -0.778003
evaluation/Rewards Std            0.279314
evaluation/Rewards Max           -0.0532253
evaluation/Rewards Min           -1
evaluation/Returns Mean         -77.8003
evaluation/Returns Std           18.5394
evaluation/Returns Max          -49.3065
evaluation/Returns Min         -100
evaluation/Actions Mean           0.0473305
evaluation/Actions Std            0.0669344
evaluation/Actions Max            0.302672
evaluation/Actions Min           -0.173064
evaluation/Num Paths             10
evaluation/Average Returns      -77.8003
time/data storing (s)             0.00118986
time/evaluation sampling (s)      0.271677
time/exploration sampling (s)     0.0681121
time/logging (s)                  0.00337158
time/saving (s)                   0.00216032
time/training (s)                 0.980919
time/epoch (s)                    1.32743
time/total (s)                    9.55803
Epoch                             6
-----------------------------  -------------
2019-04-22 20:52:47.101725 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 7 finished
-----------------------------  -------------
replay_buffer/size             1800
trainer/QF1 Loss                  0.270212
trainer/QF2 Loss                  0.273347
trainer/Policy Loss               3.81415
trainer/Q1 Predictions Mean      -5.17486
trainer/Q1 Predictions Std        0.844687
trainer/Q1 Predictions Max       -2.88197
trainer/Q1 Predictions Min       -6.16268
trainer/Q2 Predictions Mean      -5.17199
trainer/Q2 Predictions Std        0.844901
trainer/Q2 Predictions Max       -2.81074
trainer/Q2 Predictions Min       -6.21907
trainer/Q Targets Mean           -5.24364
trainer/Q Targets Std             0.968273
trainer/Q Targets Max            -1
trainer/Q Targets Min            -6.17576
trainer/Log Pis Mean             -1.3458
trainer/Log Pis Std               0.305995
trainer/Log Pis Max              -0.333534
trainer/Log Pis Min              -2.53088
trainer/Policy mu Mean            0.0619512
trainer/Policy mu Std             0.134798
trainer/Policy mu Max             0.458857
trainer/Policy mu Min            -0.306291
trainer/Policy log std Mean      -0.166027
trainer/Policy log std Std        0.0351262
trainer/Policy log std Max       -0.11591
trainer/Policy log std Min       -0.249708
trainer/Alpha                     0.657187
trainer/Alpha Loss               -1.40352
exploration/num steps total    1800
exploration/num paths total      18
exploration/path length Mean    100
exploration/path length Std       0
exploration/path length Max     100
exploration/path length Min     100
exploration/Rewards Mean         -0.612821
exploration/Rewards Std           0.279934
exploration/Rewards Max          -0.0416178
exploration/Rewards Min          -1
exploration/Returns Mean        -61.2821
exploration/Returns Std           0.841918
exploration/Returns Max         -60.4402
exploration/Returns Min         -62.124
exploration/Actions Mean          0.0389599
exploration/Actions Std           0.586329
exploration/Actions Max           0.98899
exploration/Actions Min          -0.984868
exploration/Num Paths             2
exploration/Average Returns     -61.2821
evaluation/num steps total     8000
evaluation/num paths total       80
evaluation/path length Mean     100
evaluation/path length Std        0
evaluation/path length Max      100
evaluation/path length Min      100
evaluation/Rewards Mean          -0.646962
evaluation/Rewards Std            0.248932
evaluation/Rewards Max           -0.0815266
evaluation/Rewards Min           -1
evaluation/Returns Mean         -64.6962
evaluation/Returns Std            9.84578
evaluation/Returns Max          -48.3871
evaluation/Returns Min          -78.7122
evaluation/Actions Mean           0.110136
evaluation/Actions Std            0.106142
evaluation/Actions Max            0.407053
evaluation/Actions Min           -0.247118
evaluation/Num Paths             10
evaluation/Average Returns      -64.6962
time/data storing (s)             0.00119803
time/evaluation sampling (s)      0.28129
time/exploration sampling (s)     0.0689133
time/logging (s)                  0.00331103
time/saving (s)                   0.00240871
time/training (s)                 0.984104
time/epoch (s)                    1.34122
time/total (s)                   10.9032
Epoch                             7
-----------------------------  -------------
2019-04-22 20:52:48.457358 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 8 finished
-----------------------------  -------------
replay_buffer/size             2000
trainer/QF1 Loss                  0.485117
trainer/QF2 Loss                  0.486655
trainer/Policy Loss               4.69893
trainer/Q1 Predictions Mean      -6.06211
trainer/Q1 Predictions Std        1.07049
trainer/Q1 Predictions Max       -3.37598
trainer/Q1 Predictions Min       -7.15384
trainer/Q2 Predictions Mean      -6.05404
trainer/Q2 Predictions Std        1.07718
trainer/Q2 Predictions Max       -3.3392
trainer/Q2 Predictions Min       -7.05397
trainer/Q Targets Mean           -5.95981
trainer/Q Targets Std             1.28604
trainer/Q Targets Max            -0.526607
trainer/Q Targets Min            -7.25057
trainer/Log Pis Mean             -1.30897
trainer/Log Pis Std               0.400752
trainer/Log Pis Max               0.305361
trainer/Log Pis Min              -2.847
trainer/Policy mu Mean            0.0872729
trainer/Policy mu Std             0.194456
trainer/Policy mu Max             0.606938
trainer/Policy mu Min            -0.450466
trainer/Policy log std Mean      -0.174957
trainer/Policy log std Std        0.0471134
trainer/Policy log std Max       -0.0757348
trainer/Policy log std Min       -0.28929
trainer/Alpha                     0.619316
trainer/Alpha Loss               -1.58448
exploration/num steps total    2000
exploration/num paths total      20
exploration/path length Mean    100
exploration/path length Std       0
exploration/path length Max     100
exploration/path length Min     100
exploration/Rewards Mean         -0.627748
exploration/Rewards Std           0.236558
exploration/Rewards Max          -0.101277
exploration/Rewards Min          -1
exploration/Returns Mean        -62.7748
exploration/Returns Std           7.07269
exploration/Returns Max         -55.7021
exploration/Returns Min         -69.8475
exploration/Actions Mean          0.0922379
exploration/Actions Std           0.561088
exploration/Actions Max           0.988733
exploration/Actions Min          -0.982265
exploration/Num Paths             2
exploration/Average Returns     -62.7748
evaluation/num steps total     9000
evaluation/num paths total       90
evaluation/path length Mean     100
evaluation/path length Std        0
evaluation/path length Max      100
evaluation/path length Min      100
evaluation/Rewards Mean          -0.687914
evaluation/Rewards Std            0.258739
evaluation/Rewards Max           -0.0743027
evaluation/Rewards Min           -1
evaluation/Returns Mean         -68.7914
evaluation/Returns Std           12.6835
evaluation/Returns Max          -51.2209
evaluation/Returns Min         -100
evaluation/Actions Mean           0.16164
evaluation/Actions Std            0.157616
evaluation/Actions Max            0.541886
evaluation/Actions Min           -0.164716
evaluation/Num Paths             10
evaluation/Average Returns      -68.7914
time/data storing (s)             0.00119037
time/evaluation sampling (s)      0.278995
time/exploration sampling (s)     0.0692093
time/logging (s)                  0.00338277
time/saving (s)                   0.00241676
time/training (s)                 0.995554
time/epoch (s)                    1.35075
time/total (s)                   12.2581
Epoch                             8
-----------------------------  -------------
2019-04-22 20:52:49.811467 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 9 finished
-----------------------------  --------------
replay_buffer/size              2200
trainer/QF1 Loss                   0.598738
trainer/QF2 Loss                   0.60378
trainer/Policy Loss                4.85805
trainer/Q1 Predictions Mean       -6.2515
trainer/Q1 Predictions Std         1.34902
trainer/Q1 Predictions Max        -3.85408
trainer/Q1 Predictions Min        -8.37561
trainer/Q2 Predictions Mean       -6.24007
trainer/Q2 Predictions Std         1.33847
trainer/Q2 Predictions Max        -3.81713
trainer/Q2 Predictions Min        -8.33054
trainer/Q Targets Mean            -6.25859
trainer/Q Targets Std              1.56739
trainer/Q Targets Max             -0.520961
trainer/Q Targets Min             -8.05617
trainer/Log Pis Mean              -1.2964
trainer/Log Pis Std                0.362426
trainer/Log Pis Max               -0.404105
trainer/Log Pis Min               -2.25692
trainer/Policy mu Mean             0.117283
trainer/Policy mu Std              0.204099
trainer/Policy mu Max              0.563152
trainer/Policy mu Min             -0.513673
trainer/Policy log std Mean       -0.196397
trainer/Policy log std Std         0.0369016
trainer/Policy log std Max        -0.131966
trainer/Policy log std Min        -0.265959
trainer/Alpha                      0.583771
trainer/Alpha Loss                -1.7733
exploration/num steps total     2200
exploration/num paths total       22
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.508764
exploration/Rewards Std            0.228565
exploration/Rewards Max           -0.0227805
exploration/Rewards Min           -1
exploration/Returns Mean         -50.8764
exploration/Returns Std            4.02574
exploration/Returns Max          -46.8506
exploration/Returns Min          -54.9021
exploration/Actions Mean           0.145339
exploration/Actions Std            0.553511
exploration/Actions Max            0.975958
exploration/Actions Min           -0.947721
exploration/Num Paths              2
exploration/Average Returns      -50.8764
evaluation/num steps total     10000
evaluation/num paths total       100
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.633476
evaluation/Rewards Std             0.237864
evaluation/Rewards Max            -0.00221
evaluation/Rewards Min            -1
evaluation/Returns Mean          -63.3476
evaluation/Returns Std            13.16
evaluation/Returns Max           -53.004
evaluation/Returns Min          -100
evaluation/Actions Mean            0.0968761
evaluation/Actions Std             0.216733
evaluation/Actions Max             0.381548
evaluation/Actions Min            -0.512517
evaluation/Num Paths              10
evaluation/Average Returns       -63.3476
time/data storing (s)              0.0012565
time/evaluation sampling (s)       0.284423
time/exploration sampling (s)      0.0729475
time/logging (s)                   0.00338229
time/saving (s)                    0.00237053
time/training (s)                  0.984828
time/epoch (s)                     1.34921
time/total (s)                    13.6115
Epoch                              9
-----------------------------  --------------
2019-04-22 20:52:51.167057 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 10 finished
-----------------------------  --------------
replay_buffer/size              2400
trainer/QF1 Loss                   0.540742
trainer/QF2 Loss                   0.545501
trainer/Policy Loss                5.16527
trainer/Q1 Predictions Mean       -6.46757
trainer/Q1 Predictions Std         1.84048
trainer/Q1 Predictions Max        -4.04223
trainer/Q1 Predictions Min        -8.8962
trainer/Q2 Predictions Mean       -6.45787
trainer/Q2 Predictions Std         1.84071
trainer/Q2 Predictions Max        -4.04264
trainer/Q2 Predictions Min        -8.84975
trainer/Q Targets Mean            -6.43957
trainer/Q Targets Std              1.93086
trainer/Q Targets Max             -1
trainer/Q Targets Min             -8.93765
trainer/Log Pis Mean              -1.26421
trainer/Log Pis Std                0.423984
trainer/Log Pis Max               -0.297366
trainer/Log Pis Min               -2.52824
trainer/Policy mu Mean             0.100495
trainer/Policy mu Std              0.245563
trainer/Policy mu Max              0.619549
trainer/Policy mu Min             -0.715245
trainer/Policy log std Mean       -0.230716
trainer/Policy log std Std         0.0610641
trainer/Policy log std Max        -0.13852
trainer/Policy log std Min        -0.358081
trainer/Alpha                      0.550268
trainer/Alpha Loss                -1.94891
exploration/num steps total     2400
exploration/num paths total       24
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.528385
exploration/Rewards Std            0.214443
exploration/Rewards Max           -0.0521003
exploration/Rewards Min           -1
exploration/Returns Mean         -52.8385
exploration/Returns Std            1.55822
exploration/Returns Max          -51.2802
exploration/Returns Min          -54.3967
exploration/Actions Mean           0.0994446
exploration/Actions Std            0.551843
exploration/Actions Max            0.978844
exploration/Actions Min           -0.995174
exploration/Num Paths              2
exploration/Average Returns      -52.8385
evaluation/num steps total     11000
evaluation/num paths total       110
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.586713
evaluation/Rewards Std             0.216773
evaluation/Rewards Max            -0.0388693
evaluation/Rewards Min            -1
evaluation/Returns Mean          -58.6713
evaluation/Returns Std            15.012
evaluation/Returns Max           -48.1889
evaluation/Returns Min          -100
evaluation/Actions Mean            0.103381
evaluation/Actions Std             0.1941
evaluation/Actions Max             0.527595
evaluation/Actions Min            -0.616345
evaluation/Num Paths              10
evaluation/Average Returns       -58.6713
time/data storing (s)              0.00119496
time/evaluation sampling (s)       0.280228
time/exploration sampling (s)      0.0700402
time/logging (s)                   0.00334508
time/saving (s)                    0.00213032
time/training (s)                  0.993677
time/epoch (s)                     1.35062
time/total (s)                    14.9662
Epoch                             10
-----------------------------  --------------
2019-04-22 20:52:52.528695 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 11 finished
-----------------------------  --------------
replay_buffer/size              2600
trainer/QF1 Loss                   0.37762
trainer/QF2 Loss                   0.391252
trainer/Policy Loss                5.53989
trainer/Q1 Predictions Mean       -6.84883
trainer/Q1 Predictions Std         1.87937
trainer/Q1 Predictions Max        -4.50533
trainer/Q1 Predictions Min        -9.6794
trainer/Q2 Predictions Mean       -6.83791
trainer/Q2 Predictions Std         1.88452
trainer/Q2 Predictions Max        -4.50782
trainer/Q2 Predictions Min        -9.66563
trainer/Q Targets Mean            -6.94698
trainer/Q Targets Std              1.983
trainer/Q Targets Max             -0.678432
trainer/Q Targets Min             -9.61186
trainer/Log Pis Mean              -1.22914
trainer/Log Pis Std                0.574141
trainer/Log Pis Max                0.341223
trainer/Log Pis Min               -3.50171
trainer/Policy mu Mean             0.119487
trainer/Policy mu Std              0.304836
trainer/Policy mu Max              0.782408
trainer/Policy mu Min             -0.698169
trainer/Policy log std Mean       -0.223374
trainer/Policy log std Std         0.054633
trainer/Policy log std Max        -0.129147
trainer/Policy log std Min        -0.331486
trainer/Alpha                      0.518782
trainer/Alpha Loss                -2.11825
exploration/num steps total     2600
exploration/num paths total       26
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.432631
exploration/Rewards Std            0.194694
exploration/Rewards Max           -0.017797
exploration/Rewards Min           -1
exploration/Returns Mean         -43.2631
exploration/Returns Std            3.24908
exploration/Returns Max          -40.014
exploration/Returns Min          -46.5122
exploration/Actions Mean           0.0820703
exploration/Actions Std            0.580266
exploration/Actions Max            0.954594
exploration/Actions Min           -0.973974
exploration/Num Paths              2
exploration/Average Returns      -43.2631
evaluation/num steps total     12000
evaluation/num paths total       120
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.526861
evaluation/Rewards Std             0.166249
evaluation/Rewards Max            -0.063968
evaluation/Rewards Min            -1
evaluation/Returns Mean          -52.6861
evaluation/Returns Std             3.10719
evaluation/Returns Max           -48.6789
evaluation/Returns Min           -59.9811
evaluation/Actions Mean            0.0709713
evaluation/Actions Std             0.11588
evaluation/Actions Max             0.613805
evaluation/Actions Min            -0.511865
evaluation/Num Paths              10
evaluation/Average Returns       -52.6861
time/data storing (s)              0.0011465
time/evaluation sampling (s)       0.28279
time/exploration sampling (s)      0.0692015
time/logging (s)                   0.00344698
time/saving (s)                    0.00221431
time/training (s)                  0.997983
time/epoch (s)                     1.35678
time/total (s)                    16.3271
Epoch                             11
-----------------------------  --------------
2019-04-22 20:52:53.873971 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 12 finished
-----------------------------  --------------
replay_buffer/size              2800
trainer/QF1 Loss                   0.354127
trainer/QF2 Loss                   0.352555
trainer/Policy Loss                5.92263
trainer/Q1 Predictions Mean       -7.11249
trainer/Q1 Predictions Std         2.07494
trainer/Q1 Predictions Max        -4.90811
trainer/Q1 Predictions Min       -10.9504
trainer/Q2 Predictions Mean       -7.1175
trainer/Q2 Predictions Std         2.07795
trainer/Q2 Predictions Max        -4.9155
trainer/Q2 Predictions Min       -10.7811
trainer/Q Targets Mean            -7.07898
trainer/Q Targets Std              2.20604
trainer/Q Targets Max             -0.21799
trainer/Q Targets Min            -10.6977
trainer/Log Pis Mean              -1.0861
trainer/Log Pis Std                0.597865
trainer/Log Pis Max                0.43676
trainer/Log Pis Min               -3.15356
trainer/Policy mu Mean             0.143875
trainer/Policy mu Std              0.313209
trainer/Policy mu Max              0.816804
trainer/Policy mu Min             -0.775647
trainer/Policy log std Mean       -0.249563
trainer/Policy log std Std         0.0669564
trainer/Policy log std Max        -0.136063
trainer/Policy log std Min        -0.393294
trainer/Alpha                      0.489327
trainer/Alpha Loss                -2.20482
exploration/num steps total     2800
exploration/num paths total       28
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.592732
exploration/Rewards Std            0.303239
exploration/Rewards Max           -0.0567339
exploration/Rewards Min           -1
exploration/Returns Mean         -59.2732
exploration/Returns Std           14.157
exploration/Returns Max          -45.1162
exploration/Returns Min          -73.4302
exploration/Actions Mean           0.0235223
exploration/Actions Std            0.569492
exploration/Actions Max            0.984813
exploration/Actions Min           -0.995725
exploration/Num Paths              2
exploration/Average Returns      -59.2732
evaluation/num steps total     13000
evaluation/num paths total       130
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.368875
evaluation/Rewards Std             0.284712
evaluation/Rewards Max            -0.111749
evaluation/Rewards Min            -1
evaluation/Returns Mean          -36.8875
evaluation/Returns Std            21.6434
evaluation/Returns Max           -23.4832
evaluation/Returns Min          -100
evaluation/Actions Mean            0.0735898
evaluation/Actions Std             0.182485
evaluation/Actions Max             0.694873
evaluation/Actions Min            -0.471409
evaluation/Num Paths              10
evaluation/Average Returns       -36.8875
time/data storing (s)              0.00124327
time/evaluation sampling (s)       0.271379
time/exploration sampling (s)      0.0697445
time/logging (s)                   0.00349086
time/saving (s)                    0.00242709
time/training (s)                  0.992263
time/epoch (s)                     1.34055
time/total (s)                    17.6716
Epoch                             12
-----------------------------  --------------
2019-04-22 20:52:55.217195 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 13 finished
-----------------------------  --------------
replay_buffer/size              3000
trainer/QF1 Loss                   0.079235
trainer/QF2 Loss                   0.0771814
trainer/Policy Loss                6.39389
trainer/Q1 Predictions Mean       -7.59687
trainer/Q1 Predictions Std         2.26985
trainer/Q1 Predictions Max        -5.2611
trainer/Q1 Predictions Min       -11.2134
trainer/Q2 Predictions Mean       -7.61164
trainer/Q2 Predictions Std         2.26215
trainer/Q2 Predictions Max        -5.29047
trainer/Q2 Predictions Min       -11.2465
trainer/Q Targets Mean            -7.58706
trainer/Q Targets Std              2.29193
trainer/Q Targets Max             -5.02695
trainer/Q Targets Min            -11.2307
trainer/Log Pis Mean              -1.13476
trainer/Log Pis Std                0.62981
trainer/Log Pis Max                0.276029
trainer/Log Pis Min               -2.72842
trainer/Policy mu Mean             0.10494
trainer/Policy mu Std              0.332635
trainer/Policy mu Max              0.935141
trainer/Policy mu Min             -0.962742
trainer/Policy log std Mean       -0.261389
trainer/Policy log std Std         0.0569532
trainer/Policy log std Max        -0.165663
trainer/Policy log std Min        -0.413129
trainer/Alpha                      0.461645
trainer/Alpha Loss                -2.42213
exploration/num steps total     3000
exploration/num paths total       30
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.506478
exploration/Rewards Std            0.240413
exploration/Rewards Max           -0.0397737
exploration/Rewards Min           -1
exploration/Returns Mean         -50.6478
exploration/Returns Std            5.98345
exploration/Returns Max          -44.6644
exploration/Returns Min          -56.6313
exploration/Actions Mean           0.0403333
exploration/Actions Std            0.576935
exploration/Actions Max            0.988965
exploration/Actions Min           -0.961418
exploration/Num Paths              2
exploration/Average Returns      -50.6478
evaluation/num steps total     14000
evaluation/num paths total       140
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.389679
evaluation/Rewards Std             0.370273
evaluation/Rewards Max            -0.0828318
evaluation/Rewards Min            -1
evaluation/Returns Mean          -38.9679
evaluation/Returns Std            31.0529
evaluation/Returns Max           -16.2648
evaluation/Returns Min          -100
evaluation/Actions Mean            0.0264587
evaluation/Actions Std             0.255872
evaluation/Actions Max             0.803556
evaluation/Actions Min            -0.740744
evaluation/Num Paths              10
evaluation/Average Returns       -38.9679
time/data storing (s)              0.00117873
time/evaluation sampling (s)       0.27152
time/exploration sampling (s)      0.0703545
time/logging (s)                   0.0035365
time/saving (s)                    0.00243058
time/training (s)                  0.989639
time/epoch (s)                     1.33866
time/total (s)                    19.014
Epoch                             13
-----------------------------  --------------
2019-04-22 20:52:56.558126 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 14 finished
-----------------------------  --------------
replay_buffer/size              3200
trainer/QF1 Loss                   0.381271
trainer/QF2 Loss                   0.370555
trainer/Policy Loss                6.56027
trainer/Q1 Predictions Mean       -7.76789
trainer/Q1 Predictions Std         2.37917
trainer/Q1 Predictions Max        -5.2573
trainer/Q1 Predictions Min       -11.9135
trainer/Q2 Predictions Mean       -7.78008
trainer/Q2 Predictions Std         2.38944
trainer/Q2 Predictions Max        -5.27476
trainer/Q2 Predictions Min       -12.0388
trainer/Q Targets Mean            -7.91485
trainer/Q Targets Std              2.5024
trainer/Q Targets Max             -0.566307
trainer/Q Targets Min            -12.0241
trainer/Log Pis Mean              -1.05009
trainer/Log Pis Std                0.716263
trainer/Log Pis Max                0.463941
trainer/Log Pis Min               -3.34865
trainer/Policy mu Mean             0.104017
trainer/Policy mu Std              0.421469
trainer/Policy mu Max              1.18136
trainer/Policy mu Min             -1.04629
trainer/Policy log std Mean       -0.296589
trainer/Policy log std Std         0.0688324
trainer/Policy log std Max        -0.189861
trainer/Policy log std Min        -0.489722
trainer/Alpha                      0.435643
trainer/Alpha Loss                -2.53355
exploration/num steps total     3200
exploration/num paths total       32
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.401751
exploration/Rewards Std            0.201548
exploration/Rewards Max           -0.0351632
exploration/Rewards Min           -1
exploration/Returns Mean         -40.1751
exploration/Returns Std            1.59428
exploration/Returns Max          -38.5808
exploration/Returns Min          -41.7694
exploration/Actions Mean           0.0531582
exploration/Actions Std            0.556726
exploration/Actions Max            0.992697
exploration/Actions Min           -0.987072
exploration/Num Paths              2
exploration/Average Returns      -40.1751
evaluation/num steps total     15000
evaluation/num paths total       150
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.204958
evaluation/Rewards Std             0.162785
evaluation/Rewards Max            -0.00729891
evaluation/Rewards Min            -1
evaluation/Returns Mean          -20.4958
evaluation/Returns Std             3.84537
evaluation/Returns Max           -16.7288
evaluation/Returns Min           -30.3361
evaluation/Actions Mean            0.0146441
evaluation/Actions Std             0.119615
evaluation/Actions Max             0.826016
evaluation/Actions Min            -0.722623
evaluation/Num Paths              10
evaluation/Average Returns       -20.4958
time/data storing (s)              0.00120794
time/evaluation sampling (s)       0.273521
time/exploration sampling (s)      0.0712878
time/logging (s)                   0.00342431
time/saving (s)                    0.00235102
time/training (s)                  0.983927
time/epoch (s)                     1.33572
time/total (s)                    20.3538
Epoch                             14
-----------------------------  --------------
2019-04-22 20:52:57.905570 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 15 finished
-----------------------------  --------------
replay_buffer/size              3400
trainer/QF1 Loss                   1.16208
trainer/QF2 Loss                   1.16292
trainer/Policy Loss                6.78531
trainer/Q1 Predictions Mean       -8.0662
trainer/Q1 Predictions Std         2.6003
trainer/Q1 Predictions Max        -5.64575
trainer/Q1 Predictions Min       -12.9662
trainer/Q2 Predictions Mean       -8.05043
trainer/Q2 Predictions Std         2.60453
trainer/Q2 Predictions Max        -5.62329
trainer/Q2 Predictions Min       -12.9636
trainer/Q Targets Mean            -8.07102
trainer/Q Targets Std              2.72478
trainer/Q Targets Max             -1
trainer/Q Targets Min            -13.0065
trainer/Log Pis Mean              -1.16269
trainer/Log Pis Std                0.627032
trainer/Log Pis Max                0.64116
trainer/Log Pis Min               -3.22913
trainer/Policy mu Mean             0.0518225
trainer/Policy mu Std              0.361422
trainer/Policy mu Max              1.11367
trainer/Policy mu Min             -0.944143
trainer/Policy log std Mean       -0.268958
trainer/Policy log std Std         0.0656113
trainer/Policy log std Max        -0.17104
trainer/Policy log std Min        -0.472468
trainer/Alpha                      0.41117
trainer/Alpha Loss                -2.80992
exploration/num steps total     3400
exploration/num paths total       34
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.433837
exploration/Rewards Std            0.219677
exploration/Rewards Max           -0.0152173
exploration/Rewards Min           -1
exploration/Returns Mean         -43.3837
exploration/Returns Std            1.06995
exploration/Returns Max          -42.3137
exploration/Returns Min          -44.4536
exploration/Actions Mean           0.0194688
exploration/Actions Std            0.584686
exploration/Actions Max            0.976695
exploration/Actions Min           -0.983748
exploration/Num Paths              2
exploration/Average Returns      -43.3837
evaluation/num steps total     16000
evaluation/num paths total       160
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0792592
evaluation/Rewards Std             0.22581
evaluation/Rewards Max            -0.00670902
evaluation/Rewards Min            -1
evaluation/Returns Mean           -7.92592
evaluation/Returns Std             4.22475
evaluation/Returns Max            -2.46272
evaluation/Returns Min           -16.6876
evaluation/Actions Mean            0.0163054
evaluation/Actions Std             0.128656
evaluation/Actions Max             0.847396
evaluation/Actions Min            -0.77174
evaluation/Num Paths              10
evaluation/Average Returns        -7.92592
time/data storing (s)              0.0011894
time/evaluation sampling (s)       0.270449
time/exploration sampling (s)      0.070386
time/logging (s)                   0.00352355
time/saving (s)                    0.00235209
time/training (s)                  0.995117
time/epoch (s)                     1.34302
time/total (s)                    21.7005
Epoch                             15
-----------------------------  --------------
2019-04-22 20:52:59.244797 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 16 finished
-----------------------------  --------------
replay_buffer/size              3600
trainer/QF1 Loss                   0.10449
trainer/QF2 Loss                   0.105718
trainer/Policy Loss                7.09604
trainer/Q1 Predictions Mean       -8.27216
trainer/Q1 Predictions Std         2.52867
trainer/Q1 Predictions Max        -6.07754
trainer/Q1 Predictions Min       -15.1824
trainer/Q2 Predictions Mean       -8.24717
trainer/Q2 Predictions Std         2.53369
trainer/Q2 Predictions Max        -6.09295
trainer/Q2 Predictions Min       -15.3175
trainer/Q Targets Mean            -8.23128
trainer/Q Targets Std              2.59091
trainer/Q Targets Max             -5.91747
trainer/Q Targets Min            -14.3687
trainer/Log Pis Mean              -1.02055
trainer/Log Pis Std                0.628511
trainer/Log Pis Max                0.777905
trainer/Log Pis Min               -3.14545
trainer/Policy mu Mean             0.0779682
trainer/Policy mu Std              0.427821
trainer/Policy mu Max              1.30144
trainer/Policy mu Min             -1.09386
trainer/Policy log std Mean       -0.296454
trainer/Policy log std Std         0.065901
trainer/Policy log std Max        -0.178341
trainer/Policy log std Min        -0.499152
trainer/Alpha                      0.388133
trainer/Alpha Loss                -2.8578
exploration/num steps total     3600
exploration/num paths total       36
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.458783
exploration/Rewards Std            0.270139
exploration/Rewards Max           -0.0147673
exploration/Rewards Min           -1
exploration/Returns Mean         -45.8783
exploration/Returns Std            2.15648
exploration/Returns Max          -43.7218
exploration/Returns Min          -48.0348
exploration/Actions Mean           0.0328821
exploration/Actions Std            0.579939
exploration/Actions Max            0.988999
exploration/Actions Min           -0.977693
exploration/Num Paths              2
exploration/Average Returns      -45.8783
evaluation/num steps total     17000
evaluation/num paths total       170
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.156499
evaluation/Rewards Std             0.237971
evaluation/Rewards Max            -0.0801154
evaluation/Rewards Min            -1
evaluation/Returns Mean          -15.6499
evaluation/Returns Std             4.55712
evaluation/Returns Max           -10.1399
evaluation/Returns Min           -24.1295
evaluation/Actions Mean            0.0264874
evaluation/Actions Std             0.152792
evaluation/Actions Max             0.869908
evaluation/Actions Min            -0.668239
evaluation/Num Paths              10
evaluation/Average Returns       -15.6499
time/data storing (s)              0.00115898
time/evaluation sampling (s)       0.266141
time/exploration sampling (s)      0.069648
time/logging (s)                   0.00337715
time/saving (s)                    0.00226647
time/training (s)                  0.991378
time/epoch (s)                     1.33397
time/total (s)                    23.0387
Epoch                             16
-----------------------------  --------------
2019-04-22 20:53:00.599518 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 17 finished
-----------------------------  --------------
replay_buffer/size              3800
trainer/QF1 Loss                   0.106543
trainer/QF2 Loss                   0.10963
trainer/Policy Loss                7.52821
trainer/Q1 Predictions Mean       -8.80665
trainer/Q1 Predictions Std         2.74859
trainer/Q1 Predictions Max        -6.29179
trainer/Q1 Predictions Min       -14.1577
trainer/Q2 Predictions Mean       -8.81433
trainer/Q2 Predictions Std         2.74176
trainer/Q2 Predictions Max        -6.31134
trainer/Q2 Predictions Min       -14.2677
trainer/Q Targets Mean            -8.84825
trainer/Q Targets Std              2.87229
trainer/Q Targets Max             -5.95517
trainer/Q Targets Min            -14.3286
trainer/Log Pis Mean              -1.13438
trainer/Log Pis Std                0.720306
trainer/Log Pis Max                0.594189
trainer/Log Pis Min               -3.09936
trainer/Policy mu Mean             0.0733021
trainer/Policy mu Std              0.427701
trainer/Policy mu Max              1.02496
trainer/Policy mu Min             -1.14935
trainer/Policy log std Mean       -0.299023
trainer/Policy log std Std         0.0729443
trainer/Policy log std Max        -0.203297
trainer/Policy log std Min        -0.467833
trainer/Alpha                      0.366477
trainer/Alpha Loss                -3.14544
exploration/num steps total     3800
exploration/num paths total       38
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.43063
exploration/Rewards Std            0.232177
exploration/Rewards Max           -0.0405791
exploration/Rewards Min           -1
exploration/Returns Mean         -43.063
exploration/Returns Std            2.48505
exploration/Returns Max          -40.5779
exploration/Returns Min          -45.548
exploration/Actions Mean           0.0431807
exploration/Actions Std            0.566487
exploration/Actions Max            0.991304
exploration/Actions Min           -0.992136
exploration/Num Paths              2
exploration/Average Returns      -43.063
evaluation/num steps total     18000
evaluation/num paths total       180
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.115191
evaluation/Rewards Std             0.205487
evaluation/Rewards Max            -0.0207373
evaluation/Rewards Min            -1
evaluation/Returns Mean          -11.5191
evaluation/Returns Std             2.31905
evaluation/Returns Max            -8.16783
evaluation/Returns Min           -16.0609
evaluation/Actions Mean            0.0140175
evaluation/Actions Std             0.142413
evaluation/Actions Max             0.860691
evaluation/Actions Min            -0.812288
evaluation/Num Paths              10
evaluation/Average Returns       -11.5191
time/data storing (s)              0.00118204
time/evaluation sampling (s)       0.269644
time/exploration sampling (s)      0.0693064
time/logging (s)                   0.0034918
time/saving (s)                    0.00233692
time/training (s)                  1.00377
time/epoch (s)                     1.34973
time/total (s)                    24.3926
Epoch                             17
-----------------------------  --------------
2019-04-22 20:53:01.945202 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 18 finished
-----------------------------  --------------
replay_buffer/size              4000
trainer/QF1 Loss                   0.602093
trainer/QF2 Loss                   0.599735
trainer/Policy Loss                7.29834
trainer/Q1 Predictions Mean       -8.38232
trainer/Q1 Predictions Std         2.52034
trainer/Q1 Predictions Max        -6.29478
trainer/Q1 Predictions Min       -14.2051
trainer/Q2 Predictions Mean       -8.39499
trainer/Q2 Predictions Std         2.5224
trainer/Q2 Predictions Max        -6.28698
trainer/Q2 Predictions Min       -14.2884
trainer/Q Targets Mean            -8.58635
trainer/Q Targets Std              2.72022
trainer/Q Targets Max             -0.678432
trainer/Q Targets Min            -14.7653
trainer/Log Pis Mean              -0.886853
trainer/Log Pis Std                0.85066
trainer/Log Pis Max                1.34615
trainer/Log Pis Min               -3.70302
trainer/Policy mu Mean             0.0852797
trainer/Policy mu Std              0.512228
trainer/Policy mu Max              1.34997
trainer/Policy mu Min             -1.18628
trainer/Policy log std Mean       -0.351936
trainer/Policy log std Std         0.0855695
trainer/Policy log std Max        -0.226488
trainer/Policy log std Min        -0.545647
trainer/Alpha                      0.346077
trainer/Alpha Loss                -3.06241
exploration/num steps total     4000
exploration/num paths total       40
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.38279
exploration/Rewards Std            0.241718
exploration/Rewards Max           -0.00651426
exploration/Rewards Min           -1
exploration/Returns Mean         -38.279
exploration/Returns Std            7.86803
exploration/Returns Max          -30.411
exploration/Returns Min          -46.1471
exploration/Actions Mean           0.0242128
exploration/Actions Std            0.531746
exploration/Actions Max            0.993094
exploration/Actions Min           -0.963763
exploration/Num Paths              2
exploration/Average Returns      -38.279
evaluation/num steps total     19000
evaluation/num paths total       190
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0977606
evaluation/Rewards Std             0.222329
evaluation/Rewards Max            -0.0116327
evaluation/Rewards Min            -1
evaluation/Returns Mean           -9.77606
evaluation/Returns Std             4.4883
evaluation/Returns Max            -3.90405
evaluation/Returns Min           -17.6247
evaluation/Actions Mean            0.00756431
evaluation/Actions Std             0.151353
evaluation/Actions Max             0.884252
evaluation/Actions Min            -0.842726
evaluation/Num Paths              10
evaluation/Average Returns        -9.77606
time/data storing (s)              0.00118767
time/evaluation sampling (s)       0.265792
time/exploration sampling (s)      0.0697056
time/logging (s)                   0.00365143
time/saving (s)                    0.00190502
time/training (s)                  0.998292
time/epoch (s)                     1.34053
time/total (s)                    25.7373
Epoch                             18
-----------------------------  --------------
2019-04-22 20:53:03.296350 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 19 finished
-----------------------------  --------------
replay_buffer/size              4200
trainer/QF1 Loss                   0.107471
trainer/QF2 Loss                   0.118749
trainer/Policy Loss                7.98247
trainer/Q1 Predictions Mean       -9.22243
trainer/Q1 Predictions Std         3.04148
trainer/Q1 Predictions Max        -6.5092
trainer/Q1 Predictions Min       -16.6656
trainer/Q2 Predictions Mean       -9.19633
trainer/Q2 Predictions Std         3.0346
trainer/Q2 Predictions Max        -6.50885
trainer/Q2 Predictions Min       -16.8399
trainer/Q Targets Mean            -9.30148
trainer/Q Targets Std              2.92853
trainer/Q Targets Max             -6.59802
trainer/Q Targets Min            -16.3024
trainer/Log Pis Mean              -0.954354
trainer/Log Pis Std                0.781679
trainer/Log Pis Max                1.58886
trainer/Log Pis Min               -3.53891
trainer/Policy mu Mean             0.219285
trainer/Policy mu Std              0.496667
trainer/Policy mu Max              1.43851
trainer/Policy mu Min             -0.870163
trainer/Policy log std Mean       -0.360726
trainer/Policy log std Std         0.0815028
trainer/Policy log std Max        -0.231217
trainer/Policy log std Min        -0.521438
trainer/Alpha                      0.326886
trainer/Alpha Loss                -3.30254
exploration/num steps total     4200
exploration/num paths total       42
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.412233
exploration/Rewards Std            0.284219
exploration/Rewards Max           -0.00728813
exploration/Rewards Min           -1
exploration/Returns Mean         -41.2233
exploration/Returns Std            0.829782
exploration/Returns Max          -40.3935
exploration/Returns Min          -42.0531
exploration/Actions Mean           0.0582893
exploration/Actions Std            0.537011
exploration/Actions Max            0.985248
exploration/Actions Min           -0.986379
exploration/Num Paths              2
exploration/Average Returns      -41.2233
evaluation/num steps total     20000
evaluation/num paths total       200
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0888158
evaluation/Rewards Std             0.227639
evaluation/Rewards Max            -0.00695955
evaluation/Rewards Min            -1
evaluation/Returns Mean           -8.88158
evaluation/Returns Std             3.12253
evaluation/Returns Max            -2.89097
evaluation/Returns Min           -15.1765
evaluation/Actions Mean            0.0266997
evaluation/Actions Std             0.160764
evaluation/Actions Max             0.898265
evaluation/Actions Min            -0.704225
evaluation/Num Paths              10
evaluation/Average Returns        -8.88158
time/data storing (s)              0.00117565
time/evaluation sampling (s)       0.272806
time/exploration sampling (s)      0.0676367
time/logging (s)                   0.0034278
time/saving (s)                    0.00232282
time/training (s)                  0.998732
time/epoch (s)                     1.3461
time/total (s)                    27.0874
Epoch                             19
-----------------------------  --------------
2019-04-22 20:53:04.645659 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 20 finished
-----------------------------  --------------
replay_buffer/size              4400
trainer/QF1 Loss                   0.090771
trainer/QF2 Loss                   0.0900767
trainer/Policy Loss                8.23835
trainer/Q1 Predictions Mean       -9.22481
trainer/Q1 Predictions Std         3.06572
trainer/Q1 Predictions Max        -6.67976
trainer/Q1 Predictions Min       -15.684
trainer/Q2 Predictions Mean       -9.22705
trainer/Q2 Predictions Std         3.04811
trainer/Q2 Predictions Max        -6.74567
trainer/Q2 Predictions Min       -15.756
trainer/Q Targets Mean            -9.27204
trainer/Q Targets Std              3.04069
trainer/Q Targets Max             -6.61862
trainer/Q Targets Min            -15.9498
trainer/Log Pis Mean              -0.774035
trainer/Log Pis Std                0.888119
trainer/Log Pis Max                1.70299
trainer/Log Pis Min               -3.04679
trainer/Policy mu Mean             0.116045
trainer/Policy mu Std              0.531369
trainer/Policy mu Max              1.33261
trainer/Policy mu Min             -1.2224
trainer/Policy log std Mean       -0.360853
trainer/Policy log std Std         0.0715708
trainer/Policy log std Max        -0.241304
trainer/Policy log std Min        -0.486652
trainer/Alpha                      0.308785
trainer/Alpha Loss                -3.25902
exploration/num steps total     4400
exploration/num paths total       44
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.461444
exploration/Rewards Std            0.286144
exploration/Rewards Max           -0.00930783
exploration/Rewards Min           -1
exploration/Returns Mean         -46.1444
exploration/Returns Std            3.91669
exploration/Returns Max          -42.2278
exploration/Returns Min          -50.0611
exploration/Actions Mean           0.056548
exploration/Actions Std            0.564377
exploration/Actions Max            0.982998
exploration/Actions Min           -0.976427
exploration/Num Paths              2
exploration/Average Returns      -46.1444
evaluation/num steps total     21000
evaluation/num paths total       210
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0877383
evaluation/Rewards Std             0.241399
evaluation/Rewards Max            -0.0102163
evaluation/Rewards Min            -1
evaluation/Returns Mean           -8.77383
evaluation/Returns Std             4.623
evaluation/Returns Max            -2.43531
evaluation/Returns Min           -14.805
evaluation/Actions Mean            0.0252795
evaluation/Actions Std             0.163649
evaluation/Actions Max             0.912425
evaluation/Actions Min            -0.836265
evaluation/Num Paths              10
evaluation/Average Returns        -8.77383
time/data storing (s)              0.00115455
time/evaluation sampling (s)       0.27489
time/exploration sampling (s)      0.0682676
time/logging (s)                   0.00334176
time/saving (s)                    0.00237334
time/training (s)                  0.993963
time/epoch (s)                     1.34399
time/total (s)                    28.4357
Epoch                             20
-----------------------------  --------------
2019-04-22 20:53:06.013278 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 21 finished
-----------------------------  --------------
replay_buffer/size              4600
trainer/QF1 Loss                   1.55796
trainer/QF2 Loss                   1.57769
trainer/Policy Loss                8.17563
trainer/Q1 Predictions Mean       -9.20717
trainer/Q1 Predictions Std         2.80939
trainer/Q1 Predictions Max        -7.01515
trainer/Q1 Predictions Min       -15.3933
trainer/Q2 Predictions Mean       -9.20597
trainer/Q2 Predictions Std         2.80013
trainer/Q2 Predictions Max        -7.03806
trainer/Q2 Predictions Min       -15.3752
trainer/Q Targets Mean            -9.15308
trainer/Q Targets Std              2.9702
trainer/Q Targets Max             -1
trainer/Q Targets Min            -15.715
trainer/Log Pis Mean              -0.78697
trainer/Log Pis Std                0.969759
trainer/Log Pis Max                1.65634
trainer/Log Pis Min               -3.88228
trainer/Policy mu Mean             0.138232
trainer/Policy mu Std              0.534828
trainer/Policy mu Max              1.54946
trainer/Policy mu Min             -1.18663
trainer/Policy log std Mean       -0.387876
trainer/Policy log std Std         0.0915031
trainer/Policy log std Max        -0.241297
trainer/Policy log std Min        -0.597261
trainer/Alpha                      0.291755
trainer/Alpha Loss                -3.43232
exploration/num steps total     4600
exploration/num paths total       46
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.388685
exploration/Rewards Std            0.252747
exploration/Rewards Max           -0.0128329
exploration/Rewards Min           -1
exploration/Returns Mean         -38.8685
exploration/Returns Std            0.820519
exploration/Returns Max          -38.048
exploration/Returns Min          -39.689
exploration/Actions Mean           0.0236005
exploration/Actions Std            0.560855
exploration/Actions Max            0.987144
exploration/Actions Min           -0.992294
exploration/Num Paths              2
exploration/Average Returns      -38.8685
evaluation/num steps total     22000
evaluation/num paths total       220
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.117856
evaluation/Rewards Std             0.216804
evaluation/Rewards Max            -0.0487523
evaluation/Rewards Min            -1
evaluation/Returns Mean          -11.7856
evaluation/Returns Std             2.76158
evaluation/Returns Max            -7.85963
evaluation/Returns Min           -17.4047
evaluation/Actions Mean            0.0271202
evaluation/Actions Std             0.166108
evaluation/Actions Max             0.909865
evaluation/Actions Min            -0.793152
evaluation/Num Paths              10
evaluation/Average Returns       -11.7856
time/data storing (s)              0.00132428
time/evaluation sampling (s)       0.268611
time/exploration sampling (s)      0.0712451
time/logging (s)                   0.00342634
time/saving (s)                    0.00244235
time/training (s)                  1.01519
time/epoch (s)                     1.36223
time/total (s)                    29.8025
Epoch                             21
-----------------------------  --------------
2019-04-22 20:53:07.378960 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 22 finished
-----------------------------  --------------
replay_buffer/size              4800
trainer/QF1 Loss                   0.560053
trainer/QF2 Loss                   0.551736
trainer/Policy Loss                8.37674
trainer/Q1 Predictions Mean       -9.5325
trainer/Q1 Predictions Std         3.16601
trainer/Q1 Predictions Max        -6.91191
trainer/Q1 Predictions Min       -17.2071
trainer/Q2 Predictions Mean       -9.52616
trainer/Q2 Predictions Std         3.16828
trainer/Q2 Predictions Max        -6.97671
trainer/Q2 Predictions Min       -17.3841
trainer/Q Targets Mean            -9.56244
trainer/Q Targets Std              3.19176
trainer/Q Targets Max             -0.548248
trainer/Q Targets Min            -17.0239
trainer/Log Pis Mean              -0.843569
trainer/Log Pis Std                1.17579
trainer/Log Pis Max                1.5602
trainer/Log Pis Min               -5.32477
trainer/Policy mu Mean             0.164142
trainer/Policy mu Std              0.561556
trainer/Policy mu Max              1.60066
trainer/Policy mu Min             -1.02971
trainer/Policy log std Mean       -0.387467
trainer/Policy log std Std         0.0689992
trainer/Policy log std Max        -0.257625
trainer/Policy log std Min        -0.561562
trainer/Alpha                      0.275712
trainer/Alpha Loss                -3.66286
exploration/num steps total     4800
exploration/num paths total       48
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.378435
exploration/Rewards Std            0.243341
exploration/Rewards Max           -0.0238213
exploration/Rewards Min           -1
exploration/Returns Mean         -37.8435
exploration/Returns Std            0.455806
exploration/Returns Max          -37.3877
exploration/Returns Min          -38.2993
exploration/Actions Mean           0.0266546
exploration/Actions Std            0.565961
exploration/Actions Max            0.989514
exploration/Actions Min           -0.977687
exploration/Num Paths              2
exploration/Average Returns      -37.8435
evaluation/num steps total     23000
evaluation/num paths total       230
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.11241
evaluation/Rewards Std             0.181341
evaluation/Rewards Max            -0.00380941
evaluation/Rewards Min            -1
evaluation/Returns Mean          -11.241
evaluation/Returns Std             1.86218
evaluation/Returns Max            -7.14599
evaluation/Returns Min           -14.4385
evaluation/Actions Mean            0.0202101
evaluation/Actions Std             0.155573
evaluation/Actions Max             0.877073
evaluation/Actions Min            -0.823803
evaluation/Num Paths              10
evaluation/Average Returns       -11.241
time/data storing (s)              0.00120516
time/evaluation sampling (s)       0.273628
time/exploration sampling (s)      0.0699189
time/logging (s)                   0.00338442
time/saving (s)                    0.00241086
time/training (s)                  1.00979
time/epoch (s)                     1.36034
time/total (s)                    31.1669
Epoch                             22
-----------------------------  --------------
2019-04-22 20:53:08.764387 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 23 finished
-----------------------------  --------------
replay_buffer/size              5000
trainer/QF1 Loss                   0.120153
trainer/QF2 Loss                   0.123423
trainer/Policy Loss                8.57179
trainer/Q1 Predictions Mean       -9.73203
trainer/Q1 Predictions Std         3.16598
trainer/Q1 Predictions Max        -7.20203
trainer/Q1 Predictions Min       -17.2085
trainer/Q2 Predictions Mean       -9.74217
trainer/Q2 Predictions Std         3.16897
trainer/Q2 Predictions Max        -7.21943
trainer/Q2 Predictions Min       -17.188
trainer/Q Targets Mean            -9.91775
trainer/Q Targets Std              3.1833
trainer/Q Targets Max             -7.19595
trainer/Q Targets Min            -17.45
trainer/Log Pis Mean              -0.942875
trainer/Log Pis Std                1.04641
trainer/Log Pis Max                1.02716
trainer/Log Pis Min               -3.77094
trainer/Policy mu Mean             0.171166
trainer/Policy mu Std              0.579356
trainer/Policy mu Max              1.58549
trainer/Policy mu Min             -1.02245
trainer/Policy log std Mean       -0.413252
trainer/Policy log std Std         0.0720366
trainer/Policy log std Max        -0.292035
trainer/Policy log std Min        -0.564345
trainer/Alpha                      0.260673
trainer/Alpha Loss                -3.95584
exploration/num steps total     5000
exploration/num paths total       50
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.343821
exploration/Rewards Std            0.219641
exploration/Rewards Max           -0.032503
exploration/Rewards Min           -1
exploration/Returns Mean         -34.3821
exploration/Returns Std            4.33624
exploration/Returns Max          -30.0459
exploration/Returns Min          -38.7184
exploration/Actions Mean           0.0413811
exploration/Actions Std            0.554308
exploration/Actions Max            0.988865
exploration/Actions Min           -0.975216
exploration/Num Paths              2
exploration/Average Returns      -34.3821
evaluation/num steps total     24000
evaluation/num paths total       240
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0563228
evaluation/Rewards Std             0.196124
evaluation/Rewards Max            -0.00615536
evaluation/Rewards Min            -1
evaluation/Returns Mean           -5.63228
evaluation/Returns Std             2.2091
evaluation/Returns Max            -0.995388
evaluation/Returns Min            -8.73149
evaluation/Actions Mean            0.0197714
evaluation/Actions Std             0.152697
evaluation/Actions Max             0.919191
evaluation/Actions Min            -0.782285
evaluation/Num Paths              10
evaluation/Average Returns        -5.63228
time/data storing (s)              0.00130969
time/evaluation sampling (s)       0.273429
time/exploration sampling (s)      0.0684681
time/logging (s)                   0.00342654
time/saving (s)                    0.00234497
time/training (s)                  1.03124
time/epoch (s)                     1.38022
time/total (s)                    32.5514
Epoch                             23
-----------------------------  --------------
2019-04-22 20:53:10.173534 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 24 finished
-----------------------------  --------------
replay_buffer/size              5200
trainer/QF1 Loss                   1.69824
trainer/QF2 Loss                   1.69294
trainer/Policy Loss                8.49215
trainer/Q1 Predictions Mean       -9.49008
trainer/Q1 Predictions Std         3.03038
trainer/Q1 Predictions Max        -7.35509
trainer/Q1 Predictions Min       -19.0694
trainer/Q2 Predictions Mean       -9.49517
trainer/Q2 Predictions Std         3.03081
trainer/Q2 Predictions Max        -7.38697
trainer/Q2 Predictions Min       -19.1505
trainer/Q Targets Mean            -9.32178
trainer/Q Targets Std              3.39889
trainer/Q Targets Max             -0.287894
trainer/Q Targets Min            -19.044
trainer/Log Pis Mean              -0.846145
trainer/Log Pis Std                1.08738
trainer/Log Pis Max                2.08556
trainer/Log Pis Min               -4.87091
trainer/Policy mu Mean             0.101054
trainer/Policy mu Std              0.563118
trainer/Policy mu Max              1.42407
trainer/Policy mu Min             -1.21152
trainer/Policy log std Mean       -0.425323
trainer/Policy log std Std         0.0891309
trainer/Policy log std Max        -0.27902
trainer/Policy log std Min        -0.596745
trainer/Alpha                      0.246485
trainer/Alpha Loss                -3.9851
exploration/num steps total     5200
exploration/num paths total       52
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.333538
exploration/Rewards Std            0.221967
exploration/Rewards Max           -0.0340891
exploration/Rewards Min           -1
exploration/Returns Mean         -33.3538
exploration/Returns Std            0.499696
exploration/Returns Max          -32.8541
exploration/Returns Min          -33.8534
exploration/Actions Mean           0.0278226
exploration/Actions Std            0.531668
exploration/Actions Max            0.983739
exploration/Actions Min           -0.978721
exploration/Num Paths              2
exploration/Average Returns      -33.3538
evaluation/num steps total     25000
evaluation/num paths total       250
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.108665
evaluation/Rewards Std             0.209942
evaluation/Rewards Max            -0.0503102
evaluation/Rewards Min            -1
evaluation/Returns Mean          -10.8665
evaluation/Returns Std             2.60581
evaluation/Returns Max            -7.19672
evaluation/Returns Min           -16.265
evaluation/Actions Mean            0.0298747
evaluation/Actions Std             0.164606
evaluation/Actions Max             0.922831
evaluation/Actions Min            -0.772961
evaluation/Num Paths              10
evaluation/Average Returns       -10.8665
time/data storing (s)              0.00125098
time/evaluation sampling (s)       0.28597
time/exploration sampling (s)      0.0729766
time/logging (s)                   0.00334924
time/saving (s)                    0.00225381
time/training (s)                  1.03815
time/epoch (s)                     1.40395
time/total (s)                    33.9593
Epoch                             24
-----------------------------  --------------
2019-04-22 20:53:11.564051 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 25 finished
-----------------------------  --------------
replay_buffer/size              5400
trainer/QF1 Loss                   0.127939
trainer/QF2 Loss                   0.133958
trainer/Policy Loss                9.31652
trainer/Q1 Predictions Mean      -10.1625
trainer/Q1 Predictions Std         3.23095
trainer/Q1 Predictions Max        -7.39783
trainer/Q1 Predictions Min       -17.78
trainer/Q2 Predictions Mean      -10.162
trainer/Q2 Predictions Std         3.23582
trainer/Q2 Predictions Max        -7.45356
trainer/Q2 Predictions Min       -17.7229
trainer/Q Targets Mean           -10.3905
trainer/Q Targets Std              3.26538
trainer/Q Targets Max             -7.47429
trainer/Q Targets Min            -18.234
trainer/Log Pis Mean              -0.598893
trainer/Log Pis Std                1.05607
trainer/Log Pis Max                1.81792
trainer/Log Pis Min               -3.4342
trainer/Policy mu Mean             0.212882
trainer/Policy mu Std              0.662617
trainer/Policy mu Max              1.68415
trainer/Policy mu Min             -1.22424
trainer/Policy log std Mean       -0.423296
trainer/Policy log std Std         0.0704609
trainer/Policy log std Max        -0.302198
trainer/Policy log std Min        -0.624086
trainer/Alpha                      0.233055
trainer/Alpha Loss                -3.78451
exploration/num steps total     5400
exploration/num paths total       54
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.325859
exploration/Rewards Std            0.215193
exploration/Rewards Max           -0.0230653
exploration/Rewards Min           -1
exploration/Returns Mean         -32.5859
exploration/Returns Std            4.96885
exploration/Returns Max          -27.617
exploration/Returns Min          -37.5547
exploration/Actions Mean           0.0257932
exploration/Actions Std            0.532342
exploration/Actions Max            0.984719
exploration/Actions Min           -0.975347
exploration/Num Paths              2
exploration/Average Returns      -32.5859
evaluation/num steps total     26000
evaluation/num paths total       260
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0494116
evaluation/Rewards Std             0.168292
evaluation/Rewards Max            -0.0121297
evaluation/Rewards Min            -1
evaluation/Returns Mean           -4.94116
evaluation/Returns Std             3.08418
evaluation/Returns Max            -1.76072
evaluation/Returns Min           -10.2325
evaluation/Actions Mean            0.0281388
evaluation/Actions Std             0.142098
evaluation/Actions Max             0.930917
evaluation/Actions Min            -0.773274
evaluation/Num Paths              10
evaluation/Average Returns        -4.94116
time/data storing (s)              0.0012582
time/evaluation sampling (s)       0.283221
time/exploration sampling (s)      0.069438
time/logging (s)                   0.00358754
time/saving (s)                    0.00245063
time/training (s)                  1.02553
time/epoch (s)                     1.38549
time/total (s)                    35.3491
Epoch                             25
-----------------------------  --------------
2019-04-22 20:53:12.991005 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 26 finished
-----------------------------  --------------
replay_buffer/size              5600
trainer/QF1 Loss                   0.0745447
trainer/QF2 Loss                   0.0739658
trainer/Policy Loss                8.68359
trainer/Q1 Predictions Mean       -9.61605
trainer/Q1 Predictions Std         2.76598
trainer/Q1 Predictions Max        -7.63285
trainer/Q1 Predictions Min       -17.5058
trainer/Q2 Predictions Mean       -9.61549
trainer/Q2 Predictions Std         2.76608
trainer/Q2 Predictions Max        -7.66791
trainer/Q2 Predictions Min       -17.4917
trainer/Q Targets Mean            -9.63562
trainer/Q Targets Std              2.74263
trainer/Q Targets Max             -7.55903
trainer/Q Targets Min            -17.4506
trainer/Log Pis Mean              -0.645641
trainer/Log Pis Std                1.01464
trainer/Log Pis Max                1.90087
trainer/Log Pis Min               -3.43178
trainer/Policy mu Mean             0.0230842
trainer/Policy mu Std              0.590659
trainer/Policy mu Max              1.50957
trainer/Policy mu Min             -1.14143
trainer/Policy log std Mean       -0.465853
trainer/Policy log std Std         0.0788202
trainer/Policy log std Max        -0.310896
trainer/Policy log std Min        -0.6074
trainer/Alpha                      0.220397
trainer/Alpha Loss                -4.00033
exploration/num steps total     5600
exploration/num paths total       56
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.326833
exploration/Rewards Std            0.186372
exploration/Rewards Max           -0.00213431
exploration/Rewards Min           -1
exploration/Returns Mean         -32.6833
exploration/Returns Std            0.099139
exploration/Returns Max          -32.5841
exploration/Returns Min          -32.7824
exploration/Actions Mean          -0.0090152
exploration/Actions Std            0.522132
exploration/Actions Max            0.979993
exploration/Actions Min           -0.945588
exploration/Num Paths              2
exploration/Average Returns      -32.6833
evaluation/num steps total     27000
evaluation/num paths total       270
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.158781
evaluation/Rewards Std             0.179212
evaluation/Rewards Max            -0.113927
evaluation/Rewards Min            -1
evaluation/Returns Mean          -15.8781
evaluation/Returns Std             2.70835
evaluation/Returns Max           -12.0495
evaluation/Returns Min           -21.3339
evaluation/Actions Mean            0.0264387
evaluation/Actions Std             0.150811
evaluation/Actions Max             0.923256
evaluation/Actions Min            -0.830454
evaluation/Num Paths              10
evaluation/Average Returns       -15.8781
time/data storing (s)              0.00139921
time/evaluation sampling (s)       0.291305
time/exploration sampling (s)      0.0731053
time/logging (s)                   0.00341609
time/saving (s)                    0.0208836
time/training (s)                  1.03151
time/epoch (s)                     1.42162
time/total (s)                    36.7747
Epoch                             26
-----------------------------  --------------
2019-04-22 20:53:14.388992 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 27 finished
-----------------------------  --------------
replay_buffer/size              5800
trainer/QF1 Loss                   0.048823
trainer/QF2 Loss                   0.0509009
trainer/Policy Loss                8.66797
trainer/Q1 Predictions Mean       -9.65548
trainer/Q1 Predictions Std         2.6658
trainer/Q1 Predictions Max        -7.79263
trainer/Q1 Predictions Min       -17.3888
trainer/Q2 Predictions Mean       -9.64095
trainer/Q2 Predictions Std         2.66711
trainer/Q2 Predictions Max        -7.82563
trainer/Q2 Predictions Min       -17.3853
trainer/Q Targets Mean            -9.7065
trainer/Q Targets Std              2.69523
trainer/Q Targets Max             -7.82036
trainer/Q Targets Min            -17.5742
trainer/Log Pis Mean              -0.727841
trainer/Log Pis Std                1.01893
trainer/Log Pis Max                1.69618
trainer/Log Pis Min               -3.93367
trainer/Policy mu Mean             0.0439944
trainer/Policy mu Std              0.623332
trainer/Policy mu Max              1.54115
trainer/Policy mu Min             -1.18452
trainer/Policy log std Mean       -0.468171
trainer/Policy log std Std         0.0802279
trainer/Policy log std Max        -0.310714
trainer/Policy log std Min        -0.601917
trainer/Alpha                      0.208474
trainer/Alpha Loss                -4.27632
exploration/num steps total     5800
exploration/num paths total       58
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.347808
exploration/Rewards Std            0.225774
exploration/Rewards Max           -0.0184878
exploration/Rewards Min           -1
exploration/Returns Mean         -34.7808
exploration/Returns Std            1.987
exploration/Returns Max          -32.7938
exploration/Returns Min          -36.7678
exploration/Actions Mean           0.0491782
exploration/Actions Std            0.545525
exploration/Actions Max            0.986372
exploration/Actions Min           -0.944295
exploration/Num Paths              2
exploration/Average Returns      -34.7808
evaluation/num steps total     28000
evaluation/num paths total       280
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0711343
evaluation/Rewards Std             0.214422
evaluation/Rewards Max            -0.0071726
evaluation/Rewards Min            -1
evaluation/Returns Mean           -7.11343
evaluation/Returns Std             3.98623
evaluation/Returns Max            -1.48778
evaluation/Returns Min           -11.2378
evaluation/Actions Mean            0.0341199
evaluation/Actions Std             0.168002
evaluation/Actions Max             0.935818
evaluation/Actions Min            -0.569698
evaluation/Num Paths              10
evaluation/Average Returns        -7.11343
time/data storing (s)              0.0013043
time/evaluation sampling (s)       0.280109
time/exploration sampling (s)      0.0706027
time/logging (s)                   0.0037777
time/saving (s)                    0.00265649
time/training (s)                  1.03427
time/epoch (s)                     1.39272
time/total (s)                    38.1719
Epoch                             27
-----------------------------  --------------
2019-04-22 20:53:15.836209 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 28 finished
-----------------------------  --------------
replay_buffer/size              6000
trainer/QF1 Loss                   0.7145
trainer/QF2 Loss                   0.721623
trainer/Policy Loss                9.27142
trainer/Q1 Predictions Mean      -10.0231
trainer/Q1 Predictions Std         2.80875
trainer/Q1 Predictions Max        -7.77752
trainer/Q1 Predictions Min       -17.3471
trainer/Q2 Predictions Mean      -10.0211
trainer/Q2 Predictions Std         2.80023
trainer/Q2 Predictions Max        -7.79392
trainer/Q2 Predictions Min       -17.3133
trainer/Q Targets Mean           -10.1493
trainer/Q Targets Std              3.01526
trainer/Q Targets Max             -0.278721
trainer/Q Targets Min            -17.8499
trainer/Log Pis Mean              -0.4406
trainer/Log Pis Std                1.02618
trainer/Log Pis Max                2.10773
trainer/Log Pis Min               -3.42377
trainer/Policy mu Mean             0.124322
trainer/Policy mu Std              0.686823
trainer/Policy mu Max              1.71373
trainer/Policy mu Min             -1.25604
trainer/Policy log std Mean       -0.499198
trainer/Policy log std Std         0.0906671
trainer/Policy log std Max        -0.307135
trainer/Policy log std Min        -0.669179
trainer/Alpha                      0.197128
trainer/Alpha Loss                -3.96262
exploration/num steps total     6000
exploration/num paths total       60
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.311228
exploration/Rewards Std            0.237147
exploration/Rewards Max           -0.016519
exploration/Rewards Min           -1
exploration/Returns Mean         -31.1228
exploration/Returns Std            2.79261
exploration/Returns Max          -28.3302
exploration/Returns Min          -33.9154
exploration/Actions Mean           0.0379806
exploration/Actions Std            0.531006
exploration/Actions Max            0.966259
exploration/Actions Min           -0.969583
exploration/Num Paths              2
exploration/Average Returns      -31.1228
evaluation/num steps total     29000
evaluation/num paths total       290
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0778306
evaluation/Rewards Std             0.213065
evaluation/Rewards Max            -0.0208553
evaluation/Rewards Min            -1
evaluation/Returns Mean           -7.78306
evaluation/Returns Std             2.52203
evaluation/Returns Max            -3.69874
evaluation/Returns Min           -11.5074
evaluation/Actions Mean            0.0307694
evaluation/Actions Std             0.172076
evaluation/Actions Max             0.93728
evaluation/Actions Min            -0.808667
evaluation/Num Paths              10
evaluation/Average Returns        -7.78306
time/data storing (s)              0.00126974
time/evaluation sampling (s)       0.2789
time/exploration sampling (s)      0.0684815
time/logging (s)                   0.00315483
time/saving (s)                    0.00248708
time/training (s)                  1.08638
time/epoch (s)                     1.44068
time/total (s)                    39.6174
Epoch                             28
-----------------------------  --------------
2019-04-22 20:53:17.620841 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 29 finished
-----------------------------  --------------
replay_buffer/size              6200
trainer/QF1 Loss                   0.0702824
trainer/QF2 Loss                   0.06535
trainer/Policy Loss                9.0102
trainer/Q1 Predictions Mean       -9.73836
trainer/Q1 Predictions Std         2.57598
trainer/Q1 Predictions Max        -7.94132
trainer/Q1 Predictions Min       -17.1212
trainer/Q2 Predictions Mean       -9.73841
trainer/Q2 Predictions Std         2.57065
trainer/Q2 Predictions Max        -7.964
trainer/Q2 Predictions Min       -17.165
trainer/Q Targets Mean            -9.81371
trainer/Q Targets Std              2.52297
trainer/Q Targets Max             -7.92606
trainer/Q Targets Min            -17.0459
trainer/Log Pis Mean              -0.469535
trainer/Log Pis Std                1.07708
trainer/Log Pis Max                1.90042
trainer/Log Pis Min               -3.52181
trainer/Policy mu Mean             0.163655
trainer/Policy mu Std              0.618826
trainer/Policy mu Max              1.6125
trainer/Policy mu Min             -1.17881
trainer/Policy log std Mean       -0.561795
trainer/Policy log std Std         0.111423
trainer/Policy log std Max        -0.320656
trainer/Policy log std Min        -0.763124
trainer/Alpha                      0.186449
trainer/Alpha Loss                -4.14714
exploration/num steps total     6200
exploration/num paths total       62
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.278351
exploration/Rewards Std            0.182806
exploration/Rewards Max           -0.0228353
exploration/Rewards Min           -1
exploration/Returns Mean         -27.8351
exploration/Returns Std            4.16832
exploration/Returns Max          -23.6668
exploration/Returns Min          -32.0035
exploration/Actions Mean           0.0105694
exploration/Actions Std            0.502146
exploration/Actions Max            0.983728
exploration/Actions Min           -0.961715
exploration/Num Paths              2
exploration/Average Returns      -27.8351
evaluation/num steps total     30000
evaluation/num paths total       300
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.093356
evaluation/Rewards Std             0.217658
evaluation/Rewards Max            -0.0212128
evaluation/Rewards Min            -1
evaluation/Returns Mean           -9.3356
evaluation/Returns Std             3.36141
evaluation/Returns Max            -4.26793
evaluation/Returns Min           -13.6693
evaluation/Actions Mean            0.0226744
evaluation/Actions Std             0.180938
evaluation/Actions Max             0.938782
evaluation/Actions Min            -0.796786
evaluation/Num Paths              10
evaluation/Average Returns        -9.3356
time/data storing (s)              0.00125626
time/evaluation sampling (s)       0.287819
time/exploration sampling (s)      0.0727921
time/logging (s)                   0.0034983
time/saving (s)                    0.00283546
time/training (s)                  1.41128
time/epoch (s)                     1.77948
time/total (s)                    41.4018
Epoch                             29
-----------------------------  --------------
2019-04-22 20:53:19.088172 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 30 finished
-----------------------------  --------------
replay_buffer/size              6400
trainer/QF1 Loss                   0.799754
trainer/QF2 Loss                   0.818627
trainer/Policy Loss                9.49821
trainer/Q1 Predictions Mean      -10.178
trainer/Q1 Predictions Std         2.55668
trainer/Q1 Predictions Max        -8.25979
trainer/Q1 Predictions Min       -17.5806
trainer/Q2 Predictions Mean      -10.193
trainer/Q2 Predictions Std         2.56095
trainer/Q2 Predictions Max        -8.2909
trainer/Q2 Predictions Min       -17.6667
trainer/Q Targets Mean           -10.0102
trainer/Q Targets Std              2.84039
trainer/Q Targets Max             -0.497701
trainer/Q Targets Min            -17.7447
trainer/Log Pis Mean              -0.455767
trainer/Log Pis Std                1.11555
trainer/Log Pis Max                1.8102
trainer/Log Pis Min               -3.8992
trainer/Policy mu Mean             0.0908591
trainer/Policy mu Std              0.675726
trainer/Policy mu Max              1.76151
trainer/Policy mu Min             -1.36362
trainer/Policy log std Mean       -0.561004
trainer/Policy log std Std         0.107783
trainer/Policy log std Max        -0.324166
trainer/Policy log std Min        -0.793133
trainer/Alpha                      0.17638
trainer/Alpha Loss                -4.26036
exploration/num steps total     6400
exploration/num paths total       64
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.291493
exploration/Rewards Std            0.18838
exploration/Rewards Max           -0.0123459
exploration/Rewards Min           -1
exploration/Returns Mean         -29.1493
exploration/Returns Std            4.27565
exploration/Returns Max          -24.8737
exploration/Returns Min          -33.425
exploration/Actions Mean           0.0371378
exploration/Actions Std            0.490325
exploration/Actions Max            0.976961
exploration/Actions Min           -0.931689
exploration/Num Paths              2
exploration/Average Returns      -29.1493
evaluation/num steps total     31000
evaluation/num paths total       310
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.085031
evaluation/Rewards Std             0.172157
evaluation/Rewards Max            -0.0466625
evaluation/Rewards Min            -1
evaluation/Returns Mean           -8.5031
evaluation/Returns Std             2.54595
evaluation/Returns Max            -5.40542
evaluation/Returns Min           -15.0274
evaluation/Actions Mean            0.00506179
evaluation/Actions Std             0.147159
evaluation/Actions Max             0.941759
evaluation/Actions Min            -0.877292
evaluation/Num Paths              10
evaluation/Average Returns        -8.5031
time/data storing (s)              0.00135356
time/evaluation sampling (s)       0.293108
time/exploration sampling (s)      0.0741637
time/logging (s)                   0.00363383
time/saving (s)                    0.00253293
time/training (s)                  1.08511
time/epoch (s)                     1.4599
time/total (s)                    42.8671
Epoch                             30
-----------------------------  --------------
2019-04-22 20:53:21.143565 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 31 finished
-----------------------------  --------------
replay_buffer/size              6600
trainer/QF1 Loss                   0.696295
trainer/QF2 Loss                   0.709011
trainer/Policy Loss                9.13457
trainer/Q1 Predictions Mean       -9.78579
trainer/Q1 Predictions Std         2.33485
trainer/Q1 Predictions Max        -8.13933
trainer/Q1 Predictions Min       -17.321
trainer/Q2 Predictions Mean       -9.793
trainer/Q2 Predictions Std         2.35678
trainer/Q2 Predictions Max        -8.15722
trainer/Q2 Predictions Min       -17.4275
trainer/Q Targets Mean            -9.7763
trainer/Q Targets Std              2.56818
trainer/Q Targets Max             -0.377727
trainer/Q Targets Min            -17.6209
trainer/Log Pis Mean              -0.333863
trainer/Log Pis Std                1.04638
trainer/Log Pis Max                2.20485
trainer/Log Pis Min               -3.23645
trainer/Policy mu Mean             0.11241
trainer/Policy mu Std              0.654784
trainer/Policy mu Max              1.55844
trainer/Policy mu Min             -1.29379
trainer/Policy log std Mean       -0.582968
trainer/Policy log std Std         0.11644
trainer/Policy log std Max        -0.287311
trainer/Policy log std Min        -0.798448
trainer/Alpha                      0.166835
trainer/Alpha Loss                -4.17871
exploration/num steps total     6600
exploration/num paths total       66
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.308186
exploration/Rewards Std            0.225676
exploration/Rewards Max           -0.0108246
exploration/Rewards Min           -1
exploration/Returns Mean         -30.8186
exploration/Returns Std            0.271058
exploration/Returns Max          -30.5476
exploration/Returns Min          -31.0897
exploration/Actions Mean           0.0439408
exploration/Actions Std            0.519018
exploration/Actions Max            0.993047
exploration/Actions Min           -0.923964
exploration/Num Paths              2
exploration/Average Returns      -30.8186
evaluation/num steps total     32000
evaluation/num paths total       320
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0993261
evaluation/Rewards Std             0.22593
evaluation/Rewards Max            -0.0160529
evaluation/Rewards Min            -1
evaluation/Returns Mean           -9.93261
evaluation/Returns Std             2.62099
evaluation/Returns Max            -5.25919
evaluation/Returns Min           -13.4371
evaluation/Actions Mean            0.0444704
evaluation/Actions Std             0.19094
evaluation/Actions Max             0.944458
evaluation/Actions Min            -0.860766
evaluation/Num Paths              10
evaluation/Average Returns        -9.93261
time/data storing (s)              0.00183193
time/evaluation sampling (s)       0.334979
time/exploration sampling (s)      0.146576
time/logging (s)                   0.00391907
time/saving (s)                    0.00273183
time/training (s)                  1.55899
time/epoch (s)                     2.04903
time/total (s)                    44.9216
Epoch                             31
-----------------------------  --------------
2019-04-22 20:53:23.183149 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 32 finished
-----------------------------  --------------
replay_buffer/size              6800
trainer/QF1 Loss                   0.0781929
trainer/QF2 Loss                   0.0776399
trainer/Policy Loss                9.20458
trainer/Q1 Predictions Mean       -9.82372
trainer/Q1 Predictions Std         2.53288
trainer/Q1 Predictions Max        -8.07323
trainer/Q1 Predictions Min       -17.3763
trainer/Q2 Predictions Mean       -9.82368
trainer/Q2 Predictions Std         2.54028
trainer/Q2 Predictions Max        -8.12448
trainer/Q2 Predictions Min       -17.4547
trainer/Q Targets Mean           -10.019
trainer/Q Targets Std              2.57881
trainer/Q Targets Max             -8.17539
trainer/Q Targets Min            -17.97
trainer/Log Pis Mean              -0.385045
trainer/Log Pis Std                0.978159
trainer/Log Pis Max                1.80634
trainer/Log Pis Min               -3.96167
trainer/Policy mu Mean             0.032671
trainer/Policy mu Std              0.675787
trainer/Policy mu Max              1.63099
trainer/Policy mu Min             -1.36741
trainer/Policy log std Mean       -0.570384
trainer/Policy log std Std         0.132019
trainer/Policy log std Max        -0.279838
trainer/Policy log std Min        -0.825614
trainer/Alpha                      0.157818
trainer/Alpha Loss                -4.40287
exploration/num steps total     6800
exploration/num paths total       68
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.275687
exploration/Rewards Std            0.198604
exploration/Rewards Max           -0.00180503
exploration/Rewards Min           -1
exploration/Returns Mean         -27.5687
exploration/Returns Std            1.72293
exploration/Returns Max          -25.8458
exploration/Returns Min          -29.2916
exploration/Actions Mean           0.0392437
exploration/Actions Std            0.516389
exploration/Actions Max            0.965661
exploration/Actions Min           -0.933498
exploration/Num Paths              2
exploration/Average Returns      -27.5687
evaluation/num steps total     33000
evaluation/num paths total       330
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.107864
evaluation/Rewards Std             0.18012
evaluation/Rewards Max            -0.0656105
evaluation/Rewards Min            -1
evaluation/Returns Mean          -10.7864
evaluation/Returns Std             2.46526
evaluation/Returns Max            -6.79579
evaluation/Returns Min           -13.6285
evaluation/Actions Mean            0.0287017
evaluation/Actions Std             0.156869
evaluation/Actions Max             0.933589
evaluation/Actions Min            -0.703832
evaluation/Num Paths              10
evaluation/Average Returns       -10.7864
time/data storing (s)              0.00139613
time/evaluation sampling (s)       0.337479
time/exploration sampling (s)      0.0938501
time/logging (s)                   0.00442838
time/saving (s)                    0.00290686
time/training (s)                  1.59327
time/epoch (s)                     2.03333
time/total (s)                    46.9605
Epoch                             32
-----------------------------  --------------
2019-04-22 20:53:24.823857 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 33 finished
-----------------------------  --------------
replay_buffer/size              7000
trainer/QF1 Loss                   0.693226
trainer/QF2 Loss                   0.701242
trainer/Policy Loss                9.42173
trainer/Q1 Predictions Mean      -10.1104
trainer/Q1 Predictions Std         2.81582
trainer/Q1 Predictions Max        -8.20068
trainer/Q1 Predictions Min       -18.0433
trainer/Q2 Predictions Mean      -10.0954
trainer/Q2 Predictions Std         2.78804
trainer/Q2 Predictions Max        -8.23205
trainer/Q2 Predictions Min       -18.0484
trainer/Q Targets Mean           -10.112
trainer/Q Targets Std              2.87152
trainer/Q Targets Max             -0.377727
trainer/Q Targets Min            -18.1637
trainer/Log Pis Mean              -0.437193
trainer/Log Pis Std                0.985759
trainer/Log Pis Max                1.70099
trainer/Log Pis Min               -4.08013
trainer/Policy mu Mean             0.134223
trainer/Policy mu Std              0.691654
trainer/Policy mu Max              1.65428
trainer/Policy mu Min             -1.42785
trainer/Policy log std Mean       -0.608384
trainer/Policy log std Std         0.12886
trainer/Policy log std Max        -0.34043
trainer/Policy log std Min        -0.867545
trainer/Alpha                      0.149217
trainer/Alpha Loss                -4.63572
exploration/num steps total     7000
exploration/num paths total       70
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.272611
exploration/Rewards Std            0.206149
exploration/Rewards Max           -0.0254209
exploration/Rewards Min           -1
exploration/Returns Mean         -27.2611
exploration/Returns Std            3.94076
exploration/Returns Max          -23.3203
exploration/Returns Min          -31.2019
exploration/Actions Mean           0.0063836
exploration/Actions Std            0.477322
exploration/Actions Max            0.963401
exploration/Actions Min           -0.97142
exploration/Num Paths              2
exploration/Average Returns      -27.2611
evaluation/num steps total     34000
evaluation/num paths total       340
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0837296
evaluation/Rewards Std             0.180339
evaluation/Rewards Max            -0.0079173
evaluation/Rewards Min            -1
evaluation/Returns Mean           -8.37296
evaluation/Returns Std             3.52714
evaluation/Returns Max            -4.30326
evaluation/Returns Min           -13.4984
evaluation/Actions Mean            0.0154575
evaluation/Actions Std             0.159947
evaluation/Actions Max             0.9283
evaluation/Actions Min            -0.831464
evaluation/Num Paths              10
evaluation/Average Returns        -8.37296
time/data storing (s)              0.00191726
time/evaluation sampling (s)       0.328097
time/exploration sampling (s)      0.0915035
time/logging (s)                   0.00431105
time/saving (s)                    0.00252468
time/training (s)                  1.20548
time/epoch (s)                     1.63384
time/total (s)                    48.5997
Epoch                             33
-----------------------------  --------------
2019-04-22 20:53:26.456749 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 34 finished
-----------------------------  --------------
replay_buffer/size              7200
trainer/QF1 Loss                   0.732099
trainer/QF2 Loss                   0.739533
trainer/Policy Loss                9.53116
trainer/Q1 Predictions Mean      -10.155
trainer/Q1 Predictions Std         2.67107
trainer/Q1 Predictions Max        -8.28607
trainer/Q1 Predictions Min       -17.7209
trainer/Q2 Predictions Mean      -10.1409
trainer/Q2 Predictions Std         2.67883
trainer/Q2 Predictions Max        -8.28307
trainer/Q2 Predictions Min       -17.8024
trainer/Q Targets Mean           -10.204
trainer/Q Targets Std              2.83308
trainer/Q Targets Max             -0.393255
trainer/Q Targets Min            -17.6475
trainer/Log Pis Mean              -0.336561
trainer/Log Pis Std                1.0661
trainer/Log Pis Max                2.1807
trainer/Log Pis Min               -3.26962
trainer/Policy mu Mean             0.00625073
trainer/Policy mu Std              0.683639
trainer/Policy mu Max              1.55899
trainer/Policy mu Min             -1.38048
trainer/Policy log std Mean       -0.621959
trainer/Policy log std Std         0.123243
trainer/Policy log std Max        -0.343953
trainer/Policy log std Min        -0.873888
trainer/Alpha                      0.141173
trainer/Alpha Loss                -4.57381
exploration/num steps total     7200
exploration/num paths total       72
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.228509
exploration/Rewards Std            0.156198
exploration/Rewards Max           -0.00542082
exploration/Rewards Min           -1
exploration/Returns Mean         -22.8509
exploration/Returns Std            0.476233
exploration/Returns Max          -22.3747
exploration/Returns Min          -23.3272
exploration/Actions Mean           0.0171684
exploration/Actions Std            0.476229
exploration/Actions Max            0.984127
exploration/Actions Min           -0.92284
exploration/Num Paths              2
exploration/Average Returns      -22.8509
evaluation/num steps total     35000
evaluation/num paths total       350
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.121808
evaluation/Rewards Std             0.219114
evaluation/Rewards Max            -0.0598732
evaluation/Rewards Min            -1
evaluation/Returns Mean          -12.1808
evaluation/Returns Std             2.89301
evaluation/Returns Max            -8.40115
evaluation/Returns Min           -15.9089
evaluation/Actions Mean            0.0238492
evaluation/Actions Std             0.183848
evaluation/Actions Max             0.937153
evaluation/Actions Min            -0.890325
evaluation/Num Paths              10
evaluation/Average Returns       -12.1808
time/data storing (s)              0.00130035
time/evaluation sampling (s)       0.316792
time/exploration sampling (s)      0.078114
time/logging (s)                   0.00359662
time/saving (s)                    0.00241504
time/training (s)                  1.22396
time/epoch (s)                     1.62618
time/total (s)                    50.2306
Epoch                             34
-----------------------------  --------------
2019-04-22 20:53:28.064666 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 35 finished
-----------------------------  --------------
replay_buffer/size              7400
trainer/QF1 Loss                   0.711792
trainer/QF2 Loss                   0.713109
trainer/Policy Loss                9.73571
trainer/Q1 Predictions Mean      -10.2148
trainer/Q1 Predictions Std         2.93374
trainer/Q1 Predictions Max        -8.32402
trainer/Q1 Predictions Min       -18.2086
trainer/Q2 Predictions Mean      -10.2127
trainer/Q2 Predictions Std         2.94133
trainer/Q2 Predictions Max        -8.38048
trainer/Q2 Predictions Min       -18.1876
trainer/Q Targets Mean           -10.1527
trainer/Q Targets Std              3.03775
trainer/Q Targets Max             -0.383687
trainer/Q Targets Min            -18.0501
trainer/Log Pis Mean              -0.243959
trainer/Log Pis Std                1.21201
trainer/Log Pis Max                2.46562
trainer/Log Pis Min               -4.55737
trainer/Policy mu Mean             0.14575
trainer/Policy mu Std              0.668447
trainer/Policy mu Max              1.78398
trainer/Policy mu Min             -1.48833
trainer/Policy log std Mean       -0.681309
trainer/Policy log std Std         0.144689
trainer/Policy log std Max        -0.352728
trainer/Policy log std Min        -0.94541
trainer/Alpha                      0.133592
trainer/Alpha Loss                -4.51639
exploration/num steps total     7400
exploration/num paths total       74
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.263604
exploration/Rewards Std            0.228933
exploration/Rewards Max           -0.0183555
exploration/Rewards Min           -1
exploration/Returns Mean         -26.3604
exploration/Returns Std            2.00836
exploration/Returns Max          -24.352
exploration/Returns Min          -28.3688
exploration/Actions Mean           0.0610395
exploration/Actions Std            0.479183
exploration/Actions Max            0.969762
exploration/Actions Min           -0.905157
exploration/Num Paths              2
exploration/Average Returns      -26.3604
evaluation/num steps total     36000
evaluation/num paths total       360
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.048916
evaluation/Rewards Std             0.169055
evaluation/Rewards Max            -0.00641724
evaluation/Rewards Min            -1
evaluation/Returns Mean           -4.8916
evaluation/Returns Std             2.38397
evaluation/Returns Max            -1.58864
evaluation/Returns Min           -10.2828
evaluation/Actions Mean            0.0136442
evaluation/Actions Std             0.151844
evaluation/Actions Max             0.945911
evaluation/Actions Min            -0.889333
evaluation/Num Paths              10
evaluation/Average Returns        -4.8916
time/data storing (s)              0.00157766
time/evaluation sampling (s)       0.322687
time/exploration sampling (s)      0.0866413
time/logging (s)                   0.00410621
time/saving (s)                    0.00283422
time/training (s)                  1.18509
time/epoch (s)                     1.60294
time/total (s)                    51.838
Epoch                             35
-----------------------------  --------------
2019-04-22 20:53:29.652221 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 36 finished
-----------------------------  --------------
replay_buffer/size              7600
trainer/QF1 Loss                   2.24428
trainer/QF2 Loss                   2.26395
trainer/Policy Loss                9.32194
trainer/Q1 Predictions Mean       -9.88914
trainer/Q1 Predictions Std         2.45871
trainer/Q1 Predictions Max        -8.48148
trainer/Q1 Predictions Min       -17.6039
trainer/Q2 Predictions Mean       -9.87921
trainer/Q2 Predictions Std         2.44951
trainer/Q2 Predictions Max        -8.48182
trainer/Q2 Predictions Min       -17.4933
trainer/Q Targets Mean            -9.69023
trainer/Q Targets Std              2.76601
trainer/Q Targets Max             -0.452071
trainer/Q Targets Min            -17.6266
trainer/Log Pis Mean              -0.363081
trainer/Log Pis Std                1.15279
trainer/Log Pis Max                2.7785
trainer/Log Pis Min               -4.29567
trainer/Policy mu Mean             0.0639674
trainer/Policy mu Std              0.649525
trainer/Policy mu Max              1.70479
trainer/Policy mu Min             -1.39876
trainer/Policy log std Mean       -0.669959
trainer/Policy log std Std         0.116728
trainer/Policy log std Max        -0.38624
trainer/Policy log std Min        -0.921562
trainer/Alpha                      0.126381
trainer/Alpha Loss                -4.88726
exploration/num steps total     7600
exploration/num paths total       76
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.256366
exploration/Rewards Std            0.228942
exploration/Rewards Max           -0.0136805
exploration/Rewards Min           -1
exploration/Returns Mean         -25.6366
exploration/Returns Std            0.118949
exploration/Returns Max          -25.5176
exploration/Returns Min          -25.7555
exploration/Actions Mean           0.0513823
exploration/Actions Std            0.465234
exploration/Actions Max            0.974279
exploration/Actions Min           -0.932229
exploration/Num Paths              2
exploration/Average Returns      -25.6366
evaluation/num steps total     37000
evaluation/num paths total       370
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0809838
evaluation/Rewards Std             0.231147
evaluation/Rewards Max            -0.00475455
evaluation/Rewards Min            -1
evaluation/Returns Mean           -8.09838
evaluation/Returns Std             3.2462
evaluation/Returns Max            -2.097
evaluation/Returns Min           -12.0128
evaluation/Actions Mean            0.0244967
evaluation/Actions Std             0.200478
evaluation/Actions Max             0.952185
evaluation/Actions Min            -0.890739
evaluation/Num Paths              10
evaluation/Average Returns        -8.09838
time/data storing (s)              0.00137916
time/evaluation sampling (s)       0.31593
time/exploration sampling (s)      0.0809005
time/logging (s)                   0.00361765
time/saving (s)                    0.00273607
time/training (s)                  1.17494
time/epoch (s)                     1.57951
time/total (s)                    53.4235
Epoch                             36
-----------------------------  --------------
2019-04-22 20:53:31.205853 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 37 finished
-----------------------------  --------------
replay_buffer/size              7800
trainer/QF1 Loss                   0.0402051
trainer/QF2 Loss                   0.039688
trainer/Policy Loss                9.37413
trainer/Q1 Predictions Mean       -9.80434
trainer/Q1 Predictions Std         2.16064
trainer/Q1 Predictions Max        -8.52027
trainer/Q1 Predictions Min       -16.7799
trainer/Q2 Predictions Mean       -9.79997
trainer/Q2 Predictions Std         2.14579
trainer/Q2 Predictions Max        -8.55095
trainer/Q2 Predictions Min       -16.5983
trainer/Q Targets Mean            -9.79349
trainer/Q Targets Std              2.19824
trainer/Q Targets Max             -8.40774
trainer/Q Targets Min            -16.7513
trainer/Log Pis Mean              -0.253789
trainer/Log Pis Std                1.00949
trainer/Log Pis Max                1.82818
trainer/Log Pis Min               -2.74757
trainer/Policy mu Mean             0.0649692
trainer/Policy mu Std              0.682017
trainer/Policy mu Max              1.81878
trainer/Policy mu Min             -1.49412
trainer/Policy log std Mean       -0.702748
trainer/Policy log std Std         0.133348
trainer/Policy log std Max        -0.376737
trainer/Policy log std Min        -0.97039
trainer/Alpha                      0.119573
trainer/Alpha Loss                -4.78605
exploration/num steps total     7800
exploration/num paths total       78
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.276895
exploration/Rewards Std            0.215061
exploration/Rewards Max           -0.0282793
exploration/Rewards Min           -1
exploration/Returns Mean         -27.6895
exploration/Returns Std            1.37546
exploration/Returns Max          -26.3141
exploration/Returns Min          -29.065
exploration/Actions Mean           0.0352515
exploration/Actions Std            0.483629
exploration/Actions Max            0.98499
exploration/Actions Min           -0.965404
exploration/Num Paths              2
exploration/Average Returns      -27.6895
evaluation/num steps total     38000
evaluation/num paths total       380
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0987036
evaluation/Rewards Std             0.199093
evaluation/Rewards Max            -0.0391588
evaluation/Rewards Min            -1
evaluation/Returns Mean           -9.87036
evaluation/Returns Std             3.11554
evaluation/Returns Max            -5.13058
evaluation/Returns Min           -13.9433
evaluation/Actions Mean            0.0340438
evaluation/Actions Std             0.172824
evaluation/Actions Max             0.950222
evaluation/Actions Min            -0.793892
evaluation/Num Paths              10
evaluation/Average Returns        -9.87036
time/data storing (s)              0.00184184
time/evaluation sampling (s)       0.309658
time/exploration sampling (s)      0.0793115
time/logging (s)                   0.0038235
time/saving (s)                    0.00274063
time/training (s)                  1.15061
time/epoch (s)                     1.54799
time/total (s)                    54.976
Epoch                             37
-----------------------------  --------------
2019-04-22 20:53:32.816468 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 38 finished
-----------------------------  --------------
replay_buffer/size              8000
trainer/QF1 Loss                   0.843271
trainer/QF2 Loss                   0.835417
trainer/Policy Loss                9.46157
trainer/Q1 Predictions Mean       -9.90674
trainer/Q1 Predictions Std         2.2898
trainer/Q1 Predictions Max        -8.48154
trainer/Q1 Predictions Min       -17.553
trainer/Q2 Predictions Mean       -9.92046
trainer/Q2 Predictions Std         2.28387
trainer/Q2 Predictions Max        -8.50573
trainer/Q2 Predictions Min       -17.7315
trainer/Q Targets Mean            -9.92346
trainer/Q Targets Std              2.44915
trainer/Q Targets Max             -0.678432
trainer/Q Targets Min            -17.5409
trainer/Log Pis Mean              -0.249952
trainer/Log Pis Std                1.15796
trainer/Log Pis Max                2.99659
trainer/Log Pis Min               -3.38715
trainer/Policy mu Mean             0.0178472
trainer/Policy mu Std              0.733307
trainer/Policy mu Max              1.70677
trainer/Policy mu Min             -1.60099
trainer/Policy log std Mean       -0.689575
trainer/Policy log std Std         0.140677
trainer/Policy log std Max        -0.400152
trainer/Policy log std Min        -0.989576
trainer/Alpha                      0.113143
trainer/Alpha Loss                -4.90225
exploration/num steps total     8000
exploration/num paths total       80
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.266145
exploration/Rewards Std            0.199308
exploration/Rewards Max           -0.00528112
exploration/Rewards Min           -1
exploration/Returns Mean         -26.6145
exploration/Returns Std            0.789974
exploration/Returns Max          -25.8245
exploration/Returns Min          -27.4044
exploration/Actions Mean           0.0374227
exploration/Actions Std            0.475727
exploration/Actions Max            0.976132
exploration/Actions Min           -0.916503
exploration/Num Paths              2
exploration/Average Returns      -26.6145
evaluation/num steps total     39000
evaluation/num paths total       390
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0557352
evaluation/Rewards Std             0.182793
evaluation/Rewards Max            -0.0119993
evaluation/Rewards Min            -1
evaluation/Returns Mean           -5.57352
evaluation/Returns Std             1.98894
evaluation/Returns Max            -1.83831
evaluation/Returns Min            -8.76966
evaluation/Actions Mean            0.0179656
evaluation/Actions Std             0.165567
evaluation/Actions Max             0.95122
evaluation/Actions Min            -0.910327
evaluation/Num Paths              10
evaluation/Average Returns        -5.57352
time/data storing (s)              0.00132183
time/evaluation sampling (s)       0.299133
time/exploration sampling (s)      0.0735141
time/logging (s)                   0.00371434
time/saving (s)                    0.00274476
time/training (s)                  1.22387
time/epoch (s)                     1.6043
time/total (s)                    56.5855
Epoch                             38
-----------------------------  --------------
2019-04-22 20:53:34.293834 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 39 finished
-----------------------------  --------------
replay_buffer/size              8200
trainer/QF1 Loss                   0.0497639
trainer/QF2 Loss                   0.0514158
trainer/Policy Loss                9.79636
trainer/Q1 Predictions Mean      -10.1956
trainer/Q1 Predictions Std         2.41009
trainer/Q1 Predictions Max        -8.54092
trainer/Q1 Predictions Min       -16.667
trainer/Q2 Predictions Mean      -10.1982
trainer/Q2 Predictions Std         2.41575
trainer/Q2 Predictions Max        -8.57974
trainer/Q2 Predictions Min       -16.8097
trainer/Q Targets Mean           -10.1406
trainer/Q Targets Std              2.34019
trainer/Q Targets Max             -8.55344
trainer/Q Targets Min            -16.7201
trainer/Log Pis Mean              -0.0774476
trainer/Log Pis Std                1.21208
trainer/Log Pis Max                3.27344
trainer/Log Pis Min               -3.66407
trainer/Policy mu Mean             0.167989
trainer/Policy mu Std              0.740853
trainer/Policy mu Max              1.78734
trainer/Policy mu Min             -1.6071
trainer/Policy log std Mean       -0.752507
trainer/Policy log std Std         0.152244
trainer/Policy log std Max        -0.401568
trainer/Policy log std Min        -1.06804
trainer/Alpha                      0.107003
trainer/Alpha Loss                -4.64231
exploration/num steps total     8200
exploration/num paths total       82
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.200892
exploration/Rewards Std            0.104237
exploration/Rewards Max           -0.0125337
exploration/Rewards Min           -0.514864
exploration/Returns Mean         -20.0892
exploration/Returns Std            0.154975
exploration/Returns Max          -19.9342
exploration/Returns Min          -20.2442
exploration/Actions Mean           0.00649726
exploration/Actions Std            0.445191
exploration/Actions Max            0.935447
exploration/Actions Min           -0.94196
exploration/Num Paths              2
exploration/Average Returns      -20.0892
evaluation/num steps total     40000
evaluation/num paths total       400
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0713725
evaluation/Rewards Std             0.217072
evaluation/Rewards Max            -0.0143589
evaluation/Rewards Min            -1
evaluation/Returns Mean           -7.13725
evaluation/Returns Std             2.38436
evaluation/Returns Max            -3.03647
evaluation/Returns Min           -11.6055
evaluation/Actions Mean            0.0367396
evaluation/Actions Std             0.197972
evaluation/Actions Max             0.946775
evaluation/Actions Min            -0.889605
evaluation/Num Paths              10
evaluation/Average Returns        -7.13725
time/data storing (s)              0.00122987
time/evaluation sampling (s)       0.284938
time/exploration sampling (s)      0.0701393
time/logging (s)                   0.00374189
time/saving (s)                    0.00258863
time/training (s)                  1.10904
time/epoch (s)                     1.47167
time/total (s)                    58.0617
Epoch                             39
-----------------------------  --------------
2019-04-22 20:53:35.760106 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 40 finished
-----------------------------  --------------
replay_buffer/size              8400
trainer/QF1 Loss                   0.753901
trainer/QF2 Loss                   0.762333
trainer/Policy Loss                9.61689
trainer/Q1 Predictions Mean       -9.93578
trainer/Q1 Predictions Std         2.06214
trainer/Q1 Predictions Max        -8.5914
trainer/Q1 Predictions Min       -16.5161
trainer/Q2 Predictions Mean       -9.94408
trainer/Q2 Predictions Std         2.07647
trainer/Q2 Predictions Max        -8.6315
trainer/Q2 Predictions Min       -16.7038
trainer/Q Targets Mean            -9.87159
trainer/Q Targets Std              2.26268
trainer/Q Targets Max             -0.39035
trainer/Q Targets Min            -16.7843
trainer/Log Pis Mean              -0.103752
trainer/Log Pis Std                1.00347
trainer/Log Pis Max                2.98885
trainer/Log Pis Min               -3.61781
trainer/Policy mu Mean             0.0299493
trainer/Policy mu Std              0.72847
trainer/Policy mu Max              1.72532
trainer/Policy mu Min             -1.58046
trainer/Policy log std Mean       -0.78878
trainer/Policy log std Std         0.141719
trainer/Policy log std Max        -0.443926
trainer/Policy log std Min        -1.04891
trainer/Alpha                      0.101332
trainer/Alpha Loss                -4.81566
exploration/num steps total     8400
exploration/num paths total       84
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.219341
exploration/Rewards Std            0.141619
exploration/Rewards Max           -0.018414
exploration/Rewards Min           -1
exploration/Returns Mean         -21.9341
exploration/Returns Std            0.39954
exploration/Returns Max          -21.5346
exploration/Returns Min          -22.3337
exploration/Actions Mean           0.026973
exploration/Actions Std            0.434863
exploration/Actions Max            0.962143
exploration/Actions Min           -0.943858
exploration/Num Paths              2
exploration/Average Returns      -21.9341
evaluation/num steps total     41000
evaluation/num paths total       410
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.133413
evaluation/Rewards Std             0.215489
evaluation/Rewards Max            -0.0666294
evaluation/Rewards Min            -1
evaluation/Returns Mean          -13.3413
evaluation/Returns Std             3.05158
evaluation/Returns Max            -8.07487
evaluation/Returns Min           -17.1364
evaluation/Actions Mean            0.0320776
evaluation/Actions Std             0.201275
evaluation/Actions Max             0.941293
evaluation/Actions Min            -0.908162
evaluation/Num Paths              10
evaluation/Average Returns       -13.3413
time/data storing (s)              0.00122844
time/evaluation sampling (s)       0.284263
time/exploration sampling (s)      0.0709555
time/logging (s)                   0.00360512
time/saving (s)                    0.00266394
time/training (s)                  1.09787
time/epoch (s)                     1.46058
time/total (s)                    59.5266
Epoch                             40
-----------------------------  --------------
2019-04-22 20:53:37.235869 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 41 finished
-----------------------------  --------------
replay_buffer/size              8600
trainer/QF1 Loss                   1.50264
trainer/QF2 Loss                   1.49922
trainer/Policy Loss                9.28876
trainer/Q1 Predictions Mean       -9.71341
trainer/Q1 Predictions Std         1.69146
trainer/Q1 Predictions Max        -8.64714
trainer/Q1 Predictions Min       -16.7022
trainer/Q2 Predictions Mean       -9.70445
trainer/Q2 Predictions Std         1.69864
trainer/Q2 Predictions Max        -8.65768
trainer/Q2 Predictions Min       -16.7063
trainer/Q Targets Mean            -9.52468
trainer/Q Targets Std              2.17269
trainer/Q Targets Max             -0.263902
trainer/Q Targets Min            -16.9681
trainer/Log Pis Mean              -0.200084
trainer/Log Pis Std                1.12138
trainer/Log Pis Max                2.81829
trainer/Log Pis Min               -2.62847
trainer/Policy mu Mean             0.122305
trainer/Policy mu Std              0.704703
trainer/Policy mu Max              1.77306
trainer/Policy mu Min             -1.65991
trainer/Policy log std Mean       -0.765524
trainer/Policy log std Std         0.139593
trainer/Policy log std Max        -0.431527
trainer/Policy log std Min        -1.0342
trainer/Alpha                      0.095935
trainer/Alpha Loss                -5.15658
exploration/num steps total     8600
exploration/num paths total       86
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.238474
exploration/Rewards Std            0.18001
exploration/Rewards Max           -0.018351
exploration/Rewards Min           -1
exploration/Returns Mean         -23.8474
exploration/Returns Std            0.437772
exploration/Returns Max          -23.4096
exploration/Returns Min          -24.2851
exploration/Actions Mean          -0.0020045
exploration/Actions Std            0.478291
exploration/Actions Max            0.992603
exploration/Actions Min           -0.966412
exploration/Num Paths              2
exploration/Average Returns      -23.8474
evaluation/num steps total     42000
evaluation/num paths total       420
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0923925
evaluation/Rewards Std             0.163974
evaluation/Rewards Max            -0.0246773
evaluation/Rewards Min            -1
evaluation/Returns Mean           -9.23925
evaluation/Returns Std             2.8575
evaluation/Returns Max            -5.96793
evaluation/Returns Min           -14.9021
evaluation/Actions Mean            0.0126447
evaluation/Actions Std             0.166196
evaluation/Actions Max             0.943419
evaluation/Actions Min            -0.900938
evaluation/Num Paths              10
evaluation/Average Returns        -9.23925
time/data storing (s)              0.00123464
time/evaluation sampling (s)       0.291581
time/exploration sampling (s)      0.0699942
time/logging (s)                   0.00307516
time/saving (s)                    0.00246176
time/training (s)                  1.10103
time/epoch (s)                     1.46938
time/total (s)                    61.0005
Epoch                             41
-----------------------------  --------------
2019-04-22 20:53:38.699046 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 42 finished
-----------------------------  --------------
replay_buffer/size              8800
trainer/QF1 Loss                   1.4941
trainer/QF2 Loss                   1.49005
trainer/Policy Loss                9.26282
trainer/Q1 Predictions Mean       -9.76355
trainer/Q1 Predictions Std         2.01885
trainer/Q1 Predictions Max        -8.51962
trainer/Q1 Predictions Min       -17.0106
trainer/Q2 Predictions Mean       -9.77033
trainer/Q2 Predictions Std         2.00745
trainer/Q2 Predictions Max        -8.59033
trainer/Q2 Predictions Min       -17.0739
trainer/Q Targets Mean            -9.76726
trainer/Q Targets Std              2.47323
trainer/Q Targets Max             -0.383687
trainer/Q Targets Min            -17.0638
trainer/Log Pis Mean              -0.284401
trainer/Log Pis Std                1.08173
trainer/Log Pis Max                2.28825
trainer/Log Pis Min               -3.21111
trainer/Policy mu Mean             0.132968
trainer/Policy mu Std              0.667493
trainer/Policy mu Max              1.62354
trainer/Policy mu Min             -1.48875
trainer/Policy log std Mean       -0.82293
trainer/Policy log std Std         0.145335
trainer/Policy log std Max        -0.454145
trainer/Policy log std Min        -1.06737
trainer/Alpha                      0.090812
trainer/Alpha Loss                -5.47957
exploration/num steps total     8800
exploration/num paths total       88
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.229337
exploration/Rewards Std            0.205699
exploration/Rewards Max           -0.0111766
exploration/Rewards Min           -1
exploration/Returns Mean         -22.9337
exploration/Returns Std            3.12221
exploration/Returns Max          -19.8115
exploration/Returns Min          -26.0559
exploration/Actions Mean           0.0102509
exploration/Actions Std            0.450469
exploration/Actions Max            0.963294
exploration/Actions Min           -0.970218
exploration/Num Paths              2
exploration/Average Returns      -22.9337
evaluation/num steps total     43000
evaluation/num paths total       430
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.132573
evaluation/Rewards Std             0.193753
evaluation/Rewards Max            -0.0397533
evaluation/Rewards Min            -1
evaluation/Returns Mean          -13.2573
evaluation/Returns Std             2.57612
evaluation/Returns Max            -8.53861
evaluation/Returns Min           -17.8277
evaluation/Actions Mean            0.0173918
evaluation/Actions Std             0.189679
evaluation/Actions Max             0.952306
evaluation/Actions Min            -0.949196
evaluation/Num Paths              10
evaluation/Average Returns       -13.2573
time/data storing (s)              0.00124082
time/evaluation sampling (s)       0.289196
time/exploration sampling (s)      0.0733126
time/logging (s)                   0.00385838
time/saving (s)                    0.00255766
time/training (s)                  1.08787
time/epoch (s)                     1.45803
time/total (s)                    62.463
Epoch                             42
-----------------------------  --------------
2019-04-22 20:53:40.262229 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 43 finished
-----------------------------  --------------
replay_buffer/size              9000
trainer/QF1 Loss                   0.0259048
trainer/QF2 Loss                   0.0282788
trainer/Policy Loss                8.98718
trainer/Q1 Predictions Mean       -9.54881
trainer/Q1 Predictions Std         1.84072
trainer/Q1 Predictions Max        -8.62416
trainer/Q1 Predictions Min       -15.8131
trainer/Q2 Predictions Mean       -9.55099
trainer/Q2 Predictions Std         1.86014
trainer/Q2 Predictions Max        -8.61558
trainer/Q2 Predictions Min       -15.8268
trainer/Q Targets Mean            -9.6585
trainer/Q Targets Std              1.85414
trainer/Q Targets Max             -8.68191
trainer/Q Targets Min            -16.1568
trainer/Log Pis Mean              -0.469418
trainer/Log Pis Std                1.17752
trainer/Log Pis Max                2.67443
trainer/Log Pis Min               -4.69628
trainer/Policy mu Mean             0.102758
trainer/Policy mu Std              0.640093
trainer/Policy mu Max              1.80226
trainer/Policy mu Min             -1.57572
trainer/Policy log std Mean       -0.810725
trainer/Policy log std Std         0.115845
trainer/Policy log std Max        -0.455575
trainer/Policy log std Min        -1.02906
trainer/Alpha                      0.0859919
trainer/Alpha Loss                -6.05801
exploration/num steps total     9000
exploration/num paths total       90
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.214731
exploration/Rewards Std            0.168276
exploration/Rewards Max           -0.0229369
exploration/Rewards Min           -1
exploration/Returns Mean         -21.4731
exploration/Returns Std            0.875611
exploration/Returns Max          -20.5974
exploration/Returns Min          -22.3487
exploration/Actions Mean           0.0306006
exploration/Actions Std            0.473674
exploration/Actions Max            0.980398
exploration/Actions Min           -0.962497
exploration/Num Paths              2
exploration/Average Returns      -21.4731
evaluation/num steps total     44000
evaluation/num paths total       440
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0788844
evaluation/Rewards Std             0.191728
evaluation/Rewards Max            -0.0148562
evaluation/Rewards Min            -1
evaluation/Returns Mean           -7.88844
evaluation/Returns Std             2.58585
evaluation/Returns Max            -4.09633
evaluation/Returns Min           -11.3804
evaluation/Actions Mean            0.0249953
evaluation/Actions Std             0.187249
evaluation/Actions Max             0.959177
evaluation/Actions Min            -0.900775
evaluation/Num Paths              10
evaluation/Average Returns        -7.88844
time/data storing (s)              0.00122944
time/evaluation sampling (s)       0.316015
time/exploration sampling (s)      0.0705272
time/logging (s)                   0.00392322
time/saving (s)                    0.00275581
time/training (s)                  1.163
time/epoch (s)                     1.55745
time/total (s)                    64.0248
Epoch                             43
-----------------------------  --------------
2019-04-22 20:53:41.867563 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 44 finished
-----------------------------  --------------
replay_buffer/size              9200
trainer/QF1 Loss                   0.811141
trainer/QF2 Loss                   0.80118
trainer/Policy Loss                9.76661
trainer/Q1 Predictions Mean      -10.088
trainer/Q1 Predictions Std         2.07917
trainer/Q1 Predictions Max        -8.64918
trainer/Q1 Predictions Min       -16.5876
trainer/Q2 Predictions Mean      -10.0805
trainer/Q2 Predictions Std         2.07431
trainer/Q2 Predictions Max        -8.65117
trainer/Q2 Predictions Min       -16.4949
trainer/Q Targets Mean           -10.0741
trainer/Q Targets Std              2.28311
trainer/Q Targets Max             -0.566307
trainer/Q Targets Min            -16.9625
trainer/Log Pis Mean              -0.019779
trainer/Log Pis Std                1.27882
trainer/Log Pis Max                2.89084
trainer/Log Pis Min               -6.28133
trainer/Policy mu Mean             0.1251
trainer/Policy mu Std              0.776034
trainer/Policy mu Max              1.7829
trainer/Policy mu Min             -1.65627
trainer/Policy log std Mean       -0.802163
trainer/Policy log std Std         0.154857
trainer/Policy log std Max        -0.42965
trainer/Policy log std Min        -1.09012
trainer/Alpha                      0.0813935
trainer/Alpha Loss                -5.06598
exploration/num steps total     9200
exploration/num paths total       92
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.218558
exploration/Rewards Std            0.19314
exploration/Rewards Max           -0.0143791
exploration/Rewards Min           -1
exploration/Returns Mean         -21.8558
exploration/Returns Std            3.74266
exploration/Returns Max          -18.1131
exploration/Returns Min          -25.5984
exploration/Actions Mean           0.0151744
exploration/Actions Std            0.446672
exploration/Actions Max            0.990884
exploration/Actions Min           -0.957977
exploration/Num Paths              2
exploration/Average Returns      -21.8558
evaluation/num steps total     45000
evaluation/num paths total       450
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0934673
evaluation/Rewards Std             0.206294
evaluation/Rewards Max            -0.00662063
evaluation/Rewards Min            -1
evaluation/Returns Mean           -9.34673
evaluation/Returns Std             2.29176
evaluation/Returns Max            -4.81868
evaluation/Returns Min           -13.7368
evaluation/Actions Mean            0.0314447
evaluation/Actions Std             0.191309
evaluation/Actions Max             0.955818
evaluation/Actions Min            -0.903755
evaluation/Num Paths              10
evaluation/Average Returns        -9.34673
time/data storing (s)              0.00124474
time/evaluation sampling (s)       0.297229
time/exploration sampling (s)      0.0709708
time/logging (s)                   0.00349589
time/saving (s)                    0.00768203
time/training (s)                  1.21877
time/epoch (s)                     1.59939
time/total (s)                    65.6288
Epoch                             44
-----------------------------  --------------
2019-04-22 20:53:43.410624 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 45 finished
-----------------------------  --------------
replay_buffer/size              9400
trainer/QF1 Loss                   0.0205435
trainer/QF2 Loss                   0.0198194
trainer/Policy Loss                9.78256
trainer/Q1 Predictions Mean      -10.057
trainer/Q1 Predictions Std         2.3594
trainer/Q1 Predictions Max        -8.69321
trainer/Q1 Predictions Min       -17.226
trainer/Q2 Predictions Mean      -10.0444
trainer/Q2 Predictions Std         2.34172
trainer/Q2 Predictions Max        -8.71201
trainer/Q2 Predictions Min       -17.139
trainer/Q Targets Mean           -10.1029
trainer/Q Targets Std              2.33469
trainer/Q Targets Max             -8.63153
trainer/Q Targets Min            -17.2226
trainer/Log Pis Mean              -0.0627256
trainer/Log Pis Std                1.25127
trainer/Log Pis Max                3.15821
trainer/Log Pis Min               -4.05057
trainer/Policy mu Mean             0.0927443
trainer/Policy mu Std              0.765139
trainer/Policy mu Max              1.77142
trainer/Policy mu Min             -1.68518
trainer/Policy log std Mean       -0.806639
trainer/Policy log std Std         0.145124
trainer/Policy log std Max        -0.450635
trainer/Policy log std Min        -1.08568
trainer/Alpha                      0.0769958
trainer/Alpha Loss                -5.28826
exploration/num steps total     9400
exploration/num paths total       94
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.246021
exploration/Rewards Std            0.225419
exploration/Rewards Max           -0.00601739
exploration/Rewards Min           -1
exploration/Returns Mean         -24.6021
exploration/Returns Std            0.801452
exploration/Returns Max          -23.8006
exploration/Returns Min          -25.4035
exploration/Actions Mean           0.0401441
exploration/Actions Std            0.473179
exploration/Actions Max            0.989226
exploration/Actions Min           -0.88515
exploration/Num Paths              2
exploration/Average Returns      -24.6021
evaluation/num steps total     46000
evaluation/num paths total       460
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0953757
evaluation/Rewards Std             0.188652
evaluation/Rewards Max            -0.0325696
evaluation/Rewards Min            -1
evaluation/Returns Mean           -9.53757
evaluation/Returns Std             2.91372
evaluation/Returns Max            -5.61502
evaluation/Returns Min           -13.6326
evaluation/Actions Mean            0.0214372
evaluation/Actions Std             0.178701
evaluation/Actions Max             0.957859
evaluation/Actions Min            -0.93454
evaluation/Num Paths              10
evaluation/Average Returns        -9.53757
time/data storing (s)              0.00122915
time/evaluation sampling (s)       0.290974
time/exploration sampling (s)      0.0759435
time/logging (s)                   0.00385183
time/saving (s)                    0.00255876
time/training (s)                  1.16313
time/epoch (s)                     1.53769
time/total (s)                    67.1709
Epoch                             45
-----------------------------  --------------
2019-04-22 20:53:44.896451 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 46 finished
-----------------------------  --------------
replay_buffer/size              9600
trainer/QF1 Loss                   0.025227
trainer/QF2 Loss                   0.0311667
trainer/Policy Loss                9.36649
trainer/Q1 Predictions Mean       -9.67205
trainer/Q1 Predictions Std         1.82323
trainer/Q1 Predictions Max        -8.68147
trainer/Q1 Predictions Min       -17.1192
trainer/Q2 Predictions Mean       -9.66814
trainer/Q2 Predictions Std         1.81917
trainer/Q2 Predictions Max        -8.69069
trainer/Q2 Predictions Min       -17.2571
trainer/Q Targets Mean            -9.73263
trainer/Q Targets Std              1.84419
trainer/Q Targets Max             -8.71354
trainer/Q Targets Min            -16.7406
trainer/Log Pis Mean              -0.0854045
trainer/Log Pis Std                1.1213
trainer/Log Pis Max                2.71598
trainer/Log Pis Min               -5.19758
trainer/Policy mu Mean             0.0620096
trainer/Policy mu Std              0.706022
trainer/Policy mu Max              1.88964
trainer/Policy mu Min             -1.47865
trainer/Policy log std Mean       -0.883757
trainer/Policy log std Std         0.157331
trainer/Policy log std Max        -0.508822
trainer/Policy log std Min        -1.20835
trainer/Alpha                      0.0728956
trainer/Alpha Loss                -5.46053
exploration/num steps total     9600
exploration/num paths total       96
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.237136
exploration/Rewards Std            0.220085
exploration/Rewards Max           -0.00691257
exploration/Rewards Min           -1
exploration/Returns Mean         -23.7136
exploration/Returns Std            2.10587
exploration/Returns Max          -21.6077
exploration/Returns Min          -25.8195
exploration/Actions Mean           0.031166
exploration/Actions Std            0.463768
exploration/Actions Max            0.988263
exploration/Actions Min           -0.950416
exploration/Num Paths              2
exploration/Average Returns      -23.7136
evaluation/num steps total     47000
evaluation/num paths total       470
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0572268
evaluation/Rewards Std             0.200968
evaluation/Rewards Max            -0.0088432
evaluation/Rewards Min            -1
evaluation/Returns Mean           -5.72268
evaluation/Returns Std             2.58026
evaluation/Returns Max            -3.06801
evaluation/Returns Min           -10.8801
evaluation/Actions Mean            0.0163948
evaluation/Actions Std             0.177665
evaluation/Actions Max             0.960027
evaluation/Actions Min            -0.950681
evaluation/Num Paths              10
evaluation/Average Returns        -5.72268
time/data storing (s)              0.00122144
time/evaluation sampling (s)       0.294777
time/exploration sampling (s)      0.0724491
time/logging (s)                   0.00369542
time/saving (s)                    0.00249886
time/training (s)                  1.1045
time/epoch (s)                     1.47914
time/total (s)                    68.655
Epoch                             46
-----------------------------  --------------
2019-04-22 20:53:46.392931 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 47 finished
-----------------------------  --------------
replay_buffer/size              9800
trainer/QF1 Loss                   1.47602
trainer/QF2 Loss                   1.48363
trainer/Policy Loss                9.80954
trainer/Q1 Predictions Mean       -9.79115
trainer/Q1 Predictions Std         2.11468
trainer/Q1 Predictions Max        -8.55204
trainer/Q1 Predictions Min       -17.475
trainer/Q2 Predictions Mean       -9.78309
trainer/Q2 Predictions Std         2.11551
trainer/Q2 Predictions Max        -8.5975
trainer/Q2 Predictions Min       -17.5197
trainer/Q Targets Mean            -9.75252
trainer/Q Targets Std              2.49888
trainer/Q Targets Max             -0.177995
trainer/Q Targets Min            -17.4813
trainer/Log Pis Mean               0.23063
trainer/Log Pis Std                1.1832
trainer/Log Pis Max                2.93557
trainer/Log Pis Min               -3.75309
trainer/Policy mu Mean             0.075761
trainer/Policy mu Std              0.773038
trainer/Policy mu Max              1.87102
trainer/Policy mu Min             -1.76302
trainer/Policy log std Mean       -0.943921
trainer/Policy log std Std         0.173943
trainer/Policy log std Max        -0.470691
trainer/Policy log std Min        -1.24482
trainer/Alpha                      0.0690786
trainer/Alpha Loss                -4.72819
exploration/num steps total     9800
exploration/num paths total       98
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.19867
exploration/Rewards Std            0.184157
exploration/Rewards Max           -0.00467261
exploration/Rewards Min           -1
exploration/Returns Mean         -19.867
exploration/Returns Std            2.70712
exploration/Returns Max          -17.1599
exploration/Returns Min          -22.5741
exploration/Actions Mean           0.0186554
exploration/Actions Std            0.429348
exploration/Actions Max            0.954278
exploration/Actions Min           -0.975007
exploration/Num Paths              2
exploration/Average Returns      -19.867
evaluation/num steps total     48000
evaluation/num paths total       480
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.1228
evaluation/Rewards Std             0.215026
evaluation/Rewards Max            -0.0442829
evaluation/Rewards Min            -1
evaluation/Returns Mean          -12.28
evaluation/Returns Std             2.36123
evaluation/Returns Max            -8.64367
evaluation/Returns Min           -15.1674
evaluation/Actions Mean            0.0323941
evaluation/Actions Std             0.190656
evaluation/Actions Max             0.959624
evaluation/Actions Min            -0.923325
evaluation/Num Paths              10
evaluation/Average Returns       -12.28
time/data storing (s)              0.0012377
time/evaluation sampling (s)       0.290268
time/exploration sampling (s)      0.0714103
time/logging (s)                   0.00403772
time/saving (s)                    0.00280151
time/training (s)                  1.12087
time/epoch (s)                     1.49062
time/total (s)                    70.1504
Epoch                             47
-----------------------------  --------------
2019-04-22 20:53:47.872305 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 48 finished
-----------------------------  --------------
replay_buffer/size             10000
trainer/QF1 Loss                   0.797344
trainer/QF2 Loss                   0.811326
trainer/Policy Loss                9.88854
trainer/Q1 Predictions Mean       -9.74919
trainer/Q1 Predictions Std         2.03591
trainer/Q1 Predictions Max        -8.48739
trainer/Q1 Predictions Min       -16.3782
trainer/Q2 Predictions Mean       -9.75567
trainer/Q2 Predictions Std         2.03723
trainer/Q2 Predictions Max        -8.55296
trainer/Q2 Predictions Min       -16.424
trainer/Q Targets Mean            -9.84961
trainer/Q Targets Std              2.20289
trainer/Q Targets Max             -0.710891
trainer/Q Targets Min            -16.8397
trainer/Log Pis Mean               0.352063
trainer/Log Pis Std                1.10282
trainer/Log Pis Max                3.49075
trainer/Log Pis Min               -2.25968
trainer/Policy mu Mean             0.11966
trainer/Policy mu Std              0.780887
trainer/Policy mu Max              1.95466
trainer/Policy mu Min             -1.90071
trainer/Policy log std Mean       -0.909874
trainer/Policy log std Std         0.164919
trainer/Policy log std Max        -0.464089
trainer/Policy log std Min        -1.17282
trainer/Alpha                      0.0654837
trainer/Alpha Loss                -4.49176
exploration/num steps total    10000
exploration/num paths total      100
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.245372
exploration/Rewards Std            0.251057
exploration/Rewards Max           -0.00604095
exploration/Rewards Min           -1
exploration/Returns Mean         -24.5372
exploration/Returns Std            0.901052
exploration/Returns Max          -23.6361
exploration/Returns Min          -25.4382
exploration/Actions Mean           0.0521578
exploration/Actions Std            0.463998
exploration/Actions Max            0.990739
exploration/Actions Min           -0.923241
exploration/Num Paths              2
exploration/Average Returns      -24.5372
evaluation/num steps total     49000
evaluation/num paths total       490
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0730796
evaluation/Rewards Std             0.196582
evaluation/Rewards Max            -0.0194844
evaluation/Rewards Min            -1
evaluation/Returns Mean           -7.30796
evaluation/Returns Std             2.38725
evaluation/Returns Max            -3.54739
evaluation/Returns Min           -11.4663
evaluation/Actions Mean            0.0330315
evaluation/Actions Std             0.188981
evaluation/Actions Max             0.964682
evaluation/Actions Min            -0.932046
evaluation/Num Paths              10
evaluation/Average Returns        -7.30796
time/data storing (s)              0.00122366
time/evaluation sampling (s)       0.288307
time/exploration sampling (s)      0.0711436
time/logging (s)                   0.00361957
time/saving (s)                    0.00253253
time/training (s)                  1.10609
time/epoch (s)                     1.47292
time/total (s)                    71.6278
Epoch                             48
-----------------------------  --------------
2019-04-22 20:53:49.367990 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 49 finished
-----------------------------  --------------
replay_buffer/size             10200
trainer/QF1 Loss                   1.1823
trainer/QF2 Loss                   1.21346
trainer/Policy Loss               10.2506
trainer/Q1 Predictions Mean      -10.1151
trainer/Q1 Predictions Std         2.14906
trainer/Q1 Predictions Max        -8.84143
trainer/Q1 Predictions Min       -17.6075
trainer/Q2 Predictions Mean      -10.1028
trainer/Q2 Predictions Std         2.14766
trainer/Q2 Predictions Max        -8.84039
trainer/Q2 Predictions Min       -17.5619
trainer/Q Targets Mean            -9.88442
trainer/Q Targets Std              2.27691
trainer/Q Targets Max             -1
trainer/Q Targets Min            -16.9801
trainer/Log Pis Mean               0.393061
trainer/Log Pis Std                1.18527
trainer/Log Pis Max                3.33175
trainer/Log Pis Min               -2.56123
trainer/Policy mu Mean             0.180608
trainer/Policy mu Std              0.74529
trainer/Policy mu Max              1.88665
trainer/Policy mu Min             -1.83483
trainer/Policy log std Mean       -0.996494
trainer/Policy log std Std         0.184862
trainer/Policy log std Max        -0.54613
trainer/Policy log std Min        -1.30945
trainer/Alpha                      0.062093
trainer/Alpha Loss                -4.46546
exploration/num steps total    10200
exploration/num paths total      102
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.23772
exploration/Rewards Std            0.252916
exploration/Rewards Max           -0.00383459
exploration/Rewards Min           -1
exploration/Returns Mean         -23.772
exploration/Returns Std            0.835813
exploration/Returns Max          -22.9362
exploration/Returns Min          -24.6078
exploration/Actions Mean           0.051077
exploration/Actions Std            0.429618
exploration/Actions Max            0.991317
exploration/Actions Min           -0.890558
exploration/Num Paths              2
exploration/Average Returns      -23.772
evaluation/num steps total     50000
evaluation/num paths total       500
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0742308
evaluation/Rewards Std             0.182238
evaluation/Rewards Max            -0.0196001
evaluation/Rewards Min            -1
evaluation/Returns Mean           -7.42308
evaluation/Returns Std             1.89558
evaluation/Returns Max            -4.65625
evaluation/Returns Min           -11.6487
evaluation/Actions Mean            0.0263094
evaluation/Actions Std             0.176187
evaluation/Actions Max             0.961998
evaluation/Actions Min            -0.955658
evaluation/Num Paths              10
evaluation/Average Returns        -7.42308
time/data storing (s)              0.00122552
time/evaluation sampling (s)       0.296135
time/exploration sampling (s)      0.0723812
time/logging (s)                   0.00364367
time/saving (s)                    0.00259311
time/training (s)                  1.11383
time/epoch (s)                     1.48981
time/total (s)                    73.1225
Epoch                             49
-----------------------------  --------------
2019-04-22 20:53:50.884075 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 50 finished
-----------------------------  --------------
replay_buffer/size             10400
trainer/QF1 Loss                   0.0189717
trainer/QF2 Loss                   0.0197645
trainer/Policy Loss                9.89288
trainer/Q1 Predictions Mean       -9.84689
trainer/Q1 Predictions Std         2.1041
trainer/Q1 Predictions Max        -8.67887
trainer/Q1 Predictions Min       -17.4652
trainer/Q2 Predictions Mean       -9.8532
trainer/Q2 Predictions Std         2.09786
trainer/Q2 Predictions Max        -8.71566
trainer/Q2 Predictions Min       -17.4206
trainer/Q Targets Mean            -9.84796
trainer/Q Targets Std              2.03826
trainer/Q Targets Max             -8.65314
trainer/Q Targets Min            -17.179
trainer/Log Pis Mean               0.262901
trainer/Log Pis Std                1.3737
trainer/Log Pis Max                4.02475
trainer/Log Pis Min               -3.55517
trainer/Policy mu Mean             0.125822
trainer/Policy mu Std              0.757211
trainer/Policy mu Max              1.92018
trainer/Policy mu Min             -1.88084
trainer/Policy log std Mean       -1.02418
trainer/Policy log std Std         0.192977
trainer/Policy log std Max        -0.497479
trainer/Policy log std Min        -1.34417
trainer/Alpha                      0.0589426
trainer/Alpha Loss                -4.91761
exploration/num steps total    10400
exploration/num paths total      104
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.195942
exploration/Rewards Std            0.213882
exploration/Rewards Max           -0.00371542
exploration/Rewards Min           -1
exploration/Returns Mean         -19.5942
exploration/Returns Std            1.24297
exploration/Returns Max          -18.3512
exploration/Returns Min          -20.8372
exploration/Actions Mean           0.0153095
exploration/Actions Std            0.418011
exploration/Actions Max            0.990315
exploration/Actions Min           -0.970687
exploration/Num Paths              2
exploration/Average Returns      -19.5942
evaluation/num steps total     51000
evaluation/num paths total       510
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0649319
evaluation/Rewards Std             0.185505
evaluation/Rewards Max            -0.010061
evaluation/Rewards Min            -1
evaluation/Returns Mean           -6.49319
evaluation/Returns Std             1.88293
evaluation/Returns Max            -4.30149
evaluation/Returns Min            -9.76851
evaluation/Actions Mean            0.0269653
evaluation/Actions Std             0.1908
evaluation/Actions Max             0.965627
evaluation/Actions Min            -0.915229
evaluation/Num Paths              10
evaluation/Average Returns        -6.49319
time/data storing (s)              0.0012508
time/evaluation sampling (s)       0.30197
time/exploration sampling (s)      0.0734337
time/logging (s)                   0.00339981
time/saving (s)                    0.00275048
time/training (s)                  1.12697
time/epoch (s)                     1.50977
time/total (s)                    74.6366
Epoch                             50
-----------------------------  --------------
2019-04-22 20:53:52.370333 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 51 finished
-----------------------------  --------------
replay_buffer/size             10600
trainer/QF1 Loss                   2.18688
trainer/QF2 Loss                   2.21581
trainer/Policy Loss                9.33521
trainer/Q1 Predictions Mean       -9.18779
trainer/Q1 Predictions Std         1.37604
trainer/Q1 Predictions Max        -8.48081
trainer/Q1 Predictions Min       -15.579
trainer/Q2 Predictions Mean       -9.17335
trainer/Q2 Predictions Std         1.3652
trainer/Q2 Predictions Max        -8.47429
trainer/Q2 Predictions Min       -15.4687
trainer/Q Targets Mean            -9.15839
trainer/Q Targets Std              2.06323
trainer/Q Targets Max             -0.179324
trainer/Q Targets Min            -15.7153
trainer/Log Pis Mean               0.30966
trainer/Log Pis Std                1.11784
trainer/Log Pis Max                4.20594
trainer/Log Pis Min               -2.50205
trainer/Policy mu Mean             0.0428942
trainer/Policy mu Std              0.703183
trainer/Policy mu Max              1.86525
trainer/Policy mu Min             -1.76561
trainer/Policy log std Mean       -1.05098
trainer/Policy log std Std         0.187491
trainer/Policy log std Max        -0.511365
trainer/Policy log std Min        -1.33984
trainer/Alpha                      0.0560368
trainer/Alpha Loss                -4.8707
exploration/num steps total    10600
exploration/num paths total      106
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.165737
exploration/Rewards Std            0.141942
exploration/Rewards Max           -0.0142675
exploration/Rewards Min           -1
exploration/Returns Mean         -16.5737
exploration/Returns Std            1.94414
exploration/Returns Max          -14.6295
exploration/Returns Min          -18.5178
exploration/Actions Mean           0.0270733
exploration/Actions Std            0.376789
exploration/Actions Max            0.969562
exploration/Actions Min           -0.86861
exploration/Num Paths              2
exploration/Average Returns      -16.5737
evaluation/num steps total     52000
evaluation/num paths total       520
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.071989
evaluation/Rewards Std             0.195109
evaluation/Rewards Max            -0.0148261
evaluation/Rewards Min            -1
evaluation/Returns Mean           -7.1989
evaluation/Returns Std             2.88823
evaluation/Returns Max            -3.57989
evaluation/Returns Min           -11.6149
evaluation/Actions Mean            0.0277134
evaluation/Actions Std             0.18544
evaluation/Actions Max             0.959522
evaluation/Actions Min            -0.932594
evaluation/Num Paths              10
evaluation/Average Returns        -7.1989
time/data storing (s)              0.00122491
time/evaluation sampling (s)       0.288026
time/exploration sampling (s)      0.0701992
time/logging (s)                   0.00370006
time/saving (s)                    0.00255611
time/training (s)                  1.11482
time/epoch (s)                     1.48053
time/total (s)                    76.1218
Epoch                             51
-----------------------------  --------------
2019-04-22 20:53:53.842240 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 52 finished
-----------------------------  --------------
replay_buffer/size             10800
trainer/QF1 Loss                   1.44733
trainer/QF2 Loss                   1.44013
trainer/Policy Loss                9.98393
trainer/Q1 Predictions Mean       -9.85151
trainer/Q1 Predictions Std         2.2483
trainer/Q1 Predictions Max        -8.56117
trainer/Q1 Predictions Min       -17.1714
trainer/Q2 Predictions Mean       -9.85036
trainer/Q2 Predictions Std         2.25734
trainer/Q2 Predictions Max        -8.57127
trainer/Q2 Predictions Min       -17.2003
trainer/Q Targets Mean            -9.81262
trainer/Q Targets Std              2.60489
trainer/Q Targets Max             -0.393255
trainer/Q Targets Min            -17.2307
trainer/Log Pis Mean               0.360781
trainer/Log Pis Std                1.29821
trainer/Log Pis Max                3.50727
trainer/Log Pis Min               -3.25289
trainer/Policy mu Mean             0.0501888
trainer/Policy mu Std              0.809837
trainer/Policy mu Max              1.8315
trainer/Policy mu Min             -1.77377
trainer/Policy log std Mean       -1.06444
trainer/Policy log std Std         0.235679
trainer/Policy log std Max        -0.515015
trainer/Policy log std Min        -1.39811
trainer/Alpha                      0.0532698
trainer/Alpha Loss                -4.8064
exploration/num steps total    10800
exploration/num paths total      108
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.180473
exploration/Rewards Std            0.18657
exploration/Rewards Max           -0.0115413
exploration/Rewards Min           -1
exploration/Returns Mean         -18.0473
exploration/Returns Std            1.15239
exploration/Returns Max          -16.8949
exploration/Returns Min          -19.1997
exploration/Actions Mean           0.0219489
exploration/Actions Std            0.377705
exploration/Actions Max            0.990796
exploration/Actions Min           -0.902915
exploration/Num Paths              2
exploration/Average Returns      -18.0473
evaluation/num steps total     53000
evaluation/num paths total       530
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.100064
evaluation/Rewards Std             0.167438
evaluation/Rewards Max            -0.0426059
evaluation/Rewards Min            -1
evaluation/Returns Mean          -10.0064
evaluation/Returns Std             2.53634
evaluation/Returns Max            -6.48642
evaluation/Returns Min           -15.0896
evaluation/Actions Mean            0.0205551
evaluation/Actions Std             0.166174
evaluation/Actions Max             0.963303
evaluation/Actions Min            -0.944694
evaluation/Num Paths              10
evaluation/Average Returns       -10.0064
time/data storing (s)              0.0012264
time/evaluation sampling (s)       0.288527
time/exploration sampling (s)      0.069488
time/logging (s)                   0.00364345
time/saving (s)                    0.0025719
time/training (s)                  1.10005
time/epoch (s)                     1.4655
time/total (s)                    77.5921
Epoch                             52
-----------------------------  --------------
2019-04-22 20:53:55.347473 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 53 finished
-----------------------------  --------------
replay_buffer/size             11000
trainer/QF1 Loss                   0.737134
trainer/QF2 Loss                   0.731272
trainer/Policy Loss                9.87959
trainer/Q1 Predictions Mean       -9.64303
trainer/Q1 Predictions Std         2.02256
trainer/Q1 Predictions Max        -8.56053
trainer/Q1 Predictions Min       -17.1321
trainer/Q2 Predictions Mean       -9.64416
trainer/Q2 Predictions Std         2.01519
trainer/Q2 Predictions Max        -8.53093
trainer/Q2 Predictions Min       -17.0805
trainer/Q Targets Mean            -9.6806
trainer/Q Targets Std              2.24199
trainer/Q Targets Max             -0.492348
trainer/Q Targets Min            -17.1531
trainer/Log Pis Mean               0.433973
trainer/Log Pis Std                1.26865
trainer/Log Pis Max                3.02526
trainer/Log Pis Min               -3.77666
trainer/Policy mu Mean             0.103899
trainer/Policy mu Std              0.77399
trainer/Policy mu Max              1.9162
trainer/Policy mu Min             -1.78488
trainer/Policy log std Mean       -1.05983
trainer/Policy log std Std         0.21215
trainer/Policy log std Max        -0.521409
trainer/Policy log std Min        -1.41202
trainer/Alpha                      0.0505706
trainer/Alpha Loss                -4.67321
exploration/num steps total    11000
exploration/num paths total      110
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.209548
exploration/Rewards Std            0.232096
exploration/Rewards Max           -0.0168012
exploration/Rewards Min           -1
exploration/Returns Mean         -20.9548
exploration/Returns Std            1.04113
exploration/Returns Max          -19.9136
exploration/Returns Min          -21.9959
exploration/Actions Mean           0.0428556
exploration/Actions Std            0.397265
exploration/Actions Max            0.99248
exploration/Actions Min           -0.850487
exploration/Num Paths              2
exploration/Average Returns      -20.9548
evaluation/num steps total     54000
evaluation/num paths total       540
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0977969
evaluation/Rewards Std             0.19162
evaluation/Rewards Max            -0.0433861
evaluation/Rewards Min            -1
evaluation/Returns Mean           -9.77969
evaluation/Returns Std             2.66219
evaluation/Returns Max            -6.62819
evaluation/Returns Min           -14.2186
evaluation/Actions Mean            0.0233287
evaluation/Actions Std             0.177333
evaluation/Actions Max             0.962382
evaluation/Actions Min            -0.943012
evaluation/Num Paths              10
evaluation/Average Returns        -9.77969
time/data storing (s)              0.00138284
time/evaluation sampling (s)       0.294701
time/exploration sampling (s)      0.0740356
time/logging (s)                   0.00373752
time/saving (s)                    0.00288104
time/training (s)                  1.12174
time/epoch (s)                     1.49847
time/total (s)                    79.0957
Epoch                             53
-----------------------------  --------------
2019-04-22 20:53:57.152548 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 54 finished
-----------------------------  --------------
replay_buffer/size             11200
trainer/QF1 Loss                   1.57109
trainer/QF2 Loss                   1.56625
trainer/Policy Loss               10.1071
trainer/Q1 Predictions Mean       -9.75937
trainer/Q1 Predictions Std         2.31747
trainer/Q1 Predictions Max        -8.32936
trainer/Q1 Predictions Min       -16.7189
trainer/Q2 Predictions Mean       -9.75638
trainer/Q2 Predictions Std         2.31008
trainer/Q2 Predictions Max        -8.33531
trainer/Q2 Predictions Min       -16.6662
trainer/Q Targets Mean            -9.90234
trainer/Q Targets Std              2.40522
trainer/Q Targets Max             -1
trainer/Q Targets Min            -17.3852
trainer/Log Pis Mean               0.536097
trainer/Log Pis Std                1.18773
trainer/Log Pis Max                3.58175
trainer/Log Pis Min               -3.56488
trainer/Policy mu Mean             0.210232
trainer/Policy mu Std              0.827535
trainer/Policy mu Max              1.94218
trainer/Policy mu Min             -1.76009
trainer/Policy log std Mean       -1.06993
trainer/Policy log std Std         0.252639
trainer/Policy log std Max        -0.501867
trainer/Policy log std Min        -1.42233
trainer/Alpha                      0.048054
trainer/Alpha Loss                -4.4432
exploration/num steps total    11200
exploration/num paths total      112
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.180275
exploration/Rewards Std            0.168455
exploration/Rewards Max           -0.00904151
exploration/Rewards Min           -1
exploration/Returns Mean         -18.0275
exploration/Returns Std            1.64557
exploration/Returns Max          -16.3819
exploration/Returns Min          -19.6731
exploration/Actions Mean           0.00616316
exploration/Actions Std            0.37875
exploration/Actions Max            0.98328
exploration/Actions Min           -0.94652
exploration/Num Paths              2
exploration/Average Returns      -18.0275
evaluation/num steps total     55000
evaluation/num paths total       550
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.113028
evaluation/Rewards Std             0.180168
evaluation/Rewards Max            -0.0607476
evaluation/Rewards Min            -1
evaluation/Returns Mean          -11.3028
evaluation/Returns Std             2.46978
evaluation/Returns Max            -7.30511
evaluation/Returns Min           -15.5122
evaluation/Actions Mean            0.0248897
evaluation/Actions Std             0.189371
evaluation/Actions Max             0.961583
evaluation/Actions Min            -0.944263
evaluation/Num Paths              10
evaluation/Average Returns       -11.3028
time/data storing (s)              0.00143018
time/evaluation sampling (s)       0.337706
time/exploration sampling (s)      0.108425
time/logging (s)                   0.00543244
time/saving (s)                    0.00251831
time/training (s)                  1.34527
time/epoch (s)                     1.80079
time/total (s)                    80.9013
Epoch                             54
-----------------------------  --------------
2019-04-22 20:53:58.642420 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 55 finished
-----------------------------  --------------
replay_buffer/size             11400
trainer/QF1 Loss                   0.020656
trainer/QF2 Loss                   0.0192067
trainer/Policy Loss               10.4668
trainer/Q1 Predictions Mean      -10.094
trainer/Q1 Predictions Std         2.38523
trainer/Q1 Predictions Max        -8.60559
trainer/Q1 Predictions Min       -17.7826
trainer/Q2 Predictions Mean      -10.0994
trainer/Q2 Predictions Std         2.371
trainer/Q2 Predictions Max        -8.59417
trainer/Q2 Predictions Min       -17.9548
trainer/Q Targets Mean           -10.1194
trainer/Q Targets Std              2.37052
trainer/Q Targets Max             -8.59019
trainer/Q Targets Min            -17.9751
trainer/Log Pis Mean               0.660123
trainer/Log Pis Std                1.28396
trainer/Log Pis Max                3.35177
trainer/Log Pis Min               -2.76948
trainer/Policy mu Mean             0.0798499
trainer/Policy mu Std              0.884667
trainer/Policy mu Max              1.99641
trainer/Policy mu Min             -1.93869
trainer/Policy log std Mean       -1.07311
trainer/Policy log std Std         0.244529
trainer/Policy log std Max        -0.52439
trainer/Policy log std Min        -1.48512
trainer/Alpha                      0.0456596
trainer/Alpha Loss                -4.13524
exploration/num steps total    11400
exploration/num paths total      114
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.218529
exploration/Rewards Std            0.22416
exploration/Rewards Max           -0.0111187
exploration/Rewards Min           -1
exploration/Returns Mean         -21.8529
exploration/Returns Std            1.71888
exploration/Returns Max          -20.1341
exploration/Returns Min          -23.5718
exploration/Actions Mean           0.0433757
exploration/Actions Std            0.402006
exploration/Actions Max            0.99028
exploration/Actions Min           -0.832531
exploration/Num Paths              2
exploration/Average Returns      -21.8529
evaluation/num steps total     56000
evaluation/num paths total       560
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.143338
evaluation/Rewards Std             0.178309
evaluation/Rewards Max            -0.0712818
evaluation/Rewards Min            -1
evaluation/Returns Mean          -14.3338
evaluation/Returns Std             2.20094
evaluation/Returns Max           -11.1417
evaluation/Returns Min           -18.1711
evaluation/Actions Mean            0.0132154
evaluation/Actions Std             0.186204
evaluation/Actions Max             0.967875
evaluation/Actions Min            -0.963493
evaluation/Num Paths              10
evaluation/Average Returns       -14.3338
time/data storing (s)              0.00148172
time/evaluation sampling (s)       0.295561
time/exploration sampling (s)      0.0742853
time/logging (s)                   0.00306503
time/saving (s)                    0.00254967
time/training (s)                  1.10427
time/epoch (s)                     1.48121
time/total (s)                    82.3873
Epoch                             55
-----------------------------  --------------
2019-04-22 20:54:00.148240 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 56 finished
-----------------------------  --------------
replay_buffer/size             11600
trainer/QF1 Loss                   1.43762
trainer/QF2 Loss                   1.44886
trainer/Policy Loss                9.9654
trainer/Q1 Predictions Mean       -9.63476
trainer/Q1 Predictions Std         1.98749
trainer/Q1 Predictions Max        -8.51065
trainer/Q1 Predictions Min       -16.8353
trainer/Q2 Predictions Mean       -9.66121
trainer/Q2 Predictions Std         2.0071
trainer/Q2 Predictions Max        -8.53983
trainer/Q2 Predictions Min       -17.0819
trainer/Q Targets Mean            -9.58033
trainer/Q Targets Std              2.4103
trainer/Q Targets Max             -0.210124
trainer/Q Targets Min            -17.1339
trainer/Log Pis Mean               0.538269
trainer/Log Pis Std                1.30127
trainer/Log Pis Max                3.60633
trainer/Log Pis Min               -3.63775
trainer/Policy mu Mean             0.179336
trainer/Policy mu Std              0.834609
trainer/Policy mu Max              2.0515
trainer/Policy mu Min             -1.91805
trainer/Policy log std Mean       -1.12869
trainer/Policy log std Std         0.238436
trainer/Policy log std Max        -0.539674
trainer/Policy log std Min        -1.48524
trainer/Alpha                      0.0433728
trainer/Alpha Loss                -4.58642
exploration/num steps total    11600
exploration/num paths total      116
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.170117
exploration/Rewards Std            0.168615
exploration/Rewards Max           -0.0104542
exploration/Rewards Min           -1
exploration/Returns Mean         -17.0117
exploration/Returns Std            1.66808
exploration/Returns Max          -15.3436
exploration/Returns Min          -18.6798
exploration/Actions Mean           0.0241041
exploration/Actions Std            0.365297
exploration/Actions Max            0.978845
exploration/Actions Min           -0.90123
exploration/Num Paths              2
exploration/Average Returns      -17.0117
evaluation/num steps total     57000
evaluation/num paths total       570
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0808772
evaluation/Rewards Std             0.192683
evaluation/Rewards Max            -0.0250017
evaluation/Rewards Min            -1
evaluation/Returns Mean           -8.08772
evaluation/Returns Std             2.63456
evaluation/Returns Max            -5.05888
evaluation/Returns Min           -12.25
evaluation/Actions Mean            0.0248693
evaluation/Actions Std             0.189147
evaluation/Actions Max             0.969405
evaluation/Actions Min            -0.959855
evaluation/Num Paths              10
evaluation/Average Returns        -8.08772
time/data storing (s)              0.00122275
time/evaluation sampling (s)       0.289242
time/exploration sampling (s)      0.0731096
time/logging (s)                   0.00398628
time/saving (s)                    0.00325295
time/training (s)                  1.12966
time/epoch (s)                     1.50047
time/total (s)                    83.8927
Epoch                             56
-----------------------------  --------------
2019-04-22 20:54:01.853028 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 57 finished
-----------------------------  --------------
replay_buffer/size             11800
trainer/QF1 Loss                   0.070922
trainer/QF2 Loss                   0.0808352
trainer/Policy Loss               10.3933
trainer/Q1 Predictions Mean       -9.80296
trainer/Q1 Predictions Std         2.26474
trainer/Q1 Predictions Max        -8.4224
trainer/Q1 Predictions Min       -16.6886
trainer/Q2 Predictions Mean       -9.77904
trainer/Q2 Predictions Std         2.26257
trainer/Q2 Predictions Max        -8.37766
trainer/Q2 Predictions Min       -16.652
trainer/Q Targets Mean           -10.0214
trainer/Q Targets Std              2.31541
trainer/Q Targets Max             -8.55146
trainer/Q Targets Min            -16.8078
trainer/Log Pis Mean               0.880148
trainer/Log Pis Std                1.22271
trainer/Log Pis Max                4.09278
trainer/Log Pis Min               -1.37804
trainer/Policy mu Mean             0.168381
trainer/Policy mu Std              0.875993
trainer/Policy mu Max              2.12183
trainer/Policy mu Min             -2.08782
trainer/Policy log std Mean       -1.18932
trainer/Policy log std Std         0.264579
trainer/Policy log std Max        -0.505293
trainer/Policy log std Min        -1.52576
trainer/Alpha                      0.0412404
trainer/Alpha Loss                -3.5702
exploration/num steps total    11800
exploration/num paths total      118
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.154107
exploration/Rewards Std            0.163198
exploration/Rewards Max           -0.0135813
exploration/Rewards Min           -1
exploration/Returns Mean         -15.4107
exploration/Returns Std            2.74588
exploration/Returns Max          -12.6648
exploration/Returns Min          -18.1565
exploration/Actions Mean           0.032148
exploration/Actions Std            0.343734
exploration/Actions Max            0.985852
exploration/Actions Min           -0.77962
exploration/Num Paths              2
exploration/Average Returns      -15.4107
evaluation/num steps total     58000
evaluation/num paths total       580
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0763117
evaluation/Rewards Std             0.18432
evaluation/Rewards Max            -0.0266993
evaluation/Rewards Min            -1
evaluation/Returns Mean           -7.63117
evaluation/Returns Std             2.00028
evaluation/Returns Max            -4.81152
evaluation/Returns Min           -12.4114
evaluation/Actions Mean            0.0227537
evaluation/Actions Std             0.184816
evaluation/Actions Max             0.973408
evaluation/Actions Min            -0.967472
evaluation/Num Paths              10
evaluation/Average Returns        -7.63117
time/data storing (s)              0.00128419
time/evaluation sampling (s)       0.321565
time/exploration sampling (s)      0.0809103
time/logging (s)                   0.00301551
time/saving (s)                    0.00243495
time/training (s)                  1.28772
time/epoch (s)                     1.69693
time/total (s)                    85.5948
Epoch                             57
-----------------------------  --------------
2019-04-22 20:54:03.601938 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 58 finished
-----------------------------  --------------
replay_buffer/size             12000
trainer/QF1 Loss                   1.45955
trainer/QF2 Loss                   1.45087
trainer/Policy Loss               10.324
trainer/Q1 Predictions Mean       -9.49152
trainer/Q1 Predictions Std         1.91276
trainer/Q1 Predictions Max        -8.54185
trainer/Q1 Predictions Min       -16.505
trainer/Q2 Predictions Mean       -9.48732
trainer/Q2 Predictions Std         1.90421
trainer/Q2 Predictions Max        -8.53406
trainer/Q2 Predictions Min       -16.3776
trainer/Q Targets Mean            -9.34534
trainer/Q Targets Std              2.35692
trainer/Q Targets Max             -0.073538
trainer/Q Targets Min            -16.6027
trainer/Log Pis Mean               0.980418
trainer/Log Pis Std                1.1376
trainer/Log Pis Max                4.02586
trainer/Log Pis Min               -3.03508
trainer/Policy mu Mean             0.0752293
trainer/Policy mu Std              0.798966
trainer/Policy mu Max              2.08939
trainer/Policy mu Min             -1.84828
trainer/Policy log std Mean       -1.25382
trainer/Policy log std Std         0.234158
trainer/Policy log std Max        -0.548646
trainer/Policy log std Min        -1.61943
trainer/Alpha                      0.0392568
trainer/Alpha Loss                -3.30078
exploration/num steps total    12000
exploration/num paths total      120
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.151707
exploration/Rewards Std            0.13383
exploration/Rewards Max           -0.00438354
exploration/Rewards Min           -1
exploration/Returns Mean         -15.1707
exploration/Returns Std            0.860373
exploration/Returns Max          -14.3103
exploration/Returns Min          -16.0311
exploration/Actions Mean           0.0300389
exploration/Actions Std            0.330446
exploration/Actions Max            0.950965
exploration/Actions Min           -0.69257
exploration/Num Paths              2
exploration/Average Returns      -15.1707
evaluation/num steps total     59000
evaluation/num paths total       590
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.106845
evaluation/Rewards Std             0.174517
evaluation/Rewards Max            -0.0551367
evaluation/Rewards Min            -1
evaluation/Returns Mean          -10.6845
evaluation/Returns Std             2.34347
evaluation/Returns Max            -7.39941
evaluation/Returns Min           -15.2931
evaluation/Actions Mean            0.0261673
evaluation/Actions Std             0.183704
evaluation/Actions Max             0.974959
evaluation/Actions Min            -0.925682
evaluation/Num Paths              10
evaluation/Average Returns       -10.6845
time/data storing (s)              0.00125232
time/evaluation sampling (s)       0.326045
time/exploration sampling (s)      0.0794143
time/logging (s)                   0.00514369
time/saving (s)                    0.00314632
time/training (s)                  1.33071
time/epoch (s)                     1.74571
time/total (s)                    87.345
Epoch                             58
-----------------------------  --------------
2019-04-22 20:54:05.324302 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 59 finished
-----------------------------  --------------
replay_buffer/size             12200
trainer/QF1 Loss                   0.709083
trainer/QF2 Loss                   0.707041
trainer/Policy Loss               10.0339
trainer/Q1 Predictions Mean       -9.16052
trainer/Q1 Predictions Std         1.55646
trainer/Q1 Predictions Max        -8.39368
trainer/Q1 Predictions Min       -15.8875
trainer/Q2 Predictions Mean       -9.16075
trainer/Q2 Predictions Std         1.56233
trainer/Q2 Predictions Max        -8.38442
trainer/Q2 Predictions Min       -15.8547
trainer/Q Targets Mean            -9.18931
trainer/Q Targets Std              1.81672
trainer/Q Targets Max             -0.244815
trainer/Q Targets Min            -16.2548
trainer/Log Pis Mean               1.05338
trainer/Log Pis Std                1.028
trainer/Log Pis Max                3.70291
trainer/Log Pis Min               -2.50076
trainer/Policy mu Mean             0.0892891
trainer/Policy mu Std              0.760282
trainer/Policy mu Max              2.10643
trainer/Policy mu Min             -1.49548
trainer/Policy log std Mean       -1.32297
trainer/Policy log std Std         0.232451
trainer/Policy log std Max        -0.522266
trainer/Policy log std Min        -1.64437
trainer/Alpha                      0.0373979
trainer/Alpha Loss                -3.11049
exploration/num steps total    12200
exploration/num paths total      122
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.152478
exploration/Rewards Std            0.173525
exploration/Rewards Max           -0.0193812
exploration/Rewards Min           -1
exploration/Returns Mean         -15.2478
exploration/Returns Std            2.93568
exploration/Returns Max          -12.3122
exploration/Returns Min          -18.1835
exploration/Actions Mean           0.0198031
exploration/Actions Std            0.329974
exploration/Actions Max            0.992315
exploration/Actions Min           -0.862186
exploration/Num Paths              2
exploration/Average Returns      -15.2478
evaluation/num steps total     60000
evaluation/num paths total       600
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.129158
evaluation/Rewards Std             0.22188
evaluation/Rewards Max            -0.0520034
evaluation/Rewards Min            -1
evaluation/Returns Mean          -12.9158
evaluation/Returns Std             2.97499
evaluation/Returns Max            -8.59319
evaluation/Returns Min           -16.0125
evaluation/Actions Mean            0.0419111
evaluation/Actions Std             0.207115
evaluation/Actions Max             0.971511
evaluation/Actions Min            -0.964145
evaluation/Num Paths              10
evaluation/Average Returns       -12.9158
time/data storing (s)              0.00229731
time/evaluation sampling (s)       0.312013
time/exploration sampling (s)      0.0866601
time/logging (s)                   0.0036127
time/saving (s)                    0.00266225
time/training (s)                  1.30507
time/epoch (s)                     1.71231
time/total (s)                    89.0632
Epoch                             59
-----------------------------  --------------
2019-04-22 20:54:06.941378 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 60 finished
-----------------------------  --------------
replay_buffer/size             12400
trainer/QF1 Loss                   0.0208368
trainer/QF2 Loss                   0.0178539
trainer/Policy Loss               10.3284
trainer/Q1 Predictions Mean       -9.56262
trainer/Q1 Predictions Std         2.23828
trainer/Q1 Predictions Max        -8.38975
trainer/Q1 Predictions Min       -16.748
trainer/Q2 Predictions Mean       -9.5657
trainer/Q2 Predictions Std         2.22935
trainer/Q2 Predictions Max        -8.41386
trainer/Q2 Predictions Min       -16.5882
trainer/Q Targets Mean            -9.63041
trainer/Q Targets Std              2.28652
trainer/Q Targets Max             -8.43456
trainer/Q Targets Min            -17.0459
trainer/Log Pis Mean               1.00222
trainer/Log Pis Std                1.15087
trainer/Log Pis Max                4.53742
trainer/Log Pis Min               -2.6374
trainer/Policy mu Mean             0.0666469
trainer/Policy mu Std              0.807054
trainer/Policy mu Max              2.15611
trainer/Policy mu Min             -1.84877
trainer/Policy log std Mean       -1.31814
trainer/Policy log std Std         0.249698
trainer/Policy log std Max        -0.615556
trainer/Policy log std Min        -1.68643
trainer/Alpha                      0.0356585
trainer/Alpha Loss                -3.32612
exploration/num steps total    12400
exploration/num paths total      124
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.163559
exploration/Rewards Std            0.206824
exploration/Rewards Max           -0.0113105
exploration/Rewards Min           -1
exploration/Returns Mean         -16.3559
exploration/Returns Std            3.44911
exploration/Returns Max          -12.9068
exploration/Returns Min          -19.805
exploration/Actions Mean           0.00965752
exploration/Actions Std            0.336921
exploration/Actions Max            0.99816
exploration/Actions Min           -0.964759
exploration/Num Paths              2
exploration/Average Returns      -16.3559
evaluation/num steps total     61000
evaluation/num paths total       610
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.10226
evaluation/Rewards Std             0.206255
evaluation/Rewards Max            -0.0300969
evaluation/Rewards Min            -1
evaluation/Returns Mean          -10.226
evaluation/Returns Std             3.11877
evaluation/Returns Max            -5.77497
evaluation/Returns Min           -14.396
evaluation/Actions Mean            0.0323144
evaluation/Actions Std             0.203976
evaluation/Actions Max             0.978495
evaluation/Actions Min            -0.961129
evaluation/Num Paths              10
evaluation/Average Returns       -10.226
time/data storing (s)              0.00124347
time/evaluation sampling (s)       0.328253
time/exploration sampling (s)      0.0764329
time/logging (s)                   0.00362997
time/saving (s)                    0.00247979
time/training (s)                  1.19888
time/epoch (s)                     1.61092
time/total (s)                    90.6787
Epoch                             60
-----------------------------  --------------
2019-04-22 20:54:08.567538 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 61 finished
-----------------------------  --------------
replay_buffer/size             12600
trainer/QF1 Loss                   1.38244
trainer/QF2 Loss                   1.36375
trainer/Policy Loss                9.64755
trainer/Q1 Predictions Mean       -9.05604
trainer/Q1 Predictions Std         1.77342
trainer/Q1 Predictions Max        -8.32346
trainer/Q1 Predictions Min       -17.3939
trainer/Q2 Predictions Mean       -9.05708
trainer/Q2 Predictions Std         1.76005
trainer/Q2 Predictions Max        -8.31677
trainer/Q2 Predictions Min       -17.2703
trainer/Q Targets Mean            -9.00006
trainer/Q Targets Std              2.16796
trainer/Q Targets Max             -0.0577922
trainer/Q Targets Min            -17.2152
trainer/Log Pis Mean               0.747122
trainer/Log Pis Std                1.15745
trainer/Log Pis Max                3.35214
trainer/Log Pis Min               -3.30723
trainer/Policy mu Mean            -0.094584
trainer/Policy mu Std              0.728972
trainer/Policy mu Max              2.12869
trainer/Policy mu Min             -1.75383
trainer/Policy log std Mean       -1.35224
trainer/Policy log std Std         0.235698
trainer/Policy log std Max        -0.567837
trainer/Policy log std Min        -1.66489
trainer/Alpha                      0.0340517
trainer/Alpha Loss                -4.23426
exploration/num steps total    12600
exploration/num paths total      126
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.132321
exploration/Rewards Std            0.109319
exploration/Rewards Max           -0.00208625
exploration/Rewards Min           -0.945867
exploration/Returns Mean         -13.2321
exploration/Returns Std            0.337086
exploration/Returns Max          -12.8951
exploration/Returns Min          -13.5692
exploration/Actions Mean           0.00701327
exploration/Actions Std            0.308828
exploration/Actions Max            0.969526
exploration/Actions Min           -0.98379
exploration/Num Paths              2
exploration/Average Returns      -13.2321
evaluation/num steps total     62000
evaluation/num paths total       620
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.104306
evaluation/Rewards Std             0.198654
evaluation/Rewards Max            -0.0539413
evaluation/Rewards Min            -1
evaluation/Returns Mean          -10.4306
evaluation/Returns Std             3.03441
evaluation/Returns Max            -5.9073
evaluation/Returns Min           -14.1326
evaluation/Actions Mean            0.0293758
evaluation/Actions Std             0.187231
evaluation/Actions Max             0.975054
evaluation/Actions Min            -0.874762
evaluation/Num Paths              10
evaluation/Average Returns       -10.4306
time/data storing (s)              0.001225
time/evaluation sampling (s)       0.296015
time/exploration sampling (s)      0.0727295
time/logging (s)                   0.00383712
time/saving (s)                    0.00293763
time/training (s)                  1.24403
time/epoch (s)                     1.62078
time/total (s)                    92.3037
Epoch                             61
-----------------------------  --------------
2019-04-22 20:54:10.151113 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 62 finished
-----------------------------  --------------
replay_buffer/size             12800
trainer/QF1 Loss                   2.04244
trainer/QF2 Loss                   2.03612
trainer/Policy Loss               10.5233
trainer/Q1 Predictions Mean       -9.71698
trainer/Q1 Predictions Std         2.39796
trainer/Q1 Predictions Max        -8.24555
trainer/Q1 Predictions Min       -16.6418
trainer/Q2 Predictions Mean       -9.70566
trainer/Q2 Predictions Std         2.39059
trainer/Q2 Predictions Max        -8.25011
trainer/Q2 Predictions Min       -16.7196
trainer/Q Targets Mean            -9.55592
trainer/Q Targets Std              2.85808
trainer/Q Targets Max             -0.0577922
trainer/Q Targets Min            -16.5617
trainer/Log Pis Mean               1.05865
trainer/Log Pis Std                1.30948
trainer/Log Pis Max                4.42446
trainer/Log Pis Min               -3.06509
trainer/Policy mu Mean             0.104567
trainer/Policy mu Std              0.853312
trainer/Policy mu Max              2.15309
trainer/Policy mu Min             -2.14794
trainer/Policy log std Mean       -1.32157
trainer/Policy log std Std         0.301592
trainer/Policy log std Max        -0.49039
trainer/Policy log std Min        -1.6804
trainer/Alpha                      0.0324906
trainer/Alpha Loss                -3.22558
exploration/num steps total    12800
exploration/num paths total      128
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.159938
exploration/Rewards Std            0.184471
exploration/Rewards Max           -0.00687275
exploration/Rewards Min           -1
exploration/Returns Mean         -15.9938
exploration/Returns Std            2.87019
exploration/Returns Max          -13.1236
exploration/Returns Min          -18.864
exploration/Actions Mean           0.0150024
exploration/Actions Std            0.318162
exploration/Actions Max            0.993305
exploration/Actions Min           -0.982872
exploration/Num Paths              2
exploration/Average Returns      -15.9938
evaluation/num steps total     63000
evaluation/num paths total       630
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.107798
evaluation/Rewards Std             0.147545
evaluation/Rewards Max            -0.0621561
evaluation/Rewards Min            -1
evaluation/Returns Mean          -10.7798
evaluation/Returns Std             2.41689
evaluation/Returns Max            -8.22511
evaluation/Returns Min           -16.917
evaluation/Actions Mean            0.0242492
evaluation/Actions Std             0.159798
evaluation/Actions Max             0.975126
evaluation/Actions Min            -0.947232
evaluation/Num Paths              10
evaluation/Average Returns       -10.7798
time/data storing (s)              0.00156298
time/evaluation sampling (s)       0.322803
time/exploration sampling (s)      0.0901507
time/logging (s)                   0.00419163
time/saving (s)                    0.00286949
time/training (s)                  1.15598
time/epoch (s)                     1.57755
time/total (s)                    93.8861
Epoch                             62
-----------------------------  --------------
2019-04-22 20:54:12.009045 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 63 finished
-----------------------------  --------------
replay_buffer/size             13000
trainer/QF1 Loss                   0.0347462
trainer/QF2 Loss                   0.032153
trainer/Policy Loss                9.9515
trainer/Q1 Predictions Mean       -9.10605
trainer/Q1 Predictions Std         1.74246
trainer/Q1 Predictions Max        -8.2483
trainer/Q1 Predictions Min       -17.9752
trainer/Q2 Predictions Mean       -9.10654
trainer/Q2 Predictions Std         1.76631
trainer/Q2 Predictions Max        -8.25356
trainer/Q2 Predictions Min       -18.174
trainer/Q Targets Mean            -9.21458
trainer/Q Targets Std              1.81434
trainer/Q Targets Max             -8.30993
trainer/Q Targets Min            -18.1952
trainer/Log Pis Mean               1.05346
trainer/Log Pis Std                1.45875
trainer/Log Pis Max                4.59254
trainer/Log Pis Min               -4.0408
trainer/Policy mu Mean             0.099341
trainer/Policy mu Std              0.827663
trainer/Policy mu Max              2.17486
trainer/Policy mu Min             -2.00526
trainer/Policy log std Mean       -1.38146
trainer/Policy log std Std         0.28774
trainer/Policy log std Max        -0.543781
trainer/Policy log std Min        -1.75935
trainer/Alpha                      0.0310161
trainer/Alpha Loss                -3.28736
exploration/num steps total    13000
exploration/num paths total      130
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.148273
exploration/Rewards Std            0.174758
exploration/Rewards Max           -0.0100758
exploration/Rewards Min           -1
exploration/Returns Mean         -14.8273
exploration/Returns Std            0.856439
exploration/Returns Max          -13.9708
exploration/Returns Min          -15.6837
exploration/Actions Mean           0.00252309
exploration/Actions Std            0.326899
exploration/Actions Max            0.988131
exploration/Actions Min           -0.992296
exploration/Num Paths              2
exploration/Average Returns      -14.8273
evaluation/num steps total     64000
evaluation/num paths total       640
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.08463
evaluation/Rewards Std             0.176583
evaluation/Rewards Max            -0.0382602
evaluation/Rewards Min            -1
evaluation/Returns Mean           -8.463
evaluation/Returns Std             2.50793
evaluation/Returns Max            -4.69811
evaluation/Returns Min           -12.5041
evaluation/Actions Mean            0.0299196
evaluation/Actions Std             0.180061
evaluation/Actions Max             0.979903
evaluation/Actions Min            -0.854742
evaluation/Num Paths              10
evaluation/Average Returns        -8.463
time/data storing (s)              0.00136963
time/evaluation sampling (s)       0.342113
time/exploration sampling (s)      0.0839034
time/logging (s)                   0.00396908
time/saving (s)                    0.00255185
time/training (s)                  1.41676
time/epoch (s)                     1.85067
time/total (s)                    95.7416
Epoch                             63
-----------------------------  --------------
2019-04-22 20:54:13.698171 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 64 finished
-----------------------------  --------------
replay_buffer/size             13200
trainer/QF1 Loss                   0.027324
trainer/QF2 Loss                   0.0258424
trainer/Policy Loss                9.84312
trainer/Q1 Predictions Mean       -8.84869
trainer/Q1 Predictions Std         1.64273
trainer/Q1 Predictions Max        -8.14611
trainer/Q1 Predictions Min       -17.465
trainer/Q2 Predictions Mean       -8.85552
trainer/Q2 Predictions Std         1.63848
trainer/Q2 Predictions Max        -8.16321
trainer/Q2 Predictions Min       -17.3075
trainer/Q Targets Mean            -8.97594
trainer/Q Targets Std              1.59853
trainer/Q Targets Max             -8.28569
trainer/Q Targets Min            -17.1708
trainer/Log Pis Mean               1.15628
trainer/Log Pis Std                1.17062
trainer/Log Pis Max                4.74153
trainer/Log Pis Min               -2.3754
trainer/Policy mu Mean             0.0480281
trainer/Policy mu Std              0.778914
trainer/Policy mu Max              2.35503
trainer/Policy mu Min             -2.03458
trainer/Policy log std Mean       -1.4042
trainer/Policy log std Std         0.268541
trainer/Policy log std Max        -0.373034
trainer/Policy log std Min        -1.71444
trainer/Alpha                      0.0296121
trainer/Alpha Loss                -2.96936
exploration/num steps total    13200
exploration/num paths total      132
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.144665
exploration/Rewards Std            0.160475
exploration/Rewards Max           -0.00376181
exploration/Rewards Min           -1
exploration/Returns Mean         -14.4665
exploration/Returns Std            0.335016
exploration/Returns Max          -14.1315
exploration/Returns Min          -14.8015
exploration/Actions Mean           0.0405642
exploration/Actions Std            0.330886
exploration/Actions Max            0.992814
exploration/Actions Min           -0.758729
exploration/Num Paths              2
exploration/Average Returns      -14.4665
evaluation/num steps total     65000
evaluation/num paths total       650
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0795179
evaluation/Rewards Std             0.196062
evaluation/Rewards Max            -0.0161624
evaluation/Rewards Min            -1
evaluation/Returns Mean           -7.95179
evaluation/Returns Std             2.99435
evaluation/Returns Max            -3.42598
evaluation/Returns Min           -11.9215
evaluation/Actions Mean            0.0230348
evaluation/Actions Std             0.184171
evaluation/Actions Max             0.979866
evaluation/Actions Min            -0.96216
evaluation/Num Paths              10
evaluation/Average Returns        -7.95179
time/data storing (s)              0.00157907
time/evaluation sampling (s)       0.366939
time/exploration sampling (s)      0.0947603
time/logging (s)                   0.00394438
time/saving (s)                    0.00251174
time/training (s)                  1.21164
time/epoch (s)                     1.68137
time/total (s)                    97.429
Epoch                             64
-----------------------------  --------------
2019-04-22 20:54:15.300834 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 65 finished
-----------------------------  --------------
replay_buffer/size             13400
trainer/QF1 Loss                   1.3981
trainer/QF2 Loss                   1.39666
trainer/Policy Loss               10.295
trainer/Q1 Predictions Mean       -9.31151
trainer/Q1 Predictions Std         2.04044
trainer/Q1 Predictions Max        -8.3221
trainer/Q1 Predictions Min       -16.3051
trainer/Q2 Predictions Mean       -9.30846
trainer/Q2 Predictions Std         2.02766
trainer/Q2 Predictions Max        -8.32797
trainer/Q2 Predictions Min       -16.3685
trainer/Q Targets Mean            -9.05563
trainer/Q Targets Std              2.37872
trainer/Q Targets Max             -0.235231
trainer/Q Targets Min            -16.3838
trainer/Log Pis Mean               1.13648
trainer/Log Pis Std                1.40734
trainer/Log Pis Max                4.96587
trainer/Log Pis Min               -4.35485
trainer/Policy mu Mean             0.214521
trainer/Policy mu Std              0.799011
trainer/Policy mu Max              2.39861
trainer/Policy mu Min             -2.07752
trainer/Policy log std Mean       -1.43948
trainer/Policy log std Std         0.280868
trainer/Policy log std Max        -0.545584
trainer/Policy log std Min        -1.74852
trainer/Alpha                      0.0283336
trainer/Alpha Loss                -3.07715
exploration/num steps total    13400
exploration/num paths total      134
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.138665
exploration/Rewards Std            0.162487
exploration/Rewards Max           -0.00896718
exploration/Rewards Min           -1
exploration/Returns Mean         -13.8665
exploration/Returns Std            1.89539
exploration/Returns Max          -11.9711
exploration/Returns Min          -15.7619
exploration/Actions Mean           0.0167382
exploration/Actions Std            0.310612
exploration/Actions Max            0.996525
exploration/Actions Min           -0.990862
exploration/Num Paths              2
exploration/Average Returns      -13.8665
evaluation/num steps total     66000
evaluation/num paths total       660
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.080992
evaluation/Rewards Std             0.183155
evaluation/Rewards Max            -0.0108027
evaluation/Rewards Min            -1
evaluation/Returns Mean           -8.0992
evaluation/Returns Std             2.04391
evaluation/Returns Max            -4.59035
evaluation/Returns Min           -11.0349
evaluation/Actions Mean            0.0311716
evaluation/Actions Std             0.183662
evaluation/Actions Max             0.985496
evaluation/Actions Min            -0.870273
evaluation/Num Paths              10
evaluation/Average Returns        -8.0992
time/data storing (s)              0.00143048
time/evaluation sampling (s)       0.325601
time/exploration sampling (s)      0.0841668
time/logging (s)                   0.00337543
time/saving (s)                    0.0021352
time/training (s)                  1.17803
time/epoch (s)                     1.59474
time/total (s)                    99.0291
Epoch                             65
-----------------------------  --------------
2019-04-22 20:54:16.954656 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 66 finished
-----------------------------  --------------
replay_buffer/size             13600
trainer/QF1 Loss                   1.04696
trainer/QF2 Loss                   1.05434
trainer/Policy Loss               10.388
trainer/Q1 Predictions Mean       -9.19159
trainer/Q1 Predictions Std         2.02459
trainer/Q1 Predictions Max        -8.11481
trainer/Q1 Predictions Min       -16.346
trainer/Q2 Predictions Mean       -9.20843
trainer/Q2 Predictions Std         2.04221
trainer/Q2 Predictions Max        -8.13655
trainer/Q2 Predictions Min       -16.4256
trainer/Q Targets Mean            -9.17514
trainer/Q Targets Std              2.18849
trainer/Q Targets Max             -1
trainer/Q Targets Min            -16.4537
trainer/Log Pis Mean               1.45982
trainer/Log Pis Std                1.14444
trainer/Log Pis Max                4.57998
trainer/Log Pis Min               -1.32053
trainer/Policy mu Mean             0.0246203
trainer/Policy mu Std              0.871598
trainer/Policy mu Max              2.31828
trainer/Policy mu Min             -2.33675
trainer/Policy log std Mean       -1.45603
trainer/Policy log std Std         0.332688
trainer/Policy log std Max        -0.487989
trainer/Policy log std Min        -1.84687
trainer/Alpha                      0.0271096
trainer/Alpha Loss                -1.9488
exploration/num steps total    13600
exploration/num paths total      136
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.131362
exploration/Rewards Std            0.162278
exploration/Rewards Max           -0.0064711
exploration/Rewards Min           -1
exploration/Returns Mean         -13.1362
exploration/Returns Std            0.841707
exploration/Returns Max          -12.2945
exploration/Returns Min          -13.978
exploration/Actions Mean          -0.0213362
exploration/Actions Std            0.284683
exploration/Actions Max            0.957107
exploration/Actions Min           -0.987907
exploration/Num Paths              2
exploration/Average Returns      -13.1362
evaluation/num steps total     67000
evaluation/num paths total       670
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0875489
evaluation/Rewards Std             0.181471
evaluation/Rewards Max            -0.0169598
evaluation/Rewards Min            -1
evaluation/Returns Mean           -8.75489
evaluation/Returns Std             2.9849
evaluation/Returns Max            -4.98868
evaluation/Returns Min           -13.9615
evaluation/Actions Mean            0.0161476
evaluation/Actions Std             0.179003
evaluation/Actions Max             0.985116
evaluation/Actions Min            -0.975129
evaluation/Num Paths              10
evaluation/Average Returns        -8.75489
time/data storing (s)              0.00145956
time/evaluation sampling (s)       0.316401
time/exploration sampling (s)      0.0843791
time/logging (s)                   0.00355774
time/saving (s)                    0.00247841
time/training (s)                  1.23949
time/epoch (s)                     1.64777
time/total (s)                   100.682
Epoch                             66
-----------------------------  --------------
2019-04-22 20:54:18.545581 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 67 finished
-----------------------------  --------------
replay_buffer/size             13800
trainer/QF1 Loss                   0.651866
trainer/QF2 Loss                   0.646504
trainer/Policy Loss                9.83871
trainer/Q1 Predictions Mean       -8.83589
trainer/Q1 Predictions Std         1.69888
trainer/Q1 Predictions Max        -8.05505
trainer/Q1 Predictions Min       -16.004
trainer/Q2 Predictions Mean       -8.83483
trainer/Q2 Predictions Std         1.6917
trainer/Q2 Predictions Max        -8.05732
trainer/Q2 Predictions Min       -15.9792
trainer/Q Targets Mean            -8.88278
trainer/Q Targets Std              1.902
trainer/Q Targets Max             -0.25272
trainer/Q Targets Min            -16.2752
trainer/Log Pis Mean               1.17924
trainer/Log Pis Std                1.32144
trainer/Log Pis Max                4.4202
trainer/Log Pis Min               -2.68665
trainer/Policy mu Mean             0.0397926
trainer/Policy mu Std              0.804945
trainer/Policy mu Max              2.22882
trainer/Policy mu Min             -2.18201
trainer/Policy log std Mean       -1.53819
trainer/Policy log std Std         0.288141
trainer/Policy log std Max        -0.526494
trainer/Policy log std Min        -1.84842
trainer/Alpha                      0.0260209
trainer/Alpha Loss                -2.99467
exploration/num steps total    13800
exploration/num paths total      138
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.163997
exploration/Rewards Std            0.2414
exploration/Rewards Max           -0.0069784
exploration/Rewards Min           -1
exploration/Returns Mean         -16.3997
exploration/Returns Std            1.4918
exploration/Returns Max          -14.9079
exploration/Returns Min          -17.8915
exploration/Actions Mean           0.0344454
exploration/Actions Std            0.304792
exploration/Actions Max            0.998783
exploration/Actions Min           -0.792902
exploration/Num Paths              2
exploration/Average Returns      -16.3997
evaluation/num steps total     68000
evaluation/num paths total       680
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.102162
evaluation/Rewards Std             0.17897
evaluation/Rewards Max            -0.0513677
evaluation/Rewards Min            -1
evaluation/Returns Mean          -10.2162
evaluation/Returns Std             2.5979
evaluation/Returns Max            -6.31553
evaluation/Returns Min           -13.5701
evaluation/Actions Mean            0.0252187
evaluation/Actions Std             0.193098
evaluation/Actions Max             0.982307
evaluation/Actions Min            -0.960803
evaluation/Num Paths              10
evaluation/Average Returns       -10.2162
time/data storing (s)              0.00157551
time/evaluation sampling (s)       0.309679
time/exploration sampling (s)      0.084287
time/logging (s)                   0.00320681
time/saving (s)                    0.00269429
time/training (s)                  1.1827
time/epoch (s)                     1.58415
time/total (s)                   102.27
Epoch                             67
-----------------------------  --------------
2019-04-22 20:54:20.121775 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 68 finished
-----------------------------  --------------
replay_buffer/size             14000
trainer/QF1 Loss                   1.30949
trainer/QF2 Loss                   1.31041
trainer/Policy Loss               10.4434
trainer/Q1 Predictions Mean       -9.12866
trainer/Q1 Predictions Std         2.10983
trainer/Q1 Predictions Max        -8.03215
trainer/Q1 Predictions Min       -16.829
trainer/Q2 Predictions Mean       -9.11266
trainer/Q2 Predictions Std         2.10176
trainer/Q2 Predictions Max        -8.04217
trainer/Q2 Predictions Min       -16.6693
trainer/Q Targets Mean            -9.05815
trainer/Q Targets Std              2.48027
trainer/Q Targets Max             -0.0277823
trainer/Q Targets Min            -17.1585
trainer/Log Pis Mean               1.49742
trainer/Log Pis Std                1.25648
trainer/Log Pis Max                4.6446
trainer/Log Pis Min               -2.46993
trainer/Policy mu Mean             0.142256
trainer/Policy mu Std              0.847159
trainer/Policy mu Max              2.33564
trainer/Policy mu Min             -2.14316
trainer/Policy log std Mean       -1.54398
trainer/Policy log std Std         0.370292
trainer/Policy log std Max        -0.416917
trainer/Policy log std Min        -1.90226
trainer/Alpha                      0.0250175
trainer/Alpha Loss                -1.85352
exploration/num steps total    14000
exploration/num paths total      140
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.138672
exploration/Rewards Std            0.187643
exploration/Rewards Max           -0.00789151
exploration/Rewards Min           -1
exploration/Returns Mean         -13.8672
exploration/Returns Std            1.7263
exploration/Returns Max          -12.1409
exploration/Returns Min          -15.5935
exploration/Actions Mean           0.0268098
exploration/Actions Std            0.287115
exploration/Actions Max            0.996467
exploration/Actions Min           -0.990039
exploration/Num Paths              2
exploration/Average Returns      -13.8672
evaluation/num steps total     69000
evaluation/num paths total       690
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.118932
evaluation/Rewards Std             0.22212
evaluation/Rewards Max            -0.0585227
evaluation/Rewards Min            -1
evaluation/Returns Mean          -11.8932
evaluation/Returns Std             2.295
evaluation/Returns Max            -8.13756
evaluation/Returns Min           -14.9601
evaluation/Actions Mean            0.0387905
evaluation/Actions Std             0.214021
evaluation/Actions Max             0.983529
evaluation/Actions Min            -0.909104
evaluation/Num Paths              10
evaluation/Average Returns       -11.8932
time/data storing (s)              0.00144114
time/evaluation sampling (s)       0.308353
time/exploration sampling (s)      0.0833092
time/logging (s)                   0.00376504
time/saving (s)                    0.00273909
time/training (s)                  1.17044
time/epoch (s)                     1.57005
time/total (s)                   103.845
Epoch                             68
-----------------------------  --------------
2019-04-22 20:54:21.615534 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 69 finished
-----------------------------  --------------
replay_buffer/size             14200
trainer/QF1 Loss                   1.67938
trainer/QF2 Loss                   1.68812
trainer/Policy Loss                9.8611
trainer/Q1 Predictions Mean       -8.61479
trainer/Q1 Predictions Std         1.53713
trainer/Q1 Predictions Max        -7.99831
trainer/Q1 Predictions Min       -16.9717
trainer/Q2 Predictions Mean       -8.6159
trainer/Q2 Predictions Std         1.53239
trainer/Q2 Predictions Max        -7.98987
trainer/Q2 Predictions Min       -16.733
trainer/Q Targets Mean            -8.56915
trainer/Q Targets Std              1.64647
trainer/Q Targets Max             -1
trainer/Q Targets Min            -16.6776
trainer/Log Pis Mean               1.3821
trainer/Log Pis Std                1.07663
trainer/Log Pis Max                4.55796
trainer/Log Pis Min               -2.64678
trainer/Policy mu Mean             0.0725379
trainer/Policy mu Std              0.705412
trainer/Policy mu Max              2.28683
trainer/Policy mu Min             -1.76343
trainer/Policy log std Mean       -1.68213
trainer/Policy log std Std         0.299799
trainer/Policy log std Max        -0.476162
trainer/Policy log std Min        -1.98009
trainer/Alpha                      0.0239933
trainer/Alpha Loss                -2.30463
exploration/num steps total    14200
exploration/num paths total      142
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.134958
exploration/Rewards Std            0.207991
exploration/Rewards Max           -0.00575635
exploration/Rewards Min           -1
exploration/Returns Mean         -13.4958
exploration/Returns Std            0.888952
exploration/Returns Max          -12.6068
exploration/Returns Min          -14.3847
exploration/Actions Mean           0.0475109
exploration/Actions Std            0.291868
exploration/Actions Max            0.997326
exploration/Actions Min           -0.587115
exploration/Num Paths              2
exploration/Average Returns      -13.4958
evaluation/num steps total     70000
evaluation/num paths total       700
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0824729
evaluation/Rewards Std             0.174722
evaluation/Rewards Max            -0.0365849
evaluation/Rewards Min            -1
evaluation/Returns Mean           -8.24729
evaluation/Returns Std             2.50754
evaluation/Returns Max            -5.23368
evaluation/Returns Min           -13.7765
evaluation/Actions Mean            0.0167685
evaluation/Actions Std             0.177731
evaluation/Actions Max             0.986097
evaluation/Actions Min            -0.986866
evaluation/Num Paths              10
evaluation/Average Returns        -8.24729
time/data storing (s)              0.0012506
time/evaluation sampling (s)       0.298277
time/exploration sampling (s)      0.0695445
time/logging (s)                   0.0033921
time/saving (s)                    0.0026545
time/training (s)                  1.11245
time/epoch (s)                     1.48757
time/total (s)                   105.337
Epoch                             69
-----------------------------  --------------
2019-04-22 20:54:23.075743 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 70 finished
-----------------------------  --------------
replay_buffer/size             14400
trainer/QF1 Loss                   0.0273097
trainer/QF2 Loss                   0.0300794
trainer/Policy Loss                9.86153
trainer/Q1 Predictions Mean       -8.83093
trainer/Q1 Predictions Std         1.82609
trainer/Q1 Predictions Max        -7.9001
trainer/Q1 Predictions Min       -16.3027
trainer/Q2 Predictions Mean       -8.81845
trainer/Q2 Predictions Std         1.81882
trainer/Q2 Predictions Max        -7.89024
trainer/Q2 Predictions Min       -16.3032
trainer/Q Targets Mean            -8.94204
trainer/Q Targets Std              1.83765
trainer/Q Targets Max             -7.96959
trainer/Q Targets Min            -16.1867
trainer/Log Pis Mean               1.21031
trainer/Log Pis Std                1.42736
trainer/Log Pis Max                5.56331
trainer/Log Pis Min               -3.12177
trainer/Policy mu Mean             0.124108
trainer/Policy mu Std              0.848124
trainer/Policy mu Max              2.37638
trainer/Policy mu Min             -2.47348
trainer/Policy log std Mean       -1.54202
trainer/Policy log std Std         0.367639
trainer/Policy log std Max        -0.288242
trainer/Policy log std Min        -1.89315
trainer/Alpha                      0.0230791
trainer/Alpha Loss                -2.97605
exploration/num steps total    14400
exploration/num paths total      144
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.172095
exploration/Rewards Std            0.249683
exploration/Rewards Max           -0.00862853
exploration/Rewards Min           -1
exploration/Returns Mean         -17.2095
exploration/Returns Std            1.27129
exploration/Returns Max          -15.9382
exploration/Returns Min          -18.4808
exploration/Actions Mean           0.0237642
exploration/Actions Std            0.337371
exploration/Actions Max            0.998235
exploration/Actions Min           -0.958705
exploration/Num Paths              2
exploration/Average Returns      -17.2095
evaluation/num steps total     71000
evaluation/num paths total       710
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0856309
evaluation/Rewards Std             0.158046
evaluation/Rewards Max            -0.0360003
evaluation/Rewards Min            -1
evaluation/Returns Mean           -8.56309
evaluation/Returns Std             2.25261
evaluation/Returns Max            -5.6363
evaluation/Returns Min           -12.4308
evaluation/Actions Mean            0.0121377
evaluation/Actions Std             0.173255
evaluation/Actions Max             0.984378
evaluation/Actions Min            -0.984876
evaluation/Num Paths              10
evaluation/Average Returns        -8.56309
time/data storing (s)              0.00145696
time/evaluation sampling (s)       0.286144
time/exploration sampling (s)      0.0707051
time/logging (s)                   0.00347599
time/saving (s)                    0.00206287
time/training (s)                  1.08988
time/epoch (s)                     1.45372
time/total (s)                   106.796
Epoch                             70
-----------------------------  --------------
2019-04-22 20:54:24.539634 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 71 finished
-----------------------------  --------------
replay_buffer/size             14600
trainer/QF1 Loss                   0.00982546
trainer/QF2 Loss                   0.0111079
trainer/Policy Loss               10.3347
trainer/Q1 Predictions Mean       -8.85224
trainer/Q1 Predictions Std         1.83641
trainer/Q1 Predictions Max        -7.94159
trainer/Q1 Predictions Min       -15.9582
trainer/Q2 Predictions Mean       -8.85381
trainer/Q2 Predictions Std         1.82481
trainer/Q2 Predictions Max        -7.9534
trainer/Q2 Predictions Min       -15.9392
trainer/Q Targets Mean            -8.86671
trainer/Q Targets Std              1.8762
trainer/Q Targets Max             -7.93523
trainer/Q Targets Min            -16.1306
trainer/Log Pis Mean               1.64791
trainer/Log Pis Std                1.14087
trainer/Log Pis Max                5.89576
trainer/Log Pis Min               -0.715784
trainer/Policy mu Mean             0.0946603
trainer/Policy mu Std              0.859833
trainer/Policy mu Max              2.49287
trainer/Policy mu Min             -2.49858
trainer/Policy log std Mean       -1.61366
trainer/Policy log std Std         0.364537
trainer/Policy log std Max        -0.50078
trainer/Policy log std Min        -1.96664
trainer/Alpha                      0.022332
trainer/Alpha Loss                -1.33849
exploration/num steps total    14600
exploration/num paths total      146
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.10519
exploration/Rewards Std            0.142769
exploration/Rewards Max           -0.0141838
exploration/Rewards Min           -1
exploration/Returns Mean         -10.519
exploration/Returns Std            1.06172
exploration/Returns Max           -9.45725
exploration/Returns Min          -11.5807
exploration/Actions Mean           0.0317707
exploration/Actions Std            0.265127
exploration/Actions Max            0.993861
exploration/Actions Min           -0.478944
exploration/Num Paths              2
exploration/Average Returns      -10.519
evaluation/num steps total     72000
evaluation/num paths total       720
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0744845
evaluation/Rewards Std             0.191552
evaluation/Rewards Max            -0.0222935
evaluation/Rewards Min            -1
evaluation/Returns Mean           -7.44845
evaluation/Returns Std             2.65159
evaluation/Returns Max            -3.85177
evaluation/Returns Min           -11.3809
evaluation/Actions Mean            0.0291289
evaluation/Actions Std             0.197128
evaluation/Actions Max             0.98769
evaluation/Actions Min            -0.970248
evaluation/Num Paths              10
evaluation/Average Returns        -7.44845
time/data storing (s)              0.00126636
time/evaluation sampling (s)       0.293365
time/exploration sampling (s)      0.0756494
time/logging (s)                   0.00382239
time/saving (s)                    0.00226109
time/training (s)                  1.08117
time/epoch (s)                     1.45753
time/total (s)                   108.259
Epoch                             71
-----------------------------  --------------
2019-04-22 20:54:26.018640 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 72 finished
-----------------------------  --------------
replay_buffer/size             14800
trainer/QF1 Loss                   1.23435
trainer/QF2 Loss                   1.22647
trainer/Policy Loss               10.2888
trainer/Q1 Predictions Mean       -8.79736
trainer/Q1 Predictions Std         2.07043
trainer/Q1 Predictions Max        -7.85505
trainer/Q1 Predictions Min       -17.3411
trainer/Q2 Predictions Mean       -8.79268
trainer/Q2 Predictions Std         2.08243
trainer/Q2 Predictions Max        -7.83786
trainer/Q2 Predictions Min       -17.3403
trainer/Q Targets Mean            -8.71903
trainer/Q Targets Std              2.41457
trainer/Q Targets Max             -0.133393
trainer/Q Targets Min            -17.6091
trainer/Log Pis Mean               1.693
trainer/Log Pis Std                1.13973
trainer/Log Pis Max                6.02646
trainer/Log Pis Min               -0.852869
trainer/Policy mu Mean             0.087167
trainer/Policy mu Std              0.777869
trainer/Policy mu Max              2.49262
trainer/Policy mu Min             -2.36805
trainer/Policy log std Mean       -1.70124
trainer/Policy log std Std         0.352817
trainer/Policy log std Max        -0.432766
trainer/Policy log std Min        -2.01525
trainer/Alpha                      0.0214805
trainer/Alpha Loss                -1.17903
exploration/num steps total    14800
exploration/num paths total      148
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.136678
exploration/Rewards Std            0.202219
exploration/Rewards Max           -0.0150259
exploration/Rewards Min           -1
exploration/Returns Mean         -13.6678
exploration/Returns Std            3.10726
exploration/Returns Max          -10.5606
exploration/Returns Min          -16.7751
exploration/Actions Mean           0.0167992
exploration/Actions Std            0.285758
exploration/Actions Max            0.996282
exploration/Actions Min           -0.996619
exploration/Num Paths              2
exploration/Average Returns      -13.6678
evaluation/num steps total     73000
evaluation/num paths total       730
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0750313
evaluation/Rewards Std             0.159112
evaluation/Rewards Max            -0.0309674
evaluation/Rewards Min            -1
evaluation/Returns Mean           -7.50313
evaluation/Returns Std             2.42199
evaluation/Returns Max            -4.98288
evaluation/Returns Min           -11.1028
evaluation/Actions Mean            0.0251443
evaluation/Actions Std             0.166058
evaluation/Actions Max             0.987181
evaluation/Actions Min            -0.977444
evaluation/Num Paths              10
evaluation/Average Returns        -7.50313
time/data storing (s)              0.0012745
time/evaluation sampling (s)       0.281799
time/exploration sampling (s)      0.0710323
time/logging (s)                   0.00356663
time/saving (s)                    0.00229193
time/training (s)                  1.11241
time/epoch (s)                     1.47237
time/total (s)                   109.736
Epoch                             72
-----------------------------  --------------
2019-04-22 20:54:27.479787 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 73 finished
-----------------------------  --------------
replay_buffer/size             15000
trainer/QF1 Loss                   0.670006
trainer/QF2 Loss                   0.667897
trainer/Policy Loss                9.54837
trainer/Q1 Predictions Mean       -8.26205
trainer/Q1 Predictions Std         1.44647
trainer/Q1 Predictions Max        -7.61279
trainer/Q1 Predictions Min       -16.1361
trainer/Q2 Predictions Mean       -8.26131
trainer/Q2 Predictions Std         1.44989
trainer/Q2 Predictions Max        -7.57575
trainer/Q2 Predictions Min       -16.0289
trainer/Q Targets Mean            -8.47945
trainer/Q Targets Std              1.68817
trainer/Q Targets Max             -0.154946
trainer/Q Targets Min            -16.5604
trainer/Log Pis Mean               1.4652
trainer/Log Pis Std                1.59353
trainer/Log Pis Max                5.11405
trainer/Log Pis Min               -4.02767
trainer/Policy mu Mean             0.063429
trainer/Policy mu Std              0.890663
trainer/Policy mu Max              2.62722
trainer/Policy mu Min             -2.50824
trainer/Policy log std Mean       -1.59638
trainer/Policy log std Std         0.381479
trainer/Policy log std Max        -0.373968
trainer/Policy log std Min        -1.94175
trainer/Alpha                      0.020669
trainer/Alpha Loss                -2.07446
exploration/num steps total    15000
exploration/num paths total      150
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.0971465
exploration/Rewards Std            0.0865949
exploration/Rewards Max           -0.00596633
exploration/Rewards Min           -1
exploration/Returns Mean          -9.71465
exploration/Returns Std            1.08886
exploration/Returns Max           -8.62579
exploration/Returns Min          -10.8035
exploration/Actions Mean           0.0145846
exploration/Actions Std            0.24444
exploration/Actions Max            0.980994
exploration/Actions Min           -0.555767
exploration/Num Paths              2
exploration/Average Returns       -9.71465
evaluation/num steps total     74000
evaluation/num paths total       740
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.100833
evaluation/Rewards Std             0.194239
evaluation/Rewards Max            -0.0366854
evaluation/Rewards Min            -1
evaluation/Returns Mean          -10.0833
evaluation/Returns Std             3.08517
evaluation/Returns Max            -5.64672
evaluation/Returns Min           -14.5137
evaluation/Actions Mean            0.0187991
evaluation/Actions Std             0.19066
evaluation/Actions Max             0.988138
evaluation/Actions Min            -0.987605
evaluation/Num Paths              10
evaluation/Average Returns       -10.0833
time/data storing (s)              0.00122574
time/evaluation sampling (s)       0.282208
time/exploration sampling (s)      0.0701467
time/logging (s)                   0.0034332
time/saving (s)                    0.00273316
time/training (s)                  1.09464
time/epoch (s)                     1.45438
time/total (s)                   111.195
Epoch                             73
-----------------------------  --------------
2019-04-22 20:54:29.215195 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 74 finished
-----------------------------  --------------
replay_buffer/size             15200
trainer/QF1 Loss                   2.61044
trainer/QF2 Loss                   2.63006
trainer/Policy Loss               10.4243
trainer/Q1 Predictions Mean       -8.73585
trainer/Q1 Predictions Std         2.00787
trainer/Q1 Predictions Max        -7.75987
trainer/Q1 Predictions Min       -16.3138
trainer/Q2 Predictions Mean       -8.73651
trainer/Q2 Predictions Std         2.02595
trainer/Q2 Predictions Max        -7.72509
trainer/Q2 Predictions Min       -16.2373
trainer/Q Targets Mean            -8.51395
trainer/Q Targets Std              2.44361
trainer/Q Targets Max             -0.201944
trainer/Q Targets Min            -16.674
trainer/Log Pis Mean               1.91172
trainer/Log Pis Std                1.18433
trainer/Log Pis Max                5.46622
trainer/Log Pis Min               -1.86475
trainer/Policy mu Mean             0.125069
trainer/Policy mu Std              0.822628
trainer/Policy mu Max              2.46941
trainer/Policy mu Min             -2.48737
trainer/Policy log std Mean       -1.78441
trainer/Policy log std Std         0.411255
trainer/Policy log std Max        -0.438623
trainer/Policy log std Min        -2.1563
trainer/Alpha                      0.0199502
trainer/Alpha Loss                -0.345546
exploration/num steps total    15200
exploration/num paths total      152
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.0934847
exploration/Rewards Std            0.117095
exploration/Rewards Max           -0.00797276
exploration/Rewards Min           -1
exploration/Returns Mean          -9.34847
exploration/Returns Std            1.05625
exploration/Returns Max           -8.29222
exploration/Returns Min          -10.4047
exploration/Actions Mean           0.0118598
exploration/Actions Std            0.240175
exploration/Actions Max            0.995114
exploration/Actions Min           -0.961747
exploration/Num Paths              2
exploration/Average Returns       -9.34847
evaluation/num steps total     75000
evaluation/num paths total       750
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0809069
evaluation/Rewards Std             0.173204
evaluation/Rewards Max            -0.032336
evaluation/Rewards Min            -1
evaluation/Returns Mean           -8.09069
evaluation/Returns Std             2.72444
evaluation/Returns Max            -4.9066
evaluation/Returns Min           -13.6723
evaluation/Actions Mean            0.0061599
evaluation/Actions Std             0.183096
evaluation/Actions Max             0.985949
evaluation/Actions Min            -0.987224
evaluation/Num Paths              10
evaluation/Average Returns        -8.09069
time/data storing (s)              0.0031172
time/evaluation sampling (s)       0.349188
time/exploration sampling (s)      0.0852866
time/logging (s)                   0.00443367
time/saving (s)                    0.002774
time/training (s)                  1.28489
time/epoch (s)                     1.72969
time/total (s)                   112.93
Epoch                             74
-----------------------------  --------------
2019-04-22 20:54:30.939406 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 75 finished
-----------------------------  --------------
replay_buffer/size             15400
trainer/QF1 Loss                   0.0128296
trainer/QF2 Loss                   0.0126334
trainer/Policy Loss               10.192
trainer/Q1 Predictions Mean       -8.60028
trainer/Q1 Predictions Std         1.96495
trainer/Q1 Predictions Max        -7.73521
trainer/Q1 Predictions Min       -17.1078
trainer/Q2 Predictions Mean       -8.60242
trainer/Q2 Predictions Std         1.9633
trainer/Q2 Predictions Max        -7.72009
trainer/Q2 Predictions Min       -17.1634
trainer/Q Targets Mean            -8.58335
trainer/Q Targets Std              1.89797
trainer/Q Targets Max             -7.70795
trainer/Q Targets Min            -16.8873
trainer/Log Pis Mean               1.79047
trainer/Log Pis Std                1.0952
trainer/Log Pis Max                5.6206
trainer/Log Pis Min               -1.57578
trainer/Policy mu Mean             0.105747
trainer/Policy mu Std              0.842894
trainer/Policy mu Max              2.51355
trainer/Policy mu Min             -2.4955
trainer/Policy log std Mean       -1.72858
trainer/Policy log std Std         0.375244
trainer/Policy log std Max        -0.417684
trainer/Policy log std Min        -2.07814
trainer/Alpha                      0.01947
trainer/Alpha Loss                -0.825288
exploration/num steps total    15400
exploration/num paths total      154
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.0996813
exploration/Rewards Std            0.0969534
exploration/Rewards Max           -0.00806183
exploration/Rewards Min           -1
exploration/Returns Mean          -9.96813
exploration/Returns Std            0.590637
exploration/Returns Max           -9.37749
exploration/Returns Min          -10.5588
exploration/Actions Mean          -0.0106716
exploration/Actions Std            0.223962
exploration/Actions Max            0.656845
exploration/Actions Min           -0.996118
exploration/Num Paths              2
exploration/Average Returns       -9.96813
evaluation/num steps total     76000
evaluation/num paths total       760
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0901079
evaluation/Rewards Std             0.156682
evaluation/Rewards Max            -0.0405231
evaluation/Rewards Min            -1
evaluation/Returns Mean           -9.01079
evaluation/Returns Std             2.5973
evaluation/Returns Max            -5.99342
evaluation/Returns Min           -13.7396
evaluation/Actions Mean            0.0107247
evaluation/Actions Std             0.162645
evaluation/Actions Max             0.987782
evaluation/Actions Min            -0.989979
evaluation/Num Paths              10
evaluation/Average Returns        -9.01079
time/data storing (s)              0.00142319
time/evaluation sampling (s)       0.311965
time/exploration sampling (s)      0.0792193
time/logging (s)                   0.0037301
time/saving (s)                    0.00334793
time/training (s)                  1.3169
time/epoch (s)                     1.71658
time/total (s)                   114.651
Epoch                             75
-----------------------------  --------------
2019-04-22 20:54:32.654528 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 76 finished
-----------------------------  --------------
replay_buffer/size             15600
trainer/QF1 Loss                   0.0477744
trainer/QF2 Loss                   0.0512336
trainer/Policy Loss               10.0869
trainer/Q1 Predictions Mean       -8.56581
trainer/Q1 Predictions Std         2.19026
trainer/Q1 Predictions Max        -7.46169
trainer/Q1 Predictions Min       -15.8803
trainer/Q2 Predictions Mean       -8.55964
trainer/Q2 Predictions Std         2.18525
trainer/Q2 Predictions Max        -7.47309
trainer/Q2 Predictions Min       -15.9592
trainer/Q Targets Mean            -8.75865
trainer/Q Targets Std              2.20547
trainer/Q Targets Max             -7.65001
trainer/Q Targets Min            -16.2341
trainer/Log Pis Mean               1.71537
trainer/Log Pis Std                1.56295
trainer/Log Pis Max                6.19415
trainer/Log Pis Min               -4.32913
trainer/Policy mu Mean             0.190843
trainer/Policy mu Std              0.875689
trainer/Policy mu Max              2.5229
trainer/Policy mu Min             -2.47557
trainer/Policy log std Mean       -1.76634
trainer/Policy log std Std         0.426428
trainer/Policy log std Max        -0.466373
trainer/Policy log std Min        -2.13319
trainer/Alpha                      0.0190677
trainer/Alpha Loss                -1.12705
exploration/num steps total    15600
exploration/num paths total      156
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.134259
exploration/Rewards Std            0.228384
exploration/Rewards Max           -0.00615705
exploration/Rewards Min           -1
exploration/Returns Mean         -13.4259
exploration/Returns Std            1.91271
exploration/Returns Max          -11.5132
exploration/Returns Min          -15.3386
exploration/Actions Mean           0.046228
exploration/Actions Std            0.27937
exploration/Actions Max            0.992401
exploration/Actions Min           -0.556021
exploration/Num Paths              2
exploration/Average Returns      -13.4259
evaluation/num steps total     77000
evaluation/num paths total       770
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0720883
evaluation/Rewards Std             0.178401
evaluation/Rewards Max            -0.0318772
evaluation/Rewards Min            -1
evaluation/Returns Mean           -7.20883
evaluation/Returns Std             1.85135
evaluation/Returns Max            -5.08414
evaluation/Returns Min           -10.259
evaluation/Actions Mean            0.0243261
evaluation/Actions Std             0.187836
evaluation/Actions Max             0.987266
evaluation/Actions Min            -0.986554
evaluation/Num Paths              10
evaluation/Average Returns        -7.20883
time/data storing (s)              0.00124002
time/evaluation sampling (s)       0.304317
time/exploration sampling (s)      0.07758
time/logging (s)                   0.00381232
time/saving (s)                    0.00238157
time/training (s)                  1.31907
time/epoch (s)                     1.7084
time/total (s)                   116.365
Epoch                             76
-----------------------------  --------------
2019-04-22 20:54:34.330458 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 77 finished
-----------------------------  --------------
replay_buffer/size             15800
trainer/QF1 Loss                   0.570984
trainer/QF2 Loss                   0.577188
trainer/Policy Loss                9.91044
trainer/Q1 Predictions Mean       -8.47778
trainer/Q1 Predictions Std         2.16844
trainer/Q1 Predictions Max        -7.45721
trainer/Q1 Predictions Min       -17.0535
trainer/Q2 Predictions Mean       -8.47619
trainer/Q2 Predictions Std         2.17515
trainer/Q2 Predictions Max        -7.46532
trainer/Q2 Predictions Min       -17.0726
trainer/Q Targets Mean            -8.53202
trainer/Q Targets Std              2.26659
trainer/Q Targets Max             -0.492348
trainer/Q Targets Min            -16.9801
trainer/Log Pis Mean               1.61087
trainer/Log Pis Std                1.27812
trainer/Log Pis Max                4.53129
trainer/Log Pis Min               -2.68523
trainer/Policy mu Mean             0.123369
trainer/Policy mu Std              0.844373
trainer/Policy mu Max              2.54927
trainer/Policy mu Min             -2.36554
trainer/Policy log std Mean       -1.78165
trainer/Policy log std Std         0.399106
trainer/Policy log std Max        -0.530618
trainer/Policy log std Min        -2.14348
trainer/Alpha                      0.0185487
trainer/Alpha Loss                -1.55153
exploration/num steps total    15800
exploration/num paths total      158
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.115119
exploration/Rewards Std            0.173463
exploration/Rewards Max           -0.00607149
exploration/Rewards Min           -1
exploration/Returns Mean         -11.5119
exploration/Returns Std            0.837836
exploration/Returns Max          -10.6741
exploration/Returns Min          -12.3497
exploration/Actions Mean          -0.00601701
exploration/Actions Std            0.266859
exploration/Actions Max            0.996857
exploration/Actions Min           -0.988967
exploration/Num Paths              2
exploration/Average Returns      -11.5119
evaluation/num steps total     78000
evaluation/num paths total       780
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0748288
evaluation/Rewards Std             0.175366
evaluation/Rewards Max            -0.0160916
evaluation/Rewards Min            -1
evaluation/Returns Mean           -7.48288
evaluation/Returns Std             2.32369
evaluation/Returns Max            -3.88351
evaluation/Returns Min           -11.8742
evaluation/Actions Mean            0.0125875
evaluation/Actions Std             0.182081
evaluation/Actions Max             0.988945
evaluation/Actions Min            -0.991636
evaluation/Num Paths              10
evaluation/Average Returns        -7.48288
time/data storing (s)              0.00148163
time/evaluation sampling (s)       0.332584
time/exploration sampling (s)      0.0770201
time/logging (s)                   0.00346765
time/saving (s)                    0.0022649
time/training (s)                  1.25256
time/epoch (s)                     1.66938
time/total (s)                   118.038
Epoch                             77
-----------------------------  --------------
2019-04-22 20:54:35.816721 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 78 finished
-----------------------------  --------------
replay_buffer/size             16000
trainer/QF1 Loss                   0.567826
trainer/QF2 Loss                   0.572316
trainer/Policy Loss                9.81729
trainer/Q1 Predictions Mean       -8.15432
trainer/Q1 Predictions Std         1.56054
trainer/Q1 Predictions Max        -7.45088
trainer/Q1 Predictions Min       -15.8884
trainer/Q2 Predictions Mean       -8.15891
trainer/Q2 Predictions Std         1.56109
trainer/Q2 Predictions Max        -7.43629
trainer/Q2 Predictions Min       -15.7364
trainer/Q Targets Mean            -8.19252
trainer/Q Targets Std              1.75192
trainer/Q Targets Max             -0.108375
trainer/Q Targets Min            -15.9235
trainer/Log Pis Mean               1.88519
trainer/Log Pis Std                1.31842
trainer/Log Pis Max                5.99043
trainer/Log Pis Min               -1.76329
trainer/Policy mu Mean             0.0110573
trainer/Policy mu Std              0.835897
trainer/Policy mu Max              2.5677
trainer/Policy mu Min             -2.06549
trainer/Policy log std Mean       -1.79769
trainer/Policy log std Std         0.385656
trainer/Policy log std Max        -0.536634
trainer/Policy log std Min        -2.21464
trainer/Alpha                      0.0180896
trainer/Alpha Loss                -0.460666
exploration/num steps total    16000
exploration/num paths total      160
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.135349
exploration/Rewards Std            0.204484
exploration/Rewards Max           -0.00472708
exploration/Rewards Min           -1
exploration/Returns Mean         -13.5349
exploration/Returns Std            1.31875
exploration/Returns Max          -12.2162
exploration/Returns Min          -14.8537
exploration/Actions Mean           0.0116032
exploration/Actions Std            0.266356
exploration/Actions Max            0.995217
exploration/Actions Min           -0.998598
exploration/Num Paths              2
exploration/Average Returns      -13.5349
evaluation/num steps total     79000
evaluation/num paths total       790
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.104049
evaluation/Rewards Std             0.186381
evaluation/Rewards Max            -0.0248016
evaluation/Rewards Min            -1
evaluation/Returns Mean          -10.4049
evaluation/Returns Std             2.38168
evaluation/Returns Max            -6.33246
evaluation/Returns Min           -13.8929
evaluation/Actions Mean            0.023819
evaluation/Actions Std             0.190158
evaluation/Actions Max             0.989315
evaluation/Actions Min            -0.98633
evaluation/Num Paths              10
evaluation/Average Returns       -10.4049
time/data storing (s)              0.00125292
time/evaluation sampling (s)       0.29843
time/exploration sampling (s)      0.0731539
time/logging (s)                   0.00355249
time/saving (s)                    0.00241064
time/training (s)                  1.10153
time/epoch (s)                     1.48033
time/total (s)                   119.523
Epoch                             78
-----------------------------  --------------
2019-04-22 20:54:37.302751 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 79 finished
-----------------------------  --------------
replay_buffer/size             16200
trainer/QF1 Loss                   2.17326
trainer/QF2 Loss                   2.18953
trainer/Policy Loss               10.4043
trainer/Q1 Predictions Mean       -8.5656
trainer/Q1 Predictions Std         2.21338
trainer/Q1 Predictions Max        -7.41408
trainer/Q1 Predictions Min       -16.5394
trainer/Q2 Predictions Mean       -8.56577
trainer/Q2 Predictions Std         2.20314
trainer/Q2 Predictions Max        -7.4176
trainer/Q2 Predictions Min       -16.5857
trainer/Q Targets Mean            -8.33847
trainer/Q Targets Std              2.72968
trainer/Q Targets Max             -0.226221
trainer/Q Targets Min            -16.8228
trainer/Log Pis Mean               2.08281
trainer/Log Pis Std                1.37075
trainer/Log Pis Max                6.16282
trainer/Log Pis Min               -2.03038
trainer/Policy mu Mean             0.203121
trainer/Policy mu Std              0.896125
trainer/Policy mu Max              2.76582
trainer/Policy mu Min             -2.53854
trainer/Policy log std Mean       -1.79841
trainer/Policy log std Std         0.461199
trainer/Policy log std Max        -0.450927
trainer/Policy log std Min        -2.22522
trainer/Alpha                      0.0177046
trainer/Alpha Loss                 0.334037
exploration/num steps total    16200
exploration/num paths total      162
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.0992538
exploration/Rewards Std            0.14845
exploration/Rewards Max           -0.00374861
exploration/Rewards Min           -1
exploration/Returns Mean          -9.92538
exploration/Returns Std            2.35669
exploration/Returns Max           -7.56869
exploration/Returns Min          -12.2821
exploration/Actions Mean           0.0223169
exploration/Actions Std            0.215538
exploration/Actions Max            0.994412
exploration/Actions Min           -0.430989
exploration/Num Paths              2
exploration/Average Returns       -9.92538
evaluation/num steps total     80000
evaluation/num paths total       800
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.086936
evaluation/Rewards Std             0.19693
evaluation/Rewards Max            -0.0316987
evaluation/Rewards Min            -1
evaluation/Returns Mean           -8.6936
evaluation/Returns Std             2.25256
evaluation/Returns Max            -4.10945
evaluation/Returns Min           -12.3161
evaluation/Actions Mean            0.0308643
evaluation/Actions Std             0.199756
evaluation/Actions Max             0.989839
evaluation/Actions Min            -0.989849
evaluation/Num Paths              10
evaluation/Average Returns        -8.6936
time/data storing (s)              0.0012398
time/evaluation sampling (s)       0.286941
time/exploration sampling (s)      0.0687249
time/logging (s)                   0.00343605
time/saving (s)                    0.00215845
time/training (s)                  1.11767
time/epoch (s)                     1.48017
time/total (s)                   121.007
Epoch                             79
-----------------------------  --------------
2019-04-22 20:54:38.824410 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 80 finished
-----------------------------  --------------
replay_buffer/size             16400
trainer/QF1 Loss                   0.569686
trainer/QF2 Loss                   0.566832
trainer/Policy Loss                9.75092
trainer/Q1 Predictions Mean       -8.07197
trainer/Q1 Predictions Std         1.6171
trainer/Q1 Predictions Max        -7.3987
trainer/Q1 Predictions Min       -15.5477
trainer/Q2 Predictions Mean       -8.06887
trainer/Q2 Predictions Std         1.61215
trainer/Q2 Predictions Max        -7.39516
trainer/Q2 Predictions Min       -15.6219
trainer/Q Targets Mean            -8.01639
trainer/Q Targets Std              1.78196
trainer/Q Targets Max             -0.391327
trainer/Q Targets Min            -15.6863
trainer/Log Pis Mean               1.8389
trainer/Log Pis Std                1.06612
trainer/Log Pis Max                4.73967
trainer/Log Pis Min               -2.18565
trainer/Policy mu Mean             0.0989679
trainer/Policy mu Std              0.765557
trainer/Policy mu Max              2.57723
trainer/Policy mu Min             -1.95795
trainer/Policy log std Mean       -1.9191
trainer/Policy log std Std         0.39145
trainer/Policy log std Max        -0.434923
trainer/Policy log std Min        -2.29663
trainer/Alpha                      0.0172638
trainer/Alpha Loss                -0.653933
exploration/num steps total    16400
exploration/num paths total      164
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.100455
exploration/Rewards Std            0.15437
exploration/Rewards Max           -0.00499515
exploration/Rewards Min           -1
exploration/Returns Mean         -10.0455
exploration/Returns Std            0.857214
exploration/Returns Max           -9.18833
exploration/Returns Min          -10.9028
exploration/Actions Mean           0.00572782
exploration/Actions Std            0.226746
exploration/Actions Max            0.986584
exploration/Actions Min           -0.996303
exploration/Num Paths              2
exploration/Average Returns      -10.0455
evaluation/num steps total     81000
evaluation/num paths total       810
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0997555
evaluation/Rewards Std             0.200873
evaluation/Rewards Max            -0.0405894
evaluation/Rewards Min            -1
evaluation/Returns Mean           -9.97555
evaluation/Returns Std             2.43217
evaluation/Returns Max            -5.14663
evaluation/Returns Min           -13.7955
evaluation/Actions Mean            0.038393
evaluation/Actions Std             0.196122
evaluation/Actions Max             0.990397
evaluation/Actions Min            -0.960361
evaluation/Num Paths              10
evaluation/Average Returns        -9.97555
time/data storing (s)              0.00132532
time/evaluation sampling (s)       0.301611
time/exploration sampling (s)      0.0779004
time/logging (s)                   0.00332481
time/saving (s)                    0.0025729
time/training (s)                  1.12894
time/epoch (s)                     1.51567
time/total (s)                   122.527
Epoch                             80
-----------------------------  --------------
2019-04-22 20:54:40.341751 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 81 finished
-----------------------------  ---------------
replay_buffer/size             16600
trainer/QF1 Loss                   0.0225225
trainer/QF2 Loss                   0.0201469
trainer/Policy Loss                9.79786
trainer/Q1 Predictions Mean       -8.08868
trainer/Q1 Predictions Std         1.7755
trainer/Q1 Predictions Max        -7.22708
trainer/Q1 Predictions Min       -15.2033
trainer/Q2 Predictions Mean       -8.09553
trainer/Q2 Predictions Std         1.78858
trainer/Q2 Predictions Max        -7.2416
trainer/Q2 Predictions Min       -15.2421
trainer/Q Targets Mean            -8.21419
trainer/Q Targets Std              1.78137
trainer/Q Targets Max             -7.30861
trainer/Q Targets Min            -15.549
trainer/Log Pis Mean               1.92776
trainer/Log Pis Std                1.61808
trainer/Log Pis Max                6.39962
trainer/Log Pis Min               -2.72563
trainer/Policy mu Mean             0.179368
trainer/Policy mu Std              0.867119
trainer/Policy mu Max              2.7964
trainer/Policy mu Min             -1.8218
trainer/Policy log std Mean       -1.84691
trainer/Policy log std Std         0.419814
trainer/Policy log std Max        -0.449445
trainer/Policy log std Min        -2.29277
trainer/Alpha                      0.0170637
trainer/Alpha Loss                -0.294084
exploration/num steps total    16600
exploration/num paths total      166
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.0849786
exploration/Rewards Std            0.151676
exploration/Rewards Max           -0.00569391
exploration/Rewards Min           -1
exploration/Returns Mean          -8.49786
exploration/Returns Std            0.724952
exploration/Returns Max           -7.77291
exploration/Returns Min           -9.22282
exploration/Actions Mean           0.0324794
exploration/Actions Std            0.221716
exploration/Actions Max            0.99652
exploration/Actions Min           -0.58229
exploration/Num Paths              2
exploration/Average Returns       -8.49786
evaluation/num steps total     82000
evaluation/num paths total       820
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0526511
evaluation/Rewards Std             0.197076
evaluation/Rewards Max            -0.000437148
evaluation/Rewards Min            -1
evaluation/Returns Mean           -5.26511
evaluation/Returns Std             2.66821
evaluation/Returns Max            -1.25309
evaluation/Returns Min            -9.58522
evaluation/Actions Mean            0.0296747
evaluation/Actions Std             0.197975
evaluation/Actions Max             0.992123
evaluation/Actions Min            -0.991353
evaluation/Num Paths              10
evaluation/Average Returns        -5.26511
time/data storing (s)              0.00126878
time/evaluation sampling (s)       0.290114
time/exploration sampling (s)      0.0749406
time/logging (s)                   0.0034635
time/saving (s)                    0.00244149
time/training (s)                  1.13941
time/epoch (s)                     1.51164
time/total (s)                   124.043
Epoch                             81
-----------------------------  ---------------
2019-04-22 20:54:42.128801 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 82 finished
-----------------------------  --------------
replay_buffer/size             16800
trainer/QF1 Loss                   1.04498
trainer/QF2 Loss                   1.0416
trainer/Policy Loss                9.22106
trainer/Q1 Predictions Mean       -7.76008
trainer/Q1 Predictions Std         1.63045
trainer/Q1 Predictions Max        -7.12355
trainer/Q1 Predictions Min       -15.6796
trainer/Q2 Predictions Mean       -7.75934
trainer/Q2 Predictions Std         1.63326
trainer/Q2 Predictions Max        -7.13444
trainer/Q2 Predictions Min       -15.7154
trainer/Q Targets Mean            -7.78794
trainer/Q Targets Std              2.01303
trainer/Q Targets Max             -0.0577922
trainer/Q Targets Min            -16.188
trainer/Log Pis Mean               1.61388
trainer/Log Pis Std                1.37821
trainer/Log Pis Max                6.48235
trainer/Log Pis Min               -4.49594
trainer/Policy mu Mean             0.0778227
trainer/Policy mu Std              0.73026
trainer/Policy mu Max              2.42534
trainer/Policy mu Min             -2.28463
trainer/Policy log std Mean       -1.87585
trainer/Policy log std Std         0.390304
trainer/Policy log std Max        -0.33486
trainer/Policy log std Min        -2.24162
trainer/Alpha                      0.0168237
trainer/Alpha Loss                -1.57723
exploration/num steps total    16800
exploration/num paths total      168
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.0922538
exploration/Rewards Std            0.153252
exploration/Rewards Max           -0.00307858
exploration/Rewards Min           -1
exploration/Returns Mean          -9.22538
exploration/Returns Std            1.34209
exploration/Returns Max           -7.88329
exploration/Returns Min          -10.5675
exploration/Actions Mean           0.0267757
exploration/Actions Std            0.219594
exploration/Actions Max            0.994081
exploration/Actions Min           -0.539153
exploration/Num Paths              2
exploration/Average Returns       -9.22538
evaluation/num steps total     83000
evaluation/num paths total       830
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0706419
evaluation/Rewards Std             0.169554
evaluation/Rewards Max            -0.0144138
evaluation/Rewards Min            -1
evaluation/Returns Mean           -7.06419
evaluation/Returns Std             1.35704
evaluation/Returns Max            -5.49049
evaluation/Returns Min           -10.1853
evaluation/Actions Mean            0.024225
evaluation/Actions Std             0.185295
evaluation/Actions Max             0.987082
evaluation/Actions Min            -0.98796
evaluation/Num Paths              10
evaluation/Average Returns        -7.06419
time/data storing (s)              0.0014512
time/evaluation sampling (s)       0.30338
time/exploration sampling (s)      0.0805596
time/logging (s)                   0.00381614
time/saving (s)                    0.00237343
time/training (s)                  1.3887
time/epoch (s)                     1.78028
time/total (s)                   125.828
Epoch                             82
-----------------------------  --------------
2019-04-22 20:54:43.644709 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 83 finished
-----------------------------  --------------
replay_buffer/size             17000
trainer/QF1 Loss                   0.0155703
trainer/QF2 Loss                   0.0140068
trainer/Policy Loss               10.0673
trainer/Q1 Predictions Mean       -8.11625
trainer/Q1 Predictions Std         1.96218
trainer/Q1 Predictions Max        -7.13777
trainer/Q1 Predictions Min       -16.4853
trainer/Q2 Predictions Mean       -8.11077
trainer/Q2 Predictions Std         1.95907
trainer/Q2 Predictions Max        -7.13316
trainer/Q2 Predictions Min       -16.4629
trainer/Q Targets Mean            -8.16015
trainer/Q Targets Std              1.88075
trainer/Q Targets Max             -7.19916
trainer/Q Targets Min            -16.2546
trainer/Log Pis Mean               2.11847
trainer/Log Pis Std                1.15515
trainer/Log Pis Max                6.02983
trainer/Log Pis Min               -1.58609
trainer/Policy mu Mean             0.090889
trainer/Policy mu Std              0.93616
trainer/Policy mu Max              2.76042
trainer/Policy mu Min             -2.16603
trainer/Policy log std Mean       -1.85978
trainer/Policy log std Std         0.509598
trainer/Policy log std Max        -0.483882
trainer/Policy log std Min        -2.40551
trainer/Alpha                      0.0166749
trainer/Alpha Loss                 0.484997
exploration/num steps total    17000
exploration/num paths total      170
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.119139
exploration/Rewards Std            0.120376
exploration/Rewards Max           -0.0206869
exploration/Rewards Min           -1
exploration/Returns Mean         -11.9139
exploration/Returns Std            1.89708
exploration/Returns Max          -10.0168
exploration/Returns Min          -13.811
exploration/Actions Mean          -0.0155216
exploration/Actions Std            0.189165
exploration/Actions Max            0.737809
exploration/Actions Min           -0.996925
exploration/Num Paths              2
exploration/Average Returns      -11.9139
evaluation/num steps total     84000
evaluation/num paths total       840
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.125675
evaluation/Rewards Std             0.167257
evaluation/Rewards Max            -0.0901018
evaluation/Rewards Min            -1
evaluation/Returns Mean          -12.5675
evaluation/Returns Std             2.49162
evaluation/Returns Max            -9.0641
evaluation/Returns Min           -16.9902
evaluation/Actions Mean            0.0314913
evaluation/Actions Std             0.178747
evaluation/Actions Max             0.990368
evaluation/Actions Min            -0.94241
evaluation/Num Paths              10
evaluation/Average Returns       -12.5675
time/data storing (s)              0.00139244
time/evaluation sampling (s)       0.289185
time/exploration sampling (s)      0.0707842
time/logging (s)                   0.0034616
time/saving (s)                    0.0023758
time/training (s)                  1.14197
time/epoch (s)                     1.50917
time/total (s)                   127.342
Epoch                             83
-----------------------------  --------------
2019-04-22 20:54:45.134914 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 84 finished
-----------------------------  --------------
replay_buffer/size             17200
trainer/QF1 Loss                   0.0478187
trainer/QF2 Loss                   0.0500291
trainer/Policy Loss                9.5021
trainer/Q1 Predictions Mean       -7.73009
trainer/Q1 Predictions Std         1.70567
trainer/Q1 Predictions Max        -6.93488
trainer/Q1 Predictions Min       -16.3852
trainer/Q2 Predictions Mean       -7.72597
trainer/Q2 Predictions Std         1.71015
trainer/Q2 Predictions Max        -6.9345
trainer/Q2 Predictions Min       -16.2986
trainer/Q Targets Mean            -7.92381
trainer/Q Targets Std              1.66052
trainer/Q Targets Max             -7.11064
trainer/Q Targets Min            -16.426
trainer/Log Pis Mean               1.98665
trainer/Log Pis Std                1.3054
trainer/Log Pis Max                5.12812
trainer/Log Pis Min               -3.59542
trainer/Policy mu Mean             0.112258
trainer/Policy mu Std              0.850642
trainer/Policy mu Max              2.53056
trainer/Policy mu Min             -2.19269
trainer/Policy log std Mean       -1.88132
trainer/Policy log std Std         0.491714
trainer/Policy log std Max        -0.432099
trainer/Policy log std Min        -2.33699
trainer/Alpha                      0.0167787
trainer/Alpha Loss                -0.0545909
exploration/num steps total    17200
exploration/num paths total      172
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.107831
exploration/Rewards Std            0.17852
exploration/Rewards Max           -0.00502503
exploration/Rewards Min           -1
exploration/Returns Mean         -10.7831
exploration/Returns Std            2.82359
exploration/Returns Max           -7.95952
exploration/Returns Min          -13.6067
exploration/Actions Mean           0.0297871
exploration/Actions Std            0.238412
exploration/Actions Max            0.999087
exploration/Actions Min           -0.97779
exploration/Num Paths              2
exploration/Average Returns      -10.7831
evaluation/num steps total     85000
evaluation/num paths total       850
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.086591
evaluation/Rewards Std             0.182967
evaluation/Rewards Max            -0.0354555
evaluation/Rewards Min            -1
evaluation/Returns Mean           -8.6591
evaluation/Returns Std             2.55872
evaluation/Returns Max            -5.57642
evaluation/Returns Min           -13.3052
evaluation/Actions Mean            0.0309806
evaluation/Actions Std             0.19239
evaluation/Actions Max             0.989821
evaluation/Actions Min            -0.989071
evaluation/Num Paths              10
evaluation/Average Returns        -8.6591
time/data storing (s)              0.00122737
time/evaluation sampling (s)       0.295199
time/exploration sampling (s)      0.0762929
time/logging (s)                   0.00369466
time/saving (s)                    0.00261266
time/training (s)                  1.10454
time/epoch (s)                     1.48357
time/total (s)                   128.83
Epoch                             84
-----------------------------  --------------
2019-04-22 20:54:46.703473 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 85 finished
-----------------------------  --------------
replay_buffer/size             17400
trainer/QF1 Loss                   0.510681
trainer/QF2 Loss                   0.510972
trainer/Policy Loss                9.33668
trainer/Q1 Predictions Mean       -7.73594
trainer/Q1 Predictions Std         1.63645
trainer/Q1 Predictions Max        -7.08029
trainer/Q1 Predictions Min       -17.0043
trainer/Q2 Predictions Mean       -7.73653
trainer/Q2 Predictions Std         1.63308
trainer/Q2 Predictions Max        -7.08981
trainer/Q2 Predictions Min       -16.9447
trainer/Q Targets Mean            -7.6422
trainer/Q Targets Std              1.77546
trainer/Q Targets Max             -0.0538626
trainer/Q Targets Min            -16.5708
trainer/Log Pis Mean               1.80446
trainer/Log Pis Std                1.18508
trainer/Log Pis Max                5.57482
trainer/Log Pis Min               -1.7497
trainer/Policy mu Mean             0.0611806
trainer/Policy mu Std              0.741948
trainer/Policy mu Max              2.73082
trainer/Policy mu Min             -2.39397
trainer/Policy log std Mean       -1.96051
trainer/Policy log std Std         0.403429
trainer/Policy log std Max        -0.596901
trainer/Policy log std Min        -2.31969
trainer/Alpha                      0.0168209
trainer/Alpha Loss                -0.798804
exploration/num steps total    17400
exploration/num paths total      174
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.119221
exploration/Rewards Std            0.205407
exploration/Rewards Max           -0.00613328
exploration/Rewards Min           -1
exploration/Returns Mean         -11.9221
exploration/Returns Std            3.73957
exploration/Returns Max           -8.18249
exploration/Returns Min          -15.6616
exploration/Actions Mean           0.0165497
exploration/Actions Std            0.246477
exploration/Actions Max            0.998398
exploration/Actions Min           -0.983353
exploration/Num Paths              2
exploration/Average Returns      -11.9221
evaluation/num steps total     86000
evaluation/num paths total       860
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0804794
evaluation/Rewards Std             0.172861
evaluation/Rewards Max            -0.0296497
evaluation/Rewards Min            -1
evaluation/Returns Mean           -8.04794
evaluation/Returns Std             2.68491
evaluation/Returns Max            -4.62523
evaluation/Returns Min           -12.7197
evaluation/Actions Mean            0.0235359
evaluation/Actions Std             0.17172
evaluation/Actions Max             0.991366
evaluation/Actions Min            -0.978812
evaluation/Num Paths              10
evaluation/Average Returns        -8.04794
time/data storing (s)              0.00124899
time/evaluation sampling (s)       0.293842
time/exploration sampling (s)      0.0703681
time/logging (s)                   0.0038944
time/saving (s)                    0.00295665
time/training (s)                  1.18976
time/epoch (s)                     1.56207
time/total (s)                   130.397
Epoch                             85
-----------------------------  --------------
2019-04-22 20:54:48.343731 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 86 finished
-----------------------------  --------------
replay_buffer/size             17600
trainer/QF1 Loss                   0.96833
trainer/QF2 Loss                   0.969737
trainer/Policy Loss                9.40352
trainer/Q1 Predictions Mean       -7.71097
trainer/Q1 Predictions Std         1.77663
trainer/Q1 Predictions Max        -6.96529
trainer/Q1 Predictions Min       -15.7905
trainer/Q2 Predictions Mean       -7.71963
trainer/Q2 Predictions Std         1.78607
trainer/Q2 Predictions Max        -6.96507
trainer/Q2 Predictions Min       -15.9593
trainer/Q Targets Mean            -7.62449
trainer/Q Targets Std              2.06202
trainer/Q Targets Max             -0.0806942
trainer/Q Targets Min            -15.8936
trainer/Log Pis Mean               1.88485
trainer/Log Pis Std                1.11658
trainer/Log Pis Max                5.04828
trainer/Log Pis Min               -1.35704
trainer/Policy mu Mean             0.0761292
trainer/Policy mu Std              0.753336
trainer/Policy mu Max              2.51267
trainer/Policy mu Min             -2.8376
trainer/Policy log std Mean       -1.9664
trainer/Policy log std Std         0.457684
trainer/Policy log std Max        -0.377084
trainer/Policy log std Min        -2.34467
trainer/Alpha                      0.0170354
trainer/Alpha Loss                -0.468961
exploration/num steps total    17600
exploration/num paths total      176
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.101135
exploration/Rewards Std            0.195755
exploration/Rewards Max           -0.00375944
exploration/Rewards Min           -1
exploration/Returns Mean         -10.1135
exploration/Returns Std            2.55755
exploration/Returns Max           -7.55592
exploration/Returns Min          -12.671
exploration/Actions Mean           0.041771
exploration/Actions Std            0.230672
exploration/Actions Max            0.993765
exploration/Actions Min           -0.473771
exploration/Num Paths              2
exploration/Average Returns      -10.1135
evaluation/num steps total     87000
evaluation/num paths total       870
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0590856
evaluation/Rewards Std             0.183499
evaluation/Rewards Max            -0.0159564
evaluation/Rewards Min            -1
evaluation/Returns Mean           -5.90856
evaluation/Returns Std             2.71509
evaluation/Returns Max            -1.93315
evaluation/Returns Min           -11.2516
evaluation/Actions Mean            0.0199529
evaluation/Actions Std             0.184882
evaluation/Actions Max             0.989686
evaluation/Actions Min            -0.993479
evaluation/Num Paths              10
evaluation/Average Returns        -5.90856
time/data storing (s)              0.00138399
time/evaluation sampling (s)       0.298694
time/exploration sampling (s)      0.0794829
time/logging (s)                   0.0035302
time/saving (s)                    0.00258675
time/training (s)                  1.24728
time/epoch (s)                     1.63295
time/total (s)                   132.034
Epoch                             86
-----------------------------  --------------
2019-04-22 20:54:49.870135 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 87 finished
-----------------------------  --------------
replay_buffer/size             17800
trainer/QF1 Loss                   0.48364
trainer/QF2 Loss                   0.484313
trainer/Policy Loss                9.84592
trainer/Q1 Predictions Mean       -7.95441
trainer/Q1 Predictions Std         2.23607
trainer/Q1 Predictions Max        -6.87189
trainer/Q1 Predictions Min       -16.715
trainer/Q2 Predictions Mean       -7.94916
trainer/Q2 Predictions Std         2.24392
trainer/Q2 Predictions Max        -6.8671
trainer/Q2 Predictions Min       -16.6845
trainer/Q Targets Mean            -7.96682
trainer/Q Targets Std              2.35498
trainer/Q Targets Max             -0.16808
trainer/Q Targets Min            -16.59
trainer/Log Pis Mean               2.13177
trainer/Log Pis Std                1.30828
trainer/Log Pis Max                5.96269
trainer/Log Pis Min               -0.176525
trainer/Policy mu Mean             0.203715
trainer/Policy mu Std              0.900319
trainer/Policy mu Max              2.64361
trainer/Policy mu Min             -2.38425
trainer/Policy log std Mean       -1.88725
trainer/Policy log std Std         0.515979
trainer/Policy log std Max        -0.447759
trainer/Policy log std Min        -2.37439
trainer/Alpha                      0.0170652
trainer/Alpha Loss                 0.536393
exploration/num steps total    17800
exploration/num paths total      178
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.118427
exploration/Rewards Std            0.15343
exploration/Rewards Max           -0.00294666
exploration/Rewards Min           -1
exploration/Returns Mean         -11.8427
exploration/Returns Std            2.58905
exploration/Returns Max           -9.25368
exploration/Returns Min          -14.4318
exploration/Actions Mean           0.0310264
exploration/Actions Std            0.214885
exploration/Actions Max            0.997316
exploration/Actions Min           -0.584253
exploration/Num Paths              2
exploration/Average Returns      -11.8427
evaluation/num steps total     88000
evaluation/num paths total       880
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.115374
evaluation/Rewards Std             0.177618
evaluation/Rewards Max            -0.0727085
evaluation/Rewards Min            -1
evaluation/Returns Mean          -11.5374
evaluation/Returns Std             1.79284
evaluation/Returns Max            -8.87699
evaluation/Returns Min           -14.1862
evaluation/Actions Mean            0.0151828
evaluation/Actions Std             0.19734
evaluation/Actions Max             0.992038
evaluation/Actions Min            -0.985531
evaluation/Num Paths              10
evaluation/Average Returns       -11.5374
time/data storing (s)              0.00131983
time/evaluation sampling (s)       0.28136
time/exploration sampling (s)      0.0715314
time/logging (s)                   0.00371183
time/saving (s)                    0.00273866
time/training (s)                  1.15936
time/epoch (s)                     1.52002
time/total (s)                   133.559
Epoch                             87
-----------------------------  --------------
2019-04-22 20:54:51.538792 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 88 finished
-----------------------------  --------------
replay_buffer/size             18000
trainer/QF1 Loss                   0.481519
trainer/QF2 Loss                   0.485772
trainer/Policy Loss                9.79159
trainer/Q1 Predictions Mean       -7.51663
trainer/Q1 Predictions Std         1.91442
trainer/Q1 Predictions Max        -6.67693
trainer/Q1 Predictions Min       -16.2829
trainer/Q2 Predictions Mean       -7.50436
trainer/Q2 Predictions Std         1.93444
trainer/Q2 Predictions Max        -6.66899
trainer/Q2 Predictions Min       -16.3996
trainer/Q Targets Mean            -7.63756
trainer/Q Targets Std              2.04025
trainer/Q Targets Max             -0.248362
trainer/Q Targets Min            -16.3524
trainer/Log Pis Mean               2.44168
trainer/Log Pis Std                1.05451
trainer/Log Pis Max                5.30976
trainer/Log Pis Min               -1.51779
trainer/Policy mu Mean             0.141279
trainer/Policy mu Std              0.823195
trainer/Policy mu Max              2.56482
trainer/Policy mu Min             -2.66475
trainer/Policy log std Mean       -2.03216
trainer/Policy log std Std         0.478683
trainer/Policy log std Max        -0.538319
trainer/Policy log std Min        -2.47125
trainer/Alpha                      0.0172663
trainer/Alpha Loss                 1.79283
exploration/num steps total    18000
exploration/num paths total      180
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.0677366
exploration/Rewards Std            0.120347
exploration/Rewards Max           -0.0059033
exploration/Rewards Min           -1
exploration/Returns Mean          -6.77366
exploration/Returns Std            1.13805
exploration/Returns Max           -5.63561
exploration/Returns Min           -7.91171
exploration/Actions Mean           0.0248947
exploration/Actions Std            0.187229
exploration/Actions Max            0.998853
exploration/Actions Min           -0.358485
exploration/Num Paths              2
exploration/Average Returns       -6.77366
evaluation/num steps total     89000
evaluation/num paths total       890
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0631269
evaluation/Rewards Std             0.186199
evaluation/Rewards Max            -0.0135897
evaluation/Rewards Min            -1
evaluation/Returns Mean           -6.31269
evaluation/Returns Std             1.90558
evaluation/Returns Max            -2.50087
evaluation/Returns Min            -8.686
evaluation/Actions Mean            0.0283333
evaluation/Actions Std             0.186663
evaluation/Actions Max             0.991514
evaluation/Actions Min            -0.97941
evaluation/Num Paths              10
evaluation/Average Returns        -6.31269
time/data storing (s)              0.00143358
time/evaluation sampling (s)       0.357162
time/exploration sampling (s)      0.102105
time/logging (s)                   0.0079766
time/saving (s)                    0.0101908
time/training (s)                  1.18685
time/epoch (s)                     1.66572
time/total (s)                   135.23
Epoch                             88
-----------------------------  --------------
2019-04-22 20:54:53.189046 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 89 finished
-----------------------------  --------------
replay_buffer/size             18200
trainer/QF1 Loss                   0.0156025
trainer/QF2 Loss                   0.0175011
trainer/Policy Loss                9.09737
trainer/Q1 Predictions Mean       -7.62004
trainer/Q1 Predictions Std         1.94243
trainer/Q1 Predictions Max        -6.78856
trainer/Q1 Predictions Min       -16.0763
trainer/Q2 Predictions Mean       -7.6281
trainer/Q2 Predictions Std         1.9557
trainer/Q2 Predictions Max        -6.80621
trainer/Q2 Predictions Min       -16.2547
trainer/Q Targets Mean            -7.65122
trainer/Q Targets Std              1.89124
trainer/Q Targets Max             -6.79475
trainer/Q Targets Min            -15.2931
trainer/Log Pis Mean               1.69089
trainer/Log Pis Std                1.50079
trainer/Log Pis Max                5.87335
trainer/Log Pis Min               -3.95279
trainer/Policy mu Mean             0.0632082
trainer/Policy mu Std              0.841731
trainer/Policy mu Max              2.71002
trainer/Policy mu Min             -2.73616
trainer/Policy log std Mean       -1.87326
trainer/Policy log std Std         0.476144
trainer/Policy log std Max        -0.334375
trainer/Policy log std Min        -2.31599
trainer/Alpha                      0.0172931
trainer/Alpha Loss                -1.25418
exploration/num steps total    18200
exploration/num paths total      182
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.105715
exploration/Rewards Std            0.180696
exploration/Rewards Max           -0.00222927
exploration/Rewards Min           -1
exploration/Returns Mean         -10.5715
exploration/Returns Std            1.40308
exploration/Returns Max           -9.1684
exploration/Returns Min          -11.9746
exploration/Actions Mean           0.0376488
exploration/Actions Std            0.243767
exploration/Actions Max            0.99872
exploration/Actions Min           -0.621573
exploration/Num Paths              2
exploration/Average Returns      -10.5715
evaluation/num steps total     90000
evaluation/num paths total       900
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0777945
evaluation/Rewards Std             0.188954
evaluation/Rewards Max            -0.022725
evaluation/Rewards Min            -1
evaluation/Returns Mean           -7.77945
evaluation/Returns Std             2.04944
evaluation/Returns Max            -3.98764
evaluation/Returns Min           -10.7129
evaluation/Actions Mean            0.0196119
evaluation/Actions Std             0.195722
evaluation/Actions Max             0.989544
evaluation/Actions Min            -0.979383
evaluation/Num Paths              10
evaluation/Average Returns        -7.77945
time/data storing (s)              0.0014953
time/evaluation sampling (s)       0.341278
time/exploration sampling (s)      0.0810277
time/logging (s)                   0.00357273
time/saving (s)                    0.00276447
time/training (s)                  1.20185
time/epoch (s)                     1.63198
time/total (s)                   136.872
Epoch                             89
-----------------------------  --------------
2019-04-22 20:54:54.853280 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 90 finished
-----------------------------  --------------
replay_buffer/size             18400
trainer/QF1 Loss                   0.0819165
trainer/QF2 Loss                   0.0816353
trainer/Policy Loss                8.66244
trainer/Q1 Predictions Mean       -7.10853
trainer/Q1 Predictions Std         1.44379
trainer/Q1 Predictions Max        -6.49469
trainer/Q1 Predictions Min       -14.4218
trainer/Q2 Predictions Mean       -7.10972
trainer/Q2 Predictions Std         1.44503
trainer/Q2 Predictions Max        -6.49465
trainer/Q2 Predictions Min       -14.4941
trainer/Q Targets Mean            -7.38039
trainer/Q Targets Std              1.47293
trainer/Q Targets Max             -6.7344
trainer/Q Targets Min            -15.1192
trainer/Log Pis Mean               1.69586
trainer/Log Pis Std                1.20228
trainer/Log Pis Max                6.22695
trainer/Log Pis Min               -2.93489
trainer/Policy mu Mean             0.0890773
trainer/Policy mu Std              0.804577
trainer/Policy mu Max              2.63631
trainer/Policy mu Min             -2.33115
trainer/Policy log std Mean       -1.85223
trainer/Policy log std Std         0.473981
trainer/Policy log std Max        -0.347217
trainer/Policy log std Min        -2.36482
trainer/Alpha                      0.0171115
trainer/Alpha Loss                -1.2372
exploration/num steps total    18400
exploration/num paths total      184
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.128892
exploration/Rewards Std            0.215374
exploration/Rewards Max           -0.00101286
exploration/Rewards Min           -1
exploration/Returns Mean         -12.8892
exploration/Returns Std            1.00783
exploration/Returns Max          -11.8813
exploration/Returns Min          -13.897
exploration/Actions Mean           0.0279653
exploration/Actions Std            0.26836
exploration/Actions Max            0.998648
exploration/Actions Min           -0.980559
exploration/Num Paths              2
exploration/Average Returns      -12.8892
evaluation/num steps total     91000
evaluation/num paths total       910
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0933808
evaluation/Rewards Std             0.171888
evaluation/Rewards Max            -0.00274962
evaluation/Rewards Min            -1
evaluation/Returns Mean           -9.33808
evaluation/Returns Std             2.39799
evaluation/Returns Max            -5.84305
evaluation/Returns Min           -13.7829
evaluation/Actions Mean            0.0220793
evaluation/Actions Std             0.184985
evaluation/Actions Max             0.990853
evaluation/Actions Min            -0.990266
evaluation/Num Paths              10
evaluation/Average Returns        -9.33808
time/data storing (s)              0.00122795
time/evaluation sampling (s)       0.305172
time/exploration sampling (s)      0.0778263
time/logging (s)                   0.00376387
time/saving (s)                    0.00281483
time/training (s)                  1.26682
time/epoch (s)                     1.65762
time/total (s)                   138.534
Epoch                             90
-----------------------------  --------------
2019-04-22 20:54:56.600931 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 91 finished
-----------------------------  --------------
replay_buffer/size             18600
trainer/QF1 Loss                   0.0131579
trainer/QF2 Loss                   0.0111815
trainer/Policy Loss                9.2459
trainer/Q1 Predictions Mean       -7.43547
trainer/Q1 Predictions Std         1.84769
trainer/Q1 Predictions Max        -6.65553
trainer/Q1 Predictions Min       -15.5017
trainer/Q2 Predictions Mean       -7.43919
trainer/Q2 Predictions Std         1.84108
trainer/Q2 Predictions Max        -6.67195
trainer/Q2 Predictions Min       -15.5152
trainer/Q Targets Mean            -7.4604
trainer/Q Targets Std              1.7802
trainer/Q Targets Max             -6.6881
trainer/Q Targets Min            -15.3806
trainer/Log Pis Mean               1.96816
trainer/Log Pis Std                1.10064
trainer/Log Pis Max                5.05003
trainer/Log Pis Min               -0.394769
trainer/Policy mu Mean             0.0848847
trainer/Policy mu Std              0.787157
trainer/Policy mu Max              2.52176
trainer/Policy mu Min             -2.40337
trainer/Policy log std Mean       -1.91106
trainer/Policy log std Std         0.464808
trainer/Policy log std Max        -0.578901
trainer/Policy log std Min        -2.40241
trainer/Alpha                      0.0165703
trainer/Alpha Loss                -0.130561
exploration/num steps total    18600
exploration/num paths total      186
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.0854036
exploration/Rewards Std            0.146497
exploration/Rewards Max           -0.00064405
exploration/Rewards Min           -1
exploration/Returns Mean          -8.54036
exploration/Returns Std            2.0291
exploration/Returns Max           -6.51125
exploration/Returns Min          -10.5695
exploration/Actions Mean           0.00237936
exploration/Actions Std            0.240318
exploration/Actions Max            0.976801
exploration/Actions Min           -0.983741
exploration/Num Paths              2
exploration/Average Returns       -8.54036
evaluation/num steps total     92000
evaluation/num paths total       920
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0511846
evaluation/Rewards Std             0.185577
evaluation/Rewards Max            -0.00880641
evaluation/Rewards Min            -1
evaluation/Returns Mean           -5.11846
evaluation/Returns Std             2.60054
evaluation/Returns Max            -1.77204
evaluation/Returns Min            -9.84596
evaluation/Actions Mean            0.0153615
evaluation/Actions Std             0.186991
evaluation/Actions Max             0.988773
evaluation/Actions Min            -0.991629
evaluation/Num Paths              10
evaluation/Average Returns        -5.11846
time/data storing (s)              0.00124475
time/evaluation sampling (s)       0.31025
time/exploration sampling (s)      0.0739313
time/logging (s)                   0.003505
time/saving (s)                    0.00238123
time/training (s)                  1.34823
time/epoch (s)                     1.73954
time/total (s)                   140.279
Epoch                             91
-----------------------------  --------------
2019-04-22 20:54:58.074691 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 92 finished
-----------------------------  --------------
replay_buffer/size             18800
trainer/QF1 Loss                   0.871645
trainer/QF2 Loss                   0.879163
trainer/Policy Loss                9.41452
trainer/Q1 Predictions Mean       -7.37363
trainer/Q1 Predictions Std         1.96024
trainer/Q1 Predictions Max        -6.50464
trainer/Q1 Predictions Min       -15.2923
trainer/Q2 Predictions Mean       -7.3622
trainer/Q2 Predictions Std         1.94136
trainer/Q2 Predictions Max        -6.49974
trainer/Q2 Predictions Min       -15.2896
trainer/Q Targets Mean            -7.3956
trainer/Q Targets Std              2.24357
trainer/Q Targets Max             -0.101324
trainer/Q Targets Min            -15.7948
trainer/Log Pis Mean               2.20634
trainer/Log Pis Std                1.17718
trainer/Log Pis Max                6.46456
trainer/Log Pis Min               -0.538297
trainer/Policy mu Mean             0.0505097
trainer/Policy mu Std              0.848019
trainer/Policy mu Max              2.62519
trainer/Policy mu Min             -2.39484
trainer/Policy log std Mean       -1.96507
trainer/Policy log std Std         0.550666
trainer/Policy log std Max        -0.342666
trainer/Policy log std Min        -2.48807
trainer/Alpha                      0.0164313
trainer/Alpha Loss                 0.847788
exploration/num steps total    18800
exploration/num paths total      188
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.124737
exploration/Rewards Std            0.195247
exploration/Rewards Max           -0.0112651
exploration/Rewards Min           -1
exploration/Returns Mean         -12.4737
exploration/Returns Std            3.7244
exploration/Returns Max           -8.74925
exploration/Returns Min          -16.1981
exploration/Actions Mean           0.0215045
exploration/Actions Std            0.250226
exploration/Actions Max            0.99659
exploration/Actions Min           -0.979124
exploration/Num Paths              2
exploration/Average Returns      -12.4737
evaluation/num steps total     93000
evaluation/num paths total       930
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0938923
evaluation/Rewards Std             0.156846
evaluation/Rewards Max            -0.0195481
evaluation/Rewards Min            -1
evaluation/Returns Mean           -9.38923
evaluation/Returns Std             1.24842
evaluation/Returns Max            -7.31942
evaluation/Returns Min           -10.4996
evaluation/Actions Mean            0.02158
evaluation/Actions Std             0.178679
evaluation/Actions Max             0.993367
evaluation/Actions Min            -0.991192
evaluation/Num Paths              10
evaluation/Average Returns        -9.38923
time/data storing (s)              0.00126585
time/evaluation sampling (s)       0.292459
time/exploration sampling (s)      0.0760227
time/logging (s)                   0.00352049
time/saving (s)                    0.00238955
time/training (s)                  1.09119
time/epoch (s)                     1.46685
time/total (s)                   141.75
Epoch                             92
-----------------------------  --------------
2019-04-22 20:54:59.542632 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 93 finished
-----------------------------  --------------
replay_buffer/size             19000
trainer/QF1 Loss                   0.0286054
trainer/QF2 Loss                   0.0274545
trainer/Policy Loss                9.77642
trainer/Q1 Predictions Mean       -7.61454
trainer/Q1 Predictions Std         2.13521
trainer/Q1 Predictions Max        -6.55042
trainer/Q1 Predictions Min       -14.5963
trainer/Q2 Predictions Mean       -7.61324
trainer/Q2 Predictions Std         2.14079
trainer/Q2 Predictions Max        -6.54064
trainer/Q2 Predictions Min       -14.7512
trainer/Q Targets Mean            -7.70042
trainer/Q Targets Std              2.25425
trainer/Q Targets Max             -6.5707
trainer/Q Targets Min            -15.2113
trainer/Log Pis Mean               2.35982
trainer/Log Pis Std                1.05544
trainer/Log Pis Max                5.2535
trainer/Log Pis Min               -1.49074
trainer/Policy mu Mean             0.092068
trainer/Policy mu Std              0.913138
trainer/Policy mu Max              2.66394
trainer/Policy mu Min             -2.86002
trainer/Policy log std Mean       -1.94198
trainer/Policy log std Std         0.561946
trainer/Policy log std Max        -0.395097
trainer/Policy log std Min        -2.47466
trainer/Alpha                      0.0170194
trainer/Alpha Loss                 1.46577
exploration/num steps total    19000
exploration/num paths total      190
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.0663768
exploration/Rewards Std            0.0857795
exploration/Rewards Max           -0.00259089
exploration/Rewards Min           -1
exploration/Returns Mean          -6.63768
exploration/Returns Std            1.13275
exploration/Returns Max           -5.50492
exploration/Returns Min           -7.77043
exploration/Actions Mean           0.00727279
exploration/Actions Std            0.171279
exploration/Actions Max            0.991778
exploration/Actions Min           -0.611164
exploration/Num Paths              2
exploration/Average Returns       -6.63768
evaluation/num steps total     94000
evaluation/num paths total       940
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0714938
evaluation/Rewards Std             0.165516
evaluation/Rewards Max            -0.0132415
evaluation/Rewards Min            -1
evaluation/Returns Mean           -7.14938
evaluation/Returns Std             2.58004
evaluation/Returns Max            -4.13419
evaluation/Returns Min           -11.9544
evaluation/Actions Mean            0.0218808
evaluation/Actions Std             0.179923
evaluation/Actions Max             0.990412
evaluation/Actions Min            -0.99062
evaluation/Num Paths              10
evaluation/Average Returns        -7.14938
time/data storing (s)              0.00127561
time/evaluation sampling (s)       0.28159
time/exploration sampling (s)      0.0704064
time/logging (s)                   0.00334623
time/saving (s)                    0.00206772
time/training (s)                  1.10244
time/epoch (s)                     1.46113
time/total (s)                   143.216
Epoch                             93
-----------------------------  --------------
2019-04-22 20:55:01.134499 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 94 finished
-----------------------------  --------------
replay_buffer/size             19200
trainer/QF1 Loss                   0.855814
trainer/QF2 Loss                   0.860846
trainer/Policy Loss                8.82184
trainer/Q1 Predictions Mean       -6.94441
trainer/Q1 Predictions Std         1.28126
trainer/Q1 Predictions Max        -6.39643
trainer/Q1 Predictions Min       -15.8594
trainer/Q2 Predictions Mean       -6.93978
trainer/Q2 Predictions Std         1.29307
trainer/Q2 Predictions Max        -6.37713
trainer/Q2 Predictions Min       -15.9861
trainer/Q Targets Mean            -6.93248
trainer/Q Targets Std              1.59409
trainer/Q Targets Max             -0.237702
trainer/Q Targets Min            -16.1347
trainer/Log Pis Mean               2.07306
trainer/Log Pis Std                1.12363
trainer/Log Pis Max                4.86216
trainer/Log Pis Min               -2.45062
trainer/Policy mu Mean            -0.0337421
trainer/Policy mu Std              0.827225
trainer/Policy mu Max              2.59189
trainer/Policy mu Min             -2.25047
trainer/Policy log std Mean       -1.92547
trainer/Policy log std Std         0.512516
trainer/Policy log std Max        -0.433562
trainer/Policy log std Min        -2.46969
trainer/Alpha                      0.0174494
trainer/Alpha Loss                 0.295764
exploration/num steps total    19200
exploration/num paths total      192
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.113933
exploration/Rewards Std            0.139986
exploration/Rewards Max           -0.00382514
exploration/Rewards Min           -1
exploration/Returns Mean         -11.3933
exploration/Returns Std            1.80296
exploration/Returns Max           -9.59038
exploration/Returns Min          -13.1963
exploration/Actions Mean           0.017349
exploration/Actions Std            0.210078
exploration/Actions Max            0.998721
exploration/Actions Min           -0.954898
exploration/Num Paths              2
exploration/Average Returns      -11.3933
evaluation/num steps total     95000
evaluation/num paths total       950
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.123087
evaluation/Rewards Std             0.189905
evaluation/Rewards Max            -0.0171707
evaluation/Rewards Min            -1
evaluation/Returns Mean          -12.3087
evaluation/Returns Std             1.82838
evaluation/Returns Max           -10.0823
evaluation/Returns Min           -15.6034
evaluation/Actions Mean            0.0108882
evaluation/Actions Std             0.200188
evaluation/Actions Max             0.989905
evaluation/Actions Min            -0.991348
evaluation/Num Paths              10
evaluation/Average Returns       -12.3087
time/data storing (s)              0.00148183
time/evaluation sampling (s)       0.313391
time/exploration sampling (s)      0.126215
time/logging (s)                   0.0034948
time/saving (s)                    0.00241491
time/training (s)                  1.1386
time/epoch (s)                     1.5856
time/total (s)                   144.806
Epoch                             94
-----------------------------  --------------
2019-04-22 20:55:02.621250 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 95 finished
-----------------------------  --------------
replay_buffer/size             19400
trainer/QF1 Loss                   0.412969
trainer/QF2 Loss                   0.414632
trainer/Policy Loss                9.24546
trainer/Q1 Predictions Mean       -7.23106
trainer/Q1 Predictions Std         1.77768
trainer/Q1 Predictions Max        -6.40814
trainer/Q1 Predictions Min       -15.4137
trainer/Q2 Predictions Mean       -7.22784
trainer/Q2 Predictions Std         1.77363
trainer/Q2 Predictions Max        -6.42148
trainer/Q2 Predictions Min       -15.3904
trainer/Q Targets Mean            -7.20164
trainer/Q Targets Std              1.89331
trainer/Q Targets Max             -0.123042
trainer/Q Targets Min            -15.071
trainer/Log Pis Mean               2.18509
trainer/Log Pis Std                1.20665
trainer/Log Pis Max                5.99723
trainer/Log Pis Min               -1.81652
trainer/Policy mu Mean             0.101507
trainer/Policy mu Std              0.8554
trainer/Policy mu Max              2.61759
trainer/Policy mu Min             -2.23438
trainer/Policy log std Mean       -1.88288
trainer/Policy log std Std         0.515125
trainer/Policy log std Max        -0.487012
trainer/Policy log std Min        -2.3882
trainer/Alpha                      0.0175961
trainer/Alpha Loss                 0.747776
exploration/num steps total    19400
exploration/num paths total      194
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.0812651
exploration/Rewards Std            0.0849317
exploration/Rewards Max           -0.00487996
exploration/Rewards Min           -1
exploration/Returns Mean          -8.12651
exploration/Returns Std            0.464002
exploration/Returns Max           -7.66251
exploration/Returns Min           -8.59051
exploration/Actions Mean           0.0027586
exploration/Actions Std            0.198825
exploration/Actions Max            0.986342
exploration/Actions Min           -0.983946
exploration/Num Paths              2
exploration/Average Returns       -8.12651
evaluation/num steps total     96000
evaluation/num paths total       960
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0908363
evaluation/Rewards Std             0.148273
evaluation/Rewards Max            -0.0515275
evaluation/Rewards Min            -1
evaluation/Returns Mean           -9.08363
evaluation/Returns Std             1.50099
evaluation/Returns Max            -7.13651
evaluation/Returns Min           -11.3165
evaluation/Actions Mean            0.0166918
evaluation/Actions Std             0.169475
evaluation/Actions Max             0.993075
evaluation/Actions Min            -0.979453
evaluation/Num Paths              10
evaluation/Average Returns        -9.08363
time/data storing (s)              0.00142064
time/evaluation sampling (s)       0.28996
time/exploration sampling (s)      0.074347
time/logging (s)                   0.00352848
time/saving (s)                    0.00242531
time/training (s)                  1.10895
time/epoch (s)                     1.48063
time/total (s)                   146.291
Epoch                             95
-----------------------------  --------------
2019-04-22 20:55:04.146874 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 96 finished
-----------------------------  --------------
replay_buffer/size             19600
trainer/QF1 Loss                   0.00466851
trainer/QF2 Loss                   0.00459412
trainer/Policy Loss                9.00255
trainer/Q1 Predictions Mean       -6.94504
trainer/Q1 Predictions Std         1.43854
trainer/Q1 Predictions Max        -6.36022
trainer/Q1 Predictions Min       -14.7708
trainer/Q2 Predictions Mean       -6.93832
trainer/Q2 Predictions Std         1.43806
trainer/Q2 Predictions Max        -6.36189
trainer/Q2 Predictions Min       -14.7097
trainer/Q Targets Mean            -6.96313
trainer/Q Targets Std              1.41129
trainer/Q Targets Max             -6.37964
trainer/Q Targets Min            -14.5876
trainer/Log Pis Mean               2.20515
trainer/Log Pis Std                1.24896
trainer/Log Pis Max                5.70467
trainer/Log Pis Min               -1.29196
trainer/Policy mu Mean             0.05994
trainer/Policy mu Std              0.814744
trainer/Policy mu Max              2.78291
trainer/Policy mu Min             -2.02456
trainer/Policy log std Mean       -2.0065
trainer/Policy log std Std         0.5025
trainer/Policy log std Max        -0.467035
trainer/Policy log std Min        -2.4085
trainer/Alpha                      0.0174792
trainer/Alpha Loss                 0.8302
exploration/num steps total    19600
exploration/num paths total      196
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.106592
exploration/Rewards Std            0.207632
exploration/Rewards Max           -0.00358335
exploration/Rewards Min           -1
exploration/Returns Mean         -10.6592
exploration/Returns Std            0.592343
exploration/Returns Max          -10.0669
exploration/Returns Min          -11.2515
exploration/Actions Mean           0.0499594
exploration/Actions Std            0.251017
exploration/Actions Max            0.997637
exploration/Actions Min           -0.464035
exploration/Num Paths              2
exploration/Average Returns      -10.6592
evaluation/num steps total     97000
evaluation/num paths total       970
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0391903
evaluation/Rewards Std             0.124303
evaluation/Rewards Max            -0.0159935
evaluation/Rewards Min            -1
evaluation/Returns Mean           -3.91903
evaluation/Returns Std             1.23482
evaluation/Returns Max            -2.06984
evaluation/Returns Min            -5.87003
evaluation/Actions Mean            0.0221012
evaluation/Actions Std             0.153016
evaluation/Actions Max             0.988536
evaluation/Actions Min            -0.986184
evaluation/Num Paths              10
evaluation/Average Returns        -3.91903
time/data storing (s)              0.00124989
time/evaluation sampling (s)       0.29926
time/exploration sampling (s)      0.0868513
time/logging (s)                   0.00317973
time/saving (s)                    0.00237753
time/training (s)                  1.12615
time/epoch (s)                     1.51907
time/total (s)                   147.814
Epoch                             96
-----------------------------  --------------
2019-04-22 20:55:05.650428 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 97 finished
-----------------------------  --------------
replay_buffer/size             19800
trainer/QF1 Loss                   0.404289
trainer/QF2 Loss                   0.405935
trainer/Policy Loss                8.6756
trainer/Q1 Predictions Mean       -6.76531
trainer/Q1 Predictions Std         1.24044
trainer/Q1 Predictions Max        -6.24812
trainer/Q1 Predictions Min       -13.7589
trainer/Q2 Predictions Mean       -6.7697
trainer/Q2 Predictions Std         1.2326
trainer/Q2 Predictions Max        -6.26186
trainer/Q2 Predictions Min       -13.8382
trainer/Q Targets Mean            -6.78629
trainer/Q Targets Std              1.40541
trainer/Q Targets Max             -0.0538626
trainer/Q Targets Min            -13.7916
trainer/Log Pis Mean               2.031
trainer/Log Pis Std                1.2803
trainer/Log Pis Max                6.30893
trainer/Log Pis Min               -1.84387
trainer/Policy mu Mean             0.0112358
trainer/Policy mu Std              0.777679
trainer/Policy mu Max              2.62127
trainer/Policy mu Min             -2.63075
trainer/Policy log std Mean       -2.01565
trainer/Policy log std Std         0.490577
trainer/Policy log std Max        -0.459855
trainer/Policy log std Min        -2.45523
trainer/Alpha                      0.0176162
trainer/Alpha Loss                 0.125214
exploration/num steps total    19800
exploration/num paths total      198
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.143142
exploration/Rewards Std            0.25102
exploration/Rewards Max           -0.00832073
exploration/Rewards Min           -1
exploration/Returns Mean         -14.3142
exploration/Returns Std            1.37828
exploration/Returns Max          -12.9359
exploration/Returns Min          -15.6925
exploration/Actions Mean           0.0662185
exploration/Actions Std            0.267238
exploration/Actions Max            0.996536
exploration/Actions Min           -0.406532
exploration/Num Paths              2
exploration/Average Returns      -14.3142
evaluation/num steps total     98000
evaluation/num paths total       980
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.101832
evaluation/Rewards Std             0.212528
evaluation/Rewards Max            -0.0392493
evaluation/Rewards Min            -1
evaluation/Returns Mean          -10.1832
evaluation/Returns Std             2.80125
evaluation/Returns Max            -4.95176
evaluation/Returns Min           -13.1489
evaluation/Actions Mean            0.0302144
evaluation/Actions Std             0.214012
evaluation/Actions Max             0.9903
evaluation/Actions Min            -0.965764
evaluation/Num Paths              10
evaluation/Average Returns       -10.1832
time/data storing (s)              0.00139328
time/evaluation sampling (s)       0.281448
time/exploration sampling (s)      0.0723575
time/logging (s)                   0.00367073
time/saving (s)                    0.00236238
time/training (s)                  1.13651
time/epoch (s)                     1.49774
time/total (s)                   149.316
Epoch                             97
-----------------------------  --------------
2019-04-22 20:55:07.149960 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 98 finished
-----------------------------  --------------
replay_buffer/size             20000
trainer/QF1 Loss                   0.424
trainer/QF2 Loss                   0.431928
trainer/Policy Loss                8.47547
trainer/Q1 Predictions Mean       -6.78942
trainer/Q1 Predictions Std         0.961553
trainer/Q1 Predictions Max        -6.39655
trainer/Q1 Predictions Min       -14.1453
trainer/Q2 Predictions Mean       -6.80344
trainer/Q2 Predictions Std         0.951728
trainer/Q2 Predictions Max        -6.39669
trainer/Q2 Predictions Min       -14.1106
trainer/Q Targets Mean            -6.60997
trainer/Q Targets Std              1.15021
trainer/Q Targets Max             -0.123042
trainer/Q Targets Min            -13.8317
trainer/Log Pis Mean               1.81703
trainer/Log Pis Std                1.27172
trainer/Log Pis Max                5.32428
trainer/Log Pis Min               -2.65761
trainer/Policy mu Mean             0.111391
trainer/Policy mu Std              0.705501
trainer/Policy mu Max              2.62151
trainer/Policy mu Min             -2.13726
trainer/Policy log std Mean       -1.97129
trainer/Policy log std Std         0.408889
trainer/Policy log std Max        -0.558597
trainer/Policy log std Min        -2.38037
trainer/Alpha                      0.0177875
trainer/Alpha Loss                -0.7372
exploration/num steps total    20000
exploration/num paths total      200
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.0802676
exploration/Rewards Std            0.141876
exploration/Rewards Max           -0.00364647
exploration/Rewards Min           -1
exploration/Returns Mean          -8.02676
exploration/Returns Std            2.23352
exploration/Returns Max           -5.79324
exploration/Returns Min          -10.2603
exploration/Actions Mean           0.015897
exploration/Actions Std            0.198044
exploration/Actions Max            0.992326
exploration/Actions Min           -0.917164
exploration/Num Paths              2
exploration/Average Returns       -8.02676
evaluation/num steps total     99000
evaluation/num paths total       990
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.061637
evaluation/Rewards Std             0.189905
evaluation/Rewards Max            -0.00919393
evaluation/Rewards Min            -1
evaluation/Returns Mean           -6.1637
evaluation/Returns Std             2.7768
evaluation/Returns Max            -1.94935
evaluation/Returns Min           -11.1889
evaluation/Actions Mean            0.0210126
evaluation/Actions Std             0.189943
evaluation/Actions Max             0.992526
evaluation/Actions Min            -0.992727
evaluation/Num Paths              10
evaluation/Average Returns        -6.1637
time/data storing (s)              0.00127182
time/evaluation sampling (s)       0.280562
time/exploration sampling (s)      0.0691914
time/logging (s)                   0.00338438
time/saving (s)                    0.00245127
time/training (s)                  1.13601
time/epoch (s)                     1.49287
time/total (s)                   150.814
Epoch                             98
-----------------------------  --------------
2019-04-22 20:55:08.672147 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 99 finished
-----------------------------  ---------------
replay_buffer/size              20200
trainer/QF1 Loss                    0.0149193
trainer/QF2 Loss                    0.0164006
trainer/Policy Loss                 8.47723
trainer/Q1 Predictions Mean        -6.91532
trainer/Q1 Predictions Std          1.43154
trainer/Q1 Predictions Max         -6.31703
trainer/Q1 Predictions Min        -14.6883
trainer/Q2 Predictions Mean        -6.91324
trainer/Q2 Predictions Std          1.42594
trainer/Q2 Predictions Max         -6.32012
trainer/Q2 Predictions Min        -14.6185
trainer/Q Targets Mean             -6.85784
trainer/Q Targets Std               1.50443
trainer/Q Targets Max              -6.20738
trainer/Q Targets Min             -14.8324
trainer/Log Pis Mean                1.70688
trainer/Log Pis Std                 1.39654
trainer/Log Pis Max                 4.5732
trainer/Log Pis Min                -3.47364
trainer/Policy mu Mean              0.0859894
trainer/Policy mu Std               0.807001
trainer/Policy mu Max               2.48482
trainer/Policy mu Min              -2.61813
trainer/Policy log std Mean        -1.89806
trainer/Policy log std Std          0.475093
trainer/Policy log std Max         -0.50418
trainer/Policy log std Min         -2.37134
trainer/Alpha                       0.0170689
trainer/Alpha Loss                 -1.19308
exploration/num steps total     20200
exploration/num paths total       202
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.126721
exploration/Rewards Std             0.23573
exploration/Rewards Max            -0.00421167
exploration/Rewards Min            -1
exploration/Returns Mean          -12.6721
exploration/Returns Std             0.162686
exploration/Returns Max           -12.5094
exploration/Returns Min           -12.8348
exploration/Actions Mean            0.023448
exploration/Actions Std             0.280444
exploration/Actions Max             0.997533
exploration/Actions Min            -0.956664
exploration/Num Paths               2
exploration/Average Returns       -12.6721
evaluation/num steps total     100000
evaluation/num paths total       1000
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.073457
evaluation/Rewards Std              0.204748
evaluation/Rewards Max             -0.0105929
evaluation/Rewards Min             -1
evaluation/Returns Mean            -7.3457
evaluation/Returns Std              2.20691
evaluation/Returns Max             -2.86261
evaluation/Returns Min            -10.7045
evaluation/Actions Mean             0.0282724
evaluation/Actions Std              0.198093
evaluation/Actions Max              0.989713
evaluation/Actions Min             -0.991549
evaluation/Num Paths               10
evaluation/Average Returns         -7.3457
time/data storing (s)               0.00126457
time/evaluation sampling (s)        0.308016
time/exploration sampling (s)       0.07712
time/logging (s)                    0.00372493
time/saving (s)                     0.00240614
time/training (s)                   1.12364
time/epoch (s)                      1.51617
time/total (s)                    152.334
Epoch                              99
-----------------------------  ---------------
2019-04-22 20:55:10.162517 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 100 finished
-----------------------------  ---------------
replay_buffer/size              20400
trainer/QF1 Loss                    1.44695
trainer/QF2 Loss                    1.45997
trainer/Policy Loss                 8.83305
trainer/Q1 Predictions Mean        -6.97084
trainer/Q1 Predictions Std          1.88424
trainer/Q1 Predictions Max         -6.11514
trainer/Q1 Predictions Min        -14.9691
trainer/Q2 Predictions Mean        -6.97007
trainer/Q2 Predictions Std          1.88306
trainer/Q2 Predictions Max         -6.11179
trainer/Q2 Predictions Min        -15.119
trainer/Q Targets Mean             -6.90694
trainer/Q Targets Std               2.07919
trainer/Q Targets Max              -0.0221559
trainer/Q Targets Min             -15.7052
trainer/Log Pis Mean                2.08373
trainer/Log Pis Std                 1.11936
trainer/Log Pis Max                 5.35988
trainer/Log Pis Min                -0.655717
trainer/Policy mu Mean              0.11021
trainer/Policy mu Std               0.838385
trainer/Policy mu Max               2.65824
trainer/Policy mu Min              -2.408
trainer/Policy log std Mean        -1.95628
trainer/Policy log std Std          0.536171
trainer/Policy log std Max         -0.474251
trainer/Policy log std Min         -2.49014
trainer/Alpha                       0.0166802
trainer/Alpha Loss                  0.34274
exploration/num steps total     20400
exploration/num paths total       204
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.105914
exploration/Rewards Std             0.18996
exploration/Rewards Max            -0.00236141
exploration/Rewards Min            -1
exploration/Returns Mean          -10.5914
exploration/Returns Std             1.63158
exploration/Returns Max            -8.95982
exploration/Returns Min           -12.223
exploration/Actions Mean            0.0249325
exploration/Actions Std             0.251886
exploration/Actions Max             0.997903
exploration/Actions Min            -0.928943
exploration/Num Paths               2
exploration/Average Returns       -10.5914
evaluation/num steps total     101000
evaluation/num paths total       1010
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0835608
evaluation/Rewards Std              0.192066
evaluation/Rewards Max             -0.0260517
evaluation/Rewards Min             -1
evaluation/Returns Mean            -8.35608
evaluation/Returns Std              1.44628
evaluation/Returns Max             -5.5868
evaluation/Returns Min            -10.4331
evaluation/Actions Mean             0.0222963
evaluation/Actions Std              0.195007
evaluation/Actions Max              0.992368
evaluation/Actions Min             -0.993389
evaluation/Num Paths               10
evaluation/Average Returns         -8.35608
time/data storing (s)               0.00131287
time/evaluation sampling (s)        0.300394
time/exploration sampling (s)       0.0757964
time/logging (s)                    0.00365345
time/saving (s)                     0.00244613
time/training (s)                   1.10047
time/epoch (s)                      1.48407
time/total (s)                    153.823
Epoch                             100
-----------------------------  ---------------
2019-04-22 20:55:11.641251 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 101 finished
-----------------------------  ---------------
replay_buffer/size              20600
trainer/QF1 Loss                    0.377909
trainer/QF2 Loss                    0.373958
trainer/Policy Loss                 9.2825
trainer/Q1 Predictions Mean        -7.23443
trainer/Q1 Predictions Std          2.06588
trainer/Q1 Predictions Max         -6.13435
trainer/Q1 Predictions Min        -15.0392
trainer/Q2 Predictions Mean        -7.23599
trainer/Q2 Predictions Std          2.06919
trainer/Q2 Predictions Max         -6.13981
trainer/Q2 Predictions Min        -14.9803
trainer/Q Targets Mean             -7.20345
trainer/Q Targets Std               2.21854
trainer/Q Targets Max              -0.229094
trainer/Q Targets Min             -15.2369
trainer/Log Pis Mean                2.23231
trainer/Log Pis Std                 1.16752
trainer/Log Pis Max                 5.48604
trainer/Log Pis Min                -1.52141
trainer/Policy mu Mean              0.217586
trainer/Policy mu Std               0.967708
trainer/Policy mu Max               2.65854
trainer/Policy mu Min              -2.86935
trainer/Policy log std Mean        -1.81184
trainer/Policy log std Std          0.568202
trainer/Policy log std Max         -0.46706
trainer/Policy log std Min         -2.37826
trainer/Alpha                       0.0169742
trainer/Alpha Loss                  0.946895
exploration/num steps total     20600
exploration/num paths total       206
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.123627
exploration/Rewards Std             0.235233
exploration/Rewards Max            -0.00363295
exploration/Rewards Min            -1
exploration/Returns Mean          -12.3627
exploration/Returns Std             1.45919
exploration/Returns Max           -10.9035
exploration/Returns Min           -13.8219
exploration/Actions Mean            0.0414039
exploration/Actions Std             0.24592
exploration/Actions Max             0.997569
exploration/Actions Min            -0.70392
exploration/Num Paths               2
exploration/Average Returns       -12.3627
evaluation/num steps total     102000
evaluation/num paths total       1020
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0636652
evaluation/Rewards Std              0.179918
evaluation/Rewards Max             -0.0173813
evaluation/Rewards Min             -1
evaluation/Returns Mean            -6.36652
evaluation/Returns Std              2.43656
evaluation/Returns Max             -2.5154
evaluation/Returns Min            -10.6753
evaluation/Actions Mean             0.030151
evaluation/Actions Std              0.181599
evaluation/Actions Max              0.987899
evaluation/Actions Min             -0.969144
evaluation/Num Paths               10
evaluation/Average Returns         -6.36652
time/data storing (s)               0.00128758
time/evaluation sampling (s)        0.286421
time/exploration sampling (s)       0.0716178
time/logging (s)                    0.00410536
time/saving (s)                     0.0180074
time/training (s)                   1.09127
time/epoch (s)                      1.4727
time/total (s)                    155.299
Epoch                             101
-----------------------------  ---------------
2019-04-22 20:55:13.147856 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 102 finished
-----------------------------  ---------------
replay_buffer/size              20800
trainer/QF1 Loss                    0.747621
trainer/QF2 Loss                    0.743055
trainer/Policy Loss                 8.39871
trainer/Q1 Predictions Mean        -6.619
trainer/Q1 Predictions Std          1.47187
trainer/Q1 Predictions Max         -5.96039
trainer/Q1 Predictions Min        -12.6272
trainer/Q2 Predictions Mean        -6.62171
trainer/Q2 Predictions Std          1.47081
trainer/Q2 Predictions Max         -5.96361
trainer/Q2 Predictions Min        -12.6774
trainer/Q Targets Mean             -6.64243
trainer/Q Targets Std               1.77629
trainer/Q Targets Max              -0.0160481
trainer/Q Targets Min             -12.9603
trainer/Log Pis Mean                1.91145
trainer/Log Pis Std                 1.29682
trainer/Log Pis Max                 4.47544
trainer/Log Pis Min                -2.41926
trainer/Policy mu Mean              0.132085
trainer/Policy mu Std               0.82773
trainer/Policy mu Max               2.55555
trainer/Policy mu Min              -2.88273
trainer/Policy log std Mean        -1.94995
trainer/Policy log std Std          0.518971
trainer/Policy log std Max         -0.363421
trainer/Policy log std Min         -2.40318
trainer/Alpha                       0.0167923
trainer/Alpha Loss                 -0.361876
exploration/num steps total     20800
exploration/num paths total       208
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.0989433
exploration/Rewards Std             0.167893
exploration/Rewards Max            -0.00406514
exploration/Rewards Min            -1
exploration/Returns Mean           -9.89433
exploration/Returns Std             2.86203
exploration/Returns Max            -7.03229
exploration/Returns Min           -12.7564
exploration/Actions Mean            0.00743679
exploration/Actions Std             0.218811
exploration/Actions Max             0.995132
exploration/Actions Min            -0.931514
exploration/Num Paths               2
exploration/Average Returns        -9.89433
evaluation/num steps total     103000
evaluation/num paths total       1030
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0883056
evaluation/Rewards Std              0.18631
evaluation/Rewards Max             -0.0212877
evaluation/Rewards Min             -1
evaluation/Returns Mean            -8.83056
evaluation/Returns Std              2.54979
evaluation/Returns Max             -4.60909
evaluation/Returns Min            -12.4582
evaluation/Actions Mean             0.0259917
evaluation/Actions Std              0.188712
evaluation/Actions Max              0.988713
evaluation/Actions Min             -0.992824
evaluation/Num Paths               10
evaluation/Average Returns         -8.83056
time/data storing (s)               0.00131785
time/evaluation sampling (s)        0.306142
time/exploration sampling (s)       0.0774833
time/logging (s)                    0.00337226
time/saving (s)                     0.00245619
time/training (s)                   1.10797
time/epoch (s)                      1.49874
time/total (s)                    156.803
Epoch                             102
-----------------------------  ---------------
2019-04-22 20:55:14.620956 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 103 finished
-----------------------------  ---------------
replay_buffer/size              21000
trainer/QF1 Loss                    0.378737
trainer/QF2 Loss                    0.379647
trainer/Policy Loss                 8.56171
trainer/Q1 Predictions Mean        -6.72301
trainer/Q1 Predictions Std          1.88151
trainer/Q1 Predictions Max         -5.95692
trainer/Q1 Predictions Min        -15.3158
trainer/Q2 Predictions Mean        -6.72692
trainer/Q2 Predictions Std          1.86839
trainer/Q2 Predictions Max         -5.96344
trainer/Q2 Predictions Min        -15.362
trainer/Q Targets Mean             -6.7359
trainer/Q Targets Std               1.9717
trainer/Q Targets Max              -0.288207
trainer/Q Targets Min             -15.3363
trainer/Log Pis Mean                2.01013
trainer/Log Pis Std                 1.34344
trainer/Log Pis Max                 4.75649
trainer/Log Pis Min                -4.00988
trainer/Policy mu Mean              0.130205
trainer/Policy mu Std               0.774835
trainer/Policy mu Max               2.63347
trainer/Policy mu Min              -1.61018
trainer/Policy log std Mean        -1.94996
trainer/Policy log std Std          0.496858
trainer/Policy log std Max         -0.365982
trainer/Policy log std Min         -2.40221
trainer/Alpha                       0.0169467
trainer/Alpha Loss                  0.041309
exploration/num steps total     21000
exploration/num paths total       210
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.0980968
exploration/Rewards Std             0.18298
exploration/Rewards Max            -0.00299252
exploration/Rewards Min            -1
exploration/Returns Mean           -9.80968
exploration/Returns Std             0.560487
exploration/Returns Max            -9.24919
exploration/Returns Min           -10.3702
exploration/Actions Mean            0.0345862
exploration/Actions Std             0.22949
exploration/Actions Max             0.998268
exploration/Actions Min            -0.530426
exploration/Num Paths               2
exploration/Average Returns        -9.80968
evaluation/num steps total     104000
evaluation/num paths total       1040
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0753973
evaluation/Rewards Std              0.199917
evaluation/Rewards Max             -0.0276973
evaluation/Rewards Min             -1
evaluation/Returns Mean            -7.53973
evaluation/Returns Std              2.57453
evaluation/Returns Max             -3.07663
evaluation/Returns Min            -12.0032
evaluation/Actions Mean             0.0263336
evaluation/Actions Std              0.200007
evaluation/Actions Max              0.988985
evaluation/Actions Min             -0.973688
evaluation/Num Paths               10
evaluation/Average Returns         -7.53973
time/data storing (s)               0.00130984
time/evaluation sampling (s)        0.293672
time/exploration sampling (s)       0.0768274
time/logging (s)                    0.00348668
time/saving (s)                     0.00223651
time/training (s)                   1.08895
time/epoch (s)                      1.46648
time/total (s)                    158.274
Epoch                             103
-----------------------------  ---------------
2019-04-22 20:55:16.113182 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 104 finished
-----------------------------  ---------------
replay_buffer/size              21200
trainer/QF1 Loss                    0.00654085
trainer/QF2 Loss                    0.00659047
trainer/Policy Loss                 8.25373
trainer/Q1 Predictions Mean        -6.62601
trainer/Q1 Predictions Std          1.60001
trainer/Q1 Predictions Max         -5.98715
trainer/Q1 Predictions Min        -15.1888
trainer/Q2 Predictions Mean        -6.62355
trainer/Q2 Predictions Std          1.60218
trainer/Q2 Predictions Max         -5.98459
trainer/Q2 Predictions Min        -15.1216
trainer/Q Targets Mean             -6.63371
trainer/Q Targets Std               1.58593
trainer/Q Targets Max              -5.97306
trainer/Q Targets Min             -14.9171
trainer/Log Pis Mean                1.80173
trainer/Log Pis Std                 1.19943
trainer/Log Pis Max                 4.87778
trainer/Log Pis Min                -1.93999
trainer/Policy mu Mean              0.134032
trainer/Policy mu Std               0.736247
trainer/Policy mu Max               2.6555
trainer/Policy mu Min              -2.33921
trainer/Policy log std Mean        -1.99221
trainer/Policy log std Std          0.462313
trainer/Policy log std Max         -0.490761
trainer/Policy log std Min         -2.38573
trainer/Alpha                       0.0171672
trainer/Alpha Loss                 -0.805907
exploration/num steps total     21200
exploration/num paths total       212
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.124787
exploration/Rewards Std             0.234496
exploration/Rewards Max            -0.00728054
exploration/Rewards Min            -1
exploration/Returns Mean          -12.4787
exploration/Returns Std             1.88143
exploration/Returns Max           -10.5973
exploration/Returns Min           -14.3602
exploration/Actions Mean            0.0459547
exploration/Actions Std             0.257503
exploration/Actions Max             0.997067
exploration/Actions Min            -0.604352
exploration/Num Paths               2
exploration/Average Returns       -12.4787
evaluation/num steps total     105000
evaluation/num paths total       1050
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0663938
evaluation/Rewards Std              0.198235
evaluation/Rewards Max             -0.0187173
evaluation/Rewards Min             -1
evaluation/Returns Mean            -6.63938
evaluation/Returns Std              2.38539
evaluation/Returns Max             -4.25715
evaluation/Returns Min            -11.1439
evaluation/Actions Mean             0.0240134
evaluation/Actions Std              0.197506
evaluation/Actions Max              0.99116
evaluation/Actions Min             -0.992661
evaluation/Num Paths               10
evaluation/Average Returns         -6.63938
time/data storing (s)               0.00151302
time/evaluation sampling (s)        0.290104
time/exploration sampling (s)       0.075913
time/logging (s)                    0.00354091
time/saving (s)                     0.00248845
time/training (s)                   1.11185
time/epoch (s)                      1.48541
time/total (s)                    159.764
Epoch                             104
-----------------------------  ---------------
2019-04-22 20:55:17.568235 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 105 finished
-----------------------------  ---------------
replay_buffer/size              21400
trainer/QF1 Loss                    0.0103806
trainer/QF2 Loss                    0.0110483
trainer/Policy Loss                 7.95789
trainer/Q1 Predictions Mean        -6.32217
trainer/Q1 Predictions Std          1.36511
trainer/Q1 Predictions Max         -5.89593
trainer/Q1 Predictions Min        -15.3804
trainer/Q2 Predictions Mean        -6.32102
trainer/Q2 Predictions Std          1.35321
trainer/Q2 Predictions Max         -5.89205
trainer/Q2 Predictions Min        -15.281
trainer/Q Targets Mean             -6.38585
trainer/Q Targets Std               1.37709
trainer/Q Targets Max              -5.92496
trainer/Q Targets Min             -15.2642
trainer/Log Pis Mean                1.74354
trainer/Log Pis Std                 1.05942
trainer/Log Pis Max                 4.21782
trainer/Log Pis Min                -3.42837
trainer/Policy mu Mean              0.0319084
trainer/Policy mu Std               0.641971
trainer/Policy mu Max               2.49689
trainer/Policy mu Min              -1.60347
trainer/Policy log std Mean        -1.96647
trainer/Policy log std Std          0.412602
trainer/Policy log std Max         -0.4933
trainer/Policy log std Min         -2.33245
trainer/Alpha                       0.0171109
trainer/Alpha Loss                 -1.04325
exploration/num steps total     21400
exploration/num paths total       214
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.111535
exploration/Rewards Std             0.193895
exploration/Rewards Max            -0.00341111
exploration/Rewards Min            -1
exploration/Returns Mean          -11.1535
exploration/Returns Std             3.77871
exploration/Returns Max            -7.37477
exploration/Returns Min           -14.9322
exploration/Actions Mean            0.0253614
exploration/Actions Std             0.223432
exploration/Actions Max             0.995035
exploration/Actions Min            -0.609534
exploration/Num Paths               2
exploration/Average Returns       -11.1535
evaluation/num steps total     106000
evaluation/num paths total       1060
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0954526
evaluation/Rewards Std              0.208128
evaluation/Rewards Max             -0.0358852
evaluation/Rewards Min             -1
evaluation/Returns Mean            -9.54526
evaluation/Returns Std              2.59649
evaluation/Returns Max             -4.353
evaluation/Returns Min            -13.3221
evaluation/Actions Mean             0.0374111
evaluation/Actions Std              0.200939
evaluation/Actions Max              0.988977
evaluation/Actions Min             -0.889755
evaluation/Num Paths               10
evaluation/Average Returns         -9.54526
time/data storing (s)               0.00129177
time/evaluation sampling (s)        0.278911
time/exploration sampling (s)       0.0721968
time/logging (s)                    0.00321884
time/saving (s)                     0.00247628
time/training (s)                   1.09022
time/epoch (s)                      1.44832
time/total (s)                    161.217
Epoch                             105
-----------------------------  ---------------
2019-04-22 20:55:19.015619 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 106 finished
-----------------------------  ---------------
replay_buffer/size              21600
trainer/QF1 Loss                    0.00901476
trainer/QF2 Loss                    0.00852995
trainer/Policy Loss                 8.59326
trainer/Q1 Predictions Mean        -6.64175
trainer/Q1 Predictions Std          1.99954
trainer/Q1 Predictions Max         -5.84584
trainer/Q1 Predictions Min        -15.5967
trainer/Q2 Predictions Mean        -6.64848
trainer/Q2 Predictions Std          1.99602
trainer/Q2 Predictions Max         -5.84832
trainer/Q2 Predictions Min        -15.6862
trainer/Q Targets Mean             -6.69755
trainer/Q Targets Std               1.97988
trainer/Q Targets Max              -5.86937
trainer/Q Targets Min             -15.5899
trainer/Log Pis Mean                2.13086
trainer/Log Pis Std                 1.18182
trainer/Log Pis Max                 5.17207
trainer/Log Pis Min                -1.33365
trainer/Policy mu Mean              0.0731513
trainer/Policy mu Std               0.750449
trainer/Policy mu Max               2.595
trainer/Policy mu Min              -2.09312
trainer/Policy log std Mean        -1.95571
trainer/Policy log std Std          0.466699
trainer/Policy log std Max         -0.577819
trainer/Policy log std Min         -2.42764
trainer/Alpha                       0.0167977
trainer/Alpha Loss                  0.534785
exploration/num steps total     21600
exploration/num paths total       216
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.109961
exploration/Rewards Std             0.203248
exploration/Rewards Max            -0.00703758
exploration/Rewards Min            -1
exploration/Returns Mean          -10.9961
exploration/Returns Std             0.236556
exploration/Returns Max           -10.7596
exploration/Returns Min           -11.2327
exploration/Actions Mean            0.0195561
exploration/Actions Std             0.257215
exploration/Actions Max             0.997337
exploration/Actions Min            -0.96775
exploration/Num Paths               2
exploration/Average Returns       -10.9961
evaluation/num steps total     107000
evaluation/num paths total       1070
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0689247
evaluation/Rewards Std              0.178799
evaluation/Rewards Max             -0.0300108
evaluation/Rewards Min             -1
evaluation/Returns Mean            -6.89247
evaluation/Returns Std              2.53777
evaluation/Returns Max             -3.19123
evaluation/Returns Min             -9.81656
evaluation/Actions Mean             0.0372255
evaluation/Actions Std              0.176726
evaluation/Actions Max              0.99091
evaluation/Actions Min             -0.306123
evaluation/Num Paths               10
evaluation/Average Returns         -6.89247
time/data storing (s)               0.00124653
time/evaluation sampling (s)        0.290506
time/exploration sampling (s)       0.0750332
time/logging (s)                    0.00346164
time/saving (s)                     0.00236168
time/training (s)                   1.06817
time/epoch (s)                      1.44078
time/total (s)                    162.662
Epoch                             106
-----------------------------  ---------------
2019-04-22 20:55:20.470165 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 107 finished
-----------------------------  ---------------
replay_buffer/size              21800
trainer/QF1 Loss                    0.0117278
trainer/QF2 Loss                    0.0132728
trainer/Policy Loss                 8.40853
trainer/Q1 Predictions Mean        -6.45071
trainer/Q1 Predictions Std          1.29453
trainer/Q1 Predictions Max         -5.84489
trainer/Q1 Predictions Min        -12.052
trainer/Q2 Predictions Mean        -6.45148
trainer/Q2 Predictions Std          1.29965
trainer/Q2 Predictions Max         -5.84765
trainer/Q2 Predictions Min        -12.0627
trainer/Q Targets Mean             -6.45507
trainer/Q Targets Std               1.31897
trainer/Q Targets Max              -5.81519
trainer/Q Targets Min             -12.3877
trainer/Log Pis Mean                2.1023
trainer/Log Pis Std                 1.18517
trainer/Log Pis Max                 6.15119
trainer/Log Pis Min                -1.27469
trainer/Policy mu Mean              0.136334
trainer/Policy mu Std               0.853355
trainer/Policy mu Max               2.6125
trainer/Policy mu Min              -2.5698
trainer/Policy log std Mean        -1.96578
trainer/Policy log std Std          0.503279
trainer/Policy log std Max         -0.502301
trainer/Policy log std Min         -2.47308
trainer/Alpha                       0.0170735
trainer/Alpha Loss                  0.416401
exploration/num steps total     21800
exploration/num paths total       218
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.0720796
exploration/Rewards Std             0.0525805
exploration/Rewards Max            -0.00315143
exploration/Rewards Min            -0.568093
exploration/Returns Mean           -7.20796
exploration/Returns Std             0.0892808
exploration/Returns Max            -7.11868
exploration/Returns Min            -7.29724
exploration/Actions Mean            0.0106803
exploration/Actions Std             0.172181
exploration/Actions Max             0.991697
exploration/Actions Min            -0.412924
exploration/Num Paths               2
exploration/Average Returns        -7.20796
evaluation/num steps total     108000
evaluation/num paths total       1080
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0772145
evaluation/Rewards Std              0.172393
evaluation/Rewards Max             -0.0253092
evaluation/Rewards Min             -1
evaluation/Returns Mean            -7.72145
evaluation/Returns Std              1.94375
evaluation/Returns Max             -5.11391
evaluation/Returns Min            -12.3948
evaluation/Actions Mean             0.00919341
evaluation/Actions Std              0.183637
evaluation/Actions Max              0.988613
evaluation/Actions Min             -0.990096
evaluation/Num Paths               10
evaluation/Average Returns         -7.72145
time/data storing (s)               0.00124851
time/evaluation sampling (s)        0.28232
time/exploration sampling (s)       0.0687845
time/logging (s)                    0.00320867
time/saving (s)                     0.00255875
time/training (s)                   1.08952
time/epoch (s)                      1.44764
time/total (s)                    164.115
Epoch                             107
-----------------------------  ---------------
2019-04-22 20:55:21.917452 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 108 finished
-----------------------------  ---------------
replay_buffer/size              22000
trainer/QF1 Loss                    0.0197856
trainer/QF2 Loss                    0.0201132
trainer/Policy Loss                 8.18253
trainer/Q1 Predictions Mean        -6.3731
trainer/Q1 Predictions Std          1.56635
trainer/Q1 Predictions Max         -5.71668
trainer/Q1 Predictions Min        -13.3108
trainer/Q2 Predictions Mean        -6.37339
trainer/Q2 Predictions Std          1.57747
trainer/Q2 Predictions Max         -5.69981
trainer/Q2 Predictions Min        -13.3668
trainer/Q Targets Mean             -6.47182
trainer/Q Targets Std               1.60348
trainer/Q Targets Max              -5.77929
trainer/Q Targets Min             -13.9679
trainer/Log Pis Mean                1.96423
trainer/Log Pis Std                 1.31777
trainer/Log Pis Max                 5.77371
trainer/Log Pis Min                -3.11987
trainer/Policy mu Mean              0.0865387
trainer/Policy mu Std               0.774876
trainer/Policy mu Max               2.62172
trainer/Policy mu Min              -2.36019
trainer/Policy log std Mean        -2.01231
trainer/Policy log std Std          0.498863
trainer/Policy log std Max         -0.545087
trainer/Policy log std Min         -2.492
trainer/Alpha                       0.0169974
trainer/Alpha Loss                 -0.145771
exploration/num steps total     22000
exploration/num paths total       220
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.0688223
exploration/Rewards Std             0.111494
exploration/Rewards Max            -0.002408
exploration/Rewards Min            -1
exploration/Returns Mean           -6.88223
exploration/Returns Std             1.40252
exploration/Returns Max            -5.47971
exploration/Returns Min            -8.28476
exploration/Actions Mean            0.00942216
exploration/Actions Std             0.191408
exploration/Actions Max             0.996654
exploration/Actions Min            -0.78642
exploration/Num Paths               2
exploration/Average Returns        -6.88223
evaluation/num steps total     109000
evaluation/num paths total       1090
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0626749
evaluation/Rewards Std              0.196438
evaluation/Rewards Max             -0.0155328
evaluation/Rewards Min             -1
evaluation/Returns Mean            -6.26749
evaluation/Returns Std              2.55115
evaluation/Returns Max             -2.78688
evaluation/Returns Min            -10.8923
evaluation/Actions Mean             0.0298512
evaluation/Actions Std              0.195472
evaluation/Actions Max              0.991253
evaluation/Actions Min             -0.99032
evaluation/Num Paths               10
evaluation/Average Returns         -6.26749
time/data storing (s)               0.00126412
time/evaluation sampling (s)        0.286524
time/exploration sampling (s)       0.0754439
time/logging (s)                    0.00349256
time/saving (s)                     0.00273272
time/training (s)                   1.07154
time/epoch (s)                      1.441
time/total (s)                    165.56
Epoch                             108
-----------------------------  ---------------
2019-04-22 20:55:23.354450 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 109 finished
-----------------------------  ---------------
replay_buffer/size              22200
trainer/QF1 Loss                    0.341994
trainer/QF2 Loss                    0.346883
trainer/Policy Loss                 8.10288
trainer/Q1 Predictions Mean        -6.32433
trainer/Q1 Predictions Std          1.40497
trainer/Q1 Predictions Max         -5.79823
trainer/Q1 Predictions Min        -13.577
trainer/Q2 Predictions Mean        -6.32573
trainer/Q2 Predictions Std          1.38897
trainer/Q2 Predictions Max         -5.8111
trainer/Q2 Predictions Min        -13.4706
trainer/Q Targets Mean             -6.22372
trainer/Q Targets Std               1.52272
trainer/Q Targets Max              -0.21799
trainer/Q Targets Min             -13.6148
trainer/Log Pis Mean                1.89537
trainer/Log Pis Std                 0.950417
trainer/Log Pis Max                 4.8381
trainer/Log Pis Min                -1.50474
trainer/Policy mu Mean              0.166337
trainer/Policy mu Std               0.704662
trainer/Policy mu Max               2.69718
trainer/Policy mu Min              -2.38419
trainer/Policy log std Mean        -2.05441
trainer/Policy log std Std          0.492696
trainer/Policy log std Max         -0.419805
trainer/Policy log std Min         -2.44563
trainer/Alpha                       0.0172146
trainer/Alpha Loss                 -0.425028
exploration/num steps total     22200
exploration/num paths total       222
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.0963142
exploration/Rewards Std             0.155368
exploration/Rewards Max            -0.00383819
exploration/Rewards Min            -1
exploration/Returns Mean           -9.63142
exploration/Returns Std             0.119607
exploration/Returns Max            -9.51181
exploration/Returns Min            -9.75103
exploration/Actions Mean            0.011019
exploration/Actions Std             0.225722
exploration/Actions Max             0.993491
exploration/Actions Min            -0.996714
exploration/Num Paths               2
exploration/Average Returns        -9.63142
evaluation/num steps total     110000
evaluation/num paths total       1100
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0754242
evaluation/Rewards Std              0.169326
evaluation/Rewards Max             -0.0365489
evaluation/Rewards Min             -1
evaluation/Returns Mean            -7.54242
evaluation/Returns Std              2.47865
evaluation/Returns Max             -4.42741
evaluation/Returns Min            -13.2681
evaluation/Actions Mean             0.0260048
evaluation/Actions Std              0.183895
evaluation/Actions Max              0.993546
evaluation/Actions Min             -0.982761
evaluation/Num Paths               10
evaluation/Average Returns         -7.54242
time/data storing (s)               0.0013158
time/evaluation sampling (s)        0.275898
time/exploration sampling (s)       0.069241
time/logging (s)                    0.00342063
time/saving (s)                     0.00235307
time/training (s)                   1.07826
time/epoch (s)                      1.43049
time/total (s)                    166.995
Epoch                             109
-----------------------------  ---------------
2019-04-22 20:55:24.801931 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 110 finished
-----------------------------  ---------------
replay_buffer/size              22400
trainer/QF1 Loss                    0.384716
trainer/QF2 Loss                    0.380706
trainer/Policy Loss                 8.39845
trainer/Q1 Predictions Mean        -6.38514
trainer/Q1 Predictions Std          1.82555
trainer/Q1 Predictions Max         -5.60797
trainer/Q1 Predictions Min        -14.3925
trainer/Q2 Predictions Mean        -6.38746
trainer/Q2 Predictions Std          1.84129
trainer/Q2 Predictions Max         -5.60557
trainer/Q2 Predictions Min        -14.3399
trainer/Q Targets Mean             -6.42822
trainer/Q Targets Std               1.94362
trainer/Q Targets Max              -0.678432
trainer/Q Targets Min             -14.7719
trainer/Log Pis Mean                2.13151
trainer/Log Pis Std                 1.1425
trainer/Log Pis Max                 5.58246
trainer/Log Pis Min                -1.95467
trainer/Policy mu Mean              0.118498
trainer/Policy mu Std               0.791956
trainer/Policy mu Max               2.56146
trainer/Policy mu Min              -2.09674
trainer/Policy log std Mean        -2.01972
trainer/Policy log std Std          0.53372
trainer/Policy log std Max         -0.551659
trainer/Policy log std Min         -2.51512
trainer/Alpha                       0.0174428
trainer/Alpha Loss                  0.53246
exploration/num steps total     22400
exploration/num paths total       224
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.129164
exploration/Rewards Std             0.225157
exploration/Rewards Max            -0.00850357
exploration/Rewards Min            -1
exploration/Returns Mean          -12.9164
exploration/Returns Std             2.30909
exploration/Returns Max           -10.6073
exploration/Returns Min           -15.2255
exploration/Actions Mean            0.00741026
exploration/Actions Std             0.249475
exploration/Actions Max             0.99872
exploration/Actions Min            -0.998897
exploration/Num Paths               2
exploration/Average Returns       -12.9164
evaluation/num steps total     111000
evaluation/num paths total       1110
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0983988
evaluation/Rewards Std              0.210242
evaluation/Rewards Max             -0.0202838
evaluation/Rewards Min             -1
evaluation/Returns Mean            -9.83988
evaluation/Returns Std              2.32324
evaluation/Returns Max             -4.63148
evaluation/Returns Min            -13.3461
evaluation/Actions Mean             0.0363577
evaluation/Actions Std              0.208333
evaluation/Actions Max              0.989348
evaluation/Actions Min             -0.983388
evaluation/Num Paths               10
evaluation/Average Returns         -9.83988
time/data storing (s)               0.00127926
time/evaluation sampling (s)        0.285653
time/exploration sampling (s)       0.0744144
time/logging (s)                    0.00341249
time/saving (s)                     0.00285084
time/training (s)                   1.07289
time/epoch (s)                      1.4405
time/total (s)                    168.44
Epoch                             110
-----------------------------  ---------------
2019-04-22 20:55:26.237631 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 111 finished
-----------------------------  ---------------
replay_buffer/size              22600
trainer/QF1 Loss                    1.29141
trainer/QF2 Loss                    1.31216
trainer/Policy Loss                 7.96719
trainer/Q1 Predictions Mean        -6.07852
trainer/Q1 Predictions Std          1.3493
trainer/Q1 Predictions Max         -5.55076
trainer/Q1 Predictions Min        -13.2022
trainer/Q2 Predictions Mean        -6.06949
trainer/Q2 Predictions Std          1.35167
trainer/Q2 Predictions Max         -5.54308
trainer/Q2 Predictions Min        -13.1344
trainer/Q Targets Mean             -5.96514
trainer/Q Targets Std               1.61952
trainer/Q Targets Max              -0.0386982
trainer/Q Targets Min             -13.1421
trainer/Log Pis Mean                2.03343
trainer/Log Pis Std                 1.20561
trainer/Log Pis Max                 5.96101
trainer/Log Pis Min                -2.01337
trainer/Policy mu Mean              0.0443574
trainer/Policy mu Std               0.72743
trainer/Policy mu Max               2.57959
trainer/Policy mu Min              -3.02187
trainer/Policy log std Mean        -2.0164
trainer/Policy log std Std          0.492393
trainer/Policy log std Max         -0.405621
trainer/Policy log std Min         -2.45383
trainer/Alpha                       0.0175842
trainer/Alpha Loss                  0.135098
exploration/num steps total     22600
exploration/num paths total       226
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.114042
exploration/Rewards Std             0.188685
exploration/Rewards Max            -0.00392188
exploration/Rewards Min            -1
exploration/Returns Mean          -11.4042
exploration/Returns Std             0.854199
exploration/Returns Max           -10.55
exploration/Returns Min           -12.2584
exploration/Actions Mean           -0.0043502
exploration/Actions Std             0.233818
exploration/Actions Max             0.995648
exploration/Actions Min            -0.99599
exploration/Num Paths               2
exploration/Average Returns       -11.4042
evaluation/num steps total     112000
evaluation/num paths total       1120
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0844143
evaluation/Rewards Std              0.17542
evaluation/Rewards Max             -0.0241147
evaluation/Rewards Min             -1
evaluation/Returns Mean            -8.44143
evaluation/Returns Std              2.60521
evaluation/Returns Max             -5.34881
evaluation/Returns Min            -13.8152
evaluation/Actions Mean             0.0105491
evaluation/Actions Std              0.174753
evaluation/Actions Max              0.98869
evaluation/Actions Min             -0.993251
evaluation/Num Paths               10
evaluation/Average Returns         -8.44143
time/data storing (s)               0.00136799
time/evaluation sampling (s)        0.285146
time/exploration sampling (s)       0.0746838
time/logging (s)                    0.00312193
time/saving (s)                     0.00237988
time/training (s)                   1.06193
time/epoch (s)                      1.42863
time/total (s)                    169.874
Epoch                             111
-----------------------------  ---------------
2019-04-22 20:55:27.725674 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 112 finished
-----------------------------  ---------------
replay_buffer/size              22800
trainer/QF1 Loss                    0.00995482
trainer/QF2 Loss                    0.0107208
trainer/Policy Loss                 7.94855
trainer/Q1 Predictions Mean        -6.18774
trainer/Q1 Predictions Std          1.64434
trainer/Q1 Predictions Max         -5.54118
trainer/Q1 Predictions Min        -14.3199
trainer/Q2 Predictions Mean        -6.18915
trainer/Q2 Predictions Std          1.64297
trainer/Q2 Predictions Max         -5.54735
trainer/Q2 Predictions Min        -14.2694
trainer/Q Targets Mean             -6.2563
trainer/Q Targets Std               1.62605
trainer/Q Targets Max              -5.57631
trainer/Q Targets Min             -14.2716
trainer/Log Pis Mean                1.87625
trainer/Log Pis Std                 1.26096
trainer/Log Pis Max                 4.94655
trainer/Log Pis Min                -4.7926
trainer/Policy mu Mean              0.0497066
trainer/Policy mu Std               0.784265
trainer/Policy mu Max               2.4404
trainer/Policy mu Min              -2.67732
trainer/Policy log std Mean        -1.96655
trainer/Policy log std Std          0.530813
trainer/Policy log std Max         -0.417451
trainer/Policy log std Min         -2.4316
trainer/Alpha                       0.0175429
trainer/Alpha Loss                 -0.500318
exploration/num steps total     22800
exploration/num paths total       228
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.0621096
exploration/Rewards Std             0.0477317
exploration/Rewards Max            -0.00232736
exploration/Rewards Min            -0.537608
exploration/Returns Mean           -6.21096
exploration/Returns Std             0.254687
exploration/Returns Max            -5.95628
exploration/Returns Min            -6.46565
exploration/Actions Mean            0.00727905
exploration/Actions Std             0.166502
exploration/Actions Max             0.949126
exploration/Actions Min            -0.80747
exploration/Num Paths               2
exploration/Average Returns        -6.21096
evaluation/num steps total     113000
evaluation/num paths total       1130
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0654257
evaluation/Rewards Std              0.154544
evaluation/Rewards Max             -0.0303719
evaluation/Rewards Min             -1
evaluation/Returns Mean            -6.54257
evaluation/Returns Std              2.40093
evaluation/Returns Max             -3.69835
evaluation/Returns Min            -11.6691
evaluation/Actions Mean             0.0200605
evaluation/Actions Std              0.173249
evaluation/Actions Max              0.992716
evaluation/Actions Min             -0.984339
evaluation/Num Paths               10
evaluation/Average Returns         -6.54257
time/data storing (s)               0.00135958
time/evaluation sampling (s)        0.291616
time/exploration sampling (s)       0.0785589
time/logging (s)                    0.0035279
time/saving (s)                     0.00273213
time/training (s)                   1.1041
time/epoch (s)                      1.48189
time/total (s)                    171.36
Epoch                             112
-----------------------------  ---------------
2019-04-22 20:55:29.377910 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 113 finished
-----------------------------  ---------------
replay_buffer/size              23000
trainer/QF1 Loss                    0.00577236
trainer/QF2 Loss                    0.00662051
trainer/Policy Loss                 7.81327
trainer/Q1 Predictions Mean        -6.18566
trainer/Q1 Predictions Std          1.65319
trainer/Q1 Predictions Max         -5.53609
trainer/Q1 Predictions Min        -14.2383
trainer/Q2 Predictions Mean        -6.17874
trainer/Q2 Predictions Std          1.64196
trainer/Q2 Predictions Max         -5.53517
trainer/Q2 Predictions Min        -14.1634
trainer/Q Targets Mean             -6.22613
trainer/Q Targets Std               1.66181
trainer/Q Targets Max              -5.53415
trainer/Q Targets Min             -14.1296
trainer/Log Pis Mean                1.75164
trainer/Log Pis Std                 0.975473
trainer/Log Pis Max                 4.35675
trainer/Log Pis Min                -2.55425
trainer/Policy mu Mean              0.0405745
trainer/Policy mu Std               0.697181
trainer/Policy mu Max               2.62189
trainer/Policy mu Min              -2.693
trainer/Policy log std Mean        -2.00066
trainer/Policy log std Std          0.442685
trainer/Policy log std Max         -0.476117
trainer/Policy log std Min         -2.41102
trainer/Alpha                       0.0169746
trainer/Alpha Loss                 -1.01231
exploration/num steps total     23000
exploration/num paths total       230
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.088208
exploration/Rewards Std             0.13749
exploration/Rewards Max            -0.00783565
exploration/Rewards Min            -1
exploration/Returns Mean           -8.8208
exploration/Returns Std             2.2698
exploration/Returns Max            -6.55101
exploration/Returns Min           -11.0906
exploration/Actions Mean            0.0137637
exploration/Actions Std             0.192343
exploration/Actions Max             0.990774
exploration/Actions Min            -0.815447
exploration/Num Paths               2
exploration/Average Returns        -8.8208
evaluation/num steps total     114000
evaluation/num paths total       1140
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0965407
evaluation/Rewards Std              0.19793
evaluation/Rewards Max             -0.0232708
evaluation/Rewards Min             -1
evaluation/Returns Mean            -9.65407
evaluation/Returns Std              2.04618
evaluation/Returns Max             -6.89254
evaluation/Returns Min            -13.444
evaluation/Actions Mean             0.0177021
evaluation/Actions Std              0.199964
evaluation/Actions Max              0.992287
evaluation/Actions Min             -0.995156
evaluation/Num Paths               10
evaluation/Average Returns         -9.65407
time/data storing (s)               0.0012489
time/evaluation sampling (s)        0.291671
time/exploration sampling (s)       0.0722931
time/logging (s)                    0.00353216
time/saving (s)                     0.00245002
time/training (s)                   1.27491
time/epoch (s)                      1.64611
time/total (s)                    173.01
Epoch                             113
-----------------------------  ---------------
2019-04-22 20:55:31.045303 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 114 finished
-----------------------------  ---------------
replay_buffer/size              23200
trainer/QF1 Loss                    0.303951
trainer/QF2 Loss                    0.303476
trainer/Policy Loss                 7.90765
trainer/Q1 Predictions Mean        -5.97998
trainer/Q1 Predictions Std          1.25953
trainer/Q1 Predictions Max         -5.51253
trainer/Q1 Predictions Min        -12.7506
trainer/Q2 Predictions Mean        -5.98965
trainer/Q2 Predictions Std          1.27428
trainer/Q2 Predictions Max         -5.52605
trainer/Q2 Predictions Min        -12.9153
trainer/Q Targets Mean             -5.927
trainer/Q Targets Std               1.40667
trainer/Q Targets Max              -0.0840238
trainer/Q Targets Min             -13.1064
trainer/Log Pis Mean                2.04814
trainer/Log Pis Std                 1.1997
trainer/Log Pis Max                 7.00795
trainer/Log Pis Min                -2.31593
trainer/Policy mu Mean              0.0789106
trainer/Policy mu Std               0.682387
trainer/Policy mu Max               2.73948
trainer/Policy mu Min              -2.48929
trainer/Policy log std Mean        -2.078
trainer/Policy log std Std          0.425946
trainer/Policy log std Max         -0.461133
trainer/Policy log std Min         -2.4479
trainer/Alpha                       0.0172142
trainer/Alpha Loss                  0.195565
exploration/num steps total     23200
exploration/num paths total       232
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.0822341
exploration/Rewards Std             0.128429
exploration/Rewards Max            -0.00540573
exploration/Rewards Min            -1
exploration/Returns Mean           -8.22341
exploration/Returns Std             1.38035
exploration/Returns Max            -6.84306
exploration/Returns Min            -9.60376
exploration/Actions Mean            0.00205871
exploration/Actions Std             0.211653
exploration/Actions Max             0.988515
exploration/Actions Min            -0.989678
exploration/Num Paths               2
exploration/Average Returns        -8.22341
evaluation/num steps total     115000
evaluation/num paths total       1150
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0945814
evaluation/Rewards Std              0.211118
evaluation/Rewards Max             -0.0194161
evaluation/Rewards Min             -1
evaluation/Returns Mean            -9.45814
evaluation/Returns Std              2.57924
evaluation/Returns Max             -4.08609
evaluation/Returns Min            -13.0653
evaluation/Actions Mean             0.0335292
evaluation/Actions Std              0.207896
evaluation/Actions Max              0.991026
evaluation/Actions Min             -0.952898
evaluation/Num Paths               10
evaluation/Average Returns         -9.45814
time/data storing (s)               0.00125188
time/evaluation sampling (s)        0.314411
time/exploration sampling (s)       0.0845979
time/logging (s)                    0.00402705
time/saving (s)                     0.00268846
time/training (s)                   1.25469
time/epoch (s)                      1.66166
time/total (s)                    174.676
Epoch                             114
-----------------------------  ---------------
2019-04-22 20:55:32.630839 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 115 finished
-----------------------------  ---------------
replay_buffer/size              23400
trainer/QF1 Loss                    0.592096
trainer/QF2 Loss                    0.596467
trainer/Policy Loss                 8.13642
trainer/Q1 Predictions Mean        -6.05479
trainer/Q1 Predictions Std          1.42427
trainer/Q1 Predictions Max         -5.45993
trainer/Q1 Predictions Min        -12.1705
trainer/Q2 Predictions Mean        -6.05343
trainer/Q2 Predictions Std          1.42288
trainer/Q2 Predictions Max         -5.45547
trainer/Q2 Predictions Min        -12.2346
trainer/Q Targets Mean             -5.98509
trainer/Q Targets Std               1.68931
trainer/Q Targets Max              -0.0687391
trainer/Q Targets Min             -12.3792
trainer/Log Pis Mean                2.23284
trainer/Log Pis Std                 1.0882
trainer/Log Pis Max                 6.27271
trainer/Log Pis Min                -2.09608
trainer/Policy mu Mean              0.159434
trainer/Policy mu Std               0.761714
trainer/Policy mu Max               2.66672
trainer/Policy mu Min              -2.35696
trainer/Policy log std Mean        -2.02902
trainer/Policy log std Std          0.508879
trainer/Policy log std Max         -0.51851
trainer/Policy log std Min         -2.48585
trainer/Alpha                       0.0175877
trainer/Alpha Loss                  0.940847
exploration/num steps total     23400
exploration/num paths total       234
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.0745737
exploration/Rewards Std             0.113765
exploration/Rewards Max            -0.00274948
exploration/Rewards Min            -1
exploration/Returns Mean           -7.45737
exploration/Returns Std             0.450091
exploration/Returns Max            -7.00727
exploration/Returns Min            -7.90746
exploration/Actions Mean            0.00949174
exploration/Actions Std             0.21125
exploration/Actions Max             0.986861
exploration/Actions Min            -0.988175
exploration/Num Paths               2
exploration/Average Returns        -7.45737
evaluation/num steps total     116000
evaluation/num paths total       1160
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0606991
evaluation/Rewards Std              0.163528
evaluation/Rewards Max             -0.0197702
evaluation/Rewards Min             -1
evaluation/Returns Mean            -6.06991
evaluation/Returns Std              2.86331
evaluation/Returns Max             -2.85133
evaluation/Returns Min            -12.2273
evaluation/Actions Mean             0.0166543
evaluation/Actions Std              0.169939
evaluation/Actions Max              0.991136
evaluation/Actions Min             -0.987768
evaluation/Num Paths               10
evaluation/Average Returns         -6.06991
time/data storing (s)               0.00131246
time/evaluation sampling (s)        0.300801
time/exploration sampling (s)       0.0752021
time/logging (s)                    0.00385467
time/saving (s)                     0.0025122
time/training (s)                   1.19477
time/epoch (s)                      1.57845
time/total (s)                    176.258
Epoch                             115
-----------------------------  ---------------
2019-04-22 20:55:34.172077 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 116 finished
-----------------------------  ---------------
replay_buffer/size              23600
trainer/QF1 Loss                    0.587589
trainer/QF2 Loss                    0.589692
trainer/Policy Loss                 8.03087
trainer/Q1 Predictions Mean        -6.18919
trainer/Q1 Predictions Std          1.95703
trainer/Q1 Predictions Max         -5.38189
trainer/Q1 Predictions Min        -15.2286
trainer/Q2 Predictions Mean        -6.1989
trainer/Q2 Predictions Std          1.96706
trainer/Q2 Predictions Max         -5.38691
trainer/Q2 Predictions Min        -15.1853
trainer/Q Targets Mean             -6.14122
trainer/Q Targets Std               2.09015
trainer/Q Targets Max              -0.0233418
trainer/Q Targets Min             -14.9603
trainer/Log Pis Mean                2.00544
trainer/Log Pis Std                 1.44018
trainer/Log Pis Max                 6.1296
trainer/Log Pis Min                -2.93731
trainer/Policy mu Mean              0.0566998
trainer/Policy mu Std               0.825682
trainer/Policy mu Max               2.4312
trainer/Policy mu Min              -2.80185
trainer/Policy log std Mean        -1.99222
trainer/Policy log std Std          0.541893
trainer/Policy log std Max         -0.49519
trainer/Policy log std Min         -2.43491
trainer/Alpha                       0.0177735
trainer/Alpha Loss                  0.0219164
exploration/num steps total     23600
exploration/num paths total       236
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.0932713
exploration/Rewards Std             0.145658
exploration/Rewards Max            -0.00332795
exploration/Rewards Min            -1
exploration/Returns Mean           -9.32713
exploration/Returns Std             0.917345
exploration/Returns Max            -8.40979
exploration/Returns Min           -10.2445
exploration/Actions Mean            0.00380487
exploration/Actions Std             0.19899
exploration/Actions Max             0.992695
exploration/Actions Min            -0.997331
exploration/Num Paths               2
exploration/Average Returns        -9.32713
evaluation/num steps total     117000
evaluation/num paths total       1170
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0963941
evaluation/Rewards Std              0.182119
evaluation/Rewards Max             -0.0216293
evaluation/Rewards Min             -1
evaluation/Returns Mean            -9.63941
evaluation/Returns Std              2.36218
evaluation/Returns Max             -6.65622
evaluation/Returns Min            -13.6144
evaluation/Actions Mean             0.0260802
evaluation/Actions Std              0.188898
evaluation/Actions Max              0.986319
evaluation/Actions Min             -0.9768
evaluation/Num Paths               10
evaluation/Average Returns         -9.63941
time/data storing (s)               0.00134949
time/evaluation sampling (s)        0.311323
time/exploration sampling (s)       0.0830641
time/logging (s)                    0.00361857
time/saving (s)                     0.00263494
time/training (s)                   1.13253
time/epoch (s)                      1.53452
time/total (s)                    177.797
Epoch                             116
-----------------------------  ---------------
2019-04-22 20:55:35.632784 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 117 finished
-----------------------------  ---------------
replay_buffer/size              23800
trainer/QF1 Loss                    0.588528
trainer/QF2 Loss                    0.590041
trainer/Policy Loss                 7.77689
trainer/Q1 Predictions Mean        -6.07224
trainer/Q1 Predictions Std          1.82217
trainer/Q1 Predictions Max         -5.37339
trainer/Q1 Predictions Min        -14.0386
trainer/Q2 Predictions Mean        -6.08197
trainer/Q2 Predictions Std          1.80477
trainer/Q2 Predictions Max         -5.38182
trainer/Q2 Predictions Min        -14.0342
trainer/Q Targets Mean             -5.98897
trainer/Q Targets Std               1.93707
trainer/Q Targets Max              -0.21799
trainer/Q Targets Min             -13.7539
trainer/Log Pis Mean                1.79336
trainer/Log Pis Std                 1.37585
trainer/Log Pis Max                 5.97788
trainer/Log Pis Min                -2.18019
trainer/Policy mu Mean              0.0156724
trainer/Policy mu Std               0.716731
trainer/Policy mu Max               2.57237
trainer/Policy mu Min              -2.54414
trainer/Policy log std Mean        -2.045
trainer/Policy log std Std          0.483808
trainer/Policy log std Max         -0.63129
trainer/Policy log std Min         -2.45027
trainer/Alpha                       0.0177267
trainer/Alpha Loss                 -0.83327
exploration/num steps total     23800
exploration/num paths total       238
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.106406
exploration/Rewards Std             0.185306
exploration/Rewards Max            -0.00610029
exploration/Rewards Min            -1
exploration/Returns Mean          -10.6406
exploration/Returns Std             1.00476
exploration/Returns Max            -9.63584
exploration/Returns Min           -11.6454
exploration/Actions Mean            0.00712535
exploration/Actions Std             0.228278
exploration/Actions Max             0.995007
exploration/Actions Min            -0.998407
exploration/Num Paths               2
exploration/Average Returns       -10.6406
evaluation/num steps total     118000
evaluation/num paths total       1180
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0879042
evaluation/Rewards Std              0.174004
evaluation/Rewards Max             -0.0501602
evaluation/Rewards Min             -1
evaluation/Returns Mean            -8.79042
evaluation/Returns Std              2.61305
evaluation/Returns Max             -5.55147
evaluation/Returns Min            -13.79
evaluation/Actions Mean             0.0271898
evaluation/Actions Std              0.187196
evaluation/Actions Max              0.991552
evaluation/Actions Min             -0.951482
evaluation/Num Paths               10
evaluation/Average Returns         -8.79042
time/data storing (s)               0.00142336
time/evaluation sampling (s)        0.286459
time/exploration sampling (s)       0.0714225
time/logging (s)                    0.00340404
time/saving (s)                     0.00232952
time/training (s)                   1.08894
time/epoch (s)                      1.45398
time/total (s)                    179.255
Epoch                             117
-----------------------------  ---------------
2019-04-22 20:55:37.156574 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 118 finished
-----------------------------  ---------------
replay_buffer/size              24000
trainer/QF1 Loss                    0.0185308
trainer/QF2 Loss                    0.0193629
trainer/Policy Loss                 7.58586
trainer/Q1 Predictions Mean        -5.75206
trainer/Q1 Predictions Std          1.29716
trainer/Q1 Predictions Max         -5.3
trainer/Q1 Predictions Min        -14.1212
trainer/Q2 Predictions Mean        -5.75138
trainer/Q2 Predictions Std          1.29626
trainer/Q2 Predictions Max         -5.29662
trainer/Q2 Predictions Min        -14.2304
trainer/Q Targets Mean             -5.82327
trainer/Q Targets Std               1.21578
trainer/Q Targets Max              -5.33708
trainer/Q Targets Min             -13.3567
trainer/Log Pis Mean                1.96227
trainer/Log Pis Std                 1.09004
trainer/Log Pis Max                 4.0787
trainer/Log Pis Min                -1.59865
trainer/Policy mu Mean             -0.0359692
trainer/Policy mu Std               0.785319
trainer/Policy mu Max               2.5011
trainer/Policy mu Min              -2.58085
trainer/Policy log std Mean        -1.98285
trainer/Policy log std Std          0.505334
trainer/Policy log std Max         -0.569422
trainer/Policy log std Min         -2.47588
trainer/Alpha                       0.0177144
trainer/Alpha Loss                 -0.152194
exploration/num steps total     24000
exploration/num paths total       240
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.0584405
exploration/Rewards Std             0.0465091
exploration/Rewards Max            -0.00707863
exploration/Rewards Min            -0.450231
exploration/Returns Mean           -5.84405
exploration/Returns Std             0.0484848
exploration/Returns Max            -5.79557
exploration/Returns Min            -5.89254
exploration/Actions Mean            0.00665683
exploration/Actions Std             0.151118
exploration/Actions Max             0.944459
exploration/Actions Min            -0.396484
exploration/Num Paths               2
exploration/Average Returns        -5.84405
evaluation/num steps total     119000
evaluation/num paths total       1190
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0772684
evaluation/Rewards Std              0.19847
evaluation/Rewards Max             -0.0154876
evaluation/Rewards Min             -1
evaluation/Returns Mean            -7.72684
evaluation/Returns Std              2.47706
evaluation/Returns Max             -3.03363
evaluation/Returns Min            -10.4906
evaluation/Actions Mean             0.0286333
evaluation/Actions Std              0.191663
evaluation/Actions Max              0.990723
evaluation/Actions Min             -0.971011
evaluation/Num Paths               10
evaluation/Average Returns         -7.72684
time/data storing (s)               0.00122471
time/evaluation sampling (s)        0.291842
time/exploration sampling (s)       0.0855568
time/logging (s)                    0.00351241
time/saving (s)                     0.00237051
time/training (s)                   1.13281
time/epoch (s)                      1.51732
time/total (s)                    180.777
Epoch                             118
-----------------------------  ---------------
2019-04-22 20:55:38.685302 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 119 finished
-----------------------------  ---------------
replay_buffer/size              24200
trainer/QF1 Loss                    0.572665
trainer/QF2 Loss                    0.577649
trainer/Policy Loss                 7.67385
trainer/Q1 Predictions Mean        -5.75374
trainer/Q1 Predictions Std          1.28521
trainer/Q1 Predictions Max         -5.33286
trainer/Q1 Predictions Min        -14.8806
trainer/Q2 Predictions Mean        -5.75347
trainer/Q2 Predictions Std          1.2875
trainer/Q2 Predictions Max         -5.34045
trainer/Q2 Predictions Min        -14.8925
trainer/Q Targets Mean             -5.64894
trainer/Q Targets Std               1.47748
trainer/Q Targets Max              -0.0947216
trainer/Q Targets Min             -14.7154
trainer/Log Pis Mean                2.03889
trainer/Log Pis Std                 1.10771
trainer/Log Pis Max                 6.66999
trainer/Log Pis Min                -0.749602
trainer/Policy mu Mean              0.0699501
trainer/Policy mu Std               0.676305
trainer/Policy mu Max               2.5909
trainer/Policy mu Min              -2.71779
trainer/Policy log std Mean        -2.00032
trainer/Policy log std Std          0.460075
trainer/Policy log std Max         -0.453137
trainer/Policy log std Min         -2.38194
trainer/Alpha                       0.0178703
trainer/Alpha Loss                  0.156497
exploration/num steps total     24200
exploration/num paths total       242
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.0857779
exploration/Rewards Std             0.154259
exploration/Rewards Max            -0.0025068
exploration/Rewards Min            -1
exploration/Returns Mean           -8.57779
exploration/Returns Std             2.58252
exploration/Returns Max            -5.99527
exploration/Returns Min           -11.1603
exploration/Actions Mean            0.023412
exploration/Actions Std             0.217646
exploration/Actions Max             0.997799
exploration/Actions Min            -0.535158
exploration/Num Paths               2
exploration/Average Returns        -8.57779
evaluation/num steps total     120000
evaluation/num paths total       1200
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0698319
evaluation/Rewards Std              0.200763
evaluation/Rewards Max             -0.0207486
evaluation/Rewards Min             -1
evaluation/Returns Mean            -6.98319
evaluation/Returns Std              2.68467
evaluation/Returns Max             -3.09241
evaluation/Returns Min            -11.1151
evaluation/Actions Mean             0.0368019
evaluation/Actions Std              0.196475
evaluation/Actions Max              0.991003
evaluation/Actions Min             -0.954166
evaluation/Num Paths               10
evaluation/Average Returns         -6.98319
time/data storing (s)               0.00123722
time/evaluation sampling (s)        0.307322
time/exploration sampling (s)       0.0798369
time/logging (s)                    0.00344831
time/saving (s)                     0.00250042
time/training (s)                   1.1276
time/epoch (s)                      1.52195
time/total (s)                    182.303
Epoch                             119
-----------------------------  ---------------
2019-04-22 20:55:40.166502 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 120 finished
-----------------------------  ---------------
replay_buffer/size              24400
trainer/QF1 Loss                    0.0155652
trainer/QF2 Loss                    0.0126788
trainer/Policy Loss                 8.44603
trainer/Q1 Predictions Mean        -6.34985
trainer/Q1 Predictions Std          2.32298
trainer/Q1 Predictions Max         -5.20462
trainer/Q1 Predictions Min        -14.1232
trainer/Q2 Predictions Mean        -6.35206
trainer/Q2 Predictions Std          2.31057
trainer/Q2 Predictions Max         -5.20938
trainer/Q2 Predictions Min        -14.1403
trainer/Q Targets Mean             -6.41879
trainer/Q Targets Std               2.28497
trainer/Q Targets Max              -5.27019
trainer/Q Targets Min             -14.3436
trainer/Log Pis Mean                2.24417
trainer/Log Pis Std                 1.27684
trainer/Log Pis Max                 5.0733
trainer/Log Pis Min                -1.2031
trainer/Policy mu Mean              0.234584
trainer/Policy mu Std               0.891775
trainer/Policy mu Max               2.6056
trainer/Policy mu Min              -2.49092
trainer/Policy log std Mean        -1.94464
trainer/Policy log std Std          0.559966
trainer/Policy log std Max         -0.613956
trainer/Policy log std Min         -2.46079
trainer/Alpha                       0.0174748
trainer/Alpha Loss                  0.988158
exploration/num steps total     24400
exploration/num paths total       244
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.062845
exploration/Rewards Std             0.0722453
exploration/Rewards Max            -0.00239788
exploration/Rewards Min            -0.801136
exploration/Returns Mean           -6.2845
exploration/Returns Std             0.460081
exploration/Returns Max            -5.82442
exploration/Returns Min            -6.74458
exploration/Actions Mean            0.00714553
exploration/Actions Std             0.17871
exploration/Actions Max             0.991224
exploration/Actions Min            -0.993919
exploration/Num Paths               2
exploration/Average Returns        -6.2845
evaluation/num steps total     121000
evaluation/num paths total       1210
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0666567
evaluation/Rewards Std              0.167908
evaluation/Rewards Max             -0.0194865
evaluation/Rewards Min             -1
evaluation/Returns Mean            -6.66567
evaluation/Returns Std              2.75883
evaluation/Returns Max             -3.56117
evaluation/Returns Min            -10.6533
evaluation/Actions Mean             0.0186284
evaluation/Actions Std              0.177134
evaluation/Actions Max              0.98981
evaluation/Actions Min             -0.99035
evaluation/Num Paths               10
evaluation/Average Returns         -6.66567
time/data storing (s)               0.00130102
time/evaluation sampling (s)        0.297243
time/exploration sampling (s)       0.074942
time/logging (s)                    0.00363926
time/saving (s)                     0.0025019
time/training (s)                   1.09515
time/epoch (s)                      1.47477
time/total (s)                    183.782
Epoch                             120
-----------------------------  ---------------
2019-04-22 20:55:41.681247 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 121 finished
-----------------------------  ---------------
replay_buffer/size              24600
trainer/QF1 Loss                    0.27526
trainer/QF2 Loss                    0.275986
trainer/Policy Loss                 8.04092
trainer/Q1 Predictions Mean        -5.93927
trainer/Q1 Predictions Std          1.56847
trainer/Q1 Predictions Max         -5.24125
trainer/Q1 Predictions Min        -12.8158
trainer/Q2 Predictions Mean        -5.93748
trainer/Q2 Predictions Std          1.56726
trainer/Q2 Predictions Max         -5.24298
trainer/Q2 Predictions Min        -12.8094
trainer/Q Targets Mean             -5.89816
trainer/Q Targets Std               1.6762
trainer/Q Targets Max              -0.0872363
trainer/Q Targets Min             -12.6032
trainer/Log Pis Mean                2.24268
trainer/Log Pis Std                 1.25047
trainer/Log Pis Max                 7.35189
trainer/Log Pis Min                -1.1829
trainer/Policy mu Mean              0.138177
trainer/Policy mu Std               0.855697
trainer/Policy mu Max               2.62817
trainer/Policy mu Min              -2.93898
trainer/Policy log std Mean        -1.9507
trainer/Policy log std Std          0.534666
trainer/Policy log std Max         -0.510393
trainer/Policy log std Min         -2.46048
trainer/Alpha                       0.0179017
trainer/Alpha Loss                  0.976309
exploration/num steps total     24600
exploration/num paths total       246
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.101316
exploration/Rewards Std             0.186235
exploration/Rewards Max            -0.00197283
exploration/Rewards Min            -1
exploration/Returns Mean          -10.1316
exploration/Returns Std             1.60986
exploration/Returns Max            -8.5217
exploration/Returns Min           -11.7414
exploration/Actions Mean            0.0504681
exploration/Actions Std             0.247637
exploration/Actions Max             0.998261
exploration/Actions Min            -0.376783
exploration/Num Paths               2
exploration/Average Returns       -10.1316
evaluation/num steps total     122000
evaluation/num paths total       1220
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0589438
evaluation/Rewards Std              0.14603
evaluation/Rewards Max             -0.00927671
evaluation/Rewards Min             -1
evaluation/Returns Mean            -5.89438
evaluation/Returns Std              2.90578
evaluation/Returns Max             -3.31492
evaluation/Returns Min            -11.2874
evaluation/Actions Mean             0.0168029
evaluation/Actions Std              0.160722
evaluation/Actions Max              0.990018
evaluation/Actions Min             -0.977428
evaluation/Num Paths               10
evaluation/Average Returns         -5.89438
time/data storing (s)               0.00123382
time/evaluation sampling (s)        0.290605
time/exploration sampling (s)       0.073368
time/logging (s)                    0.00407119
time/saving (s)                     0.00271993
time/training (s)                   1.13716
time/epoch (s)                      1.50916
time/total (s)                    185.295
Epoch                             121
-----------------------------  ---------------
2019-04-22 20:55:43.221224 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 122 finished
-----------------------------  ---------------
replay_buffer/size              24800
trainer/QF1 Loss                    0.282729
trainer/QF2 Loss                    0.281356
trainer/Policy Loss                 7.72724
trainer/Q1 Predictions Mean        -5.988
trainer/Q1 Predictions Std          1.98252
trainer/Q1 Predictions Max         -5.18202
trainer/Q1 Predictions Min        -15.1832
trainer/Q2 Predictions Mean        -5.98148
trainer/Q2 Predictions Std          1.98065
trainer/Q2 Predictions Max         -5.17406
trainer/Q2 Predictions Min        -15.1493
trainer/Q Targets Mean             -5.96282
trainer/Q Targets Std               2.00096
trainer/Q Targets Max              -0.0317594
trainer/Q Targets Min             -14.8666
trainer/Log Pis Mean                1.90141
trainer/Log Pis Std                 1.38413
trainer/Log Pis Max                 6.99391
trainer/Log Pis Min                -2.59618
trainer/Policy mu Mean              0.0114722
trainer/Policy mu Std               0.75041
trainer/Policy mu Max               2.89314
trainer/Policy mu Min              -2.22213
trainer/Policy log std Mean        -1.98314
trainer/Policy log std Std          0.512983
trainer/Policy log std Max         -0.354743
trainer/Policy log std Min         -2.42027
trainer/Alpha                       0.017959
trainer/Alpha Loss                 -0.396304
exploration/num steps total     24800
exploration/num paths total       248
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.118305
exploration/Rewards Std             0.164801
exploration/Rewards Max            -0.0131606
exploration/Rewards Min            -1
exploration/Returns Mean          -11.8305
exploration/Returns Std             3.67475
exploration/Returns Max            -8.15571
exploration/Returns Min           -15.5052
exploration/Actions Mean            0.0217663
exploration/Actions Std             0.207377
exploration/Actions Max             0.996471
exploration/Actions Min            -0.822674
exploration/Num Paths               2
exploration/Average Returns       -11.8305
evaluation/num steps total     123000
evaluation/num paths total       1230
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.108582
evaluation/Rewards Std              0.163974
evaluation/Rewards Max             -0.0401548
evaluation/Rewards Min             -1
evaluation/Returns Mean           -10.8582
evaluation/Returns Std              1.91968
evaluation/Returns Max             -7.50731
evaluation/Returns Min            -14.7729
evaluation/Actions Mean             0.0180042
evaluation/Actions Std              0.178721
evaluation/Actions Max              0.9857
evaluation/Actions Min             -0.993967
evaluation/Num Paths               10
evaluation/Average Returns        -10.8582
time/data storing (s)               0.00154468
time/evaluation sampling (s)        0.307841
time/exploration sampling (s)       0.0798391
time/logging (s)                    0.00367687
time/saving (s)                     0.0114158
time/training (s)                   1.12754
time/epoch (s)                      1.53186
time/total (s)                    186.832
Epoch                             122
-----------------------------  ---------------
2019-04-22 20:55:44.723315 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 123 finished
-----------------------------  ----------------
replay_buffer/size              25000
trainer/QF1 Loss                    0.531927
trainer/QF2 Loss                    0.535842
trainer/Policy Loss                 7.62628
trainer/Q1 Predictions Mean        -5.93564
trainer/Q1 Predictions Std          1.87228
trainer/Q1 Predictions Max         -5.17344
trainer/Q1 Predictions Min        -14.42
trainer/Q2 Predictions Mean        -5.94112
trainer/Q2 Predictions Std          1.8908
trainer/Q2 Predictions Max         -5.17642
trainer/Q2 Predictions Min        -14.6627
trainer/Q Targets Mean             -5.85001
trainer/Q Targets Std               2.03222
trainer/Q Targets Max              -0.0279247
trainer/Q Targets Min             -14.5539
trainer/Log Pis Mean                1.83945
trainer/Log Pis Std                 1.1534
trainer/Log Pis Max                 5.32962
trainer/Log Pis Min                -1.70264
trainer/Policy mu Mean              0.102129
trainer/Policy mu Std               0.756308
trainer/Policy mu Max               2.482
trainer/Policy mu Min              -2.61212
trainer/Policy log std Mean        -1.97457
trainer/Policy log std Std          0.546192
trainer/Policy log std Max         -0.253671
trainer/Policy log std Min         -2.41233
trainer/Alpha                       0.0179415
trainer/Alpha Loss                 -0.64547
exploration/num steps total     25000
exploration/num paths total       250
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.108666
exploration/Rewards Std             0.214082
exploration/Rewards Max            -0.000720786
exploration/Rewards Min            -1
exploration/Returns Mean          -10.8666
exploration/Returns Std             1.35393
exploration/Returns Max            -9.51268
exploration/Returns Min           -12.2205
exploration/Actions Mean            0.0225608
exploration/Actions Std             0.255196
exploration/Actions Max             0.996937
exploration/Actions Min            -0.994876
exploration/Num Paths               2
exploration/Average Returns       -10.8666
evaluation/num steps total     124000
evaluation/num paths total       1240
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0774911
evaluation/Rewards Std              0.19854
evaluation/Rewards Max             -0.020837
evaluation/Rewards Min             -1
evaluation/Returns Mean            -7.74911
evaluation/Returns Std              2.08785
evaluation/Returns Max             -3.41781
evaluation/Returns Min            -10.6644
evaluation/Actions Mean             0.026975
evaluation/Actions Std              0.186342
evaluation/Actions Max              0.990073
evaluation/Actions Min             -0.993075
evaluation/Num Paths               10
evaluation/Average Returns         -7.74911
time/data storing (s)               0.00129901
time/evaluation sampling (s)        0.295838
time/exploration sampling (s)       0.0769941
time/logging (s)                    0.00365071
time/saving (s)                     0.00249757
time/training (s)                   1.11535
time/epoch (s)                      1.49563
time/total (s)                    188.332
Epoch                             123
-----------------------------  ----------------
2019-04-22 20:55:46.201642 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 124 finished
-----------------------------  ---------------
replay_buffer/size              25200
trainer/QF1 Loss                    0.00852834
trainer/QF2 Loss                    0.00890972
trainer/Policy Loss                 7.7043
trainer/Q1 Predictions Mean        -5.7672
trainer/Q1 Predictions Std          1.71537
trainer/Q1 Predictions Max         -5.07614
trainer/Q1 Predictions Min        -14.2479
trainer/Q2 Predictions Mean        -5.76268
trainer/Q2 Predictions Std          1.70729
trainer/Q2 Predictions Max         -5.07766
trainer/Q2 Predictions Min        -14.2717
trainer/Q Targets Mean             -5.82164
trainer/Q Targets Std               1.67459
trainer/Q Targets Max              -5.1029
trainer/Q Targets Min             -14.2228
trainer/Log Pis Mean                2.06446
trainer/Log Pis Std                 1.02031
trainer/Log Pis Max                 4.44174
trainer/Log Pis Min                -2.63461
trainer/Policy mu Mean              0.156382
trainer/Policy mu Std               0.733769
trainer/Policy mu Max               2.50957
trainer/Policy mu Min              -2.50383
trainer/Policy log std Mean        -2.06114
trainer/Policy log std Std          0.510095
trainer/Policy log std Max         -0.478559
trainer/Policy log std Min         -2.54699
trainer/Alpha                       0.0176641
trainer/Alpha Loss                  0.260161
exploration/num steps total     25200
exploration/num paths total       252
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.0870631
exploration/Rewards Std             0.124104
exploration/Rewards Max            -0.00559904
exploration/Rewards Min            -1
exploration/Returns Mean           -8.70631
exploration/Returns Std             2.1952
exploration/Returns Max            -6.51111
exploration/Returns Min           -10.9015
exploration/Actions Mean            0.0131009
exploration/Actions Std             0.185665
exploration/Actions Max             0.997967
exploration/Actions Min            -0.901279
exploration/Num Paths               2
exploration/Average Returns        -8.70631
evaluation/num steps total     125000
evaluation/num paths total       1250
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0794781
evaluation/Rewards Std              0.160148
evaluation/Rewards Max             -0.0473087
evaluation/Rewards Min             -1
evaluation/Returns Mean            -7.94781
evaluation/Returns Std              2.02965
evaluation/Returns Max             -5.54922
evaluation/Returns Min            -12.382
evaluation/Actions Mean             0.0353836
evaluation/Actions Std              0.17946
evaluation/Actions Max              0.988972
evaluation/Actions Min             -0.89412
evaluation/Num Paths               10
evaluation/Average Returns         -7.94781
time/data storing (s)               0.00131768
time/evaluation sampling (s)        0.295976
time/exploration sampling (s)       0.0772798
time/logging (s)                    0.00335565
time/saving (s)                     0.00255197
time/training (s)                   1.09062
time/epoch (s)                      1.4711
time/total (s)                    189.808
Epoch                             124
-----------------------------  ---------------
2019-04-22 20:55:47.722495 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 125 finished
-----------------------------  ---------------
replay_buffer/size              25400
trainer/QF1 Loss                    0.517423
trainer/QF2 Loss                    0.52101
trainer/Policy Loss                 7.707
trainer/Q1 Predictions Mean        -6.00207
trainer/Q1 Predictions Std          2.12444
trainer/Q1 Predictions Max         -5.04665
trainer/Q1 Predictions Min        -14.1373
trainer/Q2 Predictions Mean        -5.99192
trainer/Q2 Predictions Std          2.12908
trainer/Q2 Predictions Max         -5.04463
trainer/Q2 Predictions Min        -14.1184
trainer/Q Targets Mean             -5.9826
trainer/Q Targets Std               2.28781
trainer/Q Targets Max              -0.0232621
trainer/Q Targets Min             -14.4646
trainer/Log Pis Mean                1.9044
trainer/Log Pis Std                 1.39513
trainer/Log Pis Max                 5.57026
trainer/Log Pis Min                -5.53154
trainer/Policy mu Mean              0.072467
trainer/Policy mu Std               0.895966
trainer/Policy mu Max               2.99059
trainer/Policy mu Min              -2.68695
trainer/Policy log std Mean        -1.84916
trainer/Policy log std Std          0.552629
trainer/Policy log std Max         -0.411726
trainer/Policy log std Min         -2.36534
trainer/Alpha                       0.0170562
trainer/Alpha Loss                 -0.389205
exploration/num steps total     25400
exploration/num paths total       254
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.112829
exploration/Rewards Std             0.185969
exploration/Rewards Max            -0.00445084
exploration/Rewards Min            -1
exploration/Returns Mean          -11.2829
exploration/Returns Std             2.39858
exploration/Returns Max            -8.8843
exploration/Returns Min           -13.6815
exploration/Actions Mean            0.048869
exploration/Actions Std             0.245788
exploration/Actions Max             0.996528
exploration/Actions Min            -0.399434
exploration/Num Paths               2
exploration/Average Returns       -11.2829
evaluation/num steps total     126000
evaluation/num paths total       1260
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0882603
evaluation/Rewards Std              0.179669
evaluation/Rewards Max             -0.0172787
evaluation/Rewards Min             -1
evaluation/Returns Mean            -8.82603
evaluation/Returns Std              2.44869
evaluation/Returns Max             -4.88767
evaluation/Returns Min            -13.4488
evaluation/Actions Mean             0.0173613
evaluation/Actions Std              0.193031
evaluation/Actions Max              0.988696
evaluation/Actions Min             -0.992445
evaluation/Num Paths               10
evaluation/Average Returns         -8.82603
time/data storing (s)               0.00121415
time/evaluation sampling (s)        0.280677
time/exploration sampling (s)       0.0699892
time/logging (s)                    0.0041793
time/saving (s)                     0.00291096
time/training (s)                   1.15629
time/epoch (s)                      1.51526
time/total (s)                    191.327
Epoch                             125
-----------------------------  ---------------
2019-04-22 20:55:49.219005 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 126 finished
-----------------------------  ----------------
replay_buffer/size              25600
trainer/QF1 Loss                    0.00765093
trainer/QF2 Loss                    0.00573248
trainer/Policy Loss                 7.79115
trainer/Q1 Predictions Mean        -5.80629
trainer/Q1 Predictions Std          1.65226
trainer/Q1 Predictions Max         -5.12146
trainer/Q1 Predictions Min        -13.6862
trainer/Q2 Predictions Mean        -5.8049
trainer/Q2 Predictions Std          1.66997
trainer/Q2 Predictions Max         -5.11674
trainer/Q2 Predictions Min        -13.7796
trainer/Q Targets Mean             -5.78902
trainer/Q Targets Std               1.70506
trainer/Q Targets Max              -5.06063
trainer/Q Targets Min             -13.9466
trainer/Log Pis Mean                2.09768
trainer/Log Pis Std                 1.3569
trainer/Log Pis Max                 7.02725
trainer/Log Pis Min                -3.61867
trainer/Policy mu Mean              0.0970196
trainer/Policy mu Std               0.771947
trainer/Policy mu Max               2.5674
trainer/Policy mu Min              -2.24637
trainer/Policy log std Mean        -2.04368
trainer/Policy log std Std          0.492768
trainer/Policy log std Max         -0.573366
trainer/Policy log std Min         -2.50901
trainer/Alpha                       0.0164954
trainer/Alpha Loss                  0.400962
exploration/num steps total     25600
exploration/num paths total       256
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.101952
exploration/Rewards Std             0.203614
exploration/Rewards Max            -0.000887571
exploration/Rewards Min            -1
exploration/Returns Mean          -10.1952
exploration/Returns Std             2.83322
exploration/Returns Max            -7.36201
exploration/Returns Min           -13.0284
exploration/Actions Mean            0.0506923
exploration/Actions Std             0.237109
exploration/Actions Max             0.994853
exploration/Actions Min            -0.353443
exploration/Num Paths               2
exploration/Average Returns       -10.1952
evaluation/num steps total     127000
evaluation/num paths total       1270
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0675718
evaluation/Rewards Std              0.198385
evaluation/Rewards Max             -0.00568849
evaluation/Rewards Min             -1
evaluation/Returns Mean            -6.75718
evaluation/Returns Std              2.53437
evaluation/Returns Max             -2.79389
evaluation/Returns Min            -10.7027
evaluation/Actions Mean             0.0243192
evaluation/Actions Std              0.19577
evaluation/Actions Max              0.993369
evaluation/Actions Min             -0.993254
evaluation/Num Paths               10
evaluation/Average Returns         -6.75718
time/data storing (s)               0.00120822
time/evaluation sampling (s)        0.31886
time/exploration sampling (s)       0.0776859
time/logging (s)                    0.00347793
time/saving (s)                     0.00216333
time/training (s)                   1.08462
time/epoch (s)                      1.48802
time/total (s)                    192.82
Epoch                             126
-----------------------------  ----------------
2019-04-22 20:55:50.694541 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 127 finished
-----------------------------  ---------------
replay_buffer/size              25800
trainer/QF1 Loss                    0.0112436
trainer/QF2 Loss                    0.0119942
trainer/Policy Loss                 7.86126
trainer/Q1 Predictions Mean        -5.76678
trainer/Q1 Predictions Std          2.06123
trainer/Q1 Predictions Max         -4.9672
trainer/Q1 Predictions Min        -13.6694
trainer/Q2 Predictions Mean        -5.77237
trainer/Q2 Predictions Std          2.07281
trainer/Q2 Predictions Max         -4.9701
trainer/Q2 Predictions Min        -13.5865
trainer/Q Targets Mean             -5.84949
trainer/Q Targets Std               2.06972
trainer/Q Targets Max              -5.00193
trainer/Q Targets Min             -13.8062
trainer/Log Pis Mean                2.24056
trainer/Log Pis Std                 1.26306
trainer/Log Pis Max                 6.649
trainer/Log Pis Min                -2.43965
trainer/Policy mu Mean              0.0980133
trainer/Policy mu Std               0.784615
trainer/Policy mu Max               2.80568
trainer/Policy mu Min              -2.1347
trainer/Policy log std Mean        -2.06509
trainer/Policy log std Std          0.523261
trainer/Policy log std Max         -0.451049
trainer/Policy log std Min         -2.49175
trainer/Alpha                       0.016761
trainer/Alpha Loss                  0.983623
exploration/num steps total     25800
exploration/num paths total       258
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.10294
exploration/Rewards Std             0.174151
exploration/Rewards Max            -0.00198806
exploration/Rewards Min            -1
exploration/Returns Mean          -10.294
exploration/Returns Std             0.648877
exploration/Returns Max            -9.64512
exploration/Returns Min           -10.9429
exploration/Actions Mean            0.0180507
exploration/Actions Std             0.237689
exploration/Actions Max             0.993129
exploration/Actions Min            -0.992576
exploration/Num Paths               2
exploration/Average Returns       -10.294
evaluation/num steps total     128000
evaluation/num paths total       1280
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0942809
evaluation/Rewards Std              0.195597
evaluation/Rewards Max             -0.0109881
evaluation/Rewards Min             -1
evaluation/Returns Mean            -9.42809
evaluation/Returns Std              2.49524
evaluation/Returns Max             -4.76973
evaluation/Returns Min            -12.4605
evaluation/Actions Mean             0.0269049
evaluation/Actions Std              0.193466
evaluation/Actions Max              0.990344
evaluation/Actions Min             -0.989715
evaluation/Num Paths               10
evaluation/Average Returns         -9.42809
time/data storing (s)               0.00145536
time/evaluation sampling (s)        0.291845
time/exploration sampling (s)       0.0764527
time/logging (s)                    0.00365261
time/saving (s)                     0.00255391
time/training (s)                   1.09272
time/epoch (s)                      1.46868
time/total (s)                    194.294
Epoch                             127
-----------------------------  ---------------
2019-04-22 20:55:52.183607 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 128 finished
-----------------------------  ---------------
replay_buffer/size              26000
trainer/QF1 Loss                    0.00243859
trainer/QF2 Loss                    0.00364954
trainer/Policy Loss                 7.07555
trainer/Q1 Predictions Mean        -5.43931
trainer/Q1 Predictions Std          1.21547
trainer/Q1 Predictions Max         -5.01378
trainer/Q1 Predictions Min        -12.2837
trainer/Q2 Predictions Mean        -5.45427
trainer/Q2 Predictions Std          1.21743
trainer/Q2 Predictions Max         -5.02894
trainer/Q2 Predictions Min        -12.3086
trainer/Q Targets Mean             -5.4293
trainer/Q Targets Std               1.21367
trainer/Q Targets Max              -4.97247
trainer/Q Targets Min             -12.3724
trainer/Log Pis Mean                1.73123
trainer/Log Pis Std                 1.11094
trainer/Log Pis Max                 4.51841
trainer/Log Pis Min                -2.58332
trainer/Policy mu Mean             -0.0619883
trainer/Policy mu Std               0.625175
trainer/Policy mu Max               2.51871
trainer/Policy mu Min              -2.07712
trainer/Policy log std Mean        -2.05819
trainer/Policy log std Std          0.463077
trainer/Policy log std Max         -0.420837
trainer/Policy log std Min         -2.47431
trainer/Alpha                       0.0172799
trainer/Alpha Loss                 -1.09075
exploration/num steps total     26000
exploration/num paths total       260
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.116909
exploration/Rewards Std             0.195623
exploration/Rewards Max            -0.00853843
exploration/Rewards Min            -1
exploration/Returns Mean          -11.6909
exploration/Returns Std             1.57449
exploration/Returns Max           -10.1164
exploration/Returns Min           -13.2654
exploration/Actions Mean            0.0428716
exploration/Actions Std             0.234766
exploration/Actions Max             0.997899
exploration/Actions Min            -0.477329
exploration/Num Paths               2
exploration/Average Returns       -11.6909
evaluation/num steps total     129000
evaluation/num paths total       1290
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0897542
evaluation/Rewards Std              0.167901
evaluation/Rewards Max             -0.0417621
evaluation/Rewards Min             -1
evaluation/Returns Mean            -8.97542
evaluation/Returns Std              2.56871
evaluation/Returns Max             -5.73092
evaluation/Returns Min            -14.3814
evaluation/Actions Mean             0.023979
evaluation/Actions Std              0.181949
evaluation/Actions Max              0.992375
evaluation/Actions Min             -0.979183
evaluation/Num Paths               10
evaluation/Average Returns         -8.97542
time/data storing (s)               0.00124786
time/evaluation sampling (s)        0.282429
time/exploration sampling (s)       0.0718383
time/logging (s)                    0.00359405
time/saving (s)                     0.00245144
time/training (s)                   1.12056
time/epoch (s)                      1.48212
time/total (s)                    195.78
Epoch                             128
-----------------------------  ---------------
2019-04-22 20:55:53.663618 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 129 finished
-----------------------------  ---------------
replay_buffer/size              26200
trainer/QF1 Loss                    0.00674213
trainer/QF2 Loss                    0.00717532
trainer/Policy Loss                 7.69966
trainer/Q1 Predictions Mean        -5.88421
trainer/Q1 Predictions Std          2.1646
trainer/Q1 Predictions Max         -4.96551
trainer/Q1 Predictions Min        -14.6669
trainer/Q2 Predictions Mean        -5.8828
trainer/Q2 Predictions Std          2.16575
trainer/Q2 Predictions Max         -4.95252
trainer/Q2 Predictions Min        -14.6954
trainer/Q Targets Mean             -5.88501
trainer/Q Targets Std               2.17187
trainer/Q Targets Max              -4.93226
trainer/Q Targets Min             -14.9418
trainer/Log Pis Mean                1.95632
trainer/Log Pis Std                 1.50109
trainer/Log Pis Max                 5.45927
trainer/Log Pis Min                -4.71625
trainer/Policy mu Mean              0.194204
trainer/Policy mu Std               0.840954
trainer/Policy mu Max               2.68919
trainer/Policy mu Min              -2.751
trainer/Policy log std Mean        -1.94849
trainer/Policy log std Std          0.603975
trainer/Policy log std Max         -0.387316
trainer/Policy log std Min         -2.52033
trainer/Alpha                       0.0174024
trainer/Alpha Loss                 -0.176961
exploration/num steps total     26200
exploration/num paths total       262
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.113347
exploration/Rewards Std             0.220906
exploration/Rewards Max            -0.00523349
exploration/Rewards Min            -1
exploration/Returns Mean          -11.3347
exploration/Returns Std             2.18168
exploration/Returns Max            -9.15298
exploration/Returns Min           -13.5163
exploration/Actions Mean            0.0287544
exploration/Actions Std             0.239896
exploration/Actions Max             0.998134
exploration/Actions Min            -0.862799
exploration/Num Paths               2
exploration/Average Returns       -11.3347
evaluation/num steps total     130000
evaluation/num paths total       1300
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0716812
evaluation/Rewards Std              0.19936
evaluation/Rewards Max             -0.0128695
evaluation/Rewards Min             -1
evaluation/Returns Mean            -7.16812
evaluation/Returns Std              3.22284
evaluation/Returns Max             -2.52903
evaluation/Returns Min            -11.9145
evaluation/Actions Mean             0.0326503
evaluation/Actions Std              0.192046
evaluation/Actions Max              0.991041
evaluation/Actions Min             -0.988491
evaluation/Num Paths               10
evaluation/Average Returns         -7.16812
time/data storing (s)               0.00142132
time/evaluation sampling (s)        0.29146
time/exploration sampling (s)       0.077736
time/logging (s)                    0.00353541
time/saving (s)                     0.00246603
time/training (s)                   1.0966
time/epoch (s)                      1.47322
time/total (s)                    197.258
Epoch                             129
-----------------------------  ---------------
2019-04-22 20:55:55.126370 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 130 finished
-----------------------------  ---------------
replay_buffer/size              26400
trainer/QF1 Loss                    0.485283
trainer/QF2 Loss                    0.486363
trainer/Policy Loss                 7.25362
trainer/Q1 Predictions Mean        -5.43297
trainer/Q1 Predictions Std          1.57262
trainer/Q1 Predictions Max         -4.93253
trainer/Q1 Predictions Min        -14.5503
trainer/Q2 Predictions Mean        -5.43485
trainer/Q2 Predictions Std          1.5771
trainer/Q2 Predictions Max         -4.91949
trainer/Q2 Predictions Min        -14.6162
trainer/Q Targets Mean             -5.35628
trainer/Q Targets Std               1.75973
trainer/Q Targets Max              -0.0386982
trainer/Q Targets Min             -14.8217
trainer/Log Pis Mean                1.94395
trainer/Log Pis Std                 1.07986
trainer/Log Pis Max                 4.70988
trainer/Log Pis Min                -1.37877
trainer/Policy mu Mean             -0.0126411
trainer/Policy mu Std               0.701518
trainer/Policy mu Max               2.59204
trainer/Policy mu Min              -2.74821
trainer/Policy log std Mean        -2.0175
trainer/Policy log std Std          0.484422
trainer/Policy log std Max         -0.476901
trainer/Policy log std Min         -2.49545
trainer/Alpha                       0.0169523
trainer/Alpha Loss                 -0.228513
exploration/num steps total     26400
exploration/num paths total       264
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.108869
exploration/Rewards Std             0.187348
exploration/Rewards Max            -0.00232185
exploration/Rewards Min            -1
exploration/Returns Mean          -10.8869
exploration/Returns Std             2.09107
exploration/Returns Max            -8.79586
exploration/Returns Min           -12.978
exploration/Actions Mean            0.0421098
exploration/Actions Std             0.235881
exploration/Actions Max             0.990597
exploration/Actions Min            -0.508417
exploration/Num Paths               2
exploration/Average Returns       -10.8869
evaluation/num steps total     131000
evaluation/num paths total       1310
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.07456
evaluation/Rewards Std              0.160305
evaluation/Rewards Max             -0.0432781
evaluation/Rewards Min             -1
evaluation/Returns Mean            -7.456
evaluation/Returns Std              2.63488
evaluation/Returns Max             -4.34045
evaluation/Returns Min            -12.5222
evaluation/Actions Mean             0.0213141
evaluation/Actions Std              0.162954
evaluation/Actions Max              0.989034
evaluation/Actions Min             -0.931816
evaluation/Num Paths               10
evaluation/Average Returns         -7.456
time/data storing (s)               0.00126883
time/evaluation sampling (s)        0.293471
time/exploration sampling (s)       0.0753587
time/logging (s)                    0.00344441
time/saving (s)                     0.00234139
time/training (s)                   1.07949
time/epoch (s)                      1.45538
time/total (s)                    198.718
Epoch                             130
-----------------------------  ---------------
2019-04-22 20:55:56.566467 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 131 finished
-----------------------------  ---------------
replay_buffer/size              26600
trainer/QF1 Loss                    0.242743
trainer/QF2 Loss                    0.244581
trainer/Policy Loss                 7.6922
trainer/Q1 Predictions Mean        -5.6578
trainer/Q1 Predictions Std          1.93718
trainer/Q1 Predictions Max         -4.8763
trainer/Q1 Predictions Min        -14.0143
trainer/Q2 Predictions Mean        -5.65641
trainer/Q2 Predictions Std          1.94155
trainer/Q2 Predictions Max         -4.87385
trainer/Q2 Predictions Min        -13.9733
trainer/Q Targets Mean             -5.64144
trainer/Q Targets Std               1.99605
trainer/Q Targets Max              -0.0160481
trainer/Q Targets Min             -13.9159
trainer/Log Pis Mean                2.18583
trainer/Log Pis Std                 1.22045
trainer/Log Pis Max                 6.60114
trainer/Log Pis Min                -2.11406
trainer/Policy mu Mean              0.177571
trainer/Policy mu Std               0.756169
trainer/Policy mu Max               2.68027
trainer/Policy mu Min              -2.00952
trainer/Policy log std Mean        -2.03876
trainer/Policy log std Std          0.514328
trainer/Policy log std Max         -0.497255
trainer/Policy log std Min         -2.52151
trainer/Alpha                       0.0171383
trainer/Alpha Loss                  0.755686
exploration/num steps total     26600
exploration/num paths total       266
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.112201
exploration/Rewards Std             0.209189
exploration/Rewards Max            -0.00270203
exploration/Rewards Min            -1
exploration/Returns Mean          -11.2201
exploration/Returns Std             4.05213
exploration/Returns Max            -7.16799
exploration/Returns Min           -15.2723
exploration/Actions Mean            0.0300389
exploration/Actions Std             0.241801
exploration/Actions Max             0.998471
exploration/Actions Min            -0.994177
exploration/Num Paths               2
exploration/Average Returns       -11.2201
evaluation/num steps total     132000
evaluation/num paths total       1320
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0822689
evaluation/Rewards Std              0.181998
evaluation/Rewards Max             -0.0417337
evaluation/Rewards Min             -1
evaluation/Returns Mean            -8.22689
evaluation/Returns Std              2.36486
evaluation/Returns Max             -4.76451
evaluation/Returns Min            -11.9961
evaluation/Actions Mean             0.0296216
evaluation/Actions Std              0.188762
evaluation/Actions Max              0.987408
evaluation/Actions Min             -0.952272
evaluation/Num Paths               10
evaluation/Average Returns         -8.22689
time/data storing (s)               0.00123505
time/evaluation sampling (s)        0.280644
time/exploration sampling (s)       0.0742396
time/logging (s)                    0.00371386
time/saving (s)                     0.00227617
time/training (s)                   1.07162
time/epoch (s)                      1.43373
time/total (s)                    200.156
Epoch                             131
-----------------------------  ---------------
2019-04-22 20:55:58.012088 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 132 finished
-----------------------------  ---------------
replay_buffer/size              26800
trainer/QF1 Loss                    0.235652
trainer/QF2 Loss                    0.236027
trainer/Policy Loss                 7.13895
trainer/Q1 Predictions Mean        -5.33009
trainer/Q1 Predictions Std          1.63036
trainer/Q1 Predictions Max         -4.81483
trainer/Q1 Predictions Min        -13.2257
trainer/Q2 Predictions Mean        -5.33091
trainer/Q2 Predictions Std          1.62956
trainer/Q2 Predictions Max         -4.81666
trainer/Q2 Predictions Min        -13.2904
trainer/Q Targets Mean             -5.34973
trainer/Q Targets Std               1.7006
trainer/Q Targets Max              -0.0535518
trainer/Q Targets Min             -13.0745
trainer/Log Pis Mean                1.93091
trainer/Log Pis Std                 1.17551
trainer/Log Pis Max                 4.85975
trainer/Log Pis Min                -2.53207
trainer/Policy mu Mean              0.0846494
trainer/Policy mu Std               0.601291
trainer/Policy mu Max               2.53603
trainer/Policy mu Min              -1.7188
trainer/Policy log std Mean        -2.16248
trainer/Policy log std Std          0.426105
trainer/Policy log std Max         -0.752095
trainer/Policy log std Min         -2.51616
trainer/Alpha                       0.0174504
trainer/Alpha Loss                 -0.279707
exploration/num steps total     26800
exploration/num paths total       268
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.135038
exploration/Rewards Std             0.231241
exploration/Rewards Max            -0.00992103
exploration/Rewards Min            -1
exploration/Returns Mean          -13.5038
exploration/Returns Std             0.357774
exploration/Returns Max           -13.146
exploration/Returns Min           -13.8615
exploration/Actions Mean            0.0240614
exploration/Actions Std             0.262139
exploration/Actions Max             0.996477
exploration/Actions Min            -0.994363
exploration/Num Paths               2
exploration/Average Returns       -13.5038
evaluation/num steps total     133000
evaluation/num paths total       1330
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.110937
evaluation/Rewards Std              0.203673
evaluation/Rewards Max             -0.0601367
evaluation/Rewards Min             -1
evaluation/Returns Mean           -11.0937
evaluation/Returns Std              2.88126
evaluation/Returns Max             -6.20356
evaluation/Returns Min            -14.1934
evaluation/Actions Mean             0.0286355
evaluation/Actions Std              0.194148
evaluation/Actions Max              0.989629
evaluation/Actions Min             -0.838197
evaluation/Num Paths               10
evaluation/Average Returns        -11.0937
time/data storing (s)               0.00135263
time/evaluation sampling (s)        0.284725
time/exploration sampling (s)       0.0748387
time/logging (s)                    0.00345093
time/saving (s)                     0.00204468
time/training (s)                   1.07202
time/epoch (s)                      1.43844
time/total (s)                    201.599
Epoch                             132
-----------------------------  ---------------
2019-04-22 20:55:59.462997 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 133 finished
-----------------------------  ---------------
replay_buffer/size              27000
trainer/QF1 Loss                    0.00254648
trainer/QF2 Loss                    0.00296801
trainer/Policy Loss                 6.9467
trainer/Q1 Predictions Mean        -5.17694
trainer/Q1 Predictions Std          0.925228
trainer/Q1 Predictions Max         -4.84594
trainer/Q1 Predictions Min        -11.4813
trainer/Q2 Predictions Mean        -5.17563
trainer/Q2 Predictions Std          0.911647
trainer/Q2 Predictions Max         -4.84751
trainer/Q2 Predictions Min        -11.469
trainer/Q Targets Mean             -5.20152
trainer/Q Targets Std               0.927874
trainer/Q Targets Max              -4.82266
trainer/Q Targets Min             -11.516
trainer/Log Pis Mean                1.84941
trainer/Log Pis Std                 1.15287
trainer/Log Pis Max                 5.67055
trainer/Log Pis Min                -2.33421
trainer/Policy mu Mean              0.0565069
trainer/Policy mu Std               0.656905
trainer/Policy mu Max               2.61077
trainer/Policy mu Min              -2.7416
trainer/Policy log std Mean        -1.97803
trainer/Policy log std Std          0.432074
trainer/Policy log std Max         -0.473352
trainer/Policy log std Min         -2.44752
trainer/Alpha                       0.0177878
trainer/Alpha Loss                 -0.606777
exploration/num steps total     27000
exploration/num paths total       270
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.0935872
exploration/Rewards Std             0.169527
exploration/Rewards Max            -0.00660332
exploration/Rewards Min            -1
exploration/Returns Mean           -9.35872
exploration/Returns Std             2.55528
exploration/Returns Max            -6.80343
exploration/Returns Min           -11.914
exploration/Actions Mean            0.0277069
exploration/Actions Std             0.219894
exploration/Actions Max             0.995303
exploration/Actions Min            -0.609091
exploration/Num Paths               2
exploration/Average Returns        -9.35872
evaluation/num steps total     134000
evaluation/num paths total       1340
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0702907
evaluation/Rewards Std              0.19681
evaluation/Rewards Max             -0.0173011
evaluation/Rewards Min             -1
evaluation/Returns Mean            -7.02907
evaluation/Returns Std              3.09571
evaluation/Returns Max             -2.54251
evaluation/Returns Min            -11.0729
evaluation/Actions Mean             0.0279628
evaluation/Actions Std              0.192091
evaluation/Actions Max              0.990855
evaluation/Actions Min             -0.993175
evaluation/Num Paths               10
evaluation/Average Returns         -7.02907
time/data storing (s)               0.00123225
time/evaluation sampling (s)        0.285499
time/exploration sampling (s)       0.0721264
time/logging (s)                    0.00352084
time/saving (s)                     0.0022353
time/training (s)                   1.07977
time/epoch (s)                      1.44438
time/total (s)                    203.048
Epoch                             133
-----------------------------  ---------------
2019-04-22 20:56:00.905399 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 134 finished
-----------------------------  ---------------
replay_buffer/size              27200
trainer/QF1 Loss                    0.227115
trainer/QF2 Loss                    0.227575
trainer/Policy Loss                 6.86407
trainer/Q1 Predictions Mean        -5.2319
trainer/Q1 Predictions Std          1.28546
trainer/Q1 Predictions Max         -4.85137
trainer/Q1 Predictions Min        -12.7664
trainer/Q2 Predictions Mean        -5.23057
trainer/Q2 Predictions Std          1.30103
trainer/Q2 Predictions Max         -4.84541
trainer/Q2 Predictions Min        -12.8288
trainer/Q Targets Mean             -5.17982
trainer/Q Targets Std               1.4122
trainer/Q Targets Max              -0.178134
trainer/Q Targets Min             -12.9266
trainer/Log Pis Mean                1.72802
trainer/Log Pis Std                 1.21851
trainer/Log Pis Max                 6.17519
trainer/Log Pis Min                -4.15548
trainer/Policy mu Mean              0.0669145
trainer/Policy mu Std               0.554228
trainer/Policy mu Max               2.74518
trainer/Policy mu Min              -1.82879
trainer/Policy log std Mean        -2.05549
trainer/Policy log std Std          0.403705
trainer/Policy log std Max         -0.480191
trainer/Policy log std Min         -2.44802
trainer/Alpha                       0.0175804
trainer/Alpha Loss                 -1.09898
exploration/num steps total     27200
exploration/num paths total       272
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.0944069
exploration/Rewards Std             0.140297
exploration/Rewards Max            -0.00254255
exploration/Rewards Min            -1
exploration/Returns Mean           -9.44069
exploration/Returns Std             2.39716
exploration/Returns Max            -7.04354
exploration/Returns Min           -11.8378
exploration/Actions Mean            0.0288474
exploration/Actions Std             0.210331
exploration/Actions Max             0.999421
exploration/Actions Min            -0.484528
exploration/Num Paths               2
exploration/Average Returns        -9.44069
evaluation/num steps total     135000
evaluation/num paths total       1350
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0845253
evaluation/Rewards Std              0.172117
evaluation/Rewards Max             -0.037512
evaluation/Rewards Min             -1
evaluation/Returns Mean            -8.45253
evaluation/Returns Std              2.30562
evaluation/Returns Max             -4.91832
evaluation/Returns Min            -12.6079
evaluation/Actions Mean             0.0188489
evaluation/Actions Std              0.189727
evaluation/Actions Max              0.991228
evaluation/Actions Min             -0.983292
evaluation/Num Paths               10
evaluation/Average Returns         -8.45253
time/data storing (s)               0.00128014
time/evaluation sampling (s)        0.281071
time/exploration sampling (s)       0.0738792
time/logging (s)                    0.00344346
time/saving (s)                     0.0022713
time/training (s)                   1.07343
time/epoch (s)                      1.43537
time/total (s)                    204.487
Epoch                             134
-----------------------------  ---------------
2019-04-22 20:56:02.376647 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 135 finished
-----------------------------  ---------------
replay_buffer/size              27400
trainer/QF1 Loss                    0.0232725
trainer/QF2 Loss                    0.0257208
trainer/Policy Loss                 7.23318
trainer/Q1 Predictions Mean        -5.15856
trainer/Q1 Predictions Std          1.44675
trainer/Q1 Predictions Max         -4.6471
trainer/Q1 Predictions Min        -13.2958
trainer/Q2 Predictions Mean        -5.1525
trainer/Q2 Predictions Std          1.44444
trainer/Q2 Predictions Max         -4.63899
trainer/Q2 Predictions Min        -13.2237
trainer/Q Targets Mean             -5.29743
trainer/Q Targets Std               1.45875
trainer/Q Targets Max              -4.76439
trainer/Q Targets Min             -13.529
trainer/Log Pis Mean                2.19946
trainer/Log Pis Std                 1.26242
trainer/Log Pis Max                 6.58407
trainer/Log Pis Min                -1.95493
trainer/Policy mu Mean              0.10619
trainer/Policy mu Std               0.698564
trainer/Policy mu Max               2.5919
trainer/Policy mu Min              -2.38045
trainer/Policy log std Mean        -2.10457
trainer/Policy log std Std          0.492499
trainer/Policy log std Max         -0.51353
trainer/Policy log std Min         -2.5517
trainer/Alpha                       0.0173781
trainer/Alpha Loss                  0.808373
exploration/num steps total     27400
exploration/num paths total       274
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.0748621
exploration/Rewards Std             0.137963
exploration/Rewards Max            -0.00556827
exploration/Rewards Min            -1
exploration/Returns Mean           -7.48621
exploration/Returns Std             1.47776
exploration/Returns Max            -6.00845
exploration/Returns Min            -8.96397
exploration/Actions Mean            0.0248245
exploration/Actions Std             0.192107
exploration/Actions Max             0.998433
exploration/Actions Min            -0.378074
exploration/Num Paths               2
exploration/Average Returns        -7.48621
evaluation/num steps total     136000
evaluation/num paths total       1360
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0670607
evaluation/Rewards Std              0.200466
evaluation/Rewards Max             -0.00776569
evaluation/Rewards Min             -1
evaluation/Returns Mean            -6.70607
evaluation/Returns Std              3.33387
evaluation/Returns Max             -2.10423
evaluation/Returns Min            -11.3139
evaluation/Actions Mean             0.0360854
evaluation/Actions Std              0.193811
evaluation/Actions Max              0.993845
evaluation/Actions Min             -0.846961
evaluation/Num Paths               10
evaluation/Average Returns         -6.70607
time/data storing (s)               0.00133958
time/evaluation sampling (s)        0.292217
time/exploration sampling (s)       0.0784824
time/logging (s)                    0.00358456
time/saving (s)                     0.00242929
time/training (s)                   1.08657
time/epoch (s)                      1.46463
time/total (s)                    205.956
Epoch                             135
-----------------------------  ---------------
2019-04-22 20:56:03.855155 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 136 finished
-----------------------------  ---------------
replay_buffer/size              27600
trainer/QF1 Loss                    0.463428
trainer/QF2 Loss                    0.461776
trainer/Policy Loss                 7.53755
trainer/Q1 Predictions Mean        -5.66206
trainer/Q1 Predictions Std          1.93457
trainer/Q1 Predictions Max         -4.74298
trainer/Q1 Predictions Min        -13.0893
trainer/Q2 Predictions Mean        -5.66706
trainer/Q2 Predictions Std          1.92201
trainer/Q2 Predictions Max         -4.76415
trainer/Q2 Predictions Min        -13.0143
trainer/Q Targets Mean             -5.57185
trainer/Q Targets Std               2.04313
trainer/Q Targets Max              -0.0165865
trainer/Q Targets Min             -12.7366
trainer/Log Pis Mean                2.03317
trainer/Log Pis Std                 1.35694
trainer/Log Pis Max                 6.2946
trainer/Log Pis Min                -2.37163
trainer/Policy mu Mean              0.167532
trainer/Policy mu Std               0.87339
trainer/Policy mu Max               2.74224
trainer/Policy mu Min              -2.33726
trainer/Policy log std Mean        -1.92106
trainer/Policy log std Std          0.594147
trainer/Policy log std Max         -0.429496
trainer/Policy log std Min         -2.49691
trainer/Alpha                       0.0175136
trainer/Alpha Loss                  0.134165
exploration/num steps total     27600
exploration/num paths total       276
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.0972179
exploration/Rewards Std             0.182803
exploration/Rewards Max            -0.00559966
exploration/Rewards Min            -1
exploration/Returns Mean           -9.72179
exploration/Returns Std             0.913394
exploration/Returns Max            -8.8084
exploration/Returns Min           -10.6352
exploration/Actions Mean           -0.0220507
exploration/Actions Std             0.229929
exploration/Actions Max             0.990792
exploration/Actions Min            -0.995707
exploration/Num Paths               2
exploration/Average Returns        -9.72179
evaluation/num steps total     137000
evaluation/num paths total       1370
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.072538
evaluation/Rewards Std              0.200432
evaluation/Rewards Max             -0.0255071
evaluation/Rewards Min             -1
evaluation/Returns Mean            -7.2538
evaluation/Returns Std              2.97789
evaluation/Returns Max             -2.56281
evaluation/Returns Min            -10.9165
evaluation/Actions Mean             0.0313959
evaluation/Actions Std              0.203568
evaluation/Actions Max              0.988566
evaluation/Actions Min             -0.97411
evaluation/Num Paths               10
evaluation/Average Returns         -7.2538
time/data storing (s)               0.00131873
time/evaluation sampling (s)        0.290529
time/exploration sampling (s)       0.0768627
time/logging (s)                    0.00348964
time/saving (s)                     0.00216586
time/training (s)                   1.0972
time/epoch (s)                      1.47156
time/total (s)                    207.432
Epoch                             136
-----------------------------  ---------------
2019-04-22 20:56:05.369434 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 137 finished
-----------------------------  ---------------
replay_buffer/size              27800
trainer/QF1 Loss                    0.639347
trainer/QF2 Loss                    0.650047
trainer/Policy Loss                 7.07601
trainer/Q1 Predictions Mean        -5.28625
trainer/Q1 Predictions Std          1.53799
trainer/Q1 Predictions Max         -4.76607
trainer/Q1 Predictions Min        -14.1842
trainer/Q2 Predictions Mean        -5.29169
trainer/Q2 Predictions Std          1.54707
trainer/Q2 Predictions Max         -4.75341
trainer/Q2 Predictions Min        -14.3597
trainer/Q Targets Mean             -5.20657
trainer/Q Targets Std               1.57316
trainer/Q Targets Max              -1
trainer/Q Targets Min             -14.1878
trainer/Log Pis Mean                1.89914
trainer/Log Pis Std                 1.43231
trainer/Log Pis Max                 6.42158
trainer/Log Pis Min                -2.91209
trainer/Policy mu Mean             -0.00115078
trainer/Policy mu Std               0.737863
trainer/Policy mu Max               2.53824
trainer/Policy mu Min              -2.91947
trainer/Policy log std Mean        -2.01208
trainer/Policy log std Std          0.503721
trainer/Policy log std Max         -0.471557
trainer/Policy log std Min         -2.47147
trainer/Alpha                       0.0172766
trainer/Alpha Loss                 -0.409329
exploration/num steps total     27800
exploration/num paths total       278
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.102854
exploration/Rewards Std             0.207621
exploration/Rewards Max            -0.00457308
exploration/Rewards Min            -1
exploration/Returns Mean          -10.2854
exploration/Returns Std             1.90347
exploration/Returns Max            -8.38193
exploration/Returns Min           -12.1889
exploration/Actions Mean            0.00751829
exploration/Actions Std             0.269057
exploration/Actions Max             0.998214
exploration/Actions Min            -0.987672
exploration/Num Paths               2
exploration/Average Returns       -10.2854
evaluation/num steps total     138000
evaluation/num paths total       1380
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0523188
evaluation/Rewards Std              0.189118
evaluation/Rewards Max             -0.00982993
evaluation/Rewards Min             -1
evaluation/Returns Mean            -5.23188
evaluation/Returns Std              3.09272
evaluation/Returns Max             -1.16216
evaluation/Returns Min             -9.91465
evaluation/Actions Mean             0.0206053
evaluation/Actions Std              0.185407
evaluation/Actions Max              0.989481
evaluation/Actions Min             -0.991093
evaluation/Num Paths               10
evaluation/Average Returns         -5.23188
time/data storing (s)               0.00132035
time/evaluation sampling (s)        0.293674
time/exploration sampling (s)       0.0772316
time/logging (s)                    0.00348291
time/saving (s)                     0.00253154
time/training (s)                   1.12985
time/epoch (s)                      1.50809
time/total (s)                    208.944
Epoch                             137
-----------------------------  ---------------
2019-04-22 20:56:06.902983 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 138 finished
-----------------------------  ---------------
replay_buffer/size              28000
trainer/QF1 Loss                    0.00445842
trainer/QF2 Loss                    0.00364974
trainer/Policy Loss                 7.2415
trainer/Q1 Predictions Mean        -5.26509
trainer/Q1 Predictions Std          1.59265
trainer/Q1 Predictions Max         -4.67479
trainer/Q1 Predictions Min        -12.831
trainer/Q2 Predictions Mean        -5.27539
trainer/Q2 Predictions Std          1.59858
trainer/Q2 Predictions Max         -4.67844
trainer/Q2 Predictions Min        -12.7607
trainer/Q Targets Mean             -5.30367
trainer/Q Targets Std               1.58185
trainer/Q Targets Max              -4.69013
trainer/Q Targets Min             -12.8289
trainer/Log Pis Mean                2.12545
trainer/Log Pis Std                 1.11037
trainer/Log Pis Max                 4.29681
trainer/Log Pis Min                -1.90828
trainer/Policy mu Mean              0.12275
trainer/Policy mu Std               0.685165
trainer/Policy mu Max               2.49586
trainer/Policy mu Min              -2.10689
trainer/Policy log std Mean        -2.07064
trainer/Policy log std Std          0.503285
trainer/Policy log std Max         -0.473484
trainer/Policy log std Min         -2.50126
trainer/Alpha                       0.0173983
trainer/Alpha Loss                  0.508242
exploration/num steps total     28000
exploration/num paths total       280
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.1023
exploration/Rewards Std             0.186559
exploration/Rewards Max            -0.00492117
exploration/Rewards Min            -1
exploration/Returns Mean          -10.23
exploration/Returns Std             1.16914
exploration/Returns Max            -9.06086
exploration/Returns Min           -11.3991
exploration/Actions Mean            0.0303042
exploration/Actions Std             0.252572
exploration/Actions Max             0.991237
exploration/Actions Min            -0.983827
exploration/Num Paths               2
exploration/Average Returns       -10.23
evaluation/num steps total     139000
evaluation/num paths total       1390
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.078587
evaluation/Rewards Std              0.187914
evaluation/Rewards Max             -0.0353792
evaluation/Rewards Min             -1
evaluation/Returns Mean            -7.8587
evaluation/Returns Std              2.7695
evaluation/Returns Max             -4.21815
evaluation/Returns Min            -12.7282
evaluation/Actions Mean             0.0214362
evaluation/Actions Std              0.202657
evaluation/Actions Max              0.990065
evaluation/Actions Min             -0.987853
evaluation/Num Paths               10
evaluation/Average Returns         -7.8587
time/data storing (s)               0.00136198
time/evaluation sampling (s)        0.310072
time/exploration sampling (s)       0.0789876
time/logging (s)                    0.00341128
time/saving (s)                     0.00234697
time/training (s)                   1.13048
time/epoch (s)                      1.52666
time/total (s)                    210.475
Epoch                             138
-----------------------------  ---------------
2019-04-22 20:56:08.426868 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 139 finished
-----------------------------  ---------------
replay_buffer/size              28200
trainer/QF1 Loss                    0.00802373
trainer/QF2 Loss                    0.00702854
trainer/Policy Loss                 7.20148
trainer/Q1 Predictions Mean        -5.16228
trainer/Q1 Predictions Std          1.55747
trainer/Q1 Predictions Max         -4.60635
trainer/Q1 Predictions Min        -14.3837
trainer/Q2 Predictions Mean        -5.15605
trainer/Q2 Predictions Std          1.54731
trainer/Q2 Predictions Max         -4.61178
trainer/Q2 Predictions Min        -14.3836
trainer/Q Targets Mean             -5.22376
trainer/Q Targets Std               1.53199
trainer/Q Targets Max              -4.64315
trainer/Q Targets Min             -14.5093
trainer/Log Pis Mean                2.16257
trainer/Log Pis Std                 0.923301
trainer/Log Pis Max                 4.67008
trainer/Log Pis Min                -0.715994
trainer/Policy mu Mean              0.113229
trainer/Policy mu Std               0.630252
trainer/Policy mu Max               2.66268
trainer/Policy mu Min              -2.27581
trainer/Policy log std Mean        -2.12499
trainer/Policy log std Std          0.448138
trainer/Policy log std Max         -0.462662
trainer/Policy log std Min         -2.46196
trainer/Alpha                       0.0176904
trainer/Alpha Loss                  0.655952
exploration/num steps total     28200
exploration/num paths total       282
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.0956868
exploration/Rewards Std             0.195307
exploration/Rewards Max            -0.00606474
exploration/Rewards Min            -1
exploration/Returns Mean           -9.56868
exploration/Returns Std             1.81777
exploration/Returns Max            -7.75091
exploration/Returns Min           -11.3864
exploration/Actions Mean            0.00574391
exploration/Actions Std             0.236637
exploration/Actions Max             0.99742
exploration/Actions Min            -0.992438
exploration/Num Paths               2
exploration/Average Returns        -9.56868
evaluation/num steps total     140000
evaluation/num paths total       1400
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0547234
evaluation/Rewards Std              0.190253
evaluation/Rewards Max             -0.0123332
evaluation/Rewards Min             -1
evaluation/Returns Mean            -5.47234
evaluation/Returns Std              3.58701
evaluation/Returns Max             -1.27466
evaluation/Returns Min            -10.3612
evaluation/Actions Mean             0.0278115
evaluation/Actions Std              0.186331
evaluation/Actions Max              0.989791
evaluation/Actions Min             -0.981478
evaluation/Num Paths               10
evaluation/Average Returns         -5.47234
time/data storing (s)               0.00122128
time/evaluation sampling (s)        0.292024
time/exploration sampling (s)       0.0791665
time/logging (s)                    0.00383459
time/saving (s)                     0.00222424
time/training (s)                   1.1389
time/epoch (s)                      1.51737
time/total (s)                    211.997
Epoch                             139
-----------------------------  ---------------
2019-04-22 20:56:09.970846 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 140 finished
-----------------------------  ---------------
replay_buffer/size              28400
trainer/QF1 Loss                    0.00765391
trainer/QF2 Loss                    0.00809587
trainer/Policy Loss                 7.08259
trainer/Q1 Predictions Mean        -5.17535
trainer/Q1 Predictions Std          1.40915
trainer/Q1 Predictions Max         -4.62393
trainer/Q1 Predictions Min        -12.7206
trainer/Q2 Predictions Mean        -5.18008
trainer/Q2 Predictions Std          1.40569
trainer/Q2 Predictions Max         -4.6392
trainer/Q2 Predictions Min        -12.7718
trainer/Q Targets Mean             -5.18279
trainer/Q Targets Std               1.37929
trainer/Q Targets Max              -4.61062
trainer/Q Targets Min             -12.7286
trainer/Log Pis Mean                2.02351
trainer/Log Pis Std                 1.32905
trainer/Log Pis Max                 5.73245
trainer/Log Pis Min                -4.1588
trainer/Policy mu Mean              0.15693
trainer/Policy mu Std               0.670392
trainer/Policy mu Max               2.54107
trainer/Policy mu Min              -1.77777
trainer/Policy log std Mean        -2.09597
trainer/Policy log std Std          0.475003
trainer/Policy log std Max         -0.46089
trainer/Policy log std Min         -2.46501
trainer/Alpha                       0.0177551
trainer/Alpha Loss                  0.0947583
exploration/num steps total     28400
exploration/num paths total       284
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.133744
exploration/Rewards Std             0.222266
exploration/Rewards Max            -0.00534551
exploration/Rewards Min            -1
exploration/Returns Mean          -13.3744
exploration/Returns Std             2.35785
exploration/Returns Max           -11.0165
exploration/Returns Min           -15.7322
exploration/Actions Mean            0.0190512
exploration/Actions Std             0.263923
exploration/Actions Max             0.99774
exploration/Actions Min            -0.988059
exploration/Num Paths               2
exploration/Average Returns       -13.3744
evaluation/num steps total     141000
evaluation/num paths total       1410
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.107881
evaluation/Rewards Std              0.196862
evaluation/Rewards Max             -0.0046123
evaluation/Rewards Min             -1
evaluation/Returns Mean           -10.7881
evaluation/Returns Std              2.99794
evaluation/Returns Max             -6.24459
evaluation/Returns Min            -14.125
evaluation/Actions Mean             0.035753
evaluation/Actions Std              0.190492
evaluation/Actions Max              0.988001
evaluation/Actions Min             -0.978939
evaluation/Num Paths               10
evaluation/Average Returns        -10.7881
time/data storing (s)               0.0013173
time/evaluation sampling (s)        0.297593
time/exploration sampling (s)       0.0724146
time/logging (s)                    0.00360514
time/saving (s)                     0.00247628
time/training (s)                   1.15938
time/epoch (s)                      1.53678
time/total (s)                    213.538
Epoch                             140
-----------------------------  ---------------
2019-04-22 20:56:11.531818 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 141 finished
-----------------------------  ---------------
replay_buffer/size              28600
trainer/QF1 Loss                    0.21296
trainer/QF2 Loss                    0.212536
trainer/Policy Loss                 7.2283
trainer/Q1 Predictions Mean        -5.13303
trainer/Q1 Predictions Std          1.84755
trainer/Q1 Predictions Max         -4.50929
trainer/Q1 Predictions Min        -13.4873
trainer/Q2 Predictions Mean        -5.13569
trainer/Q2 Predictions Std          1.84725
trainer/Q2 Predictions Max         -4.51062
trainer/Q2 Predictions Min        -13.4831
trainer/Q Targets Mean             -5.18973
trainer/Q Targets Std               1.93235
trainer/Q Targets Max              -0.068211
trainer/Q Targets Min             -13.6335
trainer/Log Pis Mean                2.20128
trainer/Log Pis Std                 1.05667
trainer/Log Pis Max                 4.34222
trainer/Log Pis Min                -3.01562
trainer/Policy mu Mean              0.0362153
trainer/Policy mu Std               0.695377
trainer/Policy mu Max               2.47061
trainer/Policy mu Min              -1.90365
trainer/Policy log std Mean        -2.09967
trainer/Policy log std Std          0.508967
trainer/Policy log std Max         -0.58305
trainer/Policy log std Min         -2.50416
trainer/Alpha                       0.0186456
trainer/Alpha Loss                  0.801578
exploration/num steps total     28600
exploration/num paths total       286
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.0702115
exploration/Rewards Std             0.0835584
exploration/Rewards Max            -0.00859935
exploration/Rewards Min            -1
exploration/Returns Mean           -7.02115
exploration/Returns Std             0.89892
exploration/Returns Max            -6.12223
exploration/Returns Min            -7.92007
exploration/Actions Mean            0.00422174
exploration/Actions Std             0.162523
exploration/Actions Max             0.974026
exploration/Actions Min            -0.994291
exploration/Num Paths               2
exploration/Average Returns        -7.02115
evaluation/num steps total     142000
evaluation/num paths total       1420
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.10849
evaluation/Rewards Std              0.23182
evaluation/Rewards Max             -0.0233242
evaluation/Rewards Min             -1
evaluation/Returns Mean           -10.849
evaluation/Returns Std              2.21171
evaluation/Returns Max             -7.02847
evaluation/Returns Min            -13.5897
evaluation/Actions Mean             0.0287053
evaluation/Actions Std              0.220218
evaluation/Actions Max              0.990744
evaluation/Actions Min             -0.993411
evaluation/Num Paths               10
evaluation/Average Returns        -10.849
time/data storing (s)               0.00129806
time/evaluation sampling (s)        0.307251
time/exploration sampling (s)       0.0844618
time/logging (s)                    0.00356494
time/saving (s)                     0.00268106
time/training (s)                   1.15429
time/epoch (s)                      1.55355
time/total (s)                    215.096
Epoch                             141
-----------------------------  ---------------
2019-04-22 20:56:13.031602 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 142 finished
-----------------------------  ----------------
replay_buffer/size              28800
trainer/QF1 Loss                    0.63517
trainer/QF2 Loss                    0.638072
trainer/Policy Loss                 7.03864
trainer/Q1 Predictions Mean        -5.08111
trainer/Q1 Predictions Std          1.58092
trainer/Q1 Predictions Max         -4.52763
trainer/Q1 Predictions Min        -14.0552
trainer/Q2 Predictions Mean        -5.07919
trainer/Q2 Predictions Std          1.58495
trainer/Q2 Predictions Max         -4.518
trainer/Q2 Predictions Min        -13.8966
trainer/Q Targets Mean             -4.99551
trainer/Q Targets Std               1.85721
trainer/Q Targets Max              -0.0534851
trainer/Q Targets Min             -14.3247
trainer/Log Pis Mean                2.09022
trainer/Log Pis Std                 0.936943
trainer/Log Pis Max                 5.00955
trainer/Log Pis Min                -0.890545
trainer/Policy mu Mean              0.150841
trainer/Policy mu Std               0.685
trainer/Policy mu Max               2.59386
trainer/Policy mu Min              -1.89936
trainer/Policy log std Mean        -2.00375
trainer/Policy log std Std          0.491815
trainer/Policy log std Max         -0.371026
trainer/Policy log std Min         -2.40909
trainer/Alpha                       0.0192076
trainer/Alpha Loss                  0.356597
exploration/num steps total     28800
exploration/num paths total       288
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.0808319
exploration/Rewards Std             0.142247
exploration/Rewards Max            -0.00443016
exploration/Rewards Min            -1
exploration/Returns Mean           -8.08319
exploration/Returns Std             1.79596
exploration/Returns Max            -6.28723
exploration/Returns Min            -9.87915
exploration/Actions Mean           -0.000222232
exploration/Actions Std             0.224122
exploration/Actions Max             0.996173
exploration/Actions Min            -0.988425
exploration/Num Paths               2
exploration/Average Returns        -8.08319
evaluation/num steps total     143000
evaluation/num paths total       1430
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0730278
evaluation/Rewards Std              0.183391
evaluation/Rewards Max             -0.027875
evaluation/Rewards Min             -1
evaluation/Returns Mean            -7.30278
evaluation/Returns Std              2.98398
evaluation/Returns Max             -3.37273
evaluation/Returns Min            -11.1464
evaluation/Actions Mean             0.0287006
evaluation/Actions Std              0.183501
evaluation/Actions Max              0.990091
evaluation/Actions Min             -0.851952
evaluation/Num Paths               10
evaluation/Average Returns         -7.30278
time/data storing (s)               0.00134908
time/evaluation sampling (s)        0.314247
time/exploration sampling (s)       0.0762108
time/logging (s)                    0.00321232
time/saving (s)                     0.010275
time/training (s)                   1.08734
time/epoch (s)                      1.49263
time/total (s)                    216.593
Epoch                             142
-----------------------------  ----------------
2019-04-22 20:56:14.587254 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 143 finished
-----------------------------  ---------------
replay_buffer/size              29000
trainer/QF1 Loss                    0.219409
trainer/QF2 Loss                    0.217619
trainer/Policy Loss                 6.32942
trainer/Q1 Predictions Mean        -4.82446
trainer/Q1 Predictions Std          1.24965
trainer/Q1 Predictions Max         -4.41365
trainer/Q1 Predictions Min        -12.2972
trainer/Q2 Predictions Mean        -4.82493
trainer/Q2 Predictions Std          1.22697
trainer/Q2 Predictions Max         -4.42324
trainer/Q2 Predictions Min        -12.0127
trainer/Q Targets Mean             -4.9019
trainer/Q Targets Std               1.30314
trainer/Q Targets Max              -0.371176
trainer/Q Targets Min             -12.0872
trainer/Log Pis Mean                1.60669
trainer/Log Pis Std                 1.42383
trainer/Log Pis Max                 6.36613
trainer/Log Pis Min                -4.0976
trainer/Policy mu Mean              0.0421881
trainer/Policy mu Std               0.607964
trainer/Policy mu Max               2.424
trainer/Policy mu Min              -2.90185
trainer/Policy log std Mean        -2.0439
trainer/Policy log std Std          0.4311
trainer/Policy log std Max         -0.488745
trainer/Policy log std Min         -2.42798
trainer/Alpha                       0.0187186
trainer/Alpha Loss                 -1.5646
exploration/num steps total     29000
exploration/num paths total       290
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.101018
exploration/Rewards Std             0.19267
exploration/Rewards Max            -0.00488704
exploration/Rewards Min            -1
exploration/Returns Mean          -10.1018
exploration/Returns Std             4.06664
exploration/Returns Max            -6.03517
exploration/Returns Min           -14.1684
exploration/Actions Mean            0.0375708
exploration/Actions Std             0.228388
exploration/Actions Max             0.997941
exploration/Actions Min            -0.631693
exploration/Num Paths               2
exploration/Average Returns       -10.1018
evaluation/num steps total     144000
evaluation/num paths total       1440
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0742362
evaluation/Rewards Std              0.202518
evaluation/Rewards Max             -0.0254242
evaluation/Rewards Min             -1
evaluation/Returns Mean            -7.42362
evaluation/Returns Std              2.47609
evaluation/Returns Max             -3.23674
evaluation/Returns Min            -10.4175
evaluation/Actions Mean             0.0359034
evaluation/Actions Std              0.198589
evaluation/Actions Max              0.98811
evaluation/Actions Min             -0.967463
evaluation/Num Paths               10
evaluation/Average Returns         -7.42362
time/data storing (s)               0.00147993
time/evaluation sampling (s)        0.308692
time/exploration sampling (s)       0.0774243
time/logging (s)                    0.00367761
time/saving (s)                     0.00265488
time/training (s)                   1.15533
time/epoch (s)                      1.54926
time/total (s)                    218.147
Epoch                             143
-----------------------------  ---------------
2019-04-22 20:56:16.119598 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 144 finished
-----------------------------  ----------------
replay_buffer/size              29200
trainer/QF1 Loss                    0.396711
trainer/QF2 Loss                    0.400198
trainer/Policy Loss                 6.63198
trainer/Q1 Predictions Mean        -4.91952
trainer/Q1 Predictions Std          1.1112
trainer/Q1 Predictions Max         -4.49781
trainer/Q1 Predictions Min        -11.9132
trainer/Q2 Predictions Mean        -4.92105
trainer/Q2 Predictions Std          1.10559
trainer/Q2 Predictions Max         -4.51007
trainer/Q2 Predictions Min        -11.9036
trainer/Q Targets Mean             -4.85445
trainer/Q Targets Std               1.3168
trainer/Q Targets Max              -0.0699014
trainer/Q Targets Min             -12.1013
trainer/Log Pis Mean                1.80596
trainer/Log Pis Std                 1.22203
trainer/Log Pis Max                 5.07123
trainer/Log Pis Min                -1.18268
trainer/Policy mu Mean              0.0474463
trainer/Policy mu Std               0.720657
trainer/Policy mu Max               2.4334
trainer/Policy mu Min              -2.44008
trainer/Policy log std Mean        -1.97115
trainer/Policy log std Std          0.500102
trainer/Policy log std Max         -0.554472
trainer/Policy log std Min         -2.44143
trainer/Alpha                       0.0183497
trainer/Alpha Loss                 -0.775746
exploration/num steps total     29200
exploration/num paths total       292
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.12526
exploration/Rewards Std             0.241022
exploration/Rewards Max            -0.000574469
exploration/Rewards Min            -1
exploration/Returns Mean          -12.526
exploration/Returns Std             2.14634
exploration/Returns Max           -10.3797
exploration/Returns Min           -14.6723
exploration/Actions Mean            0.0275038
exploration/Actions Std             0.266113
exploration/Actions Max             0.992109
exploration/Actions Min            -0.97211
exploration/Num Paths               2
exploration/Average Returns       -12.526
evaluation/num steps total     145000
evaluation/num paths total       1450
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0662166
evaluation/Rewards Std              0.189684
evaluation/Rewards Max             -0.0125335
evaluation/Rewards Min             -1
evaluation/Returns Mean            -6.62166
evaluation/Returns Std              2.87354
evaluation/Returns Max             -2.43846
evaluation/Returns Min            -10.557
evaluation/Actions Mean             0.0248645
evaluation/Actions Std              0.181329
evaluation/Actions Max              0.990661
evaluation/Actions Min             -0.991662
evaluation/Num Paths               10
evaluation/Average Returns         -6.62166
time/data storing (s)               0.00140269
time/evaluation sampling (s)        0.306873
time/exploration sampling (s)       0.082249
time/logging (s)                    0.00365148
time/saving (s)                     0.00220658
time/training (s)                   1.12849
time/epoch (s)                      1.52487
time/total (s)                    219.677
Epoch                             144
-----------------------------  ----------------
2019-04-22 20:56:17.644991 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 145 finished
-----------------------------  ---------------
replay_buffer/size              29400
trainer/QF1 Loss                    0.00872932
trainer/QF2 Loss                    0.0089206
trainer/Policy Loss                 6.79995
trainer/Q1 Predictions Mean        -4.73076
trainer/Q1 Predictions Std          0.868996
trainer/Q1 Predictions Max         -4.40331
trainer/Q1 Predictions Min        -11.4509
trainer/Q2 Predictions Mean        -4.73243
trainer/Q2 Predictions Std          0.874728
trainer/Q2 Predictions Max         -4.40768
trainer/Q2 Predictions Min        -11.4724
trainer/Q Targets Mean             -4.81286
trainer/Q Targets Std               0.885862
trainer/Q Targets Max              -4.45417
trainer/Q Targets Min             -11.6272
trainer/Log Pis Mean                2.12593
trainer/Log Pis Std                 1.00781
trainer/Log Pis Max                 6.52913
trainer/Log Pis Min                -0.77842
trainer/Policy mu Mean              0.161012
trainer/Policy mu Std               0.642812
trainer/Policy mu Max               2.62642
trainer/Policy mu Min              -1.51169
trainer/Policy log std Mean        -2.10986
trainer/Policy log std Std          0.450702
trainer/Policy log std Max         -0.579735
trainer/Policy log std Min         -2.48043
trainer/Alpha                       0.0180859
trainer/Alpha Loss                  0.505329
exploration/num steps total     29400
exploration/num paths total       294
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.112107
exploration/Rewards Std             0.232055
exploration/Rewards Max            -0.00270831
exploration/Rewards Min            -1
exploration/Returns Mean          -11.2107
exploration/Returns Std             2.64442
exploration/Returns Max            -8.56624
exploration/Returns Min           -13.8551
exploration/Actions Mean            0.0245357
exploration/Actions Std             0.257279
exploration/Actions Max             0.998325
exploration/Actions Min            -0.972816
exploration/Num Paths               2
exploration/Average Returns       -11.2107
evaluation/num steps total     146000
evaluation/num paths total       1460
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0620971
evaluation/Rewards Std              0.199054
evaluation/Rewards Max             -0.0151278
evaluation/Rewards Min             -1
evaluation/Returns Mean            -6.20971
evaluation/Returns Std              2.73258
evaluation/Returns Max             -1.67555
evaluation/Returns Min            -10.1675
evaluation/Actions Mean             0.0216096
evaluation/Actions Std              0.193176
evaluation/Actions Max              0.989861
evaluation/Actions Min             -0.992499
evaluation/Num Paths               10
evaluation/Average Returns         -6.20971
time/data storing (s)               0.00133987
time/evaluation sampling (s)        0.294242
time/exploration sampling (s)       0.072743
time/logging (s)                    0.00313497
time/saving (s)                     0.00256525
time/training (s)                   1.1431
time/epoch (s)                      1.51712
time/total (s)                    221.198
Epoch                             145
-----------------------------  ---------------
2019-04-22 20:56:19.129256 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 146 finished
-----------------------------  ---------------
replay_buffer/size              29600
trainer/QF1 Loss                    0.80117
trainer/QF2 Loss                    0.812529
trainer/Policy Loss                 6.85838
trainer/Q1 Predictions Mean        -4.96585
trainer/Q1 Predictions Std          1.42143
trainer/Q1 Predictions Max         -4.45254
trainer/Q1 Predictions Min        -12.5111
trainer/Q2 Predictions Mean        -4.97563
trainer/Q2 Predictions Std          1.40015
trainer/Q2 Predictions Max         -4.46607
trainer/Q2 Predictions Min        -12.3811
trainer/Q Targets Mean             -4.8009
trainer/Q Targets Std               1.70644
trainer/Q Targets Max              -0.0386982
trainer/Q Targets Min             -12.4159
trainer/Log Pis Mean                1.98094
trainer/Log Pis Std                 0.928415
trainer/Log Pis Max                 4.20593
trainer/Log Pis Min                -0.778705
trainer/Policy mu Mean              0.13014
trainer/Policy mu Std               0.755345
trainer/Policy mu Max               2.46271
trainer/Policy mu Min              -2.66938
trainer/Policy log std Mean        -1.93542
trainer/Policy log std Std          0.546211
trainer/Policy log std Max         -0.339152
trainer/Policy log std Min         -2.42825
trainer/Alpha                       0.0181493
trainer/Alpha Loss                 -0.0764103
exploration/num steps total     29600
exploration/num paths total       296
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.0556598
exploration/Rewards Std             0.058343
exploration/Rewards Max            -0.00300766
exploration/Rewards Min            -0.752698
exploration/Returns Mean           -5.56598
exploration/Returns Std             0.501881
exploration/Returns Max            -5.0641
exploration/Returns Min            -6.06787
exploration/Actions Mean            0.0148491
exploration/Actions Std             0.167953
exploration/Actions Max             0.984454
exploration/Actions Min            -0.374232
exploration/Num Paths               2
exploration/Average Returns        -5.56598
evaluation/num steps total     147000
evaluation/num paths total       1470
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0387836
evaluation/Rewards Std              0.15595
evaluation/Rewards Max             -0.00860108
evaluation/Rewards Min             -1
evaluation/Returns Mean            -3.87836
evaluation/Returns Std              2.79829
evaluation/Returns Max             -1.576
evaluation/Returns Min             -8.67281
evaluation/Actions Mean             0.0155954
evaluation/Actions Std              0.167438
evaluation/Actions Max              0.988108
evaluation/Actions Min             -0.987436
evaluation/Num Paths               10
evaluation/Average Returns         -3.87836
time/data storing (s)               0.00127388
time/evaluation sampling (s)        0.300686
time/exploration sampling (s)       0.0847321
time/logging (s)                    0.0033921
time/saving (s)                     0.00255118
time/training (s)                   1.08486
time/epoch (s)                      1.47749
time/total (s)                    222.68
Epoch                             146
-----------------------------  ---------------
2019-04-22 20:56:20.560132 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 147 finished
-----------------------------  ---------------
replay_buffer/size              29800
trainer/QF1 Loss                    0.461776
trainer/QF2 Loss                    0.457026
trainer/Policy Loss                 6.88882
trainer/Q1 Predictions Mean        -5.06624
trainer/Q1 Predictions Std          1.18989
trainer/Q1 Predictions Max         -4.59193
trainer/Q1 Predictions Min        -11.582
trainer/Q2 Predictions Mean        -5.05328
trainer/Q2 Predictions Std          1.18755
trainer/Q2 Predictions Max         -4.5813
trainer/Q2 Predictions Min        -11.7152
trainer/Q Targets Mean             -4.84147
trainer/Q Targets Std               1.42954
trainer/Q Targets Max              -0.0216859
trainer/Q Targets Min             -12.2376
trainer/Log Pis Mean                1.94518
trainer/Log Pis Std                 1.32499
trainer/Log Pis Max                 6.48661
trainer/Log Pis Min                -1.65325
trainer/Policy mu Mean              0.123553
trainer/Policy mu Std               0.774736
trainer/Policy mu Max               2.7131
trainer/Policy mu Min              -2.17647
trainer/Policy log std Mean        -1.9813
trainer/Policy log std Std          0.526351
trainer/Policy log std Max         -0.455308
trainer/Policy log std Min         -2.46307
trainer/Alpha                       0.0179921
trainer/Alpha Loss                 -0.220251
exploration/num steps total     29800
exploration/num paths total       298
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.113603
exploration/Rewards Std             0.223929
exploration/Rewards Max            -0.00214813
exploration/Rewards Min            -1
exploration/Returns Mean          -11.3603
exploration/Returns Std             0.579982
exploration/Returns Max           -10.7803
exploration/Returns Min           -11.9403
exploration/Actions Mean            0.0465499
exploration/Actions Std             0.257605
exploration/Actions Max             0.994529
exploration/Actions Min            -0.764149
exploration/Num Paths               2
exploration/Average Returns       -11.3603
evaluation/num steps total     148000
evaluation/num paths total       1480
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0461235
evaluation/Rewards Std              0.187119
evaluation/Rewards Max             -0.00160534
evaluation/Rewards Min             -1
evaluation/Returns Mean            -4.61235
evaluation/Returns Std              2.89718
evaluation/Returns Max             -0.773744
evaluation/Returns Min             -9.43314
evaluation/Actions Mean             0.0278429
evaluation/Actions Std              0.194229
evaluation/Actions Max              0.991926
evaluation/Actions Min             -0.977477
evaluation/Num Paths               10
evaluation/Average Returns         -4.61235
time/data storing (s)               0.00145363
time/evaluation sampling (s)        0.281946
time/exploration sampling (s)       0.0754097
time/logging (s)                    0.00391576
time/saving (s)                     0.00235706
time/training (s)                   1.05963
time/epoch (s)                      1.42471
time/total (s)                    224.109
Epoch                             147
-----------------------------  ---------------
2019-04-22 20:56:22.007383 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 148 finished
-----------------------------  ---------------
replay_buffer/size              30000
trainer/QF1 Loss                    0.197234
trainer/QF2 Loss                    0.195822
trainer/Policy Loss                 6.94903
trainer/Q1 Predictions Mean        -4.95062
trainer/Q1 Predictions Std          1.56435
trainer/Q1 Predictions Max         -4.32938
trainer/Q1 Predictions Min        -12.5892
trainer/Q2 Predictions Mean        -4.9437
trainer/Q2 Predictions Std          1.557
trainer/Q2 Predictions Max         -4.33142
trainer/Q2 Predictions Min        -12.653
trainer/Q Targets Mean             -4.96701
trainer/Q Targets Std               1.59448
trainer/Q Targets Max              -0.102638
trainer/Q Targets Min             -12.6433
trainer/Log Pis Mean                2.09627
trainer/Log Pis Std                 1.40017
trainer/Log Pis Max                 6.90136
trainer/Log Pis Min                -1.42575
trainer/Policy mu Mean              0.156323
trainer/Policy mu Std               0.753402
trainer/Policy mu Max               2.56304
trainer/Policy mu Min              -2.51501
trainer/Policy log std Mean        -2.09919
trainer/Policy log std Std          0.520678
trainer/Policy log std Max         -0.401619
trainer/Policy log std Min         -2.5167
trainer/Alpha                       0.0180061
trainer/Alpha Loss                  0.386742
exploration/num steps total     30000
exploration/num paths total       300
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.0893148
exploration/Rewards Std             0.181919
exploration/Rewards Max            -0.00660801
exploration/Rewards Min            -1
exploration/Returns Mean           -8.93148
exploration/Returns Std             3.24593
exploration/Returns Max            -5.68555
exploration/Returns Min           -12.1774
exploration/Actions Mean            0.0242288
exploration/Actions Std             0.222141
exploration/Actions Max             0.995978
exploration/Actions Min            -0.995669
exploration/Num Paths               2
exploration/Average Returns        -8.93148
evaluation/num steps total     149000
evaluation/num paths total       1490
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0614558
evaluation/Rewards Std              0.207071
evaluation/Rewards Max             -0.00765875
evaluation/Rewards Min             -1
evaluation/Returns Mean            -6.14558
evaluation/Returns Std              2.71299
evaluation/Returns Max             -1.15701
evaluation/Returns Min             -9.55072
evaluation/Actions Mean             0.0324479
evaluation/Actions Std              0.203347
evaluation/Actions Max              0.990297
evaluation/Actions Min             -0.991649
evaluation/Num Paths               10
evaluation/Average Returns         -6.14558
time/data storing (s)               0.00127116
time/evaluation sampling (s)        0.280444
time/exploration sampling (s)       0.0733433
time/logging (s)                    0.0034949
time/saving (s)                     0.00246418
time/training (s)                   1.07886
time/epoch (s)                      1.43988
time/total (s)                    225.553
Epoch                             148
-----------------------------  ---------------
2019-04-22 20:56:23.473194 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 149 finished
-----------------------------  ---------------
replay_buffer/size              30200
trainer/QF1 Loss                    0.197761
trainer/QF2 Loss                    0.19727
trainer/Policy Loss                 6.77862
trainer/Q1 Predictions Mean        -5.07508
trainer/Q1 Predictions Std          1.92698
trainer/Q1 Predictions Max         -4.37421
trainer/Q1 Predictions Min        -13.2814
trainer/Q2 Predictions Mean        -5.08088
trainer/Q2 Predictions Std          1.91323
trainer/Q2 Predictions Max         -4.3846
trainer/Q2 Predictions Min        -13.1576
trainer/Q Targets Mean             -5.03589
trainer/Q Targets Std               1.91745
trainer/Q Targets Max              -0.0612963
trainer/Q Targets Min             -12.827
trainer/Log Pis Mean                1.83137
trainer/Log Pis Std                 1.33165
trainer/Log Pis Max                 6.0587
trainer/Log Pis Min                -2.9959
trainer/Policy mu Mean              0.111231
trainer/Policy mu Std               0.688265
trainer/Policy mu Max               2.55289
trainer/Policy mu Min              -2.99133
trainer/Policy log std Mean        -2.05307
trainer/Policy log std Std          0.503485
trainer/Policy log std Max         -0.402935
trainer/Policy log std Min         -2.44231
trainer/Alpha                       0.0186228
trainer/Alpha Loss                 -0.671707
exploration/num steps total     30200
exploration/num paths total       302
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.114146
exploration/Rewards Std             0.207806
exploration/Rewards Max            -0.00321516
exploration/Rewards Min            -1
exploration/Returns Mean          -11.4146
exploration/Returns Std             1.50723
exploration/Returns Max            -9.90733
exploration/Returns Min           -12.9218
exploration/Actions Mean            0.0546508
exploration/Actions Std             0.256171
exploration/Actions Max             0.996703
exploration/Actions Min            -0.41689
exploration/Num Paths               2
exploration/Average Returns       -11.4146
evaluation/num steps total     150000
evaluation/num paths total       1500
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0609153
evaluation/Rewards Std              0.150454
evaluation/Rewards Max             -0.00761721
evaluation/Rewards Min             -1
evaluation/Returns Mean            -6.09153
evaluation/Returns Std              2.77025
evaluation/Returns Max             -3.31616
evaluation/Returns Min            -11.106
evaluation/Actions Mean             0.0120782
evaluation/Actions Std              0.162826
evaluation/Actions Max              0.9866
evaluation/Actions Min             -0.985592
evaluation/Num Paths               10
evaluation/Average Returns         -6.09153
time/data storing (s)               0.00127041
time/evaluation sampling (s)        0.286149
time/exploration sampling (s)       0.0762321
time/logging (s)                    0.00352289
time/saving (s)                     0.00245681
time/training (s)                   1.08866
time/epoch (s)                      1.4583
time/total (s)                    227.017
Epoch                             149
-----------------------------  ---------------
2019-04-22 20:56:24.949534 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 150 finished
-----------------------------  ---------------
replay_buffer/size              30400
trainer/QF1 Loss                    0.202456
trainer/QF2 Loss                    0.206354
trainer/Policy Loss                 7.1761
trainer/Q1 Predictions Mean        -5.20665
trainer/Q1 Predictions Std          2.17385
trainer/Q1 Predictions Max         -4.24538
trainer/Q1 Predictions Min        -13.825
trainer/Q2 Predictions Mean        -5.19743
trainer/Q2 Predictions Std          2.14989
trainer/Q2 Predictions Max         -4.24288
trainer/Q2 Predictions Min        -13.59
trainer/Q Targets Mean             -5.29753
trainer/Q Targets Std               2.23533
trainer/Q Targets Max              -0.0650686
trainer/Q Targets Min             -13.9143
trainer/Log Pis Mean                2.11407
trainer/Log Pis Std                 1.45727
trainer/Log Pis Max                 6.73636
trainer/Log Pis Min                -4.03699
trainer/Policy mu Mean              0.213857
trainer/Policy mu Std               0.846048
trainer/Policy mu Max               2.52836
trainer/Policy mu Min              -2.58738
trainer/Policy log std Mean        -1.95095
trainer/Policy log std Std          0.599806
trainer/Policy log std Max         -0.442206
trainer/Policy log std Min         -2.46541
trainer/Alpha                       0.0182838
trainer/Alpha Loss                  0.456476
exploration/num steps total     30400
exploration/num paths total       304
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.141836
exploration/Rewards Std             0.254162
exploration/Rewards Max            -0.00464959
exploration/Rewards Min            -1
exploration/Returns Mean          -14.1836
exploration/Returns Std             0.0078166
exploration/Returns Max           -14.1758
exploration/Returns Min           -14.1915
exploration/Actions Mean            0.0463336
exploration/Actions Std             0.258564
exploration/Actions Max             0.996502
exploration/Actions Min            -0.618239
exploration/Num Paths               2
exploration/Average Returns       -14.1836
evaluation/num steps total     151000
evaluation/num paths total       1510
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0923391
evaluation/Rewards Std              0.215267
evaluation/Rewards Max             -0.03528
evaluation/Rewards Min             -1
evaluation/Returns Mean            -9.23391
evaluation/Returns Std              2.07317
evaluation/Returns Max             -5.06518
evaluation/Returns Min            -12.4013
evaluation/Actions Mean             0.0253832
evaluation/Actions Std              0.216432
evaluation/Actions Max              0.990182
evaluation/Actions Min             -0.984114
evaluation/Num Paths               10
evaluation/Average Returns         -9.23391
time/data storing (s)               0.00128941
time/evaluation sampling (s)        0.297026
time/exploration sampling (s)       0.0788435
time/logging (s)                    0.00358489
time/saving (s)                     0.00258648
time/training (s)                   1.08559
time/epoch (s)                      1.46892
time/total (s)                    228.49
Epoch                             150
-----------------------------  ---------------
2019-04-22 20:56:26.432997 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 151 finished
-----------------------------  ---------------
replay_buffer/size              30600
trainer/QF1 Loss                    0.366431
trainer/QF2 Loss                    0.365201
trainer/Policy Loss                 6.53662
trainer/Q1 Predictions Mean        -4.60613
trainer/Q1 Predictions Std          1.10052
trainer/Q1 Predictions Max         -4.2777
trainer/Q1 Predictions Min        -12.7303
trainer/Q2 Predictions Mean        -4.6144
trainer/Q2 Predictions Std          1.11612
trainer/Q2 Predictions Max         -4.28585
trainer/Q2 Predictions Min        -12.8688
trainer/Q Targets Mean             -4.58987
trainer/Q Targets Std               1.29967
trainer/Q Targets Max              -0.0889586
trainer/Q Targets Min             -13.0178
trainer/Log Pis Mean                1.9966
trainer/Log Pis Std                 1.16583
trainer/Log Pis Max                 4.75664
trainer/Log Pis Min                -1.34517
trainer/Policy mu Mean              0.129295
trainer/Policy mu Std               0.49313
trainer/Policy mu Max               2.88214
trainer/Policy mu Min              -0.915589
trainer/Policy log std Mean        -2.27073
trainer/Policy log std Std          0.388105
trainer/Policy log std Max         -0.417473
trainer/Policy log std Min         -2.54185
trainer/Alpha                       0.0188852
trainer/Alpha Loss                 -0.0134788
exploration/num steps total     30600
exploration/num paths total       306
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.107668
exploration/Rewards Std             0.203522
exploration/Rewards Max            -0.00148463
exploration/Rewards Min            -1
exploration/Returns Mean          -10.7668
exploration/Returns Std             2.62253
exploration/Returns Max            -8.14426
exploration/Returns Min           -13.3893
exploration/Actions Mean            0.0140601
exploration/Actions Std             0.237563
exploration/Actions Max             0.997149
exploration/Actions Min            -0.994693
exploration/Num Paths               2
exploration/Average Returns       -10.7668
evaluation/num steps total     152000
evaluation/num paths total       1520
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0772658
evaluation/Rewards Std              0.173189
evaluation/Rewards Max             -0.0357714
evaluation/Rewards Min             -1
evaluation/Returns Mean            -7.72658
evaluation/Returns Std              2.49644
evaluation/Returns Max             -4.48841
evaluation/Returns Min            -12.8435
evaluation/Actions Mean             0.0255566
evaluation/Actions Std              0.184886
evaluation/Actions Max              0.991883
evaluation/Actions Min             -0.975766
evaluation/Num Paths               10
evaluation/Average Returns         -7.72658
time/data storing (s)               0.00130297
time/evaluation sampling (s)        0.280376
time/exploration sampling (s)       0.0714346
time/logging (s)                    0.00285307
time/saving (s)                     0.00271708
time/training (s)                   1.11702
time/epoch (s)                      1.47571
time/total (s)                    229.97
Epoch                             151
-----------------------------  ---------------
2019-04-22 20:56:27.898249 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 152 finished
-----------------------------  ---------------
replay_buffer/size              30800
trainer/QF1 Loss                    0.367604
trainer/QF2 Loss                    0.370213
trainer/Policy Loss                 6.98208
trainer/Q1 Predictions Mean        -4.91782
trainer/Q1 Predictions Std          1.7479
trainer/Q1 Predictions Max         -4.26315
trainer/Q1 Predictions Min        -13.1013
trainer/Q2 Predictions Mean        -4.92005
trainer/Q2 Predictions Std          1.74633
trainer/Q2 Predictions Max         -4.2747
trainer/Q2 Predictions Min        -13.144
trainer/Q Targets Mean             -4.87144
trainer/Q Targets Std               1.83807
trainer/Q Targets Max              -0.10811
trainer/Q Targets Min             -13.0385
trainer/Log Pis Mean                2.18302
trainer/Log Pis Std                 1.03387
trainer/Log Pis Max                 6.00788
trainer/Log Pis Min                -0.415869
trainer/Policy mu Mean              0.106008
trainer/Policy mu Std               0.6899
trainer/Policy mu Max               2.5844
trainer/Policy mu Min              -2.49083
trainer/Policy log std Mean        -2.12071
trainer/Policy log std Std          0.476073
trainer/Policy log std Max         -0.569294
trainer/Policy log std Min         -2.4705
trainer/Alpha                       0.0191307
trainer/Alpha Loss                  0.724102
exploration/num steps total     30800
exploration/num paths total       308
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.0624271
exploration/Rewards Std             0.0842312
exploration/Rewards Max            -0.00295437
exploration/Rewards Min            -1
exploration/Returns Mean           -6.24271
exploration/Returns Std             1.01532
exploration/Returns Max            -5.22738
exploration/Returns Min            -7.25803
exploration/Actions Mean           -0.00211598
exploration/Actions Std             0.180553
exploration/Actions Max             0.995921
exploration/Actions Min            -0.987593
exploration/Num Paths               2
exploration/Average Returns        -6.24271
evaluation/num steps total     153000
evaluation/num paths total       1530
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0637441
evaluation/Rewards Std              0.159783
evaluation/Rewards Max             -0.0145939
evaluation/Rewards Min             -1
evaluation/Returns Mean            -6.37441
evaluation/Returns Std              1.58104
evaluation/Returns Max             -3.9702
evaluation/Returns Min             -9.36151
evaluation/Actions Mean             0.0182714
evaluation/Actions Std              0.186829
evaluation/Actions Max              0.989463
evaluation/Actions Min             -0.98865
evaluation/Num Paths               10
evaluation/Average Returns         -6.37441
time/data storing (s)               0.00126042
time/evaluation sampling (s)        0.290022
time/exploration sampling (s)       0.07518
time/logging (s)                    0.00351875
time/saving (s)                     0.00242354
time/training (s)                   1.08663
time/epoch (s)                      1.45903
time/total (s)                    231.433
Epoch                             152
-----------------------------  ---------------
2019-04-22 20:56:29.383312 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 153 finished
-----------------------------  ---------------
replay_buffer/size              31000
trainer/QF1 Loss                    0.191892
trainer/QF2 Loss                    0.189003
trainer/Policy Loss                 6.66573
trainer/Q1 Predictions Mean        -5.04587
trainer/Q1 Predictions Std          1.98933
trainer/Q1 Predictions Max         -4.31843
trainer/Q1 Predictions Min        -13.6674
trainer/Q2 Predictions Mean        -5.04519
trainer/Q2 Predictions Std          1.96854
trainer/Q2 Predictions Max         -4.32408
trainer/Q2 Predictions Min        -13.4462
trainer/Q Targets Mean             -4.96786
trainer/Q Targets Std               1.99158
trainer/Q Targets Max              -0.0773518
trainer/Q Targets Min             -13.3161
trainer/Log Pis Mean                1.69848
trainer/Log Pis Std                 1.27893
trainer/Log Pis Max                 6.52504
trainer/Log Pis Min                -2.90342
trainer/Policy mu Mean              0.0226518
trainer/Policy mu Std               0.749379
trainer/Policy mu Max               2.46727
trainer/Policy mu Min              -2.53708
trainer/Policy log std Mean        -1.92126
trainer/Policy log std Std          0.512475
trainer/Policy log std Max         -0.561433
trainer/Policy log std Min         -2.33395
trainer/Alpha                       0.0189851
trainer/Alpha Loss                 -1.19519
exploration/num steps total     31000
exploration/num paths total       310
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.120363
exploration/Rewards Std             0.207491
exploration/Rewards Max            -0.0067382
exploration/Rewards Min            -1
exploration/Returns Mean          -12.0363
exploration/Returns Std             1.74641
exploration/Returns Max           -10.2899
exploration/Returns Min           -13.7827
exploration/Actions Mean            0.0275358
exploration/Actions Std             0.268166
exploration/Actions Max             0.996946
exploration/Actions Min            -0.99421
exploration/Num Paths               2
exploration/Average Returns       -12.0363
evaluation/num steps total     154000
evaluation/num paths total       1540
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.095323
evaluation/Rewards Std              0.213445
evaluation/Rewards Max             -0.0352787
evaluation/Rewards Min             -1
evaluation/Returns Mean            -9.5323
evaluation/Returns Std              2.54218
evaluation/Returns Max             -4.04734
evaluation/Returns Min            -12.775
evaluation/Actions Mean             0.0386481
evaluation/Actions Std              0.196506
evaluation/Actions Max              0.987518
evaluation/Actions Min             -0.854751
evaluation/Num Paths               10
evaluation/Average Returns         -9.5323
time/data storing (s)               0.00126464
time/evaluation sampling (s)        0.285631
time/exploration sampling (s)       0.0752826
time/logging (s)                    0.00371553
time/saving (s)                     0.00256315
time/training (s)                   1.10971
time/epoch (s)                      1.47816
time/total (s)                    232.916
Epoch                             153
-----------------------------  ---------------
2019-04-22 20:56:30.842607 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 154 finished
-----------------------------  ---------------
replay_buffer/size              31200
trainer/QF1 Loss                    0.178586
trainer/QF2 Loss                    0.179145
trainer/Policy Loss                 6.62297
trainer/Q1 Predictions Mean        -4.73176
trainer/Q1 Predictions Std          1.40868
trainer/Q1 Predictions Max         -4.24888
trainer/Q1 Predictions Min        -12.2897
trainer/Q2 Predictions Mean        -4.73215
trainer/Q2 Predictions Std          1.39793
trainer/Q2 Predictions Max         -4.2596
trainer/Q2 Predictions Min        -12.2148
trainer/Q Targets Mean             -4.72132
trainer/Q Targets Std               1.47771
trainer/Q Targets Max              -0.0965819
trainer/Q Targets Min             -12.1939
trainer/Log Pis Mean                1.97816
trainer/Log Pis Std                 1.14174
trainer/Log Pis Max                 5.01468
trainer/Log Pis Min                -3.09084
trainer/Policy mu Mean              0.0659014
trainer/Policy mu Std               0.65898
trainer/Policy mu Max               2.57935
trainer/Policy mu Min              -2.61751
trainer/Policy log std Mean        -2.06993
trainer/Policy log std Std          0.462313
trainer/Policy log std Max         -0.402486
trainer/Policy log std Min         -2.44422
trainer/Alpha                       0.0185527
trainer/Alpha Loss                 -0.0870748
exploration/num steps total     31200
exploration/num paths total       312
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.10642
exploration/Rewards Std             0.207626
exploration/Rewards Max            -0.00406219
exploration/Rewards Min            -1
exploration/Returns Mean          -10.642
exploration/Returns Std             1.62522
exploration/Returns Max            -9.01677
exploration/Returns Min           -12.2672
exploration/Actions Mean            0.058007
exploration/Actions Std             0.256406
exploration/Actions Max             0.998834
exploration/Actions Min            -0.332606
exploration/Num Paths               2
exploration/Average Returns       -10.642
evaluation/num steps total     155000
evaluation/num paths total       1550
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0587879
evaluation/Rewards Std              0.167755
evaluation/Rewards Max             -0.0239599
evaluation/Rewards Min             -1
evaluation/Returns Mean            -5.87879
evaluation/Returns Std              2.80492
evaluation/Returns Max             -2.56588
evaluation/Returns Min            -11.2294
evaluation/Actions Mean             0.0257703
evaluation/Actions Std              0.176851
evaluation/Actions Max              0.993525
evaluation/Actions Min             -0.981516
evaluation/Num Paths               10
evaluation/Average Returns         -5.87879
time/data storing (s)               0.00124383
time/evaluation sampling (s)        0.28914
time/exploration sampling (s)       0.0750365
time/logging (s)                    0.00342743
time/saving (s)                     0.00233188
time/training (s)                   1.08104
time/epoch (s)                      1.45222
time/total (s)                    234.372
Epoch                             154
-----------------------------  ---------------
2019-04-22 20:56:32.337913 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 155 finished
-----------------------------  ---------------
replay_buffer/size              31400
trainer/QF1 Loss                    0.370591
trainer/QF2 Loss                    0.374347
trainer/Policy Loss                 7.05806
trainer/Q1 Predictions Mean        -5.00653
trainer/Q1 Predictions Std          1.87968
trainer/Q1 Predictions Max         -4.26441
trainer/Q1 Predictions Min        -13.7294
trainer/Q2 Predictions Mean        -4.99806
trainer/Q2 Predictions Std          1.86452
trainer/Q2 Predictions Max         -4.27736
trainer/Q2 Predictions Min        -13.7827
trainer/Q Targets Mean             -4.89084
trainer/Q Targets Std               1.98124
trainer/Q Targets Max              -0.0519219
trainer/Q Targets Min             -13.8012
trainer/Log Pis Mean                2.19833
trainer/Log Pis Std                 1.13228
trainer/Log Pis Max                 6.18341
trainer/Log Pis Min                -1.56806
trainer/Policy mu Mean              0.237916
trainer/Policy mu Std               0.727183
trainer/Policy mu Max               2.59535
trainer/Policy mu Min              -2.46482
trainer/Policy log std Mean        -2.11179
trainer/Policy log std Std          0.566967
trainer/Policy log std Max         -0.394589
trainer/Policy log std Min         -2.51269
trainer/Alpha                       0.0184212
trainer/Alpha Loss                  0.792214
exploration/num steps total     31400
exploration/num paths total       314
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.109683
exploration/Rewards Std             0.228676
exploration/Rewards Max            -0.00418288
exploration/Rewards Min            -1
exploration/Returns Mean          -10.9683
exploration/Returns Std             2.08768
exploration/Returns Max            -8.88067
exploration/Returns Min           -13.056
exploration/Actions Mean            0.0358957
exploration/Actions Std             0.255084
exploration/Actions Max             0.994869
exploration/Actions Min            -0.977573
exploration/Num Paths               2
exploration/Average Returns       -10.9683
evaluation/num steps total     156000
evaluation/num paths total       1560
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0680214
evaluation/Rewards Std              0.215625
evaluation/Rewards Max             -0.0134041
evaluation/Rewards Min             -1
evaluation/Returns Mean            -6.80214
evaluation/Returns Std              1.91817
evaluation/Returns Max             -3.40387
evaluation/Returns Min             -9.29041
evaluation/Actions Mean             0.0388953
evaluation/Actions Std              0.204159
evaluation/Actions Max              0.98951
evaluation/Actions Min             -0.969176
evaluation/Num Paths               10
evaluation/Average Returns         -6.80214
time/data storing (s)               0.00147615
time/evaluation sampling (s)        0.281085
time/exploration sampling (s)       0.0714616
time/logging (s)                    0.00324824
time/saving (s)                     0.00237247
time/training (s)                   1.12834
time/epoch (s)                      1.48799
time/total (s)                    235.865
Epoch                             155
-----------------------------  ---------------
2019-04-22 20:56:33.789547 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 156 finished
-----------------------------  ---------------
replay_buffer/size              31600
trainer/QF1 Loss                    0.369688
trainer/QF2 Loss                    0.367838
trainer/Policy Loss                 6.65253
trainer/Q1 Predictions Mean        -4.71092
trainer/Q1 Predictions Std          1.56016
trainer/Q1 Predictions Max         -4.20526
trainer/Q1 Predictions Min        -13.2754
trainer/Q2 Predictions Mean        -4.71218
trainer/Q2 Predictions Std          1.5651
trainer/Q2 Predictions Max         -4.20472
trainer/Q2 Predictions Min        -13.2966
trainer/Q Targets Mean             -4.66291
trainer/Q Targets Std               1.7268
trainer/Q Targets Max              -0.0464777
trainer/Q Targets Min             -13.5459
trainer/Log Pis Mean                2.04788
trainer/Log Pis Std                 1.21593
trainer/Log Pis Max                 6.0581
trainer/Log Pis Min                -2.75586
trainer/Policy mu Mean              0.0228749
trainer/Policy mu Std               0.664507
trainer/Policy mu Max               2.59636
trainer/Policy mu Min              -2.28456
trainer/Policy log std Mean        -2.07973
trainer/Policy log std Std          0.464879
trainer/Policy log std Max         -0.511827
trainer/Policy log std Min         -2.47817
trainer/Alpha                       0.0188225
trainer/Alpha Loss                  0.190201
exploration/num steps total     31600
exploration/num paths total       316
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.0987056
exploration/Rewards Std             0.189566
exploration/Rewards Max            -0.00554756
exploration/Rewards Min            -1
exploration/Returns Mean           -9.87056
exploration/Returns Std             4.06366
exploration/Returns Max            -5.8069
exploration/Returns Min           -13.9342
exploration/Actions Mean            0.011381
exploration/Actions Std             0.230329
exploration/Actions Max             0.995473
exploration/Actions Min            -0.924796
exploration/Num Paths               2
exploration/Average Returns        -9.87056
evaluation/num steps total     157000
evaluation/num paths total       1570
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0563506
evaluation/Rewards Std              0.136968
evaluation/Rewards Max             -0.0285
evaluation/Rewards Min             -1
evaluation/Returns Mean            -5.63506
evaluation/Returns Std              1.83797
evaluation/Returns Max             -3.61711
evaluation/Returns Min             -9.41212
evaluation/Actions Mean             0.0116612
evaluation/Actions Std              0.168074
evaluation/Actions Max              0.986373
evaluation/Actions Min             -0.982201
evaluation/Num Paths               10
evaluation/Average Returns         -5.63506
time/data storing (s)               0.00130516
time/evaluation sampling (s)        0.289212
time/exploration sampling (s)       0.0763145
time/logging (s)                    0.00350008
time/saving (s)                     0.00249441
time/training (s)                   1.07206
time/epoch (s)                      1.44489
time/total (s)                    237.314
Epoch                             156
-----------------------------  ---------------
2019-04-22 20:56:35.253951 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 157 finished
-----------------------------  ---------------
replay_buffer/size              31800
trainer/QF1 Loss                    0.193235
trainer/QF2 Loss                    0.193778
trainer/Policy Loss                 6.77837
trainer/Q1 Predictions Mean        -4.66742
trainer/Q1 Predictions Std          1.48799
trainer/Q1 Predictions Max         -4.08981
trainer/Q1 Predictions Min        -12.9349
trainer/Q2 Predictions Mean        -4.66607
trainer/Q2 Predictions Std          1.47066
trainer/Q2 Predictions Max         -4.08886
trainer/Q2 Predictions Min        -12.7329
trainer/Q Targets Mean             -4.76075
trainer/Q Targets Std               1.59679
trainer/Q Targets Max              -0.0161457
trainer/Q Targets Min             -13.2771
trainer/Log Pis Mean                2.24615
trainer/Log Pis Std                 1.21571
trainer/Log Pis Max                 6.30995
trainer/Log Pis Min                -1.6964
trainer/Policy mu Mean              0.0825779
trainer/Policy mu Std               0.794203
trainer/Policy mu Max               2.60087
trainer/Policy mu Min              -2.48772
trainer/Policy log std Mean        -2.03551
trainer/Policy log std Std          0.550515
trainer/Policy log std Max         -0.482699
trainer/Policy log std Min         -2.46724
trainer/Alpha                       0.019034
trainer/Alpha Loss                  0.975155
exploration/num steps total     31800
exploration/num paths total       318
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.10912
exploration/Rewards Std             0.213005
exploration/Rewards Max            -0.00449082
exploration/Rewards Min            -1
exploration/Returns Mean          -10.912
exploration/Returns Std             3.49274
exploration/Returns Max            -7.41929
exploration/Returns Min           -14.4048
exploration/Actions Mean            0.0474897
exploration/Actions Std             0.241147
exploration/Actions Max             0.994403
exploration/Actions Min            -0.368424
exploration/Num Paths               2
exploration/Average Returns       -10.912
evaluation/num steps total     158000
evaluation/num paths total       1580
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0747705
evaluation/Rewards Std              0.200374
evaluation/Rewards Max             -0.00696365
evaluation/Rewards Min             -1
evaluation/Returns Mean            -7.47705
evaluation/Returns Std              2.93873
evaluation/Returns Max             -2.77138
evaluation/Returns Min            -11.396
evaluation/Actions Mean             0.0188883
evaluation/Actions Std              0.204683
evaluation/Actions Max              0.989441
evaluation/Actions Min             -0.984638
evaluation/Num Paths               10
evaluation/Average Returns         -7.47705
time/data storing (s)               0.00153139
time/evaluation sampling (s)        0.288938
time/exploration sampling (s)       0.0754233
time/logging (s)                    0.00347349
time/saving (s)                     0.00241195
time/training (s)                   1.08519
time/epoch (s)                      1.45697
time/total (s)                    238.775
Epoch                             157
-----------------------------  ---------------
2019-04-22 20:56:36.704067 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 158 finished
-----------------------------  ---------------
replay_buffer/size              32000
trainer/QF1 Loss                    0.527617
trainer/QF2 Loss                    0.528367
trainer/Policy Loss                 6.53988
trainer/Q1 Predictions Mean        -4.68422
trainer/Q1 Predictions Std          1.45216
trainer/Q1 Predictions Max         -4.11801
trainer/Q1 Predictions Min        -12.7414
trainer/Q2 Predictions Mean        -4.68672
trainer/Q2 Predictions Std          1.44698
trainer/Q2 Predictions Max         -4.12657
trainer/Q2 Predictions Min        -12.7524
trainer/Q Targets Mean             -4.65379
trainer/Q Targets Std               1.55487
trainer/Q Targets Max              -0.0740083
trainer/Q Targets Min             -13.0321
trainer/Log Pis Mean                1.96048
trainer/Log Pis Std                 1.17825
trainer/Log Pis Max                 5.68658
trainer/Log Pis Min                -1.8316
trainer/Policy mu Mean              0.112316
trainer/Policy mu Std               0.740667
trainer/Policy mu Max               2.56071
trainer/Policy mu Min              -2.74824
trainer/Policy log std Mean        -1.98858
trainer/Policy log std Std          0.531817
trainer/Policy log std Max         -0.481221
trainer/Policy log std Min         -2.45229
trainer/Alpha                       0.0185295
trainer/Alpha Loss                 -0.157605
exploration/num steps total     32000
exploration/num paths total       320
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.111079
exploration/Rewards Std             0.216782
exploration/Rewards Max            -0.00374968
exploration/Rewards Min            -1
exploration/Returns Mean          -11.1079
exploration/Returns Std             2.60648
exploration/Returns Max            -8.50143
exploration/Returns Min           -13.7144
exploration/Actions Mean            0.034302
exploration/Actions Std             0.253909
exploration/Actions Max             0.996873
exploration/Actions Min            -0.98241
exploration/Num Paths               2
exploration/Average Returns       -11.1079
evaluation/num steps total     159000
evaluation/num paths total       1590
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0639923
evaluation/Rewards Std              0.200783
evaluation/Rewards Max             -0.00439238
evaluation/Rewards Min             -1
evaluation/Returns Mean            -6.39923
evaluation/Returns Std              2.27544
evaluation/Returns Max             -2.0632
evaluation/Returns Min             -9.54547
evaluation/Actions Mean             0.0198745
evaluation/Actions Std              0.199875
evaluation/Actions Max              0.987928
evaluation/Actions Min             -0.982809
evaluation/Num Paths               10
evaluation/Average Returns         -6.39923
time/data storing (s)               0.00122951
time/evaluation sampling (s)        0.282501
time/exploration sampling (s)       0.0688731
time/logging (s)                    0.00382772
time/saving (s)                     0.00274945
time/training (s)                   1.08395
time/epoch (s)                      1.44313
time/total (s)                    240.223
Epoch                             158
-----------------------------  ---------------
2019-04-22 20:56:38.210788 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 159 finished
-----------------------------  ---------------
replay_buffer/size              32200
trainer/QF1 Loss                    0.678923
trainer/QF2 Loss                    0.677385
trainer/Policy Loss                 6.10362
trainer/Q1 Predictions Mean        -4.41318
trainer/Q1 Predictions Std          1.06459
trainer/Q1 Predictions Max         -4.09189
trainer/Q1 Predictions Min        -11.4677
trainer/Q2 Predictions Mean        -4.40837
trainer/Q2 Predictions Std          1.05827
trainer/Q2 Predictions Max         -4.09203
trainer/Q2 Predictions Min        -11.3693
trainer/Q Targets Mean             -4.29542
trainer/Q Targets Std               1.33923
trainer/Q Targets Max              -0.00819963
trainer/Q Targets Min             -11.3853
trainer/Log Pis Mean                1.78234
trainer/Log Pis Std                 1.50906
trainer/Log Pis Max                 6.9032
trainer/Log Pis Min                -4.3955
trainer/Policy mu Mean              0.0315485
trainer/Policy mu Std               0.528074
trainer/Policy mu Max               2.50764
trainer/Policy mu Min              -2.29418
trainer/Policy log std Mean        -2.15957
trainer/Policy log std Std          0.3887
trainer/Policy log std Max         -0.399792
trainer/Policy log std Min         -2.45454
trainer/Alpha                       0.0186257
trainer/Alpha Loss                 -0.866974
exploration/num steps total     32200
exploration/num paths total       322
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.0650969
exploration/Rewards Std             0.0951625
exploration/Rewards Max            -0.00257991
exploration/Rewards Min            -1
exploration/Returns Mean           -6.50969
exploration/Returns Std             0.957956
exploration/Returns Max            -5.55173
exploration/Returns Min            -7.46765
exploration/Actions Mean            0.0110148
exploration/Actions Std             0.166732
exploration/Actions Max             0.992059
exploration/Actions Min            -0.612626
exploration/Num Paths               2
exploration/Average Returns        -6.50969
evaluation/num steps total     160000
evaluation/num paths total       1600
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0565918
evaluation/Rewards Std              0.183113
evaluation/Rewards Max             -0.0156421
evaluation/Rewards Min             -1
evaluation/Returns Mean            -5.65918
evaluation/Returns Std              2.20141
evaluation/Returns Max             -1.70978
evaluation/Returns Min             -8.74992
evaluation/Actions Mean             0.0268576
evaluation/Actions Std              0.189372
evaluation/Actions Max              0.988447
evaluation/Actions Min             -0.988379
evaluation/Num Paths               10
evaluation/Average Returns         -5.65918
time/data storing (s)               0.00123348
time/evaluation sampling (s)        0.308651
time/exploration sampling (s)       0.0766084
time/logging (s)                    0.00403216
time/saving (s)                     0.00294865
time/training (s)                   1.1058
time/epoch (s)                      1.49927
time/total (s)                    241.726
Epoch                             159
-----------------------------  ---------------
2019-04-22 20:56:39.828963 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 160 finished
-----------------------------  ---------------
replay_buffer/size              32400
trainer/QF1 Loss                    0.793464
trainer/QF2 Loss                    0.791976
trainer/Policy Loss                 6.17559
trainer/Q1 Predictions Mean        -4.33782
trainer/Q1 Predictions Std          1.21574
trainer/Q1 Predictions Max         -3.96434
trainer/Q1 Predictions Min        -13.6293
trainer/Q2 Predictions Mean        -4.34134
trainer/Q2 Predictions Std          1.21254
trainer/Q2 Predictions Max         -3.97439
trainer/Q2 Predictions Min        -13.6119
trainer/Q Targets Mean             -4.28671
trainer/Q Targets Std               1.52627
trainer/Q Targets Max              -0.0689495
trainer/Q Targets Min             -13.7535
trainer/Log Pis Mean                1.90651
trainer/Log Pis Std                 1.26846
trainer/Log Pis Max                 7.0684
trainer/Log Pis Min                -3.32325
trainer/Policy mu Mean              0.0966154
trainer/Policy mu Std               0.62915
trainer/Policy mu Max               2.46377
trainer/Policy mu Min              -2.42046
trainer/Policy log std Mean        -2.05584
trainer/Policy log std Std          0.444621
trainer/Policy log std Max         -0.486647
trainer/Policy log std Min         -2.39306
trainer/Alpha                       0.0184373
trainer/Alpha Loss                 -0.373332
exploration/num steps total     32400
exploration/num paths total       324
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.099235
exploration/Rewards Std             0.187255
exploration/Rewards Max            -0.00552268
exploration/Rewards Min            -1
exploration/Returns Mean           -9.9235
exploration/Returns Std             0.0172211
exploration/Returns Max            -9.90628
exploration/Returns Min            -9.94072
exploration/Actions Mean           -0.0164692
exploration/Actions Std             0.249313
exploration/Actions Max             0.996011
exploration/Actions Min            -0.99894
exploration/Num Paths               2
exploration/Average Returns        -9.9235
evaluation/num steps total     161000
evaluation/num paths total       1610
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0751322
evaluation/Rewards Std              0.186882
evaluation/Rewards Max             -0.00695631
evaluation/Rewards Min             -1
evaluation/Returns Mean            -7.51322
evaluation/Returns Std              2.38796
evaluation/Returns Max             -3.41948
evaluation/Returns Min            -11.7637
evaluation/Actions Mean             0.0255336
evaluation/Actions Std              0.181158
evaluation/Actions Max              0.988336
evaluation/Actions Min             -0.992998
evaluation/Num Paths               10
evaluation/Average Returns         -7.51322
time/data storing (s)               0.00132829
time/evaluation sampling (s)        0.402946
time/exploration sampling (s)       0.0797968
time/logging (s)                    0.00345144
time/saving (s)                     0.00243397
time/training (s)                   1.11995
time/epoch (s)                      1.60991
time/total (s)                    243.341
Epoch                             160
-----------------------------  ---------------
2019-04-22 20:56:41.354942 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 161 finished
-----------------------------  ---------------
replay_buffer/size              32600
trainer/QF1 Loss                    0.327521
trainer/QF2 Loss                    0.327698
trainer/Policy Loss                 6.55871
trainer/Q1 Predictions Mean        -4.70601
trainer/Q1 Predictions Std          1.83393
trainer/Q1 Predictions Max         -4.07364
trainer/Q1 Predictions Min        -12.7391
trainer/Q2 Predictions Mean        -4.70688
trainer/Q2 Predictions Std          1.8378
trainer/Q2 Predictions Max         -4.06961
trainer/Q2 Predictions Min        -12.8264
trainer/Q Targets Mean             -4.66361
trainer/Q Targets Std               1.94164
trainer/Q Targets Max              -0.0416255
trainer/Q Targets Min             -12.8633
trainer/Log Pis Mean                1.94285
trainer/Log Pis Std                 1.03144
trainer/Log Pis Max                 5.30818
trainer/Log Pis Min                -2.51988
trainer/Policy mu Mean              0.11949
trainer/Policy mu Std               0.662654
trainer/Policy mu Max               2.48802
trainer/Policy mu Min              -1.63309
trainer/Policy log std Mean        -2.09431
trainer/Policy log std Std          0.4841
trainer/Policy log std Max         -0.639351
trainer/Policy log std Min         -2.45975
trainer/Alpha                       0.0180273
trainer/Alpha Loss                 -0.229485
exploration/num steps total     32600
exploration/num paths total       326
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.088997
exploration/Rewards Std             0.178234
exploration/Rewards Max            -0.00386139
exploration/Rewards Min            -1
exploration/Returns Mean           -8.8997
exploration/Returns Std             0.513276
exploration/Returns Max            -8.38642
exploration/Returns Min            -9.41297
exploration/Actions Mean            0.0227485
exploration/Actions Std             0.245165
exploration/Actions Max             0.997528
exploration/Actions Min            -0.996752
exploration/Num Paths               2
exploration/Average Returns        -8.8997
evaluation/num steps total     162000
evaluation/num paths total       1620
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0597859
evaluation/Rewards Std              0.187987
evaluation/Rewards Max             -0.0120691
evaluation/Rewards Min             -1
evaluation/Returns Mean            -5.97859
evaluation/Returns Std              2.85744
evaluation/Returns Max             -1.85256
evaluation/Returns Min            -11.0939
evaluation/Actions Mean             0.0271667
evaluation/Actions Std              0.186527
evaluation/Actions Max              0.991901
evaluation/Actions Min             -0.986014
evaluation/Num Paths               10
evaluation/Average Returns         -5.97859
time/data storing (s)               0.00129485
time/evaluation sampling (s)        0.335506
time/exploration sampling (s)       0.0782013
time/logging (s)                    0.0032704
time/saving (s)                     0.00243408
time/training (s)                   1.09811
time/epoch (s)                      1.51882
time/total (s)                    244.864
Epoch                             161
-----------------------------  ---------------
2019-04-22 20:56:42.875543 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 162 finished
-----------------------------  ---------------
replay_buffer/size              32800
trainer/QF1 Loss                    0.168487
trainer/QF2 Loss                    0.172047
trainer/Policy Loss                 6.22311
trainer/Q1 Predictions Mean        -4.43284
trainer/Q1 Predictions Std          0.820887
trainer/Q1 Predictions Max         -4.10668
trainer/Q1 Predictions Min         -9.21131
trainer/Q2 Predictions Mean        -4.44747
trainer/Q2 Predictions Std          0.813226
trainer/Q2 Predictions Max         -4.11854
trainer/Q2 Predictions Min         -9.15155
trainer/Q Targets Mean             -4.37297
trainer/Q Targets Std               0.931938
trainer/Q Targets Max              -0.0872363
trainer/Q Targets Min              -9.21548
trainer/Log Pis Mean                1.89067
trainer/Log Pis Std                 1.30681
trainer/Log Pis Max                 5.7764
trainer/Log Pis Min                -3.58592
trainer/Policy mu Mean              0.104431
trainer/Policy mu Std               0.615724
trainer/Policy mu Max               2.67264
trainer/Policy mu Min              -2.1823
trainer/Policy log std Mean        -2.13862
trainer/Policy log std Std          0.452017
trainer/Policy log std Max         -0.513537
trainer/Policy log std Min         -2.52491
trainer/Alpha                       0.0175049
trainer/Alpha Loss                 -0.442249
exploration/num steps total     32800
exploration/num paths total       328
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.0904841
exploration/Rewards Std             0.167435
exploration/Rewards Max            -0.00670493
exploration/Rewards Min            -1
exploration/Returns Mean           -9.04841
exploration/Returns Std             2.66266
exploration/Returns Max            -6.38575
exploration/Returns Min           -11.7111
exploration/Actions Mean            0.0413187
exploration/Actions Std             0.221271
exploration/Actions Max             0.997412
exploration/Actions Min            -0.398938
exploration/Num Paths               2
exploration/Average Returns        -9.04841
evaluation/num steps total     163000
evaluation/num paths total       1630
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0787607
evaluation/Rewards Std              0.201286
evaluation/Rewards Max             -0.0018539
evaluation/Rewards Min             -1
evaluation/Returns Mean            -7.87607
evaluation/Returns Std              2.81774
evaluation/Returns Max             -3.08827
evaluation/Returns Min            -12.2629
evaluation/Actions Mean             0.0293777
evaluation/Actions Std              0.193126
evaluation/Actions Max              0.990355
evaluation/Actions Min             -0.9674
evaluation/Num Paths               10
evaluation/Average Returns         -7.87607
time/data storing (s)               0.00160254
time/evaluation sampling (s)        0.294048
time/exploration sampling (s)       0.100628
time/logging (s)                    0.00345956
time/saving (s)                     0.0122081
time/training (s)                   1.10181
time/epoch (s)                      1.51376
time/total (s)                    246.382
Epoch                             162
-----------------------------  ---------------
2019-04-22 20:56:44.401254 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 163 finished
-----------------------------  ---------------
replay_buffer/size              33000
trainer/QF1 Loss                    0.165389
trainer/QF2 Loss                    0.163998
trainer/Policy Loss                 6.83183
trainer/Q1 Predictions Mean        -4.74687
trainer/Q1 Predictions Std          1.87318
trainer/Q1 Predictions Max         -4.02445
trainer/Q1 Predictions Min        -13.3748
trainer/Q2 Predictions Mean        -4.74117
trainer/Q2 Predictions Std          1.85928
trainer/Q2 Predictions Max         -4.01809
trainer/Q2 Predictions Min        -13.2388
trainer/Q Targets Mean             -4.72107
trainer/Q Targets Std               1.89411
trainer/Q Targets Max              -0.110922
trainer/Q Targets Min             -13.103
trainer/Log Pis Mean                2.20027
trainer/Log Pis Std                 0.996355
trainer/Log Pis Max                 4.72416
trainer/Log Pis Min                -1.89806
trainer/Policy mu Mean              0.201039
trainer/Policy mu Std               0.713931
trainer/Policy mu Max               2.80549
trainer/Policy mu Min              -2.7963
trainer/Policy log std Mean        -2.18445
trainer/Policy log std Std          0.540343
trainer/Policy log std Max         -0.563116
trainer/Policy log std Min         -2.60393
trainer/Alpha                       0.0181203
trainer/Alpha Loss                  0.803306
exploration/num steps total     33000
exploration/num paths total       330
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.105634
exploration/Rewards Std             0.228255
exploration/Rewards Max            -0.00245968
exploration/Rewards Min            -1
exploration/Returns Mean          -10.5634
exploration/Returns Std             0.26242
exploration/Returns Max           -10.301
exploration/Returns Min           -10.8258
exploration/Actions Mean            0.0347868
exploration/Actions Std             0.232923
exploration/Actions Max             0.997887
exploration/Actions Min            -0.743465
exploration/Num Paths               2
exploration/Average Returns       -10.5634
evaluation/num steps total     164000
evaluation/num paths total       1640
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0524665
evaluation/Rewards Std              0.193865
evaluation/Rewards Max             -0.00792539
evaluation/Rewards Min             -1
evaluation/Returns Mean            -5.24665
evaluation/Returns Std              2.45186
evaluation/Returns Max             -1.66387
evaluation/Returns Min            -10.4386
evaluation/Actions Mean             0.0211953
evaluation/Actions Std              0.196703
evaluation/Actions Max              0.991004
evaluation/Actions Min             -0.990988
evaluation/Num Paths               10
evaluation/Average Returns         -5.24665
time/data storing (s)               0.00129093
time/evaluation sampling (s)        0.296414
time/exploration sampling (s)       0.076791
time/logging (s)                    0.00348624
time/saving (s)                     0.00243265
time/training (s)                   1.13804
time/epoch (s)                      1.51846
time/total (s)                    247.905
Epoch                             163
-----------------------------  ---------------
2019-04-22 20:56:45.892219 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 164 finished
-----------------------------  ---------------
replay_buffer/size              33200
trainer/QF1 Loss                    0.321466
trainer/QF2 Loss                    0.321088
trainer/Policy Loss                 6.29124
trainer/Q1 Predictions Mean        -4.46219
trainer/Q1 Predictions Std          1.81604
trainer/Q1 Predictions Max         -3.9116
trainer/Q1 Predictions Min        -13.0157
trainer/Q2 Predictions Mean        -4.45447
trainer/Q2 Predictions Std          1.8098
trainer/Q2 Predictions Max         -3.91085
trainer/Q2 Predictions Min        -12.8846
trainer/Q Targets Mean             -4.50661
trainer/Q Targets Std               1.94057
trainer/Q Targets Max              -0.0271619
trainer/Q Targets Min             -13.0855
trainer/Log Pis Mean                1.94471
trainer/Log Pis Std                 1.02114
trainer/Log Pis Max                 3.76886
trainer/Log Pis Min                -2.02483
trainer/Policy mu Mean              0.0493897
trainer/Policy mu Std               0.565203
trainer/Policy mu Max               2.53241
trainer/Policy mu Min              -2.10419
trainer/Policy log std Mean        -2.17354
trainer/Policy log std Std          0.447306
trainer/Policy log std Max         -0.371058
trainer/Policy log std Min         -2.51282
trainer/Alpha                       0.0188901
trainer/Alpha Loss                 -0.21947
exploration/num steps total     33200
exploration/num paths total       332
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.112472
exploration/Rewards Std             0.195558
exploration/Rewards Max            -0.00542305
exploration/Rewards Min            -1
exploration/Returns Mean          -11.2472
exploration/Returns Std             1.15374
exploration/Returns Max           -10.0934
exploration/Returns Min           -12.4009
exploration/Actions Mean            0.00907639
exploration/Actions Std             0.230297
exploration/Actions Max             0.992996
exploration/Actions Min            -0.993668
exploration/Num Paths               2
exploration/Average Returns       -11.2472
evaluation/num steps total     165000
evaluation/num paths total       1650
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.100847
evaluation/Rewards Std              0.19727
evaluation/Rewards Max             -0.0333424
evaluation/Rewards Min             -1
evaluation/Returns Mean           -10.0847
evaluation/Returns Std              2.09626
evaluation/Returns Max             -6.29213
evaluation/Returns Min            -13.195
evaluation/Actions Mean             0.03896
evaluation/Actions Std              0.199597
evaluation/Actions Max              0.990355
evaluation/Actions Min             -0.994101
evaluation/Num Paths               10
evaluation/Average Returns        -10.0847
time/data storing (s)               0.00127847
time/evaluation sampling (s)        0.293217
time/exploration sampling (s)       0.0743409
time/logging (s)                    0.00351733
time/saving (s)                     0.00258095
time/training (s)                   1.10865
time/epoch (s)                      1.48358
time/total (s)                    249.393
Epoch                             164
-----------------------------  ---------------
2019-04-22 20:56:47.485738 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 165 finished
-----------------------------  ---------------
replay_buffer/size              33400
trainer/QF1 Loss                    0.0109795
trainer/QF2 Loss                    0.0108032
trainer/Policy Loss                 6.06696
trainer/Q1 Predictions Mean        -4.35323
trainer/Q1 Predictions Std          1.44091
trainer/Q1 Predictions Max         -3.98307
trainer/Q1 Predictions Min        -14.2987
trainer/Q2 Predictions Mean        -4.35626
trainer/Q2 Predictions Std          1.44719
trainer/Q2 Predictions Max         -3.98599
trainer/Q2 Predictions Min        -14.5055
trainer/Q Targets Mean             -4.38747
trainer/Q Targets Std               1.38195
trainer/Q Targets Max              -3.98677
trainer/Q Targets Min             -14.0799
trainer/Log Pis Mean                1.79352
trainer/Log Pis Std                 1.02282
trainer/Log Pis Max                 5.15073
trainer/Log Pis Min                -2.97653
trainer/Policy mu Mean              0.0100275
trainer/Policy mu Std               0.545035
trainer/Policy mu Max               2.33305
trainer/Policy mu Min              -2.75978
trainer/Policy log std Mean        -2.09096
trainer/Policy log std Std          0.435346
trainer/Policy log std Max         -0.414368
trainer/Policy log std Min         -2.4441
trainer/Alpha                       0.0189187
trainer/Alpha Loss                 -0.819215
exploration/num steps total     33400
exploration/num paths total       334
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.10248
exploration/Rewards Std             0.177094
exploration/Rewards Max            -0.00181034
exploration/Rewards Min            -1
exploration/Returns Mean          -10.248
exploration/Returns Std             1.36832
exploration/Returns Max            -8.87963
exploration/Returns Min           -11.6163
exploration/Actions Mean            0.0151299
exploration/Actions Std             0.239246
exploration/Actions Max             0.994682
exploration/Actions Min            -0.99617
exploration/Num Paths               2
exploration/Average Returns       -10.248
evaluation/num steps total     166000
evaluation/num paths total       1660
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.095112
evaluation/Rewards Std              0.190284
evaluation/Rewards Max             -0.0426668
evaluation/Rewards Min             -1
evaluation/Returns Mean            -9.5112
evaluation/Returns Std              2.40543
evaluation/Returns Max             -6.11399
evaluation/Returns Min            -13.174
evaluation/Actions Mean             0.0245597
evaluation/Actions Std              0.193456
evaluation/Actions Max              0.989503
evaluation/Actions Min             -0.992761
evaluation/Num Paths               10
evaluation/Average Returns         -9.5112
time/data storing (s)               0.00124019
time/evaluation sampling (s)        0.285231
time/exploration sampling (s)       0.0700965
time/logging (s)                    0.00359608
time/saving (s)                     0.00239664
time/training (s)                   1.22398
time/epoch (s)                      1.58654
time/total (s)                    250.984
Epoch                             165
-----------------------------  ---------------
2019-04-22 20:56:49.040802 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 166 finished
-----------------------------  ----------------
replay_buffer/size              33600
trainer/QF1 Loss                    0.00239415
trainer/QF2 Loss                    0.0029224
trainer/Policy Loss                 6.19974
trainer/Q1 Predictions Mean        -4.34059
trainer/Q1 Predictions Std          0.929327
trainer/Q1 Predictions Max         -3.98417
trainer/Q1 Predictions Min         -9.3276
trainer/Q2 Predictions Mean        -4.34384
trainer/Q2 Predictions Std          0.922671
trainer/Q2 Predictions Max         -3.98745
trainer/Q2 Predictions Min         -9.45253
trainer/Q Targets Mean             -4.36303
trainer/Q Targets Std               0.93379
trainer/Q Targets Max              -3.95913
trainer/Q Targets Min              -9.47665
trainer/Log Pis Mean                1.95253
trainer/Log Pis Std                 1.11671
trainer/Log Pis Max                 5.62323
trainer/Log Pis Min                -1.38015
trainer/Policy mu Mean              0.0569762
trainer/Policy mu Std               0.720599
trainer/Policy mu Max               2.54424
trainer/Policy mu Min              -2.5045
trainer/Policy log std Mean        -1.99554
trainer/Policy log std Std          0.524915
trainer/Policy log std Max         -0.341018
trainer/Policy log std Min         -2.4376
trainer/Alpha                       0.0189798
trainer/Alpha Loss                 -0.188187
exploration/num steps total     33600
exploration/num paths total       336
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.0659025
exploration/Rewards Std             0.100141
exploration/Rewards Max            -0.000907465
exploration/Rewards Min            -1
exploration/Returns Mean           -6.59025
exploration/Returns Std             0.165482
exploration/Returns Max            -6.42477
exploration/Returns Min            -6.75573
exploration/Actions Mean           -0.00306405
exploration/Actions Std             0.188277
exploration/Actions Max             0.990214
exploration/Actions Min            -0.993935
exploration/Num Paths               2
exploration/Average Returns        -6.59025
evaluation/num steps total     167000
evaluation/num paths total       1670
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0423085
evaluation/Rewards Std              0.173587
evaluation/Rewards Max             -0.00572802
evaluation/Rewards Min             -1
evaluation/Returns Mean            -4.23085
evaluation/Returns Std              2.21166
evaluation/Returns Max             -0.79921
evaluation/Returns Min             -8.03576
evaluation/Actions Mean             0.0227724
evaluation/Actions Std              0.176181
evaluation/Actions Max              0.993302
evaluation/Actions Min             -0.990932
evaluation/Num Paths               10
evaluation/Average Returns         -4.23085
time/data storing (s)               0.00133067
time/evaluation sampling (s)        0.291771
time/exploration sampling (s)       0.0766689
time/logging (s)                    0.00387097
time/saving (s)                     0.00255808
time/training (s)                   1.17127
time/epoch (s)                      1.54747
time/total (s)                    252.536
Epoch                             166
-----------------------------  ----------------
2019-04-22 20:56:50.542420 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 167 finished
-----------------------------  ---------------
replay_buffer/size              33800
trainer/QF1 Loss                    0.157705
trainer/QF2 Loss                    0.156647
trainer/Policy Loss                 6.65001
trainer/Q1 Predictions Mean        -4.46945
trainer/Q1 Predictions Std          1.44387
trainer/Q1 Predictions Max         -3.91049
trainer/Q1 Predictions Min        -12.7109
trainer/Q2 Predictions Mean        -4.46545
trainer/Q2 Predictions Std          1.44384
trainer/Q2 Predictions Max         -3.91251
trainer/Q2 Predictions Min        -12.7136
trainer/Q Targets Mean             -4.48002
trainer/Q Targets Std               1.50071
trainer/Q Targets Max              -0.086736
trainer/Q Targets Min             -12.5473
trainer/Log Pis Mean                2.3052
trainer/Log Pis Std                 0.94186
trainer/Log Pis Max                 6.32036
trainer/Log Pis Min                -0.757189
trainer/Policy mu Mean              0.0797147
trainer/Policy mu Std               0.722732
trainer/Policy mu Max               2.54567
trainer/Policy mu Min              -2.22449
trainer/Policy log std Mean        -2.09742
trainer/Policy log std Std          0.515042
trainer/Policy log std Max         -0.628609
trainer/Policy log std Min         -2.52836
trainer/Alpha                       0.0194365
trainer/Alpha Loss                  1.20274
exploration/num steps total     33800
exploration/num paths total       338
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.114533
exploration/Rewards Std             0.221811
exploration/Rewards Max            -0.00165007
exploration/Rewards Min            -1
exploration/Returns Mean          -11.4533
exploration/Returns Std             2.19555
exploration/Returns Max            -9.25773
exploration/Returns Min           -13.6488
exploration/Actions Mean            0.0213485
exploration/Actions Std             0.252688
exploration/Actions Max             0.998877
exploration/Actions Min            -0.983212
exploration/Num Paths               2
exploration/Average Returns       -11.4533
evaluation/num steps total     168000
evaluation/num paths total       1680
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0675344
evaluation/Rewards Std              0.161938
evaluation/Rewards Max             -0.0288976
evaluation/Rewards Min             -1
evaluation/Returns Mean            -6.75344
evaluation/Returns Std              3.04909
evaluation/Returns Max             -3.58976
evaluation/Returns Min            -12.1781
evaluation/Actions Mean             0.0288376
evaluation/Actions Std              0.162401
evaluation/Actions Max              0.989134
evaluation/Actions Min             -0.640978
evaluation/Num Paths               10
evaluation/Average Returns         -6.75344
time/data storing (s)               0.00143071
time/evaluation sampling (s)        0.311338
time/exploration sampling (s)       0.0826448
time/logging (s)                    0.00368437
time/saving (s)                     0.00261231
time/training (s)                   1.09207
time/epoch (s)                      1.49378
time/total (s)                    254.035
Epoch                             167
-----------------------------  ---------------
2019-04-22 20:56:52.006465 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 168 finished
-----------------------------  ---------------
replay_buffer/size              34000
trainer/QF1 Loss                    0.00439757
trainer/QF2 Loss                    0.00429187
trainer/Policy Loss                 6.79812
trainer/Q1 Predictions Mean        -4.88715
trainer/Q1 Predictions Std          2.32209
trainer/Q1 Predictions Max         -3.94175
trainer/Q1 Predictions Min        -13.8309
trainer/Q2 Predictions Mean        -4.88957
trainer/Q2 Predictions Std          2.32568
trainer/Q2 Predictions Max         -3.94542
trainer/Q2 Predictions Min        -13.7582
trainer/Q Targets Mean             -4.90275
trainer/Q Targets Std               2.34029
trainer/Q Targets Max              -3.93314
trainer/Q Targets Min             -13.992
trainer/Log Pis Mean                2.0216
trainer/Log Pis Std                 1.26836
trainer/Log Pis Max                 5.74477
trainer/Log Pis Min                -2.54777
trainer/Policy mu Mean              0.206226
trainer/Policy mu Std               0.79101
trainer/Policy mu Max               2.67785
trainer/Policy mu Min              -1.99972
trainer/Policy log std Mean        -2.05993
trainer/Policy log std Std          0.603428
trainer/Policy log std Max         -0.497797
trainer/Policy log std Min         -2.58512
trainer/Alpha                       0.0195595
trainer/Alpha Loss                  0.0849951
exploration/num steps total     34000
exploration/num paths total       340
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.0495861
exploration/Rewards Std             0.03264
exploration/Rewards Max            -0.00403034
exploration/Rewards Min            -0.305048
exploration/Returns Mean           -4.95861
exploration/Returns Std             0.00276318
exploration/Returns Max            -4.95584
exploration/Returns Min            -4.96137
exploration/Actions Mean            0.00339944
exploration/Actions Std             0.149223
exploration/Actions Max             0.933762
exploration/Actions Min            -0.972106
exploration/Num Paths               2
exploration/Average Returns        -4.95861
evaluation/num steps total     169000
evaluation/num paths total       1690
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0554249
evaluation/Rewards Std              0.169742
evaluation/Rewards Max             -0.0173703
evaluation/Rewards Min             -1
evaluation/Returns Mean            -5.54249
evaluation/Returns Std              2.6639
evaluation/Returns Max             -2.2265
evaluation/Returns Min            -10.9975
evaluation/Actions Mean             0.0258659
evaluation/Actions Std              0.174997
evaluation/Actions Max              0.992359
evaluation/Actions Min             -0.9786
evaluation/Num Paths               10
evaluation/Average Returns         -5.54249
time/data storing (s)               0.00147563
time/evaluation sampling (s)        0.29735
time/exploration sampling (s)       0.0790705
time/logging (s)                    0.00357297
time/saving (s)                     0.00244893
time/training (s)                   1.07178
time/epoch (s)                      1.4557
time/total (s)                    255.495
Epoch                             168
-----------------------------  ---------------
2019-04-22 20:56:53.586672 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 169 finished
-----------------------------  ---------------
replay_buffer/size              34200
trainer/QF1 Loss                    0.00601854
trainer/QF2 Loss                    0.00658728
trainer/Policy Loss                 6.64687
trainer/Q1 Predictions Mean        -4.53754
trainer/Q1 Predictions Std          1.84355
trainer/Q1 Predictions Max         -3.86507
trainer/Q1 Predictions Min        -13.2696
trainer/Q2 Predictions Mean        -4.53079
trainer/Q2 Predictions Std          1.8498
trainer/Q2 Predictions Max         -3.85659
trainer/Q2 Predictions Min        -13.3373
trainer/Q Targets Mean             -4.58672
trainer/Q Targets Std               1.84339
trainer/Q Targets Max              -3.899
trainer/Q Targets Min             -13.3954
trainer/Log Pis Mean                2.22261
trainer/Log Pis Std                 1.15663
trainer/Log Pis Max                 6.94545
trainer/Log Pis Min                -2.31124
trainer/Policy mu Mean              0.112684
trainer/Policy mu Std               0.7166
trainer/Policy mu Max               2.62489
trainer/Policy mu Min              -2.67148
trainer/Policy log std Mean        -2.12034
trainer/Policy log std Std          0.510747
trainer/Policy log std Max         -0.541723
trainer/Policy log std Min         -2.50597
trainer/Alpha                       0.0205041
trainer/Alpha Loss                  0.865384
exploration/num steps total     34200
exploration/num paths total       342
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.0742174
exploration/Rewards Std             0.144737
exploration/Rewards Max            -0.00378656
exploration/Rewards Min            -1
exploration/Returns Mean           -7.42174
exploration/Returns Std             2.202
exploration/Returns Max            -5.21974
exploration/Returns Min            -9.62374
exploration/Actions Mean            0.0118221
exploration/Actions Std             0.200926
exploration/Actions Max             0.996376
exploration/Actions Min            -0.857615
exploration/Num Paths               2
exploration/Average Returns        -7.42174
evaluation/num steps total     170000
evaluation/num paths total       1700
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0795412
evaluation/Rewards Std              0.214743
evaluation/Rewards Max             -0.0245935
evaluation/Rewards Min             -1
evaluation/Returns Mean            -7.95412
evaluation/Returns Std              2.54745
evaluation/Returns Max             -3.67943
evaluation/Returns Min            -10.7871
evaluation/Actions Mean             0.0371404
evaluation/Actions Std              0.207161
evaluation/Actions Max              0.991871
evaluation/Actions Min             -0.913314
evaluation/Num Paths               10
evaluation/Average Returns         -7.95412
time/data storing (s)               0.00135595
time/evaluation sampling (s)        0.299964
time/exploration sampling (s)       0.0801707
time/logging (s)                    0.00394491
time/saving (s)                     0.00294543
time/training (s)                   1.18485
time/epoch (s)                      1.57323
time/total (s)                    257.072
Epoch                             169
-----------------------------  ---------------
2019-04-22 20:56:55.189714 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 170 finished
-----------------------------  ---------------
replay_buffer/size              34400
trainer/QF1 Loss                    0.00495492
trainer/QF2 Loss                    0.00443382
trainer/Policy Loss                 5.91904
trainer/Q1 Predictions Mean        -4.09788
trainer/Q1 Predictions Std          0.803828
trainer/Q1 Predictions Max         -3.85626
trainer/Q1 Predictions Min        -11.3868
trainer/Q2 Predictions Mean        -4.10337
trainer/Q2 Predictions Std          0.812156
trainer/Q2 Predictions Max         -3.87285
trainer/Q2 Predictions Min        -11.4486
trainer/Q Targets Mean             -4.13536
trainer/Q Targets Std               0.800084
trainer/Q Targets Max              -3.87013
trainer/Q Targets Min             -11.4698
trainer/Log Pis Mean                1.89304
trainer/Log Pis Std                 1.17705
trainer/Log Pis Max                 5.67787
trainer/Log Pis Min                -3.30353
trainer/Policy mu Mean             -0.02982
trainer/Policy mu Std               0.544054
trainer/Policy mu Max               2.422
trainer/Policy mu Min              -2.52567
trainer/Policy log std Mean        -2.1222
trainer/Policy log std Std          0.422358
trainer/Policy log std Max         -0.471116
trainer/Policy log std Min         -2.47324
trainer/Alpha                       0.0199581
trainer/Alpha Loss                 -0.418646
exploration/num steps total     34400
exploration/num paths total       344
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.119067
exploration/Rewards Std             0.228647
exploration/Rewards Max            -0.00260181
exploration/Rewards Min            -1
exploration/Returns Mean          -11.9067
exploration/Returns Std             2.77624
exploration/Returns Max            -9.13043
exploration/Returns Min           -14.6829
exploration/Actions Mean            0.0430963
exploration/Actions Std             0.268167
exploration/Actions Max             0.996457
exploration/Actions Min            -0.80611
exploration/Num Paths               2
exploration/Average Returns       -11.9067
evaluation/num steps total     171000
evaluation/num paths total       1710
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.068095
evaluation/Rewards Std              0.17728
evaluation/Rewards Max             -0.0242448
evaluation/Rewards Min             -1
evaluation/Returns Mean            -6.8095
evaluation/Returns Std              2.62137
evaluation/Returns Max             -3.44859
evaluation/Returns Min            -11.5192
evaluation/Actions Mean             0.017225
evaluation/Actions Std              0.186398
evaluation/Actions Max              0.98725
evaluation/Actions Min             -0.987623
evaluation/Num Paths               10
evaluation/Average Returns         -6.8095
time/data storing (s)               0.00133271
time/evaluation sampling (s)        0.403108
time/exploration sampling (s)       0.0917717
time/logging (s)                    0.00382686
time/saving (s)                     0.00216625
time/training (s)                   1.09214
time/epoch (s)                      1.59434
time/total (s)                    258.672
Epoch                             170
-----------------------------  ---------------
2019-04-22 20:56:56.717816 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 171 finished
-----------------------------  ---------------
replay_buffer/size              34600
trainer/QF1 Loss                    0.00827233
trainer/QF2 Loss                    0.00788503
trainer/Policy Loss                 6.21923
trainer/Q1 Predictions Mean        -4.44261
trainer/Q1 Predictions Std          1.81293
trainer/Q1 Predictions Max         -3.8363
trainer/Q1 Predictions Min        -13.9416
trainer/Q2 Predictions Mean        -4.44862
trainer/Q2 Predictions Std          1.81264
trainer/Q2 Predictions Max         -3.84488
trainer/Q2 Predictions Min        -14.0125
trainer/Q Targets Mean             -4.48894
trainer/Q Targets Std               1.76095
trainer/Q Targets Max              -3.86943
trainer/Q Targets Min             -13.4821
trainer/Log Pis Mean                1.88445
trainer/Log Pis Std                 1.34311
trainer/Log Pis Max                 5.7437
trainer/Log Pis Min                -4.51976
trainer/Policy mu Mean              0.168359
trainer/Policy mu Std               0.636361
trainer/Policy mu Max               2.68521
trainer/Policy mu Min              -1.99039
trainer/Policy log std Mean        -2.07606
trainer/Policy log std Std          0.473178
trainer/Policy log std Max         -0.453665
trainer/Policy log std Min         -2.40973
trainer/Alpha                       0.019382
trainer/Alpha Loss                 -0.455641
exploration/num steps total     34600
exploration/num paths total       346
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.0834039
exploration/Rewards Std             0.118854
exploration/Rewards Max            -0.00533532
exploration/Rewards Min            -1
exploration/Returns Mean           -8.34039
exploration/Returns Std             0.355844
exploration/Returns Max            -7.98455
exploration/Returns Min            -8.69623
exploration/Actions Mean           -0.0206553
exploration/Actions Std             0.204748
exploration/Actions Max             0.904041
exploration/Actions Min            -0.997893
exploration/Num Paths               2
exploration/Average Returns        -8.34039
evaluation/num steps total     172000
evaluation/num paths total       1720
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0909083
evaluation/Rewards Std              0.198378
evaluation/Rewards Max             -0.0378473
evaluation/Rewards Min             -1
evaluation/Returns Mean            -9.09083
evaluation/Returns Std              2.43479
evaluation/Returns Max             -5.37431
evaluation/Returns Min            -13.194
evaluation/Actions Mean             0.0207069
evaluation/Actions Std              0.201859
evaluation/Actions Max              0.989888
evaluation/Actions Min             -0.993438
evaluation/Num Paths               10
evaluation/Average Returns         -9.09083
time/data storing (s)               0.00128968
time/evaluation sampling (s)        0.28936
time/exploration sampling (s)       0.0738691
time/logging (s)                    0.00322639
time/saving (s)                     0.00245245
time/training (s)                   1.14977
time/epoch (s)                      1.51997
time/total (s)                    260.196
Epoch                             171
-----------------------------  ---------------
2019-04-22 20:56:58.225216 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 172 finished
-----------------------------  ---------------
replay_buffer/size              34800
trainer/QF1 Loss                    0.00384173
trainer/QF2 Loss                    0.00457223
trainer/Policy Loss                 6.19551
trainer/Q1 Predictions Mean        -4.36289
trainer/Q1 Predictions Std          1.37718
trainer/Q1 Predictions Max         -3.84295
trainer/Q1 Predictions Min        -12.1263
trainer/Q2 Predictions Mean        -4.3598
trainer/Q2 Predictions Std          1.37345
trainer/Q2 Predictions Max         -3.84687
trainer/Q2 Predictions Min        -12.0882
trainer/Q Targets Mean             -4.39612
trainer/Q Targets Std               1.36369
trainer/Q Targets Max              -3.83614
trainer/Q Targets Min             -11.9931
trainer/Log Pis Mean                1.93229
trainer/Log Pis Std                 1.02314
trainer/Log Pis Max                 4.1726
trainer/Log Pis Min                -1.16415
trainer/Policy mu Mean              0.0956173
trainer/Policy mu Std               0.698509
trainer/Policy mu Max               2.54085
trainer/Policy mu Min              -2.44852
trainer/Policy log std Mean        -2.05351
trainer/Policy log std Std          0.527393
trainer/Policy log std Max         -0.402517
trainer/Policy log std Min         -2.44877
trainer/Alpha                       0.0194106
trainer/Alpha Loss                 -0.266912
exploration/num steps total     34800
exploration/num paths total       348
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.0993926
exploration/Rewards Std             0.200897
exploration/Rewards Max            -0.00164567
exploration/Rewards Min            -1
exploration/Returns Mean           -9.93926
exploration/Returns Std             0.102081
exploration/Returns Max            -9.83718
exploration/Returns Min           -10.0413
exploration/Actions Mean            0.0208106
exploration/Actions Std             0.241933
exploration/Actions Max             0.996579
exploration/Actions Min            -0.994849
exploration/Num Paths               2
exploration/Average Returns        -9.93926
evaluation/num steps total     173000
evaluation/num paths total       1730
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0665561
evaluation/Rewards Std              0.191559
evaluation/Rewards Max             -0.0197108
evaluation/Rewards Min             -1
evaluation/Returns Mean            -6.65561
evaluation/Returns Std              3.28698
evaluation/Returns Max             -2.34218
evaluation/Returns Min            -11.6413
evaluation/Actions Mean             0.0233692
evaluation/Actions Std              0.182548
evaluation/Actions Max              0.989053
evaluation/Actions Min             -0.967596
evaluation/Num Paths               10
evaluation/Average Returns         -6.65561
time/data storing (s)               0.00133549
time/evaluation sampling (s)        0.300115
time/exploration sampling (s)       0.0800835
time/logging (s)                    0.00360782
time/saving (s)                     0.0025957
time/training (s)                   1.11253
time/epoch (s)                      1.50027
time/total (s)                    261.701
Epoch                             172
-----------------------------  ---------------
2019-04-22 20:56:59.766256 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 173 finished
-----------------------------  ---------------
replay_buffer/size              35000
trainer/QF1 Loss                    0.149639
trainer/QF2 Loss                    0.149403
trainer/Policy Loss                 6.33825
trainer/Q1 Predictions Mean        -4.38682
trainer/Q1 Predictions Std          1.53009
trainer/Q1 Predictions Max         -3.80095
trainer/Q1 Predictions Min        -11.3951
trainer/Q2 Predictions Mean        -4.38337
trainer/Q2 Predictions Std          1.53032
trainer/Q2 Predictions Max         -3.79264
trainer/Q2 Predictions Min        -11.444
trainer/Q Targets Mean             -4.40488
trainer/Q Targets Std               1.59924
trainer/Q Targets Max              -0.0740083
trainer/Q Targets Min             -11.784
trainer/Log Pis Mean                2.06403
trainer/Log Pis Std                 1.11498
trainer/Log Pis Max                 4.71614
trainer/Log Pis Min                -2.74231
trainer/Policy mu Mean              0.036448
trainer/Policy mu Std               0.742612
trainer/Policy mu Max               2.58978
trainer/Policy mu Min              -1.80299
trainer/Policy log std Mean        -2.02542
trainer/Policy log std Std          0.55051
trainer/Policy log std Max         -0.512408
trainer/Policy log std Min         -2.49883
trainer/Alpha                       0.0196645
trainer/Alpha Loss                  0.251591
exploration/num steps total     35000
exploration/num paths total       350
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.0616423
exploration/Rewards Std             0.0377542
exploration/Rewards Max            -0.00445953
exploration/Rewards Min            -0.359368
exploration/Returns Mean           -6.16423
exploration/Returns Std             0.447633
exploration/Returns Max            -5.7166
exploration/Returns Min            -6.61186
exploration/Actions Mean            0.0101478
exploration/Actions Std             0.15054
exploration/Actions Max             0.996018
exploration/Actions Min            -0.391999
exploration/Num Paths               2
exploration/Average Returns        -6.16423
evaluation/num steps total     174000
evaluation/num paths total       1740
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0850736
evaluation/Rewards Std              0.190595
evaluation/Rewards Max             -0.0243239
evaluation/Rewards Min             -1
evaluation/Returns Mean            -8.50736
evaluation/Returns Std              2.69755
evaluation/Returns Max             -4.55629
evaluation/Returns Min            -12.6156
evaluation/Actions Mean             0.0170544
evaluation/Actions Std              0.187124
evaluation/Actions Max              0.990088
evaluation/Actions Min             -0.991311
evaluation/Num Paths               10
evaluation/Average Returns         -8.50736
time/data storing (s)               0.00130291
time/evaluation sampling (s)        0.314756
time/exploration sampling (s)       0.0810645
time/logging (s)                    0.00364052
time/saving (s)                     0.00230687
time/training (s)                   1.12978
time/epoch (s)                      1.53285
time/total (s)                    263.238
Epoch                             173
-----------------------------  ---------------
2019-04-22 20:57:01.437284 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 174 finished
-----------------------------  ----------------
replay_buffer/size              35200
trainer/QF1 Loss                    0.14488
trainer/QF2 Loss                    0.145262
trainer/Policy Loss                 5.90837
trainer/Q1 Predictions Mean        -4.20895
trainer/Q1 Predictions Std          1.37819
trainer/Q1 Predictions Max         -3.77634
trainer/Q1 Predictions Min        -11.5367
trainer/Q2 Predictions Mean        -4.20755
trainer/Q2 Predictions Std          1.38736
trainer/Q2 Predictions Max         -3.76962
trainer/Q2 Predictions Min        -11.5552
trainer/Q Targets Mean             -4.22807
trainer/Q Targets Std               1.42393
trainer/Q Targets Max              -0.117216
trainer/Q Targets Min             -11.3768
trainer/Log Pis Mean                1.78944
trainer/Log Pis Std                 1.25632
trainer/Log Pis Max                 4.14057
trainer/Log Pis Min                -4.5136
trainer/Policy mu Mean              0.0940163
trainer/Policy mu Std               0.587538
trainer/Policy mu Max               2.49773
trainer/Policy mu Min              -2.43714
trainer/Policy log std Mean        -2.11111
trainer/Policy log std Std          0.445238
trainer/Policy log std Max         -0.435039
trainer/Policy log std Min         -2.46834
trainer/Alpha                       0.0197596
trainer/Alpha Loss                 -0.826238
exploration/num steps total     35200
exploration/num paths total       352
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.0845177
exploration/Rewards Std             0.1538
exploration/Rewards Max            -0.000890046
exploration/Rewards Min            -1
exploration/Returns Mean           -8.45177
exploration/Returns Std             1.03214
exploration/Returns Max            -7.41963
exploration/Returns Min            -9.48391
exploration/Actions Mean            0.0221978
exploration/Actions Std             0.218636
exploration/Actions Max             0.994676
exploration/Actions Min            -0.97203
exploration/Num Paths               2
exploration/Average Returns        -8.45177
evaluation/num steps total     175000
evaluation/num paths total       1750
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0740291
evaluation/Rewards Std              0.191928
evaluation/Rewards Max             -0.0299155
evaluation/Rewards Min             -1
evaluation/Returns Mean            -7.40291
evaluation/Returns Std              2.11547
evaluation/Returns Max             -4.66731
evaluation/Returns Min            -11.5317
evaluation/Actions Mean             0.0272044
evaluation/Actions Std              0.194909
evaluation/Actions Max              0.988852
evaluation/Actions Min             -0.969665
evaluation/Num Paths               10
evaluation/Average Returns         -7.40291
time/data storing (s)               0.00146806
time/evaluation sampling (s)        0.327157
time/exploration sampling (s)       0.0874978
time/logging (s)                    0.00353746
time/saving (s)                     0.00196786
time/training (s)                   1.24207
time/epoch (s)                      1.6637
time/total (s)                    264.906
Epoch                             174
-----------------------------  ----------------
2019-04-22 20:57:02.956818 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 175 finished
-----------------------------  ---------------
replay_buffer/size              35400
trainer/QF1 Loss                    0.146252
trainer/QF2 Loss                    0.145412
trainer/Policy Loss                 6.22398
trainer/Q1 Predictions Mean        -4.47183
trainer/Q1 Predictions Std          1.97998
trainer/Q1 Predictions Max         -3.74332
trainer/Q1 Predictions Min        -13.9546
trainer/Q2 Predictions Mean        -4.46793
trainer/Q2 Predictions Std          1.97762
trainer/Q2 Predictions Max         -3.73964
trainer/Q2 Predictions Min        -13.8576
trainer/Q Targets Mean             -4.48721
trainer/Q Targets Std               1.98566
trainer/Q Targets Max              -0.0912564
trainer/Q Targets Min             -13.7465
trainer/Log Pis Mean                1.87156
trainer/Log Pis Std                 1.22282
trainer/Log Pis Max                 6.57134
trainer/Log Pis Min                -0.982458
trainer/Policy mu Mean              0.0995276
trainer/Policy mu Std               0.708332
trainer/Policy mu Max               2.51417
trainer/Policy mu Min              -2.39216
trainer/Policy log std Mean        -2.09549
trainer/Policy log std Std          0.563063
trainer/Policy log std Max         -0.415826
trainer/Policy log std Min         -2.50405
trainer/Alpha                       0.0199927
trainer/Alpha Loss                 -0.502529
exploration/num steps total     35400
exploration/num paths total       354
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.0642231
exploration/Rewards Std             0.0710589
exploration/Rewards Max            -0.00388379
exploration/Rewards Min            -0.874233
exploration/Returns Mean           -6.42231
exploration/Returns Std             0.511425
exploration/Returns Max            -5.91088
exploration/Returns Min            -6.93373
exploration/Actions Mean            0.0190939
exploration/Actions Std             0.171134
exploration/Actions Max             0.993641
exploration/Actions Min            -0.398159
exploration/Num Paths               2
exploration/Average Returns        -6.42231
evaluation/num steps total     176000
evaluation/num paths total       1760
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0826238
evaluation/Rewards Std              0.206257
evaluation/Rewards Max             -0.0284033
evaluation/Rewards Min             -1
evaluation/Returns Mean            -8.26238
evaluation/Returns Std              2.92181
evaluation/Returns Max             -3.71489
evaluation/Returns Min            -12.2084
evaluation/Actions Mean             0.0385533
evaluation/Actions Std              0.203671
evaluation/Actions Max              0.987969
evaluation/Actions Min             -0.983589
evaluation/Num Paths               10
evaluation/Average Returns         -8.26238
time/data storing (s)               0.00128737
time/evaluation sampling (s)        0.310481
time/exploration sampling (s)       0.0787012
time/logging (s)                    0.00356582
time/saving (s)                     0.00258995
time/training (s)                   1.11543
time/epoch (s)                      1.51206
time/total (s)                    266.422
Epoch                             175
-----------------------------  ---------------
2019-04-22 20:57:04.404735 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 176 finished
-----------------------------  ---------------
replay_buffer/size              35600
trainer/QF1 Loss                    0.00312022
trainer/QF2 Loss                    0.00341274
trainer/Policy Loss                 5.83411
trainer/Q1 Predictions Mean        -4.24368
trainer/Q1 Predictions Std          1.46217
trainer/Q1 Predictions Max         -3.76193
trainer/Q1 Predictions Min        -13.6914
trainer/Q2 Predictions Mean        -4.24283
trainer/Q2 Predictions Std          1.44872
trainer/Q2 Predictions Max         -3.76653
trainer/Q2 Predictions Min        -13.655
trainer/Q Targets Mean             -4.26389
trainer/Q Targets Std               1.44924
trainer/Q Targets Max              -3.77081
trainer/Q Targets Min             -13.8043
trainer/Log Pis Mean                1.66591
trainer/Log Pis Std                 1.14589
trainer/Log Pis Max                 4.09201
trainer/Log Pis Min                -4.15193
trainer/Policy mu Mean              0.048575
trainer/Policy mu Std               0.5975
trainer/Policy mu Max               2.35535
trainer/Policy mu Min              -2.36994
trainer/Policy log std Mean        -2.13808
trainer/Policy log std Std          0.491356
trainer/Policy log std Max         -0.525824
trainer/Policy log std Min         -2.50891
trainer/Alpha                       0.0201412
trainer/Alpha Loss                 -1.30461
exploration/num steps total     35600
exploration/num paths total       356
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.103586
exploration/Rewards Std             0.22263
exploration/Rewards Max            -0.00290985
exploration/Rewards Min            -1
exploration/Returns Mean          -10.3586
exploration/Returns Std             0.977649
exploration/Returns Max            -9.38097
exploration/Returns Min           -11.3363
exploration/Actions Mean            0.0442163
exploration/Actions Std             0.247619
exploration/Actions Max             0.997951
exploration/Actions Min            -0.880199
exploration/Num Paths               2
exploration/Average Returns       -10.3586
evaluation/num steps total     177000
evaluation/num paths total       1770
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0473435
evaluation/Rewards Std              0.195318
evaluation/Rewards Max             -0.0012126
evaluation/Rewards Min             -1
evaluation/Returns Mean            -4.73435
evaluation/Returns Std              2.33945
evaluation/Returns Max             -0.420811
evaluation/Returns Min             -8.95867
evaluation/Actions Mean             0.024681
evaluation/Actions Std              0.192052
evaluation/Actions Max              0.989976
evaluation/Actions Min             -0.985531
evaluation/Num Paths               10
evaluation/Average Returns         -4.73435
time/data storing (s)               0.00128309
time/evaluation sampling (s)        0.306494
time/exploration sampling (s)       0.0725545
time/logging (s)                    0.00369095
time/saving (s)                     0.00245694
time/training (s)                   1.0543
time/epoch (s)                      1.44078
time/total (s)                    267.867
Epoch                             176
-----------------------------  ---------------
2019-04-22 20:57:06.173308 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 177 finished
-----------------------------  ---------------
replay_buffer/size              35800
trainer/QF1 Loss                    0.00478904
trainer/QF2 Loss                    0.00505903
trainer/Policy Loss                 5.8094
trainer/Q1 Predictions Mean        -4.04349
trainer/Q1 Predictions Std          1.05093
trainer/Q1 Predictions Max         -3.71556
trainer/Q1 Predictions Min        -11.5607
trainer/Q2 Predictions Mean        -4.04366
trainer/Q2 Predictions Std          1.05446
trainer/Q2 Predictions Max         -3.71694
trainer/Q2 Predictions Min        -11.6063
trainer/Q Targets Mean             -4.09169
trainer/Q Targets Std               1.04448
trainer/Q Targets Max              -3.73614
trainer/Q Targets Min             -11.5837
trainer/Log Pis Mean                1.82826
trainer/Log Pis Std                 1.29205
trainer/Log Pis Max                 5.26197
trainer/Log Pis Min                -3.91859
trainer/Policy mu Mean              0.0510823
trainer/Policy mu Std               0.59256
trainer/Policy mu Max               2.59918
trainer/Policy mu Min              -1.55272
trainer/Policy log std Mean        -2.13695
trainer/Policy log std Std          0.463165
trainer/Policy log std Max         -0.505803
trainer/Policy log std Min         -2.48454
trainer/Alpha                       0.0198788
trainer/Alpha Loss                 -0.67291
exploration/num steps total     35800
exploration/num paths total       358
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.0577672
exploration/Rewards Std             0.0633032
exploration/Rewards Max            -0.00240585
exploration/Rewards Min            -0.698064
exploration/Returns Mean           -5.77672
exploration/Returns Std             0.0732559
exploration/Returns Max            -5.70346
exploration/Returns Min            -5.84997
exploration/Actions Mean            0.00841631
exploration/Actions Std             0.180834
exploration/Actions Max             0.992128
exploration/Actions Min            -0.91614
exploration/Num Paths               2
exploration/Average Returns        -5.77672
evaluation/num steps total     178000
evaluation/num paths total       1780
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0672403
evaluation/Rewards Std              0.201779
evaluation/Rewards Max             -0.0117638
evaluation/Rewards Min             -1
evaluation/Returns Mean            -6.72403
evaluation/Returns Std              2.2182
evaluation/Returns Max             -2.86954
evaluation/Returns Min            -10.0161
evaluation/Actions Mean             0.029333
evaluation/Actions Std              0.203367
evaluation/Actions Max              0.98985
evaluation/Actions Min             -0.97716
evaluation/Num Paths               10
evaluation/Average Returns         -6.72403
time/data storing (s)               0.00124388
time/evaluation sampling (s)        0.346401
time/exploration sampling (s)       0.0740091
time/logging (s)                    0.00350191
time/saving (s)                     0.00244492
time/training (s)                   1.33319
time/epoch (s)                      1.76079
time/total (s)                    269.632
Epoch                             177
-----------------------------  ---------------
2019-04-22 20:57:08.097473 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 178 finished
-----------------------------  ---------------
replay_buffer/size              36000
trainer/QF1 Loss                    0.139893
trainer/QF2 Loss                    0.139478
trainer/Policy Loss                 5.96869
trainer/Q1 Predictions Mean        -4.27445
trainer/Q1 Predictions Std          1.78216
trainer/Q1 Predictions Max         -3.72155
trainer/Q1 Predictions Min        -12.8855
trainer/Q2 Predictions Mean        -4.27282
trainer/Q2 Predictions Std          1.77
trainer/Q2 Predictions Max         -3.72686
trainer/Q2 Predictions Min        -12.7741
trainer/Q Targets Mean             -4.25846
trainer/Q Targets Std               1.81881
trainer/Q Targets Max              -0.104837
trainer/Q Targets Min             -12.8859
trainer/Log Pis Mean                1.79377
trainer/Log Pis Std                 1.05946
trainer/Log Pis Max                 4.19566
trainer/Log Pis Min                -2.00435
trainer/Policy mu Mean              0.0477849
trainer/Policy mu Std               0.570255
trainer/Policy mu Max               2.39572
trainer/Policy mu Min              -2.7495
trainer/Policy log std Mean        -2.14012
trainer/Policy log std Std          0.43277
trainer/Policy log std Max         -0.209275
trainer/Policy log std Min         -2.50003
trainer/Alpha                       0.0197634
trainer/Alpha Loss                 -0.809208
exploration/num steps total     36000
exploration/num paths total       360
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.098453
exploration/Rewards Std             0.183411
exploration/Rewards Max            -0.00199198
exploration/Rewards Min            -1
exploration/Returns Mean           -9.8453
exploration/Returns Std             0.529323
exploration/Returns Max            -9.31598
exploration/Returns Min           -10.3746
exploration/Actions Mean            0.01686
exploration/Actions Std             0.235915
exploration/Actions Max             0.994376
exploration/Actions Min            -0.991091
exploration/Num Paths               2
exploration/Average Returns        -9.8453
evaluation/num steps total     179000
evaluation/num paths total       1790
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.086235
evaluation/Rewards Std              0.211285
evaluation/Rewards Max             -0.0182708
evaluation/Rewards Min             -1
evaluation/Returns Mean            -8.6235
evaluation/Returns Std              2.41486
evaluation/Returns Max             -4.49826
evaluation/Returns Min            -11.7754
evaluation/Actions Mean             0.0243198
evaluation/Actions Std              0.20748
evaluation/Actions Max              0.990797
evaluation/Actions Min             -0.993451
evaluation/Num Paths               10
evaluation/Average Returns         -8.6235
time/data storing (s)               0.00129093
time/evaluation sampling (s)        0.29324
time/exploration sampling (s)       0.0780529
time/logging (s)                    0.00449737
time/saving (s)                     0.00260695
time/training (s)                   1.53823
time/epoch (s)                      1.91792
time/total (s)                    271.555
Epoch                             178
-----------------------------  ---------------
2019-04-22 20:57:09.785005 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 179 finished
-----------------------------  ---------------
replay_buffer/size              36200
trainer/QF1 Loss                    0.00370295
trainer/QF2 Loss                    0.00386713
trainer/Policy Loss                 6.01632
trainer/Q1 Predictions Mean        -4.07029
trainer/Q1 Predictions Std          1.22406
trainer/Q1 Predictions Max         -3.68478
trainer/Q1 Predictions Min        -12.6605
trainer/Q2 Predictions Mean        -4.06711
trainer/Q2 Predictions Std          1.22599
trainer/Q2 Predictions Max         -3.67567
trainer/Q2 Predictions Min        -12.7512
trainer/Q Targets Mean             -4.11255
trainer/Q Targets Std               1.22822
trainer/Q Targets Max              -3.69289
trainer/Q Targets Min             -12.8806
trainer/Log Pis Mean                2.03191
trainer/Log Pis Std                 0.970653
trainer/Log Pis Max                 4.91503
trainer/Log Pis Min                -1.06783
trainer/Policy mu Mean              0.0251825
trainer/Policy mu Std               0.651251
trainer/Policy mu Max               2.56731
trainer/Policy mu Min              -2.55875
trainer/Policy log std Mean        -2.16243
trainer/Policy log std Std          0.508277
trainer/Policy log std Max         -0.378061
trainer/Policy log std Min         -2.57788
trainer/Alpha                       0.0198722
trainer/Alpha Loss                  0.125047
exploration/num steps total     36200
exploration/num paths total       362
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.100444
exploration/Rewards Std             0.205109
exploration/Rewards Max            -0.00360454
exploration/Rewards Min            -1
exploration/Returns Mean          -10.0444
exploration/Returns Std             2.35076
exploration/Returns Max            -7.69368
exploration/Returns Min           -12.3952
exploration/Actions Mean            0.0403272
exploration/Actions Std             0.244818
exploration/Actions Max             0.99893
exploration/Actions Min            -0.809514
exploration/Num Paths               2
exploration/Average Returns       -10.0444
evaluation/num steps total     180000
evaluation/num paths total       1800
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0698368
evaluation/Rewards Std              0.201336
evaluation/Rewards Max             -0.0168078
evaluation/Rewards Min             -1
evaluation/Returns Mean            -6.98368
evaluation/Returns Std              2.61996
evaluation/Returns Max             -2.2311
evaluation/Returns Min            -10.4379
evaluation/Actions Mean             0.0359693
evaluation/Actions Std              0.203108
evaluation/Actions Max              0.990103
evaluation/Actions Min             -0.982978
evaluation/Num Paths               10
evaluation/Average Returns         -6.98368
time/data storing (s)               0.00135782
time/evaluation sampling (s)        0.30117
time/exploration sampling (s)       0.0763214
time/logging (s)                    0.00439496
time/saving (s)                     0.00313019
time/training (s)                   1.29283
time/epoch (s)                      1.6792
time/total (s)                    273.239
Epoch                             179
-----------------------------  ---------------
2019-04-22 20:57:11.490943 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 180 finished
-----------------------------  ---------------
replay_buffer/size              36400
trainer/QF1 Loss                    0.140684
trainer/QF2 Loss                    0.140104
trainer/Policy Loss                 5.67184
trainer/Q1 Predictions Mean        -3.9002
trainer/Q1 Predictions Std          0.573139
trainer/Q1 Predictions Max         -3.68003
trainer/Q1 Predictions Min         -8.88855
trainer/Q2 Predictions Mean        -3.90203
trainer/Q2 Predictions Std          0.585478
trainer/Q2 Predictions Max         -3.68018
trainer/Q2 Predictions Min         -9.03972
trainer/Q Targets Mean             -3.88739
trainer/Q Targets Std               0.710545
trainer/Q Targets Max              -0.0748346
trainer/Q Targets Min              -9.23243
trainer/Log Pis Mean                1.85333
trainer/Log Pis Std                 1.16824
trainer/Log Pis Max                 4.52081
trainer/Log Pis Min                -3.07811
trainer/Policy mu Mean              0.0405875
trainer/Policy mu Std               0.511104
trainer/Policy mu Max               2.37643
trainer/Policy mu Min              -1.60036
trainer/Policy log std Mean        -2.18443
trainer/Policy log std Std          0.410279
trainer/Policy log std Max         -0.611402
trainer/Policy log std Min         -2.51189
trainer/Alpha                       0.0203271
trainer/Alpha Loss                 -0.571383
exploration/num steps total     36400
exploration/num paths total       364
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.105637
exploration/Rewards Std             0.215883
exploration/Rewards Max            -0.0071404
exploration/Rewards Min            -1
exploration/Returns Mean          -10.5637
exploration/Returns Std             2.20745
exploration/Returns Max            -8.35624
exploration/Returns Min           -12.7711
exploration/Actions Mean           -0.00537596
exploration/Actions Std             0.25678
exploration/Actions Max             0.998577
exploration/Actions Min            -0.992265
exploration/Num Paths               2
exploration/Average Returns       -10.5637
evaluation/num steps total     181000
evaluation/num paths total       1810
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0661679
evaluation/Rewards Std              0.200707
evaluation/Rewards Max             -0.0111858
evaluation/Rewards Min             -1
evaluation/Returns Mean            -6.61679
evaluation/Returns Std              3.12443
evaluation/Returns Max             -2.11025
evaluation/Returns Min            -11.1324
evaluation/Actions Mean             0.0304476
evaluation/Actions Std              0.193515
evaluation/Actions Max              0.988805
evaluation/Actions Min             -0.972984
evaluation/Num Paths               10
evaluation/Average Returns         -6.61679
time/data storing (s)               0.00150261
time/evaluation sampling (s)        0.31424
time/exploration sampling (s)       0.0770342
time/logging (s)                    0.00375208
time/saving (s)                     0.0025624
time/training (s)                   1.29641
time/epoch (s)                      1.6955
time/total (s)                    274.94
Epoch                             180
-----------------------------  ---------------
2019-04-22 20:57:12.991791 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 181 finished
-----------------------------  ---------------
replay_buffer/size              36600
trainer/QF1 Loss                    0.263438
trainer/QF2 Loss                    0.263798
trainer/Policy Loss                 5.85896
trainer/Q1 Predictions Mean        -4.04281
trainer/Q1 Predictions Std          1.2123
trainer/Q1 Predictions Max         -3.61314
trainer/Q1 Predictions Min        -11.226
trainer/Q2 Predictions Mean        -4.04062
trainer/Q2 Predictions Std          1.20223
trainer/Q2 Predictions Max         -3.61942
trainer/Q2 Predictions Min        -11.1478
trainer/Q Targets Mean             -4.04588
trainer/Q Targets Std               1.33584
trainer/Q Targets Max              -0.0837462
trainer/Q Targets Min             -11.3357
trainer/Log Pis Mean                1.89088
trainer/Log Pis Std                 1.19788
trainer/Log Pis Max                 4.08695
trainer/Log Pis Min                -3.44392
trainer/Policy mu Mean              0.0985451
trainer/Policy mu Std               0.66183
trainer/Policy mu Max               2.53325
trainer/Policy mu Min              -1.99537
trainer/Policy log std Mean        -2.11748
trainer/Policy log std Std          0.536516
trainer/Policy log std Max         -0.52819
trainer/Policy log std Min         -2.55349
trainer/Alpha                       0.0200876
trainer/Alpha Loss                 -0.426383
exploration/num steps total     36600
exploration/num paths total       366
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.0665276
exploration/Rewards Std             0.122765
exploration/Rewards Max            -0.00163341
exploration/Rewards Min            -1
exploration/Returns Mean           -6.65276
exploration/Returns Std             1.48503
exploration/Returns Max            -5.16773
exploration/Returns Min            -8.13779
exploration/Actions Mean            0.00239108
exploration/Actions Std             0.197378
exploration/Actions Max             0.998566
exploration/Actions Min            -0.988113
exploration/Num Paths               2
exploration/Average Returns        -6.65276
evaluation/num steps total     182000
evaluation/num paths total       1820
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0651629
evaluation/Rewards Std              0.18239
evaluation/Rewards Max             -0.00644881
evaluation/Rewards Min             -1
evaluation/Returns Mean            -6.51629
evaluation/Returns Std              3.25491
evaluation/Returns Max             -2.62767
evaluation/Returns Min            -11.8204
evaluation/Actions Mean             0.0206992
evaluation/Actions Std              0.186507
evaluation/Actions Max              0.987715
evaluation/Actions Min             -0.990644
evaluation/Num Paths               10
evaluation/Average Returns         -6.51629
time/data storing (s)               0.00129425
time/evaluation sampling (s)        0.322969
time/exploration sampling (s)       0.0767848
time/logging (s)                    0.00420504
time/saving (s)                     0.00358781
time/training (s)                   1.08456
time/epoch (s)                      1.4934
time/total (s)                    276.439
Epoch                             181
-----------------------------  ---------------
2019-04-22 20:57:14.810690 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 182 finished
-----------------------------  ---------------
replay_buffer/size              36800
trainer/QF1 Loss                    0.00488727
trainer/QF2 Loss                    0.00731994
trainer/Policy Loss                 5.99366
trainer/Q1 Predictions Mean        -4.21427
trainer/Q1 Predictions Std          1.60675
trainer/Q1 Predictions Max         -3.63244
trainer/Q1 Predictions Min        -12.4682
trainer/Q2 Predictions Mean        -4.2271
trainer/Q2 Predictions Std          1.60483
trainer/Q2 Predictions Max         -3.64342
trainer/Q2 Predictions Min        -12.5456
trainer/Q Targets Mean             -4.2576
trainer/Q Targets Std               1.61689
trainer/Q Targets Max              -3.6492
trainer/Q Targets Min             -12.5804
trainer/Log Pis Mean                1.8889
trainer/Log Pis Std                 1.23589
trainer/Log Pis Max                 6.46749
trainer/Log Pis Min                -1.96096
trainer/Policy mu Mean              0.0145271
trainer/Policy mu Std               0.711833
trainer/Policy mu Max               2.55785
trainer/Policy mu Min              -2.5926
trainer/Policy log std Mean        -2.04427
trainer/Policy log std Std          0.538174
trainer/Policy log std Max         -0.413354
trainer/Policy log std Min         -2.43207
trainer/Alpha                       0.0199327
trainer/Alpha Loss                 -0.434997
exploration/num steps total     36800
exploration/num paths total       368
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.0678544
exploration/Rewards Std             0.103334
exploration/Rewards Max            -0.0070925
exploration/Rewards Min            -1
exploration/Returns Mean           -6.78544
exploration/Returns Std             0.621978
exploration/Returns Max            -6.16346
exploration/Returns Min            -7.40742
exploration/Actions Mean            0.0217972
exploration/Actions Std             0.182558
exploration/Actions Max             0.997011
exploration/Actions Min            -0.333203
exploration/Num Paths               2
exploration/Average Returns        -6.78544
evaluation/num steps total     183000
evaluation/num paths total       1830
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0597892
evaluation/Rewards Std              0.173492
evaluation/Rewards Max             -0.0139765
evaluation/Rewards Min             -1
evaluation/Returns Mean            -5.97892
evaluation/Returns Std              2.97608
evaluation/Returns Max             -2.94449
evaluation/Returns Min            -11.1979
evaluation/Actions Mean             0.0258208
evaluation/Actions Std              0.181885
evaluation/Actions Max              0.990947
evaluation/Actions Min             -0.986486
evaluation/Num Paths               10
evaluation/Average Returns         -5.97892
time/data storing (s)               0.00153637
time/evaluation sampling (s)        0.419596
time/exploration sampling (s)       0.081084
time/logging (s)                    0.00374465
time/saving (s)                     0.00253713
time/training (s)                   1.29981
time/epoch (s)                      1.80831
time/total (s)                    278.253
Epoch                             182
-----------------------------  ---------------
2019-04-22 20:57:16.430283 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 183 finished
-----------------------------  ---------------
replay_buffer/size              37000
trainer/QF1 Loss                    0.140354
trainer/QF2 Loss                    0.142549
trainer/Policy Loss                 5.98486
trainer/Q1 Predictions Mean        -4.08303
trainer/Q1 Predictions Std          1.2953
trainer/Q1 Predictions Max         -3.61178
trainer/Q1 Predictions Min        -11.853
trainer/Q2 Predictions Mean        -4.08593
trainer/Q2 Predictions Std          1.2895
trainer/Q2 Predictions Max         -3.61991
trainer/Q2 Predictions Min        -11.8673
trainer/Q Targets Mean             -4.0904
trainer/Q Targets Std               1.3321
trainer/Q Targets Max              -0.377727
trainer/Q Targets Min             -11.5919
trainer/Log Pis Mean                2.01433
trainer/Log Pis Std                 0.985028
trainer/Log Pis Max                 5.32845
trainer/Log Pis Min                -0.51139
trainer/Policy mu Mean              0.0925234
trainer/Policy mu Std               0.679195
trainer/Policy mu Max               2.46535
trainer/Policy mu Min              -1.59011
trainer/Policy log std Mean        -2.03839
trainer/Policy log std Std          0.512127
trainer/Policy log std Max         -0.438482
trainer/Policy log std Min         -2.43998
trainer/Alpha                       0.0197147
trainer/Alpha Loss                  0.0562639
exploration/num steps total     37000
exploration/num paths total       370
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.122874
exploration/Rewards Std             0.240116
exploration/Rewards Max            -0.00545332
exploration/Rewards Min            -1
exploration/Returns Mean          -12.2874
exploration/Returns Std             0.760539
exploration/Returns Max           -11.5269
exploration/Returns Min           -13.0479
exploration/Actions Mean            0.0324529
exploration/Actions Std             0.276297
exploration/Actions Max             0.997557
exploration/Actions Min            -0.964025
exploration/Num Paths               2
exploration/Average Returns       -12.2874
evaluation/num steps total     184000
evaluation/num paths total       1840
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.052227
evaluation/Rewards Std              0.158722
evaluation/Rewards Max             -0.00661697
evaluation/Rewards Min             -1
evaluation/Returns Mean            -5.2227
evaluation/Returns Std              1.76308
evaluation/Returns Max             -2.19223
evaluation/Returns Min             -7.16202
evaluation/Actions Mean             0.0238451
evaluation/Actions Std              0.183212
evaluation/Actions Max              0.987146
evaluation/Actions Min             -0.986961
evaluation/Num Paths               10
evaluation/Average Returns         -5.2227
time/data storing (s)               0.00140718
time/evaluation sampling (s)        0.327025
time/exploration sampling (s)       0.0745397
time/logging (s)                    0.00367097
time/saving (s)                     0.00249544
time/training (s)                   1.20119
time/epoch (s)                      1.61033
time/total (s)                    279.868
Epoch                             183
-----------------------------  ---------------
2019-04-22 20:57:17.804743 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 184 finished
-----------------------------  ----------------
replay_buffer/size              37200
trainer/QF1 Loss                    0.134061
trainer/QF2 Loss                    0.133508
trainer/Policy Loss                 5.89329
trainer/Q1 Predictions Mean        -4.07541
trainer/Q1 Predictions Std          1.38677
trainer/Q1 Predictions Max         -3.6295
trainer/Q1 Predictions Min        -11.4617
trainer/Q2 Predictions Mean        -4.07128
trainer/Q2 Predictions Std          1.38792
trainer/Q2 Predictions Max         -3.62065
trainer/Q2 Predictions Min        -11.3778
trainer/Q Targets Mean             -4.06376
trainer/Q Targets Std               1.43608
trainer/Q Targets Max              -0.0530277
trainer/Q Targets Min             -11.3487
trainer/Log Pis Mean                1.92067
trainer/Log Pis Std                 1.06613
trainer/Log Pis Max                 5.35712
trainer/Log Pis Min                -2.1215
trainer/Policy mu Mean              0.066999
trainer/Policy mu Std               0.562986
trainer/Policy mu Max               2.4393
trainer/Policy mu Min              -1.91549
trainer/Policy log std Mean        -2.13507
trainer/Policy log std Std          0.421503
trainer/Policy log std Max         -0.608971
trainer/Policy log std Min         -2.45429
trainer/Alpha                       0.0196835
trainer/Alpha Loss                 -0.311605
exploration/num steps total     37200
exploration/num paths total       372
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.0799808
exploration/Rewards Std             0.13721
exploration/Rewards Max            -0.000811552
exploration/Rewards Min            -1
exploration/Returns Mean           -7.99808
exploration/Returns Std             2.28657
exploration/Returns Max            -5.71151
exploration/Returns Min           -10.2846
exploration/Actions Mean            0.00235419
exploration/Actions Std             0.20238
exploration/Actions Max             0.995477
exploration/Actions Min            -0.992789
exploration/Num Paths               2
exploration/Average Returns        -7.99808
evaluation/num steps total     185000
evaluation/num paths total       1850
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0803072
evaluation/Rewards Std              0.186067
evaluation/Rewards Max             -0.0186461
evaluation/Rewards Min             -1
evaluation/Returns Mean            -8.03072
evaluation/Returns Std              2.46578
evaluation/Returns Max             -4.45919
evaluation/Returns Min            -12.9534
evaluation/Actions Mean             0.0301818
evaluation/Actions Std              0.192225
evaluation/Actions Max              0.990765
evaluation/Actions Min             -0.984292
evaluation/Num Paths               10
evaluation/Average Returns         -8.03072
time/data storing (s)               0.00129556
time/evaluation sampling (s)        0.278106
time/exploration sampling (s)       0.0723295
time/logging (s)                    0.00369438
time/saving (s)                     0.0025858
time/training (s)                   1.00867
time/epoch (s)                      1.36669
time/total (s)                    281.239
Epoch                             184
-----------------------------  ----------------
2019-04-22 20:57:19.304141 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 185 finished
-----------------------------  ---------------
replay_buffer/size              37400
trainer/QF1 Loss                    0.00885514
trainer/QF2 Loss                    0.00953101
trainer/Policy Loss                 5.84882
trainer/Q1 Predictions Mean        -4.02523
trainer/Q1 Predictions Std          1.48402
trainer/Q1 Predictions Max         -3.57265
trainer/Q1 Predictions Min        -12.6793
trainer/Q2 Predictions Mean        -4.02296
trainer/Q2 Predictions Std          1.48221
trainer/Q2 Predictions Max         -3.57697
trainer/Q2 Predictions Min        -12.6066
trainer/Q Targets Mean             -4.09527
trainer/Q Targets Std               1.48338
trainer/Q Targets Max              -3.60564
trainer/Q Targets Min             -12.7115
trainer/Log Pis Mean                1.91552
trainer/Log Pis Std                 1.27419
trainer/Log Pis Max                 5.83609
trainer/Log Pis Min                -1.89722
trainer/Policy mu Mean              0.0580562
trainer/Policy mu Std               0.58201
trainer/Policy mu Max               2.6402
trainer/Policy mu Min              -2.42585
trainer/Policy log std Mean        -2.11055
trainer/Policy log std Std          0.440828
trainer/Policy log std Max         -0.559912
trainer/Policy log std Min         -2.45581
trainer/Alpha                       0.0195327
trainer/Alpha Loss                 -0.332501
exploration/num steps total     37400
exploration/num paths total       374
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.102872
exploration/Rewards Std             0.205123
exploration/Rewards Max            -0.00204114
exploration/Rewards Min            -1
exploration/Returns Mean          -10.2872
exploration/Returns Std             3.19902
exploration/Returns Max            -7.0882
exploration/Returns Min           -13.4862
exploration/Actions Mean            0.0259113
exploration/Actions Std             0.247239
exploration/Actions Max             0.991784
exploration/Actions Min            -0.982827
exploration/Num Paths               2
exploration/Average Returns       -10.2872
evaluation/num steps total     186000
evaluation/num paths total       1860
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0681038
evaluation/Rewards Std              0.21962
evaluation/Rewards Max             -0.0114212
evaluation/Rewards Min             -1
evaluation/Returns Mean            -6.81038
evaluation/Returns Std              2.677
evaluation/Returns Max             -2.42376
evaluation/Returns Min            -10.2914
evaluation/Actions Mean             0.0404615
evaluation/Actions Std              0.209469
evaluation/Actions Max              0.99099
evaluation/Actions Min             -0.916197
evaluation/Num Paths               10
evaluation/Average Returns         -6.81038
time/data storing (s)               0.00135298
time/evaluation sampling (s)        0.3126
time/exploration sampling (s)       0.0752544
time/logging (s)                    0.00389072
time/saving (s)                     0.00246341
time/training (s)                   1.09593
time/epoch (s)                      1.49149
time/total (s)                    282.736
Epoch                             185
-----------------------------  ---------------
2019-04-22 20:57:20.737334 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 186 finished
-----------------------------  ---------------
replay_buffer/size              37600
trainer/QF1 Loss                    0.255884
trainer/QF2 Loss                    0.257811
trainer/Policy Loss                 6.3525
trainer/Q1 Predictions Mean        -4.49177
trainer/Q1 Predictions Std          2.20238
trainer/Q1 Predictions Max         -3.54293
trainer/Q1 Predictions Min        -12.3343
trainer/Q2 Predictions Mean        -4.49038
trainer/Q2 Predictions Std          2.18689
trainer/Q2 Predictions Max         -3.55539
trainer/Q2 Predictions Min        -12.2557
trainer/Q Targets Mean             -4.47472
trainer/Q Targets Std               2.25985
trainer/Q Targets Max              -0.0307667
trainer/Q Targets Min             -12.5141
trainer/Log Pis Mean                1.99894
trainer/Log Pis Std                 1.29108
trainer/Log Pis Max                 5.61052
trainer/Log Pis Min                -2.21539
trainer/Policy mu Mean              0.211798
trainer/Policy mu Std               0.812413
trainer/Policy mu Max               2.62727
trainer/Policy mu Min              -2.11609
trainer/Policy log std Mean        -2.03083
trainer/Policy log std Std          0.579375
trainer/Policy log std Max         -0.546259
trainer/Policy log std Min         -2.4915
trainer/Alpha                       0.0196788
trainer/Alpha Loss                 -0.00414993
exploration/num steps total     37600
exploration/num paths total       376
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.0918742
exploration/Rewards Std             0.176034
exploration/Rewards Max            -0.00169608
exploration/Rewards Min            -1
exploration/Returns Mean           -9.18742
exploration/Returns Std             1.67393
exploration/Returns Max            -7.51349
exploration/Returns Min           -10.8614
exploration/Actions Mean            0.019924
exploration/Actions Std             0.220089
exploration/Actions Max             0.991511
exploration/Actions Min            -0.96191
exploration/Num Paths               2
exploration/Average Returns        -9.18742
evaluation/num steps total     187000
evaluation/num paths total       1870
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0677176
evaluation/Rewards Std              0.189668
evaluation/Rewards Max             -0.016417
evaluation/Rewards Min             -1
evaluation/Returns Mean            -6.77176
evaluation/Returns Std              3.21865
evaluation/Returns Max             -2.56696
evaluation/Returns Min            -11.8199
evaluation/Actions Mean             0.0236261
evaluation/Actions Std              0.189385
evaluation/Actions Max              0.990573
evaluation/Actions Min             -0.990588
evaluation/Num Paths               10
evaluation/Average Returns         -6.77176
time/data storing (s)               0.00128584
time/evaluation sampling (s)        0.291128
time/exploration sampling (s)       0.0736838
time/logging (s)                    0.00370703
time/saving (s)                     0.00260997
time/training (s)                   1.05225
time/epoch (s)                      1.42466
time/total (s)                    284.165
Epoch                             186
-----------------------------  ---------------
2019-04-22 20:57:22.134466 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 187 finished
-----------------------------  ---------------
replay_buffer/size              37800
trainer/QF1 Loss                    0.406007
trainer/QF2 Loss                    0.404241
trainer/Policy Loss                 5.89913
trainer/Q1 Predictions Mean        -4.02975
trainer/Q1 Predictions Std          1.17589
trainer/Q1 Predictions Max         -3.6611
trainer/Q1 Predictions Min        -12.6051
trainer/Q2 Predictions Mean        -4.02493
trainer/Q2 Predictions Std          1.16867
trainer/Q2 Predictions Max         -3.65062
trainer/Q2 Predictions Min        -12.5542
trainer/Q Targets Mean             -3.85412
trainer/Q Targets Std               1.35292
trainer/Q Targets Max              -0.0739758
trainer/Q Targets Min             -12.4795
trainer/Log Pis Mean                1.95909
trainer/Log Pis Std                 1.28813
trainer/Log Pis Max                 6.31285
trainer/Log Pis Min                -4.26003
trainer/Policy mu Mean              0.0527169
trainer/Policy mu Std               0.647737
trainer/Policy mu Max               2.53961
trainer/Policy mu Min              -2.3832
trainer/Policy log std Mean        -2.12884
trainer/Policy log std Std          0.487791
trainer/Policy log std Max         -0.476722
trainer/Policy log std Min         -2.5214
trainer/Alpha                       0.0198934
trainer/Alpha Loss                 -0.160247
exploration/num steps total     37800
exploration/num paths total       378
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.075303
exploration/Rewards Std             0.127981
exploration/Rewards Max            -0.00775648
exploration/Rewards Min            -1
exploration/Returns Mean           -7.5303
exploration/Returns Std             2.12486
exploration/Returns Max            -5.40544
exploration/Returns Min            -9.65516
exploration/Actions Mean            0.0178398
exploration/Actions Std             0.197754
exploration/Actions Max             0.997625
exploration/Actions Min            -0.701421
exploration/Num Paths               2
exploration/Average Returns        -7.5303
evaluation/num steps total     188000
evaluation/num paths total       1880
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0858403
evaluation/Rewards Std              0.19739
evaluation/Rewards Max             -0.0150251
evaluation/Rewards Min             -1
evaluation/Returns Mean            -8.58403
evaluation/Returns Std              3.35938
evaluation/Returns Max             -4.03332
evaluation/Returns Min            -13.0411
evaluation/Actions Mean             0.0280179
evaluation/Actions Std              0.203351
evaluation/Actions Max              0.98997
evaluation/Actions Min             -0.984263
evaluation/Num Paths               10
evaluation/Average Returns         -8.58403
time/data storing (s)               0.00135012
time/evaluation sampling (s)        0.29009
time/exploration sampling (s)       0.0744063
time/logging (s)                    0.00331069
time/saving (s)                     0.00256766
time/training (s)                   1.01647
time/epoch (s)                      1.3882
time/total (s)                    285.559
Epoch                             187
-----------------------------  ---------------
2019-04-22 20:57:23.593189 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 188 finished
-----------------------------  ----------------
replay_buffer/size              38000
trainer/QF1 Loss                    0.129841
trainer/QF2 Loss                    0.129431
trainer/Policy Loss                 6.09031
trainer/Q1 Predictions Mean        -4.00165
trainer/Q1 Predictions Std          1.3279
trainer/Q1 Predictions Max         -3.56374
trainer/Q1 Predictions Min        -11.1489
trainer/Q2 Predictions Mean        -3.99526
trainer/Q2 Predictions Std          1.32252
trainer/Q2 Predictions Max         -3.55672
trainer/Q2 Predictions Min        -11.0897
trainer/Q Targets Mean             -3.99317
trainer/Q Targets Std               1.37995
trainer/Q Targets Max              -0.0293724
trainer/Q Targets Min             -10.8969
trainer/Log Pis Mean                2.15112
trainer/Log Pis Std                 1.32241
trainer/Log Pis Max                 5.23576
trainer/Log Pis Min                -4.63827
trainer/Policy mu Mean              0.107134
trainer/Policy mu Std               0.628402
trainer/Policy mu Max               2.69408
trainer/Policy mu Min              -2.50296
trainer/Policy log std Mean        -2.1471
trainer/Policy log std Std          0.483419
trainer/Policy log std Max         -0.551394
trainer/Policy log std Min         -2.484
trainer/Alpha                       0.019399
trainer/Alpha Loss                  0.595815
exploration/num steps total     38000
exploration/num paths total       380
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.12792
exploration/Rewards Std             0.255226
exploration/Rewards Max            -0.00318786
exploration/Rewards Min            -1
exploration/Returns Mean          -12.792
exploration/Returns Std             0.639163
exploration/Returns Max           -12.1528
exploration/Returns Min           -13.4311
exploration/Actions Mean            0.0558584
exploration/Actions Std             0.26696
exploration/Actions Max             0.995464
exploration/Actions Min            -0.787895
exploration/Num Paths               2
exploration/Average Returns       -12.792
evaluation/num steps total     189000
evaluation/num paths total       1890
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0329456
evaluation/Rewards Std              0.163026
evaluation/Rewards Max             -0.000434607
evaluation/Rewards Min             -1
evaluation/Returns Mean            -3.29456
evaluation/Returns Std              2.18609
evaluation/Returns Max             -0.197907
evaluation/Returns Min             -6.57508
evaluation/Actions Mean             0.0247478
evaluation/Actions Std              0.160139
evaluation/Actions Max              0.992951
evaluation/Actions Min             -0.953506
evaluation/Num Paths               10
evaluation/Average Returns         -3.29456
time/data storing (s)               0.0012825
time/evaluation sampling (s)        0.278128
time/exploration sampling (s)       0.0710868
time/logging (s)                    0.00400863
time/saving (s)                     0.0031093
time/training (s)                   1.0945
time/epoch (s)                      1.45211
time/total (s)                    287.016
Epoch                             188
-----------------------------  ----------------
2019-04-22 20:57:25.129726 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 189 finished
-----------------------------  ---------------
replay_buffer/size              38200
trainer/QF1 Loss                    0.130297
trainer/QF2 Loss                    0.130568
trainer/Policy Loss                 5.94863
trainer/Q1 Predictions Mean        -4.0852
trainer/Q1 Predictions Std          1.66309
trainer/Q1 Predictions Max         -3.57328
trainer/Q1 Predictions Min        -12.0604
trainer/Q2 Predictions Mean        -4.07973
trainer/Q2 Predictions Std          1.66103
trainer/Q2 Predictions Max         -3.57034
trainer/Q2 Predictions Min        -12.0396
trainer/Q Targets Mean             -4.0678
trainer/Q Targets Std               1.72816
trainer/Q Targets Max              -0.0920502
trainer/Q Targets Min             -12.2772
trainer/Log Pis Mean                1.94562
trainer/Log Pis Std                 1.17598
trainer/Log Pis Max                 4.98034
trainer/Log Pis Min                -2.08314
trainer/Policy mu Mean              0.100749
trainer/Policy mu Std               0.630185
trainer/Policy mu Max               2.39796
trainer/Policy mu Min              -1.96003
trainer/Policy log std Mean        -2.09062
trainer/Policy log std Std          0.487393
trainer/Policy log std Max         -0.487647
trainer/Policy log std Min         -2.43309
trainer/Alpha                       0.0195386
trainer/Alpha Loss                 -0.214012
exploration/num steps total     38200
exploration/num paths total       382
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.113218
exploration/Rewards Std             0.231511
exploration/Rewards Max            -0.00296665
exploration/Rewards Min            -1
exploration/Returns Mean          -11.3218
exploration/Returns Std             1.57344
exploration/Returns Max            -9.74831
exploration/Returns Min           -12.8952
exploration/Actions Mean            0.033972
exploration/Actions Std             0.252683
exploration/Actions Max             0.996267
exploration/Actions Min            -0.931568
exploration/Num Paths               2
exploration/Average Returns       -11.3218
evaluation/num steps total     190000
evaluation/num paths total       1900
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0551307
evaluation/Rewards Std              0.193696
evaluation/Rewards Max             -0.011604
evaluation/Rewards Min             -1
evaluation/Returns Mean            -5.51307
evaluation/Returns Std              3.05276
evaluation/Returns Max             -1.19355
evaluation/Returns Min             -9.69813
evaluation/Actions Mean             0.0238256
evaluation/Actions Std              0.187154
evaluation/Actions Max              0.989616
evaluation/Actions Min             -0.977347
evaluation/Num Paths               10
evaluation/Average Returns         -5.51307
time/data storing (s)               0.00126926
time/evaluation sampling (s)        0.288985
time/exploration sampling (s)       0.0736873
time/logging (s)                    0.0031011
time/saving (s)                     0.0023838
time/training (s)                   1.1566
time/epoch (s)                      1.52602
time/total (s)                    288.546
Epoch                             189
-----------------------------  ---------------
2019-04-22 20:57:26.640435 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 190 finished
-----------------------------  ---------------
replay_buffer/size              38400
trainer/QF1 Loss                    0.00719951
trainer/QF2 Loss                    0.00798565
trainer/Policy Loss                 5.57048
trainer/Q1 Predictions Mean        -3.85118
trainer/Q1 Predictions Std          1.29671
trainer/Q1 Predictions Max         -3.51575
trainer/Q1 Predictions Min        -12.5634
trainer/Q2 Predictions Mean        -3.84552
trainer/Q2 Predictions Std          1.3005
trainer/Q2 Predictions Max         -3.49836
trainer/Q2 Predictions Min        -12.4664
trainer/Q Targets Mean             -3.90849
trainer/Q Targets Std               1.34225
trainer/Q Targets Max              -3.52151
trainer/Q Targets Min             -12.952
trainer/Log Pis Mean                1.78073
trainer/Log Pis Std                 1.24144
trainer/Log Pis Max                 5.85044
trainer/Log Pis Min                -2.25667
trainer/Policy mu Mean              0.0258889
trainer/Policy mu Std               0.499608
trainer/Policy mu Max               2.45754
trainer/Policy mu Min              -1.96202
trainer/Policy log std Mean        -2.18021
trainer/Policy log std Std          0.39588
trainer/Policy log std Max         -0.523862
trainer/Policy log std Min         -2.48047
trainer/Alpha                       0.019359
trainer/Alpha Loss                 -0.864905
exploration/num steps total     38400
exploration/num paths total       384
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.0915017
exploration/Rewards Std             0.154326
exploration/Rewards Max            -0.00389736
exploration/Rewards Min            -1
exploration/Returns Mean           -9.15017
exploration/Returns Std             0.0151711
exploration/Returns Max            -9.13499
exploration/Returns Min            -9.16534
exploration/Actions Mean            0.0416166
exploration/Actions Std             0.230445
exploration/Actions Max             0.993614
exploration/Actions Min            -0.386576
exploration/Num Paths               2
exploration/Average Returns        -9.15017
evaluation/num steps total     191000
evaluation/num paths total       1910
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0930674
evaluation/Rewards Std              0.202206
evaluation/Rewards Max             -0.0440171
evaluation/Rewards Min             -1
evaluation/Returns Mean            -9.30674
evaluation/Returns Std              2.78753
evaluation/Returns Max             -4.49747
evaluation/Returns Min            -12.4759
evaluation/Actions Mean             0.0275212
evaluation/Actions Std              0.20538
evaluation/Actions Max              0.989708
evaluation/Actions Min             -0.977145
evaluation/Num Paths               10
evaluation/Average Returns         -9.30674
time/data storing (s)               0.00128942
time/evaluation sampling (s)        0.275127
time/exploration sampling (s)       0.0722296
time/logging (s)                    0.00367373
time/saving (s)                     0.00255008
time/training (s)                   1.15026
time/epoch (s)                      1.50513
time/total (s)                    290.055
Epoch                             190
-----------------------------  ---------------
2019-04-22 20:57:28.241530 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 191 finished
-----------------------------  ---------------
replay_buffer/size              38600
trainer/QF1 Loss                    0.00203584
trainer/QF2 Loss                    0.0015228
trainer/Policy Loss                 6.05106
trainer/Q1 Predictions Mean        -4.04555
trainer/Q1 Predictions Std          1.39232
trainer/Q1 Predictions Max         -3.52472
trainer/Q1 Predictions Min        -10.9802
trainer/Q2 Predictions Mean        -4.05342
trainer/Q2 Predictions Std          1.40019
trainer/Q2 Predictions Max         -3.52613
trainer/Q2 Predictions Min        -10.9924
trainer/Q Targets Mean             -4.06628
trainer/Q Targets Std               1.40044
trainer/Q Targets Max              -3.52584
trainer/Q Targets Min             -10.9637
trainer/Log Pis Mean                2.09086
trainer/Log Pis Std                 1.29265
trainer/Log Pis Max                 6.52895
trainer/Log Pis Min                -2.00058
trainer/Policy mu Mean              0.158503
trainer/Policy mu Std               0.709542
trainer/Policy mu Max               2.67296
trainer/Policy mu Min              -1.97326
trainer/Policy log std Mean        -2.09927
trainer/Policy log std Std          0.514394
trainer/Policy log std Max         -0.539159
trainer/Policy log std Min         -2.48511
trainer/Alpha                       0.0194363
trainer/Alpha Loss                  0.358053
exploration/num steps total     38600
exploration/num paths total       386
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.10915
exploration/Rewards Std             0.226804
exploration/Rewards Max            -0.00446843
exploration/Rewards Min            -1
exploration/Returns Mean          -10.915
exploration/Returns Std             2.73058
exploration/Returns Max            -8.18446
exploration/Returns Min           -13.6456
exploration/Actions Mean            0.0453077
exploration/Actions Std             0.243836
exploration/Actions Max             0.99649
exploration/Actions Min            -0.588491
exploration/Num Paths               2
exploration/Average Returns       -10.915
evaluation/num steps total     192000
evaluation/num paths total       1920
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0604478
evaluation/Rewards Std              0.198991
evaluation/Rewards Max             -0.0136845
evaluation/Rewards Min             -1
evaluation/Returns Mean            -6.04478
evaluation/Returns Std              1.87565
evaluation/Returns Max             -3.60744
evaluation/Returns Min            -10.3022
evaluation/Actions Mean             0.030022
evaluation/Actions Std              0.203381
evaluation/Actions Max              0.990612
evaluation/Actions Min             -0.966342
evaluation/Num Paths               10
evaluation/Average Returns         -6.04478
time/data storing (s)               0.00135047
time/evaluation sampling (s)        0.291558
time/exploration sampling (s)       0.0734569
time/logging (s)                    0.00353744
time/saving (s)                     0.00250683
time/training (s)                   1.2206
time/epoch (s)                      1.59301
time/total (s)                    291.653
Epoch                             191
-----------------------------  ---------------
2019-04-22 20:57:29.808626 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 192 finished
-----------------------------  ---------------
replay_buffer/size              38800
trainer/QF1 Loss                    0.124234
trainer/QF2 Loss                    0.124319
trainer/Policy Loss                 5.97655
trainer/Q1 Predictions Mean        -3.93586
trainer/Q1 Predictions Std          1.19188
trainer/Q1 Predictions Max         -3.53232
trainer/Q1 Predictions Min        -10.7575
trainer/Q2 Predictions Mean        -3.93415
trainer/Q2 Predictions Std          1.17944
trainer/Q2 Predictions Max         -3.53403
trainer/Q2 Predictions Min        -10.6932
trainer/Q Targets Mean             -3.90964
trainer/Q Targets Std               1.26104
trainer/Q Targets Max              -0.0955214
trainer/Q Targets Min             -10.8021
trainer/Log Pis Mean                2.11264
trainer/Log Pis Std                 1.07626
trainer/Log Pis Max                 6.14184
trainer/Log Pis Min                -1.7433
trainer/Policy mu Mean              0.106889
trainer/Policy mu Std               0.658011
trainer/Policy mu Max               2.71651
trainer/Policy mu Min              -2.43032
trainer/Policy log std Mean        -2.14267
trainer/Policy log std Std          0.497999
trainer/Policy log std Max         -0.452347
trainer/Policy log std Min         -2.47772
trainer/Alpha                       0.0192974
trainer/Alpha Loss                  0.444659
exploration/num steps total     38800
exploration/num paths total       388
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.0975768
exploration/Rewards Std             0.196565
exploration/Rewards Max            -0.00521327
exploration/Rewards Min            -1
exploration/Returns Mean           -9.75768
exploration/Returns Std             0.478697
exploration/Returns Max            -9.27898
exploration/Returns Min           -10.2364
exploration/Actions Mean            0.0188772
exploration/Actions Std             0.254278
exploration/Actions Max             0.989438
exploration/Actions Min            -0.998429
exploration/Num Paths               2
exploration/Average Returns        -9.75768
evaluation/num steps total     193000
evaluation/num paths total       1930
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0511296
evaluation/Rewards Std              0.149474
evaluation/Rewards Max             -0.0211574
evaluation/Rewards Min             -1
evaluation/Returns Mean            -5.11296
evaluation/Returns Std              2.29989
evaluation/Returns Max             -2.66542
evaluation/Returns Min            -10.0309
evaluation/Actions Mean             0.0161276
evaluation/Actions Std              0.167773
evaluation/Actions Max              0.990529
evaluation/Actions Min             -0.981541
evaluation/Num Paths               10
evaluation/Average Returns         -5.11296
time/data storing (s)               0.00142252
time/evaluation sampling (s)        0.302796
time/exploration sampling (s)       0.0733485
time/logging (s)                    0.00422773
time/saving (s)                     0.00253042
time/training (s)                   1.17593
time/epoch (s)                      1.56026
time/total (s)                    293.218
Epoch                             192
-----------------------------  ---------------
2019-04-22 20:57:31.407209 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 193 finished
-----------------------------  ---------------
replay_buffer/size              39000
trainer/QF1 Loss                    0.247197
trainer/QF2 Loss                    0.244973
trainer/Policy Loss                 5.74036
trainer/Q1 Predictions Mean        -3.84665
trainer/Q1 Predictions Std          1.35292
trainer/Q1 Predictions Max         -3.45849
trainer/Q1 Predictions Min        -11.7089
trainer/Q2 Predictions Mean        -3.84018
trainer/Q2 Predictions Std          1.36416
trainer/Q2 Predictions Max         -3.44416
trainer/Q2 Predictions Min        -11.8621
trainer/Q Targets Mean             -3.83885
trainer/Q Targets Std               1.44972
trainer/Q Targets Max              -0.108195
trainer/Q Targets Min             -11.9778
trainer/Log Pis Mean                1.99424
trainer/Log Pis Std                 1.30417
trainer/Log Pis Max                 4.15726
trainer/Log Pis Min                -5.94516
trainer/Policy mu Mean              0.056154
trainer/Policy mu Std               0.510053
trainer/Policy mu Max               2.44122
trainer/Policy mu Min              -2.41089
trainer/Policy log std Mean        -2.27341
trainer/Policy log std Std          0.422941
trainer/Policy log std Max         -0.467173
trainer/Policy log std Min         -2.60267
trainer/Alpha                       0.0196682
trainer/Alpha Loss                 -0.0226429
exploration/num steps total     39000
exploration/num paths total       390
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.0921341
exploration/Rewards Std             0.174467
exploration/Rewards Max            -0.00500903
exploration/Rewards Min            -1
exploration/Returns Mean           -9.21341
exploration/Returns Std             0.931967
exploration/Returns Max            -8.28144
exploration/Returns Min           -10.1454
exploration/Actions Mean            0.0394522
exploration/Actions Std             0.215151
exploration/Actions Max             0.996968
exploration/Actions Min            -0.423463
exploration/Num Paths               2
exploration/Average Returns        -9.21341
evaluation/num steps total     194000
evaluation/num paths total       1940
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0735251
evaluation/Rewards Std              0.178885
evaluation/Rewards Max             -0.0054807
evaluation/Rewards Min             -1
evaluation/Returns Mean            -7.35251
evaluation/Returns Std              3.25651
evaluation/Returns Max             -3.61887
evaluation/Returns Min            -12.3711
evaluation/Actions Mean             0.0305288
evaluation/Actions Std              0.180132
evaluation/Actions Max              0.990996
evaluation/Actions Min             -0.988594
evaluation/Num Paths               10
evaluation/Average Returns         -7.35251
time/data storing (s)               0.00138892
time/evaluation sampling (s)        0.308641
time/exploration sampling (s)       0.07456
time/logging (s)                    0.0035502
time/saving (s)                     0.00259077
time/training (s)                   1.19907
time/epoch (s)                      1.5898
time/total (s)                    294.812
Epoch                             193
-----------------------------  ---------------
2019-04-22 20:57:33.041132 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 194 finished
-----------------------------  ---------------
replay_buffer/size              39200
trainer/QF1 Loss                    0.246698
trainer/QF2 Loss                    0.247584
trainer/Policy Loss                 5.78735
trainer/Q1 Predictions Mean        -3.85751
trainer/Q1 Predictions Std          0.932465
trainer/Q1 Predictions Max         -3.49411
trainer/Q1 Predictions Min        -10.3421
trainer/Q2 Predictions Mean        -3.85723
trainer/Q2 Predictions Std          0.928202
trainer/Q2 Predictions Max         -3.4982
trainer/Q2 Predictions Min        -10.3604
trainer/Q Targets Mean             -3.788
trainer/Q Targets Std               1.03198
trainer/Q Targets Max              -0.0559695
trainer/Q Targets Min             -10.1533
trainer/Log Pis Mean                2.05429
trainer/Log Pis Std                 1.11658
trainer/Log Pis Max                 5.3028
trainer/Log Pis Min                -0.768285
trainer/Policy mu Mean              0.0274529
trainer/Policy mu Std               0.653154
trainer/Policy mu Max               2.44579
trainer/Policy mu Min              -2.68266
trainer/Policy log std Mean        -2.1465
trainer/Policy log std Std          0.491501
trainer/Policy log std Max         -0.485174
trainer/Policy log std Min         -2.55034
trainer/Alpha                       0.0197231
trainer/Alpha Loss                  0.213137
exploration/num steps total     39200
exploration/num paths total       392
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.103778
exploration/Rewards Std             0.215361
exploration/Rewards Max            -0.00509072
exploration/Rewards Min            -1
exploration/Returns Mean          -10.3778
exploration/Returns Std             0.300027
exploration/Returns Max           -10.0778
exploration/Returns Min           -10.6778
exploration/Actions Mean            0.0428776
exploration/Actions Std             0.236724
exploration/Actions Max             0.9968
exploration/Actions Min            -0.954005
exploration/Num Paths               2
exploration/Average Returns       -10.3778
evaluation/num steps total     195000
evaluation/num paths total       1950
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.05395
evaluation/Rewards Std              0.190524
evaluation/Rewards Max             -0.00549665
evaluation/Rewards Min             -1
evaluation/Returns Mean            -5.395
evaluation/Returns Std              2.14486
evaluation/Returns Max             -2.09721
evaluation/Returns Min             -8.57662
evaluation/Actions Mean             0.0286993
evaluation/Actions Std              0.194633
evaluation/Actions Max              0.98956
evaluation/Actions Min             -0.989196
evaluation/Num Paths               10
evaluation/Average Returns         -5.395
time/data storing (s)               0.00135554
time/evaluation sampling (s)        0.312526
time/exploration sampling (s)       0.0806971
time/logging (s)                    0.00300583
time/saving (s)                     0.00249352
time/training (s)                   1.22611
time/epoch (s)                      1.62619
time/total (s)                    296.442
Epoch                             194
-----------------------------  ---------------
2019-04-22 20:57:34.520945 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 195 finished
-----------------------------  ---------------
replay_buffer/size              39400
trainer/QF1 Loss                    0.00317446
trainer/QF2 Loss                    0.00281074
trainer/Policy Loss                 5.82217
trainer/Q1 Predictions Mean        -3.94667
trainer/Q1 Predictions Std          1.31382
trainer/Q1 Predictions Max         -3.47384
trainer/Q1 Predictions Min        -11.2619
trainer/Q2 Predictions Mean        -3.95199
trainer/Q2 Predictions Std          1.30069
trainer/Q2 Predictions Max         -3.48531
trainer/Q2 Predictions Min        -11.2355
trainer/Q Targets Mean             -3.95664
trainer/Q Targets Std               1.2763
trainer/Q Targets Max              -3.45154
trainer/Q Targets Min             -11.0244
trainer/Log Pis Mean                1.99136
trainer/Log Pis Std                 1.23323
trainer/Log Pis Max                 5.29674
trainer/Log Pis Min                -3.43496
trainer/Policy mu Mean              0.0404335
trainer/Policy mu Std               0.689094
trainer/Policy mu Max               2.46888
trainer/Policy mu Min              -2.32572
trainer/Policy log std Mean        -2.08773
trainer/Policy log std Std          0.521902
trainer/Policy log std Max         -0.515879
trainer/Policy log std Min         -2.48277
trainer/Alpha                       0.0199859
trainer/Alpha Loss                 -0.0338149
exploration/num steps total     39400
exploration/num paths total       394
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.0965337
exploration/Rewards Std             0.2022
exploration/Rewards Max            -0.00774183
exploration/Rewards Min            -1
exploration/Returns Mean           -9.65337
exploration/Returns Std             0.483751
exploration/Returns Max            -9.16961
exploration/Returns Min           -10.1371
exploration/Actions Mean            0.0131456
exploration/Actions Std             0.249595
exploration/Actions Max             0.990806
exploration/Actions Min            -0.996386
exploration/Num Paths               2
exploration/Average Returns        -9.65337
evaluation/num steps total     196000
evaluation/num paths total       1960
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0535324
evaluation/Rewards Std              0.163603
evaluation/Rewards Max             -0.00459524
evaluation/Rewards Min             -1
evaluation/Returns Mean            -5.35324
evaluation/Returns Std              1.80375
evaluation/Returns Max             -2.15138
evaluation/Returns Min             -8.78108
evaluation/Actions Mean             0.0143337
evaluation/Actions Std              0.180077
evaluation/Actions Max              0.98748
evaluation/Actions Min             -0.989437
evaluation/Num Paths               10
evaluation/Average Returns         -5.35324
time/data storing (s)               0.00131734
time/evaluation sampling (s)        0.298726
time/exploration sampling (s)       0.0780186
time/logging (s)                    0.00357951
time/saving (s)                     0.00196454
time/training (s)                   1.08897
time/epoch (s)                      1.47257
time/total (s)                    297.919
Epoch                             195
-----------------------------  ---------------
2019-04-22 20:57:35.919483 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 196 finished
-----------------------------  ---------------
replay_buffer/size              39600
trainer/QF1 Loss                    0.121969
trainer/QF2 Loss                    0.122598
trainer/Policy Loss                 5.80367
trainer/Q1 Predictions Mean        -3.90567
trainer/Q1 Predictions Std          1.37045
trainer/Q1 Predictions Max         -3.43292
trainer/Q1 Predictions Min        -11.7798
trainer/Q2 Predictions Mean        -3.91252
trainer/Q2 Predictions Std          1.38804
trainer/Q2 Predictions Max         -3.43083
trainer/Q2 Predictions Min        -11.8051
trainer/Q Targets Mean             -3.91801
trainer/Q Targets Std               1.42206
trainer/Q Targets Max              -0.33805
trainer/Q Targets Min             -11.7315
trainer/Log Pis Mean                1.98165
trainer/Log Pis Std                 1.05617
trainer/Log Pis Max                 5.36381
trainer/Log Pis Min                -0.858432
trainer/Policy mu Mean              0.0504883
trainer/Policy mu Std               0.642496
trainer/Policy mu Max               2.53211
trainer/Policy mu Min              -2.53426
trainer/Policy log std Mean        -2.06514
trainer/Policy log std Std          0.489485
trainer/Policy log std Max         -0.387779
trainer/Policy log std Min         -2.42997
trainer/Alpha                       0.0202977
trainer/Alpha Loss                 -0.0715294
exploration/num steps total     39600
exploration/num paths total       396
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.0956056
exploration/Rewards Std             0.186066
exploration/Rewards Max            -0.00492439
exploration/Rewards Min            -1
exploration/Returns Mean           -9.56056
exploration/Returns Std             1.51143
exploration/Returns Max            -8.04913
exploration/Returns Min           -11.072
exploration/Actions Mean            0.0255184
exploration/Actions Std             0.241739
exploration/Actions Max             0.995526
exploration/Actions Min            -0.962742
exploration/Num Paths               2
exploration/Average Returns        -9.56056
evaluation/num steps total     197000
evaluation/num paths total       1970
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0550448
evaluation/Rewards Std              0.150755
evaluation/Rewards Max             -0.00995261
evaluation/Rewards Min             -1
evaluation/Returns Mean            -5.50448
evaluation/Returns Std              1.9728
evaluation/Returns Max             -2.75724
evaluation/Returns Min             -9.3897
evaluation/Actions Mean             0.00487783
evaluation/Actions Std              0.167236
evaluation/Actions Max              0.989857
evaluation/Actions Min             -0.990546
evaluation/Num Paths               10
evaluation/Average Returns         -5.50448
time/data storing (s)               0.001303
time/evaluation sampling (s)        0.295216
time/exploration sampling (s)       0.0732674
time/logging (s)                    0.00359798
time/saving (s)                     0.00261521
time/training (s)                   1.01466
time/epoch (s)                      1.39066
time/total (s)                    299.314
Epoch                             196
-----------------------------  ---------------
2019-04-22 20:57:37.313814 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 197 finished
-----------------------------  ---------------
replay_buffer/size              39800
trainer/QF1 Loss                    0.00770893
trainer/QF2 Loss                    0.00775792
trainer/Policy Loss                 5.62238
trainer/Q1 Predictions Mean        -3.79036
trainer/Q1 Predictions Std          1.29702
trainer/Q1 Predictions Max         -3.39144
trainer/Q1 Predictions Min        -12.4279
trainer/Q2 Predictions Mean        -3.79662
trainer/Q2 Predictions Std          1.28459
trainer/Q2 Predictions Max         -3.39601
trainer/Q2 Predictions Min        -12.2392
trainer/Q Targets Mean             -3.8608
trainer/Q Targets Std               1.32058
trainer/Q Targets Max              -3.42044
trainer/Q Targets Min             -12.6773
trainer/Log Pis Mean                1.91504
trainer/Log Pis Std                 1.16912
trainer/Log Pis Max                 4.30095
trainer/Log Pis Min                -3.19223
trainer/Policy mu Mean              0.0465915
trainer/Policy mu Std               0.567021
trainer/Policy mu Max               2.47138
trainer/Policy mu Min              -2.42896
trainer/Policy log std Mean        -2.10193
trainer/Policy log std Std          0.462044
trainer/Policy log std Max         -0.337573
trainer/Policy log std Min         -2.48421
trainer/Alpha                       0.0202744
trainer/Alpha Loss                 -0.331205
exploration/num steps total     39800
exploration/num paths total       398
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.100904
exploration/Rewards Std             0.197952
exploration/Rewards Max            -0.00447165
exploration/Rewards Min            -1
exploration/Returns Mean          -10.0904
exploration/Returns Std             1.30776
exploration/Returns Max            -8.78262
exploration/Returns Min           -11.3981
exploration/Actions Mean            0.0354238
exploration/Actions Std             0.248876
exploration/Actions Max             0.994512
exploration/Actions Min            -0.997806
exploration/Num Paths               2
exploration/Average Returns       -10.0904
evaluation/num steps total     198000
evaluation/num paths total       1980
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0736712
evaluation/Rewards Std              0.191821
evaluation/Rewards Max             -0.0174017
evaluation/Rewards Min             -1
evaluation/Returns Mean            -7.36712
evaluation/Returns Std              2.47852
evaluation/Returns Max             -3.7103
evaluation/Returns Min            -12.3719
evaluation/Actions Mean             0.0333984
evaluation/Actions Std              0.195289
evaluation/Actions Max              0.989756
evaluation/Actions Min             -0.990197
evaluation/Num Paths               10
evaluation/Average Returns         -7.36712
time/data storing (s)               0.00126299
time/evaluation sampling (s)        0.28564
time/exploration sampling (s)       0.0696092
time/logging (s)                    0.00345954
time/saving (s)                     0.00240213
time/training (s)                   1.02354
time/epoch (s)                      1.38591
time/total (s)                    300.704
Epoch                             197
-----------------------------  ---------------
2019-04-22 20:57:38.654473 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 198 finished
-----------------------------  ---------------
replay_buffer/size              40000
trainer/QF1 Loss                    0.0028736
trainer/QF2 Loss                    0.00354782
trainer/Policy Loss                 6.1784
trainer/Q1 Predictions Mean        -4.15926
trainer/Q1 Predictions Std          1.82387
trainer/Q1 Predictions Max         -3.42492
trainer/Q1 Predictions Min        -13.2251
trainer/Q2 Predictions Mean        -4.16711
trainer/Q2 Predictions Std          1.84271
trainer/Q2 Predictions Max         -3.42309
trainer/Q2 Predictions Min        -13.3393
trainer/Q Targets Mean             -4.18018
trainer/Q Targets Std               1.81246
trainer/Q Targets Max              -3.40725
trainer/Q Targets Min             -12.9775
trainer/Log Pis Mean                2.12333
trainer/Log Pis Std                 1.0791
trainer/Log Pis Max                 5.90349
trainer/Log Pis Min                -2.31287
trainer/Policy mu Mean              0.151805
trainer/Policy mu Std               0.758547
trainer/Policy mu Max               2.58585
trainer/Policy mu Min              -2.1645
trainer/Policy log std Mean        -2.02121
trainer/Policy log std Std          0.592414
trainer/Policy log std Max         -0.438394
trainer/Policy log std Min         -2.46275
trainer/Alpha                       0.0197915
trainer/Alpha Loss                  0.483758
exploration/num steps total     40000
exploration/num paths total       400
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.0648382
exploration/Rewards Std             0.110391
exploration/Rewards Max            -0.00283716
exploration/Rewards Min            -1
exploration/Returns Mean           -6.48382
exploration/Returns Std             1.49582
exploration/Returns Max            -4.988
exploration/Returns Min            -7.97964
exploration/Actions Mean            0.0106622
exploration/Actions Std             0.179469
exploration/Actions Max             0.996531
exploration/Actions Min            -0.986855
exploration/Num Paths               2
exploration/Average Returns        -6.48382
evaluation/num steps total     199000
evaluation/num paths total       1990
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0624479
evaluation/Rewards Std              0.175167
evaluation/Rewards Max             -0.0256371
evaluation/Rewards Min             -1
evaluation/Returns Mean            -6.24479
evaluation/Returns Std              2.84675
evaluation/Returns Max             -2.70841
evaluation/Returns Min            -11.5417
evaluation/Actions Mean             0.0282453
evaluation/Actions Std              0.178347
evaluation/Actions Max              0.992338
evaluation/Actions Min             -0.948377
evaluation/Num Paths               10
evaluation/Average Returns         -6.24479
time/data storing (s)               0.00125938
time/evaluation sampling (s)        0.273169
time/exploration sampling (s)       0.0698703
time/logging (s)                    0.00337631
time/saving (s)                     0.00233544
time/training (s)                   0.983288
time/epoch (s)                      1.3333
time/total (s)                    302.042
Epoch                             198
-----------------------------  ---------------
2019-04-22 20:57:39.980062 PDT | [sac-pointmass-multitask-1_2019_04_22_20_52_36_0000--s-0] Epoch 199 finished
-----------------------------  ---------------
replay_buffer/size              40200
trainer/QF1 Loss                    0.118206
trainer/QF2 Loss                    0.116476
trainer/Policy Loss                 5.56864
trainer/Q1 Predictions Mean        -3.76959
trainer/Q1 Predictions Std          1.24626
trainer/Q1 Predictions Max         -3.39293
trainer/Q1 Predictions Min        -11.6739
trainer/Q2 Predictions Mean        -3.77359
trainer/Q2 Predictions Std          1.24962
trainer/Q2 Predictions Max         -3.38788
trainer/Q2 Predictions Min        -11.6542
trainer/Q Targets Mean             -3.77817
trainer/Q Targets Std               1.29159
trainer/Q Targets Max              -0.054551
trainer/Q Targets Min             -11.5724
trainer/Log Pis Mean                1.89422
trainer/Log Pis Std                 1.30002
trainer/Log Pis Max                 4.44806
trainer/Log Pis Min                -6.00803
trainer/Policy mu Mean              0.171648
trainer/Policy mu Std               0.563777
trainer/Policy mu Max               2.42501
trainer/Policy mu Min              -1.50865
trainer/Policy log std Mean        -2.13712
trainer/Policy log std Std          0.445773
trainer/Policy log std Max         -0.61758
trainer/Policy log std Min         -2.45336
trainer/Alpha                       0.0197003
trainer/Alpha Loss                 -0.415371
exploration/num steps total     40200
exploration/num paths total       402
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.0709753
exploration/Rewards Std             0.11965
exploration/Rewards Max            -0.00797877
exploration/Rewards Min            -1
exploration/Returns Mean           -7.09753
exploration/Returns Std             0.698354
exploration/Returns Max            -6.39918
exploration/Returns Min            -7.79589
exploration/Actions Mean            0.0111096
exploration/Actions Std             0.213767
exploration/Actions Max             0.997058
exploration/Actions Min            -0.993743
exploration/Num Paths               2
exploration/Average Returns        -7.09753
evaluation/num steps total     200000
evaluation/num paths total       2000
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.062713
evaluation/Rewards Std              0.184537
evaluation/Rewards Max             -0.00775741
evaluation/Rewards Min             -1
evaluation/Returns Mean            -6.2713
evaluation/Returns Std              2.14444
evaluation/Returns Max             -2.53474
evaluation/Returns Min            -11.1186
evaluation/Actions Mean             0.00567629
evaluation/Actions Std              0.189903
evaluation/Actions Max              0.989476
evaluation/Actions Min             -0.992897
evaluation/Num Paths               10
evaluation/Average Returns         -6.2713
time/data storing (s)               0.00122137
time/evaluation sampling (s)        0.26532
time/exploration sampling (s)       0.0677277
time/logging (s)                    0.00332035
time/saving (s)                     0.00245933
time/training (s)                   0.977952
time/epoch (s)                      1.318
time/total (s)                    303.364
Epoch                             199
-----------------------------  ---------------
